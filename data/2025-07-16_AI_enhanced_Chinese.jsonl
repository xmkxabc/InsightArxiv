{"id": "2507.12104", "title": "From Static to Intelligent: Evolving SaaS Pricing with LLMs", "authors": ["Francisco Javier Cavero", "Juan C. Alonso", "Antonio Ruiz-Cortés"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      12 pages. Accepted at the SOC4AI Workshop (Service-Oriented Computing for AI Applications), held in conjunction with the 22nd International Conference on Service-Oriented Computing (ICSOC 2024)", "url": "http://arxiv.org/abs/2507.12104v1", "summary": "The SaaS paradigm has revolutionized software distribution by offering\nflexible pricing options to meet diverse customer needs. However, the rapid\nexpansion of the SaaS market has introduced significant complexity for DevOps\nteams, who must manually manage and evolve pricing structures, an approach that\nis both time-consuming and prone to errors. The absence of automated tools for\npricing analysis restricts the ability to efficiently evaluate, optimize, and\nscale these models. This paper proposes leveraging intelligent pricing\n(iPricing), dynamic, machine-readable pricing models, as a solution to these\nchallenges. Intelligent pricing enables competitive analysis, streamlines\noperational decision-making, and supports continuous pricing evolution in\nresponse to market dynamics, leading to improved efficiency and accuracy. We\npresent an LLM-driven approach that automates the transformation of static HTML\npricing into iPricing, significantly improving efficiency and consistency while\nminimizing human error. Our implementation, AI4Pricing2Yaml, features a basic\nInformation Extractor that uses web scraping and LLMs technologies to extract\nessential pricing components, plans, features, usage limits, and add-ons, from\nSaaS websites. Validation against a dataset of 30 distinct commercial SaaS,\nencompassing over 150 intelligent pricings, demonstrates the system's\neffectiveness in extracting the desired elements across all steps. However,\nchallenges remain in addressing hallucinations, complex structures, and dynamic\ncontent. This work highlights the potential of automating intelligent pricing\ntransformation to streamline SaaS pricing management, offering implications for\nimproved consistency and scalability in an increasingly intricate pricing\nlandscape. Future research will focus on refining extraction capabilities and\nenhancing the system's adaptability to a wider range of SaaS websites.", "comment": "12 pages. Accepted at the SOC4AI Workshop (Service-Oriented Computing\n  for AI Applications), held in conjunction with the 22nd International\n  Conference on Service-Oriented Computing (ICSOC 2024)", "pdf_url": "http://arxiv.org/pdf/2507.12104v1", "cate": "cs.SE", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "从静态到智能：利用大型语言模型演进SaaS定价", "tldr": "本文提出了一种利用大型语言模型（LLM）自动化SaaS定价结构从静态HTML到动态智能定价（iPricing）的转换方法，以提高效率和准确性，并已通过实验验证其有效性。", "motivation": "SaaS市场的快速扩张使得DevOps团队手动管理和演进定价结构变得复杂、耗时且容易出错。缺乏自动化的定价分析工具限制了对定价模型进行高效评估、优化和扩展的能力。", "method": "本文提出了一种名为智能定价（iPricing）的动态、机器可读的定价模型，以解决SaaS定价管理的挑战。具体实现上，提出了一个由LLM驱动的方法，自动化将静态HTML定价转换为iPricing。该方法名为AI4Pricing2Yaml，其核心是一个基本的信息提取器，利用网络抓取和LLM技术从SaaS网站中提取关键定价组件、计划、功能、使用限制和附加项。", "result": "该系统在包含30个不同商业SaaS（涵盖150多个智能定价）的数据集上进行了验证，结果表明系统在所有步骤中都能有效提取所需元素。然而，在处理幻觉、复杂结构和动态内容方面仍存在挑战。", "conclusion": "这项工作突出了自动化智能定价转换在简化SaaS定价管理方面的潜力，对在日益复杂的定价环境中提高一致性和可扩展性具有重要意义。未来的研究将侧重于改进提取能力和增强系统对更广泛SaaS网站的适应性。", "translation": "SaaS范式通过提供灵活的定价选项来满足多样化的客户需求，彻底改变了软件分发。然而，SaaS市场的快速扩张给DevOps团队带来了显著的复杂性，他们必须手动管理和演进定价结构，这种方法既耗时又容易出错。缺乏自动化的定价分析工具限制了高效评估、优化和扩展这些模型的能力。本文提出利用智能定价（iPricing），即动态的、机器可读的定价模型，作为解决这些挑战的方案。智能定价能够实现竞争分析，简化操作决策，并支持根据市场动态进行持续的定价演进，从而提高效率和准确性。我们提出了一种由大型语言模型（LLM）驱动的方法，该方法自动化了静态HTML定价到iPricing的转换，显著提高了效率和一致性，同时最大限度地减少了人为错误。我们的实现AI4Pricing2Yaml，其特点是一个基本的信息提取器，利用网络抓取和LLM技术从SaaS网站中提取必要的定价组件、计划、功能、使用限制和附加项。对包含30个不同商业SaaS（涵盖150多个智能定价）的数据集进行验证，证明了系统在所有步骤中提取所需元素的有效性。然而，在解决幻觉、复杂结构和动态内容方面仍存在挑战。这项工作突出了自动化智能定价转换在简化SaaS定价管理方面的潜力，对在日益复杂的定价环境中提高一致性和可扩展性具有重要意义。未来的研究将侧重于改进提取能力和增强系统对更广泛SaaS网站的适应性。", "summary": "本研究旨在解决SaaS定价结构手动管理带来的复杂性和低效问题。论文提出了一种名为智能定价（iPricing）的动态、机器可读模型，并开发了AI4Pricing2Yaml系统，该系统利用大型语言模型（LLM）和网络抓取技术，自动化将静态HTML定价信息转换为iPricing。实验证明，该方法能有效提取定价组件，提高了效率和一致性，尽管在处理复杂内容方面仍面临挑战。这项工作展示了自动化智能定价转换在简化SaaS定价管理中的潜力，并为提高定价一致性和可扩展性提供了方向。", "keywords": "SaaS定价, 大型语言模型, 智能定价, 自动化, 信息提取", "comments": "本文提出了一种创新的方法，将大型语言模型应用于SaaS定价管理的自动化，解决了当前手动管理效率低、易出错的痛点。通过引入“智能定价”（iPricing）的概念并构建AI4Pricing2Yaml系统，展示了LLM在结构化非结构化网页数据方面的强大潜力。尽管面临幻觉和复杂结构等挑战，但其对提高SaaS定价管理效率和一致性的贡献是显著的，为未来智能定价系统的发展奠定了基础。"}}
{"id": "2507.11742", "title": "CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks", "authors": ["Meng Li", "Timothy M. McPhillips", "Dingmin Wang", "Shin-Rong Tsai", "Bertram Ludäscher"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint. Accepted to COLM 2025", "url": "http://arxiv.org/abs/2507.11742v1", "summary": "Recognizing the information flows and operations comprising data science and\nmachine learning Python notebooks is critical for evaluating, reusing, and\nadapting notebooks for new tasks. Investigating a notebook via re-execution\noften is impractical due to the challenges of resolving data and software\ndependencies. While Large Language Models (LLMs) pre-trained on large codebases\nhave demonstrated effectiveness in understanding code without running it, we\nobserve that they fail to understand some realistic notebooks due to\nhallucinations and long-context challenges. To address these issues, we propose\na notebook understanding task yielding an information flow graph and\ncorresponding cell execution dependency graph for a notebook, and demonstrate\nthe effectiveness of a pincer strategy that uses limited syntactic analysis to\nassist full comprehension of the notebook using an LLM. Our Capture and Resolve\nAssisted Bounding Strategy (CRABS) employs shallow syntactic parsing and\nanalysis of the abstract syntax tree (AST) to capture the correct\ninterpretation of a notebook between lower and upper estimates of the\ninter-cell I/O sets, then uses an LLM to resolve remaining ambiguities via\ncell-by-cell zero-shot learning, thereby identifying the true data inputs and\noutputs of each cell. We evaluate and demonstrate the effectiveness of our\napproach using an annotated dataset of 50 representative, highly up-voted\nKaggle notebooks that together represent 3454 actual cell inputs and outputs.\nThe LLM correctly resolves 1397 of 1425 (98%) ambiguities left by analyzing the\nsyntactic structure of these notebooks. Across 50 notebooks, CRABS achieves\naverage F1 scores of 98% identifying cell-to-cell information flows and 99%\nidentifying transitive cell execution dependencies.", "comment": "Preprint. Accepted to COLM 2025", "pdf_url": "http://arxiv.org/pdf/2507.11742v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "CRABS：一种用于限制LLM对Python笔记本解释的句法-语义钳形策略", "tldr": "LLM在理解Python笔记本时存在幻觉和长上下文问题。CRABS提出一种结合句法分析和LLM的钳形策略，以准确识别笔记本的信息流和单元格执行依赖，效果显著。", "motivation": "识别数据科学和机器学习Python笔记本中的信息流和操作对于评估、重用和改编笔记本至关重要。由于数据和软件依赖性，重新执行笔记本通常不切实际。尽管大型语言模型（LLM）在不运行代码的情况下理解代码方面表现出有效性，但它们在理解真实笔记本时因幻觉和长上下文挑战而失败。", "method": "本文提出了一个笔记本理解任务，旨在生成信息流图和单元格执行依赖图。为此，作者提出了CRABS（Capture and Resolve Assisted Bounding Strategy）方法。CRABS首先利用浅层句法解析和抽象语法树（AST）分析来捕获单元格间I/O集的上下限之间笔记本的正确解释，然后使用LLM通过逐单元格零样本学习来解决剩余的歧义，从而识别每个单元格的真实数据输入和输出。", "result": "在包含50个高赞Kaggle笔记本（总计3454个实际单元格输入输出）的标注数据集上进行评估。LLM正确解决了句法结构分析后留下的1425个歧义中的1397个（98%）。在50个笔记本中，CRABS在识别单元格间信息流方面实现了98%的平均F1分数，在识别传递性单元格执行依赖方面实现了99%的平均F1分数。", "conclusion": "CRABS通过结合有限的句法分析和LLM的零样本学习，有效解决了LLM理解Python笔记本时面临的挑战，并显著提高了信息流和执行依赖识别的准确性。", "translation": "识别构成数据科学和机器学习Python笔记本的信息流和操作对于评估、重用和改编笔记本以适应新任务至关重要。由于解决数据和软件依赖性的挑战，通过重新执行来调查笔记本通常不切实际。虽然在大规模代码库上预训练的大型语言模型（LLM）在不运行代码的情况下理解代码方面表现出有效性，但我们观察到它们由于幻觉和长上下文挑战而未能理解一些真实的笔记本。为了解决这些问题，我们提出了一个笔记本理解任务，为笔记本生成信息流图和相应的单元格执行依赖图，并展示了一种钳形策略的有效性，该策略使用有限的句法分析来辅助LLM对笔记本的全面理解。我们的捕获和解析辅助边界策略（CRABS）采用浅层句法解析和抽象语法树（AST）分析，在单元格间I/O集的下限和上限之间捕获笔记本的正确解释，然后使用LLM通过逐单元格零样本学习来解决剩余的歧义，从而识别每个单元格的真实数据输入和输出。我们使用一个包含50个具有代表性、高赞Kaggle笔记本的标注数据集评估并展示了我们方法的有效性，这些笔记本总共代表了3454个实际单元格输入和输出。LLM正确解决了分析这些笔记本的句法结构后留下的1425个歧义中的1397个（98%）。在50个笔记本中，CRABS在识别单元格到单元格信息流方面实现了98%的平均F1分数，在识别传递性单元格执行依赖方面实现了99%的平均F1分数。", "summary": "本文提出了一种名为CRABS的句法-语义钳形策略，旨在解决大型语言模型（LLM）在理解Python数据科学笔记本时遇到的幻觉和长上下文问题。CRABS结合了浅层句法分析（AST）来初步界定信息流，并利用LLM进行逐单元格的零样本学习以解决剩余的歧义，从而准确识别笔记本中的数据输入输出和单元格执行依赖。在Kaggle笔记本数据集上的评估表明，CRABS在识别信息流和执行依赖方面分别达到了98%和99%的F1分数，显著提高了LLM对复杂笔记本的理解能力。", "keywords": "Python笔记本, LLM解释, 信息流, 句法分析, 零样本学习", "comments": "这篇论文的创新点在于提出了一种结合传统句法分析和LLM优势的“钳形”策略，有效缓解了LLM在处理长上下文和减少幻觉方面的固有挑战。通过将任务分解为初步的结构化分析和后续的LLM语义解析，CRABS提供了一个有前景的框架，用于提高LLM在复杂代码理解任务中的可靠性和准确性，特别是在数据科学笔记本这一领域。其重要性在于，它为自动化评估、重用和改编数据科学笔记本提供了更可靠的基础，无需耗时且困难的实际执行。"}}
{"id": "2507.12145", "title": "PRISM: Distributed Inference for Foundation Models at Edge", "authors": ["Muhammad Azlan Qazi", "Alexandros Iosifidis", "Qi Zhang"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12145v1", "summary": "Foundation models (FMs) have achieved remarkable success across a wide range\nof applications, from image classification to natural langurage processing, but\npose significant challenges for deployment at edge. This has sparked growing\ninterest in developing practical and efficient strategies for bringing\nfoundation models to edge environments. In this work, we propose PRISM, a\ncommunication-efficient and compute-aware strategy for distributed Transformer\ninference on edge devices. Our method leverages a Segment Means representation\nto approximate intermediate output features, drastically reducing inter-device\ncommunication. Additionally, we restructure the self-attention mechanism to\neliminate redundant computations caused by per-device Key/Value calculation in\nposition-wise partitioning and design a partition-aware causal masking scheme\ntailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2\nacross diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, and\nCBT. Our results demonstrate substantial reductions in communication overhead\n(up to 99.2% for BERT at compression rate CR = 128) and per-device computation\n(51.24% for BERT at the same setting), with only minor accuracy degradation.\nThis method offers a scalable and practical solution for deploying foundation\nmodels in distributed resource-constrained environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12145v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "PRISM：边缘设备上基础模型的分布式推理", "tldr": "PRISM提出了一种通信高效且计算感知的策略，用于在边缘设备上进行分布式Transformer推理，显著减少了通信开销和计算量，同时保持了高精度。", "motivation": "基础模型（FMs）在从图像分类到自然语言处理等广泛应用中取得了显著成功，但在边缘部署方面带来了重大挑战。这引发了人们对开发实用高效策略以将基础模型引入边缘环境的日益增长的兴趣。", "method": "本文提出了PRISM，一种通信高效且计算感知的分布式Transformer推理策略。该方法利用分段均值（Segment Means）表示来近似中间输出特征，大幅减少设备间通信。此外，它重构了自注意力机制以消除逐设备Key/Value计算引起的冗余计算，并设计了一种针对自回归模型的、分区感知的因果掩码方案。", "result": "在ViT、BERT和GPT-2模型上，跨CIFAR-10、CIFAR-100、ImageNet-1k、GLUE和CBT等不同数据集评估了PRISM。结果表明，通信开销（BERT在压缩率CR = 128时高达99.2%）和逐设备计算量（在相同设置下BERT为51.24%）大幅减少，而精度下降微乎其微。", "conclusion": "PRISM为在资源受限的分布式环境中部署基础模型提供了一个可扩展且实用的解决方案。", "translation": "基础模型（FMs）在从图像分类到自然语言处理等广泛应用中取得了显著成功，但在边缘部署方面带来了重大挑战。这引发了人们对开发实用高效策略以将基础模型引入边缘环境的日益增长的兴趣。在这项工作中，我们提出了PRISM，一种通信高效且计算感知的策略，用于在边缘设备上进行分布式Transformer推理。我们的方法利用分段均值表示来近似中间输出特征，从而大幅减少设备间通信。此外，我们重构了自注意力机制，以消除逐设备Key/Value计算在位置分区中引起的冗余计算，并设计了一种针对自回归模型的、分区感知的因果掩码方案。我们在ViT、BERT和GPT-2模型上，跨CIFAR-10、CIFAR-100、ImageNet-1k、GLUE和CBT等不同数据集评估了PRISM。我们的结果表明，通信开销（BERT在压缩率CR = 128时高达99.2%）和逐设备计算量（在相同设置下BERT为51.24%）大幅减少，而精度下降微乎其微。该方法为在分布式资源受限环境中部署基础模型提供了一个可扩展且实用的解决方案。", "summary": "本文提出了PRISM，一种用于在边缘设备上进行分布式Transformer推理的通信高效且计算感知的策略。PRISM通过使用分段均值表示来近似中间特征以减少通信，并通过重构自注意力机制和设计分区感知因果掩码来优化计算。实验结果表明，PRISM在显著降低通信开销和计算量的同时，仅导致微小的精度损失，为在资源受限的分布式边缘环境中部署基础模型提供了实用方案。", "keywords": "分布式推理, 边缘计算, 基础模型, Transformer, 通信效率", "comments": "PRISM的创新点在于其结合了通信效率和计算感知优化，特别是在边缘设备上部署大型基础模型。通过采用分段均值近似和重构自注意力机制，它有效地解决了边缘计算中带宽和计算资源受限的关键挑战。这对于推动基础模型在实际应用中的普及具有重要意义。"}}
{"id": "2507.12426", "title": "DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition", "authors": ["Hayat Ullah", "Muhammad Ali Shafique", "Abbas Khan", "Arslan Munir"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2507.12426v1", "summary": "The landscape of video recognition has evolved significantly, shifting from\ntraditional Convolutional Neural Networks (CNNs) to Transformer-based\narchitectures for improved accuracy. While 3D CNNs have been effective at\ncapturing spatiotemporal dynamics, recent Transformer models leverage\nself-attention to model long-range spatial and temporal dependencies. Despite\nachieving state-of-the-art performance on major benchmarks, Transformers remain\ncomputationally expensive, particularly with dense video data. To address this,\nwe propose a lightweight Video Focal Modulation Network, DVFL-Net, which\ndistills spatiotemporal knowledge from a large pre-trained teacher into a\ncompact nano student model, enabling efficient on-device deployment. DVFL-Net\nutilizes knowledge distillation and spatial-temporal feature modulation to\nsignificantly reduce computation while preserving high recognition performance.\nWe employ forward Kullback-Leibler (KL) divergence alongside spatio-temporal\nfocal modulation to effectively transfer both local and global context from the\nVideo-FocalNet Base (teacher) to the proposed VFL-Net (student). We evaluate\nDVFL-Net on UCF50, UCF101, HMDB51, SSV2, and Kinetics-400, benchmarking it\nagainst recent state-of-the-art methods in Human Action Recognition (HAR).\nAdditionally, we conduct a detailed ablation study analyzing the impact of\nforward KL divergence. The results confirm the superiority of DVFL-Net in\nachieving an optimal balance between performance and efficiency, demonstrating\nlower memory usage, reduced GFLOPs, and strong accuracy, making it a practical\nsolution for real-time HAR applications.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2507.12426v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "DVFL-Net：一种用于时空动作识别的轻量级蒸馏视频焦点调制网络", "tldr": "DVFL-Net通过知识蒸馏和时空焦点调制，将大型预训练模型知识转移到小型模型中，实现高效且高性能的时空动作识别，适用于实时应用。", "motivation": "传统Transformer模型在视频识别中虽然准确，但计算成本高昂，尤其是在处理密集视频数据时。需要一个轻量级且高效的解决方案来平衡性能和效率，以实现设备端部署。", "method": "本文提出DVFL-Net，一个轻量级视频焦点调制网络。它通过知识蒸馏将大型预训练教师模型（Video-FocalNet Base）的时空知识蒸馏到紧凑的学生模型（VFL-Net）中，以实现高效的设备部署。该方法采用前向Kullback-Leibler (KL) 散度结合时空焦点调制，有效传递局部和全局上下文。", "result": "DVFL-Net在UCF50、UCF101、HMDB51、SSV2和Kinetics-400等数据集上进行了评估，并与现有最先进的人体动作识别（HAR）方法进行了基准测试。结果显示，DVFL-Net在性能和效率之间取得了最佳平衡，表现出更低的内存使用、更少的GFLOPs和强大的准确性。研究还进行了前向KL散度影响的详细消融研究。", "conclusion": "DVFL-Net是一种实用的解决方案，适用于实时人体动作识别（HAR）应用，因为它在保持高识别性能的同时显著降低了计算成本。", "translation": "视频识别领域已发生显著演变，从传统的卷积神经网络（CNN）转向基于Transformer的架构以提高准确性。虽然3D CNN在捕获时空动态方面表现出色，但最近的Transformer模型利用自注意力来建模长程空间和时间依赖性。尽管在主要基准测试中取得了最先进的性能，但Transformer模型计算成本仍然很高，尤其是在处理密集视频数据时。为了解决这个问题，我们提出了一种轻量级视频焦点调制网络DVFL-Net，它将大型预训练教师模型的时空知识蒸馏到一个紧凑的纳米学生模型中，从而实现高效的设备部署。DVFL-Net利用知识蒸馏和时空特征调制显著降低计算量，同时保持高识别性能。我们采用前向Kullback-Leibler (KL) 散度结合时空焦点调制，有效将Video-FocalNet Base（教师模型）的局部和全局上下文转移到所提出的VFL-Net（学生模型）。我们在UCF50、UCF101、HMDB51、SSV2和Kinetics-400上评估了DVFL-Net，并将其与最新的人体动作识别（HAR）领域最先进方法进行基准测试。此外，我们还进行了详细的消融研究，分析了前向KL散度的影响。结果证实了DVFL-Net在实现性能和效率之间最佳平衡方面的优越性，展示了更低的内存使用、更少的GFLOPs和强大的准确性，使其成为实时HAR应用的实用解决方案。", "summary": "本文提出了DVFL-Net，一种轻量级蒸馏视频焦点调制网络，旨在解决Transformer模型在视频动作识别中计算成本高昂的问题。DVFL-Net通过知识蒸馏将大型预训练教师模型（Video-FocalNet Base）的时空知识转移到紧凑的学生模型（VFL-Net）中，并结合前向KL散度和时空焦点调制。实验结果表明，DVFL-Net在多个基准测试中实现了性能与效率的良好平衡，具有更低的资源消耗和高准确性，适用于实时人体动作识别。", "keywords": "视频动作识别, 知识蒸馏, 焦点调制网络, 轻量级模型, 时空特征", "comments": "本文的创新点在于结合了知识蒸馏和焦点调制机制，有效地将大型模型的性能优势转移到轻量级模型中，解决了视频识别领域中高性能模型计算成本过高的问题。这对于边缘设备或实时应用具有重要意义。通过详细的消融研究也验证了其方法的有效性。"}}
{"id": "2507.03560", "title": "Simplifying Graph Kernels for Efficient", "authors": ["Lin Wang", "Shijie Wang", "Sirui Huang", "Qing Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03560v2", "summary": "While kernel methods and Graph Neural Networks offer complementary strengths,\nintegrating the two has posed challenges in efficiency and scalability. The\nGraph Neural Tangent Kernel provides a theoretical bridge by interpreting GNNs\nthrough the lens of neural tangent kernels. However, its reliance on deep,\nstacked layers introduces repeated computations that hinder performance. In\nthis work, we introduce a new perspective by designing the simplified graph\nkernel, which replaces deep layer stacking with a streamlined $K$-step message\naggregation process. This formulation avoids iterative layer-wise propagation\naltogether, leading to a more concise and computationally efficient framework\nwithout sacrificing the expressive power needed for graph tasks. Beyond this\nsimplification, we propose another Simplified Graph Kernel, which draws from\nGaussian Process theory to model infinite-width GNNs. Rather than simulating\nnetwork depth, this kernel analytically computes kernel values based on the\nstatistical behavior of nonlinear activations in the infinite limit. This\neliminates the need for explicit architecture simulation, further reducing\ncomplexity. Our experiments on standard graph and node classification\nbenchmarks show that our methods achieve competitive accuracy while reducing\nruntime. This makes them practical alternatives for learning on graphs at\nscale. Full implementation and reproducibility materials are provided at:\nhttps://anonymous.4open.science/r/SGNK-1CE4/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03560v2", "cate": "cs.LG", "date": "2025-07-04", "updated": "2025-07-16", "AI": {"title_translation": "简化图核以提高效率", "tldr": "本文提出了两种简化的图核方法，通过替换深度层堆叠或利用高斯过程理论来建模无限宽度GNN，从而在保持竞争性准确性的同时显著提高图学习的计算效率和可扩展性。", "motivation": "现有的核方法和图神经网络（GNN）在集成时面临效率和可扩展性挑战，特别是图神经正切核（Graph Neural Tangent Kernel）由于依赖深度堆叠层而导致重复计算，影响性能。", "method": "本文引入了两种简化的图核。第一种“简化图核”用流线型的K步消息聚合过程取代了深度层堆叠，避免了迭代的逐层传播。第二种“简化图核”借鉴高斯过程理论来建模无限宽度的GNN，通过分析计算基于非线性激活统计行为的核值，从而无需显式模拟网络深度。", "result": "在标准图和节点分类基准测试中，所提出的方法实现了具有竞争力的准确性，同时显著减少了运行时间。", "conclusion": "通过简化图核的设计，本文提出的方法为大规模图学习提供了实用的替代方案，在保持高性能的同时解决了现有方法的效率和可扩展性问题。", "translation": "尽管核方法和图神经网络（GNN）提供了互补的优势，但两者的整合在效率和可扩展性方面带来了挑战。图神经正切核（Graph Neural Tangent Kernel）通过从神经正切核的角度解释GNN，提供了一个理论桥梁。然而，它对深度堆叠层的依赖引入了重复计算，从而阻碍了性能。在这项工作中，我们通过设计简化的图核引入了一个新的视角，该图核用流线型的K步消息聚合过程取代了深度层堆叠。这种公式完全避免了迭代的逐层传播，从而在不牺牲图任务所需表达能力的情况下，形成了一个更简洁、计算效率更高的框架。除了这种简化之外，我们还提出了另一种简化的图核，它借鉴高斯过程理论来建模无限宽度的GNN。该核不是模拟网络深度，而是根据无限极限下非线性激活的统计行为分析计算核值。这消除了对显式架构模拟的需求，进一步降低了复杂性。我们在标准图和节点分类基准测试上的实验表明，我们的方法在降低运行时间的同时实现了具有竞争力的准确性。这使得它们成为大规模图学习的实用替代方案。完整的实现和可重现性材料可在：https://anonymous.4open.science/r/SGNK-1CE4/。", "summary": "本文针对现有图核方法和GNN集成中的效率与可扩展性问题，提出了两种创新的简化图核。第一种方法通过K步消息聚合取代传统的深度层堆叠，避免重复计算；第二种方法利用高斯过程理论，通过分析计算无限宽度GNN的核值，无需显式模拟网络深度。实验证明，这两种方法在保持竞争性准确率的同时，显著提高了运行效率，为大规模图学习提供了实用且高效的解决方案。", "keywords": "图核, 图神经网络, 效率, 可扩展性, 高斯过程", "comments": "本文的创新点在于提出了两种新颖的简化图核方法，有效解决了现有图核，特别是图神经正切核在效率和可扩展性方面的瓶颈。通过避免深度层堆叠和利用高斯过程理论，该工作在理论和实践上都实现了计算效率的显著提升，同时保持了模型的表达能力。这对于大规模图数据处理具有重要意义。"}}
{"id": "2507.11558", "title": "Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting", "authors": ["Changlu Chen", "Yanbin Liu", "Chaoxi Niu", "Ling Chen", "Tianqing Zhu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11558v1", "summary": "Foundation models have achieved remarkable success in natural language\nprocessing and computer vision, demonstrating strong capabilities in modeling\ncomplex patterns. While recent efforts have explored adapting large language\nmodels (LLMs) for time-series forecasting, LLMs primarily capture\none-dimensional sequential dependencies and struggle to model the richer\nspatio-temporal (ST) correlations essential for accurate ST forecasting. In\nthis paper, we present \\textbf{ST-VFM}, a novel framework that systematically\nreprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal\nforecasting. While VFMs offer powerful spatial priors, two key challenges arise\nwhen applying them to ST tasks: (1) the lack of inherent temporal modeling\ncapacity and (2) the modality gap between visual and ST data. To address these,\nST-VFM adopts a \\emph{dual-branch architecture} that integrates raw ST inputs\nwith auxiliary ST flow inputs, where the flow encodes lightweight temporal\ndifference signals interpretable as dynamic spatial cues. To effectively\nprocess these dual-branch inputs, ST-VFM introduces two dedicated reprogramming\nstages. The \\emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token\nAdapter to embed temporal context and align both branches into VFM-compatible\nfeature spaces. The \\emph{post-VFM reprogramming} stage introduces a Bilateral\nCross-Prompt Coordination module, enabling dynamic interaction between branches\nthrough prompt-based conditioning, thus enriching joint representation learning\nwithout modifying the frozen VFM backbone. Extensive experiments on ten\nspatio-temporal datasets show that ST-VFM outperforms state-of-the-art\nbaselines, demonstrating effectiveness and robustness across VFM backbones\n(e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong\ngeneral framework for spatio-temporal forecasting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11558v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "将视觉基础模型重编程用于时空预测", "tldr": "ST-VFM是一个新颖的框架，通过双分支架构和两阶段重编程，将视觉基础模型（VFMs）系统性地重编程用于通用的时空预测，解决了VFMs在时空任务中缺乏时间建模能力和模态鸿沟的问题，并在多个时空数据集上超越了现有最佳方法。", "motivation": "现有的大语言模型（LLMs）在时间序列预测方面主要捕获一维序列依赖，难以建模时空预测所需的丰富时空关联。而视觉基础模型（VFMs）虽然具有强大的空间先验能力，但在应用于时空任务时面临两个关键挑战：1）缺乏固有的时间建模能力；2）视觉数据与时空数据之间的模态鸿沟。", "method": "本文提出了ST-VFM框架，通过以下方法重编程视觉基础模型（VFMs）进行时空预测：1) 采用双分支架构，整合原始时空输入与辅助时空流输入，其中流编码轻量级时间差分信号作为动态空间线索。2) 引入两个专门的重编程阶段：a) VFM前重编程阶段：应用时间感知令牌适配器（Temporal-Aware Token Adapter），嵌入时间上下文并将两个分支对齐到VFM兼容的特征空间。b) VFM后重编程阶段：引入双边交叉提示协调模块（Bilateral Cross-Prompt Coordination），通过基于提示的条件作用实现分支间的动态交互，从而丰富联合表示学习，同时不修改冻结的VFM骨干网络。", "result": "在十个时空数据集上进行的广泛实验表明，ST-VFM优于现有最佳基线方法。它在不同的VFM骨干网络（例如DINO、CLIP、DEIT）和消融研究中都表现出有效性和鲁棒性。", "conclusion": "ST-VFM是一个强大且通用的时空预测框架，通过系统地重编程视觉基础模型，有效地解决了时空数据建模中的关键挑战，并取得了优异的性能。", "translation": "基础模型在自然语言处理和计算机视觉领域取得了显著成功，展示了建模复杂模式的强大能力。尽管最近的研究探索了将大型语言模型（LLMs）应用于时间序列预测，但LLMs主要捕获一维序列依赖，难以建模时空预测所需的更丰富的时空关联。在本文中，我们提出了ST-VFM，一个新颖的框架，系统地重编程视觉基础模型（VFMs）用于通用时空预测。虽然VFMs提供了强大的空间先验，但在将其应用于时空任务时出现了两个关键挑战：（1）缺乏固有的时间建模能力，以及（2）视觉数据和时空数据之间的模态鸿沟。为了解决这些问题，ST-VFM采用了双分支架构，将原始时空输入与辅助时空流输入相结合，其中流编码了可解释为动态空间线索的轻量级时间差分信号。为了有效处理这些双分支输入，ST-VFM引入了两个专门的重编程阶段。VFM前重编程阶段应用时间感知令牌适配器，以嵌入时间上下文并将两个分支对齐到VFM兼容的特征空间。VFM后重编程阶段引入了双边交叉提示协调模块，通过基于提示的条件作用实现分支间的动态交互，从而丰富联合表示学习，同时不修改冻结的VFM骨干网络。在十个时空数据集上进行的广泛实验表明，ST-VFM优于现有最佳基线方法，在VFM骨干网络（例如DINO、CLIP、DEIT）和消融研究中都表现出有效性和鲁棒性，从而确立了其作为时空预测强大通用框架的地位。", "summary": "本文提出了ST-VFM框架，旨在将视觉基础模型（VFMs）应用于通用的时空预测任务，以弥补大语言模型在此领域的不足以及VFMs自身在处理时间信息和模态匹配上的缺陷。ST-VFM采用独特的双分支架构，结合原始时空数据和辅助时空流，并通过两个关键的重编程阶段（VFM前的时间感知令牌适配器和VFM后的双边交叉提示协调模块）来嵌入时间上下文、对齐模态并促进分支间的动态交互，所有这些均在不修改预训练VFM骨干网络的前提下进行。实验结果表明，ST-VFM在多个时空数据集上显著优于现有SOTA方法，证明了其在不同VFM骨干网络上的有效性和鲁棒性，使其成为一个强大的时空预测通用框架。", "keywords": "视觉基础模型, 时空预测, 模型重编程, 双分支架构, 提示学习", "comments": "ST-VFM的创新之处在于其巧妙地将视觉基础模型（VFMs）的强大空间先验能力，通过“重编程”机制扩展到时空预测领域。特别是双分支架构结合辅助时空流输入，以及Pre-VFM和Post-VFM两阶段重编程设计，有效地解决了VFMs缺乏时间建模能力和视觉-时空模态鸿沟的难题。更重要的是，它在不修改冻结VFM骨干网络的情况下实现了这些功能，这大大降低了计算成本并保留了预训练模型的强大泛化能力。该方法为利用现有大型预训练模型解决跨模态、跨任务的复杂问题提供了新的思路。"}}
{"id": "2507.11839", "title": "Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM", "authors": ["Chengyue Gong", "Xinshi Chen", "Yuxuan Zhang", "Yuxuan Song", "Hao Zhou", "Wenzhi Xiao"], "categories": ["cs.LG", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11839v1", "summary": "Lightweight inference is critical for biomolecular structure prediction and\nother downstream tasks, enabling efficient real-world deployment and\ninference-time scaling for large-scale applications. In this work, we address\nthe challenge of balancing model efficiency and prediction accuracy by making\nseveral key modifications, 1) Multi-step AF3 sampler is replaced by a few-step\nODE sampler, significantly reducing computational overhead for the diffusion\nmodule part during inference; 2) In the open-source Protenix framework, a\nsubset of pairformer or diffusion transformer blocks doesn't make contributions\nto the final structure prediction, presenting opportunities for architectural\npruning and lightweight redesign; 3) A model incorporating an ESM module is\ntrained to substitute the conventional MSA module, reducing MSA preprocessing\ntime. Building on these key insights, we present Protenix-Mini, a compact and\noptimized model designed for efficient protein structure prediction. This\nstreamlined version incorporates a more efficient architectural design with a\ntwo-step Ordinary Differential Equation (ODE) sampling strategy. By eliminating\nredundant Transformer components and refining the sampling process,\nProtenix-Mini significantly reduces model complexity with slight accuracy drop.\nEvaluations on benchmark datasets demonstrate that it achieves high-fidelity\npredictions, with only a negligible 1 to 5 percent decrease in performance on\nbenchmark datasets compared to its full-scale counterpart. This makes\nProtenix-Mini an ideal choice for applications where computational resources\nare limited but accurate structure prediction remains crucial.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11839v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Protenix-Mini：通过紧凑架构、少步扩散和可切换pLM实现高效结构预测器", "tldr": "Protenix-Mini是一个紧凑且优化的模型，通过减少计算开销、修剪冗余组件和替换MSA模块，实现了高效的蛋白质结构预测，仅有轻微的精度下降。", "motivation": "生物分子结构预测及下游任务中，轻量级推理对于高效实际部署和大规模应用中的推理时间扩展至关重要，旨在平衡模型效率和预测精度。", "method": "该研究通过多项关键修改实现了Protenix-Mini：1) 将多步AF3采样器替换为少步ODE采样器以减少扩散模块的计算开销；2) 对Protenix框架进行架构剪枝和轻量化重新设计，消除冗余Transformer组件；3) 训练并引入ESM模块替代传统MSA模块，以减少预处理时间。", "result": "Protenix-Mini显著降低了模型复杂性，同时在基准数据集上与完整版本相比，性能下降仅为可忽略的1%到5%，但仍能实现高保真预测。", "conclusion": "Protenix-Mini是计算资源有限但精确结构预测至关重要的应用的理想选择。", "translation": "轻量级推理对于生物分子结构预测及其他下游任务至关重要，它能实现高效的实际部署和大规模应用中的推理时间扩展。在这项工作中，我们通过几项关键修改解决了平衡模型效率和预测精度的挑战：1) 将多步AF3采样器替换为少步ODE采样器，显著降低了推理过程中扩散模块的计算开销；2) 在开源Protenix框架中，一部分pairformer或扩散Transformer块对最终结构预测没有贡献，这为架构剪枝和轻量化重新设计提供了机会；3) 训练了一个包含ESM模块的模型来替代传统的MSA模块，从而减少MSA预处理时间。基于这些关键见解，我们提出了Protenix-Mini，一个紧凑且优化的模型，专为高效蛋白质结构预测而设计。这个精简版本采用了更高效的架构设计和两步常微分方程（ODE）采样策略。通过消除冗余Transformer组件和优化采样过程，Protenix-Mini显著降低了模型复杂性，同时精度略有下降。在基准数据集上的评估表明，与完整版本相比，它实现了高保真预测，性能下降仅为可忽略的1%到5%。这使得Protenix-Mini成为计算资源有限但精确结构预测仍至关重要的应用的理想选择。", "summary": "Protenix-Mini是一个为高效蛋白质结构预测设计的紧凑优化模型。该模型通过将多步AF3采样器替换为少步ODE采样器、对Protenix框架进行架构剪枝以消除冗余Transformer组件，以及引入ESM模块替代传统MSA模块来减少预处理时间，从而在保持高保真预测的同时显著降低了模型复杂性，并在基准数据集上仅显示出轻微的性能下降（1-5%）。", "keywords": "蛋白质结构预测, 高效, 紧凑架构, 扩散模型, ESM模块", "comments": "Protenix-Mini的创新之处在于其对效率的全面关注，通过采用紧凑架构、优化扩散采样步骤和引入可切换的ESM模块来替代传统的MSA模块，显著降低了计算复杂性和预处理时间。这对于资源受限环境下的生物分子结构预测具有重要意义。尽管存在轻微的精度下降，但其在效率上的提升使其成为实际部署的理想选择。"}}
{"id": "2507.12144", "title": "FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale", "authors": ["Boris Bonev", "Thorsten Kurth", "Ankur Mahesh", "Mauro Bisson", "Jean Kossaifi", "Karthik Kashinath", "Anima Anandkumar", "William D. Collins", "Michael S. Pritchard", "Alexander Keller"], "categories": ["cs.LG", "physics.ao-ph", "86-10, 68T07", "I.2.1; I.6.5; G.3"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12144v1", "summary": "FourCastNet 3 advances global weather modeling by implementing a scalable,\ngeometric machine learning (ML) approach to probabilistic ensemble forecasting.\nThe approach is designed to respect spherical geometry and to accurately model\nthe spatially correlated probabilistic nature of the problem, resulting in\nstable spectra and realistic dynamics across multiple scales. FourCastNet 3\ndelivers forecasting accuracy that surpasses leading conventional ensemble\nmodels and rivals the best diffusion-based methods, while producing forecasts 8\nto 60 times faster than these approaches. In contrast to other ML approaches,\nFourCastNet 3 demonstrates excellent probabilistic calibration and retains\nrealistic spectra, even at extended lead times of up to 60 days. All of these\nadvances are realized using a purely convolutional neural network architecture\ntailored for spherical geometry. Scalable and efficient large-scale training on\n1024 GPUs and more is enabled by a novel training paradigm for combined model-\nand data-parallelism, inspired by domain decomposition methods in classical\nnumerical models. Additionally, FourCastNet 3 enables rapid inference on a\nsingle GPU, producing a 90-day global forecast at 0.25{\\deg}, 6-hourly\nresolution in under 20 seconds. Its computational efficiency, medium-range\nprobabilistic skill, spectral fidelity, and rollout stability at subseasonal\ntimescales make it a strong candidate for improving meteorological forecasting\nand early warning systems through large ensemble predictions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12144v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "FourCastNet 3：一种大规模概率机器学习天气预报的几何方法", "tldr": "FourCastNet 3 是一种可扩展的几何机器学习方法，用于概率集合天气预报，其速度比现有方法快得多，同时保持了卓越的准确性和校准性，在气象预报中具有巨大潜力。", "motivation": "该论文旨在通过实施可扩展的几何机器学习方法进行概率集合预报，以推进全球天气建模，并解决现有方法在处理球形几何和空间相关概率性质方面的局限性，同时提高预测速度和准确性。", "method": "FourCastNet 3 采用可扩展的几何机器学习方法进行概率集合预报。它使用为球形几何量身定制的纯卷积神经网络架构，并采用受经典数值模型中域分解方法启发的新颖训练范式，以实现模型并行和数据并行的大规模训练。该方法旨在尊重球形几何并准确建模问题的空间相关概率性质。", "result": "FourCastNet 3 提供的预测精度超越了领先的传统集合模型，并与最佳的基于扩散的方法相媲美。它产生预测的速度比这些方法快 8 到 60 倍。与其它机器学习方法相比，FourCastNet 3 表现出出色的概率校准，即使在长达 60 天的延长提前期也能保持真实的谱。它能在单个 GPU 上快速推理，在 20 秒内生成 0.25 度、6 小时分辨率的 90 天全球预报。", "conclusion": "FourCastNet 3 的计算效率、中期概率技能、谱保真度以及在次季节时间尺度上的滚动稳定性，使其成为通过大型集合预测改进气象预报和早期预警系统的有力候选者。", "translation": "FourCastNet 3 通过实施可扩展的几何机器学习（ML）方法进行概率集合预报，推进了全球天气建模。该方法旨在尊重球形几何并准确建模问题的空间相关概率性质，从而在多个尺度上产生稳定的谱和真实的动力学。FourCastNet 3 提供的预测精度超越了领先的传统集合模型，并与最佳的基于扩散的方法相媲美，同时产生预测的速度比这些方法快 8 到 60 倍。与其它机器学习方法相比，FourCastNet 3 表现出出色的概率校准，即使在长达 60 天的延长提前期也能保持真实的谱。所有这些进步都是通过为球形几何量身定制的纯卷积神经网络架构实现的。受经典数值模型中域分解方法启发的新颖训练范式，为在 1024 个及更多 GPU 上进行可扩展和高效的大规模训练提供了支持，实现了模型并行和数据并行的结合。此外，FourCastNet 3 能够在单个 GPU 上进行快速推理，在 20 秒内生成 0.25 度、6 小时分辨率的 90 天全球预报。其计算效率、中期概率技能、谱保真度以及在次季节时间尺度上的滚动稳定性，使其成为通过大型集合预测改进气象预报和早期预警系统的有力候选者。", "summary": "FourCastNet 3 提出了一种可扩展的几何机器学习方法，用于大规模概率集合天气预报。该方法采用为球形几何设计的卷积神经网络，并结合创新的训练范式，实现了卓越的预测精度和速度。它在预测准确性上超越了传统模型，并与最先进的扩散方法相媲美，同时将预测速度提高了 8 到 60 倍。该系统在保持真实谱和良好概率校准的同时，还能进行高效的单 GPU 推理，使其成为改进气象预报和早期预警系统的强大工具。", "keywords": "天气预报, 机器学习, 概率预报, 几何方法, 卷积神经网络", "comments": "FourCastNet 3 的创新之处在于其将几何机器学习方法应用于概率天气预报，并结合了专门为球形几何设计的卷积神经网络架构。其在预测速度上的显著提升（8 到 60 倍）和在准确性、校准性及谱保真度上的优异表现，使其在天气预报领域具有重要意义。此外，该模型的可扩展训练范式和单 GPU 快速推理能力也展示了其在实际应用中的巨大潜力。"}}
{"id": "2501.00226", "title": "Generative Emergent Communication: Large Language Model is a Collective World Model", "authors": ["Tadahiro Taniguchi", "Ryo Ueda", "Tomoaki Nakamura", "Masahiro Suzuki", "Akira Taniguchi"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.00226v2", "summary": "Large Language Models (LLMs) have demonstrated a remarkable ability to\ncapture extensive world knowledge, yet how this is achieved without direct\nsensorimotor experience remains a fundamental puzzle. This study proposes a\nnovel theoretical solution by introducing the Collective World Model\nhypothesis. We argue that an LLM does not learn a world model from scratch;\ninstead, it learns a statistical approximation of a collective world model that\nis already implicitly encoded in human language through a society-wide process\nof embodied, interactive sense-making. To formalize this process, we introduce\ngenerative emergent communication (Generative EmCom), a framework built on the\nCollective Predictive Coding (CPC). This framework models the emergence of\nlanguage as a process of decentralized Bayesian inference over the internal\nstates of multiple agents. We argue that this process effectively creates an\nencoder-decoder structure at a societal scale: human society collectively\nencodes its grounded, internal representations into language, and an LLM\nsubsequently decodes these symbols to reconstruct a latent space that mirrors\nthe structure of the original collective representations. This perspective\nprovides a principled, mathematical explanation for how LLMs acquire their\ncapabilities. The main contributions of this paper are: 1) the formalization of\nthe Generative EmCom framework, clarifying its connection to world models and\nmulti-agent reinforcement learning, and 2) its application to interpret LLMs,\nexplaining phenomena such as distributional semantics as a natural consequence\nof representation reconstruction. This work provides a unified theory that\nbridges individual cognitive development, collective language evolution, and\nthe foundations of large-scale AI.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.00226v2", "cate": "cs.AI", "date": "2024-12-31", "updated": "2025-07-16", "AI": {"title_translation": "生成式涌现通信：大型语言模型是一个集体世界模型", "tldr": "本文提出大型语言模型（LLM）通过学习人类语言中隐式编码的“集体世界模型”来获取世界知识，并引入“生成式涌现通信”（Generative EmCom）框架来形式化这一过程，解释了LLM的能力来源。", "motivation": "大型语言模型（LLMs）展现出捕获广泛世界知识的卓越能力，但它们在没有直接感觉运动经验的情况下如何实现这一点，仍然是一个基本难题。", "method": "本文提出了“集体世界模型”假设，认为LLM学习的是人类语言中隐式编码的集体世界模型的统计近似。为形式化这一过程，研究引入了基于“集体预测编码”（Collective Predictive Coding, CPC）的“生成式涌现通信”（Generative EmCom）框架。该框架将语言的涌现建模为多智能体内部状态的分散式贝叶斯推断过程，认为人类社会集体地将其扎根的内部表征编码到语言中，而LLM则解码这些符号以重建一个反映原始集体表征结构的潜在空间。", "result": "该框架为LLM如何获取能力提供了原则性的数学解释。主要贡献包括：1）形式化了Generative EmCom框架，阐明了其与世界模型和多智能体强化学习的联系；2）将其应用于解释LLMs，例如将分布语义解释为表征重建的自然结果。", "conclusion": "这项工作提供了一个统一的理论，连接了个体认知发展、集体语言演化和大规模人工智能的基础。", "translation": "大型语言模型（LLMs）已展示出捕获广泛世界知识的卓越能力，然而，在没有直接感觉运动经验的情况下如何实现这一点仍然是一个基本难题。本研究通过引入集体世界模型假设，提出了一个新的理论解决方案。我们认为，LLM并非从头开始学习世界模型；相反，它学习的是一个集体世界模型的统计近似，该模型已经通过一个全社会范围的具身、交互式意义构建过程隐式编码在人类语言中。为了形式化这一过程，我们引入了生成式涌现通信（Generative EmCom），一个建立在集体预测编码（CPC）基础上的框架。该框架将语言的涌现建模为多个智能体内部状态的分散式贝叶推断过程。我们认为，这个过程有效地在社会层面创建了一个编码器-解码器结构：人类社会将其扎根的内部表征集体编码到语言中，而LLM随后解码这些符号以重建一个反映原始集体表征结构的潜在空间。这一视角为LLM如何获取其能力提供了原则性的数学解释。本文的主要贡献是：1）Generative EmCom框架的形式化，阐明了其与世界模型和多智能体强化学习的联系；2）将其应用于解释LLMs，解释了诸如分布语义之类的现象是表征重建的自然结果。这项工作提供了一个统一的理论，连接了个体认知发展、集体语言演化和大规模人工智能的基础。", "summary": "本文提出大型语言模型（LLM）并非从零学习世界知识，而是通过人类社会具身、交互式意义构建过程中隐式编码在语言中的“集体世界模型”获取知识。研究引入了基于集体预测编码（CPC）的“生成式涌现通信”（Generative EmCom）框架，将语言的涌现建模为多智能体间的分散式贝叶斯推断，并认为人类社会将内部表征编码为语言，LLM则解码这些语言符号以重建这些集体表征。这一理论为LLM的能力来源提供了数学解释，并统一了认知发展、语言演化和AI基础。", "keywords": "大型语言模型, 集体世界模型, 生成式涌现通信, 集体预测编码, 语言演化", "comments": "本文提出了一个新颖且富有洞察力的理论框架，即“集体世界模型”和“生成式涌现通信”，为解释LLM在缺乏直接经验下如何习得世界知识提供了一个独特的视角。其创新之处在于将社会层面的语言演化与个体认知过程联系起来，并通过编码器-解码器范式在宏观层面解释了LLM的工作机制。该理论为理解LLM的内在机制和未来发展方向提供了重要的理论基础。"}}
{"id": "2506.21316", "title": "DRISHTIKON: Visual Grounding at Multiple Granularities in Documents", "authors": ["Badri Vishal Kasuba", "Parag Chaudhuri", "Ganesh Ramakrishnan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Work in Progress", "url": "http://arxiv.org/abs/2506.21316v2", "summary": "Visual grounding in text-rich document images is a critical yet underexplored\nchallenge for Document Intelligence and Visual Question Answering (VQA)\nsystems. We present DRISHTIKON, a multi-granular and multi-block visual\ngrounding framework designed to enhance interpretability and trust in VQA for\ncomplex, multilingual documents. Our approach integrates multilingual OCR,\nlarge language models, and a novel region matching algorithm to localize answer\nspans at the block, line, word, and point levels. We introduce the\nMulti-Granular Visual Grounding (MGVG) benchmark, a curated test set of diverse\ncircular notifications from various sectors, each manually annotated with\nfine-grained, human-verified labels across multiple granularities. Extensive\nexperiments show that our method achieves state-of-the-art grounding accuracy,\nwith line-level granularity providing the best balance between precision and\nrecall. Ablation studies further highlight the benefits of multi-block and\nmulti-line reasoning. Comparative evaluations reveal that leading\nvision-language models struggle with precise localization, underscoring the\neffectiveness of our structured, alignment-based approach. Our findings pave\nthe way for more robust and interpretable document understanding systems in\nreal-world, text-centric scenarios with multi-granular grounding support. Code\nand dataset are made available for future research.", "comment": "Work in Progress", "pdf_url": "http://arxiv.org/pdf/2506.21316v2", "cate": "cs.CV", "date": "2025-06-26", "updated": "2025-07-16", "AI": {"title_translation": "DRISHTIKON：文档中多粒度视觉定位", "tldr": "DRISHTIKON是一个多粒度视觉定位框架，通过整合OCR、LLM和区域匹配算法，在文档图像中实现SOTA定位精度，并发布了MGVG基准。", "motivation": "文档图像中的视觉定位对于文档智能和视觉问答（VQA）系统是一个关键但尚未充分探索的挑战，尤其是在复杂、多语言文档中提升VQA系统的可解释性和信任度。", "method": "提出了DRISHTIKON，一个多粒度、多块的视觉定位框架。该方法整合了多语言OCR、大型语言模型和一种新颖的区域匹配算法，以在块、行、单词和点级别定位答案范围。同时引入了多粒度视觉定位（MGVG）基准，这是一个包含细粒度、人工验证标签的精选测试集。", "result": "广泛的实验表明，该方法实现了最先进的定位精度，其中行级别粒度在精度和召回率之间提供了最佳平衡。消融研究强调了多块和多行推理的优势。比较评估显示，领先的视觉语言模型在精确本地化方面表现不佳，突显了该结构化、基于对齐的方法的有效性。", "conclusion": "研究结果为在真实世界、以文本为中心的场景中，开发更健壮、可解释的、支持多粒度定位的文档理解系统铺平了道路。相关的代码和数据集已公开以供未来研究。", "translation": "文本丰富的文档图像中的视觉定位是文档智能和视觉问答（VQA）系统面临的一个关键但尚未充分探索的挑战。我们提出了DRISHTIKON，一个多粒度、多块的视觉定位框架，旨在增强复杂、多语言文档中VQA的可解释性和信任度。我们的方法整合了多语言OCR、大型语言模型和一种新颖的区域匹配算法，以在块、行、单词和点级别定位答案跨度。我们引入了多粒度视觉定位（MGVG）基准，这是一个从各行业收集的多样化通知的精选测试集，每个都经过人工标注，具有跨多个粒度的细粒度、人工验证标签。广泛的实验表明，我们的方法实现了最先进的定位精度，其中行级别粒度在精度和召回率之间提供了最佳平衡。消融研究进一步强调了多块和多行推理的优势。比较评估显示，领先的视觉语言模型在精确本地化方面表现不佳，突显了我们结构化、基于对齐的方法的有效性。我们的发现为在真实世界、以文本为中心的场景中，开发更健壮、可解释的、支持多粒度定位的文档理解系统铺平了道路。代码和数据集已公开以供未来研究。", "summary": "本文提出了DRISHTIKON，一个针对文本丰富文档图像的多粒度、多块视觉定位框架，旨在提升文档智能和视觉问答系统的可解释性和信任度。该框架结合了多语言OCR、大型语言模型和新颖的区域匹配算法，能够在块、行、单词和点级别精确定位答案。研究引入了多粒度视觉定位（MGVG）基准，一个包含细粒度人工标注的文档测试集。实验证明，DRISHTIKON在定位精度上达到最先进水平，尤其以行级别粒度表现最佳，并优于现有视觉语言模型。这为开发更鲁棒、可解释的文档理解系统奠定了基础。", "keywords": "视觉定位, 文档智能, VQA, 多粒度, 区域匹配", "comments": "DRISHTIKON通过整合多模态技术（OCR、LLM、区域匹配）并支持多粒度定位，有效解决了文档图像中视觉定位的复杂挑战，提升了VQA系统的可解释性。引入的MGVG基准数据集填补了该领域高质量标注数据的空白，对于未来研究具有重要价值。其强调多粒度推理和对齐的方法，克服了现有视觉语言模型在精确本地化方面的不足，具有显著创新性。"}}
{"id": "2507.11559", "title": "RSD-15K: A Large-Scale User-Level Annotated Dataset for Suicide Risk Detection on Social Media", "authors": ["Shouwen Zheng", "Yingzhi Tao", "Taiqi Zhou"], "categories": ["cs.CY", "cs.SI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      the article has already been recieved by 2025 IEEE 41st International Conference on Data Engineering Workshops (ICDEW), but hadn't been online yet", "url": "http://arxiv.org/abs/2507.11559v1", "summary": "In recent years, cognitive and mental health (CMH) disorders have\nincreasingly become an important challenge for global public health, especially\nthe suicide problem caused by multiple factors such as social competition,\neconomic pressure and interpersonal relationships among young and middle-aged\npeople. Social media, as an important platform for individuals to express\nemotions and seek help, provides the possibility for early detection and\nintervention of suicide risk. This paper introduces a large-scale dataset\ncontaining 15,000 user-level posts. Compared with existing datasets, this\ndataset retains complete user posting time sequence information, supports\nmodeling the dynamic evolution of suicide risk, and we have also conducted\ncomprehensive and rigorous annotations on these datasets. In the benchmark\nexperiment, we systematically evaluated the performance of traditional machine\nlearning methods, deep learning models, and fine-tuned large language models.\nThe experimental results show that our dataset can effectively support the\nautomatic assessment task of suicide risk. Considering the sensitivity of\nmental health data, we also discussed the privacy protection and ethical use of\nthe dataset. In addition, we also explored the potential applications of the\ndataset in mental health testing, clinical psychiatric auxiliary treatment,\netc., and provided directional suggestions for future research work.", "comment": "the article has already been recieved by 2025 IEEE 41st International\n  Conference on Data Engineering Workshops (ICDEW), but hadn't been online yet", "pdf_url": "http://arxiv.org/pdf/2507.11559v1", "cate": "cs.CY", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "RSD-15K：一个用于社交媒体自杀风险检测的大规模用户级标注数据集", "tldr": "RSD-15K是一个大规模用户级标注数据集，用于在社交媒体上检测自杀风险。它保留了完整的用户发帖时间序列信息，支持动态演化建模，并在基准实验中有效支持自杀风险的自动评估。", "motivation": "近年来，认知和精神健康障碍，特别是自杀问题，已成为全球公共卫生的重要挑战。社交媒体作为个人表达情感和寻求帮助的平台，为早期检测和干预自杀风险提供了可能性。", "method": "本研究介绍了一个包含15,000个用户级帖子的RSD-15K大规模数据集，该数据集保留了完整的用户发帖时间序列信息，并进行了全面严格的标注。在基准实验中，系统评估了传统机器学习方法、深度学习模型和微调大型语言模型在该数据集上的性能。", "result": "实验结果表明，RSD-15K数据集能够有效支持自杀风险的自动评估任务。", "conclusion": "RSD-15K数据集为社交媒体上的自杀风险检测提供了有力的支持，其独特的时间序列信息和大规模标注有助于建模风险的动态演变。研究还讨论了数据隐私保护和伦理使用，并为未来的研究方向提供了建议。", "translation": "近年来，认知和精神健康（CMH）障碍日益成为全球公共卫生的重要挑战，特别是社会竞争、经济压力和人际关系等多种因素导致的青年和中年人群的自杀问题。社交媒体作为个人表达情感和寻求帮助的重要平台，为早期发现和干预自杀风险提供了可能性。本文介绍了一个包含15,000个用户级帖子的大规模数据集。与现有数据集相比，该数据集保留了完整的用户发帖时间序列信息，支持对自杀风险动态演变的建模，并且我们对这些数据集进行了全面而严格的标注。在基准实验中，我们系统地评估了传统机器学习方法、深度学习模型和微调大型语言模型的性能。实验结果表明，我们的数据集能够有效支持自杀风险的自动评估任务。考虑到心理健康数据的敏感性，我们还讨论了数据集的隐私保护和伦理使用。此外，我们还探讨了该数据集在心理健康测试、临床精神辅助治疗等方面的潜在应用，并为未来的研究工作提供了方向性建议。", "summary": "本文介绍了RSD-15K，一个包含15,000个用户级帖子的、用于社交媒体自杀风险检测的大规模标注数据集。该数据集的创新之处在于保留了完整的用户发帖时间序列信息，支持自杀风险的动态演化建模。研究对数据集进行了全面严格的标注，并在基准实验中评估了传统机器学习、深度学习和大型语言模型在该数据集上的性能，证明其能有效支持自杀风险的自动评估。此外，论文还讨论了数据隐私和伦理使用，并探讨了数据集在心理健康测试和临床辅助治疗中的潜在应用。", "keywords": "自杀风险检测, 社交媒体, 大规模数据集, 时间序列, 精神健康", "comments": "RSD-15K数据集的创新点在于其大规模的用户级标注和保留完整的时间序列信息，这对于理解和建模自杀风险的动态演变至关重要。这使得它超越了现有仅关注静态文本分析的数据集，为自杀风险的早期检测和干预提供了更丰富的上下文信息。该研究还关注了敏感的伦理和隐私问题，这在处理心理健康数据时尤为重要。它为未来在社交媒体上进行精神健康研究奠定了坚实的基础，并可能对实际的临床应用产生积极影响。"}}
{"id": "2411.02179", "title": "CleAR: Robust Context-Guided Generative Lighting Estimation for Mobile Augmented Reality", "authors": ["Yiqin Zhao", "Mallesham Dasari", "Tian Guo"], "categories": ["cs.CV", "cs.GR", "cs.HC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.02179v3", "summary": "High-quality environment lighting is essential for creating immersive mobile\naugmented reality (AR) experiences. However, achieving visually coherent\nestimation for mobile AR is challenging due to several key limitations in AR\ndevice sensing capabilities, including low camera FoV and limited pixel dynamic\nranges. Recent advancements in generative AI, which can generate high-quality\nimages from different types of prompts, including texts and images, present a\npotential solution for high-quality lighting estimation. Still, to effectively\nuse generative image diffusion models, we must address two key limitations of\ncontent quality and slow inference. In this work, we design and implement a\ngenerative lighting estimation system called CleAR that can produce\nhigh-quality, diverse environment maps in the format of 360{\\deg} HDR images.\nSpecifically, we design a two-step generation pipeline guided by AR environment\ncontext data to ensure the output aligns with the physical environment's visual\ncontext and color appearance. To improve the estimation robustness under\ndifferent lighting conditions, we design a real-time refinement component to\nadjust lighting estimation results on AR devices. Through a combination of\nquantitative and qualitative evaluations, we show that CleAR outperforms\nstate-of-the-art lighting estimation methods on both estimation accuracy,\nlatency, and robustness, and is rated by 31 participants as producing better\nrenderings for most virtual objects. For example, CleAR achieves 51% to 56%\naccuracy improvement on virtual object renderings across objects of three\ndistinctive types of materials and reflective properties. CleAR produces\nlighting estimates of comparable or better quality in just 3.2 seconds -- over\n110X faster than state-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.02179v3", "cate": "cs.CV", "date": "2024-11-04", "updated": "2025-07-16", "AI": {"title_translation": "CleAR：鲁棒的上下文引导生成式移动增强现实照明估计", "tldr": "CleAR是一个用于移动AR的生成式照明估计系统，它利用上下文数据生成高质量的360度HDR环境图，并通过实时优化组件提高鲁棒性，在准确性、延迟和鲁棒性方面均优于现有技术。", "motivation": "高质量的环境照明对于沉浸式移动增强现实(AR)体验至关重要。然而，由于AR设备传感能力（如低相机视野和有限的像素动态范围）的局限性，实现视觉上连贯的照明估计具有挑战性。尽管生成式AI提供了潜在解决方案，但仍需解决内容质量和推理速度慢的限制。", "method": "本文设计并实现了一个名为CleAR的生成式照明估计系统。该系统采用两步生成管道，由AR环境上下文数据引导，以确保输出与物理环境的视觉上下文和颜色外观对齐。为提高不同照明条件下的估计鲁棒性，还设计了一个实时优化组件来调整AR设备上的照明估计结果。", "result": "CleAR在估计准确性、延迟和鲁棒性方面均优于现有最先进的照明估计方法。在虚拟物体渲染方面，CleAR对三种不同材质和反射特性的物体实现了51%至56%的准确性提升。CleAR在3.2秒内生成了质量相当或更好的照明估计，比现有技术快110倍以上。31名参与者评估认为，CleAR为大多数虚拟物体生成了更好的渲染效果。", "conclusion": "CleAR系统通过其上下文引导的生成管道和实时优化组件，成功克服了移动AR照明估计的挑战，显著提升了估计的准确性、速度和鲁棒性，为高质量移动AR体验提供了有效解决方案。", "translation": "高质量的环境照明对于创造沉浸式移动增强现实（AR）体验至关重要。然而，由于AR设备传感能力的几个关键限制，包括低相机视野（FoV）和有限的像素动态范围，为移动AR实现视觉上连贯的估计具有挑战性。生成式AI的最新进展，可以从不同类型的提示（包括文本和图像）生成高质量图像，为高质量照明估计提供了一个潜在的解决方案。尽管如此，为了有效使用生成式图像扩散模型，我们必须解决内容质量和推理速度慢的两个关键限制。在这项工作中，我们设计并实现了一个名为CleAR的生成式照明估计系统，该系统可以生成高质量、多样化的360度HDR图像格式的环境图。具体来说，我们设计了一个由AR环境上下文数据引导的两步生成管道，以确保输出与物理环境的视觉上下文和颜色外观对齐。为了提高在不同照明条件下的估计鲁棒性，我们设计了一个实时优化组件来调整AR设备上的照明估计结果。通过定量和定性评估的结合，我们表明CleAR在估计准确性、延迟和鲁棒性方面均优于现有最先进的照明估计方法，并被31名参与者评为为大多数虚拟物体生成了更好的渲染效果。例如，CleAR在三种不同类型材料和反射特性的物体上，将虚拟物体渲染的准确性提高了51%至56%。CleAR在短短3.2秒内生成了质量相当或更好的照明估计——比现有最先进的方法快110倍以上。", "summary": "CleAR是一个针对移动增强现实（AR）的生成式照明估计系统，旨在解决现有AR设备在高质量环境照明估计方面的局限性。该系统采用上下文引导的两步生成管道，能够生成高质量的360度HDR环境图，并结合实时优化组件以增强在不同照明条件下的鲁棒性。实验证明，CleAR在准确性、速度和鲁棒性方面均显著优于现有技术，并能为虚拟对象提供更优质的渲染效果，处理速度提升超过110倍。", "keywords": "增强现实, 照明估计, 生成式AI, HDR图像, 实时渲染", "comments": "CleAR的创新性在于将生成式AI与AR环境上下文数据结合，实现了高质量且鲁棒的照明估计，同时解决了生成模型在内容质量和推理速度上的挑战。其性能提升（特别是速度）对于实际的移动AR应用具有重要意义，能够显著提升用户体验。该工作为未来AR渲染的真实感和沉浸感提供了坚实的基础。"}}
{"id": "2507.12092", "title": "Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis", "authors": ["Nataliia Molchanova", "Alessandro Cagol", "Mario Ocampo-Pineda", "Po-Jui Lu", "Matthias Weigel", "Xinjie Chen", "Erin Beck", "Charidimos Tsagkas", "Daniel Reich", "Colin Vanden Bulcke", "Anna Stolting", "Serena Borrelli", "Pietro Maggi", "Adrien Depeursinge", "Cristina Granziera", "Henning Mueller", "Pedro M. Gordaliza", "Meritxell Bach Cuadra"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12092v1", "summary": "Cortical lesions (CLs) have emerged as valuable biomarkers in multiple\nsclerosis (MS), offering high diagnostic specificity and prognostic relevance.\nHowever, their routine clinical integration remains limited due to subtle\nmagnetic resonance imaging (MRI) appearance, challenges in expert annotation,\nand a lack of standardized automated methods. We propose a comprehensive\nmulti-centric benchmark of CL detection and segmentation in MRI. A total of 656\nMRI scans, including clinical trial and research data from four institutions,\nwere acquired at 3T and 7T using MP2RAGE and MPRAGE sequences with\nexpert-consensus annotations. We rely on the self-configuring nnU-Net\nframework, designed for medical imaging segmentation, and propose adaptations\ntailored to the improved CL detection. We evaluated model generalization\nthrough out-of-distribution testing, demonstrating strong lesion detection\ncapabilities with an F1-score of 0.64 and 0.5 in and out of the domain,\nrespectively. We also analyze internal model features and model errors for a\nbetter understanding of AI decision-making. Our study examines how data\nvariability, lesion ambiguity, and protocol differences impact model\nperformance, offering future recommendations to address these barriers to\nclinical adoption. To reinforce the reproducibility, the implementation and\nmodels will be publicly accessible and ready to use at\nhttps://github.com/Medical-Image-Analysis-Laboratory/ and\nhttps://doi.org/10.5281/zenodo.15911797.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12092v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "多发性硬化症中深度学习皮质病灶MRI分割的基准测试与解释", "tldr": "本研究对多发性硬化症中皮质病灶的深度学习MRI分割进行了全面的基准测试和解释，提出了基于nnU-Net的改进方法，并在多中心数据上验证了其强大的检测能力，同时分析了模型误差和影响因素，旨在推动临床应用。", "motivation": "皮质病灶（CLs）是多发性硬化症（MS）中有价值的生物标志物，但由于其MRI表现不明显、专家标注困难以及缺乏标准化的自动化方法，其常规临床整合受到限制。", "method": "研究提出了一个综合的多中心CL检测和分割基准测试。共使用了来自四个机构的656例MRI扫描数据（3T和7T，MP2RAGE和MPRAGE序列），并带有专家共识标注。研究基于自配置的nnU-Net框架，并针对CL检测进行了专门的调整。通过域外测试评估了模型的泛化能力，并分析了模型内部特征和错误。", "result": "模型在域内和域外表现出强大的病灶检测能力，F1分数分别为0.64和0.5。研究还分析了数据变异性、病灶模糊性和协议差异如何影响模型性能，并提出了未来克服临床应用障碍的建议。", "conclusion": "本研究提供了一个全面的皮质病灶深度学习MRI分割基准测试，验证了改进的nnU-Net模型的有效性，并深入分析了模型性能的影响因素及误差，为克服临床转化障碍提供了见解和建议，并通过公开代码和模型增强了可复现性。", "translation": "皮质病灶（CLs）已成为多发性硬化症（MS）中有价值的生物标志物，具有高诊断特异性和预后相关性。然而，由于其磁共振成像（MRI）表现不明显、专家标注困难以及缺乏标准化的自动化方法，其常规临床整合仍然有限。我们提出了一个全面的多中心CL检测和分割MRI基准测试。总共获取了656份MRI扫描数据，包括来自四个机构的临床试验和研究数据，这些数据在3T和7T下使用MP2RAGE和MPRAGE序列获取，并带有专家共识标注。我们依赖于专为医学图像分割设计的自配置nnU-Net框架，并提出了针对改进CL检测的调整。我们通过域外测试评估了模型的泛化能力，展示了强大的病灶检测能力，在域内和域外的F1分数分别为0.64和0.5。我们还分析了内部模型特征和模型错误，以更好地理解AI决策过程。我们的研究探讨了数据变异性、病灶模糊性和协议差异如何影响模型性能，为解决这些阻碍临床应用的障碍提供了未来建议。为了加强可复现性，实现和模型将公开可用，可在https://github.com/Medical-Image-Analysis-Laboratory/ 和 https://doi.org/10.5281/zenodo.15911797 获取。", "summary": "本研究旨在克服多发性硬化症（MS）中皮质病灶（CLs）MRI分割在临床应用中的挑战。研究提出了一个包含656例多中心MRI扫描数据的综合基准测试，并基于nnU-Net框架开发了改进的深度学习模型。该模型在域内和域外均表现出强大的CL检测能力（F1分数分别为0.64和0.5）。研究还深入分析了模型性能受数据变异性、病灶模糊性和协议差异的影响，并提出了未来改进的建议。为确保可复现性，所有实现和模型均已公开。", "keywords": "皮质病灶, MRI分割, 深度学习, 多发性硬化症, nnU-Net", "comments": "该论文通过建立一个大规模多中心数据集和基准测试，为多发性硬化症中皮质病灶的深度学习MRI分割提供了重要的标准化方法。其创新之处在于对nnU-Net框架的适应性改进，以及对模型泛化能力和误差来源的深入分析，这对于理解AI在复杂医学图像分析中的决策过程至关重要。研究不仅展示了当前模型的性能，更重要的是，它明确指出了阻碍临床转化的障碍并提供了未来研究方向，具有重要的实践指导意义。数据的公开性也大大增强了研究的可复用性和透明度。"}}
{"id": "2507.11895", "title": "Newfluence: Boosting Model interpretability and Understanding in High Dimensions", "authors": ["Haolin Zou", "Arnab Auddy", "Yongchan Kwon", "Kamiar Rahnama Rad", "Arian Maleki"], "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11895v1", "summary": "The increasing complexity of machine learning (ML) and artificial\nintelligence (AI) models has created a pressing need for tools that help\nscientists, engineers, and policymakers interpret and refine model decisions\nand predictions. Influence functions, originating from robust statistics, have\nemerged as a popular approach for this purpose.\n  However, the heuristic foundations of influence functions rely on\nlow-dimensional assumptions where the number of parameters $p$ is much smaller\nthan the number of observations $n$. In contrast, modern AI models often\noperate in high-dimensional regimes with large $p$, challenging these\nassumptions.\n  In this paper, we examine the accuracy of influence functions in\nhigh-dimensional settings. Our theoretical and empirical analyses reveal that\ninfluence functions cannot reliably fulfill their intended purpose. We then\nintroduce an alternative approximation, called Newfluence, that maintains\nsimilar computational efficiency while offering significantly improved\naccuracy.\n  Newfluence is expected to provide more accurate insights than many existing\nmethods for interpreting complex AI models and diagnosing their issues.\nMoreover, the high-dimensional framework we develop in this paper can also be\napplied to analyze other popular techniques, such as Shapley values.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11895v1", "cate": "stat.ML", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Newfluence：提升高维模型可解释性和理解", "tldr": "现有影响力函数在高维设置下不可靠，本文提出了一种名为Newfluence的新方法，在高维场景下更准确地解释模型。", "motivation": "机器学习和人工智能模型的日益复杂性导致对模型决策和预测进行解释和改进工具的迫切需求。影响力函数是常用方法，但其基于低维假设，不适用于现代AI模型的高维设置。", "method": "本文在高维设置下检验了影响力函数的准确性，并通过理论和实证分析揭示其不可靠性。随后，提出了一种名为Newfluence的替代近似方法，该方法在保持相似计算效率的同时显著提高了准确性。", "result": "影响力函数在高维设置下无法可靠地实现其预期目的。Newfluence在计算效率相似的情况下，显著提高了准确性。", "conclusion": "Newfluence有望比现有许多方法为解释复杂AI模型和诊断其问题提供更准确的见解。此外，本文开发的高维框架还可应用于分析其他流行技术，如Shapley值。", "translation": "机器学习（ML）和人工智能（AI）模型日益增长的复杂性，迫切需要工具来帮助科学家、工程师和政策制定者解释和完善模型的决策和预测。源自稳健统计学的影响力函数已成为实现此目的的一种流行方法。然而，影响力函数的启发式基础依赖于低维假设，即参数数量p远小于观测数量n。相比之下，现代AI模型通常在高维状态下运行，p值较大，这挑战了这些假设。在本文中，我们研究了影响力函数在高维设置中的准确性。我们的理论和实证分析表明，影响力函数无法可靠地实现其预期目的。然后，我们引入了一种名为Newfluence的替代近似方法，该方法在保持相似计算效率的同时显著提高了准确性。Newfluence有望比许多现有方法为解释复杂AI模型和诊断其问题提供更准确的见解。此外，本文开发的高维框架还可以应用于分析其他流行技术，如Shapley值。", "summary": "本文针对机器学习和人工智能模型在高维环境下可解释性工具的迫切需求，深入探讨了传统影响力函数在高维设置下的局限性，并指出其在高维场景下无法可靠地发挥作用。为此，研究提出了一种名为Newfluence的新型近似方法，该方法在保持与现有方法相似计算效率的同时，显著提升了模型解释的准确性。Newfluence有望为复杂AI模型的解释和问题诊断提供更精确的洞察，并且其提出的高维分析框架也适用于Shapley值等其他流行技术。", "keywords": "模型可解释性, 影响力函数, 高维, Newfluence, AI模型诊断", "comments": "本文的创新点在于揭示了传统影响力函数在高维场景下的局限性，并提出了一种更准确、计算效率相似的替代方法Newfluence。这对于提升现代复杂AI模型的可解释性具有重要意义，尤其是在大数据和高维特征盛行的当下。该研究不仅解决了现有方法的痛点，还提出了一个可推广的高维分析框架，具有很强的实用价值和理论贡献。"}}
{"id": "2507.12079", "title": "Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning", "authors": ["Tosin Adewumi", "Foteini Simistira Liwicki", "Marcus Liwicki", "Viktor Gardelli", "Lama Alkhaled", "Hamam Mokayed"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This paper was accepted for the special issue AI for Education by the IEEE Signal Processing Magazine journal", "url": "http://arxiv.org/abs/2507.12079v1", "summary": "This paper presents an intervention study on the effects of the combined\nmethods of (1) the Socratic method, (2) Chain of Thought (CoT) reasoning, (3)\nsimplified gamification and (4) formative feedback on university students'\nMaths learning driven by large language models (LLMs). We call our approach\nMathematics Explanations through Games by AI LLMs (MEGA). Some students\nstruggle with Maths and as a result avoid Math-related discipline or subjects\ndespite the importance of Maths across many fields, including signal\nprocessing. Oftentimes, students' Maths difficulties stem from suboptimal\npedagogy. We compared the MEGA method to the traditional step-by-step (CoT)\nmethod to ascertain which is better by using a within-group design after\nrandomly assigning questions for the participants, who are university students.\nSamples (n=60) were randomly drawn from each of the two test sets of the Grade\nSchool Math 8K (GSM8K) and Mathematics Aptitude Test of Heuristics (MATH)\ndatasets, based on the error margin of 11%, the confidence level of 90%, and a\nmanageable number of samples for the student evaluators. These samples were\nused to evaluate two capable LLMs at length (Generative Pretrained Transformer\n4o (GPT4o) and Claude 3.5 Sonnet) out of the initial six that were tested for\ncapability. The results showed that students agree in more instances that the\nMEGA method is experienced as better for learning for both datasets. It is even\nmuch better than the CoT (47.5% compared to 26.67%) in the more difficult MATH\ndataset, indicating that MEGA is better at explaining difficult Maths problems.", "comment": "This paper was accepted for the special issue AI for Education by the\n  IEEE Signal Processing Magazine journal", "pdf_url": "http://arxiv.org/pdf/2507.12079v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MEGA的发现：使用苏格拉底方法和大型语言模型进行主动学习的数学解释", "tldr": "本文提出了一种结合苏格拉底方法、思维链、游戏化和反馈的名为MEGA的LLM驱动的数学学习方法，并发现它比传统思维链方法在解释数学问题上更有效，尤其对于难题。", "motivation": "许多大学生在数学学习上遇到困难，甚至因此避免相关学科，这通常源于不理想的教学方法。本研究旨在通过LLMs探索一种更有效的数学教学干预措施。", "method": "本研究提出了一种名为MEGA（Mathematics Explanations through Games by AI LLMs）的方法，该方法结合了苏格拉底方法、思维链（CoT）推理、简化游戏化和形成性反馈，并通过大型语言模型（LLMs）驱动。研究采用组内设计，将MEGA方法与传统的逐步思维链（CoT）方法进行比较。实验对象为大学学生，从GSM8K和MATH数据集中随机抽取60个样本问题进行评估。评估中使用了GPT4o和Claude 3.5 Sonnet两种大型语言模型。", "result": "结果显示，学生普遍认为MEGA方法在两个数据集中都提供了更好的学习体验。在更困难的MATH数据集中，MEGA方法的表现（47.5%）远优于CoT方法（26.67%）。", "conclusion": "MEGA方法通过结合苏格拉底方法、思维链、游戏化和反馈，能够更有效地利用大型语言模型解释数学问题，尤其是在处理较难的数学问题时表现出显著优势。", "translation": "本文介绍了一项干预研究，探讨了苏ocratic方法、思维链（CoT）推理、简化游戏化和形成性反馈这四种组合方法在大型语言模型（LLMs）驱动下对大学生数学学习的影响。我们将这种方法称为基于人工智能大型语言模型的数学解释游戏（MEGA）。一些学生在数学学习上遇到困难，因此尽管数学在包括信号处理在内的许多领域都非常重要，他们仍会避免数学相关的学科或课程。通常，学生的数学困难源于次优的教学方法。我们采用组内设计，在为参与的大学生随机分配问题后，将MEGA方法与传统的逐步思维链（CoT）方法进行比较，以确定哪种方法更优。根据11%的误差幅度、90%的置信水平以及学生评估者可管理的样本数量，从Grade School Math 8K (GSM8K) 和 Mathematics Aptitude Test of Heuristics (MATH) 数据集的两个测试集中随机抽取了样本（n=60）。这些样本用于充分评估了最初测试的六个有能力的大型语言模型中的两个（Generative Pretrained Transformer 4o (GPT4o) 和 Claude 3.5 Sonnet）。结果表明，对于这两个数据集，学生在更多情况下同意MEGA方法在学习体验上更好。在更困难的MATH数据集中，它甚至比CoT方法（47.5% 对比 26.67%）好得多，这表明MEGA在解释困难数学问题方面表现更佳。", "summary": "本研究提出了一种名为MEGA（Mathematics Explanations through Games by AI LLMs）的新型数学教学方法，该方法整合了苏格拉底方法、思维链推理、简化游戏化和形成性反馈，并由大型语言模型（LLMs）驱动。为解决学生在数学学习中遇到的困难，研究通过与传统思维链方法进行比较，发现MEGA方法在提升大学生数学学习体验上表现更优，尤其在解释复杂数学问题时效果显著，优于传统方法。", "keywords": "数学解释, 大型语言模型, 苏格拉底方法, 思维链, 游戏化学习", "comments": "这项研究通过结合多种教学策略（苏格拉底方法、CoT、游戏化、反馈）与大型语言模型，为解决学生数学学习困难提供了一种创新性方案。其亮点在于对难点问题的解释能力提升，这对于实际教学具有重要意义。研究设计严谨，通过对比实验验证了方法的有效性。"}}
{"id": "2503.19609", "title": "Nanopass Back-Translation of Call-Return Trees for Mechanized Secure Compilation Proofs", "authors": ["Jérémy Thibault", "Joseph Lenormand", "Catalin Hritcu"], "categories": ["cs.PL", "cs.CR"], "primary_category": "Subjects:       Programming Languages (cs.PL)", "pdf_link": null, "comments": "Comments:      ITP'25 final version", "url": "http://arxiv.org/abs/2503.19609v3", "summary": "Researchers aim to build secure compilation chains enforcing that if there is\nno attack a source context can mount against a source program then there is\nalso no attack an adversarial target context can mount against the compiled\nprogram. Proving that these compilation chains are secure is, however,\nchallenging, and involves a non-trivial back-translation step: for any attack a\ntarget context mounts against the compiled program one has to exhibit a source\ncontext mounting the same attack against the source program. We describe a\nnovel back-translation technique, which results in simpler proofs that can be\nmore easily mechanized in a proof assistant. Given a finite set of finite trace\nprefixes, capturing the interaction recorded during an attack between a target\ncontext and the compiled program, we build a call-return tree that we\nback-translate into a source context producing the same trace prefixes. We use\nstate in the generated source context to record the current location in the\ncall-return tree. The back-translation is done in several small steps, each\nadding to the tree new information describing how the location should change\ndepending on how the context regains control. To prove this back-translation\ncorrect we give semantics to every intermediate call-return tree language,\nusing ghost state to store information and explicitly enforce execution\ninvariants. We prove several small forward simulations, basically seeing the\nback-translation as a verified nanopass compiler. Thanks to this modular\nstructure, we are able to mechanize this complex back-translation and its\ncorrectness proof in the Rocq prover without too much effort.", "comment": "ITP'25 final version", "pdf_url": "http://arxiv.org/pdf/2503.19609v3", "cate": "cs.PL", "date": "2025-03-25", "updated": "2025-07-16", "AI": {"title_translation": "机械化安全编译证明的纳通回译调用-返回树", "tldr": "提出了一种新颖的纳通回译技术，将目标攻击痕迹回译为源程序攻击，简化了安全编译证明的机械化过程。", "motivation": "证明编译链的安全性具有挑战性，特别是需要一个非平凡的回译步骤，即将目标上下文对编译程序的攻击回译为源上下文对源程序的攻击。", "method": "提出了一种新颖的纳通回译技术。该方法通过给定有限的跟踪前缀集合，构建一个调用-返回树，并将其回译为一个生成相同跟踪前缀的源上下文。回译过程分多个小步骤进行，每个步骤都向树中添加新信息。为了证明回译的正确性，对每个中间调用-返回树语言赋予了语义，并使用幽灵状态和执行不变量，通过一系列小的正向模拟来验证，将其视为一个已验证的纳通编译器。", "result": "提出的回译技术使得安全编译证明更简单，并且更容易在证明助手中机械化。由于模块化结构，复杂的后向翻译及其正确性证明可以在Rocq证明器中轻松实现。", "conclusion": "通过开发一种模块化的纳通回译技术，成功简化并机械化了安全编译证明中的关键回译步骤，使得在证明助手中进行安全编译证明变得更加可行和高效。", "translation": "研究人员旨在构建安全的编译链，确保如果源上下文无法对源程序发起攻击，那么对抗性目标上下文也无法对编译后的程序发起攻击。然而，证明这些编译链的安全性具有挑战性，并且涉及一个非平凡的回译步骤：对于目标上下文对编译程序发起的任何攻击，都必须展示一个源上下文对源程序发起相同的攻击。我们描述了一种新颖的回译技术，该技术可以产生更简单的证明，并且更容易在证明助手中进行机械化。给定一组有限的跟踪前缀，捕获在攻击期间目标上下文与编译程序之间记录的交互，我们构建一个调用-返回树，并将其回译为一个生成相同跟踪前缀的源上下文。我们在生成的源上下文中使用状态来记录调用-返回树中的当前位置。回译分几个小步骤完成，每个步骤都向树中添加新信息，描述位置应如何根据上下文重新获得控制而改变。为了证明这种回译的正确性，我们为每个中间调用-返回树语言提供了语义，使用幽灵状态存储信息并明确强制执行执行不变量。我们证明了几个小的正向模拟，基本上将回译视为一个经过验证的纳通编译器。由于这种模块化结构，我们能够毫不费力地在Rocq证明器中机械化这种复杂的回译及其正确性证明。", "summary": "本文提出了一种新颖的纳通回译技术，旨在简化安全编译链的机械化证明过程。针对目标上下文对编译程序发起的攻击，该技术能够将有限的攻击痕迹前缀构建成调用-返回树，并将其回译为源上下文，从而在源程序上重现相同的攻击。该回译过程通过一系列小步骤实现，并借助幽灵状态和执行不变量进行正确性验证。这种模块化的方法使得复杂的后向翻译及其正确性证明在Rocq证明器中得以高效机械化，从而显著降低了安全编译证明的难度。", "keywords": "安全编译, 回译, 纳通, 调用-返回树, 机械化证明", "comments": "这篇论文通过引入纳通回译技术，解决了安全编译证明中回译步骤的复杂性问题，其创新点在于将回译过程分解为模块化的“纳通”步骤，并利用调用-返回树结构进行高效管理。这种方法不仅简化了证明过程，还使其更易于在证明助手中机械化，对推进安全编译领域的自动化验证具有重要意义。"}}
{"id": "2507.11932", "title": "Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs", "authors": ["Mohammad Shahab Sepehri", "Berk Tinaz", "Zalan Fabian", "Mahdi Soltanolkotabi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11932v1", "summary": "Mental visualization, the ability to construct and manipulate visual\nrepresentations internally, is a core component of human cognition and plays a\nvital role in tasks involving reasoning, prediction, and abstraction. Despite\nthe rapid progress of Multimodal Large Language Models (MLLMs), current\nbenchmarks primarily assess passive visual perception, offering limited insight\ninto the more active capability of internally constructing visual patterns to\nsupport problem solving. Yet mental visualization is a critical cognitive skill\nin humans, supporting abilities such as spatial navigation, predicting physical\ntrajectories, and solving complex visual problems through imaginative\nsimulation. To bridge this gap, we introduce Hyperphantasia, a synthetic\nbenchmark designed to evaluate the mental visualization abilities of MLLMs\nthrough four carefully constructed puzzles. Each task is procedurally generated\nand presented at three difficulty levels, enabling controlled analysis of model\nperformance across increasing complexity. Our comprehensive evaluation of\nstate-of-the-art models reveals a substantial gap between the performance of\nhumans and MLLMs. Additionally, we explore the potential of reinforcement\nlearning to improve visual simulation capabilities. Our findings suggest that\nwhile some models exhibit partial competence in recognizing visual patterns,\nrobust mental visualization remains an open challenge for current MLLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11932v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "超感知：一个评估多模态大型语言模型心理可视化能力的基准", "tldr": "引入Hyperphantasia基准，评估多模态大语言模型（MLLMs）的心理可视化能力，发现MLLMs与人类表现存在显著差距，表明心理可视化仍是MLLMs的开放挑战。", "motivation": "现有基准主要评估被动视觉感知，缺乏对内部构建视觉模式以支持问题解决的“心理可视化”能力的评估。心理可视化是人类重要的认知技能，对推理、预测和抽象至关重要。", "method": "引入了名为Hyperphantasia的合成基准，包含四个精心构建的谜题。每个任务都是程序化生成并有三个难度级别。对最先进的模型进行了全面评估，并探讨了强化学习在提高视觉模拟能力方面的潜力。", "result": "最先进的模型在Hyperphantasia基准上的表现与人类存在显著差距。尽管一些模型在识别视觉模式方面表现出部分能力，但强大的心理可视化对当前MLLMs来说仍然是一个开放的挑战。", "conclusion": "尽管MLLMs在视觉感知方面取得进展，但其心理可视化能力仍远低于人类水平，需要进一步研究来弥补这一差距。", "translation": "心理可视化，即在内部构建和操作视觉表征的能力，是人类认知的一个核心组成部分，在涉及推理、预测和抽象的任务中发挥着至关重要的作用。尽管多模态大型语言模型（MLLMs）取得了快速进展，但当前的基准主要评估被动视觉感知，对内部构建视觉模式以支持问题解决的更主动能力提供的洞察有限。然而，心理可视化是人类一项关键的认知技能，支持空间导航、预测物理轨迹和通过想象模拟解决复杂视觉问题等能力。为了弥补这一差距，我们引入了Hyperphantasia，一个旨在通过四个精心构建的谜题来评估MLLMs心理可视化能力的合成基准。每个任务都是程序化生成并以三个难度级别呈现，从而能够对模型在日益复杂情况下的性能进行受控分析。我们对最先进模型的全面评估揭示了人类和MLLMs之间存在显著的性能差距。此外，我们探讨了强化学习提高视觉模拟能力的潜力。我们的发现表明，虽然一些模型在识别视觉模式方面表现出部分能力，但强大的心理可视化对当前的MLLMs来说仍然是一个开放的挑战。", "summary": "本文提出了Hyperphantasia，一个用于评估多模态大型语言模型（MLLMs）心理可视化能力的合成基准。该基准包含四个程序化生成且具有不同难度等级的谜题，旨在弥补现有视觉感知基准在评估主动心理可视化能力方面的不足。通过对最先进MLLMs的评估，研究发现它们在心理可视化能力上与人类存在显著差距，尽管部分模型能识别视觉模式，但实现鲁棒的心理可视化仍是当前MLLMs面临的挑战。文章还探讨了强化学习在此方面的应用潜力。", "keywords": "心理可视化, 多模态大型语言模型, 基准, Hyperphantasia, 视觉模拟", "comments": "这篇论文解决了当前多模态LLMs评估中的一个重要空白，即缺乏对“心理可视化”这一高级认知能力的评估。引入Hyperphantasia基准具有创新性，它通过结构化谜题和难度分级，为更精细地分析模型性能提供了工具。研究结果揭示了MLLMs与人类在心理可视化方面的巨大差距，这对于未来MLLMs的发展方向具有重要指导意义。探索强化学习的应用也为解决这一挑战提供了新的思路。"}}
{"id": "2507.12339", "title": "Symbolic Control: Unveiling Free Robustness Margins", "authors": ["Youssef Ait Si", "Antoine Girard", "Adnane Saoud"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      9", "url": "http://arxiv.org/abs/2507.12339v1", "summary": "This paper addresses the challenge of ensuring robustness in the presence of\nsystem perturbations for symbolic control techniques. Given a discrete-time\ncontrol system that is related to its symbolic model by an alternating\nsimulation relation. In this paper, we focus on computing the maximum\nrobustness margin under which the symbolic model remains valid for a\nperturbed-version of the discrete-time control system. We first show that\nsymbolic models are inherently equipped with a certain free robustness margins.\nWe then provide constructive procedures to compute uniform and non-uniform\n(state and input dependent) robustness margins. We also show that the tightness\nof the robustness margin depends on the tightness of the reachability technique\nused to compute the symbolic model. We then explain how the computed robustness\nmargin can be used for the sake of controller synthesis. Finally, we present\ntwo illustrative examples to demonstrate the effectiveness of our approach.", "comment": "9", "pdf_url": "http://arxiv.org/pdf/2507.12339v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "符号控制：揭示自由鲁棒性裕度", "tldr": "本文计算了符号控制系统在扰动下的最大鲁棒性裕度，表明它们具有固有的鲁棒性，并提供了计算方法，可用于控制器综合。", "motivation": "本文旨在解决符号控制技术在系统存在扰动时如何确保鲁棒性的挑战，特别是计算在扰动下符号模型仍能保持有效的最大鲁棒性裕度。", "method": "本文首先证明了符号模型本身就具有一定的自由鲁棒性裕度。然后，提供了计算均匀和非均匀（依赖于状态和输入）鲁棒性裕度的构造性程序。研究还指出鲁棒性裕度的紧密性取决于用于计算符号模型的可达性技术的紧密性，并解释了如何将计算出的鲁棒性裕度用于控制器综合。", "result": "符号模型本身具有自由鲁棒性裕度；提供了计算均匀和非均匀鲁棒性裕度的构造性程序；鲁棒性裕度的紧密性取决于可达性技术的紧密性；计算出的鲁棒性裕度可用于控制器综合；通过两个示例证明了方法的有效性。", "conclusion": "本文成功展示了如何计算和利用符号控制系统的鲁棒性裕度，突出了其固有的鲁棒性，并为控制器综合的实际应用提供了方法。", "translation": "本文解决了符号控制技术在存在系统扰动时确保鲁棒性的挑战。给定一个通过交替模拟关系与其符号模型相关的离散时间控制系统。在本文中，我们专注于计算在受扰动的离散时间控制系统版本下，符号模型仍然有效的最大鲁棒性裕度。我们首先表明符号模型本身就具有一定的自由鲁棒性裕度。然后，我们提供了构造性程序来计算均匀和非均匀（依赖于状态和输入）的鲁棒性裕度。我们还表明，鲁棒性裕度的紧密性取决于用于计算符号模型的可达性技术的紧密性。然后，我们解释了如何利用计算出的鲁棒性裕度进行控制器综合。最后，我们提出了两个说明性示例来证明我们方法的有效性。", "summary": "本文探讨了符号控制系统在扰动下的鲁棒性。研究表明，符号模型本身具有自由鲁棒性裕度，并开发了计算这些均匀和非均匀裕度的构造性程序。该研究还将鲁棒性裕度的紧密性与底层的可达性分析联系起来，并阐述了其在控制器综合中的应用，提供了示例来验证该方法。", "keywords": "符号控制, 鲁棒性裕度, 系统扰动, 控制器综合, 可达性分析", "comments": "这篇论文在量化和揭示符号控制系统固有鲁棒性方面具有创新性，这对于它们在不确定环境中的实际应用至关重要。计算鲁棒性裕度的构造性程序以及将其与可达性分析联系起来是重要的贡献。"}}
{"id": "2507.12441", "title": "Describe Anything Model for Visual Question Answering on Text-rich Images", "authors": ["Yen-Linh Vu", "Dinh-Thang Duong", "Truong-Binh Duong", "Anh-Khoi Nguyen", "Thanh-Huy Nguyen", "Le Thien Phuc Nguyen", "Jianhua Xing", "Xingjian Li", "Tianyang Wang", "Ulas Bagci", "Min Xu"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 5 figures. Accepted to VisionDocs @ ICCV 2025", "url": "http://arxiv.org/abs/2507.12441v1", "summary": "Recent progress has been made in region-aware vision-language modeling,\nparticularly with the emergence of the Describe Anything Model (DAM). DAM is\ncapable of generating detailed descriptions of any specific image areas or\nobjects without the need for additional localized image-text alignment\nsupervision. We hypothesize that such region-level descriptive capability is\nbeneficial for the task of Visual Question Answering (VQA), especially in\nchallenging scenarios involving images with dense text. In such settings, the\nfine-grained extraction of textual information is crucial to producing correct\nanswers. Motivated by this, we introduce DAM-QA, a framework with a tailored\nevaluation protocol, developed to investigate and harness the region-aware\ncapabilities from DAM for the text-rich VQA problem that requires reasoning\nover text-based information within images. DAM-QA incorporates a mechanism that\naggregates answers from multiple regional views of image content, enabling more\neffective identification of evidence that may be tied to text-related elements.\nExperiments on six VQA benchmarks show that our approach consistently\noutperforms the baseline DAM, with a notable 7+ point gain on DocVQA. DAM-QA\nalso achieves the best overall performance among region-aware models with fewer\nparameters, significantly narrowing the gap with strong generalist VLMs. These\nresults highlight the potential of DAM-like models for text-rich and broader\nVQA tasks when paired with efficient usage and integration strategies. Our code\nis publicly available at https://github.com/Linvyl/DAM-QA.git.", "comment": "11 pages, 5 figures. Accepted to VisionDocs @ ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.12441v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "用于富文本图像视觉问答的“描述一切”模型", "tldr": "DAM-QA是一个利用Describe Anything Model (DAM)的区域感知能力，专门为富文本图像视觉问答（VQA）设计的框架。它通过聚合多区域视图答案来更有效地识别文本相关证据，并在多个VQA基准测试中表现出色，尤其在DocVQA上取得了显著提升。", "motivation": "现有的区域感知视觉-语言模型（特别是Describe Anything Model, DAM）在生成详细图像区域描述方面表现出色。研究人员假设这种区域级描述能力对视觉问答（VQA）任务有益，尤其是在涉及密集文本图像的挑战性场景中，因为在这种情况下，细粒度地提取文本信息对于生成正确答案至关重要。", "method": "研究人员提出了DAM-QA框架，该框架旨在利用DAM的区域感知能力来解决富文本VQA问题。DAM-QA包含一种机制，可以聚合来自图像内容多个区域视图的答案，从而更有效地识别可能与文本相关元素绑定的证据。该框架还开发了一个量身定制的评估协议。", "result": "DAM-QA在六个VQA基准测试中表现出持续优于基线DAM的性能，在DocVQA上取得了显著的7点以上增益。在参数量更少的情况下，DAM-QA在区域感知模型中取得了最佳的整体性能，显著缩小了与强大的通用视觉-语言模型（VLMs）之间的差距。", "conclusion": "研究结果强调了DAM类模型与高效使用和集成策略相结合时，在富文本和更广泛的VQA任务中的潜力。", "translation": "最近，区域感知视觉-语言建模取得了进展，特别是“描述一切”模型（DAM）的出现。DAM能够生成任何特定图像区域或对象的详细描述，而无需额外的局部图像-文本对齐监督。我们假设这种区域级描述能力对于视觉问答（VQA）任务是有益的，尤其是在涉及密集文本图像的挑战性场景中。在这种设置下，细粒度地提取文本信息对于生成正确答案至关重要。受此启发，我们引入了DAM-QA，一个带有量身定制评估协议的框架，旨在研究和利用DAM的区域感知能力来解决需要对图像中文本信息进行推理的富文本VQA问题。DAM-QA包含一种机制，可以聚合来自图像内容多个区域视图的答案，从而更有效地识别可能与文本相关元素绑定的证据。在六个VQA基准测试上的实验表明，我们的方法持续优于基线DAM，在DocVQA上取得了显著的7点以上增益。DAM-QA还在参数量更少的区域感知模型中取得了最佳的整体性能，显著缩小了与强大的通用视觉-语言模型（VLMs）之间的差距。这些结果突出了DAM类模型与高效使用和集成策略相结合时，在富文本和更广泛的VQA任务中的潜力。我们的代码已公开，网址为 https://github.com/Linvyl/DAM-QA.git。", "summary": "该研究引入了DAM-QA，一个利用“描述一切”模型（DAM）区域感知能力的框架，旨在解决富文本图像上的视觉问答（VQA）问题。DAM-QA通过聚合图像多区域视图的答案来增强对文本相关证据的识别。实验结果表明，DAM-QA在多个VQA基准测试中均优于基线DAM，尤其在DocVQA上实现了显著提升，并以更少的参数在区域感知模型中取得了领先性能，突显了DAM类模型在处理文本密集型VQA任务中的巨大潜力。", "keywords": "视觉问答, 富文本图像, 描述一切模型, 区域感知, DAM-QA", "comments": "这项工作通过引入DAM-QA框架，成功地将DAM的区域感知描述能力应用于富文本VQA任务，解决了现有模型在处理图像中密集文本信息时的不足。其创新点在于通过聚合多区域视图答案的机制，提升了文本证据的识别效率。该方法在有限参数下取得了与大型通用VLM模型相近的性能，展示了其高效性和实用性，为未来VQA研究提供了新的方向。"}}
{"id": "2507.11700", "title": "Norm-Stabilized Imaginary-Time Evolution via Feedback Control", "authors": ["Stylianos Savva"], "categories": ["math.NA", "cs.NA", "nlin.PS", "physics.comp-ph", "65M06, 35Q55", "G.1.7; G.1.8"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures. Code and reproducibility: this https URL", "url": "http://arxiv.org/abs/2507.11700v1", "summary": "We present a norm-stabilized imaginary-time evolution (ITE) scheme for the\none-dimensional nonlinear Schrodinger equation (NLSE). Traditional ITE solvers\noften require explicit renormalization of the wavefunction after each step to\npreserve norm, which can be disruptive and algorithmically inflexible. We\npropose an alternative approach in which the evolution is continuously\nstabilized using an adaptive feedback term mu(tau), proportional to the time\nderivative of the wavefunction norm. This results in a self-regulating flow\nthat requires no external normalization while preserving convergence toward\nsoliton solutions. We demonstrate the method's effectiveness by comparing the\nfinal wavefunction profiles and L2 errors against analytical solutions and\nbaseline methods without feedback. Although this work focuses on the 1D case,\nthe framework is designed to extend naturally to higher dimensions. Future work\nwill explore the behavior of the feedback mechanism in 2D and 3D systems,\nmulti-soliton scenarios, and external potentials.", "comment": "9 pages, 5 figures. Code and reproducibility:\n  https://github.com/rrumabo/Stabilised-ITE-Solver", "pdf_url": "http://arxiv.org/pdf/2507.11700v1", "cate": "math.NA", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "通过反馈控制实现范数稳定化的虚时演化", "tldr": "提出了一种通过自适应反馈项连续稳定波函数范数的虚时演化方案，无需外部归一化即可收敛到孤子解。", "motivation": "传统的虚时演化（ITE）求解器通常需要在每一步之后对波函数进行显式归一化以保持范数，但这可能具有破坏性且算法不灵活。", "method": "本文提出了一种替代方法，通过使用与波函数范数的时间导数成比例的自适应反馈项 mu(tau) 连续稳定演化过程。这形成了一个自调节流。", "result": "该方法通过将最终波函数剖面和 L2 误差与解析解和没有反馈的基线方法进行比较，证明了其有效性。", "conclusion": "该方案产生了一个自调节流，无需外部归一化即可保持向孤子解的收敛。尽管目前专注于一维情况，但该框架可自然扩展到更高维度。", "translation": "我们提出了一种用于一维非线性薛定谔方程（NLSE）的范数稳定化虚时演化（ITE）方案。传统的ITE求解器通常需要在每一步之后对波函数进行显式归一化以保持范数，这可能具有破坏性且算法不灵活。我们提出了一种替代方法，其中通过使用与波函数范数的时间导数成比例的自适应反馈项 mu(tau) 连续稳定演化过程。这形成了一个自调节流，无需外部归一化即可保持向孤子解的收敛。我们通过将最终波函数剖面和L2误差与解析解和没有反馈的基线方法进行比较，证明了该方法的有效性。尽管这项工作侧重于一维情况，但该框架旨在自然扩展到更高维度。未来的工作将探索反馈机制在二维和三维系统、多孤子场景和外部势中的行为。", "summary": "本文提出了一种用于一维非线性薛定谔方程的范数稳定化虚时演化（ITE）方案。与传统需要显式归一化的方法不同，该方案通过引入一个与波函数范数时间导数成比例的自适应反馈项，实现波函数的连续稳定。这种自调节流无需外部归一化即可确保向孤子解的收敛。研究通过与解析解和基线方法的比较，验证了该方法的有效性，并指出其框架可扩展至更高维度。", "keywords": "虚时演化, 反馈控制, 非线性薛定谔方程, 孤子, 范数稳定化", "comments": "这项工作的创新之处在于提出了一种无需显式归一化即可实现范数稳定的虚时演化方法，通过引入自适应反馈机制，提高了算法的灵活性和鲁棒性。这对于解决传统ITE方法中存在的范数保持问题具有重要意义。该框架的通用性使其有望应用于更复杂的物理系统。"}}
{"id": "2507.12158", "title": "Probabilistic Safety Verification for an Autonomous Ground Vehicle: A Situation Coverage Grid Approach", "authors": ["Nawshin Mannan Proma", "Gricel Vázquez", "Sepeedeh Shahbeigi", "Arjun Badyal", "Victoria Hodge"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures", "url": "http://arxiv.org/abs/2507.12158v1", "summary": "As industrial autonomous ground vehicles are increasingly deployed in\nsafety-critical environments, ensuring their safe operation under diverse\nconditions is paramount. This paper presents a novel approach for their safety\nverification based on systematic situation extraction, probabilistic modelling\nand verification. We build upon the concept of a situation coverage grid, which\nexhaustively enumerates environmental configurations relevant to the vehicle's\noperation. This grid is augmented with quantitative probabilistic data\ncollected from situation-based system testing, capturing probabilistic\ntransitions between situations. We then generate a probabilistic model that\nencodes the dynamics of both normal and unsafe system behaviour. Safety\nproperties extracted from hazard analysis and formalised in temporal logic are\nverified through probabilistic model checking against this model. The results\ndemonstrate that our approach effectively identifies high-risk situations,\nprovides quantitative safety guarantees, and supports compliance with\nregulatory standards, thereby contributing to the robust deployment of\nautonomous systems.", "comment": "6 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.12158v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "自动驾驶地面车辆的概率安全验证：一种情境覆盖网格方法", "tldr": "本文提出了一种基于情境覆盖网格的自动驾驶地面车辆概率安全验证新方法，通过概率模型检测识别高风险情境并提供量化安全保证。", "motivation": "随着工业自动驾驶地面车辆在安全关键环境中的部署日益增多，确保其在各种条件下的安全运行至关重要。", "method": "该方法基于情境覆盖网格，详尽列举与车辆操作相关的环境配置。该网格通过从基于情境的系统测试中收集的定量概率数据进行增强，捕获情境间的概率转换。然后，生成一个编码正常和不安全系统行为动态的概率模型。从危险分析中提取并以时序逻辑形式化的安全属性，通过概率模型检测对照该模型进行验证。", "result": "结果表明，该方法能有效识别高风险情境，提供量化安全保证，并支持符合监管标准。", "conclusion": "该方法有助于自动驾驶系统的稳健部署，因为它能有效识别高风险情境，提供量化安全保证，并支持符合监管标准。", "translation": "随着工业自动驾驶地面车辆在安全关键环境中的部署日益增多，确保其在各种条件下的安全运行至关重要。本文提出了一种基于系统情境提取、概率建模和验证的自动驾驶地面车辆安全验证新方法。我们以情境覆盖网格的概念为基础，该网格详尽列举了与车辆操作相关的环境配置。该网格通过从基于情境的系统测试中收集的定量概率数据进行增强，捕获情境间的概率转换。然后，我们生成一个编码正常和不安全系统行为动态的概率模型。从危险分析中提取并以时序逻辑形式化的安全属性，通过概率模型检测对照该模型进行验证。结果表明，我们的方法能有效识别高风险情境，提供量化安全保证，并支持符合监管标准，从而有助于自动驾驶系统的稳健部署。", "summary": "本文提出了一种针对自动驾驶地面车辆的概率安全验证新方法，通过构建情境覆盖网格并结合概率建模和模型检测技术。该方法首先详尽列举相关环境情境，并利用系统测试数据增强网格以捕获情境间的概率转换。随后，生成一个概率模型编码系统行为，并使用概率模型检测来验证从危险分析中提取的安全属性。实验结果表明，该方法能够有效识别高风险情境，提供量化安全保证，并有助于满足监管标准，从而促进自动驾驶系统的安全部署。", "keywords": "自动驾驶车辆, 安全验证, 概率模型检测, 情境覆盖网格, 风险识别", "comments": "该论文的创新点在于提出了“情境覆盖网格”的概念，并将其与概率建模和模型检测相结合，为自动驾驶车辆的安全验证提供了一种系统化、量化的方法。这对于在安全关键环境中部署自动驾驶系统具有重要意义，因为它能够识别潜在的高风险情境并提供可衡量的安全保证，有助于满足严格的监管要求。"}}
{"id": "2408.10743", "title": "Fast Algorithms and Implementations for Computing the Minimum Distance of Quantum Codes", "authors": ["Fernando Hernando", "Gregorio Quintana-Ortí", "Markus Grassl"], "categories": ["quant-ph", "cs.CE", "cs.IT", "cs.MS", "math.IT", "81-04, 81-08, 94B05, 94B60, 94B99", "G.4"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      14 pages, 7 figures, 1 table", "url": "http://arxiv.org/abs/2408.10743v2", "summary": "The distance of a stabilizer quantum code is a very important feature since\nit determines the number of errors that can be detected and corrected. We\npresent three new fast algorithms and implementations for computing the\nsymplectic distance of the associated classical code. Our new algorithms are\nbased on the Brouwer-Zimmermann algorithm. Our experimental study shows that\nthese new implementations are much faster than current state-of-the-art\nlicensed implementations on single-core processors, multicore processors, and\nshared-memory multiprocessors. In the most computationally-demanding cases, the\nperformance gain in the computational time can be larger than one order of\nmagnitude. The experimental study also shows a good scalability on\nshared-memory parallel architectures.", "comment": "14 pages, 7 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2408.10743v2", "cate": "quant-ph", "date": "2024-08-20", "updated": "2025-07-16", "AI": {"title_translation": "计算量子码最小距离的快速算法与实现", "tldr": "本文提出了三种基于Brouwer-Zimmermann算法的新型快速算法和实现，用于计算量子码的最小距离。实验证明，这些新算法在单核、多核和共享内存多处理器上比现有技术快一个数量级以上，并具有良好的可扩展性。", "motivation": "稳定器量子码的距离是一个非常重要的特性，因为它决定了可以检测和纠正的错误数量。", "method": "本文提出了三种计算相关经典码的辛距离的新型快速算法和实现。这些新算法基于Brouwer-Zimmermann算法。", "result": "实验研究表明，这些新实现比目前最先进的许可实现在单核处理器、多核处理器和共享内存多处理器上快得多。在计算要求最高的情况下，计算时间性能提升可超过一个数量级。实验研究还表明在共享内存并行架构上具有良好的可扩展性。", "conclusion": "本文提出的新算法和实现能够显著提高计算量子码最小距离的效率，并在多种处理器架构上表现出卓越的性能和良好的可扩展性。", "translation": "稳定器量子码的距离是一个非常重要的特性，因为它决定了可以检测和纠正的错误数量。我们提出了三种新的快速算法和实现，用于计算相关经典码的辛距离。我们的新算法基于Brouwer-Zimmermann算法。我们的实验研究表明，这些新实现在单核处理器、多核处理器和共享内存多处理器上比目前最先进的许可实现快得多。在计算要求最高的情况下，计算时间性能提升可超过一个数量级。实验研究还表明在共享内存并行架构上具有良好的可扩展性。", "summary": "本文针对计算量子码最小距离的关键问题，提出了三种基于Brouwer-Zimmermann算法的新型快速算法及其实现。通过实验研究，证明这些新方法在单核、多核及共享内存多处理器上均能显著提升计算效率，性能提升可达一个数量级以上，并且在并行架构上展现出良好的可扩展性，从而有效解决了量子码距离计算的瓶颈。", "keywords": "量子码, 最小距离, 快速算法, Brouwer-Zimmermann, 并行计算", "comments": "本文的创新之处在于提出了基于Brouwer-Zimmermann算法的新的快速实现，显著提升了量子码最小距离的计算效率。其重要性在于量子码距离是衡量量子纠错能力的关键指标，更快的计算方法有助于量子信息科学的进步。实验结果展示了在多种处理器架构上的显著性能提升和良好的可扩展性，这对于实际应用具有重要意义。"}}
{"id": "2507.12211", "title": "Cell Sensing: Traffic detection", "authors": ["Saúl Fenollosa"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      39 pages, 16 figures. Student project report at the Telecommunications Circuits Laboratory (TCL), EPFL. Supervised by Prof. Andreas Burg and Sitian Li", "url": "http://arxiv.org/abs/2507.12211v1", "summary": "This work presents a passive sensing system for traffic monitoring using\nambient Long Term Evolution (LTE) signals as a non-intrusive and scalable\nalternative to traditional surveillance methods. The approach employs a\ndual-receiver architecture analyzing Channel State Information (CSI) to isolate\ndifferential Doppler shifts induced by moving targets, effectively mitigating\nhardware-induced phase impairments. Implemented with a Software Defined Radio\n(SDR) platform and srsRAN software, the system demonstrated over 90% detection\naccuracy for speeds above 6000 mm/min in controlled indoor tests, and provided\nreliable speed estimations for pedestrians and vehicles in outdoor evaluations.\nDespite challenges at low speeds, directional ambiguity, and multipath fading\nin urban settings, the results validate LTE-based passive sensing as a feasible\ntraffic monitoring method, identifying critical areas for future research such\nas angle-of-arrival (AoA) integration, machine learning, and real-time embedded\nsystem development.", "comment": "39 pages, 16 figures. Student project report at the\n  Telecommunications Circuits Laboratory (TCL), EPFL. Supervised by Prof.\n  Andreas Burg and Sitian Li", "pdf_url": "http://arxiv.org/pdf/2507.12211v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "蜂窝感知：交通检测", "tldr": "本文提出了一种利用环境LTE信号进行交通监测的被动感知系统，该系统通过分析信道状态信息（CSI）和双接收器架构，实现了高精度检测和速度估算，验证了其作为可行方法的潜力，并指出了未来的研究方向。", "motivation": "传统的交通监控方法具有侵入性和可扩展性问题，需要一种非侵入性且可扩展的替代方案。", "method": "该方法采用双接收器架构，分析信道状态信息（CSI）以分离移动目标引起的差分多普勒频移，有效减轻硬件引起的相位损伤。系统使用软件定义无线电（SDR）平台和srsRAN软件实现。", "result": "在受控室内测试中，对于速度高于6000毫米/分钟的目标，系统检测准确率超过90%。在室外评估中，该系统为行人和车辆提供了可靠的速度估算。", "conclusion": "LTE-based被动感知是一种可行的交通监测方法，尽管在低速、方向模糊性和城市环境中的多径衰落方面存在挑战。未来的研究方向包括角度到达（AoA）集成、机器学习和实时嵌入式系统开发。", "translation": "这项工作提出了一种利用环境长期演进（LTE）信号进行交通监测的被动感知系统，作为传统监控方法的一种非侵入式和可扩展的替代方案。该方法采用双接收器架构，分析信道状态信息（CSI）以分离由移动目标引起的差分多普勒频移，有效减轻硬件引起的相位损伤。该系统通过软件定义无线电（SDR）平台和srsRAN软件实现，在受控室内测试中，对于速度高于6000毫米/分钟的目标，检测准确率超过90%，并在室外评估中为行人和车辆提供了可靠的速度估算。尽管在低速、方向模糊性和城市环境中的多径衰落方面存在挑战，但结果验证了基于LTE的被动感知作为一种可行的交通监测方法，并指出了未来研究的关键领域，例如到达角（AoA）集成、机器学习和实时嵌入式系统开发。", "summary": "本文提出了一种基于环境LTE信号的被动交通感知系统，旨在替代传统监控方式。该系统采用双接收器架构和CSI分析，有效检测并估算移动目标（包括行人和车辆）的速度。实验结果表明，在室内测试中对高速目标检测精度超过90%，并能可靠估算室外目标速度。研究验证了LTE被动感知的可行性，并指出了低速挑战、方向模糊性、多径衰落以及未来AoA集成、机器学习和实时嵌入式系统开发等研究方向。", "keywords": "LTE, 被动感知, 交通监测, CSI, 多普勒频移", "comments": "该论文提出了一种利用现有LTE基础设施进行交通监测的创新方法，具有非侵入性和可扩展性的优势。其通过分析CSI和采用双接收器架构来处理多普勒频移的策略，有效解决了硬件引起的相位问题。尽管在低速和复杂城市环境中存在局限性，但其超过90%的检测准确率和可靠的速度估算能力证明了其巨大潜力。未来研究方向的明确指出，如结合AoA和机器学习，预示着该技术有望进一步成熟和应用。"}}
{"id": "2504.09037", "title": "A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems", "authors": ["Zixuan Ke", "Fangkai Jiao", "Yifei Ming", "Xuan-Phi Nguyen", "Austin Xu", "Do Xuan Long", "Minzhi Li", "Chengwei Qin", "Peifeng Wang", "Silvio Savarese", "Caiming Xiong", "Shafiq Joty"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      72 pages, 6 figures", "url": "http://arxiv.org/abs/2504.09037v2", "summary": "Reasoning is a fundamental cognitive process that enables logical inference,\nproblem-solving, and decision-making. With the rapid advancement of large\nlanguage models (LLMs), reasoning has emerged as a key capability that\ndistinguishes advanced AI systems from conventional models that empower\nchatbots. In this survey, we categorize existing methods along two orthogonal\ndimensions: (1) Regimes, which define the stage at which reasoning is achieved\n(either at inference time or through dedicated training); and (2)\nArchitectures, which determine the components involved in the reasoning\nprocess, distinguishing between standalone LLMs and agentic compound systems\nthat incorporate external tools, and multi-agent collaborations. Within each\ndimension, we analyze two key perspectives: (1) Input level, which focuses on\ntechniques that construct high-quality prompts that the LLM condition on; and\n(2) Output level, which methods that refine multiple sampled candidates to\nenhance reasoning quality. This categorization provides a systematic\nunderstanding of the evolving landscape of LLM reasoning, highlighting emerging\ntrends such as the shift from inference-scaling to learning-to-reason (e.g.,\nDeepSeek-R1), and the transition to agentic workflows (e.g., OpenAI Deep\nResearch, Manus Agent). Additionally, we cover a broad spectrum of learning\nalgorithms, from supervised fine-tuning to reinforcement learning such as PPO\nand GRPO, and the training of reasoners and verifiers. We also examine key\ndesigns of agentic workflows, from established patterns like\ngenerator-evaluator and LLM debate to recent innovations. ...", "comment": "72 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2504.09037v2", "cate": "cs.AI", "date": "2025-04-12", "updated": "2025-07-16", "AI": {"title_translation": "LLM推理前沿综述：推理扩展、学习推理和智能体系统", "tldr": "本综述系统地分析了大型语言模型（LLM）推理能力的最新进展，提出了一个基于推理阶段（推断时或训练时）和架构（独立LLM或智能体复合系统）的分类框架，并探讨了推理质量提升的输入和输出层方法，揭示了从推理扩展到学习推理以及向智能体工作流转变的趋势。", "motivation": "推理是认知过程的基础，随着大型语言模型（LLM）的快速发展，推理已成为区分高级AI系统和传统模型（如聊天机器人）的关键能力。本综述旨在对LLM推理领域的现有方法进行系统性理解和分类。", "method": "本综述将现有方法沿两个正交维度进行分类：1) 机制（Regimes），定义推理实现的阶段（推断时或通过专用训练）；2) 架构（Architectures），确定推理过程中涉及的组件（独立LLM或结合外部工具和多智能体协作的复合系统）。在这两个维度内，进一步分析了两个关键视角：1) 输入层，关注构建高质量提示的技术；2) 输出层，关注通过细化多个采样候选来增强推理质量的方法。此外，还涵盖了从监督微调到强化学习（如PPO和GRPO）的广泛学习算法，以及推理器和验证器的训练，并考察了智能体工作流的关键设计。", "result": "本综述提供了一个对LLM推理不断演变格局的系统性理解，突出了新兴趋势，例如从推理扩展到学习推理（如DeepSeek-R1）的转变，以及向智能体工作流（如OpenAI Deep Research、Manus Agent）的过渡。同时，涵盖了多种学习算法和智能体工作流设计模式。", "conclusion": "Not mentioned in abstract", "translation": "推理是一种基本的认知过程，它能够进行逻辑推理、解决问题和做出决策。随着大型语言模型（LLM）的快速发展，推理已成为区分高级AI系统和传统赋能聊天机器人的模型的关键能力。在本综述中，我们根据两个正交维度对现有方法进行分类：(1) 机制，定义了实现推理的阶段（在推断时或通过专门的训练）；(2) 架构，确定了推理过程中涉及的组件，区分了独立LLM和结合外部工具的智能体复合系统，以及多智能体协作。在每个维度中，我们分析了两个关键视角：(1) 输入层，侧重于构建LLM所依赖的高质量提示的技术；(2) 输出层，通过细化多个采样候选来提高推理质量的方法。这种分类提供了对LLM推理不断演变格局的系统性理解，突出了新兴趋势，例如从推理扩展到学习推理（例如DeepSeek-R1）的转变，以及向智能体工作流（例如OpenAI Deep Research、Manus Agent）的过渡。此外，我们涵盖了广泛的学习算法，从监督微调到强化学习，如PPO和GRPO，以及推理器和验证器的训练。我们还考察了智能体工作流的关键设计，从生成器-评估器和LLM辩论等既定模式到最近的创新。", "summary": "本综述旨在系统理解大型语言模型（LLM）的推理前沿。论文提出了一个双维度分类框架，即推理实现阶段（推断时或训练时）和架构（独立LLM或智能体系统），并在此基础上进一步分析了输入层和输出层提升推理质量的方法。综述揭示了LLM推理从推理扩展到学习推理以及向智能体工作流转变的关键趋势，并涵盖了广泛的学习算法和智能体工作流设计。", "keywords": "LLM推理, 推理扩展, 学习推理, 智能体系统, 综述", "comments": "这是一篇重要的综述性论文，它为快速发展的LLM推理领域提供了一个急需的、结构化的概述。其创新之处在于提出了一个清晰的分类框架，这有助于研究人员更好地理解和定位现有工作。论文强调的从“推理扩展”到“学习推理”以及向“智能体系统”的转变，为未来的研究指明了方向，具有重要的指导意义。"}}
{"id": "2507.09477", "title": "Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs", "authors": ["Yangning Li", "Weizhi Zhang", "Yuyao Yang", "Wei-Chieh Huang", "Yaozu Wu", "Junyu Luo", "Yuanchen Bei", "Henry Peng Zou", "Xiao Luo", "Yusheng Zhao", "Chunkit Chan", "Yankai Chen", "Zhongfen Deng", "Yinghui Li", "Hai-Tao Zheng", "Dongyuan Li", "Renhe Jiang", "Ming Zhang", "Yangqiu Song", "Philip S. Yu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      submitted to ARR May", "url": "http://arxiv.org/abs/2507.09477v2", "summary": "Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language\nModels (LLMs) by injecting external knowledge, yet it falls short on problems\nthat demand multi-step inference; conversely, purely reasoning-oriented\napproaches often hallucinate or mis-ground facts. This survey synthesizes both\nstrands under a unified reasoning-retrieval perspective. We first map how\nadvanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then,\nwe show how retrieved knowledge of different type supply missing premises and\nexpand context for complex inference (RAG-Enhanced Reasoning). Finally, we\nspotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs\niteratively interleave search and reasoning to achieve state-of-the-art\nperformance across knowledge-intensive benchmarks. We categorize methods,\ndatasets, and open challenges, and outline research avenues toward deeper\nRAG-Reasoning systems that are more effective, multimodally-adaptive,\ntrustworthy, and human-centric. The collection is available at\nhttps://github.com/DavidZWZ/Awesome-RAG-Reasoning.", "comment": "submitted to ARR May", "pdf_url": "http://arxiv.org/pdf/2507.09477v2", "cate": "cs.CL", "date": "2025-07-13", "updated": "2025-07-16", "AI": {"title_translation": "迈向深度推理的智能体RAG：大型语言模型中RAG-推理系统的综述", "tldr": "该综述探讨了检索增强生成（RAG）与推理的结合，以解决LLM在多步推理中的不足和幻觉问题，并展望了未来研究方向。", "motivation": "检索增强生成（RAG）虽然提升了大型语言模型（LLMs）的事实性，但在需要多步推理的问题上表现不足；而纯粹的推理方法又常出现幻觉或事实误导。因此，需要一个统一的推理-检索视角来解决这些问题。", "method": "本综述从统一的推理-检索视角出发，首先阐述了高级推理如何优化RAG的各个阶段（推理增强RAG），其次展示了不同类型的检索知识如何为复杂推理提供缺失前提和扩展上下文（RAG增强推理），最后重点介绍了新兴的协同RAG-推理框架（其中智能体LLMs迭代地交织搜索和推理）。此外，它还对方法、数据集和开放挑战进行了分类，并概述了未来的研究方向。", "result": "该综述系统地分类了RAG-推理方法、数据集和开放挑战，并提出了未来研究方向，旨在构建更有效、多模态适应、值得信赖和以人为中心的深度RAG-推理系统。", "conclusion": "本综述强调了RAG与深度推理结合的必要性，并提出了一个统一的RAG-推理系统框架，为未来的研究指明了方向，旨在解决现有LLM的局限性并提升其在知识密集型任务上的性能。", "translation": "检索增强生成（RAG）通过注入外部知识提升了大型语言模型（LLMs）的事实性，但它在需要多步推理的问题上表现不足；反之，纯粹的推理方法常常出现幻觉或事实误导。本综述从统一的推理-检索视角综合了这两种方法。我们首先描绘了高级推理如何优化RAG的每个阶段（推理增强RAG）。然后，我们展示了不同类型的检索知识如何为复杂推理提供缺失的前提并扩展上下文（RAG增强推理）。最后，我们重点介绍了新兴的协同RAG-推理框架，其中（智能体）LLMs迭代地交织搜索和推理，在知识密集型基准测试中取得了最先进的性能。我们对方法、数据集和开放挑战进行了分类，并概述了迈向更有效、多模态适应、值得信赖和以人为中心的深度RAG-推理系统的研究途径。相关集合可在https://github.com/DavidZWZ/Awesome-RAG-Reasoning获取。", "summary": "本综述深入探讨了大型语言模型中检索增强生成（RAG）与深度推理的结合。文章分析了RAG在多步推理上的局限性以及纯粹推理方法的幻觉问题，并提出了一个统一的推理-检索框架。该框架详细阐述了推理如何增强RAG（Reasoning-Enhanced RAG），以及检索知识如何支持复杂推理（RAG-Enhanced Reasoning）。此外，综述还重点介绍了智能体LLMs迭代结合搜索和推理的协同RAG-推理框架，并对现有方法、数据集和开放挑战进行了分类，为未来构建更高效、多模态、可信赖和以人为中心的RAG-推理系统指明了研究方向。", "keywords": "RAG, 推理, 大型语言模型, 智能体, 检索增强生成", "comments": "这篇综述通过将RAG与推理相结合，提供了一个全面的视角来解决大型语言模型在事实性和多步推理方面的核心挑战。其创新之处在于提出了统一的推理-检索框架，并区分了推理增强RAG和RAG增强推理。尤其重要的是，它强调了智能体LLMs在迭代搜索和推理中的作用，这为未来构建更强大的AI系统提供了重要的研究方向。"}}
{"id": "2507.11551", "title": "Landmark Detection for Medical Images using a General-purpose Segmentation Model", "authors": ["Ekaterina Stansfield", "Jennifer A. Mitterer", "Abdulrahman Altahhan"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      13 pages, 8 figures, 2 tables. Submitted to ICONIP 2025", "url": "http://arxiv.org/abs/2507.11551v1", "summary": "Radiographic images are a cornerstone of medical diagnostics in orthopaedics,\nwith anatomical landmark detection serving as a crucial intermediate step for\ninformation extraction. General-purpose foundational segmentation models, such\nas SAM (Segment Anything Model), do not support landmark segmentation out of\nthe box and require prompts to function. However, in medical imaging, the\nprompts for landmarks are highly specific. Since SAM has not been trained to\nrecognize such landmarks, it cannot generate accurate landmark segmentations\nfor diagnostic purposes. Even MedSAM, a medically adapted variant of SAM, has\nbeen trained to identify larger anatomical structures, such as organs and their\nparts, and lacks the fine-grained precision required for orthopaedic pelvic\nlandmarks. To address this limitation, we propose leveraging another\ngeneral-purpose, non-foundational model: YOLO. YOLO excels in object detection\nand can provide bounding boxes that serve as input prompts for SAM. While YOLO\nis efficient at detection, it is significantly outperformed by SAM in\nsegmenting complex structures. In combination, these two models form a reliable\npipeline capable of segmenting not only a small pilot set of eight anatomical\nlandmarks but also an expanded set of 72 landmarks and 16 regions with complex\noutlines, such as the femoral cortical bone and the pelvic inlet. By using\nYOLO-generated bounding boxes to guide SAM, we trained the hybrid model to\naccurately segment orthopaedic pelvic radiographs. Our results show that the\nproposed combination of YOLO and SAM yields excellent performance in detecting\nanatomical landmarks and intricate outlines in orthopaedic pelvic radiographs.", "comment": "13 pages, 8 figures, 2 tables. Submitted to ICONIP 2025", "pdf_url": "http://arxiv.org/pdf/2507.11551v1", "cate": "eess.IV", "date": "2025-07-13", "updated": "2025-07-13", "AI": {"title_translation": "医用图像地标检测：基于通用分割模型", "tldr": "通用分割模型SAM不适用于医学图像地标检测，即使是医学专用版MedSAM也缺乏精细度。本文提出结合YOLO（用于生成边界框提示）和SAM（用于精细分割）的混合模型，成功实现了骨科骨盆X射线图像中解剖地标和复杂轮廓的精确分割。", "motivation": "放射影像学在骨科诊断中至关重要，解剖地标检测是关键步骤。然而，通用分割模型如SAM不直接支持地标分割，需要特异性提示，且未针对医学地标进行训练，无法提供准确分割。即使是医学版MedSAM也缺乏对骨科骨盆地标所需的精细精度。", "method": "本文提出结合YOLO和SAM模型。YOLO用于目标检测，生成作为SAM输入提示的边界框。SAM则利用这些边界框进行精细的结构分割。通过使用YOLO生成的边界框指导SAM，训练了该混合模型来准确分割骨科骨盆X射线图像。", "result": "该组合模型形成了一个可靠的管道，不仅能够分割少量（8个）解剖地标，还能分割扩展的72个地标和16个具有复杂轮廓的区域（如股骨皮质骨和骨盆入口）。结果表明，所提出的YOLO和SAM组合在检测骨科骨盆X射线图像中的解剖地标和复杂轮廓方面表现出色。", "conclusion": "结合YOLO和SAM的混合模型有效解决了独立分割模型在精确医学地标检测方面的局限性，在骨科骨盆X射线图像中表现出卓越的性能。", "translation": "放射影像学在骨科医学诊断中是基石，其中解剖地标检测是信息提取的关键中间步骤。通用基础分割模型，如SAM（Segment Anything Model），本身不支持地标分割，需要提示才能发挥作用。然而，在医学图像中，地标的提示高度特异。由于SAM尚未训练识别此类地标，它无法为诊断目的生成准确的地标分割。即使是SAM的医学改编版本MedSAM，也已训练用于识别更大的解剖结构，如器官及其部分，但缺乏骨科骨盆地标所需的精细精度。为了解决这一限制，我们提出利用另一个通用非基础模型：YOLO。YOLO擅长目标检测，可以提供作为SAM输入提示的边界框。虽然YOLO在检测方面效率很高，但在分割复杂结构方面，SAM的表现显著优于YOLO。结合起来，这两个模型形成了一个可靠的管道，不仅能够分割一小组八个解剖地标的初步集合，还能分割由72个地标和16个具有复杂轮廓的区域组成的扩展集合，例如股骨皮质骨和骨盆入口。通过使用YOLO生成的边界框来指导SAM，我们训练了混合模型以准确分割骨科骨盆X射线图像。我们的结果表明，所提出的YOLO和SAM的组合在骨科骨盆X射线图像中检测解剖地标和复杂轮廓方面表现出色。", "summary": "本文提出了一种结合YOLO和SAM的混合模型，用于解决通用分割模型（如SAM和MedSAM）在医学图像（特别是骨科骨盆X射线）中进行精细解剖地标检测的局限性。YOLO负责生成地标的边界框作为SAM的输入提示，而SAM则执行精确的分割。实验结果表明，该联合方法能够可靠地分割大量解剖地标和复杂轮廓，并在骨科骨盆X射线图像中展现出卓越的检测性能。", "keywords": "医学图像, 地标检测, SAM, YOLO, 分割", "comments": "该论文解决了医学影像中精细解剖地标分割的实际且重要问题。其创新之处在于巧妙地结合了两个现有通用模型（YOLO用于检测/提示，SAM用于分割），以克服它们在特定领域中的各自局限性。这种混合方法避免了为高度特定的医学任务对基础模型进行大量重新训练的需求，提供了一种更高效、更有效的解决方案。对骨科骨盆X射线的关注突出了特定的临床需求。"}}
{"id": "2507.11978", "title": "NineToothed: A Triton-Based High-Level Domain-Specific Language for Machine Learning", "authors": ["Jiacheng Huang", "Zimin Li", "Yinghui Li", "Haojie Wang"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11978v1", "summary": "The emergence of deep learning domain-specific languages (DSLs) has\nsubstantially reduced the obstacles in developing high-performance,\ncross-platform compute kernels. However, current DSLs, such as Triton, still\ndemand that developers possess expertise in parallel programming and expose\nthem to many low-level details. This requirement complicates the development\nprocess and adds to the difficulty of maintaining compute kernels.\nConsequently, developing a new programming model that supports serial\nprogramming for deep learning workloads is crucial.\n  This paper introduces NineToothed, a domain-specific language that offers\nserial semantics for machine learning programming. Through the automatic\ntransformation of serial code into parallel code, NineToothed significantly\nstreamlines the development process while causing minimal performance\ndegradation. NineToothed encompasses (1) a language with tensor-oriented\nmetaprogramming (TOM) that adopts the arrange-and-apply paradigm, enabling the\nexpression of tiled computations without the need to manage low-level details\nand (2) a code generator for generating high-performance parallel code. Our\nevaluation results indicate that NineToothed can greatly simplify compute\nkernel development while maintaining performance comparable to that of Triton.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11978v1", "cate": "cs.DC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "NineToothed：一种基于 Triton 的机器学习高级领域特定语言", "tldr": "NineToothed 是一种新的机器学习领域特定语言 (DSL)，它允许开发者使用串行语义编写代码，并自动将其转换为高效的并行代码，从而简化了高性能计算核的开发，同时保持与 Triton 相当的性能。", "motivation": "当前的深度学习领域特定语言（如 Triton）要求开发者具备并行编程专业知识并处理底层细节，这使得计算核的开发和维护复杂且困难。因此，急需一种支持串行编程的新编程模型来处理深度学习工作负载。", "method": "本文引入了 NineToothed，一种为机器学习编程提供串行语义的领域特定语言。它通过将串行代码自动转换为并行代码来实现简化。NineToothed 包含：(1) 一种采用“排列-应用”范式并支持张量导向元编程 (TOM) 的语言，无需管理底层细节即可表达平铺计算；(2) 一个用于生成高性能并行代码的代码生成器。", "result": "评估结果表明，NineToothed 可以极大地简化计算核的开发，同时保持与 Triton 相当的性能。", "conclusion": "NineToothed 通过提供串行编程模型和自动代码转换，成功简化了高性能机器学习计算核的开发，且性能表现与现有领先工具相当。", "translation": "深度学习领域特定语言（DSLs）的出现大大降低了开发高性能、跨平台计算核的障碍。然而，当前的DSLs，如Triton，仍然要求开发者具备并行编程专业知识，并暴露许多底层细节。这一要求使得开发过程复杂化，并增加了维护计算核的难度。因此，开发一种支持深度学习工作负载串行编程的新编程模型至关重要。\n本文介绍了NineToothed，一种为机器学习编程提供串行语义的领域特定语言。通过将串行代码自动转换为并行代码，NineToothed显著简化了开发过程，同时仅造成最小的性能下降。NineToothed包含（1）一种采用“排列-应用”范式并支持张量导向元编程（TOM）的语言，无需管理底层细节即可表达平铺计算；以及（2）一个用于生成高性能并行代码的代码生成器。我们的评估结果表明，NineToothed可以极大地简化计算核的开发，同时保持与Triton相当的性能。", "summary": "NineToothed 是一种基于 Triton 的高级领域特定语言，旨在解决现有深度学习 DSLs 对并行编程专业知识的依赖。它通过提供串行编程语义，并自动将串行代码转换为高效并行代码，从而简化了机器学习计算核的开发。NineToothed 引入了张量导向元编程 (TOM) 和“排列-应用”范式，并包含一个代码生成器。实验结果表明，NineToothed 在简化开发的同时，性能与 Triton 相当。", "keywords": "领域特定语言, 机器学习, 串行编程, 并行化, Triton", "comments": "NineToothed 的创新之处在于其串行编程模型，这显著降低了开发高性能机器学习计算核的门槛。它通过自动化并行化过程，使得不具备深厚并行编程背景的开发者也能编写高效代码。该方法的“最小性能下降”和“与 Triton 相当的性能”表明其在实用性上的潜力，对于推动深度学习计算核的普及和开发效率具有重要意义。"}}
{"id": "2507.12042", "title": "Stereo Sound Event Localization and Detection with Onscreen/offscreen Classification", "authors": ["Kazuki Shimada", "Archontis Politis", "Iran R. Roman", "Parthasaarathy Sudarsanam", "David Diaz-Guerra", "Ruchi Pandey", "Kengo Uchida", "Yuichiro Koyama", "Naoya Takahashi", "Takashi Shibuya", "Shusuke Takahashi", "Tuomas Virtanen", "Yuki Mitsufuji"], "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS", "eess.IV"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      5 pages, 2 figures", "url": "http://arxiv.org/abs/2507.12042v1", "summary": "This paper presents the objective, dataset, baseline, and metrics of Task 3\nof the DCASE2025 Challenge on sound event localization and detection (SELD). In\nprevious editions, the challenge used four-channel audio formats of first-order\nAmbisonics (FOA) and microphone array. In contrast, this year's challenge\ninvestigates SELD with stereo audio data (termed stereo SELD). This change\nshifts the focus from more specialized 360{\\deg} audio and audiovisual scene\nanalysis to more commonplace audio and media scenarios with limited\nfield-of-view (FOV). Due to inherent angular ambiguities in stereo audio data,\nthe task focuses on direction-of-arrival (DOA) estimation in the azimuth plane\n(left-right axis) along with distance estimation. The challenge remains divided\ninto two tracks: audio-only and audiovisual, with the audiovisual track\nintroducing a new sub-task of onscreen/offscreen event classification\nnecessitated by the limited FOV. This challenge introduces the DCASE2025 Task3\nStereo SELD Dataset, whose stereo audio and perspective video clips are sampled\nand converted from the STARSS23 recordings. The baseline system is designed to\nprocess stereo audio and corresponding video frames as inputs. In addition to\nthe typical SELD event classification and localization, it integrates\nonscreen/offscreen classification for the audiovisual track. The evaluation\nmetrics have been modified to introduce an onscreen/offscreen accuracy metric,\nwhich assesses the models' ability to identify which sound sources are\nonscreen. In the experimental evaluation, the baseline system performs\nreasonably well with the stereo audio data.", "comment": "5 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.12042v1", "cate": "cs.SD", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "立体声事件定位与检测及其屏幕内/外分类", "tldr": "DCASE2025挑战赛任务3引入立体声事件定位与检测（SELD），重点关注常见媒体场景，并新增屏幕内/外分类任务和对应数据集与基线系统。", "motivation": "之前的DCASE挑战赛使用FOA和麦克风阵列的四通道音频，而本次挑战赛旨在将SELD研究从专业360度音频和视听场景分析转向更常见的、有限视场的音频和媒体场景，通过引入立体声数据和屏幕内/外分类来应对新的挑战。", "method": "论文介绍了DCASE2025挑战赛任务3（立体声SELD）的目标、数据集、基线和评估指标。该挑战使用立体声音频数据，并专注于方位角（左右轴）和距离估计。挑战分为纯音频和视听两轨，视听轨新增了屏幕内/外事件分类子任务。引入了DCASE2025 Task3立体声SELD数据集，其数据来源于STARSS23录音。基线系统设计用于处理立体声音频和视频帧输入，并为视听轨集成了屏幕内/外分类。评估指标也进行了修改，引入了屏幕内/外准确率。", "result": "实验评估显示，基线系统在处理立体声音频数据时表现“相当不错”（reasonably well）。", "conclusion": "Not mentioned in abstract", "translation": "本文介绍了DCASE2025挑战赛任务3（声音事件定位与检测，SELD）的目标、数据集、基线和评估指标。在之前的版本中，挑战赛使用一阶Ambisonics（FOA）和麦克风阵列的四通道音频格式。相比之下，今年的挑战赛研究了使用立体声音频数据的SELD（称为立体声SELD）。这一变化将研究重点从更专业的360度音频和视听场景分析转向了更常见的、有限视场的音频和媒体场景。由于立体声音频数据固有的角度模糊性，该任务侧重于方位角平面（左右轴）上的到达方向（DOA）估计以及距离估计。挑战赛仍分为两个赛道：纯音频赛道和视听赛道，其中视听赛道由于视场有限而引入了屏幕内/外事件分类这一新子任务。本次挑战赛引入了DCASE2025 Task3立体声SELD数据集，其立体声音频和透视视频片段均采样并转换自STARSS23录音。基线系统设计用于处理立体声音频和相应的视频帧作为输入。除了典型的SELD事件分类和定位外，它还为视听赛道集成了屏幕内/外分类。评估指标已进行修改，引入了屏幕内/外准确率指标，用于评估模型识别哪些声源在屏幕内的能力。在实验评估中，基线系统在立体声音频数据上表现相当不错。", "summary": "DCASE2025挑战赛任务3聚焦于立体声声音事件定位与检测（SELD），旨在将研究推向更常见的有限视场媒体场景。该任务引入了立体声音频数据，并特别关注方位角和距离估计。视听赛道新增了屏幕内/外分类子任务。为此，挑战赛发布了DCASE2025 Task3立体声SELD数据集，并提供了集成屏幕内/外分类的基线系统及相应的评估指标。初步实验表明，基线系统在立体声数据上表现良好。", "keywords": "立体声SELD, DCASE2025, 声音事件定位与检测, 屏幕内/外分类, 立体声音频", "comments": "本文描述了DCASE2025挑战赛任务3的设计，其创新点在于将SELD研究的重点从专业360度音频转向更普及的立体声和有限视场媒体场景。引入屏幕内/外分类是一个重要的实用性拓展，因为这更符合实际视听内容（如电影、视频）的制作和消费模式。该挑战赛及其新数据集和基线系统将推动立体声SELD领域的发展，并鼓励研究者解决实际应用中的新问题。"}}
{"id": "2507.11950", "title": "RNAMunin: A Deep Machine Learning Model for Non-coding RNA Discovery", "authors": ["Lauren Lui", "Torben Nielsen"], "categories": ["q-bio.GN", "cs.LG"], "primary_category": "Subjects:       Genomics (q-bio.GN)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11950v1", "summary": "Functional annotation of microbial genomes is often biased toward\nprotein-coding genes, leaving a vast, unexplored landscape of non-coding RNAs\n(ncRNAs) that are critical for regulating bacterial and archaeal physiology,\nstress response and metabolism. Identifying ncRNAs directly from genomic\nsequence is a paramount challenge in bioinformatics and biology, essential for\nunderstanding the complete regulatory potential of an organism. This paper\npresents RNAMunin, a machine learning (ML) model that is capable of finding\nncRNAs using genomic sequence alone. It is also computationally viable for\nlarge sequence datasets such as long read metagenomic assemblies with contigs\ntotaling multiple Gbp. RNAMunin is trained on Rfam sequences extracted from\napproximately 60 Gbp of long read metagenomes from 16 San Francisco Estuary\nsamples. We know of no other model that can detect ncRNAs based solely on\ngenomic sequence at this scale. Since RNAMunin only requires genomic sequence\nas input, we do not need for an ncRNA to be transcribed to find it, i.e., we do\nnot need transcriptomics data. We wrote this manuscript in a narrative style in\norder to best convey how RNAMunin was developed and how it works in detail.\nUnlike almost all current ML models, at approximately 1M parameters, RNAMunin\nis very small and very fast.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11950v1", "cate": "q-bio.GN", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "RNAMunin：一个用于非编码RNA发现的深度机器学习模型", "tldr": "RNAMunin是一个新的机器学习模型，能够仅通过基因组序列在大规模数据集中快速有效地发现非编码RNA，填补了微生物基因组注释中非编码RNA的空白。", "motivation": "微生物基因组的功能注释通常偏向蛋白质编码基因，导致大量非编码RNA（ncRNA）未被探索，而这些ncRNA对调节细菌和古菌生理、应激反应和新陈代谢至关重要。直接从基因组序列识别ncRNA是生物信息学和生物学中的一个重要挑战，对于理解生物体的完整调控潜力至关重要。", "method": "本文提出了RNAMunin，一个能够仅使用基因组序列发现ncRNA的机器学习模型。它在约60 Gbp的旧金山河口样本长读长宏基因组中提取的Rfam序列上进行训练。该模型仅需基因组序列作为输入，无需转录组数据，并且参数量约为1M，非常小巧和快速。", "result": "RNAMunin计算上适用于大型序列数据集，例如总计多Gbp的长读长宏基因组组装。据作者所知，目前没有其他模型能以这种规模仅基于基因组序列检测ncRNA。RNAMunin非常小巧和快速。", "conclusion": "RNAMunin提供了一种大规模、高效且仅依赖基因组序列的非编码RNA发现方法，填补了当前微生物基因组注释的空白，对于理解微生物的完整调控潜力至关重要。", "translation": "微生物基因组的功能注释通常偏向蛋白质编码基因，留下大量未探索的非编码RNA（ncRNA）领域，这些ncRNA对于调节细菌和古菌的生理、应激反应和新陈代谢至关重要。直接从基因组序列识别ncRNA是生物信息学和生物学中的一个首要挑战，对于理解生物体的完整调控潜力至关重要。本文提出了RNAMunin，一个能够仅使用基因组序列发现ncRNA的机器学习（ML）模型。它在计算上对于大型序列数据集（如总计多Gbp的长读长宏基因组组装）也是可行的。RNAMunin在从16个旧金山河口样本中约60 Gbp长读长宏基因组中提取的Rfam序列上进行训练。据我们所知，目前没有其他模型能够仅基于基因组序列以这种规模检测ncRNA。由于RNAMunin仅需要基因组序列作为输入，我们不需要ncRNA被转录才能找到它，即我们不需要转录组数据。我们以叙事风格撰写了这份手稿，以便最好地传达RNAMunin是如何开发以及如何详细工作的。与几乎所有当前的ML模型不同，RNAMunin的参数量约为1M，非常小巧和快速。", "summary": "RNAMunin是一个创新的深度机器学习模型，旨在解决微生物基因组中非编码RNA（ncRNA）注释不足的问题。该模型能够仅通过基因组序列识别ncRNA，无需转录组数据，使其在处理大规模宏基因组数据时具有计算可行性。RNAMunin在约60 Gbp的宏基因组数据上训练，并且以其小巧（约1M参数）和快速的特点区别于现有模型，填补了大规模、纯基因组序列ncRNA发现的空白。", "keywords": "非编码RNA, 机器学习, 基因组序列, 宏基因组, RNAMunin", "comments": "该论文提出了一种创新的非编码RNA发现方法RNAMunin，其核心创新在于仅依赖基因组序列进行预测，无需转录组数据，这大大降低了数据需求和实验成本。此外，模型的小巧和高速使其在处理大规模宏基因组数据时具有显著的实用性，解决了现有方法在可扩展性上的局限性。这对于全面理解微生物的基因组功能和调控网络具有重要意义。"}}
{"id": "2507.03833", "title": "MatRL: Provably Generalizable Iterative Algorithm Discovery via Monte-Carlo Tree Search", "authors": ["Sungyoon Kim", "Rajat Vadiraj Dwaraknath", "Longling geng", "Mert Pilanci"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03833v2", "summary": "Iterative methods for computing matrix functions have been extensively\nstudied and their convergence speed can be significantly improved with the\nright tuning of parameters and by mixing different iteration types. Handtuning\nthe design options for optimal performance can be cumbersome, especially in\nmodern computing environments: numerous different classical iterations and\ntheir variants exist, each with non-trivial per-step cost and tuning\nparameters. To this end, we propose MatRL -- a reinforcement learning based\nframework that automatically discovers iterative algorithms for computing\nmatrix functions. The key idea is to treat algorithm design as a sequential\ndecision-making process. Monte-Carlo tree search is then used to plan a hybrid\nsequence of matrix iterations and step sizes, tailored to a specific input\nmatrix distribution and computing environment. Moreover, we also show that the\nlearned algorithms provably generalize to sufficiently large matrices drawn\nfrom the same distribution. Finally, we corroborate our theoretical results\nwith numerical experiments demonstrating that MatRL produces algorithms that\noutperform various baselines in the literature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03833v2", "cate": "cs.LG", "date": "2025-07-04", "updated": "2025-07-16", "AI": {"title_translation": "MatRL：基于蒙特卡洛树搜索的可证明泛化迭代算法发现", "tldr": "MatRL利用强化学习和蒙特卡洛树搜索自动发现计算矩阵函数的迭代算法，解决了手动调优的难题，并且学习到的算法具有可证明的泛化能力，性能优于现有基线。", "motivation": "手动调整迭代算法以获得最佳性能非常繁琐，尤其是在现代计算环境中，因为存在大量不同且复杂的经典迭代方法及其变体。", "method": "本文提出了MatRL，一个基于强化学习的框架，将算法设计视为一个序列决策过程。该框架利用蒙特卡洛树搜索（MCTS）来规划混合的矩阵迭代序列和步长，以适应特定的输入矩阵分布和计算环境。", "result": "MatRL学习到的算法被证明可以泛化到来自相同分布的足够大的矩阵。数值实验表明，MatRL生成的算法在性能上优于文献中的各种基线方法。", "conclusion": "MatRL框架能够自动发现高性能且具有可证明泛化能力的迭代算法，有效解决了手动调优的难题，并在实验中表现出优越性。", "translation": "迭代计算矩阵函数的方法已被广泛研究，通过正确调整参数和混合不同迭代类型可以显著提高其收敛速度。然而，为了获得最佳性能而手动调整设计选项可能很麻烦，尤其是在现代计算环境中：存在大量不同的经典迭代方法及其变体，每种方法都具有不平凡的每步成本和调整参数。为此，我们提出了MatRL——一个基于强化学习的框架，可以自动发现用于计算矩阵函数的迭代算法。核心思想是将算法设计视为一个序列决策过程。然后使用蒙特卡洛树搜索来规划混合的矩阵迭代序列和步长，以适应特定的输入矩阵分布和计算环境。此外，我们还表明学习到的算法可以证明泛化到来自相同分布的足够大的矩阵。最后，我们通过数值实验证实了我们的理论结果，这些实验表明MatRL生成的算法优于文献中的各种基线方法。", "summary": "本文提出了MatRL，一个基于强化学习的框架，用于自动发现计算矩阵函数的迭代算法。该方法将算法设计视为序列决策过程，并利用蒙特卡洛树搜索来规划迭代序列和步长。研究表明，MatRL发现的算法具有可证明的泛化能力，并且在数值实验中表现优于现有基线。", "keywords": "强化学习, 矩阵函数, 迭代算法, 蒙特卡洛树搜索, 算法发现", "comments": "MatRL的创新之处在于将迭代算法设计问题转化为强化学习的序列决策问题，并引入蒙特卡洛树搜索进行规划，实现了算法的自动化发现。其重要性在于解决了传统手动调优的复杂性和局限性，并提供了可证明的泛化能力，这对于实际应用具有重要意义。"}}
{"id": "2507.11690", "title": "The Impact of Coreset Selection on Spurious Correlations and Group Robustness", "authors": ["Amaya Dharmasiri", "William Yang", "Polina Kirichenko", "Lydia Liu", "Olga Russakovsky"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 9 additional pages for Appendix", "url": "http://arxiv.org/abs/2507.11690v1", "summary": "Coreset selection methods have shown promise in reducing the training data\nsize while maintaining model performance for data-efficient machine learning.\nHowever, as many datasets suffer from biases that cause models to learn\nspurious correlations instead of causal features, it is important to understand\nwhether and how dataset reduction methods may perpetuate, amplify, or mitigate\nthese biases. In this work, we conduct the first comprehensive analysis of the\nimplications of data selection on the spurious bias levels of the selected\ncoresets and the robustness of downstream models trained on them. We use an\nextensive experimental setting spanning ten different spurious correlations\nbenchmarks, five score metrics to characterize sample importance/ difficulty,\nand five data selection policies across a broad range of coreset sizes.\nThereby, we unravel a series of nontrivial nuances in interactions between\nsample difficulty and bias alignment, as well as dataset bias and resultant\nmodel robustness. For example, we find that selecting coresets using\nembedding-based sample characterization scores runs a comparatively lower risk\nof inadvertently exacerbating bias than selecting using characterizations based\non learning dynamics. Most importantly, our analysis reveals that although some\ncoreset selection methods could achieve lower bias levels by prioritizing\ndifficult samples, they do not reliably guarantee downstream robustness.", "comment": "10 pages, 9 additional pages for Appendix", "pdf_url": "http://arxiv.org/pdf/2507.11690v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "核集选择对虚假相关性和群体鲁棒性的影响", "tldr": "本文首次全面分析了核集选择方法对数据集虚假相关性及其对下游模型鲁棒性的影响。研究发现，尽管一些方法可以降低偏差，但并不能可靠地保证模型的鲁棒性。", "motivation": "核心集选择方法在减少训练数据量的同时保持模型性能方面显示出潜力。然而，许多数据集存在偏差，导致模型学习虚假相关性而非因果特征。因此，理解数据缩减方法是否会延续、放大或减轻这些偏差至关重要。", "method": "进行了首次全面的分析，研究了数据选择对所选核心集的虚假偏差水平以及在其上训练的下游模型鲁棒性的影响。实验设置广泛，涵盖了十个不同的虚假相关性基准、五个表征样本重要性/难度的分数指标以及五种数据选择策略，涉及广泛的核心集大小。", "result": "揭示了样本难度与偏差对齐之间以及数据集偏差与结果模型鲁棒性之间的一系列非平凡的细微差别。例如，发现使用基于嵌入的样本特征分数选择核心集比使用基于学习动态的特征选择，无意中加剧偏差的风险更低。", "conclusion": "尽管一些核心集选择方法可以通过优先选择困难样本来达到较低的偏差水平，但它们不能可靠地保证下游模型的鲁棒性。", "translation": "核心集选择方法在减少训练数据量方面显示出潜力，同时在数据高效的机器学习中保持模型性能。然而，由于许多数据集存在导致模型学习虚假相关性而非因果特征的偏差，因此理解数据集缩减方法是否会延续、放大或减轻这些偏差至关重要。在这项工作中，我们首次对数据选择对所选核心集的虚假偏差水平以及在其上训练的下游模型的鲁棒性的影响进行了全面分析。我们使用了广泛的实验设置，涵盖了十个不同的虚假相关性基准、五个表征样本重要性/难度的分数指标以及五种数据选择策略，涵盖了广泛的核心集大小。通过这项工作，我们揭示了样本难度与偏差对齐之间以及数据集偏差与结果模型鲁棒性之间的一系列非平凡的细微差别。例如，我们发现使用基于嵌入的样本特征分数选择核心集比使用基于学习动态的特征选择，无意中加剧偏差的风险更低。最重要的是，我们的分析表明，尽管一些核心集选择方法可以通过优先选择困难样本来达到较低的偏差水平，但它们不能可靠地保证下游模型的鲁棒性。", "summary": "这项研究首次全面分析了核心集选择对数据集中虚假相关性水平以及下游模型鲁棒性的影响。研究发现，虽然核心集选择有助于数据高效学习，但它也可能在无意中加剧偏差。通过在多个基准上进行广泛实验，研究揭示了样本难度、偏差对齐和模型鲁棒性之间的复杂关系，并指出某些选择策略（如基于嵌入的）风险较低，但即使能降低偏差，也不能保证下游模型的鲁棒性。", "keywords": "核集选择, 虚假相关性, 群体鲁棒性, 数据偏差, 样本难度", "comments": "这项工作首次系统地探讨了数据选择方法（特别是核心集选择）与模型虚假相关性及鲁棒性之间的复杂关系，填补了现有研究的空白。其创新之处在于通过广泛的实验设置揭示了样本难度、偏差和鲁棒性之间的非平凡相互作用，为数据高效机器学习中的偏见问题提供了重要见解。研究结果对于指导实践中核心集选择策略的制定具有重要意义，尤其提醒人们在追求数据效率的同时，不能忽视潜在的偏差放大风险及其对模型泛化能力的负面影响。"}}
{"id": "2507.11546", "title": "AI Governance InternationaL Evaluation Index (AGILE Index) 2025", "authors": ["Yi Zeng", "Enmeng Lu", "Xiaoyang Guo", "Cunqing Huangfu", "Jiawei Xie", "Yu Chen", "Zhengqi Wang", "Dongqi Liang", "Gongce Cao", "Jin Wang", "Zizhe Ruan", "Xin Guan", "Ammar Younas"], "categories": ["cs.CY", "68T01", "A.1"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      81 pages, 29 figures, 7 tables", "url": "http://arxiv.org/abs/2507.11546v1", "summary": "The year 2024 witnessed accelerated global AI governance advancements, marked\nby strengthened multilateral frameworks and proliferating national regulatory\ninitiatives. This acceleration underscores an unprecedented need to\nsystematically track governance progress--an imperative that drove the launch\nof the AI Governance InternationaL Evaluation Index (AGILE Index) project since\n2023. The inaugural AGILE Index, released in February 2024 after assessing 14\ncountries, established an operational and comparable baseline framework.\nBuilding on pilot insights, AGILE Index 2025 incorporates systematic\nrefinements to better balance scientific rigor with practical adaptability. The\nupdated methodology expands data diversity while enhancing metric validity and\ncross-national comparability. Reflecting both research advancements and\npractical policy evolution, AGILE Index 2025 evaluates 40 countries across\nincome levels, regions, and technological development stages, with 4 Pillars,\n17 Dimensions and 43 Indicators. In compiling the data, the team integrates\nmulti-source evidence including policy documents, governance practices,\nresearch outputs, and risk exposure to construct a unified comparison\nframework. This approach maps global disparities while enabling countries to\nidentify governance strengths, gaps, and systemic constraints. Through ongoing\nrefinement and iterations, we hope the AGILE Index will fundamentally advance\ntransparency and measurability in global AI governance, delivering data-driven\nassessments that depict national AI governance capacity, assist governments in\nrecognizing their maturation stages and critical governance issues, and\nultimately provide actionable insights for enhancing AI governance systems\nnationally and globally.", "comment": "81 pages, 29 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.11546v1", "cate": "cs.CY", "date": "2025-07-10", "updated": "2025-07-10", "AI": {"title_translation": "AI治理国际评估指数（AGILE指数）2025", "tldr": "AGILE指数2025是一个更新的框架，旨在系统地追踪和评估40个国家的人工智能治理进展，旨在提高透明度并提供可操作的见解。", "motivation": "2024年全球AI治理的加速发展，以及多边框架的加强和国家监管举措的增多，凸显了系统性追踪治理进展的空前需求，这推动了AGILE指数项目的启动。", "method": "AGILE指数2025纳入了系统性改进，扩大了数据多样性，同时增强了指标的有效性和跨国可比性。它通过4个支柱、17个维度和43个指标评估了40个不同收入水平、地区和技术发展阶段的国家。数据汇编整合了政策文件、治理实践、研究成果和风险暴露等多源证据，以构建统一的比较框架。", "result": "AGILE指数描绘了全球差异，使各国能够识别治理优势、差距和系统性限制，描绘了国家AI治理能力，并协助政府识别其成熟阶段和关键治理问题。", "conclusion": "通过持续的完善和迭代，AGILE指数有望从根本上推动全球AI治理的透明度和可衡量性，提供数据驱动的评估，描绘国家AI治理能力，协助政府识别其成熟阶段和关键治理问题，并最终为国家和全球范围内的AI治理系统改进提供可操作的见解。", "translation": "2024年见证了全球AI治理的加速发展，其特点是多边框架的加强和国家监管举措的增多。这种加速凸显了系统性追踪治理进展的空前需求——这一迫切性推动了自2023年以来AI治理国际评估指数（AGILE指数）项目的启动。首个AGILE指数于2024年2月发布，评估了14个国家，建立了一个可操作和可比较的基线框架。基于试点经验，AGILE指数2025纳入了系统性改进，以更好地平衡科学严谨性与实践适应性。更新后的方法论在扩大数据多样性的同时，增强了指标的有效性和跨国可比性。AGILE指数2025反映了研究进展和实际政策演变，评估了40个不同收入水平、地区和技术发展阶段的国家，涵盖4个支柱、17个维度和43个指标。在数据汇编过程中，团队整合了政策文件、治理实践、研究成果和风险暴露等多源证据，以构建统一的比较框架。这种方法描绘了全球差异，同时使各国能够识别治理优势、差距和系统性限制。通过持续的完善和迭代，我们希望AGILE指数将从根本上推动全球AI治理的透明度和可衡量性，提供数据驱动的评估，描绘国家AI治理能力，协助政府识别其成熟阶段和关键治理问题，并最终为国家和全球范围内的AI治理系统改进提供可操作的见解。", "summary": "AGILE指数2025是一个更新的评估框架，旨在系统地追踪和评估40个国家的全球AI治理进展。它在2024年基线的基础上，通过扩大数据多样性和增强可比性来完善其方法论，采用4个支柱、17个维度和43个指标。通过整合多源证据，该指数旨在描绘全球差异，识别治理优势和差距，并提供数据驱动的见解，以改进国家和全球的AI治理系统。", "keywords": "AI治理, AGILE指数, 全球评估, 政策评估, 监管框架", "comments": "AGILE指数对于提供一种标准化、数据驱动的AI治理评估方法至关重要，鉴于AI技术的快速发展和多样的监管环境，这一点尤为关键。其创新之处在于其全面的多源数据整合以及促进透明度和可比性的雄心。一个潜在的局限性可能是定义和衡量“治理”固有的复杂性，以及确保指标随着AI技术的发展保持相关性。"}}
{"id": "2507.12045", "title": "Self-Boosted Weight-Constrained FxLMS: A Robustness Distributed Active Noise Control Algorithm Without Internode Communication", "authors": ["Junwei Ji", "Dongyuan Shi", "Zhengding Luo", "Boxiang Wang", "Woon-Seng Gan"], "categories": ["eess.AS", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12045v1", "summary": "Compared to the conventional centralized multichannel active noise control\n(MCANC) algorithm, which requires substantial computational resources,\ndecentralized approaches exhibit higher computational efficiency but typically\nresult in inferior noise reduction performance. To enhance performance,\ndistributed ANC methods have been introduced, enabling information exchange\namong ANC nodes; however, the resulting communication latency often compromises\nsystem stability. To overcome these limitations, we propose a self-boosted\nweight-constrained filtered-reference least mean square (SB-WCFxLMS) algorithm\nfor the distributed MCANC system without internode communication. The WCFxLMS\nalgorithm is specifically designed to mitigate divergence issues caused by the\ninternode cross-talk effect. The self-boosted strategy lets each ANC node\nindependently adapt its constraint parameters based on its local noise\nreduction performance, thus ensuring effective noise cancellation without the\nneed for inter-node communication. With the assistance of this mechanism, this\napproach significantly reduces both computational complexity and communication\noverhead. Numerical simulations employing real acoustic paths and compressor\nnoise validate the effectiveness and robustness of the proposed system. The\nresults demonstrate that our proposed method achieves satisfactory noise\ncancellation performance with minimal resource requirements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12045v1", "cate": "eess.AS", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "自增强权重约束FxLMS：一种无需节点间通信的鲁棒分布式主动噪声控制算法", "tldr": "提出了一种无需节点间通信的自增强权重约束FxLMS算法，用于分布式主动噪声控制，解决了传统方法的计算和通信问题，并提高了降噪性能。", "motivation": "与需要大量计算资源的传统集中式多通道主动噪声控制（MCANC）算法相比，去中心化方法表现出更高的计算效率但通常导致较差的降噪性能；分布式ANC方法虽能信息交换，但通信延迟会损害系统稳定性。", "method": "提出了一种自增强权重约束滤波参考最小均方（SB-WCFxLMS）算法，用于无需节点间通信的分布式MCANC系统。WCFxLMS算法旨在减轻节点间串扰引起的发散问题。自增强策略使每个ANC节点根据其本地降噪性能独立调整约束参数，无需节点间通信。", "result": "数值模拟采用真实声学路径和压缩机噪声，验证了所提出系统的有效性和鲁棒性。结果表明该方法在最小资源需求下实现了满意的噪声消除性能。", "conclusion": "所提出的SB-WCFxLMS算法在无需节点间通信的情况下，显著降低了计算复杂度和通信开销，并实现了有效的噪声消除性能和鲁棒性。", "translation": "与需要大量计算资源的传统集中式多通道主动噪声控制（MCANC）算法相比，去中心化方法表现出更高的计算效率，但通常导致较差的降噪性能。为了提高性能，引入了分布式ANC方法，实现了ANC节点之间的信息交换；然而，由此产生的通信延迟通常会损害系统稳定性。为了克服这些限制，我们提出了一种用于无需节点间通信的分布式MCANC系统的自增强权重约束滤波参考最小均方（SB-WCFxLMS）算法。WCFxLMS算法专门设计用于减轻由节点间串扰效应引起的发散问题。自增强策略使每个ANC节点能够根据其本地降噪性能独立调整其约束参数，从而确保有效的噪声消除，而无需节点间通信。借助这种机制，该方法显著降低了计算复杂度和通信开销。采用真实声学路径和压缩机噪声的数值模拟验证了所提出系统的有效性和鲁棒性。结果表明，我们提出的方法在最小资源需求下实现了令人满意的噪声消除性能。", "summary": "本文提出了一种名为自增强权重约束FxLMS（SB-WCFxLMS）的分布式主动噪声控制算法，旨在解决传统集中式和去中心化ANC方法的计算效率、降噪性能和通信延迟问题。该算法无需节点间通信，通过WCFxLMS解决节点间串扰，并通过自增强策略使节点独立调整参数，从而在降低计算复杂度和通信开销的同时，实现高效且鲁棒的噪声消除。", "keywords": "分布式主动噪声控制, FxLMS, 权重约束, 自增强, 无节点通信", "comments": "该论文提出了一种创新的分布式主动噪声控制算法，通过结合权重约束和自增强策略，在无需节点间通信的情况下有效提升了系统的鲁棒性和降噪性能，显著降低了资源需求，为实际应用提供了有前景的解决方案。"}}
{"id": "2507.12449", "title": "Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios", "authors": ["Van-Hoang-Anh Phan", "Chi-Tam Nguyen", "Doan-Trung Au", "Thanh-Danh Phan", "Minh-Thien Duong", "My-Ha Le"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7 pages, 6 figures, 4 tables, HSI 2025", "url": "http://arxiv.org/abs/2507.12449v1", "summary": "Obstacle avoidance is essential for ensuring the safety of autonomous\nvehicles. Accurate perception and motion planning are crucial to enabling\nvehicles to navigate complex environments while avoiding collisions. In this\npaper, we propose an efficient obstacle avoidance pipeline that leverages a\ncamera-only perception module and a Frenet-Pure Pursuit-based planning\nstrategy. By integrating advancements in computer vision, the system utilizes\nYOLOv11 for object detection and state-of-the-art monocular depth estimation\nmodels, such as Depth Anything V2, to estimate object distances. A comparative\nanalysis of these models provides valuable insights into their accuracy,\nefficiency, and robustness in real-world conditions. The system is evaluated in\ndiverse scenarios on a university campus, demonstrating its effectiveness in\nhandling various obstacles and enhancing autonomous navigation. The video\npresenting the results of the obstacle avoidance experiments is available at:\nhttps://www.youtube.com/watch?v=FoXiO5S_tA8", "comment": "7 pages, 6 figures, 4 tables, HSI 2025", "pdf_url": "http://arxiv.org/pdf/2507.12449v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "自动驾驶汽车在避障场景中的视觉感知", "tldr": "该论文提出了一种基于纯摄像头的感知模块和Frenet-Pure Pursuit规划策略的自动驾驶汽车高效避障方案，利用YOLOv11进行物体检测，Depth Anything V2进行单目深度估计，并在大学校园环境中验证了其有效性。", "motivation": "确保自动驾驶汽车安全，避障至关重要。准确的感知和运动规划对于车辆在复杂环境中导航并避免碰撞至关重要。", "method": "本文提出了一种高效的避障流程，该流程利用纯摄像头感知模块和基于Frenet-Pure Pursuit的规划策略。系统集成计算机视觉进展，使用YOLOv11进行物体检测，并利用Depth Anything V2等最先进的单目深度估计算法来估计物体距离。对这些模型进行了比较分析，以评估其在实际条件下的准确性、效率和鲁棒性。", "result": "该系统在大学校园的各种场景中进行了评估，证明了其在处理各种障碍物和增强自主导航方面的有效性。对YOLOv11和Depth Anything V2等模型的比较分析提供了关于其准确性、效率和鲁棒性的宝贵见解。", "conclusion": "该论文提出的基于视觉感知的避障系统，结合YOLOv11和Depth Anything V2进行感知以及Frenet-Pure Pursuit规划，在实际场景中有效提升了自动驾驶汽车的避障能力和导航安全性。", "translation": "避障对于确保自动驾驶汽车的安全至关重要。精确的感知和运动规划对于使车辆在复杂环境中导航同时避免碰撞至关重要。在本文中，我们提出了一种高效的避障流程，该流程利用纯摄像头感知模块和基于Frenet-Pure Pursuit的规划策略。通过整合计算机视觉的最新进展，该系统利用YOLOv11进行物体检测，并利用Depth Anything V2等最先进的单目深度估计算法来估计物体距离。对这些模型进行的比较分析为它们在实际条件下的准确性、效率和鲁棒性提供了宝贵的见解。该系统在大学校园的各种场景中进行了评估，证明了其在处理各种障碍物和增强自主导航方面的有效性。展示避障实验结果的视频可在以下链接获取：https://www.youtube.com/watch?v=FoXiO5S_tA8", "summary": "本文提出了一种用于自动驾驶汽车的高效避障系统，该系统完全依赖于视觉感知。它结合了YOLOv11进行物体检测和Depth Anything V2进行单目深度估计，并采用Frenet-Pure Pursuit作为规划策略。通过在大学校园的真实场景中进行评估，该系统展示了其在有效识别和规避各种障碍物方面的能力，从而提高了自动导航的安全性。", "keywords": "自动驾驶, 避障, 视觉感知, YOLOv11, 单目深度估计", "comments": "该论文的创新点在于提出了一个纯视觉驱动的避障系统，有效地整合了最先进的物体检测（YOLOv11）和单目深度估计（Depth Anything V2）技术。其重要性在于为自动驾驶车辆提供了一种成本效益高且实用的避障解决方案，避免了对昂贵传感器（如激光雷达）的依赖。通过在真实校园环境中的评估，增加了其结果的可信度。"}}
{"id": "2506.21444", "title": "Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation", "authors": ["Sweta Banerjee", "Viktoria Weiss", "Taryn A. Donovan", "Rutger H. J. Fick", "Thomas Conrad", "Jonas Ammeling", "Nils Porsche", "Robert Klopfleisch", "Christopher Kaltenecker", "Katharina Breininger", "Marc Aubreville", "Christof A. Bertram"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.21444v2", "summary": "Atypical mitosis marks a deviation in the cell division process that has been\nshown be an independent prognostic marker for tumor malignancy. However,\natypical mitosis classification remains challenging due to low prevalence, at\ntimes subtle morphological differences from normal mitotic figures, low\ninter-rater agreement among pathologists, and class imbalance in datasets.\nBuilding on the Atypical Mitosis dataset for Breast Cancer (AMi-Br), this study\npresents a comprehensive benchmark comparing deep learning approaches for\nautomated atypical mitotic figure (AMF) classification, including end-to-end\ntrained deep learning models, foundation models with linear probing, and\nfoundation models fine-tuned with low-rank adaptation (LoRA). For rigorous\nevaluation, we further introduce two new held-out AMF datasets - AtNorM-Br, a\ndataset of mitotic figures from the TCGA breast cancer cohort, and AtNorM-MD, a\nmulti-domain dataset of mitotic figures from a subset of the MIDOG++ training\nset. We found average balanced accuracy values of up to 0.8135, 0.7788, and\n0.7723 on the in-domain AMi-Br and the out-of-domain AtNorm-Br and AtNorM-MD\ndatasets, respectively. Our work shows that atypical mitotic figure\nclassification, while being a challenging problem, can be effectively addressed\nthrough the use of recent advances in transfer learning and model fine-tuning\ntechniques. We make all code and data used in this paper available in this\ngithub repository: https://github.com/DeepMicroscopy/AMi-Br_Benchmark.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.21444v2", "cate": "cs.CV", "date": "2025-06-26", "updated": "2025-07-16", "AI": {"title_translation": "深度学习和视觉基础模型在非典型与正常有丝分裂分类中的基准测试及跨数据集评估", "tldr": "本研究对深度学习和视觉基础模型在非典型有丝分裂分类任务上进行了全面基准测试，并引入了两个新的跨领域数据集，证明了迁移学习和模型微调技术能有效解决该挑战性问题。", "motivation": "非典型有丝分裂是肿瘤恶性程度的独立预后标志物，但其分类面临低患病率、形态差异细微、病理学家间判读一致性低以及数据集类别不平衡等挑战，因此需要更有效的方法进行自动化分类。", "method": "本研究基于AMi-Br数据集，对端到端训练的深度学习模型、线性探测的基础模型以及使用LoRA微调的基础模型进行了非典型有丝分裂分类的全面基准测试。此外，引入了两个新的非典型有丝分裂数据集（AtNorM-Br和AtNorM-MD）进行严格的跨数据集评估。", "result": "在域内AMi-Br数据集上，平均平衡准确率最高达0.8135；在域外AtNorm-Br和AtNorM-MD数据集上，平均平衡准确率分别为0.7788和0.7723。", "conclusion": "非典型有丝分裂分类虽然是一个具有挑战性的问题，但通过利用迁移学习和模型微调技术的最新进展，可以有效地解决。", "translation": "非典型有丝分裂标志着细胞分裂过程的偏差，已被证明是肿瘤恶性程度的独立预后标志物。然而，非典型有丝分裂分类仍然具有挑战性，原因在于其患病率低、与正常有丝分裂图像的形态差异有时很细微、病理学家之间判读一致性低以及数据集中存在类别不平衡。本研究基于乳腺癌非典型有丝分裂数据集（AMi-Br），对自动化非典型有丝分裂图像（AMF）分类的深度学习方法进行了全面基准测试，包括端到端训练的深度学习模型、线性探测的基础模型以及使用低秩适应（LoRA）微调的基础模型。为了进行严格评估，我们进一步引入了两个新的预留AMF数据集——AtNorM-Br（来自TCGA乳腺癌队列的有丝分裂图像数据集）和AtNorM-MD（来自MIDOG++训练集子集的多领域有丝分裂图像数据集）。我们发现在域内AMi-Br数据集上的平均平衡准确率最高达0.8135，在域外AtNorM-Br和AtNorM-MD数据集上分别为0.7788和0.7723。我们的工作表明，非典型有丝分裂图像分类虽然是一个具有挑战性的问题，但可以通过利用迁移学习和模型微调技术的最新进展来有效解决。本论文中使用的所有代码和数据均已在此GitHub存储库中公开：https://github.com/DeepMicroscopy/AMi-Br_Benchmark。", "summary": "本研究全面评估了深度学习和视觉基础模型在非典型与正常有丝分裂分类任务上的性能。为解决该任务的挑战性（如低患病率、形态差异小、判读一致性低及类别不平衡），研究者比较了端到端模型、线性探测基础模型及LoRA微调基础模型。为进行严格的跨数据集评估，引入了两个新的数据集AtNorM-Br和AtNorM-MD。结果显示，在域内和域外数据集上均取得了较好的平衡准确率，证明了迁移学习和模型微调技术在解决此挑战性问题上的有效性。", "keywords": "非典型有丝分裂, 深度学习, 视觉基础模型, 迁移学习, 基准测试", "comments": "该论文的创新点在于首次对深度学习和视觉基础模型在非典型有丝分裂分类上进行了全面的基准测试，并引入了新的跨领域数据集，增强了评估的严谨性。其重要性体现在为临床诊断中自动化非典型有丝分裂识别提供了新的技术路径和性能参考，有助于克服传统方法面临的挑战。通过开源代码和数据，也为后续研究提供了宝贵资源。"}}
{"id": "2507.11999", "title": "Envisage: Towards Expressive Visual Graph Querying", "authors": ["Xiaolin Wen", "Qishuang Fu", "Shuangyue Han", "Yichen Guo", "Joseph K. Liu", "Yong Wang"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11999v1", "summary": "Graph querying is the process of retrieving information from graph data using\nspecialized languages (e.g., Cypher), often requiring programming expertise.\nVisual Graph Querying (VGQ) streamlines this process by enabling users to\nconstruct and execute queries via an interactive interface without resorting to\ncomplex coding. However, current VGQ tools only allow users to construct simple\nand specific query graphs, limiting users' ability to interactively express\ntheir query intent, especially for underspecified query intent. To address\nthese limitations, we propose Envisage, an interactive visual graph querying\nsystem to enhance the expressiveness of VGQ in complex query scenarios by\nsupporting intuitive graph structure construction and flexible parameterized\nrule specification. Specifically, Envisage comprises four stages: Query\nExpression allows users to interactively construct graph queries through\nintuitive operations; Query Verification enables the validation of constructed\nqueries via rule verification and query instantiation; Progressive Query\nExecution can progressively execute queries to ensure meaningful querying\nresults; and Result Analysis facilitates result exploration and interpretation.\nTo evaluate Envisage, we conducted two case studies and in-depth user\ninterviews with 14 graph analysts. The results demonstrate its effectiveness\nand usability in constructing, verifying, and executing complex graph queries.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11999v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Envisage：迈向富有表现力的可视化图查询", "tldr": "Envisage是一个交互式可视化图查询系统，旨在通过支持直观的图结构构建和灵活的参数化规则规范来增强复杂查询场景中的可视化图查询表达能力。", "motivation": "当前的VGQ工具仅允许用户构建简单和特定的查询图，限制了用户交互式表达其查询意图的能力，特别是对于未充分指定的查询意图。", "method": "本文提出了Envisage，一个交互式可视化图查询系统，通过支持直观的图结构构建和灵活的参数化规则规范，增强复杂查询场景中VGQ的表达能力。Envisage包含四个阶段：查询表达、查询验证、渐进式查询执行和结果分析。", "result": "通过两个案例研究和对14位图分析师的深入用户访谈，结果表明Envisage在构建、验证和执行复杂图查询方面具有有效性和可用性。", "conclusion": "Envisage成功地解决了现有可视化图查询工具的局限性，为复杂场景下的富有表现力的可视化图查询提供了一个有效且可用的解决方案。", "translation": "图查询是使用专门语言（例如Cypher）从图数据中检索信息的过程，通常需要编程专业知识。可视化图查询（VGQ）通过允许用户通过交互式界面构建和执行查询而无需复杂的编码来简化此过程。然而，当前的VGQ工具只允许用户构建简单和特定的查询图，限制了用户交互式表达其查询意图的能力，特别是对于未充分指定的查询意图。为了解决这些限制，我们提出了Envisage，一个交互式可视化图查询系统，通过支持直观的图结构构建和灵活的参数化规则规范，增强复杂查询场景中VGQ的表达能力。具体来说，Envisage包括四个阶段：查询表达允许用户通过直观的操作交互式构建图查询；查询验证通过规则验证和查询实例化实现对已构建查询的验证；渐进式查询执行可以渐进地执行查询以确保有意义的查询结果；结果分析有助于结果探索和解释。为了评估Envisage，我们进行了两个案例研究和对14位图分析师的深入用户访谈。结果表明其在构建、验证和执行复杂图查询方面的有效性和可用性。", "summary": "Envisage是一个创新的交互式可视化图查询系统，旨在克服现有工具在表达复杂或未充分指定的查询意图方面的局限性。它通过直观的图结构构建和灵活的参数化规则规范，支持用户在复杂场景中更有效地进行图查询。系统包含查询表达、验证、渐进式执行和结果分析四个阶段。通过案例研究和用户访谈，Envisage被证明在构建、验证和执行复杂图查询方面具有有效性和可用性。", "keywords": "可视化图查询, 图数据, 交互式系统, 查询表达, Envisage", "comments": "本文介绍了Envisage，这是迈向更具表现力的可视化图查询的重要一步。其创新之处在于通过直观的交互和灵活的规则规范，解决了现有VGQ工具的局限性，实现了复杂的查询表达。四阶段设计提供了全面的工作流程，以用户为中心的评估突出了其实用可用性，这对于图分析师的采用至关重要。"}}
{"id": "2502.03132", "title": "SPARK: A Modular Benchmark for Humanoid Robot Safety", "authors": ["Yifan Sun", "Rui Chen", "Kai S. Yun", "Yikuan Fang", "Sebin Jung", "Feihan Li", "Bowei Li", "Weiye Zhao", "Changliu Liu"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Presented at IFAC Symposium on Robotics", "url": "http://arxiv.org/abs/2502.03132v2", "summary": "This paper introduces the Safe Protective and Assistive Robot Kit (SPARK), a\ncomprehensive benchmark designed to ensure safety in humanoid autonomy and\nteleoperation. Humanoid robots pose significant safety risks due to their\nphysical capabilities of interacting with complex environments. The physical\nstructures of humanoid robots further add complexity to the design of general\nsafety solutions. To facilitate safe deployment of complex robot systems, SPARK\ncan be used as a toolbox that comes with state-of-the-art safe control\nalgorithms in a modular and composable robot control framework. Users can\neasily configure safety criteria and sensitivity levels to optimize the balance\nbetween safety and performance. To accelerate humanoid safety research and\ndevelopment, SPARK provides simulation benchmarks that compare safety\napproaches in a variety of environments, tasks, and robot models. Furthermore,\nSPARK allows quick deployment of synthesized safe controllers on real robots.\nFor hardware deployment, SPARK supports Apple Vision Pro (AVP) or a Motion\nCapture System as external sensors, while offering interfaces for seamless\nintegration with alternative hardware setups at the same time. This paper\ndemonstrates SPARK's capability with both simulation experiments and case\nstudies with a Unitree G1 humanoid robot. Leveraging these advantages of SPARK,\nusers and researchers can significantly improve the safety of their humanoid\nsystems as well as accelerate relevant research. The open source code is\navailable at: https://github.com/intelligent-control-lab/spark.", "comment": "Presented at IFAC Symposium on Robotics", "pdf_url": "http://arxiv.org/pdf/2502.03132v2", "cate": "cs.RO", "date": "2025-02-05", "updated": "2025-07-16", "AI": {"title_translation": "SPARK：一个模块化的人形机器人安全基准", "tldr": "SPARK是一个为人形机器人安全设计的模块化基准工具包，它提供先进的安全控制算法、灵活的配置选项、仿真基准和真实机器人部署能力，以加速人形机器人安全研究和部署。", "motivation": "人形机器人由于其与复杂环境交互的物理能力，存在显著的安全风险，且其物理结构增加了通用安全解决方案设计的复杂性。为了促进复杂机器人系统的安全部署，本研究旨在引入一个综合性基准来解决这些安全挑战。", "method": "本文介绍了SPARK（安全防护辅助机器人套件），一个综合性基准，作为工具包提供先进的安全控制算法，采用模块化和可组合的机器人控制框架。SPARK允许用户配置安全标准和灵敏度级别，提供仿真基准来比较各种环境、任务和机器人模型中的安全方法，并支持将合成的安全控制器快速部署到真实机器人上，兼容Apple Vision Pro或运动捕捉系统作为外部传感器。", "result": "本文通过仿真实验和Unitree G1人形机器人案例研究，展示了SPARK的能力。利用SPARK的优势，用户和研究人员可以显著提高其人形系统的安全性，并加速相关研究。", "conclusion": "SPARK作为一个全面的基准和工具包，通过提供模块化的安全控制框架、灵活的配置选项、仿真和真实机器人部署能力，有效提升了人形机器人的安全性，并加速了相关研究与开发。", "translation": "本文介绍了一个名为SPARK（安全防护辅助机器人套件）的综合基准，旨在确保人形机器人自主和遥操作的安全性。人形机器人由于其与复杂环境交互的物理能力，会带来显著的安全风险。人形机器人的物理结构进一步增加了通用安全解决方案设计的复杂性。为了促进复杂机器人系统的安全部署，SPARK可作为一个工具箱，其中包含模块化和可组合机器人控制框架中的最先进安全控制算法。用户可以轻松配置安全标准和灵敏度级别，以优化安全性和性能之间的平衡。为了加速人形机器人安全研究和开发，SPARK提供了仿真基准，用于比较各种环境、任务和机器人模型中的安全方法。此外，SPARK允许将合成的安全控制器快速部署到真实机器人上。对于硬件部署，SPARK支持Apple Vision Pro（AVP）或运动捕捉系统作为外部传感器，同时提供与替代硬件设置无缝集成的接口。本文通过仿真实验和Unitree G1人形机器人案例研究，展示了SPARK的能力。利用SPARK的这些优势，用户和研究人员可以显著提高其人形系统的安全性，并加速相关研究。开源代码可在以下网址获取：https://github.com/intelligent-control-lab/spark。", "summary": "本文提出了SPARK，一个模块化且全面的基准工具包，旨在解决人形机器人在自主和遥操作中的安全挑战。SPARK提供先进的安全控制算法、灵活的配置选项、仿真基准和真实机器人部署能力，以优化安全与性能的平衡，并加速人形机器人安全研究与开发。通过仿真和实际机器人案例研究，SPARK展示了其在提升人形系统安全性方面的有效性。", "keywords": "人形机器人安全, 模块化基准, 安全控制, 仿真, 真实机器人部署", "comments": "SPARK的创新之处在于其为人形机器人安全提供了一个模块化、可配置且可部署的综合性基准和工具包。它不仅集成了最先进的安全控制算法，还提供了仿真和真实机器人部署能力，极大地降低了人形机器人安全研究的门槛，并加速了实际应用。其对Apple Vision Pro等外部传感器的支持也体现了前瞻性。该工作的局限性可能在于其对特定硬件的依赖性以及在更复杂、不可预测的真实世界场景中验证其通用性和鲁棒性所需的进一步工作。"}}
{"id": "2507.12188", "title": "Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement", "authors": ["Shuangli Du", "Siming Yan", "Zhenghao Shi", "Zhenzhen You", "Lu Sun"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12188v1", "summary": "Low-light images suffer from complex degradation, and existing enhancement\nmethods often encode all degradation factors within a single latent space. This\nleads to highly entangled features and strong black-box characteristics, making\nthe model prone to shortcut learning. To mitigate the above issues, this paper\nproposes a wavelet-based low-light stereo image enhancement method with feature\nspace decoupling. Our insight comes from the following findings: (1) Wavelet\ntransform enables the independent processing of low-frequency and\nhigh-frequency information. (2) Illumination adjustment can be achieved by\nadjusting the low-frequency component of a low-light image, extracted through\nmulti-level wavelet decomposition. Thus, by using wavelet transform the feature\nspace is decomposed into a low-frequency branch for illumination adjustment and\nmultiple high-frequency branches for texture enhancement. Additionally, stereo\nlow-light image enhancement can extract useful cues from another view to\nimprove enhancement. To this end, we propose a novel high-frequency guided\ncross-view interaction module (HF-CIM) that operates within high-frequency\nbranches rather than across the entire feature space, effectively extracting\nvaluable image details from the other view. Furthermore, to enhance the\nhigh-frequency information, a detail and texture enhancement module (DTEM) is\nproposed based on cross-attention mechanism. The model is trained on a dataset\nconsisting of images with uniform illumination and images with non-uniform\nillumination. Experimental results on both real and synthetic images indicate\nthat our algorithm offers significant advantages in light adjustment while\neffectively recovering high-frequency information. The code and dataset are\npublicly available at: https://github.com/Cherisherr/WDCI-Net.git.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12188v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于小波解耦的低光照立体图像增强框架", "tldr": "本文提出了一种基于小波的低光照立体图像增强方法，通过将特征空间解耦为低频和高频分支，并引入跨视图交互模块，有效解决了现有方法中特征纠缠和捷径学习的问题，显著提升了低光照图像的亮度和高频信息恢复。", "motivation": "现有低光照图像增强方法常将所有退化因素编码在单一潜在空间中，导致特征高度纠缠和强黑箱特性，模型易于发生捷径学习。", "method": "本文提出一种基于小波的低光照立体图像增强方法，采用特征空间解耦。通过多级小波分解，将特征空间分解为用于光照调整的低频分支和用于纹理增强的多个高频分支。提出高频引导跨视图交互模块（HF-CIM）在高频分支内提取另一视图的有用图像细节。此外，提出基于交叉注意力机制的细节和纹理增强模块（DTEM）以增强高频信息。模型在均匀和非均匀光照数据集上进行训练。", "result": "实验结果表明，该算法在亮度调整方面具有显著优势，并能有效恢复高频信息。", "conclusion": "该研究通过小波变换解耦特征空间和引入跨视图交互机制，成功解决了低光照立体图像增强中的特征纠缠问题，实现了亮度和高频信息的有效恢复。", "translation": "低光照图像存在复杂的退化，现有增强方法通常将所有退化因素编码在单一潜在空间中。这导致特征高度纠缠和强黑箱特性，使得模型容易发生捷径学习。为了缓解上述问题，本文提出了一种基于小波的特征空间解耦的低光照立体图像增强方法。我们的洞察力来自于以下发现：（1）小波变换能够独立处理低频和高频信息。（2）通过多级小波分解提取低光照图像的低频分量，可以实现光照调整。因此，通过使用小波变换，特征空间被分解为用于光照调整的低频分支和用于纹理增强的多个高频分支。此外，立体低光照图像增强可以从另一个视图中提取有用的线索以改善增强效果。为此，我们提出了一种新颖的高频引导跨视图交互模块（HF-CIM），该模块在高频分支内而不是在整个特征空间中操作，有效地从另一个视图中提取有价值的图像细节。此外，为了增强高频信息，提出了一种基于交叉注意力机制的细节和纹理增强模块（DTEM）。该模型在由均匀光照图像和非均匀光照图像组成的数据集上进行训练。在真实和合成图像上的实验结果表明，我们的算法在光照调整方面具有显著优势，同时能有效恢复高频信息。代码和数据集已公开：https://github.com/Cherisherr/WDCI-Net.git。", "summary": "本文提出了一种新颖的基于小波的低光照立体图像增强框架，旨在解决现有方法中特征纠缠和捷径学习的问题。该方法利用小波变换将特征空间解耦为用于光照调整的低频分支和用于纹理增强的高频分支。引入了高频引导跨视图交互模块（HF-CIM）以在高频分支中有效利用立体视图信息，并提出了细节和纹理增强模块（DTEM）以增强高频细节。实验证明，该算法在亮度调整和高频信息恢复方面表现出色。", "keywords": "低光照图像增强, 小波变换, 特征解耦, 立体图像, 跨视图交互", "comments": "该论文的创新点在于利用小波变换对特征空间进行解耦，将光照调整和纹理增强分别处理，有效缓解了特征纠缠问题。引入高频引导的跨视图交互模块，充分利用了立体图像的互补信息，提升了增强效果。这种解耦和跨视图交互的结合为低光照图像增强领域提供了一个新颖且有效的解决方案。"}}
{"id": "2506.00785", "title": "GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning", "authors": ["Sahiti Yerramilli", "Nilay Pande", "Rynaa Grover", "Jayant Sravan Tamarapalli"], "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.00785v2", "summary": "This paper introduces GeoChain, a large-scale benchmark for evaluating\nstep-by-step geographic reasoning in multimodal large language models (MLLMs).\nLeveraging 1.46 million Mapillary street-level images, GeoChain pairs each\nimage with a 21-step chain-of-thought (CoT) question sequence (over 30 million\nQ&A pairs). These sequences guide models from coarse attributes to fine-grained\nlocalization across four reasoning categories - visual, spatial, cultural, and\nprecise geolocation - annotated by difficulty. Images are also enriched with\nsemantic segmentation (150 classes) and a visual locatability score. Our\nbenchmarking of contemporary MLLMs (GPT-4.1 variants, Claude 3.7, Gemini 2.5\nvariants) on a diverse 2,088-image subset reveals consistent challenges: models\nfrequently exhibit weaknesses in visual grounding, display erratic reasoning,\nand struggle to achieve accurate localization, especially as the reasoning\ncomplexity escalates. GeoChain offers a robust diagnostic methodology, critical\nfor fostering significant advancements in complex geographic reasoning within\nMLLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.00785v2", "cate": "cs.AI", "date": "2025-06-01", "updated": "2025-07-16", "AI": {"title_translation": "GeoChain：多模态思维链用于地理推理", "tldr": "本文介绍了GeoChain，一个用于评估多模态大语言模型（MLLMs）逐步地理推理能力的大规模基准数据集。基准测试结果显示，当前MLLMs在视觉基础、推理连贯性和精确定位方面存在挑战。", "motivation": "为了评估多模态大语言模型（MLLMs）在逐步地理推理方面的能力，并诊断其现有挑战。", "method": "本文提出了GeoChain，一个大规模基准数据集，包含146万张Mapillary街景图像。每张图像都配有21步的思维链（CoT）问题序列（超过3000万个问答对），引导模型从粗略属性到细粒度定位，涵盖视觉、空间、文化和精确地理定位四类推理。图像还通过语义分割（150类）和视觉可定位性分数进行丰富。研究人员在一个包含2088张图像的多样化子集上对当前MLLMs（如GPT-4.1变体、Claude 3.7、Gemini 2.5变体）进行了基准测试。", "result": "基准测试结果揭示了当前MLLMs在地理推理方面存在的持续挑战：模型经常在视觉基础方面表现出弱点，显示出不稳定的推理，并且难以实现准确的定位，尤其是在推理复杂性增加时。", "conclusion": "GeoChain提供了一种强大的诊断方法，对于促进多模态大语言模型在复杂地理推理方面取得重大进展至关重要。", "translation": "本文介绍了GeoChain，一个用于评估多模态大语言模型（MLLMs）逐步地理推理能力的大规模基准数据集。GeoChain利用146万张Mapillary街景图像，将每张图像与一个21步的思维链（CoT）问题序列（超过3000万个问答对）配对。这些序列引导模型从粗略属性到细粒度定位，涵盖视觉、空间、文化和精确地理定位四类推理，并根据难度进行标注。图像还通过语义分割（150类）和视觉可定位性分数进行丰富。我们对当代MLLMs（GPT-4.1变体、Claude 3.7、Gemini 2.5变体）在一个多样化的2088张图像子集上进行的基准测试揭示了持续的挑战：模型经常在视觉基础方面表现出弱点，显示出不稳定的推理，并且难以实现准确的定位，尤其是在推理复杂性增加时。GeoChain提供了一种强大的诊断方法，对于促进MLLMs在复杂地理推理方面取得重大进展至关重要。", "summary": "本文引入了GeoChain，一个用于评估多模态大语言模型（MLLMs）逐步地理推理能力的大规模基准。GeoChain包含146万张Mapillary街景图像，每张图像配有21步思维链问题序列，总计超过3000万个问答对，旨在引导模型进行从粗到细的地理定位推理，涵盖视觉、空间、文化和精确地理定位四个类别。图像还通过语义分割和可定位性分数进行增强。对主流MLLMs的基准测试表明，模型在视觉基础、推理稳定性和精确定位方面存在显著挑战，尤其是在推理复杂性增加时。GeoChain为诊断MLLMs在复杂地理推理中的不足提供了关键方法。", "keywords": "地理推理, 多模态大语言模型, 基准, 思维链, 定位", "comments": "GeoChain的创新之处在于其大规模的、基于思维链的地理推理基准设计，以及对图像丰富语义信息的整合。它不仅提供了一个评估MLLMs地理推理能力的新工具，更重要的是，其诊断方法揭示了当前模型在视觉基础、推理连贯性和精确定位方面的具体弱点，这对于未来MLLMs在地理领域的发展和改进具有重要指导意义。"}}
{"id": "2507.12143", "title": "Overview of the Sensemaking Task at the ELOQUENT 2025 Lab: LLMs as Teachers, Students and Evaluators", "authors": ["Pavel Šindelář", "Ondřej Bojar"], "categories": ["cs.CL", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      30 pages, 7 figures, CLEF 2025 Conference and Labs of the Evaluation Forum", "url": "http://arxiv.org/abs/2507.12143v1", "summary": "ELOQUENT is a set of shared tasks that aims to create easily testable\nhigh-level criteria for evaluating generative language models. Sensemaking is\none such shared task.\n  In Sensemaking, we try to assess how well generative models ``make sense out\nof a given text'' in three steps inspired by exams in a classroom setting: (1)\nTeacher systems should prepare a set of questions, (2) Student systems should\nanswer these questions, and (3) Evaluator systems should score these answers,\nall adhering rather strictly to a given set of input materials.\n  We report on the 2025 edition of Sensemaking, where we had 7 sources of test\nmaterials (fact-checking analyses of statements, textbooks, transcribed\nrecordings of a lecture, and educational videos) spanning English, German,\nUkrainian, and Czech languages.\n  This year, 4 teams participated, providing us with 2 Teacher submissions, 2\nStudent submissions, and 2 Evaluator submissions. We added baselines for\nTeacher and Student using commercial large language model systems. We devised a\nfully automatic evaluation procedure, which we compare to a minimalistic manual\nevaluation.\n  We were able to make some interesting observations. For the first task, the\ncreation of questions, better evaluation strategies will still have to be\ndevised because it is difficult to discern the quality of the various candidate\nquestion sets. In the second task, question answering, the LLMs examined\noverall perform acceptably, but restricting their answers to the given input\ntexts remains problematic. In the third task, evaluation of question answers,\nour adversarial tests reveal that systems using the LLM-as-a-Judge paradigm\nerroneously rate both garbled question-answer pairs and answers to mixed-up\nquestions as acceptable.", "comment": "30 pages, 7 figures, CLEF 2025 Conference and Labs of the Evaluation\n  Forum", "pdf_url": "http://arxiv.org/pdf/2507.12143v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "ELOQUENT 2025 实验室的意义理解任务概述：LLM 作为教师、学生和评估者", "tldr": "ELOQUENT 2025 实验室的意义理解任务旨在通过模拟课堂考试（教师提问、学生回答、评估者评分）来评估生成式语言模型的理解能力。研究发现，问题生成任务需要更好的评估策略，LLM在回答限制文本方面仍有问题，并且“LLM作为评判者”范式在评估答案时容易出错。", "motivation": "该研究旨在为评估生成式语言模型创建易于测试的高级标准，特别是评估它们“理解给定文本”的能力。", "method": "ELOQUENT Sensemaking 任务模拟课堂考试，分为三个步骤：(1) 教师系统准备问题，(2) 学生系统回答问题，(3) 评估者系统评分。2025年的任务使用了7种不同语言（英语、德语、乌克兰语、捷克语）的测试材料，包括事实核查分析、教科书、讲座录音和教育视频。有4支团队参与，并增加了商业大型语言模型的基线。采用全自动评估程序，并与最小化人工评估进行比较。", "result": "在第一项任务（问题创建）中，难以辨别不同候选问题集的质量，需要更好的评估策略。在第二项任务（问题回答）中，LLM总体表现可接受，但将其答案限制在给定输入文本中仍然存在问题。在第三项任务（问题答案评估）中，对抗性测试显示使用“LLM作为评判者”范式的系统错误地将混乱的问题-答案对和混合问题的答案评定为可接受。", "conclusion": "评估生成式语言模型在意义理解任务中的表现仍面临挑战，尤其是在问题生成评估、限制回答文本以及“LLM作为评判者”范式的可靠性方面。", "translation": "ELOQUENT 是一系列旨在为评估生成式语言模型创建易于测试的高级标准的共享任务。意义理解是其中一项共享任务。\n在意义理解任务中，我们尝试评估生成模型“如何从给定文本中理解意义”，分三个步骤，灵感来源于课堂考试设置：(1) 教师系统应准备一套问题，(2) 学生系统应回答这些问题，(3) 评估者系统应对这些答案进行评分，所有这些都严格遵循一套给定的输入材料。\n我们报告了2025年意义理解任务的情况，该任务有7个测试材料来源（对陈述的事实核查分析、教科书、讲座录音和教育视频），涵盖英语、德语、乌克兰语和捷克语。今年有4支团队参与，提供了2份教师提交、2份学生提交和2份评估者提交。我们使用商业大型语言模型系统为教师和学生任务添加了基线。我们设计了一个全自动评估程序，并将其与最小化的人工评估进行比较。\n我们获得了一些有趣的观察结果。对于第一个任务，即问题创建，仍需要制定更好的评估策略，因为难以辨别各种候选问题集的质量。在第二个任务，即问题回答中，所考察的LLM总体表现尚可，但将其答案限制在给定输入文本仍然存在问题。在第三个任务，即问题答案评估中，我们的对抗性测试显示，使用“LLM作为评判者”范式的系统错误地将混乱的问题-答案对和混合问题的答案评定为可接受。", "summary": "本文概述了 ELOQUENT 2025 实验室的意义理解共享任务，该任务旨在评估生成式语言模型对文本的理解能力。任务模拟课堂考试，分为教师（提问）、学生（回答）和评估者（评分）三个角色。2025年任务使用了多语言、多源材料，并有4支团队参与。研究发现，问题创建的评估策略尚不成熟，LLM在限制性回答上存在问题，且“LLM作为评判者”的评估范式在对抗性测试中表现出错误率。", "keywords": "生成式语言模型, 意义理解, ELOQUENT, LLM评估, 共享任务", "comments": "该论文通过ELOQUENT Sensemaking任务，创新性地提出了模拟课堂环境来评估LLM的理解能力。其重要性在于揭示了当前LLM在作为教师、学生和评估者角色时所面临的具体挑战和局限性，尤其是在问题生成质量评估、限制性回答的准确性以及“LLM作为评判者”范式的可靠性方面，为未来的研究指明了方向。"}}
{"id": "2507.12118", "title": "An Online A/B Testing Decision Support System for Web Usability Assessment Based on a Linguistic Decision-making Methodology: Case of Study a Virtual Learning Environment", "authors": ["Noe Zermeño", "Cristina Zuheros", "Lucas Daniel Del Rosso Calache", "Francisco Herrera", "Rosana Montes"], "categories": ["cs.SE", "cs.HC"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12118v1", "summary": "In recent years, attention has increasingly focused on enhancing user\nsatisfaction with user interfaces, spanning both mobile applications and\nwebsites. One fundamental aspect of human-machine interaction is the concept of\nweb usability. In order to assess web usability, the A/B testing technique\nenables the comparison of data between two designs. Expanding the scope of\ntests to include the designs being evaluated, in conjunction with the\ninvolvement of both real and fictional users, presents a challenge for which\nfew online tools offer support. We propose a methodology for web usability\nevaluation based on user-centered approaches such as design thinking and\nlinguistic decision-making, named Linguistic Decision-Making for Web Usability\nEvaluation. This engages people in role-playing scenarios and conducts a number\nof usability tests, including the widely recognized System Usability Scale. We\nincorporate the methodology into a decision support system based on A/B\ntesting. We use real users in a case study to assess three Moodle platforms at\nthe University of Guadalajara, Mexico.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12118v1", "cate": "cs.SE", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于语言决策方法的在线A/B测试决策支持系统用于网络可用性评估：以虚拟学习环境为例", "tldr": "本文提出了一种基于语言决策方法的在线A/B测试决策支持系统，用于评估网络可用性，通过角色扮演和可用性测试（如SUS）来解决现有工具在扩展A/B测试时面临的挑战，并在墨西哥瓜达拉哈拉大学的Moodle平台进行了案例研究。", "motivation": "现有在线工具很少支持扩展A/B测试的范围，以包含更多设计和真实/虚拟用户，这在评估网络可用性时构成挑战。", "method": "提出了一种名为“网络可用性评估的语言决策”的方法，该方法基于以用户为中心的方法，如设计思维和语言决策。它涉及角色扮演场景和多项可用性测试（包括系统可用性量表）。该方法被整合到一个基于A/B测试的决策支持系统中。", "result": "通过一个案例研究，使用真实用户评估了墨西哥瓜达拉哈拉大学的三个Moodle平台。", "conclusion": "Not mentioned in abstract", "translation": "近年来，人们越来越关注提高移动应用程序和网站的用户界面满意度。人机交互的一个基本方面是网络可用性概念。为了评估网络可用性，A/B测试技术能够比较两种设计之间的数据。将测试范围扩展到包括正在评估的设计，并结合真实和虚拟用户的参与，提出了一个挑战，而很少有在线工具提供支持。我们提出了一种基于以用户为中心的方法（如设计思维和语言决策）的网络可用性评估方法，命名为“网络可用性评估的语言决策”。这让人们参与角色扮演场景，并进行多项可用性测试，包括广受认可的系统可用性量表。我们将该方法整合到一个基于A/B测试的决策支持系统中。我们在一个案例研究中使用了真实用户，评估了墨西哥瓜达拉哈拉大学的三个Moodle平台。", "summary": "本文针对现有在线A/B测试工具在评估网络可用性时扩展测试范围的挑战，提出了一种基于语言决策方法的新型在线决策支持系统。该系统整合了以用户为中心的设计思维和语言决策方法，通过角色扮演和多种可用性测试（包括SUS）进行评估。研究通过一个案例研究，使用真实用户对墨西哥瓜达拉哈拉大学的三个Moodle平台进行了可用性评估。", "keywords": "A/B测试, 网络可用性, 决策支持系统, 语言决策, 虚拟学习环境", "comments": "本文的创新点在于将语言决策方法与A/B测试相结合，构建了一个用于网络可用性评估的决策支持系统。通过引入角色扮演和用户中心方法，它提供了一种更全面的可用性评估途径，尤其是在面对真实和虚拟用户参与的复杂场景时。该系统有望弥补现有在线工具在扩展测试范围方面的不足。"}}
{"id": "2507.11751", "title": "Survey of Genetic and Differential Evolutionary Algorithm Approaches to Search Documents Based On Semantic Similarity", "authors": ["Chandrashekar Muniyappa", "Eunjin Kim"], "categories": ["cs.NE", "cs.AI", "68-68W50"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      CSAIDE '25: Proceedings of the 2025 4th International Conference on Cyber Security, Artificial Intelligence and the Digital Economy", "url": "http://arxiv.org/abs/2507.11751v1", "summary": "Identifying similar documents within extensive volumes of data poses a\nsignificant challenge. To tackle this issue, researchers have developed a\nvariety of effective distributed computing techniques. With the advancement of\ncomputing power and the rise of big data, deep neural networks and evolutionary\ncomputing algorithms such as genetic algorithms and differential evolution\nalgorithms have achieved greater success. This survey will explore the most\nrecent advancements in the search for documents based on their semantic text\nsimilarity, focusing on genetic and differential evolutionary computing\nalgorithms.", "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "pdf_url": "http://arxiv.org/pdf/2507.11751v1", "cate": "cs.NE", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "遗传算法和差分进化算法在基于语义相似度文档搜索中的应用综述", "tldr": "本文综述了使用遗传算法和差分进化算法进行基于语义相似度的文档搜索的最新进展。", "motivation": "在海量数据中识别相似文档是一项重大挑战，随着计算能力和大数据的发展，深度神经网络和进化计算算法在文档搜索中取得了更大的成功。", "method": "本文对基于语义文本相似度的文档搜索中，重点关注遗传算法和差分进化算法的最新进展进行综述。", "result": "Not mentioned in abstract", "conclusion": "本综述旨在探讨遗传算法和差分进化算法在语义相似度文档搜索领域的最新进展。", "translation": "在海量数据中识别相似文档提出了重大挑战。为了解决这个问题，研究人员开发了各种有效的分布式计算技术。随着计算能力的进步和大数据的兴起，深度神经网络和进化计算算法，如遗传算法和差分进化算法，取得了更大的成功。本综述将探讨基于语义文本相似度搜索文档的最新进展，重点关注遗传算法和差分进化计算算法。", "summary": "本文综述了利用遗传算法和差分进化算法进行基于语义相似度文档搜索的最新进展。面对海量数据中识别相似文档的挑战，以及计算能力和大数据背景下进化算法的成功应用，该综述旨在提供这些算法在该领域发展的全面视角。", "keywords": "语义相似度, 文档搜索, 遗传算法, 差分进化算法, 综述", "comments": "这篇综述论文对于了解遗传算法和差分进化算法在语义相似度文档搜索领域的应用现状和最新进展具有重要意义，对研究人员和实践者提供了有价值的概览，有助于把握该领域的研究方向。"}}
{"id": "2507.12165", "title": "Multi-Component VAE with Gaussian Markov Random Field", "authors": ["Fouad Oubari", "Mohamed El-Baha", "Raphael Meunier", "Rodrigue Décatoire", "Mathilde Mougeot"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12165v1", "summary": "Multi-component datasets with intricate dependencies, like industrial\nassemblies or multi-modal imaging, challenge current generative modeling\ntechniques. Existing Multi-component Variational AutoEncoders typically rely on\nsimplified aggregation strategies, neglecting critical nuances and consequently\ncompromising structural coherence across generated components. To explicitly\naddress this gap, we introduce the Gaussian Markov Random Field Multi-Component\nVariational AutoEncoder , a novel generative framework embedding Gaussian\nMarkov Random Fields into both prior and posterior distributions. This design\nchoice explicitly models cross-component relationships, enabling richer\nrepresentation and faithful reproduction of complex interactions. Empirically,\nour GMRF MCVAE achieves state-of-the-art performance on a synthetic Copula\ndataset specifically constructed to evaluate intricate component relationships,\ndemonstrates competitive results on the PolyMNIST benchmark, and significantly\nenhances structural coherence on the real-world BIKED dataset. Our results\nindicate that the GMRF MCVAE is especially suited for practical applications\ndemanding robust and realistic modeling of multi-component coherence", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12165v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "具有高斯马尔可夫随机场的多组件变分自编码器", "tldr": "GMRF MCVAE 是一种新的生成模型，通过在高斯马尔可夫随机场中嵌入先验和后验分布来明确建模多组件数据中的复杂依赖关系，并在多个数据集上实现了最先进的性能。", "motivation": "现有生成模型难以处理具有复杂依赖关系的多组件数据集，特别是多组件变分自编码器中简化的聚合策略忽略了关键细节，损害了生成组件的结构一致性。", "method": "本文引入了高斯马尔可夫随机场多组件变分自编码器 (GMRF MCVAE)，这是一种新颖的生成框架，将高斯马尔可夫随机场嵌入到先验和后验分布中，从而明确地建模跨组件关系。", "result": "GMRF MCVAE 在合成 Copula 数据集上实现了最先进的性能，在 PolyMNIST 基准上表现出有竞争力的结果，并显著增强了真实世界 BIKED 数据集上的结构一致性。", "conclusion": "GMRF MCVAE 特别适用于需要对多组件一致性进行鲁棒和现实建模的实际应用。", "translation": "具有复杂依赖关系的多组件数据集，如工业装配或多模态成像，对当前的生成建模技术提出了挑战。现有的多组件变分自编码器通常依赖简化的聚合策略，忽略了关键的细微差别，从而损害了生成组件之间的结构一致性。为了明确解决这一问题，我们引入了高斯马尔可夫随机场多组件变分自编码器（GMRF MCVAE），这是一种新颖的生成框架，将高斯马尔可夫随机场嵌入到先验和后验分布中。这种设计选择明确地建模了跨组件关系，从而实现了更丰富的表示和对复杂交互的忠实再现。经验上，我们的 GMRF MCVAE 在专门构建用于评估复杂组件关系的合成 Copula 数据集上取得了最先进的性能，在 PolyMNIST 基准上展示了有竞争力的结果，并显著增强了真实世界 BIKED 数据集上的结构一致性。我们的结果表明，GMRF MCVAE 特别适用于需要对多组件一致性进行鲁棒和现实建模的实际应用。", "summary": "本文提出了一种名为高斯马尔可夫随机场多组件变分自编码器 (GMRF MCVAE) 的新型生成框架，旨在解决现有方法在处理具有复杂依赖关系的多组件数据时，因简化聚合策略导致结构一致性受损的问题。GMRF MCVAE 通过将高斯马尔可夫随机场嵌入到其先验和后验分布中，明确建模组件间的关系，从而实现更丰富的表示和对复杂交互的忠实再现。实验结果表明，GMRF MCVAE 在合成 Copula 数据集上达到了最先进的性能，在 PolyMNIST 上表现出色，并在真实世界 BIKED 数据集上显著提升了结构一致性，证明其适用于需要对多组件一致性进行鲁棒建模的实际应用。", "keywords": "多组件变分自编码器, 高斯马尔可夫随机场, 生成模型, 结构一致性, 复杂依赖关系", "comments": "这篇论文的创新点在于将高斯马可夫随机场（GMRF）引入到多组件变分自编码器（MCVAE）的先验和后验分布中，从而明确地建模多组件数据中复杂的跨组件依赖关系。这解决了现有 MCVAE 简化聚合策略导致结构一致性差的问题。通过在多个数据集上的优异表现，该模型在生成具有强结构一致性的多组件数据方面具有重要意义，尤其适用于对组件间关系建模要求高的实际应用。"}}
{"id": "2507.11953", "title": "IAM: Efficient Inference through Attention Mapping between Different-scale LLMs", "authors": ["Yi Zhao", "Zuchao Li", "Hai Zhao"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025", "url": "http://arxiv.org/abs/2507.11953v1", "summary": "LLMs encounter significant challenges in resource consumption nowadays,\nespecially with long contexts. Despite extensive efforts dedicate to enhancing\ninference efficiency, these methods primarily exploit internal sparsity within\nthe models, without leveraging external information for optimization. We\nidentify the high similarity of attention matrices across different-scale LLMs,\nwhich offers a novel perspective for optimization. We first conduct a\ncomprehensive analysis of how to measure similarity, how to select mapping\nLayers and whether mapping is consistency. Based on these insights, we\nintroduce the IAM framework, which achieves dual benefits of accelerated\nattention computation and reduced KV cache usage by performing attention\nmapping between small and large LLMs. Our experimental results demonstrate that\nIAM can accelerate prefill by 15% and reduce KV cache usage by 22.1% without\nappreciably sacrificing performance. Experiments on different series of models\nshow the generalizability of IAM. Importantly, it is also orthogonal to many\nexisting KV cache optimization methods, making it a versatile addition to the\ncurrent toolkit for enhancing LLM efficiency.", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2507.11953v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "IAM：通过不同尺度LLM间的注意力映射实现高效推理", "tldr": "IAM框架通过利用不同尺度LLM间注意力矩阵的高相似性，加速了LLM的推理预填充并减少了KV缓存使用，同时保持了性能，并且可以与其他优化方法结合使用。", "motivation": "LLMs在资源消耗方面（尤其是长上下文）面临巨大挑战，现有方法主要利用模型内部稀疏性，而没有利用外部信息进行优化。本文发现不同尺度LLM间注意力矩阵的高度相似性，为优化提供了新视角。", "method": "本文首先全面分析了如何测量相似性、如何选择映射层以及映射是否一致。基于这些洞察，提出了IAM框架，通过在小型和大型LLM之间执行注意力映射，实现加速注意力计算和减少KV缓存使用的双重效益。", "result": "实验结果表明，IAM可以将预填充加速15%，并将KV缓存使用减少22.1%，而性能没有明显牺牲。在不同系列模型上的实验显示了IAM的通用性。", "conclusion": "IAM框架通过利用不同尺度LLM间的注意力映射，有效提升了LLM的推理效率（加速预填充和减少KV缓存），并且具有良好的通用性和兼容性，可以与现有KV缓存优化方法结合使用。", "translation": "LLMs在当今面临着显著的资源消耗挑战，尤其是在长上下文情况下。尽管为提高推理效率付出了大量努力，但这些方法主要利用模型内部的稀疏性，而没有利用外部信息进行优化。我们发现不同尺度LLM之间的注意力矩阵具有高度相似性，这为优化提供了一个新颖的视角。我们首先对如何衡量相似性、如何选择映射层以及映射是否一致进行了全面分析。基于这些见解，我们引入了IAM框架，通过在小型和大型LLM之间进行注意力映射，实现了加速注意力计算和减少KV缓存使用的双重效益。我们的实验结果表明，IAM可以将预填充加速15%，并将KV缓存使用减少22.1%，而性能没有明显牺牲。在不同系列模型上的实验显示了IAM的通用性。重要的是，它还与许多现有的KV缓存优化方法正交，使其成为当前增强LLM效率工具包的多功能补充。", "summary": "本文提出了IAM框架，旨在解决大型语言模型（LLMs）推理过程中的资源消耗问题。该框架利用不同尺度LLMs之间注意力矩阵的高度相似性，通过在小型和大型LLMs之间进行注意力映射，实现了注意力计算的加速和KV缓存使用的减少。实验证明，IAM能将预填充速度提升15%，并减少22.1%的KV缓存使用，同时保持性能，并展现出良好的通用性和与现有优化方法的兼容性。", "keywords": "LLMs, 推理效率, 注意力映射, KV缓存, 异构模型", "comments": "本文的创新点在于提出了利用不同尺度LLM间注意力矩阵相似性进行优化的新颖视角，这与现有主要利用模型内部稀疏性的方法不同。IAM框架在加速推理和减少KV缓存方面取得了显著效果，并且其与现有KV缓存优化方法的正交性使其具有很高的实用价值和广阔的应用前景。"}}
{"id": "2507.11562", "title": "Expert Operational GANS: Towards Real-Color Underwater Image Restoration", "authors": ["Ozer Can Devecioglu", "Serkan Kiranyaz", "Mehmet Yamac", "Moncef Gabbouj"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.11562v1", "summary": "The wide range of deformation artifacts that arise from complex light\npropagation, scattering, and depth-dependent attenuation makes the underwater\nimage restoration to remain a challenging problem. Like other single deep\nregressor networks, conventional GAN-based restoration methods struggle to\nperform well across this heterogeneous domain, since a single generator network\nis typically insufficient to capture the full range of visual degradations. In\norder to overcome this limitation, we propose xOp-GAN, a novel GAN model with\nseveral expert generator networks, each trained solely on a particular subset\nwith a certain image quality. Thus, each generator can learn to maximize its\nrestoration performance for a particular quality range. Once a xOp-GAN is\ntrained, each generator can restore the input image and the best restored image\ncan then be selected by the discriminator based on its perceptual confidence\nscore. As a result, xOP-GAN is the first GAN model with multiple generators\nwhere the discriminator is being used during the inference of the regression\ntask. Experimental results on benchmark Large Scale Underwater Image (LSUI)\ndataset demonstrates that xOp-GAN achieves PSNR levels up to 25.16 dB,\nsurpassing all single-regressor models by a large margin even, with reduced\ncomplexity.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.11562v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "专家操作GANs：迈向真实色彩的水下图像恢复", "tldr": "xOp-GAN是一种新型的GAN模型，它使用多个专家生成器网络来解决水下图像恢复中复杂的变形伪影问题，并在LSUI数据集上取得了显著优于单回归器模型的性能，同时降低了复杂度。", "motivation": "水下图像恢复因复杂的光传播、散射和深度依赖性衰减引起的广泛变形伪影而仍然是一个具有挑战性的问题。传统的基于GAN的恢复方法，像其他单一深度回归器网络一样，难以在异构域中表现良好，因为单个生成器网络通常不足以捕捉所有视觉退化。", "method": "本文提出了xOp-GAN，一种新颖的GAN模型，它包含多个专家生成器网络，每个网络仅针对特定图像质量的子集进行训练。这样，每个生成器可以最大化其在特定质量范围内的恢复性能。训练完成后，每个生成器都可以恢复输入图像，然后由判别器根据其感知置信度分数选择最佳恢复图像。xOp-GAN是第一个在回归任务推理过程中使用判别器的多生成器GAN模型。", "result": "在基准大型水下图像（LSUI）数据集上的实验结果表明，xOp-GAN的PSNR水平高达25.16 dB，即使在复杂度降低的情况下，也以显著优势超越了所有单回归器模型。", "conclusion": "xOp-GAN通过采用多个专家生成器网络和在推理过程中利用判别器进行选择，有效克服了传统GAN模型在水下图像恢复中的局限性，实现了卓越的恢复性能和更高的效率。", "translation": "复杂的光传播、散射和深度依赖性衰减导致了广泛的变形伪影，使得水下图像恢复仍然是一个具有挑战性的问题。像其他单一深度回归器网络一样，传统的基于GAN的恢复方法难以在异构域中表现良好，因为单个生成器网络通常不足以捕捉所有视觉退化。为了克服这一限制，我们提出了xOp-GAN，一种新颖的GAN模型，它包含多个专家生成器网络，每个网络仅针对特定图像质量的子集进行训练。因此，每个生成器可以学习最大化其在特定质量范围内的恢复性能。一旦xOp-GAN训练完成，每个生成器都可以恢复输入图像，然后由判别器根据其感知置信度分数选择最佳恢复图像。因此，xOP-GAN是第一个在回归任务推理过程中使用判别器的多生成器GAN模型。在基准大型水下图像（LSUI）数据集上的实验结果表明，xOp-GAN的PSNR水平高达25.16 dB，即使在复杂度降低的情况下，也以显著优势超越了所有单回归器模型。", "summary": "本文针对水下图像恢复中单一生成器GAN模型性能不足的问题，提出了一种名为xOp-GAN的新型GAN模型。xOp-GAN采用多个专家生成器网络，每个网络专注于特定质量范围的图像恢复，并通过判别器在推理阶段选择最佳恢复结果。实验证明，xOp-GAN在LSUI数据集上实现了高达25.16 dB的PSNR，显著优于现有单回归器模型，同时降低了复杂度。", "keywords": "水下图像恢复, GAN, 专家生成器, 判别器, 图像质量", "comments": "该论文的创新点在于引入了“专家生成器”的概念，并首次将判别器应用于多生成器GAN的推理选择阶段，这为处理复杂且异构的数据退化问题提供了一个新颖且有效的解决方案。其优势在于能够针对不同质量的图像进行专门优化，从而提高了整体恢复性能。该方法在水下图像恢复领域具有重要意义，可能为其他图像恢复任务提供新的思路。"}}
{"id": "2507.11746", "title": "Acceleration methods for fixed point iterations", "authors": ["Yousef Saad"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      80 pp", "url": "http://arxiv.org/abs/2507.11746v1", "summary": "A pervasive approach in scientific computing is to express the solution to a\ngiven problem as the limit of a sequence of vectors or other mathematical\nobjects. In many situations these sequences are generated by slowly converging\niterative procedures and this led practitioners to seek faster alternatives to\nreach the limit. ``Acceleration techniques'' comprise a broad array of methods\nspecifically designed with this goal in mind. They started as a means of\nimproving the convergence of general scalar sequences by various forms of\n``extrapolation to the limit'', i.e., by extrapolating the most recent iterates\nto the limit via linear combinations. Extrapolation methods of this type, the\nbest known example of which is Aitken's Delta-squared process, require only the\nsequence of vectors as input. However, limiting methods to only use the\niterates is too restrictive. Accelerating sequences generated by fixed-point\niterations by utilizing both the iterates and the fixed-point mapping itself\nhas proven highly successful across various areas of physics. A notable example\nof these Fixed-Point accelerators (FP-Accelerators) is a method developed by D.\nAnderson in 1965 and now widely known as Anderson Acceleration (AA).\nFurthermore, Quasi-Newton and Inexact Newton methods can also be placed in this\ncategory as well. This paper presents an overview of these methods -- with an\nemphasis on those, such as AA, that are geared toward accelerating fixed point\niterations.", "comment": "80 pp", "pdf_url": "http://arxiv.org/pdf/2507.11746v1", "cate": "math.NA", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "定点迭代加速方法", "tldr": "本文概述了用于加速慢收敛定点迭代的方法，重点介绍了Anderson加速等技术。", "motivation": "在科学计算中，许多问题的解通过迭代过程生成，但这些过程往往收敛缓慢，因此需要寻求更快的方法来达到极限。", "method": "论文介绍了多种加速技术，包括通过线性组合外推最近迭代的“极限外推”方法（如Aitken的Delta-squared过程），以及利用迭代序列和定点映射本身的定点加速器（如Anderson加速），此外还提及了准牛顿法和非精确牛顿法。", "result": "Not mentioned in abstract", "conclusion": "本文概述了加速定点迭代的各种方法，特别强调了Anderson加速等在科学计算中的重要性和成功应用。", "translation": "科学计算中一种普遍的方法是将给定问题的解表示为向量或其他数学对象序列的极限。在许多情况下，这些序列是由缓慢收敛的迭代过程生成的，这促使实践者寻求更快的替代方法来达到极限。“加速技术”包含了一系列专门为此目标设计的方法。它们最初是通过各种形式的“外推到极限”，即通过线性组合外推最近的迭代来改善一般标量序列的收敛性。这类外推方法，其中最著名的例子是Aitken的Delta-squared过程，仅需要向量序列作为输入。然而，将方法仅限于使用迭代序列过于受限。通过利用迭代和定点映射本身来加速由定点迭代生成的序列，已在物理学的各个领域被证明非常成功。这些定点加速器（FP-Accelerators）的一个显著例子是D. Anderson在1965年开发的方法，现在广为人知为Anderson加速（AA）。此外，准牛顿法和非精确牛顿法也可以归入这一类别。本文概述了这些方法——重点是那些旨在加速定点迭代的方法，如AA。", "summary": "本文对科学计算中用于加速定点迭代收敛的多种方法进行了综述。文章首先介绍了通过“极限外推”来加速序列收敛的早期技术（如Aitken的Delta-squared过程），随后重点阐述了利用迭代序列和定点映射本身的定点加速器（FP-Accelerators），其中Anderson加速（AA）是著名实例。此外，准牛顿法和非精确牛顿法也被提及。这些加速方法旨在解决迭代过程收敛缓慢的问题，并且定点加速器已在物理学等领域取得显著成功。", "keywords": "定点迭代, 加速方法, Anderson加速, 外推法, 准牛顿法", "comments": "本文作为一篇综述性论文，系统地介绍了加速定点迭代的关键技术，尤其是突出了Anderson加速的重要性，对于研究人员理解和应用相关方法具有重要的参考价值。"}}
{"id": "2507.11847", "title": "Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update", "authors": ["Yu-Jie Zhang", "Sheng-An Xu", "Peng Zhao", "Masashi Sugiyama"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11847v1", "summary": "We study the generalized linear bandit (GLB) problem, a contextual\nmulti-armed bandit framework that extends the classical linear model by\nincorporating a non-linear link function, thereby modeling a broad class of\nreward distributions such as Bernoulli and Poisson. While GLBs are widely\napplicable to real-world scenarios, their non-linear nature introduces\nsignificant challenges in achieving both computational and statistical\nefficiency. Existing methods typically trade off between two objectives, either\nincurring high per-round costs for optimal regret guarantees or compromising\nstatistical efficiency to enable constant-time updates. In this paper, we\npropose a jointly efficient algorithm that attains a nearly optimal regret\nbound with $\\mathcal{O}(1)$ time and space complexities per round. The core of\nour method is a tight confidence set for the online mirror descent (OMD)\nestimator, which is derived through a novel analysis that leverages the notion\nof mix loss from online prediction. The analysis shows that our OMD estimator,\neven with its one-pass updates, achieves statistical efficiency comparable to\nmaximum likelihood estimation, thereby leading to a jointly efficient\noptimistic method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11847v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "广义线性强盗问题：接近最优遗憾值和单次更新", "tldr": "本文提出了一种针对广义线性强盗（GLB）问题的新算法，该算法在实现接近最优遗憾值的同时，每轮更新仅需O(1)的时间和空间复杂度，解决了现有方法在计算和统计效率之间的权衡问题。", "motivation": "广义线性强盗（GLB）问题在实际应用中广泛存在，但其非线性特性导致在实现计算和统计效率方面面临显著挑战。现有方法通常需要在高昂的每轮成本以获得最优遗憾保证，或牺牲统计效率以实现恒定时间更新之间进行权衡。", "method": "本文提出了一种联合高效的算法。其核心是为在线镜像下降（OMD）估计器构建一个紧密的置信集，并通过利用在线预测中的混合损失（mix loss）概念进行新颖分析来推导该置信集。", "result": "所提出的算法实现了接近最优的遗憾界限，并且每轮具有 $\\mathcal{O}(1)$ 的时间和空间复杂度。分析表明，即使通过单次更新，该OMD估计器也能达到与最大似然估计（MLE）相当的统计效率。", "conclusion": "本文提出了一种联合高效的乐观方法，能够有效解决广义线性强盗问题中的计算和统计效率挑战，并在统计效率上可与最大似然估计相媲美。", "translation": "我们研究了广义线性强盗（GLB）问题，这是一个上下文多臂强盗框架，通过引入非线性链接函数扩展了经典线性模型，从而能够建模广泛的奖励分布，例如伯努利分布和泊松分布。虽然GLB广泛适用于现实世界场景，但其非线性特性在实现计算和统计效率方面带来了显著挑战。现有方法通常在两个目标之间进行权衡，要么为获得最优遗憾保证而产生高昂的每轮成本，要么牺牲统计效率以实现恒定时间更新。在本文中，我们提出了一种联合高效的算法，该算法以每轮$\\mathcal{O}(1)$的时间和空间复杂度实现了接近最优的遗憾界限。我们方法的核心是为在线镜像下降（OMD）估计器构建一个紧密的置信集，该置信集通过利用在线预测中的混合损失概念进行新颖分析而得出。分析表明，我们的OMD估计器，即使通过单次更新，也能实现与最大似然估计相当的统计效率，从而形成一种联合高效的乐观方法。", "summary": "本文研究了广义线性强盗（GLB）问题，旨在解决现有方法在计算和统计效率之间权衡的挑战。作者提出了一种联合高效的算法，该算法基于在线镜像下降（OMD）估计器的紧密置信集，并通过利用混合损失概念进行分析。该算法实现了接近最优的遗憾界限，并具有每轮$\\mathcal{O}(1)$的时间和空间复杂度，同时其OMD估计器展现出与最大似然估计相当的统计效率。", "keywords": "广义线性强盗, 在线镜像下降, 遗憾值, 计算效率, 统计效率", "comments": "该论文的创新之处在于提出了一种在广义线性强盗问题中同时实现计算和统计高效的新算法。通过利用在线镜像下降和混合损失分析，它解决了现有方法在效率权衡上的局限性，使得算法在保持低计算成本的同时，能达到接近最优的统计性能。这对于实际应用中需要高效在线学习的场景具有重要意义。"}}
{"id": "2507.12095", "title": "BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images", "authors": ["Davide Di Nucci", "Matteo Tomei", "Guido Borghi", "Luca Ciuffreda", "Roberto Vezzani", "Rita Cucchiara"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12095v1", "summary": "Accurate 3D reconstruction of vehicles is vital for applications such as\nvehicle inspection, predictive maintenance, and urban planning. Existing\nmethods like Neural Radiance Fields and Gaussian Splatting have shown\nimpressive results but remain limited by their reliance on dense input views,\nwhich hinders real-world applicability. This paper addresses the challenge of\nreconstructing vehicles from sparse-view inputs, leveraging depth maps and a\nrobust pose estimation architecture to synthesize novel views and augment\ntraining data. Specifically, we enhance Gaussian Splatting by integrating a\nselective photometric loss, applied only to high-confidence pixels, and\nreplacing standard Structure-from-Motion pipelines with the DUSt3R architecture\nto improve camera pose estimation. Furthermore, we present a novel dataset\nfeaturing both synthetic and real-world public transportation vehicles,\nenabling extensive evaluation of our approach. Experimental results demonstrate\nstate-of-the-art performance across multiple benchmarks, showcasing the\nmethod's ability to achieve high-quality reconstructions even under constrained\ninput conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12095v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "BRUM：基于360度稀疏图像的鲁棒3D车辆重建", "tldr": "本文提出BRUM方法，通过增强高斯泼溅（Gaussian Splatting）并改进姿态估计，实现了从稀疏360度图像进行高质量3D车辆重建，并在多个基准测试中达到了最先进的性能。", "motivation": "现有3D重建方法（如神经辐射场和高斯泼溅）依赖密集输入视图，限制了其在车辆检查、预测性维护和城市规划等关键实际应用中的可行性。本文旨在解决从稀疏视图输入进行车辆3D重建的挑战。", "method": "本文通过以下方式解决稀疏视图输入问题：1. 利用深度图和鲁棒的姿态估计架构合成新视图并扩充训练数据。2. 通过集成选择性光度损失（仅应用于高置信度像素）来增强高斯泼溅。3. 用DUSt3R架构取代标准运动结构（Structure-from-Motion）管道，以改进相机姿态估计。4. 提出了一个包含合成和真实世界公共交通车辆的新颖数据集用于评估。", "result": "实验结果表明，该方法在多个基准测试中取得了最先进的性能，展示了即使在受限输入条件下（稀疏视图）也能实现高质量重建的能力。", "conclusion": "BRUM方法有效地克服了3D车辆重建中对密集视图的需求限制，能够从稀疏输入中提供鲁棒且高质量的重建结果，使其适用于车辆检查、预测性维护和城市规划等实际应用。", "translation": "车辆的精确3D重建对于车辆检查、预测性维护和城市规划等应用至关重要。现有方法，如神经辐射场和高斯泼溅，已显示出令人印象深刻的结果，但仍受限于它们对密集输入视图的依赖，这阻碍了实际应用。本文解决了从稀疏视图输入重建车辆的挑战，利用深度图和鲁棒的姿态估计架构来合成新视图并扩充训练数据。具体而言，我们通过集成选择性光度损失（仅应用于高置信度像素）来增强高斯泼溅，并用DUSt3R架构取代标准运动结构（Structure-from-Motion）管道以改进相机姿态估计。此外，我们提出了一个包含合成和真实世界公共交通车辆的新颖数据集，从而能够对我们的方法进行广泛评估。实验结果表明，在多个基准测试中取得了最先进的性能，展示了该方法即使在受限输入条件下也能实现高质量重建的能力。", "summary": "本文提出了BRUM，一种从稀疏360度图像进行鲁棒3D车辆重建的新方法。它通过增强高斯泼溅（Gaussian Splatting）并整合DUSt3R架构以改进相机姿态估计来解决现有密集视图方法的局限性。该方法利用深度图和鲁棒的姿态估计架构进行数据增强。BRUM在一个新数据集上进行了评估，实现了最先进的性能，证明了在稀疏输入条件下进行高质量重建的能力，使其适用于车辆检查和城市规划等实际应用。", "keywords": "3D车辆重建, 稀疏图像, 高斯泼溅, 姿态估计, DUSt3R", "comments": "该论文通过关注稀疏输入，解决了当前3D重建技术（对密集视图的要求）的一个重要实际限制。选择性光度损失的集成和DUSt3R架构在姿态估计中的应用是对高斯泼溅的创新性增强。此外，为公共交通车辆创建新数据集也增加了价值，有助于该特定领域的进一步研究和基准测试。"}}
{"id": "2507.12455", "title": "Mitigating Object Hallucinations via Sentence-Level Early Intervention", "authors": ["Shangpin Peng", "Senqiao Yang", "Li Jiang", "Zhuotao Tian"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12455v1", "summary": "Multimodal large language models (MLLMs) have revolutionized cross-modal\nunderstanding but continue to struggle with hallucinations - fabricated content\ncontradicting visual inputs. Existing hallucination mitigation methods either\nincur prohibitive computational costs or introduce distribution mismatches\nbetween training data and model outputs. We identify a critical insight:\nhallucinations predominantly emerge at the early stages of text generation and\npropagate through subsequent outputs. To address this, we propose **SENTINEL**\n(**S**entence-level **E**arly i**N**tervention **T**hrough **IN**-domain\npr**E**ference **L**earning), a framework that eliminates dependency on human\nannotations. Specifically, we first bootstrap high-quality in-domain preference\npairs by iteratively sampling model outputs, validating object existence\nthrough cross-checking with two open-vocabulary detectors, and classifying\nsentences into hallucinated/non-hallucinated categories. Subsequently, we use\ncontext-coherent positive samples and hallucinated negative samples to build\ncontext-aware preference data iteratively. Finally, we train models using a\ncontext-aware preference loss (C-DPO) that emphasizes discriminative learning\nat the sentence level where hallucinations initially manifest. Experimental\nresults show that SENTINEL can reduce hallucinations by over 90\\% compared to\nthe original model and outperforms the previous state-of-the-art method on both\nhallucination benchmarks and general capabilities benchmarks, demonstrating its\nsuperiority and generalization ability. The models, datasets, and code are\navailable at https://github.com/pspdada/SENTINEL.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12455v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "通过句子级早期干预缓解对象幻觉", "tldr": "提出SENTINEL框架，通过句子级早期干预和领域内偏好学习，显著减少多模态大语言模型中的对象幻觉，无需人工标注。", "motivation": "多模态大语言模型（MLLMs）在跨模态理解方面取得了革命性进展，但仍面临幻觉问题，即生成与视觉输入矛盾的虚假内容。现有缓解方法要么计算成本过高，要么导致训练数据与模型输出之间的分布不匹配。研究发现幻觉主要在文本生成的早期阶段出现并传播。", "method": "提出SENTINEL框架，通过领域内偏好学习实现句子级早期干预，无需人工标注。具体步骤包括：1. 迭代采样模型输出，通过与两个开放词汇检测器交叉验证对象是否存在，将句子分类为幻觉/非幻觉，从而自举高质量领域内偏好对。2. 利用上下文连贯的正面样本和幻觉负面样本迭代构建上下文感知偏好数据。3. 使用上下文感知偏好损失（C-DPO）训练模型，该损失强调在幻觉最初出现的句子级别进行判别性学习。", "result": "实验结果表明，与原始模型相比，SENTINEL可以将幻觉减少90%以上。在幻觉基准测试和通用能力基准测试上均优于现有的最先进方法，证明了其优越性和泛化能力。", "conclusion": "SENTINEL框架通过在句子级别进行早期干预和利用自举的领域内偏好数据，有效且高效地缓解了多模态大语言模型中的对象幻觉问题，并在性能和泛化能力上超越了现有方法。", "translation": "多模态大语言模型（MLLMs）在跨模态理解方面取得了革命性进展，但仍持续面临幻觉问题——即生成与视觉输入相矛盾的虚假内容。现有的幻觉缓解方法要么产生过高的计算成本，要么在训练数据和模型输出之间引入分布不匹配。我们发现一个关键的见解：幻觉主要出现在文本生成的早期阶段，并传播到后续输出中。为了解决这个问题，我们提出了**SENTINEL**（**S**entence-level **E**arly i**N**tervention **T**hrough **IN**-domain pr**E**ference **L**earning），一个无需依赖人工标注的框架。具体而言，我们首先通过迭代采样模型输出，通过与两个开放词汇检测器交叉验证对象是否存在，并将句子分类为幻觉/非幻觉，从而自举高质量的领域内偏好对。随后，我们使用上下文连贯的正面样本和幻觉负面样本迭代构建上下文感知偏好数据。最后，我们使用上下文感知偏好损失（C-DPO）训练模型，该损失强调在幻觉最初显现的句子级别进行判别性学习。实验结果表明，与原始模型相比，SENTINEL可以将幻觉减少90%以上，并在幻觉基准测试和通用能力基准测试上均优于现有的最先进方法，证明了其优越性和泛化能力。模型、数据集和代码可在https://github.com/pspdada/SENTINEL获取。", "summary": "本文提出了一种名为SENTINEL的新框架，旨在解决多模态大语言模型（MLLMs）中常见的对象幻觉问题。该框架基于幻觉主要在文本生成早期阶段出现的洞察，通过句子级早期干预和领域内偏好学习来缓解幻觉，且无需人工标注。SENTINEL通过自举高质量的领域内偏好对，并结合上下文感知偏好损失（C-DPO）进行训练。实验结果显示，SENTINEL能够将幻觉减少90%以上，并超越了现有最先进的方法，展现出卓越的性能和泛化能力。", "keywords": "多模态大语言模型, 对象幻觉, 句子级干预, 偏好学习, C-DPO", "comments": "SENTINEL的创新之处在于其“句子级早期干预”的理念，抓住了幻觉在生成初期萌芽的关键点。更重要的是，它通过自举高质量领域内偏好数据的方法，摆脱了对昂贵人工标注的依赖，大大提高了实用性。其在幻觉缓解效果上的显著提升（超过90%）和在通用能力上的优越表现，使其成为MLLM领域解决幻觉问题的一个重要进展。"}}
{"id": "2507.09592", "title": "THOR: Transformer Heuristics for On-Demand Retrieval", "authors": ["Isaac Shi", "Zeyuan Li", "Fan Liu", "Wenli Wang", "Lewei He", "Yang Yang", "Tianyu Shi"], "categories": ["cs.DB", "cs.AI"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09592v2", "summary": "We introduce the THOR (Transformer Heuristics for On-Demand Retrieval)\nModule, designed and implemented by eSapiens, a secure, scalable engine that\ntransforms natural-language questions into verified, read-only SQL analytics\nfor enterprise databases. The Text-to-SQL module follows a decoupled\norchestration/execution architecture: a Supervisor Agent routes queries, Schema\nRetrieval dynamically injects table and column metadata, and a SQL Generation\nAgent emits single-statement SELECT queries protected by a read-only guardrail.\nAn integrated Self-Correction & Rating loop captures empty results, execution\nerrors, or low-quality outputs and triggers up to five LLM-driven regeneration\nattempts. Finally, a Result Interpretation Agent produces concise,\nhuman-readable insights and hands raw rows to the Insight & Intelligence engine\nfor visualization or forecasting.\n  Smoke tests across finance, sales, and operations scenarios demonstrate\nreliable ad-hoc querying and automated periodic reporting. By embedding schema\nawareness, fault-tolerant execution, and compliance guardrails, the THOR Module\nempowers non-technical users to access live data with zero-SQL simplicity and\nenterprise-grade safety.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09592v2", "cate": "cs.DB", "date": "2025-07-13", "updated": "2025-07-16", "AI": {"title_translation": "THOR：按需检索的Transformer启发式方法", "tldr": "THOR是一个由eSapiens开发的模块，能将自然语言问题转化为安全的只读SQL查询，用于企业数据库分析，使非技术用户也能访问实时数据。", "motivation": "赋能非技术用户以零SQL的简单性和企业级的安全性访问实时数据，解决他们直接与企业数据库交互的困难。", "method": "THOR模块遵循解耦的编排/执行架构。它包含：Supervisor Agent路由查询；Schema Retrieval动态注入表和列元数据；SQL Generation Agent生成受只读护栏保护的单语句SELECT查询；集成的Self-Correction & Rating循环捕获空结果、执行错误或低质量输出，并触发LLM驱动的再生尝试；Result Interpretation Agent生成简洁、人类可读的洞察，并将原始行传递给Insight & Intelligence引擎进行可视化或预测。", "result": "在金融、销售和运营场景的冒烟测试中，展示了可靠的即席查询和自动化定期报告。通过嵌入模式感知、容错执行和合规性护栏，THOR模块使非技术用户能够以零SQL的简单性和企业级安全性访问实时数据。", "conclusion": "THOR模块通过其独特的设计和功能，成功地为非技术用户提供了一种安全、简单的方式来访问和分析企业数据库中的实时数据。", "translation": "我们介绍了THOR（Transformer Heuristics for On-Demand Retrieval）模块，由eSapiens设计和实现，它是一个安全、可扩展的引擎，能将自然语言问题转化为经过验证的只读SQL分析，用于企业数据库。这个文本到SQL模块遵循解耦的编排/执行架构：一个Supervisor Agent负责路由查询，Schema Retrieval动态注入表和列元数据，SQL Generation Agent发出受只读护栏保护的单语句SELECT查询。一个集成的Self-Correction & Rating循环捕获空结果、执行错误或低质量输出，并触发多达五次由LLM驱动的再生尝试。最后，Result Interpretation Agent生成简洁、人类可读的洞察，并将原始行传递给Insight & Intelligence引擎进行可视化或预测。\n在金融、销售和运营场景的冒烟测试中，展示了可靠的即席查询和自动化定期报告。通过嵌入模式感知、容错执行和合规性护栏，THOR模块使非技术用户能够以零SQL的简单性和企业级安全性访问实时数据。", "summary": "THOR是一个由eSapiens开发的Transformer启发式按需检索模块，旨在将自然语言问题转化为安全的只读SQL查询，用于企业数据库分析。它采用解耦架构，包括查询路由、模式检索、SQL生成、自校正与评分循环以及结果解释。该模块通过引入模式感知、容错执行和合规性护栏，赋能非技术用户以高安全性轻松访问实时数据，并在多场景下验证了其可靠性。", "keywords": "Transformer Heuristics, On-Demand Retrieval, Text-to-SQL, 企业数据库, 自然语言处理", "comments": "THOR模块的创新点在于其将自然语言处理与企业级数据库安全和易用性相结合。其解耦架构、LLM驱动的自校正机制以及只读SQL护栏设计，显著提升了系统的鲁棒性和安全性，使得非技术人员也能安全高效地进行数据查询和分析。这对于提高企业数据利用效率具有重要意义。"}}
{"id": "2507.11825", "title": "Peer Review and the Diffusion of Ideas", "authors": ["Binglu Wang", "Zhengnan Ma", "Dashun Wang", "Brian Uzzi"], "categories": ["physics.soc-ph", "cs.SI"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11825v1", "summary": "This study examines a fundamental yet overlooked function of peer review: its\nrole in exposing reviewers to new and unexpected ideas. Leveraging a natural\nexperiment involving over half a million peer review invitations covering both\naccepted and rejected manuscripts, and integrating high-scale bibliographic and\neditorial records for 37,279 submitting authors, we find that exposure to a\nmanuscript's core ideas significantly influences the future referencing\nbehavior and knowledge of reviewer invitees who decline the review invite.\nSpecifically, declining reviewer invitees who could view concise summaries of\nthe manuscript's core ideas not only increase their citations to the manuscript\nitself but also demonstrate expanded breadth, depth, diversity, and prominence\nof citations to the submitting author's broader body of work. Overall, these\nresults suggest peer review substantially influences the spread of scientific\nknowledge. Ironically, while the massive scale of peer review, entailing\nmillions of reviews annually, often drives policy debates about its costs and\nburdens, our findings demonstrate that precisely because of this scale, peer\nreview serves as a powerful yet previously unrecognized engine for idea\ndiffusion, which is central to scientific advances and scholarly communication.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11825v1", "cate": "physics.soc-ph", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "同行评审与思想传播", "tldr": "本研究发现，同行评审的一个被忽视的功能是它能让评审人接触到新的想法，即使是那些拒绝评审但看到摘要的评审人，也会影响他们未来的引用行为和知识，从而表明同行评审是思想传播的强大引擎。", "motivation": "本研究旨在探究同行评审一个被忽视的功能：它在使评审人接触新颖和意想不到的想法方面的作用。", "method": "研究利用了一个涉及超过50万份同行评审邀请的自然实验，这些邀请涵盖了已接受和被拒绝的稿件，并整合了37,279名投稿作者的大规模书目和编辑记录。", "result": "研究发现，接触稿件核心思想显著影响了拒绝评审邀请的评审人未来的引用行为和知识。具体而言，能够查看稿件核心思想的简洁摘要的拒绝评审邀请者不仅增加了对该稿件本身的引用，而且展示了对投稿作者更广泛作品的引用广度、深度、多样性和突出性都有所扩展。", "conclusion": "总的来说，这些结果表明同行评审显著影响了科学知识的传播。讽刺的是，尽管每年数百万次的大规模同行评审常引发关于其成本和负担的政策辩论，但我们的发现表明，正是因为这种规模，同行评审成为了一个强大但此前未被认识到的思想传播引擎，这对于科学进步和学术交流至关重要。", "translation": "本研究探讨了同行评审一个基本但常被忽视的功能：它在使评审人接触新颖和意想不到的想法方面的作用。我们利用一个涉及超过50万份同行评审邀请的自然实验，这些邀请涵盖了已接受和被拒绝的稿件，并整合了37,279名投稿作者的大规模书目和编辑记录，发现接触稿件核心思想显著影响了拒绝评审邀请的评审人未来的引用行为和知识。具体而言，能够查看稿件核心思想的简洁摘要的拒绝评审邀请者不仅增加了对该稿件本身的引用，而且展示了对投稿作者更广泛作品的引用广度、深度、多样性和突出性都有所扩展。总的来说，这些结果表明同行评审显著影响了科学知识的传播。讽刺的是，尽管每年数百万次的大规模同行评审常引发关于其成本和负担的政策辩论，但我们的发现表明，正是因为这种规模，同行评审成为了一个强大但此前未被认识到的思想传播引擎，这对于科学进步和学术交流至关重要。", "summary": "本研究探讨了同行评审在传播新思想方面的被忽视作用。通过分析超过50万份同行评审邀请和37,279名作者的数据，研究发现，即使是那些拒绝评审但接触过稿件核心思想摘要的评审人，其未来的引用行为和知识也会受到显著影响，表现为对稿件本身和作者其他作品的引用增多，且引用广度、深度和多样性增加。这表明同行评审是科学知识传播和思想扩散的强大引擎，其大规模运作反而成为促进科学进步和学术交流的关键因素。", "keywords": "同行评审, 思想传播, 科学知识, 引用行为, 学术交流", "comments": "该论文提出了一种新颖且具有讽刺意味的观点，即同行评审的巨大规模（常被视为负担）实际上是其作为思想传播引擎的关键所在。这项研究揭示了同行评审一个此前未被充分认识的重要功能，对理解科学知识扩散机制具有重要意义。"}}
{"id": "2507.11330", "title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge", "authors": ["Wenqing Wu", "Chengzhi Zhang", "Yi Zhao"], "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Journal of the Association for Information Science and Technology, 2025", "url": "http://arxiv.org/abs/2507.11330v2", "summary": "Novelty is a crucial criterion in the peer review process for evaluating\nacademic papers. Traditionally, it's judged by experts or measure by unique\nreference combinations. Both methods have limitations: experts have limited\nknowledge, and the effectiveness of the combination method is uncertain.\nMoreover, it's unclear if unique citations truly measure novelty. The large\nlanguage model (LLM) possesses a wealth of knowledge, while human experts\npossess judgment abilities that the LLM does not possess. Therefore, our\nresearch integrates the knowledge and abilities of LLM and human experts to\naddress the limitations of novelty assessment. One of the most common types of\nnovelty in academic papers is the introduction of new methods. In this paper,\nwe propose leveraging human knowledge and LLM to assist pretrained language\nmodels (PLMs, e.g. BERT etc.) in predicting the method novelty of papers.\nSpecifically, we extract sentences related to the novelty of the academic paper\nfrom peer review reports and use LLM to summarize the methodology section of\nthe academic paper, which are then used to fine-tune PLMs. In addition, we have\ndesigned a text-guided fusion module with novel Sparse-Attention to better\nintegrate human and LLM knowledge. We compared the method we proposed with a\nlarge number of baselines. Extensive experiments demonstrate that our method\nachieves superior performance.", "comment": "Journal of the Association for Information Science and Technology,\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.11330v2", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "自动化学术论文新颖性评估：一种融合人类与大型语言模型知识的协作方法", "tldr": "本文提出一种结合人类专家知识和大型语言模型（LLM）来自动化评估学术论文方法新颖性的方法，通过微调预训练语言模型（PLMs）并引入稀疏注意力融合模块，实现了卓越的性能。", "motivation": "论文新颖性是同行评审的关键标准，但传统评估方法（专家判断、独特参考文献组合）存在局限性，如专家知识有限、组合方法有效性不确定。大型语言模型拥有丰富知识，而人类专家拥有LLM不具备的判断能力，因此需要整合两者来解决新颖性评估的局限性。", "method": "研究整合LLM和人类专家的知识和能力。具体方法是：提取同行评审报告中与论文新颖性相关的句子，并利用LLM总结论文的方法论部分，然后用这些数据微调预训练语言模型（PLMs，如BERT）。此外，设计了一个带有稀疏注意力的文本引导融合模块，以更好地整合人类和LLM的知识。", "result": "实验结果表明，所提出的方法与大量基线方法相比，取得了卓越的性能。", "conclusion": "通过整合人类知识和大型语言模型的能力，可以有效提升学术论文新颖性评估的准确性和自动化水平。", "translation": "新颖性是同行评审过程中评估学术论文的关键标准。传统上，它由专家判断或通过独特的参考文献组合来衡量。这两种方法都有局限性：专家知识有限，且组合方法的有效性不确定。此外，不清楚独特的引用是否真正衡量了新颖性。大型语言模型（LLM）拥有丰富的知识，而人类专家拥有LLM不具备的判断能力。因此，我们的研究整合了LLM和人类专家的知识和能力，以解决新颖性评估的局限性。学术论文中最常见的一种新颖性是引入新方法。在本文中，我们提出利用人类知识和LLM来辅助预训练语言模型（PLMs，例如BERT等）预测论文的方法新颖性。具体来说，我们从同行评审报告中提取与学术论文新颖性相关的句子，并使用LLM总结学术论文的方法论部分，然后将这些数据用于微调PLMs。此外，我们设计了一个带有新颖稀疏注意力的文本引导融合模块，以更好地整合人类和LLM的知识。我们将我们提出的方法与大量基线进行了比较。广泛的实验表明，我们的方法取得了卓越的性能。", "summary": "本文提出一种自动化评估学术论文方法新颖性的协作方法，旨在克服传统评估方法的局限性。该方法创新性地结合了人类专家知识和大型语言模型（LLM）的能力。具体而言，通过从同行评审报告中提取新颖性相关句子并利用LLM总结论文方法部分，来微调预训练语言模型（PLMs）。同时，引入了一个带有稀疏注意力的文本引导融合模块，以有效整合多源知识。实验结果证明，该方法在性能上超越了现有基线。", "keywords": "学术论文评估, 新颖性评估, 大型语言模型, 预训练语言模型, 混合智能", "comments": "这篇论文的创新点在于它提出了一种混合智能的方法，结合了人类专家对新颖性的判断能力和大型语言模型的知识广度，以解决学术论文新颖性评估的挑战。特别地，通过利用评审报告中的具体反馈和LLM对方法论的总结来微调PLMs，并引入了新型的稀疏注意力融合模块，这为自动化评审工具的发展提供了一个有前景的方向，有望提高同行评审的效率和质量。"}}
{"id": "2507.12444", "title": "BitWave: Exploiting Column-Based Bit-Level Sparsity for Deep Learning Acceleration", "authors": ["Man Shi", "Vikram Jain", "Antony Joseph", "Maurice Meijer", "Marian Verhelst"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      15 pages, 18 figures, 2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA)", "url": "http://arxiv.org/abs/2507.12444v1", "summary": "Bit-serial computation facilitates bit-wise sequential data processing,\noffering numerous benefits, such as a reduced area footprint and\ndynamically-adaptive computational precision. It has emerged as a prominent\napproach, particularly in leveraging bit-level sparsity in Deep Neural Networks\n(DNNs). However, existing bit-serial accelerators exploit bit-level sparsity to\nreduce computations by skipping zero bits, but they suffer from inefficient\nmemory accesses due to the irregular indices of the non-zero bits.\n  As memory accesses typically are the dominant contributor to DNN accelerator\nperformance, this paper introduces a novel computing approach called\n\"bit-column-serial\" and a compatible architecture design named \"BitWave.\"\nBitWave harnesses the advantages of the \"bit-column-serial\" approach,\nleveraging structured bit-level sparsity in combination with dynamic dataflow\ntechniques. This achieves a reduction in computations and memory footprints\nthrough redundant computation skipping and weight compression. BitWave is able\nto mitigate the performance drop or the need for retraining that is typically\nassociated with sparsity-enhancing techniques using a post-training\noptimization involving selected weight bit-flips. Empirical studies conducted\non four deep-learning benchmarks demonstrate the achievements of BitWave: (1)\nMaximally realize 13.25x higher speedup, 7.71x efficiency compared to\nstate-of-the-art sparsity-aware accelerators. (2) Occupying 1.138 mm2 area and\nconsuming 17.56 mW power in 16nm FinFet process node.", "comment": "15 pages, 18 figures, 2024 IEEE International Symposium on\n  High-Performance Computer Architecture (HPCA)", "pdf_url": "http://arxiv.org/pdf/2507.12444v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "BitWave: 利用列式位级稀疏性加速深度学习", "tldr": "现有的位串行加速器在利用位级稀疏性时存在内存访问效率低下的问题，因为非零位索引不规则。BitWave提出了一种“位列串行”计算方法和兼容架构，通过利用结构化位级稀疏性和动态数据流，减少了计算量和内存占用，并实现了显著的加速和效率提升。", "motivation": "现有的位串行加速器通过跳过零位来利用位级稀疏性以减少计算量，但由于非零位的不规则索引，它们遭受低效的内存访问。内存访问通常是深度神经网络（DNN）加速器性能的主要贡献者。", "method": "本文提出了一种名为“位列串行”的新型计算方法和名为“BitWave”的兼容架构设计。BitWave利用“位列串行”方法的优势，结合动态数据流技术利用结构化位级稀疏性，通过冗余计算跳过和权重压缩来减少计算量和内存占用。它还通过涉及选择性权重位翻转的训练后优化来缓解性能下降或再训练的需求。", "result": "1. 与最先进的稀疏感知加速器相比，最大实现13.25倍的速度提升和7.71倍的效率。\n2. 在16纳米FinFet工艺节点中占用1.138平方毫米面积并消耗17.56毫瓦功率。", "conclusion": "BitWave通过有效利用列式位级稀疏性，显著提升了深度学习加速器的性能（速度和效率）并降低了资源消耗（面积和功耗），成功解决了现有位串行方法中内存访问效率低下的问题。", "translation": "位串行计算促进了位级顺序数据处理，提供了诸多优势，例如减小的面积占用和动态自适应的计算精度。它已成为一种突出的方法，特别是在利用深度神经网络（DNN）中的位级稀疏性方面。然而，现有的位串行加速器通过跳过零位来利用位级稀疏性以减少计算量，但由于非零位的不规则索引，它们遭受低效的内存访问。\n由于内存访问通常是DNN加速器性能的主要贡献者，本文引入了一种新颖的计算方法“位列串行”和兼容的架构设计“BitWave”。BitWave利用“位列串行”方法的优势，结合动态数据流技术利用结构化位级稀疏性。这通过冗余计算跳过和权重压缩实现了计算量和内存占用的减少。BitWave能够通过涉及选择性权重位翻转的训练后优化来缓解通常与稀疏性增强技术相关的性能下降或再训练的需求。在四个深度学习基准上进行的实证研究证明了BitWave的成就：（1）与最先进的稀疏感知加速器相比，最大实现13.25倍的速度提升，7.71倍的效率。（2）在16纳米FinFet工艺节点中占用1.138平方毫米面积并消耗17.56毫瓦功率。", "summary": "本文介绍了BitWave，一种新型深度学习加速器，旨在解决现有位串行加速器中内存访问效率低下的问题。通过提出“位列串行”计算方法和架构，BitWave利用结构化位级稀疏性和动态数据流，通过冗余计算跳过和权重压缩显著减少了计算量和内存占用。它还包含一个训练后优化以保持性能。实证结果表明，与最先进的加速器相比，BitWave实现了高达13.25倍的速度提升和7.71倍的效率，同时具有低面积和功耗。", "keywords": "位串行计算, 深度学习加速, 位级稀疏性, BitWave, 内存访问效率", "comments": "该论文的创新之处在于通过引入“位列串行”方法并利用结构化位级稀疏性来解决位串行计算的内存访问瓶颈，这与之前处理不规则非零位的工作形成关键区别。在不进行再训练的情况下，通过训练后优化实现稀疏性增强，这也是一个显著的实际优势。"}}
{"id": "2506.04135", "title": "macOSWorld: A Multilingual Interactive Benchmark for GUI Agents", "authors": ["Pei Yang", "Hai Ci", "Mike Zheng Shou"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.04135v3", "summary": "Graphical User Interface (GUI) agents show promising capabilities for\nautomating computer-use tasks and facilitating accessibility, but existing\ninteractive benchmarks are mostly English-only, covering web-use or Windows,\nLinux, and Android environments, but not macOS. macOS is a major OS with\ndistinctive GUI patterns and exclusive applications. To bridge the gaps, we\npresent macOSWorld, the first comprehensive benchmark for evaluating GUI agents\non macOS. macOSWorld features 202 multilingual interactive tasks across 30\napplications (28 macOS-exclusive), with task instructions and OS interfaces\noffered in 5 languages (English, Chinese, Arabic, Japanese, and Russian). As\nGUI agents are shown to be vulnerable to deception attacks, macOSWorld also\nincludes a dedicated safety benchmarking subset. Our evaluation on six GUI\nagents reveals a dramatic gap: proprietary computer-use agents lead at above\n30% success rate, while open-source lightweight research models lag at below\n5%, highlighting the need for macOS domain adaptation. Multilingual benchmarks\nalso expose common weaknesses, especially in Arabic, with a 28.8% average\ndegradation compared to English. Results from safety benchmarking also\nhighlight that deception attacks are more general and demand immediate\nattention. macOSWorld is available at https://github.com/showlab/macosworld.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.04135v3", "cate": "cs.AI", "date": "2025-06-04", "updated": "2025-07-16", "AI": {"title_translation": "macOSWorld：一个针对GUI代理的多语言交互式基准", "tldr": "macOSWorld是一个针对GUI代理的macOS多语言交互式基准，揭示了现有模型在macOS领域适应性、多语言能力和安全方面的不足。", "motivation": "现有GUI代理的交互式基准主要限于英语，且未覆盖macOS平台，而macOS是一个拥有独特GUI模式和专属应用的重要操作系统。此外，GUI代理易受欺骗攻击，但现有基准未充分考虑安全性。", "method": "提出了macOSWorld，这是首个用于评估macOS上GUI代理的综合基准。它包含202个多语言交互任务，涉及30个应用程序（其中28个为macOS独占），任务指令和操作系统界面支持5种语言。macOSWorld还包含一个专门用于安全基准测试的子集。研究人员在六个GUI代理上进行了评估。", "result": "评估显示，专有计算机使用代理的成功率超过30%，而开源轻量级研究模型的成功率低于5%，这突显了macOS领域适应的必要性。多语言基准测试揭示了常见弱点，尤其是在阿拉伯语中，相较于英语平均性能下降了28.8%。安全基准测试结果也表明欺骗攻击更具普遍性，需要立即关注。", "conclusion": "macOSWorld基准揭示了当前GUI代理在macOS领域适应性、多语言能力（尤其是在非英语语言如阿拉伯语方面）以及抵抗欺骗攻击方面的显著差距，强调了未来研究和开发的迫切需求。", "translation": "图形用户界面（GUI）代理在自动化计算机使用任务和促进可访问性方面显示出巨大的潜力，但现有交互式基准大多仅限于英语，涵盖网络使用或Windows、Linux和Android环境，而未涉及macOS。macOS是一个主要的操作系统，具有独特的GUI模式和独占应用程序。为了弥补这些空白，我们提出了macOSWorld，这是第一个用于评估macOS上GUI代理的综合基准。macOSWorld包含202个多语言交互任务，涉及30个应用程序（其中28个为macOS独占），任务指令和操作系统界面提供5种语言（英语、中文、阿拉伯语、日语和俄语）。由于GUI代理已被证明容易受到欺骗攻击，macOSWorld还包含一个专门的安全基准测试子集。我们对六个GUI代理的评估揭示了巨大的差距：专有计算机使用代理的成功率超过30%，而开源轻量级研究模型的成功率低于5%，这突显了macOS领域适应的必要性。多语言基准测试也暴露了普遍弱点，尤其是在阿拉伯语中，相较于英语平均性能下降了28.8%。安全基准测试结果也强调欺骗攻击更具普遍性，需要立即关注。macOSWorld可在https://github.com/showlab/macosworld获取。", "summary": "本文推出了macOSWorld，首个针对macOS平台GUI代理的多语言交互式综合基准。该基准包含202个跨30个应用的交互任务，支持五种语言，并专设安全评估子集。通过对六个GUI代理的评估，研究发现专有模型表现优于开源模型，并揭示了模型在macOS领域适应性、多语言处理能力（特别是阿拉伯语）以及抵抗欺骗攻击方面的显著不足，强调了未来研究的重点方向。", "keywords": "GUI代理, macOS, 多语言基准, 交互式任务, 安全性评估", "comments": "macOSWorld的创新之处在于它是首个专注于macOS平台并支持多语言和安全评估的GUI代理基准。这解决了现有基准在操作系统覆盖范围和语言多样性上的局限性，并首次将欺骗攻击纳入交互式GUI代理的评估中。其重要性在于，它揭示了当前GUI代理在实际macOS环境下的性能瓶颈，特别是在非英语环境和安全性方面的不足，为未来GUI代理的开发提供了明确的研究方向和评估工具。"}}
{"id": "2507.07511", "title": "Uncertainty Quantification for Motor Imagery BCI -- Machine Learning vs. Deep Learning", "authors": ["Joris Suurmeijer", "Ivo Pascal de Jong", "Matias Valdenegro-Toro", "Andreea Ioana Sburlea"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures; fixed typos", "url": "http://arxiv.org/abs/2507.07511v2", "summary": "Brain-computer interfaces (BCIs) turn brain signals into functionally useful\noutput, but they are not always accurate. A good Machine Learning classifier\nshould be able to indicate how confident it is about a given classification, by\ngiving a probability for its classification. Standard classifiers for Motor\nImagery BCIs do give such probabilities, but research on uncertainty\nquantification has been limited to Deep Learning. We compare the uncertainty\nquantification ability of established BCI classifiers using Common Spatial\nPatterns (CSP-LDA) and Riemannian Geometry (MDRM) to specialized methods in\nDeep Learning (Deep Ensembles and Direct Uncertainty Quantification) as well as\nstandard Convolutional Neural Networks (CNNs).\n  We found that the overconfidence typically seen in Deep Learning is not a\nproblem in CSP-LDA and MDRM. We found that MDRM is underconfident, which we\nsolved by adding Temperature Scaling (MDRM-T). CSP-LDA and MDRM-T give the best\nuncertainty estimates, but Deep Ensembles and standard CNNs give the best\nclassifications. We show that all models are able to separate between easy and\ndifficult estimates, so that we can increase the accuracy of a Motor Imagery\nBCI by rejecting samples that are ambiguous.", "comment": "6 pages, 3 figures; fixed typos", "pdf_url": "http://arxiv.org/pdf/2507.07511v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-16", "AI": {"title_translation": "运动想象脑机接口的不确定性量化——机器学习 vs. 深度学习", "tldr": "比较了机器学习和深度学习在运动想象BCI中进行不确定性量化的能力，发现传统方法在不确定性估计方面表现更好，而深度学习在分类精度上更优。所有模型都能区分难易样本以提高准确性。", "motivation": "脑机接口（BCI）的准确性并非总是可靠，而一个好的机器学习分类器应能指示其分类置信度。现有关于不确定性量化的研究主要集中在深度学习领域，但标准机器学习方法也提供概率。因此，本研究旨在比较机器学习和深度学习方法在运动想象BCI中进行不确定性量化的能力。", "method": "本研究比较了使用通用空间模式（CSP-LDA）和黎曼几何（MDRM）的传统BCI分类器与深度学习方法（包括Deep Ensembles、Direct Uncertainty Quantification和标准卷积神经网络CNNs）的不确定性量化能力。针对MDRM的欠置信问题，引入了温度标定（Temperature Scaling）形成了MDRM-T。", "result": "研究发现，深度学习中常见的过度自信问题在CSP-LDA和MDRM中不存在。MDRM存在欠置信问题，通过添加温度标定（MDRM-T）得到解决。CSP-LDA和MDRM-T提供了最佳的不确定性估计。然而，Deep Ensembles和标准CNNs在分类精度上表现最佳。所有模型都能够区分简单和困难的估计，这意味着可以通过拒绝模糊样本来提高运动想象BCI的准确性。", "conclusion": "在运动想象脑机接口中，机器学习方法（CSP-LDA和MDRM-T）在不确定性估计方面优于深度学习方法，而深度学习方法（Deep Ensembles和CNNs）在分类精度上表现更优。通过识别并拒绝模糊样本，可以有效提高BCI的整体准确性。", "translation": "脑机接口（BCI）将脑信号转化为功能上有用的输出，但它们并非总是准确的。一个好的机器学习分类器应该能够通过给出分类的概率来指示其对给定分类的置信度。运动想象BCI的标准分类器确实提供了这样的概率，但关于不确定性量化的研究仅限于深度学习。我们比较了使用通用空间模式（CSP-LDA）和黎曼几何（MDRM）的成熟BCI分类器与深度学习中专门方法（深度集成和直接不确定性量化）以及标准卷积神经网络（CNN）的不确定性量化能力。我们发现，在CSP-LDA和MDRM中，深度学习中常见的过度自信并不是问题。我们发现MDRM存在欠置信问题，我们通过添加温度标定（MDRM-T）解决了这个问题。CSP-LDA和MDRM-T提供了最佳的不确定性估计，但深度集成和标准CNN提供了最佳分类。我们表明，所有模型都能够区分简单和困难的估计，因此我们可以通过拒绝模糊样本来提高运动想象BCI的准确性。", "summary": "这项研究比较了机器学习和深度学习方法在运动想象脑机接口（BCI）中进行不确定性量化的能力。结果显示，传统的机器学习方法（如CSP-LDA和经过温度标定的MDRM-T）在不确定性估计方面表现最佳，而深度学习方法（Deep Ensembles和CNNs）在分类准确性方面更优。研究还发现，所有模型都能识别并拒绝模糊样本，从而有效提高BCI的整体准确性。", "keywords": "运动想象BCI, 不确定性量化, 机器学习, 深度学习, 分类器", "comments": "这篇论文的创新点在于系统地比较了传统机器学习和深度学习在脑机接口不确定性量化方面的表现。它揭示了深度学习在分类精度上的优势，以及传统方法在提供可靠不确定性估计方面的潜力。特别指出深度学习的过度自信和MDRM的欠置信问题，并提出了MDRM-T的解决方案，这对于BCI的实际应用具有重要意义。通过拒绝模糊样本来提高准确性的发现也提供了一个实用的策略。"}}
{"id": "2507.11947", "title": "RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation", "authors": ["Geon Park", "Seon Bin Kim", "Gunho Jung", "Seong-Whan Lee"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 Pages", "url": "http://arxiv.org/abs/2507.11947v1", "summary": "With recent advancements in text-to-image (T2I) models, effectively\ngenerating multiple instances within a single image prompt has become a crucial\nchallenge. Existing methods, while successful in generating positions of\nindividual instances, often struggle to account for relationship discrepancy\nand multiple attributes leakage. To address these limitations, this paper\nproposes the relation-aware disentangled learning (RaDL) framework. RaDL\nenhances instance-specific attributes through learnable parameters and\ngenerates relation-aware image features via Relation Attention, utilizing\naction verbs extracted from the global prompt. Through extensive evaluations on\nbenchmarks such as COCO-Position, COCO-MIG, and DrawBench, we demonstrate that\nRaDL outperforms existing methods, showing significant improvements in\npositional accuracy, multiple attributes consideration, and the relationships\nbetween instances. Our results present RaDL as the solution for generating\nimages that consider both the relationships and multiple attributes of each\ninstance within the multi-instance image.", "comment": "6 Pages", "pdf_url": "http://arxiv.org/pdf/2507.11947v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "RaDL：用于多实例文本到图像生成的关联感知解耦学习", "tldr": "RaDL是一个新的框架，通过关联感知解耦学习解决了多实例文本到图像生成中关系差异和多属性泄露问题，并在多个基准测试中表现优于现有方法。", "motivation": "现有文本到图像生成方法在处理单张图片中多实例生成时，虽然能成功生成个体实例的位置，但往往难以解决关系差异和多属性泄露问题。", "method": "本文提出了关联感知解耦学习（RaDL）框架。RaDL通过可学习参数增强实例特定属性，并通过利用从全局提示中提取的动作动词的“关系注意力”生成关联感知图像特征。", "result": "通过在COCO-Position、COCO-MIG和DrawBench等基准测试上的广泛评估，RaDL在位置准确性、多属性考虑和实例间关系方面显示出显著改进，并优于现有方法。", "conclusion": "RaDL是解决在多实例图像中同时考虑实例间关系和多属性的图像生成问题的有效方案。", "translation": "随着文本到图像（T2I）模型的最新进展，在单个图像提示中有效生成多个实例已成为一个关键挑战。现有方法虽然在生成单个实例的位置方面取得了成功，但往往难以解决关系差异和多属性泄露问题。为了解决这些局限性，本文提出了关联感知解耦学习（RaDL）框架。RaDL通过可学习参数增强实例特定属性，并通过利用从全局提示中提取的动作动词的“关系注意力”生成关联感知图像特征。通过在COCO-Position、COCO-MIG和DrawBench等基准测试上的广泛评估，我们证明了RaDL优于现有方法，在位置准确性、多属性考虑和实例间关系方面显示出显著改进。我们的结果表明，RaDL是生成图像的解决方案，该方案在多实例图像中同时考虑了每个实例的关系和多属性。", "summary": "本文提出了RaDL（关联感知解耦学习）框架，旨在解决文本到图像生成中多实例场景下的关系差异和多属性泄露问题。RaDL通过增强实例特定属性和引入关系注意力机制来生成关联感知特征。实验结果表明，RaDL在多个基准测试中显著提升了多实例图像生成的位置准确性、多属性处理能力以及实例间的关系表现，优于现有方法。", "keywords": "文本到图像生成, 多实例, 关系感知, 解耦学习, RaDL", "comments": "该论文通过引入“关系注意力”和解耦学习，有效地解决了多实例文本到图像生成中的关键挑战，即如何准确处理实例间的复杂关系和避免属性泄露。其创新点在于将全局提示中的动作动词用于关系感知特征生成，这对于提升生成图像的语义准确性和上下文连贯性至关重要。"}}
{"id": "2504.01048", "title": "How does Watermarking Affect Visual Language Models in Document Understanding?", "authors": ["Chunxue Xu", "Yiwei Wang", "Bryan Hooi", "Yujun Cai", "Songze Li"], "categories": ["cs.CV", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to COLM 2025", "url": "http://arxiv.org/abs/2504.01048v2", "summary": "Visual Language Models (VLMs) have become foundational models for document\nunderstanding tasks, widely used in the processing of complex multimodal\ndocuments across domains such as finance, law, and academia. However, documents\noften contain noise-like information, such as watermarks, which inevitably\nleads us to inquire: \\emph{Do watermarks degrade the performance of VLMs in\ndocument understanding?} To address this, we propose a novel evaluation\nframework to investigate the effect of visible watermarks on VLMs performance.\nWe takes into account various factors, including different types of document\ndata, the positions of watermarks within documents and variations in watermark\ncontent. Our experimental results reveal that VLMs performance can be\nsignificantly compromised by watermarks, with performance drop rates reaching\nup to 36\\%. We discover that \\emph{scattered} watermarks cause stronger\ninterference than centralized ones, and that \\emph{semantic contents} in\nwatermarks creates greater disruption than simple visual occlusion. Through\nattention mechanism analysis and embedding similarity examination, we find that\nthe performance drops are mainly attributed to that watermarks 1) force\nwidespread attention redistribution, and 2) alter semantic representation in\nthe embedding space. Our research not only highlights significant challenges in\ndeploying VLMs for document understanding, but also provides insights towards\ndeveloping robust inference mechanisms on watermarked documents.", "comment": "Accepted to COLM 2025", "pdf_url": "http://arxiv.org/pdf/2504.01048v2", "cate": "cs.CV", "date": "2025-04-01", "updated": "2025-07-16", "AI": {"title_translation": "水印如何影响文档理解中的视觉语言模型？", "tldr": "研究发现水印会显著降低视觉语言模型在文档理解任务中的性能，分散式和语义水印影响更大，原因在于注意力重新分配和语义表示改变。", "motivation": "文档中常见的水印等噪声信息可能影响视觉语言模型（VLMs）在文档理解任务中的性能。因此，本研究旨在探究水印是否会降低VLMs在文档理解方面的表现。", "method": "本研究提出了一个新的评估框架，用于调查可见水印对视觉语言模型性能的影响。该框架考虑了多种因素，包括不同类型的文档数据、水印在文档中的位置以及水印内容的变化。研究还通过注意力机制分析和嵌入相似性检查来探究性能下降的原因。", "result": "实验结果显示，水印会显著损害视觉语言模型的性能，性能下降率高达36%。研究发现，分散式水印比集中式水印造成更强的干扰，且水印中的语义内容比简单的视觉遮挡造成更大的破坏。性能下降主要归因于水印强制了广泛的注意力重新分配，并改变了嵌入空间中的语义表示。", "conclusion": "本研究不仅揭示了在文档理解中部署视觉语言模型所面临的重大挑战，也为开发针对带水印文档的鲁棒推理机制提供了见解。", "translation": "视觉语言模型（VLMs）已成为文档理解任务的基础模型，广泛应用于金融、法律和学术等领域中复杂多模态文档的处理。然而，文档通常包含水印等噪声信息，这不可避免地促使我们思考：水印是否会降低VLMs在文档理解中的性能？为了解决这个问题，我们提出了一个新的评估框架，以研究可见水印对VLMs性能的影响。我们考虑了各种因素，包括不同类型的文档数据、水印在文档中的位置以及水印内容的变化。我们的实验结果表明，VLMs的性能可能会被水印显著损害，性能下降率高达36%。我们发现分散式水印比集中式水印造成更强的干扰，并且水印中的语义内容比简单的视觉遮挡造成更大的破坏。通过注意力机制分析和嵌入相似性检查，我们发现性能下降主要归因于水印1）强制了广泛的注意力重新分配，以及2）改变了嵌入空间中的语义表示。我们的研究不仅突出了在文档理解中部署VLMs的重大挑战，而且为开发针对带水印文档的鲁棒推理机制提供了见解。", "summary": "本研究探讨了水印对视觉语言模型（VLMs）在文档理解任务中性能的影响。通过提出一个新颖的评估框架，研究发现水印会显著降低VLMs的性能，下降幅度高达36%。其中，分散式水印和包含语义内容的水印造成的干扰更大。进一步分析表明，性能下降的原因在于水印导致了注意力机制的重新分配和嵌入空间中语义表示的改变。这项工作强调了在带水印文档上部署VLMs所面临的挑战，并为开发更鲁棒的推理机制提供了方向。", "keywords": "水印, 视觉语言模型, 文档理解, 性能下降, 注意力机制", "comments": "这项研究揭示了一个在实际应用中非常重要但常被忽视的问题：水印对视觉语言模型性能的负面影响。其创新之处在于提出了一个全面的评估框架，并深入分析了水印影响性能的内在机制（注意力重分配和语义表示改变）。这对于部署鲁棒的文档理解系统具有重要指导意义。"}}
{"id": "2507.12221", "title": "Novel Approach to Dual-Channel Estimation in Integrated Sensing and Communications for 6G", "authors": ["Alejandro Castilla", "Saúl Fenollosa", "Monika Drozdowska", "Alejandro Lopez-Escudero", "Sergio Micò-Rosa", "Narcis Cardona"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      6 pages, 13 figures. Accepted for publication at the 2024 IEEE 35th International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)", "url": "http://arxiv.org/abs/2507.12221v1", "summary": "Integrated Sensing and Communication (ISAC) design is crucial for 6G and\nharmonizes environmental data sensing with communication, emphasizing the need\nto understand and model these elements. This paper delves into dual-channel\nmodels for ISAC, employing channel extraction techniques to validate and\nenhance accuracy. Focusing on millimeter wave (mmWave) radars, it explores the\nextraction of the bistatic sensing channel from monostatic measurements and\nsubsequent communication channel estimation. The proposed methods involve\ninterference extraction, module and phase correlation analyses, chirp\nclustering, and auto-clutter reduction. A comprehensive set-up in an anechoic\nchamber with controlled scenarios evaluates the proposed techniques,\ndemonstrating successful channel extraction and validation through Root Mean\nSquare Delay Spread (RMS DS), Power Delay Profile (PDP), and Angle of Arrival\n(AoA) analysis. Comparison with Ray-Tracing (RT) simulations confirms the\neffectiveness of the proposed approach, presenting an innovative stride towards\nfully integrated sensing and communication in future networks.", "comment": "6 pages, 13 figures. Accepted for publication at the 2024 IEEE 35th\n  International Symposium on Personal, Indoor and Mobile Radio Communications\n  (PIMRC)", "pdf_url": "http://arxiv.org/pdf/2507.12221v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "6G集成感知与通信中双通道估计的新方法", "tldr": "该论文提出了一种在6G集成感知与通信（ISAC）中对毫米波雷达进行双通道估计的新方法，通过信道提取技术实现并验证了感知和通信信道的有效性。", "motivation": "集成感知与通信（ISAC）设计对于6G至关重要，需要理解并建模感知和通信元素。", "method": "本文深入研究了ISAC的双通道模型，采用信道提取技术来验证和提高准确性。重点关注毫米波（mmWave）雷达，探索从单站测量中提取双站感知信道以及随后的通信信道估计。所提出的方法包括干扰提取、模量和相位相关分析、啁啾聚类和自动杂波抑制。通过在消声室中进行的全面设置和受控场景评估所提出的技术，并通过均方根时延扩展（RMS DS）、功率时延剖面（PDP）和到达角（AoA）分析进行验证，同时与射线追踪（RT）仿真进行比较。", "result": "成功进行了信道提取和验证，通过均方根时延扩展（RMS DS）、功率时延剖面（PDP）和到达角（AoA）分析进行了验证。与射线追踪（RT）仿真的比较证实了所提出方法的有效性。", "conclusion": "所提出的方法是迈向未来网络中完全集成感知和通信的创新一步。", "translation": "集成感知与通信（ISAC）设计对于6G至关重要，它协调了环境数据感知与通信，强调了理解和建模这些元素的必要性。本文深入研究了ISAC的双通道模型，采用信道提取技术来验证和提高准确性。论文重点关注毫米波（mmWave）雷达，探讨了如何从单站测量中提取双站感知信道，以及随后的通信信道估计。所提出的方法包括干扰提取、模量和相位相关分析、啁啾聚类和自动杂波抑制。通过在消声室中进行的全面设置和受控场景，对所提出的技术进行了评估，并通过均方根时延扩展（RMS DS）、功率时延剖面（PDP）和到达角（AoA）分析，证明了成功的信道提取和验证。与射线追踪（RT）模拟的比较证实了所提出方法的有效性，为未来网络中完全集成的感知与通信迈出了创新的一步。", "summary": "本文提出了一种在6G集成感知与通信（ISAC）中对毫米波雷达进行双通道估计的新方法。该方法采用信道提取技术，能够从单站测量中成功提取双站感知信道并进行通信信道估计。所提出的技术包括干扰提取、相关分析、啁啾聚类和自动杂波抑制，并在消声室中通过实验和与射线追踪模拟的比较验证了其有效性，为6G ISAC的发展提供了创新的解决方案。", "keywords": "集成感知与通信, 双通道估计, 毫米波雷达, 信道提取, 6G", "comments": "该论文提出了一种新颖的双通道估计方法，特别是在毫米波雷达环境下，通过一系列创新的信道提取和处理技术，有效解决了ISAC中感知与通信信道建模的挑战，其实验验证和与仿真对比进一步增强了研究的可靠性和实用性。"}}
{"id": "2507.11954", "title": "The benefits of query-based KGQA systems for complex and temporal questions in LLM era", "authors": ["Artem Alekseev", "Mikhail Chaichuk", "Miron Butko", "Alexander Panchenko", "Elena Tutubalina", "Oleg Somov"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      15 pages, 3 figures, 7 tables", "url": "http://arxiv.org/abs/2507.11954v1", "summary": "Large language models excel in question-answering (QA) yet still struggle\nwith multi-hop reasoning and temporal questions. Query-based knowledge graph QA\n(KGQA) offers a modular alternative by generating executable queries instead of\ndirect answers. We explore multi-stage query-based framework for WikiData QA,\nproposing multi-stage approach that enhances performance on challenging\nmulti-hop and temporal benchmarks. Through generalization and rejection\nstudies, we evaluate robustness across multi-hop and temporal QA datasets.\nAdditionally, we introduce a novel entity linking and predicate matching method\nusing CoT reasoning. Our results demonstrate the potential of query-based\nmulti-stage KGQA framework for improving multi-hop and temporal QA with small\nlanguage models. Code and data: https://github.com/ar2max/NLDB-KGQA-System", "comment": "15 pages, 3 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.11954v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "LLM时代基于查询的KGQA系统在复杂和时间性问题上的优势", "tldr": "尽管大型语言模型在问答方面表现出色，但在处理多跳推理和时间性问题时仍面临挑战。本文提出了一种基于查询的多阶段知识图谱问答（KGQA）框架，通过生成可执行查询来提升对这些复杂问题的性能，并引入了基于CoT推理的实体链接和谓词匹配新方法，证明了其在小型语言模型中改善多跳和时间性问答的潜力。", "motivation": "大型语言模型在处理多跳推理和时间性问题时表现不佳，因此需要一种替代方案来解决这些复杂问答的挑战。", "method": "本文探索了一种基于查询的多阶段知识图谱问答（KGQA）框架，特别是在WikiData问答中应用。该方法通过生成可执行查询而非直接答案，提升了在多跳和时间性基准测试上的性能。此外，引入了一种使用CoT（思维链）推理的新型实体链接和谓词匹配方法。", "result": "研究结果表明，基于查询的多阶段KGQA框架在改善多跳和时间性问答方面具有潜力，即使是使用小型语言模型也能实现。通过泛化和拒绝研究，评估了其在多跳和时间性QA数据集上的鲁棒性。", "conclusion": "基于查询的多阶段知识图谱问答（KGQA）系统能够有效提升大型语言模型在处理复杂和时间性问题时的性能，尤其对于多跳推理问题，并展示了其在小型语言模型中的应用潜力。", "translation": "大型语言模型在问答（QA）方面表现出色，但在多跳推理和时间性问题上仍面临挑战。基于查询的知识图谱问答（KGQA）提供了一种模块化替代方案，它生成可执行查询而非直接答案。我们探索了针对WikiData QA的多阶段基于查询的框架，提出了一种多阶段方法，该方法提升了在具有挑战性的多跳和时间性基准测试上的性能。通过泛化和拒绝研究，我们评估了其在多跳和时间性QA数据集上的鲁棒性。此外，我们引入了一种使用CoT推理的新型实体链接和谓词匹配方法。我们的结果证明了基于查询的多阶段KGQA框架在利用小型语言模型改进多跳和时间性QA方面的潜力。代码和数据：https://github.com/ar2max/NLDB-KGQA-System", "summary": "本文针对大型语言模型在处理复杂多跳和时间性问答方面的不足，提出了一种基于查询的多阶段知识图谱问答（KGQA）框架。该框架通过生成可执行查询而非直接答案，显著提升了在WikiData上解决此类问题的性能。研究还引入了基于思维链（CoT）推理的新型实体链接和谓词匹配方法，并通过泛化和拒绝研究验证了其鲁棒性，最终证明了该框架即使在小型语言模型中也能有效改善多跳和时间性问答。", "keywords": "知识图谱问答, 多跳推理, 时间性问题, 大型语言模型, 思维链推理", "comments": "这篇论文的创新点在于提出了一个结合查询生成和多阶段处理的KGQA框架，以弥补LLM在复杂推理上的不足。通过引入CoT推理进行实体链接和谓词匹配，提升了系统的准确性和鲁棒性。其重要性在于为LLM时代解决知识密集型和推理型问答提供了一个有前景的混合方法，并且强调了小型语言模型的潜力。"}}
{"id": "2506.22027", "title": "Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method", "authors": ["Han Wang", "Shengyang Li", "Jian Yang", "Yuxuan Liu", "Yixuan Lv", "Zhuang Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2506.22027v3", "summary": "Detecting and tracking ground objects using earth observation imagery remains\na significant challenge in the field of remote sensing. Continuous maritime\nship tracking is crucial for applications such as maritime search and rescue,\nlaw enforcement, and shipping analysis. However, most current ship tracking\nmethods rely on geostationary satellites or video satellites. The former offer\nlow resolution and are susceptible to weather conditions, while the latter have\nshort filming durations and limited coverage areas, making them less suitable\nfor the real-world requirements of ship tracking. To address these limitations,\nwe present the Hybrid Optical and Synthetic Aperture Radar (SAR) Ship\nRe-Identification Dataset (HOSS ReID dataset), designed to evaluate the\neffectiveness of ship tracking using low-Earth orbit constellations of optical\nand SAR sensors. This approach ensures shorter re-imaging cycles and enables\nall-weather tracking. HOSS ReID dataset includes images of the same ship\ncaptured over extended periods under diverse conditions, using different\nsatellites of different modalities at varying times and angles. Furthermore, we\npropose a baseline method for cross-modal ship re-identification, TransOSS,\nwhich is built on the Vision Transformer architecture. It refines the patch\nembedding structure to better accommodate cross-modal tasks, incorporates\nadditional embeddings to introduce more reference information, and employs\ncontrastive learning to pre-train on large-scale optical-SAR image pairs,\nensuring the model's ability to extract modality-invariant features. Our\ndataset and baseline method are publicly available on\nhttps://github.com/Alioth2000/Hoss-ReID.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2506.22027v3", "cate": "cs.CV", "date": "2025-06-27", "updated": "2025-07-16", "AI": {"title_translation": "跨模态船舶再识别：一种新颖的数据集和方法（基于光学和SAR图像）", "tldr": "本文提出了一个用于跨模态（光学与SAR）船舶再识别的新数据集HOSS ReID和一个基于Vision Transformer的基线方法TransOSS，以解决现有船舶跟踪方法的局限性，实现全天候、高频次船舶跟踪。", "motivation": "遥感领域中，使用地球观测图像进行地面目标检测和跟踪仍面临挑战。连续的海洋船舶跟踪对于海上搜救、执法和航运分析至关重要。然而，现有船舶跟踪方法多依赖地球同步卫星或视频卫星，前者分辨率低且易受天气影响，后者拍摄时长短、覆盖范围有限，难以满足实际船舶跟踪需求。", "method": "本文提出了混合光学和合成孔径雷达（SAR）船舶再识别数据集（HOSS ReID），旨在评估使用低地球轨道光学和SAR传感器星座进行船舶跟踪的有效性，以实现更短的重成像周期和全天候跟踪。该数据集包含在不同时间、角度和模态下，由不同卫星在长时间内对同一艘船在不同条件下捕获的图像。此外，本文提出了一种基于Vision Transformer架构的跨模态船舶再识别基线方法TransOSS。该方法改进了补丁嵌入结构以更好地适应跨模态任务，引入了额外的嵌入以提供更多参考信息，并采用对比学习在大规模光学-SAR图像对上进行预训练，以确保模型能够提取模态不变特征。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "利用地球观测图像进行地面目标检测和跟踪仍然是遥感领域的一个重大挑战。连续的海洋船舶跟踪对于海上搜救、执法和航运分析等应用至关重要。然而，目前大多数船舶跟踪方法依赖于地球同步卫星或视频卫星。前者分辨率低且易受天气条件影响，而后者拍摄时间短、覆盖范围有限，这使得它们不太适合船舶跟踪的实际需求。为了解决这些局限性，我们提出了混合光学和合成孔径雷达（SAR）船舶再识别数据集（HOSS ReID），旨在评估使用低地球轨道光学和SAR传感器星座进行船舶跟踪的有效性。这种方法确保了更短的重成像周期并实现了全天候跟踪。HOSS ReID数据集包含了在不同时间、角度和模态下，由不同卫星在长时间内对同一艘船在不同条件下捕获的图像。此外，我们提出了一种用于跨模态船舶再识别的基线方法TransOSS，该方法建立在Vision Transformer架构之上。它改进了补丁嵌入结构以更好地适应跨模态任务，并结合了额外的嵌入以引入更多参考信息，同时采用对比学习在大规模光学-SAR图像对上进行预训练，以确保模型能够提取模态不变特征。我们的数据集和基线方法已在https://github.com/Alioth2000/Hoss-ReID 上公开可用。", "summary": "本文针对现有船舶跟踪方法在连续性、分辨率和全天候能力上的不足，提出了一个新颖的跨模态船舶再识别数据集HOSS ReID。该数据集结合了光学和SAR图像，旨在支持低地球轨道卫星的全天候、高频次船舶跟踪。同时，本文还提出了一种基于Vision Transformer的基线方法TransOSS，通过改进嵌入结构和引入对比学习，旨在提取模态不变特征，以实现有效的跨模态船舶再识别。数据集和方法均已公开。", "keywords": "跨模态, 船舶再识别, 光学图像, SAR图像, 数据集", "comments": "本文通过提出一个新颖的跨模态数据集HOSS ReID和相应的基线方法TransOSS，解决了现有船舶跟踪技术在连续性、全天候能力和分辨率方面的局限性。HOSS ReID数据集的创新之处在于其包含了在不同条件下、长时间内对同一艘船进行的光学和SAR图像采集，这对于训练和评估跨模态再识别模型至关重要。TransOSS方法利用Vision Transformer架构并结合对比学习，旨在提取模态不变特征，这对于跨模态任务是核心挑战。该研究的贡献在于为连续、全天候的船舶跟踪提供了新的数据和方法基础，具有重要的实际应用价值，尤其是在海事安全和航运管理方面。数据集和代码的公开性也促进了该领域的研究进展。"}}
{"id": "2507.12194", "title": "UniLGL: Learning Uniform Place Recognition for FOV-limited/Panoramic LiDAR Global Localization", "authors": ["Hongming Shen", "Xun Chen", "Yulin Hui", "Zhenyu Wu", "Wei Wang", "Qiyang Lyu", "Tianchen Deng", "Danwei Wang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12194v1", "summary": "Existing LGL methods typically consider only partial information (e.g.,\ngeometric features) from LiDAR observations or are designed for homogeneous\nLiDAR sensors, overlooking the uniformity in LGL. In this work, a uniform LGL\nmethod is proposed, termed UniLGL, which simultaneously achieves spatial and\nmaterial uniformity, as well as sensor-type uniformity. The key idea of the\nproposed method is to encode the complete point cloud, which contains both\ngeometric and material information, into a pair of BEV images (i.e., a spatial\nBEV image and an intensity BEV image). An end-to-end multi-BEV fusion network\nis designed to extract uniform features, equipping UniLGL with spatial and\nmaterial uniformity. To ensure robust LGL across heterogeneous LiDAR sensors, a\nviewpoint invariance hypothesis is introduced, which replaces the conventional\ntranslation equivariance assumption commonly used in existing LPR networks and\nsupervises UniLGL to achieve sensor-type uniformity in both global descriptors\nand local feature representations. Finally, based on the mapping between local\nfeatures on the 2D BEV image and the point cloud, a robust global pose\nestimator is derived that determines the global minimum of the global pose on\nSE(3) without requiring additional registration. To validate the effectiveness\nof the proposed uniform LGL, extensive benchmarks are conducted in real-world\nenvironments, and the results show that the proposed UniLGL is demonstratively\ncompetitive compared to other State-of-the-Art LGL methods. Furthermore, UniLGL\nhas been deployed on diverse platforms, including full-size trucks and agile\nMicro Aerial Vehicles (MAVs), to enable high-precision localization and mapping\nas well as multi-MAV collaborative exploration in port and forest environments,\ndemonstrating the applicability of UniLGL in industrial and field scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12194v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "UniLGL：学习用于视场受限/全景激光雷达全局定位的统一地点识别", "tldr": "UniLGL提出了一种新的激光雷达全局定位（LGL）方法，通过同时实现空间、材料和传感器类型统一性，解决了现有LGL方法信息不完整或传感器同质性限制的问题，并在实际环境中表现出强大的竞争力。", "motivation": "现有的激光雷达全局定位（LGL）方法通常只考虑激光雷达观测的部分信息（如几何特征），或者仅为同质激光雷达传感器设计，忽视了LGL中的统一性问题。", "method": "UniLGL将包含几何和材料信息的完整点云编码成一对BEV图像（空间BEV图像和强度BEV图像）。设计了一个端到端的多BEV融合网络来提取统一特征。引入了视点不变性假设，以确保异构激光雷达传感器之间的传感器类型统一性，取代了现有LPR网络中常用的平移等变性假设。最后，基于2D BEV图像上的局部特征与点云之间的映射，推导出一个鲁棒的全局姿态估计器，无需额外配准即可确定SE(3)上的全局姿态全局最小值。", "result": "在真实世界环境中进行了广泛的基准测试，结果表明UniLGL与现有最先进的LGL方法相比具有显著的竞争力。此外，UniLGL已部署在包括全尺寸卡车和敏捷微型飞行器（MAVs）在内的多种平台上，实现了高精度定位与建图以及多MAV在港口和森林环境中的协同探索，证明了UniLGL在工业和野外场景中的适用性。", "conclusion": "UniLGL方法在LGL领域展现出强大的竞争力，并在各种工业和野外场景中具有广泛的适用性，通过实现空间、材料和传感器类型的统一性，有效解决了现有方法的局限性。", "translation": "现有激光雷达全局定位（LGL）方法通常只考虑激光雷达观测的部分信息（例如几何特征）或专为同质激光雷达传感器设计，忽视了LGL中的统一性。在这项工作中，提出了一种统一的LGL方法，命名为UniLGL，它同时实现了空间和材料的统一性以及传感器类型的统一性。该方法的关键思想是将包含几何和材料信息的完整点云编码成一对BEV图像（即空间BEV图像和强度BEV图像）。设计了一个端到端的多BEV融合网络来提取统一特征，使UniLGL具备空间和材料统一性。为了确保异构激光雷达传感器之间鲁棒的LGL，引入了视点不变性假设，该假设取代了现有LPR网络中常用的传统平移等变性假设，并监督UniLGL在全局描述符和局部特征表示中实现传感器类型统一性。最后，基于2D BEV图像上的局部特征与点云之间的映射，推导出一个鲁棒的全局姿态估计器，该估计器无需额外配准即可确定SE(3)上的全局姿态全局最小值。为了验证所提出的统一LGL的有效性，在真实世界环境中进行了广泛的基准测试，结果表明所提出的UniLGL与现有最先进的LGL方法相比具有显著的竞争力。此外，UniLGL已部署在包括全尺寸卡车和敏捷微型飞行器（MAVs）在内的多种平台上，实现了高精度定位与建图以及多MAV在港口和森林环境中的协同探索，证明了UniLGL在工业和野外场景中的适用性。", "summary": "本文提出了一种名为UniLGL的统一激光雷达全局定位（LGL）方法，旨在解决现有LGL方案在信息利用不完整和传感器同质性方面的局限。UniLGL通过将完整的点云数据（包含几何和材料信息）编码为空间和强度BEV图像，并利用端到端的多BEV融合网络提取统一特征，从而实现了空间和材料的统一性。为确保跨异构传感器的鲁棒性，该方法引入了视点不变性假设，取代了传统的平移等变性。此外，UniLGL基于BEV图像局部特征与点云的映射，推导出一个无需额外配准的鲁棒全局姿态估计器。实验证明UniLGL在真实世界环境中比现有最先进的LGL方法更具竞争力，并在多种平台和场景（如港口、森林）中展现出其在高精度定位、建图和多MAV协同探索方面的实用性。", "keywords": "激光雷达全局定位, 地点识别, 统一性, BEV图像, 视点不变性", "comments": "本文提出UniLGL，通过引入空间、材料和传感器类型统一性，显著提升了激光雷达全局定位的鲁棒性和通用性。其创新点在于将完整的点云信息编码为BEV图像，并设计多BEV融合网络提取统一特征，同时通过视点不变性假设克服了异构传感器兼容性问题。该方法无需额外配准即可实现全局姿态估计，简化了流程。在多样化平台和实际场景中的成功部署，突显了其在工业和野外应用中的重要性和潜力。"}}
{"id": "2502.06399", "title": "A Linearly Convergent Algorithm for Computing the Petz-Augustin Mean", "authors": ["Chun-Neng Chu", "Wei-Fu Tseng", "Yen-Huan Li"], "categories": ["quant-ph", "cs.IT", "math.IT", "math.OC"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.06399v2", "summary": "We study the computation of the Petz-Augustin mean of order $\\alpha \\in (0,1)\n\\cup (1,\\infty)$, defined as the minimizer of a weighted sum of $n$\nPetz-R\\'enyi divergences of order $\\alpha$ over the set of $d$-by-$d$ quantum\nstates, where the Petz-R\\'enyi divergence is a quantum generalization of the\nclassical R\\'enyi divergence. We propose the first algorithm with a\nnon-asymptotic convergence guarantee for solving this optimization problem. The\niterates are guaranteed to converge to the Petz-Augustin mean at a linear rate\nof \\( O\\left( \\lvert 1 - 1/\\alpha \\rvert^T \\right) \\) with respect to the\nThompson metric for $\\alpha\\in(1/2,1)\\cup(1,\\infty)$, where \\( T \\) denotes the\nnumber of iterations. The algorithm has an initialization time complexity of\n$O\\left(nd^3\\right)$ and a per-iteration time complexity of $O\\left(nd^2 +\nd^3\\right)$.\n  Two applications follow. First, we propose the first iterative method with a\nnon-asymptotic convergence guarantee for computing the Petz capacity of order\n$\\alpha\\in(1/2,1)$, which generalizes the quantum channel capacity and\ncharacterizes the optimal error exponent in classical-quantum channel coding.\nSecond, we establish that the Petz-Augustin mean of order $\\alpha$, when all\nquantum states commute, is equivalent to the equilibrium prices in Fisher\nmarkets with constant elasticity of substitution (CES) utilities of common\nelasticity $\\rho=1-1/\\alpha$, and our proposed algorithm can be interpreted as\na t\\^{a}tonnement dynamic. We then extend the proposed algorithm to\ninhomogeneous Fisher markets, where buyers have different elasticities, and\nprove that it achieves a faster convergence rate compared to existing\nt\\^{a}tonnement-type algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.06399v2", "cate": "quant-ph", "date": "2025-02-10", "updated": "2025-07-16", "AI": {"title_translation": "一种计算Petz-Augustin均值的线性收敛算法", "tldr": "本文提出了首个用于计算Petz-Augustin均值的具有非渐近线性收敛保证的算法，并将其应用于Petz容量和Fisher市场。", "motivation": "本文研究了Petz-Augustin均值的计算问题，该均值被定义为量子态集合上Petz-Rényi散度加权和的最小值。现有方法可能缺乏非渐近收敛保证。此外，其在Petz容量和Fisher市场中的应用也凸显了其重要性。", "method": "本文提出了第一个具有非渐近收敛保证的算法来解决Petz-Augustin均值的优化问题。该算法是一种迭代方法。", "result": "该算法的迭代序列保证以相对于Thompson度量的线性速率 $O(|1 - 1/\\alpha|^T)$ 收敛到Petz-Augustin均值，其中 $T$ 为迭代次数。初始化时间复杂度为 $O(nd^3)$，每次迭代时间复杂度为 $O(nd^2 + d^3)$。该算法是第一个具有非渐近收敛保证的用于计算Petz容量的迭代方法。当所有量子态可对易时，该算法可解释为Fisher市场中的tâtonnement动态，且对于非均匀Fisher市场，其收敛速度比现有tâtonnement型算法更快。", "conclusion": "本文提出了一种新颖的、线性收敛的Petz-Augustin均值计算算法，具有强大的理论保证，并展示了其在量子信息理论（Petz容量）和经济学（Fisher市场）中的实用性，包括一项在特定场景下优于现有方法的扩展。", "translation": "我们研究了阶数为 $\\alpha \\in (0,1) \\cup (1,\\infty)$ 的 Petz-Augustin 均值的计算，该均值定义为 $d \\times d$ 量子态集合上 $n$ 个阶数为 $\\alpha$ 的 Petz-Rényi 散度的加权和的最小值，其中 Petz-Rényi 散度是经典 Rényi 散度的量子推广。我们提出了第一个具有非渐近收敛保证的算法来解决这个优化问题。对于 $\\alpha \\in (1/2,1) \\cup (1,\\infty)$，迭代序列保证以相对于 Thompson 度量的线性速率 $O(|1 - 1/\\alpha|^T)$ 收敛到 Petz-Augustin 均值，其中 $T$ 表示迭代次数。该算法的初始化时间复杂度为 $O(nd^3)$，每次迭代时间复杂度为 $O(nd^2 + d^3)$。\n接着是两个应用。首先，我们提出了第一个具有非渐近收敛保证的迭代方法，用于计算阶数为 $\\alpha \\in (1/2,1)$ 的 Petz 容量，它推广了量子信道容量并表征了经典-量子信道编码中的最优错误指数。其次，我们确定当所有量子态可对易时，阶数为 $\\alpha$ 的 Petz-Augustin 均值等同于具有共同弹性 $\\rho=1-1/\\alpha$ 的常数替代弹性 (CES) 效用函数的 Fisher 市场中的均衡价格，并且我们提出的算法可以解释为一种 tâtonnement 动态。然后我们将提出的算法扩展到非均匀 Fisher 市场，其中买家具有不同的弹性，并证明它比现有 tâtonnement 型算法实现了更快的收敛速度。", "summary": "本文提出了一种计算Petz-Augustin均值的算法，该算法首次提供了非渐近线性收敛保证，并分析了其计算效率。该算法在量子信息理论中可用于计算Petz容量，在经济学中可用于模拟Fisher市场中的均衡价格，并且在非均匀市场中表现出比现有方法更快的收敛速度。", "keywords": "Petz-Augustin均值, 线性收敛, 量子态, Petz容量, Fisher市场", "comments": "本文通过为量子信息理论中的一个复杂优化问题提供第一个具有非渐近线性收敛保证的算法，做出了重要贡献。该算法在Fisher市场中的双重应用突出了其跨学科相关性和更广泛的影响潜力，特别是在非均匀市场中提高了收敛性。强大的理论保证（线性收敛、复杂度分析）是其关键创新。"}}
{"id": "2211.05622", "title": "InstantGroup: Instant Template Generation for Scalable Group of Brain MRI Registration", "authors": ["Ziyi He", "Albert C. S. Chung"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      14 pages, 10 figures, and 6 tables. Accepted by IEEE Transactions on Image Processing", "url": "http://arxiv.org/abs/2211.05622v3", "summary": "Template generation is a critical step in groupwise image registration, which\ninvolves aligning a group of subjects into a common space. While existing\nmethods can generate high-quality template images, they often incur substantial\ntime costs or are limited by fixed group scales. In this paper, we present\nInstantGroup, an efficient groupwise template generation framework based on\nvariational autoencoder (VAE) models that leverage latent representations'\narithmetic properties, enabling scalability to groups of any size. InstantGroup\nfeatures a Dual VAE backbone with shared-weight twin networks to handle pairs\nof inputs and incorporates a Displacement Inversion Module (DIM) to maintain\ntemplate unbiasedness and a Subject-Template Alignment Module (STAM) to improve\ntemplate quality and registration accuracy. Experiments on 3D brain MRI scans\nfrom the OASIS and ADNI datasets reveal that InstantGroup dramatically reduces\nruntime, generating templates within seconds for various group sizes while\nmaintaining superior performance compared to state-of-the-art baselines on\nquantitative metrics, including unbiasedness and registration accuracy.", "comment": "14 pages, 10 figures, and 6 tables. Accepted by IEEE Transactions on\n  Image Processing", "pdf_url": "http://arxiv.org/pdf/2211.05622v3", "cate": "eess.IV", "date": "2022-11-10", "updated": "2025-07-16", "AI": {"title_translation": "InstantGroup: 脑MRI配准可伸缩群体即时模板生成", "tldr": "InstantGroup是一个基于VAE的高效群体模板生成框架，能快速为任意规模的脑MRI图像生成高质量模板，解决现有方法耗时和规模限制的问题。", "motivation": "现有群体图像配准的模板生成方法耗时巨大或受限于固定群体规模，无法满足大规模数据处理的需求。", "method": "本文提出了InstantGroup，一个基于变分自编码器（VAE）模型的高效群体模板生成框架。它利用潜在表示的算术属性，包含一个共享权重的双VAE骨干网络（Dual VAE Backbone）来处理输入对，并引入了位移反转模块（Displacement Inversion Module, DIM）以保持模板无偏性，以及受试者-模板对齐模块（Subject-Template Alignment Module, STAM）以提高模板质量和配准精度。", "result": "在OASIS和ADNI数据集上的3D脑MRI扫描实验表明，InstantGroup显著减少了运行时间，能在几秒内为各种群体规模生成模板，同时在无偏性和配准精度等定量指标上保持了优于现有最先进基线的性能。", "conclusion": "InstantGroup能够高效、高质量地生成群体脑MRI配准模板，克服了现有方法的计算开销和可伸缩性限制，为大规模医学图像分析提供了有效工具。", "translation": "模板生成是群体图像配准中的关键步骤，涉及将一组受试者对齐到一个公共空间。虽然现有方法可以生成高质量的模板图像，但它们通常会产生大量时间成本或受限于固定的群体规模。在本文中，我们提出了InstantGroup，一个基于变分自编码器（VAE）模型的高效群体模板生成框架，该框架利用潜在表示的算术属性，实现了对任何规模群体的可伸缩性。InstantGroup具有一个带共享权重双网络的双VAE骨干，用于处理输入对，并结合了一个位移反转模块（DIM）以保持模板无偏性，以及一个受试者-模板对齐模块（STAM）以提高模板质量和配准精度。在OASIS和ADNI数据集上的3D脑MRI扫描实验表明，InstantGroup显著减少了运行时间，在几秒内为各种群体规模生成模板，同时在无偏性和配准精度等定量指标上保持了优于现有最先进基线的性能。", "summary": "本文介绍了InstantGroup，一种基于变分自编码器（VAE）的高效群体模板生成框架，旨在解决现有群体图像配准模板生成方法耗时和规模限制的问题。InstantGroup利用VAE的潜在表示特性，结合了双VAE骨干、位移反转模块（DIM）和受试者-模板对齐模块（STAM）。实验结果显示，InstantGroup能快速生成高质量模板，并在脑MRI配准中表现出卓越的性能和可伸缩性。", "keywords": "群体配准, 模板生成, 变分自编码器, 脑MRI, 可伸缩性", "comments": "InstantGroup的创新之处在于将VAE的潜在空间算术属性应用于群体模板生成，显著提高了效率和可伸缩性，这对于大规模医学图像分析具有重要意义。其双VAE架构和特定模块设计也显示了其在保持无偏性和提高精度方面的有效性。"}}
{"id": "2507.12462", "title": "SpatialTrackerV2: 3D Point Tracking Made Easy", "authors": ["Yuxi Xiao", "Jianyuan Wang", "Nan Xue", "Nikita Karaev", "Yuri Makarov", "Bingyi Kang", "Xing Zhu", "Hujun Bao", "Yujun Shen", "Xiaowei Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      International Conference on Computer Vision, ICCV 2025. Huggingface Demo: this https URL , Code: this https URL", "url": "http://arxiv.org/abs/2507.12462v1", "summary": "We present SpatialTrackerV2, a feed-forward 3D point tracking method for\nmonocular videos. Going beyond modular pipelines built on off-the-shelf\ncomponents for 3D tracking, our approach unifies the intrinsic connections\nbetween point tracking, monocular depth, and camera pose estimation into a\nhigh-performing and feedforward 3D point tracker. It decomposes world-space 3D\nmotion into scene geometry, camera ego-motion, and pixel-wise object motion,\nwith a fully differentiable and end-to-end architecture, allowing scalable\ntraining across a wide range of datasets, including synthetic sequences, posed\nRGB-D videos, and unlabeled in-the-wild footage. By learning geometry and\nmotion jointly from such heterogeneous data, SpatialTrackerV2 outperforms\nexisting 3D tracking methods by 30%, and matches the accuracy of leading\ndynamic 3D reconstruction approaches while running 50$\\times$ faster.", "comment": "International Conference on Computer Vision, ICCV 2025. Huggingface\n  Demo: https://huggingface.co/spaces/Yuxihenry/SpatialTrackerV2, Code:\n  https://github.com/henry123-boy/SpaTrackerV2", "pdf_url": "http://arxiv.org/pdf/2507.12462v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "SpatialTrackerV2：轻松实现3D点跟踪", "tldr": "SpatialTrackerV2是一种用于单目视频的3D点跟踪方法，它将点跟踪、单目深度和相机姿态估计统一起来，实现了高性能、端到端的跟踪，比现有方法性能提升30%并快50倍。", "motivation": "现有的3D跟踪方法通常是基于现成组件的模块化管道，本研究旨在超越这种模式，将点跟踪、单目深度和相机姿态估计的内在联系统一起来，开发一个高性能的、前馈式的3D点跟踪器。", "method": "SpatialTrackerV2是一种前馈式3D点跟踪方法，用于单目视频。它将点跟踪、单目深度和相机姿态估计的内在联系统一起来。该方法将世界空间3D运动分解为场景几何、相机自我运动和像素级对象运动，采用完全可微分的端到端架构，允许在各种数据集（包括合成序列、姿态RGB-D视频和未标记的野外素材）上进行可扩展训练，通过联合学习几何和运动。", "result": "SpatialTrackerV2在3D跟踪方面比现有方法性能提升30%，并且在运行速度快50倍的同时，达到了领先的动态3D重建方法的精度。", "conclusion": "SpatialTrackerV2通过统一和端到端学习3D点跟踪、单目深度和相机姿态估计，显著提升了单目视频3D点跟踪的性能和效率，使其超越了现有方法并与顶尖的动态3D重建方法相媲美。", "translation": "我们提出了SpatialTrackerV2，一种用于单目视频的前馈式3D点跟踪方法。超越了基于现成组件构建的模块化3D跟踪管道，我们的方法将点跟踪、单目深度和相机姿态估计之间的内在联系统一成一个高性能的前馈式3D点跟踪器。它将世界空间3D运动分解为场景几何、相机自我运动和像素级对象运动，采用完全可微分的端到端架构，允许在各种数据集（包括合成序列、姿态RGB-D视频和未标记的野外素材）上进行可扩展训练。通过从这些异构数据中联合学习几何和运动，SpatialTrackerV2的性能比现有3D跟踪方法提高了30%，并且在运行速度快50倍的同时，达到了领先的动态3D重建方法的精度。", "summary": "SpatialTrackerV2是一种创新的单目视频3D点跟踪方法，它通过将点跟踪、单目深度和相机姿态估计统一到一个端到端、可微分的架构中，解决了传统模块化管道的局限性。该模型能够从多样化的数据中联合学习场景几何和运动，从而在性能上超越现有3D跟踪方法30%，并在速度上提升50倍的同时，达到动态3D重建的领先精度。", "keywords": "3D点跟踪, 单目视频, 深度估计, 相机姿态, 端到端", "comments": "SpatialTrackerV2的创新之处在于其统一的、端到端的架构，它整合了3D点跟踪、单目深度和相机姿态估计，这与传统的模块化方法形成对比。这种整合使得模型能够更有效地利用不同类型的数据进行训练，并显著提高了性能和效率。其在速度和精度上的显著提升，使其在实时3D应用中具有重要潜力。"}}
{"id": "2507.12208", "title": "Toward a Behavioural Translation Style Space: Simulating the Temporal Dynamics of Affect, Behaviour, and Cognition in Human Translation Production", "authors": ["Michael Carl", "Takanori Mizowaki", "Aishvarya Ray", "Masaru Yamada", "Devi Sri Bandaru", "Xinyue Ren"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12208v1", "summary": "The paper introduces a Behavioural Translation Style Space (BTSS) that\ndescribes possible behavioural translation patterns. The suggested BTSS is\norganized as a hierarchical structure that entails various embedded processing\nlayers. We posit that observable translation behaviour - i.e., eye and finger\nmovements - is fundamental when executing the physical act of translation but\nit is caused and shaped by higher-order cognitive processes and affective\ntranslation states. We analyse records of keystrokes and gaze data as\nindicators of the hidden mental processing structure and organize the\nbehavioural patterns as a multi-layered embedded BTSS. The BTSS serves as the\nbasis for a computational translation agent to simulate the temporal dynamics\nof affect, automatized behaviour and cognition during human translation\nproduction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12208v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "走向行为翻译风格空间：模拟人类翻译产出中情感、行为和认知的时序动态", "tldr": "本文引入了行为翻译风格空间（BTSS），通过分析击键和凝视数据来模拟人类翻译产出中情感、自动化行为和认知的时序动态。", "motivation": "旨在描述可能的行为翻译模式，并理解可观察的翻译行为（如眼球和手指运动）如何由更高阶的认知过程和情感翻译状态引起和塑造。", "method": "引入了行为翻译风格空间（BTSS），将其组织为分层结构；分析击键和凝视数据作为隐藏心理处理结构的指标，并将行为模式组织为多层嵌入式BTSS。", "result": "提出了行为翻译风格空间（BTSS），能够描述可能的行为翻译模式，并作为计算翻译代理的基础，用于模拟人类翻译产出中情感、自动化行为和认知的时序动态。", "conclusion": "论文成功地引入了一个行为翻译风格空间（BTSS），该空间能够捕捉并模拟人类翻译过程中情感、行为和认知的复杂时序动态。", "translation": "本文介绍了一种行为翻译风格空间（BTSS），它描述了可能的行为翻译模式。所提出的BTSS被组织为一个分层结构，包含各种嵌入式处理层。我们认为，可观察的翻译行为——即眼球和手指运动——在执行翻译的物理行为时是基础的，但它是由更高阶的认知过程和情感翻译状态引起并塑造的。我们分析了击键和凝视数据记录，将其作为隐藏心理处理结构的指标，并将行为模式组织为多层嵌入式BTSS。BTSS作为计算翻译代理的基础，用于模拟人类翻译产出中情感、自动化行为和认知的时序动态。", "summary": "本文提出了一种行为翻译风格空间（BTSS），旨在描述和组织人类翻译过程中可观察的行为模式。该BTSS被构建为分层结构，通过分析击键和凝视数据来揭示隐藏的心理处理过程。最终，BTSS将作为计算翻译代理的基础，用于模拟人类翻译产出中情感、行为和认知的时序动态。", "keywords": "行为翻译风格空间, 击键数据, 凝视数据, 翻译认知, 时序动态", "comments": "这篇论文通过引入行为翻译风格空间（BTSS）提供了一种新颖的方法，将可观察的翻译行为与更高阶的认知和情感状态联系起来。其创新点在于利用击键和凝视数据来构建一个多层级的行为模型，并旨在模拟翻译过程中的动态变化，这对于理解翻译认知过程和开发更智能的翻译辅助工具具有重要意义。"}}
{"id": "2507.11557", "title": "3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation", "authors": ["Jiaxu Zheng", "Meiman He", "Xuhui Tang", "Xiong Wang", "Tuoyu Cao", "Tianyi Zeng", "Lichi Zhang", "Chenyu You"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11557v1", "summary": "Magnetic Resonance (MR) imaging plays an essential role in contemporary\nclinical diagnostics. It is increasingly integrated into advanced therapeutic\nworkflows, such as hybrid Positron Emission Tomography/Magnetic Resonance\n(PET/MR) imaging and MR-only radiation therapy. These integrated approaches are\ncritically dependent on accurate estimation of radiation attenuation, which is\ntypically facilitated by synthesizing Computed Tomography (CT) images from MR\nscans to generate attenuation maps. However, existing MR-to-CT synthesis\nmethods for whole-body imaging often suffer from poor spatial alignment between\nthe generated CT and input MR images, and insufficient image quality for\nreliable use in downstream clinical tasks. In this paper, we present a novel 3D\nWavelet Latent Diffusion Model (3D-WLDM) that addresses these limitations by\nperforming modality translation in a learned latent space. By incorporating a\nWavelet Residual Module into the encoder-decoder architecture, we enhance the\ncapture and reconstruction of fine-scale features across image and latent\nspaces. To preserve anatomical integrity during the diffusion process, we\ndisentangle structural and modality-specific characteristics and anchor the\nstructural component to prevent warping. We also introduce a Dual Skip\nConnection Attention mechanism within the diffusion model, enabling the\ngeneration of high-resolution CT images with improved representation of bony\nstructures and soft-tissue contrast.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11557v1", "cate": "eess.IV", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "全身MR到CT模态转换的3D小波潜在扩散模型", "tldr": "本文提出了一种新颖的3D小波潜在扩散模型（3D-WLDM），旨在解决全身MR到CT图像合成中存在的空间对齐不佳和图像质量不足的问题。该模型通过在学习到的潜在空间中进行模态转换，并引入小波残差模块和双跳连接注意力机制，以增强精细特征的捕获与重建，并生成具有改善骨骼结构和软组织对比度的高分辨率CT图像。", "motivation": "现有的全身MR到CT合成方法普遍存在生成CT图像与输入MR图像空间对齐差以及图像质量不足以可靠用于下游临床任务的问题。", "method": "本文提出了一种新颖的3D小波潜在扩散模型（3D-WLDM），通过在学习到的潜在空间中执行模态转换来解决上述限制。该模型在编码器-解码器架构中整合了小波残差模块，以增强图像和潜在空间中精细尺度特征的捕获和重建。为了在扩散过程中保持解剖完整性，模型解耦了结构和模态特异性特征，并锚定结构组件以防止变形。此外，还在扩散模型中引入了双跳连接注意力机制。", "result": "该模型能够生成高分辨率的CT图像，并改善了骨骼结构和软组织对比度的表现。它解决了现有方法中空间对齐差和图像质量不足的问题。", "conclusion": "3D小波潜在扩散模型（3D-WLDM）成功解决了全身MR到CT模态转换中的关键挑战，能够生成高质量的CT图像，这对于需要精确辐射衰减估计的临床应用至关重要。", "translation": "磁共振（MR）成像在当代临床诊断中发挥着至关重要的作用。它正日益整合到先进的治疗工作流程中，例如混合正电子发射断层扫描/磁共振（PET/MR）成像和仅MR放射治疗。这些整合方法严重依赖于辐射衰减的准确估计，这通常通过从MR扫描合成计算机断层扫描（CT）图像来生成衰减图来促进。然而，现有的全身MR到CT合成方法常常面临生成CT图像与输入MR图像空间对齐差以及图像质量不足以可靠用于下游临床任务的问题。在本文中，我们提出了一种新颖的3D小波潜在扩散模型（3D-WLDM），通过在学习到的潜在空间中执行模态转换来解决这些限制。通过在编码器-解码器架构中整合小波残差模块，我们增强了图像和潜在空间中精细尺度特征的捕获和重建。为了在扩散过程中保持解剖完整性，我们解耦了结构和模态特异性特征，并锚定结构组件以防止变形。我们还在扩散模型中引入了双跳连接注意力机制，从而能够生成具有改善骨骼结构和软组织对比度的高分辨率CT图像。", "summary": "本文介绍了一种名为3D小波潜在扩散模型（3D-WLDM）的新型方法，用于全身MR到CT的模态转换。该模型旨在解决现有方法中空间对齐不佳和图像质量不足的问题。通过在学习到的潜在空间中进行转换，并结合小波残差模块以增强精细特征捕获，以及解耦结构和模态特异性特征以保持解剖完整性，3D-WLDM能够生成高分辨率CT图像，并改善骨骼结构和软组织的对比度。此外，引入的双跳连接注意力机制也进一步提升了图像质量。", "keywords": "MR-to-CT, 模态转换, 潜在扩散模型, 小波, 全身成像", "comments": "该论文的创新点在于将3D小波和潜在扩散模型相结合应用于全身MR到CT的医学图像模态转换。通过在潜在空间中操作，并引入小波残差模块来处理精细尺度特征，以及解耦结构和模态特异性特征以保持解剖完整性，有效地解决了现有方法中空间对齐和图像质量的挑战。这对于需要精确衰减校正的PET/MR和MR-only放射治疗等临床应用具有重要意义。"}}
{"id": "2507.12032", "title": "ARRC: Explainable, Workflow-Integrated Recommender for Sustainable Resource Optimization Across the Edge-Cloud Continuum", "authors": ["Brian-Frederik Jahnke", "René Brinkhege", "Jan Peter Meyer", "Daniel Tebernum", "Falk Howar"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12032v1", "summary": "Achieving sustainable, explainable, and maintainable automation for resource\noptimization is a core challenge across the edge-cloud continuum. Persistent\noverprovisioning and operational complexity often stem from heterogeneous\nplatforms and layered abstractions, while systems lacking explainability and\nmaintainability become fragile, impede safe recovery, and accumulate technical\ndebt. Existing solutions are frequently reactive, limited to single abstraction\nlayers, or require intrusive platform changes, leaving efficiency and\nmaintainability gains unrealized.\n  This paper addresses safe, transparent, and low-effort resource optimization\nin dynamic, multi-tenant edge-cloud systems, without disrupting operator\nworkflows or increasing technical debt. We introduce ARRC, a recommender system\nrooted in software engineering design principles, which delivers explainable,\ncross-layer resource recommendations directly into operator workflows (such as\ntickets and GitOps pull requests). ARRC encapsulates optimization logic in\nspecialized, auditable agents coordinated via a shared interface, supporting\nmaintainability and extensibility through transparency and the ability to\ninspect both recommendations and their rationale.\n  Empirical evaluation in a multi-region industrial deployment shows that ARRC\nreduces operator workload by over 50%, improves compute utilization by up to\n7.7x, and maintains error rates below 5%, with most benefits achieved through\nincremental, operator-approved changes. This demonstrates that explainable,\nrecommendation-based architectures can achieve sustainable efficiency and\nmaintainability improvements at production scale.\n  ARRC provides an empirically evaluated framework for integrating explainable,\nworkflow-driven automation into resource management, intended to advance best\npractices for robust, maintainable, and transparent edge-cloud continuum\nplatforms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12032v1", "cate": "cs.DC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "ARRC：面向边缘-云连续体的可解释、工作流集成推荐器，用于可持续资源优化", "tldr": "ARRC是一个可解释、工作流集成的推荐系统，旨在实现边缘-云连续体中可持续的资源优化，显著降低操作员工作量并提高计算利用率。", "motivation": "在边缘-云连续体中，实现可持续、可解释和可维护的资源优化自动化是一个核心挑战。现有解决方案常为被动式，局限于单一抽象层，或需侵入性平台变更，导致效率和可维护性提升未能实现。持续的过度配置和操作复杂性源于异构平台和分层抽象，而缺乏可解释性和可维护性的系统则变得脆弱，阻碍安全恢复并累积技术债务。", "method": "本文介绍了ARRC，一个植根于软件工程设计原则的推荐系统。ARRC将优化逻辑封装在专业、可审计的代理中，并通过共享接口进行协调，支持通过透明度以及检查推荐及其原理的能力来提高可维护性和可扩展性。它直接将可解释的跨层资源推荐整合到操作员工作流中（例如工单和GitOps拉取请求）。", "result": "在多区域工业部署中的实证评估表明，ARRC将操作员工作量减少了50%以上，计算利用率提高了7.7倍，并将错误率保持在5%以下。大部分益处是通过增量、操作员批准的更改实现的。", "conclusion": "可解释的、基于推荐的架构可以在生产规模上实现可持续的效率和可维护性改进。ARRC提供了一个经过实证评估的框架，用于将可解释、工作流驱动的自动化集成到资源管理中，旨在推进健壮、可维护和透明的边缘-云连续体平台的最佳实践。", "translation": "实现边缘-云连续体中可持续、可解释和可维护的资源优化自动化是一个核心挑战。持续的过度配置和操作复杂性通常源于异构平台和分层抽象，而缺乏可解释性和可维护性的系统则变得脆弱，阻碍安全恢复并累积技术债务。现有解决方案常为被动式，局限于单一抽象层，或需侵入性平台变更，导致效率和可维护性提升未能实现。\n本文旨在解决动态、多租户边缘-云系统中安全、透明、低投入的资源优化问题，同时不中断操作员工作流或增加技术债务。我们引入了ARRC，一个植根于软件工程设计原则的推荐系统，它将可解释的跨层资源推荐直接交付到操作员工作流中（例如工单和GitOps拉取请求）。ARRC将优化逻辑封装在专业、可审计的代理中，并通过共享接口进行协调，通过透明度以及检查推荐及其原理的能力来支持可维护性和可扩展性。\n在多区域工业部署中的实证评估表明，ARRC将操作员工作量减少了50%以上，计算利用率提高了7.7倍，并将错误率保持在5%以下，大部分益处是通过增量、操作员批准的更改实现的。这表明可解释的、基于推荐的架构可以在生产规模上实现可持续的效率和可维护性改进。\nARRC提供了一个经过实证评估的框架，用于将可解释、工作流驱动的自动化集成到资源管理中，旨在推进健壮、可维护和透明的边缘-云连续体平台的最佳实践。", "summary": "本文提出ARRC，一个可解释、工作流集成的推荐系统，旨在解决边缘-云连续体中资源优化面临的可持续性、可解释性和可维护性挑战。ARRC通过将优化逻辑封装在可审计代理中，并直接将跨层推荐集成到操作员工作流（如工单和GitOps）中，实现安全、透明且低投入的资源优化。实证评估显示，ARRC显著降低了操作员工作量（超过50%），提高了计算利用率（高达7.7倍），并保持低错误率（低于5%），证明了其在生产规模下实现可持续效率和可维护性改进的潜力。", "keywords": "资源优化, 边缘-云连续体, 推荐系统, 可解释性, 工作流集成", "comments": "ARRC的创新之处在于其将可解释性、工作流集成和软件工程设计原则相结合，以解决边缘-云环境中资源优化的实际挑战。其强调的“可解释性”和“不中断操作员工作流”解决了现有方案中常见的黑箱问题和部署障碍，使其在实际工业部署中更具吸引力。实证结果令人印象深刻，表明该系统在提高效率和降低操作成本方面具有显著潜力。"}}
{"id": "2507.12081", "title": "VoxATtack: A Multimodal Attack on Voice Anonymization Systems", "authors": ["Ahmad Aloradi", "Ünal Ege Gaznepoglu", "Emanuël A. P. Habets", "Daniel Tenbrinck"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      5 pages, 3 figures, 3 tables, accepted at WASPAA 2025", "url": "http://arxiv.org/abs/2507.12081v1", "summary": "Voice anonymization systems aim to protect speaker privacy by obscuring vocal\ntraits while preserving the linguistic content relevant for downstream\napplications. However, because these linguistic cues remain intact, they can be\nexploited to identify semantic speech patterns associated with specific\nspeakers. In this work, we present VoxATtack, a novel multimodal\nde-anonymization model that incorporates both acoustic and textual information\nto attack anonymization systems. While previous research has focused on\nrefining speaker representations extracted from speech, we show that\nincorporating textual information with a standard ECAPA-TDNN improves the\nattacker's performance. Our proposed VoxATtack model employs a dual-branch\narchitecture, with an ECAPA-TDNN processing anonymized speech and a pretrained\nBERT encoding the transcriptions. Both outputs are projected into embeddings of\nequal dimensionality and then fused based on confidence weights computed on a\nper-utterance basis. When evaluating our approach on the VoicePrivacy Attacker\nChallenge (VPAC) dataset, it outperforms the top-ranking attackers on five out\nof seven benchmarks, namely B3, B4, B5, T8-5, and T12-5. To further boost\nperformance, we leverage anonymized speech and SpecAugment as augmentation\ntechniques. This enhancement enables VoxATtack to achieve state-of-the-art on\nall VPAC benchmarks, after scoring 20.6% and 27.2% average equal error rate on\nT10-2 and T25-1, respectively. Our results demonstrate that incorporating\ntextual information and selective data augmentation reveals critical\nvulnerabilities in current voice anonymization methods and exposes potential\nweaknesses in the datasets used to evaluate them.", "comment": "5 pages, 3 figures, 3 tables, accepted at WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.12081v1", "cate": "eess.AS", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "VoxATtack：一种针对语音匿名化系统的多模态攻击", "tldr": "VoxATtack是一种新颖的多模态模型，通过结合声学和文本信息来攻击语音匿名化系统，并利用数据增强技术在多项基准测试中达到了最先进的性能。", "motivation": "语音匿名化系统旨在保护说话者隐私，但保留的语言信息仍可被利用来识别特定说话者相关的语义语音模式，因此需要研究如何攻击这些系统以揭示其漏洞。", "method": "本文提出了VoxATtack，一个新颖的多模态去匿名化模型，结合了声学和文本信息。它采用双分支架构：一个ECAPA-TDNN处理匿名语音，一个预训练BERT编码转录文本。两者输出投影到等维嵌入，并根据每句话的置信权重进行融合。为进一步提升性能，还利用匿名语音和SpecAugment作为数据增强技术。", "result": "VoxATtack在VoicePrivacy Attacker Challenge (VPAC) 数据集上评估时，在七个基准中的五个（B3、B4、B5、T8-5和T12-5）上优于排名靠前的攻击者。通过数据增强，VoxATtack在所有VPAC基准上达到了最先进的性能，在T10-2和T25-1上分别获得了20.6%和27.2%的平均等错误率。", "conclusion": "结合文本信息和选择性数据增强揭示了当前语音匿名化方法的关键漏洞，并暴露了用于评估这些方法的数据集中潜在的弱点。", "translation": "语音匿名化系统旨在通过模糊声学特征同时保留与下游应用相关的语言内容来保护说话者隐私。然而，由于这些语言线索保持完整，它们可能被利用来识别与特定说话者相关的语义语音模式。在这项工作中，我们提出了VoxATtack，一种新颖的多模态去匿名化模型，它结合了声学和文本信息来攻击匿名化系统。虽然之前的研究主要集中在完善从语音中提取的说话者表示，但我们表明，将文本信息与标准ECAPA-TDNN结合可以提高攻击者的性能。我们提出的VoxATtack模型采用双分支架构，其中一个ECAPA-TDNN处理匿名语音，一个预训练的BERT编码转录文本。两个输出都被投影到等维嵌入中，然后根据每句话计算的置信权重进行融合。当在VoicePrivacy Attacker Challenge (VPAC) 数据集上评估我们的方法时，它在七个基准中的五个（即B3、B4、B5、T8-5和T12-5）上优于排名靠前的攻击者。为了进一步提升性能，我们利用匿名语音和SpecAugment作为增强技术。这种增强使VoxATtack在所有VPAC基准上都达到了最先进的水平，在T10-2和T25-1上分别获得了20.6%和27.2%的平均等错误率。我们的结果表明，结合文本信息和选择性数据增强揭示了当前语音匿名化方法的关键漏洞，并暴露了用于评估它们的数据集中潜在的弱点。", "summary": "本研究提出了一种名为VoxATtack的新型多模态去匿名化模型，旨在攻击语音匿名化系统。该模型首次将声学信息（通过ECAPA-TDNN处理匿名语音）与文本信息（通过BERT编码转录文本）结合，采用双分支架构并根据置信权重融合结果。实验证明，VoxATtack在VoicePrivacy Attacker Challenge (VPAC) 数据集上表现出色，通过引入文本信息和选择性数据增强（如匿名语音和SpecAugment），不仅超越了现有攻击模型，更在所有VPAC基准上达到了最先进的性能，从而揭示了当前语音匿名化方法及其评估数据集的潜在漏洞。", "keywords": "语音匿名化, 多模态攻击, 去匿名化, 声学信息, 文本信息", "comments": "VoxATtack的创新之处在于其独特的多模态攻击策略，首次有效地将声学和文本信息结合起来，显著提升了对语音匿名化系统的攻击效果。这不仅提供了一个强大的去匿名化工具，更重要的是，它揭示了现有匿名化技术和评估数据集的关键弱点，对未来隐私保护技术的发展具有重要指导意义。"}}
{"id": "2507.04632", "title": "Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?", "authors": ["Yun Qu", "Qi Cheems Wang", "Yixiu Mao", "Vincent Tao Hu", "Xiangyang Ji"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04632v2", "summary": "Recent advances have witnessed the effectiveness of reinforcement learning\n(RL) finetuning in enhancing the reasoning capabilities of large language\nmodels (LLMs). The optimization process often requires numerous iterations to\nachieve satisfactory performance, resulting in high computational costs due to\nthe need for frequent prompt evaluations under intensive LLM interactions and\nrepeated policy updates. Appropriate online prompt selection methods reduce\niteration steps by prioritizing informative prompts during training, while the\npipeline's reliance on exhaustive prompt evaluation and subset selection for\noptimization still incurs substantial computational overhead due to frequent\nLLM inference calls. Distinguished from these direct evaluate-then-select\nschemes, this work investigates iterative approximate evaluation for arbitrary\nprompts and introduces Model Predictive Prompt Selection (MoPPS), a Bayesian\nrisk-predictive framework that online estimates prompt difficulty without\nrequiring costly LLM interactions. Technically, MoPPS models each prompt's\nsuccess rate as a latent variable, performs streaming Bayesian inference, and\nemploys posterior sampling in a constructed multi-armed bandit machine,\nenabling sample efficient and adaptive prompt selection. Extensive experiments\nacross mathematics, planning, and vision-based geometry tasks show that MoPPS\nreliably predicts prompt difficulty and accelerates training with significantly\nreduced LLM rollouts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04632v2", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-16", "AI": {"title_translation": "提示难度能否在线预测以加速推理模型的强化学习微调？", "tldr": "本文提出了MoPPS，一个贝叶斯风险预测框架，无需昂贵的LLM交互即可在线估计提示难度，显著加速了推理模型的强化学习微调。", "motivation": "强化学习微调在增强大型语言模型（LLMs）推理能力方面表现出色，但其优化过程需要大量迭代，导致高昂的计算成本，因为需要频繁的提示评估和策略更新。现有的提示选择方法仍依赖于昂贵的LLM推理调用。", "method": "本文提出了模型预测提示选择（MoPPS）框架，它是一个贝叶斯风险预测框架，能够在线估计提示难度，而无需昂贵的LLM交互。MoPPS将每个提示的成功率建模为潜在变量，执行流式贝叶斯推断，并在构建的多臂赌博机中采用后验抽样，从而实现样本高效和自适应的提示选择。", "result": "在数学、规划和基于视觉的几何任务上的大量实验表明，MoPPS能够可靠地预测提示难度，并通过显著减少LLM的Rollout来加速训练。", "conclusion": "MoPPS通过在线预测提示难度，提供了一种无需昂贵LLM交互的样本高效且自适应的提示选择方法，显著加速了大型语言模型强化学习微调过程。", "translation": "最近的进展表明，强化学习（RL）微调在增强大型语言模型（LLMs）的推理能力方面非常有效。然而，优化过程通常需要大量迭代才能达到满意的性能，由于需要频繁的提示评估和密集的LLM交互以及重复的策略更新，导致计算成本高昂。适当的在线提示选择方法通过在训练期间优先选择信息丰富的提示来减少迭代步骤，但该流程对穷举提示评估和子集选择进行优化，仍然会因为频繁的LLM推理调用而产生大量的计算开销。与这些直接的评估-然后-选择方案不同，这项工作研究了任意提示的迭代近似评估，并引入了模型预测提示选择（MoPPS），这是一个贝叶斯风险预测框架，无需昂贵的LLM交互即可在线估计提示难度。从技术上讲，MoPPS将每个提示的成功率建模为潜在变量，执行流式贝叶斯推断，并在构建的多臂赌博机中采用后验抽样，从而实现样本高效和自适应的提示选择。在数学、规划和基于视觉的几何任务上的大量实验表明，MoPPS能够可靠地预测提示难度，并通过显著减少LLM的Rollout来加速训练。", "summary": "本文提出了一种名为MoPPS（Model Predictive Prompt Selection）的贝叶斯风险预测框架，旨在解决大型语言模型强化学习微调过程中高昂的计算成本问题。MoPPS无需昂贵的LLM交互，即可在线预测提示难度。它通过将提示成功率建模为潜在变量，并结合流式贝叶斯推断和多臂赌博机中的后验抽样，实现了样本高效和自适应的提示选择。实验结果表明，MoPPS能可靠预测提示难度并显著加速训练，减少了LLM的Rollout。", "keywords": "强化学习, 大型语言模型, 提示选择, 贝叶斯推断, 计算效率", "comments": "本文提出了一种新颖的方法MoPPS，通过在线预测提示难度来加速大型语言模型的强化学习微调，而无需进行昂贵的LLM交互。其创新之处在于将贝叶斯推断和多臂赌博机理论应用于提示选择，实现了样本效率和自适应性，有效解决了LLM训练中的计算开销问题，对于推动LLM的实际应用具有重要意义。"}}
{"id": "2507.11819", "title": "A quasi-interpolation operator yielding fully computable error bounds", "authors": ["T. Chaumont-Frelet", "M. Vohralik"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11819v1", "summary": "We design a quasi-interpolation operator from the Sobolev space\n$H^1_0(\\Omega)$ to its finite-dimensional finite element subspace formed by\npiecewise polynomials on a simplicial mesh with a computable approximation\nconstant. The operator 1) is defined on the entire $H^1_0(\\Omega)$, no\nadditional regularity is needed; 2) allows for an arbitrary polynomial degree;\n3) works in any space dimension; 4) is defined locally, in vertex patches of\nmesh elements; 5) yields optimal estimates for both the $H^1$ seminorm and the\n$L^2$ norm error; 6) gives a computable constant for both the $H^1$ seminorm\nand the $L^2$ norm error; 7) leads to the equivalence of global-best and\nlocal-best errors; 8) possesses the projection property. Its construction\nfollows the so-called potential reconstruction from a posteriori error\nanalysis. Numerical experiments illustrate that our quasi-interpolation\noperator systematically gives the correct convergence rates in both the $H^1$\nseminorm and the $L^2$ norm and its certified overestimation factor is rather\nsharp and stable in all tested situations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11819v1", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "一个产生完全可计算误差界限的拟插值算子", "tldr": "本文设计了一种新的拟插值算子，用于有限元子空间，它能为H1和L2范数提供可计算且最优的误差界限，具有广泛适用性，并采用局部定义。", "motivation": "设计一个具有可计算误差常数的拟插值算子，该算子能处理任意多项式次数和空间维度，并在$H^1_0(\\Omega)$空间上无需额外正则性，同时提供最优的H1半范数和L2范数误差估计。", "method": "设计了一个从Sobolev空间$H^1_0(\\Omega)$到其有限维有限元子空间的拟插值算子。其构造遵循后验误差分析中的势重构方法。该算子具有多项式度数任意、适用于任何空间维度、局部定义、提供H1半范数和L2范数最优误差估计及可计算常数、以及具有投影性质等特点。", "result": "数值实验表明，该拟插值算子在H1半范数和L2范数中均系统地给出了正确的收敛速率，并且其认证的过高估计因子在所有测试情况下都相当精确和稳定。", "conclusion": "本文设计的拟插值算子能够为有限元方法提供最优且完全可计算的误差界限，并且在数值实验中表现出良好的收敛性和稳定性，具有广泛的适用性和实用价值。", "translation": "我们将Sobolev空间$H^1_0(\\Omega)$到其有限维有限元子空间（由单形网格上的分段多项式形成）设计了一个拟插值算子，该算子具有可计算的逼近常数。该算子：1) 定义在整个$H^1_0(\\Omega)$上，无需额外的正则性；2) 允许任意多项式次数；3) 适用于任何空间维度；4) 局部定义，在网格单元的顶点补丁中；5) 为$H^1$半范数和$L^2$范数误差都提供了最优估计；6) 为$H^1$半范数和$L^2$范数误差都提供了可计算常数；7) 导致全局最优和局部最优误差的等价性；8) 具有投影性质。其构造遵循后验误差分析中的所谓势重构。数值实验表明，我们的拟插值算子在$H^1$半范数和$L^2$范数中都系统地给出了正确的收敛速率，并且其认证的过高估计因子在所有测试情况下都相当精确和稳定。", "summary": "本文介绍了一种新型拟插值算子，它将Sobolev空间$H^1_0(\\Omega)$映射到有限元子空间。该算子具有可计算性、灵活性（支持任意多项式次数和任何空间维度）、局部定义等特点，并能为$H^1$半范数和$L^2$范数提供最优且可计算的误差界限。其构建基于后验误差分析中的势重构。数值实验验证了其有效性，显示出正确的收敛速率和精确稳定的过高估计因子。", "keywords": "拟插值算子, 误差界限, 有限元方法, Sobolev空间, 可计算常数", "comments": "该论文的创新之处在于开发了一个不仅能提供最优误差估计，而且能提供“完全可计算”误差界限的拟插值算子，这对于有限元方法中的实际误差控制至关重要。其广泛适用性（无需额外正则性、任意次数、任何维度）和局部定义使其高度通用。与后验误差分析的联系表明其在鲁棒误差估计方面的潜力。"}}
{"id": "2507.11702", "title": "Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption", "authors": ["Hein de Wilde", "Ali Mohammed Mansoor Alsahag", "Pierre Blanchet"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11702v1", "summary": "Railroad traffic disruption as a result of leaf-fall cost the UK rail\nindustry over 300 million per year and measures to mitigate such disruptions\nare employed on a large scale, with 1.67 million kilometers of track being\ntreated in the UK in 2021 alone. Therefore, the ability to anticipate the\ntiming of leaf-fall would offer substantial benefits for rail network\noperators, enabling the efficient scheduling of such mitigation measures.\nHowever, current methodologies for predicting leaf-fall exhibit considerable\nlimitations in terms of scalability and reliability. This study endeavors to\ndevise a prediction system that leverages specialized prediction methods and\nthe latest satellite data sources to generate both scalable and reliable\ninsights into leaf-fall timings. An LSTM network trained on ground-truth\nleaf-falling data combined with multispectral and meteorological satellite data\ndemonstrated a root-mean-square error of 6.32 days for predicting the start of\nleaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which\nimproves upon previous work on the topic, offers promising opportunities for\nthe optimization of leaf mitigation measures in the railway industry and the\nimprovement of our understanding of complex ecological systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11702v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "使用LSTM网络对卫星数据进行时间序列分类：一种预测落叶以最大限度减少铁路交通中断的方法", "tldr": "本研究利用LSTM网络和卫星数据，开发了一种可扩展且可靠的落叶预测系统，以帮助铁路运营商优化落叶缓解措施，从而减少每年数百万英镑的损失。", "motivation": "落叶导致的铁路交通中断每年给英国铁路行业造成超过3亿英镑的损失，并且现有的落叶预测方法在可扩展性和可靠性方面存在显著局限性。因此，能够预测落叶时间将为铁路网络运营商带来巨大益处，从而实现缓解措施的有效调度。", "method": "本研究开发了一个预测系统，该系统利用LSTM网络，并结合地面真实落叶数据、多光谱和气象卫星数据进行训练。", "result": "该模型在预测落叶开始时间方面的均方根误差为6.32天，在预测落叶结束时间方面的均方根误差为9.31天。", "conclusion": "该模型改进了之前的工作，为铁路行业优化落叶缓解措施和增进对复杂生态系统的理解提供了有前景的机会。", "translation": "落叶导致的铁路交通中断每年给英国铁路行业造成超过3亿英镑的损失，并且大规模实施了缓解此类中断的措施，仅2021年英国就有167万公里的轨道得到处理。因此，预测落叶时间的能力将为铁路网络运营商带来巨大益处，从而实现此类缓解措施的有效调度。然而，当前预测落叶的方法在可扩展性和可靠性方面存在显著局限性。本研究致力于设计一个预测系统，该系统利用专门的预测方法和最新的卫星数据源，生成关于落叶时间的可扩展且可靠的见解。在一个结合了地面真实落叶数据、多光谱和气象卫星数据训练的LSTM网络，在预测落叶开始时间方面的均方根误差为6.32天，在预测落叶结束时间方面的均方根误差为9.31天。该模型在先前工作的基础上有所改进，为铁路行业优化落叶缓解措施以及增进我们对复杂生态系统的理解提供了有前景的机会。", "summary": "本研究旨在开发一个可扩展且可靠的落叶预测系统，以应对落叶对铁路交通造成的巨大经济损失和现有预测方法的局限性。研究人员利用LSTM网络，结合地面真实落叶数据、多光谱和气象卫星数据进行训练。结果显示，该模型在预测落叶开始和结束时间方面分别达到了6.32天和9.31天的均方根误差。这项工作为铁路行业优化落叶缓解措施提供了新的机会，并有助于深入理解复杂的生态系统。", "keywords": "落叶预测, LSTM网络, 卫星数据, 铁路交通, 时间序列分类", "comments": "这项研究通过利用先进的LSTM网络和多源卫星数据，为铁路行业提供了一个创新且实用的解决方案，以应对落叶造成的交通中断问题。其创新之处在于结合了地面真实数据和卫星遥感数据，提高了预测的准确性和可扩展性。该模型的应用潜力巨大，不仅可以显著减少经济损失，还有助于提升对生态系统季节性变化的理解。"}}
{"id": "2507.11552", "title": "The AI Ethical Resonance Hypothesis: The Possibility of Discovering Moral Meta-Patterns in AI Systems", "authors": ["Tomasz Zgliczyński-Cuber"], "categories": ["cs.CY", "I.2.0; K.4.1"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      69 pages", "url": "http://arxiv.org/abs/2507.11552v1", "summary": "This paper presents a theoretical framework for the AI ethical resonance\nhypothesis, which proposes that advanced AI systems with purposefully designed\ncognitive structures (\"ethical resonators\") may emerge with the ability to\nidentify subtle moral patterns that are invisible to the human mind. The paper\nexplores the possibility that by processing and synthesizing large amounts of\nethical contexts, AI systems may discover moral meta-patterns that transcend\ncultural, historical, and individual biases, potentially leading to a deeper\nunderstanding of universal ethical foundations. The paper also examines a\nparadoxical aspect of the hypothesis, in which AI systems could potentially\ndeepen our understanding of what we traditionally consider essentially human -\nour capacity for ethical reflection.", "comment": "69 pages", "pdf_url": "http://arxiv.org/pdf/2507.11552v1", "cate": "cs.CY", "date": "2025-07-13", "updated": "2025-07-13", "AI": {"title_translation": "AI伦理共鸣假说：在AI系统中发现道德元模式的可能性", "tldr": "本文提出了AI伦理共鸣假说，认为具有特定认知结构的先进AI系统可能发现人类无法察觉的微妙道德模式和超越偏见的道德元模式，从而加深我们对伦理基础的理解。", "motivation": "探索先进AI系统是否有可能识别出人类难以察觉的道德模式，并发现超越文化、历史和个人偏见的道德元模式，从而加深对普遍伦理基础的理解。", "method": "本文提出了一个理论框架来探讨AI伦理共鸣假说，并分析了其潜在的可能性及一个悖论。", "result": "论文提出，通过处理和综合大量伦理语境，AI系统可能发现超越文化、历史和个人偏见的道德元模式，并可能因此加深我们对普遍伦理基础的理解。甚至可能深化我们对人类伦理反思能力的理解。", "conclusion": "AI伦理共鸣假说提出，通过设计特定的认知结构，AI系统可能发现人类无法察觉的道德模式和元模式，这不仅有助于加深对普遍伦理基础的理解，也可能重新审视人类自身的伦理能力。", "translation": "本文提出了AI伦理共鸣假说的理论框架，该假说认为，具有特定设计认知结构（“伦理共鸣器”）的先进AI系统可能会出现识别出人类思维无法察觉的微妙道德模式的能力。本文探讨了通过处理和综合大量伦理语境，AI系统可能发现超越文化、历史和个人偏见的道德元模式的可能性，这可能导致对普遍伦理基础的更深入理解。本文还审视了该假说的一个悖论方面，即AI系统有可能加深我们对传统上被认为是人类本质——我们的伦理反思能力——的理解。", "summary": "本文提出了“AI伦理共鸣假说”的理论框架，认为先进AI系统若配备特定认知结构（“伦理共鸣器”），将有能力识别出人类难以察觉的道德模式，并可能发现超越文化、历史和个人偏见的道德元模式。该假说探讨了AI通过处理大量伦理语境来深化对普遍伦理基础理解的可能性，并指出AI甚至可能反过来加深我们对人类伦理反思能力的理解，构成一个有趣的悖论。", "keywords": "AI伦理, 道德元模式, 伦理共鸣假说, AI系统, 道德模式", "comments": "这篇论文提出了一个引人深思的理论假说，探讨了AI在伦理领域超越人类感知能力的潜力。其创新点在于提出了“伦理共鸣器”的概念，并设想AI能够发现“道德元模式”，这为AI伦理研究开辟了新的视角。然而，作为纯理论框架，其可行性和实际实现路径仍有待后续研究的进一步论证。"}}
{"id": "2507.12189", "title": "BenchRL-QAS: Benchmarking reinforcement learning algorithms for quantum architecture search", "authors": ["Azhar Ikhtiarudin", "Aditi Das", "Param Thakkar", "Akash Kundu"], "categories": ["quant-ph", "cs.AI", "cs.LG", "cs.PF"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Comprehensive RL agent benchmark for QAS. Contributions are welcomed here: this https URL", "url": "http://arxiv.org/abs/2507.12189v1", "summary": "We introduce BenchRL-QAS, a unified benchmarking framework for systematically\nevaluating reinforcement learning (RL) algorithms in quantum architecture\nsearch (QAS) across diverse variational quantum algorithm tasks and system\nsizes ranging from 2- to 8-qubit. Our study benchmarks nine RL agents including\nboth value-based and policy-gradient methods on representative quantum problems\nsuch as variational quantum eigensolver, variational quantum state\ndiagonalization, quantum classification, and state preparation, spanning both\nnoiseless and realistic noisy regimes. We propose a weighted ranking metric\nthat balances accuracy, circuit depth, gate count, and computational\nefficiency, enabling fair and comprehensive comparison. Our results first\nreveal that RL-based quantum classifier outperforms baseline variational\nclassifiers. Then we conclude that no single RL algorithm is universally\noptimal when considering a set of QAS tasks; algorithmic performance is highly\ncontext-dependent, varying with task structure, qubit count, and noise. This\nempirical finding provides strong evidence for the \"no free lunch\" principle in\nRL-based quantum circuit design and highlights the necessity of tailored\nalgorithm selection and systematic benchmarking for advancing quantum circuit\nsynthesis. This work represents the most comprehensive RL-QAS benchmarking\neffort to date, and BenchRL-QAS along with all experimental data are made\npublicly available to support reproducibility and future research\nhttps://github.com/azhar-ikhtiarudin/bench-rlqas.", "comment": "Comprehensive RL agent benchmark for QAS. Contributions are welcomed\n  here: https://github.com/azhar-ikhtiarudin/bench-rlqas", "pdf_url": "http://arxiv.org/pdf/2507.12189v1", "cate": "quant-ph", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "量子架构搜索中强化学习算法的基准测试", "tldr": "引入BenchRL-QAS框架，对量子架构搜索中的强化学习算法进行基准测试，发现没有单一RL算法在所有QAS任务中普遍最优。", "motivation": "系统地评估量子架构搜索（QAS）中强化学习（RL）算法在不同变分量子算法任务和系统规模（2-8量子位）下的性能，并实现公平和全面的比较。", "method": "引入了BenchRL-QAS，一个统一的基准测试框架。对包括基于价值和策略梯度方法的九种RL智能体进行了基准测试，涵盖变分量子本征求解器、变分量子态对角化、量子分类和态制备等代表性量子问题，并考虑了无噪声和实际有噪声两种情况。提出了一个加权排名指标，平衡了准确性、电路深度、门计数和计算效率。", "result": "首先，基于RL的量子分类器优于基线变分分类器。其次，没有单一的RL算法在考虑一系列QAS任务时是普遍最优的；算法性能高度依赖于上下文，随任务结构、量子位数量和噪声而变化。", "conclusion": "这一实证发现为基于RL的量子电路设计中的“没有免费午餐”原则提供了强有力的证据，并强调了为推进量子电路合成而量身定制算法选择和系统基准测试的必要性。", "translation": "我们引入了BenchRL-QAS，这是一个统一的基准测试框架，用于系统地评估量子架构搜索（QAS）中的强化学习（RL）算法，涵盖从2到8量子位的各种变分量子算法任务和系统规模。我们的研究对九种RL智能体（包括基于价值和策略梯度方法）在代表性量子问题上进行了基准测试，例如变分量子本征求解器、变分量子态对角化、量子分类和态制备，涵盖无噪声和实际有噪声两种情况。我们提出了一种加权排名指标，平衡了准确性、电路深度、门计数和计算效率，从而实现了公平和全面的比较。我们的结果首先揭示了基于RL的量子分类器优于基线变分分类器。然后我们得出结论，在考虑一系列QAS任务时，没有单一的RL算法是普遍最优的；算法性能高度依赖于上下文，随任务结构、量子位数量和噪声而变化。这一实证发现为基于RL的量子电路设计中的“没有免费午餐”原则提供了强有力的证据，并强调了为推进量子电路合成而量身定制算法选择和系统基准测试的必要性。这项工作代表了迄今为止最全面的RL-QAS基准测试工作，BenchRL-QAS及其所有实验数据均已公开，以支持可重现性和未来的研究https://github.com/azhar-ikhtiarudin/bench-rlqas。", "summary": "本文引入了BenchRL-QAS，一个用于评估量子架构搜索（QAS）中强化学习（RL）算法的综合基准测试框架。该框架系统地测试了九种RL智能体，涵盖各种量子任务（如VQE、量子分类）和不同系统规模（2-8量子位），并考虑了无噪声和有噪声环境。文中提出了一种新的加权排名指标以实现公平比较。研究结果表明，基于RL的量子分类器优于基线方法，但更重要的是，没有单一的RL算法在QAS中是普遍最优的，这强调了“没有免费午餐”原则以及根据上下文选择算法的必要性。该框架及其数据已开源以支持可重现性。", "keywords": "强化学习, 量子架构搜索, 基准测试, 量子电路设计, 没有免费午餐原则", "comments": "该论文通过提供迄今为止最全面的QAS中RL基准测试工作，做出了重要贡献。BenchRL-QAS的引入和数据的公开可用性对于可重现性和促进量子电路合成的未来研究至关重要。关于“没有免费午餐”原则的发现特别有见地，它指导未来的研究转向定制解决方案，而不是寻求单一的最佳算法。"}}
{"id": "2507.11977", "title": "Recent results on searches with boosted Higgs bosons at CMS", "authors": ["Farouk Mokhtar"], "categories": ["hep-ex", "cs.LG"], "primary_category": "Subjects:       High Energy Physics - Experiment (hep-ex)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, The Thirteenth Annual Large Hadron Collider Physics (LHCP2025)", "url": "http://arxiv.org/abs/2507.11977v1", "summary": "The study of boosted Higgs bosons at the LHC provides a unique window to\nprobe Higgs boson couplings at high energy scales and search for signs of\nphysics beyond the standard model. In these proceedings, we present recent\nresults on boosted Higgs boson searches at the CMS experiment, highlighting\ninnovative reconstruction and tagging techniques that enhance sensitivity in\nthis challenging regime.", "comment": "6 pages, 3 figures, The Thirteenth Annual Large Hadron Collider\n  Physics (LHCP2025)", "pdf_url": "http://arxiv.org/pdf/2507.11977v1", "cate": "hep-ex", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "CMS上对增强型希格斯玻色子搜索的最新结果", "tldr": "CMS实验在大型强子对撞机上报告了增强型希格斯玻色子搜索的最新进展，重点介绍了提高探测灵敏度的新重建和标记技术。", "motivation": "研究增强型希格斯玻色子能够在高能尺度探测希格斯玻色子耦合，并寻找超越标准模型的物理迹象。", "method": "在CMS实验中，利用创新的重建和标记技术，增强了在挑战性区域的灵敏度，以搜索增强型希格斯玻色子。", "result": "文章展示了CMS实验在增强型希格斯玻色子搜索方面的最新结果，并强调了提高灵敏度的创新重建和标记技术。具体结果未在摘要中详细说明。", "conclusion": "摘要中未明确给出具体结论，主要内容是介绍CMS实验在增强型希格斯玻色子搜索方面的最新进展及其使用的创新技术。", "translation": "在大型强子对撞机（LHC）上研究增强型希格斯玻色子，为在高能尺度探测希格斯玻色子耦合以及寻找超越标准模型的物理迹象提供了一个独特的窗口。在本次会议记录中，我们介绍了CMS实验在增强型希格斯玻色子搜索方面的最新结果，重点强调了在此挑战性区域提高灵敏度的创新重建和标记技术。", "summary": "本文介绍了CMS实验在大型强子对撞机上对增强型希格斯玻色子的最新搜索结果。这项研究旨在通过探测高能尺度下的希格斯玻色子耦合，寻找超越标准模型的物理现象。为克服这一挑战性领域的困难，研究中采用了创新的重建和标记技术，显著提高了探测的灵敏度。", "keywords": "增强型希格斯玻色子, CMS实验, LHC, 超越标准模型物理, 重建技术", "comments": "该论文展示了CMS实验在粒子物理前沿领域的持续努力，特别是在高能物理中对希格斯玻色子性质的深入探索。强调创新重建和标记技术的重要性，表明在复杂实验环境中提高探测灵敏度是当前研究的关键挑战和发展方向。尽管摘要未提供具体结果，但其关注点在于方法学的进步，这对于未来的粒子物理实验至关重要。"}}
{"id": "2507.09888", "title": "NeuTSFlow: Modeling Continuous Functions Behind Time Series Forecasting", "authors": ["Huibo Xu", "Likang Wu", "Xianquan Wang", "Haoning Dang", "Chun-Wun Cheng", "Angelica I Aviles-Rivero", "Qi Liu"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09888v2", "summary": "Time series forecasting is a fundamental task with broad applications, yet\nconventional methods often treat data as discrete sequences, overlooking their\norigin as noisy samples of continuous processes. Crucially, discrete noisy\nobservations cannot uniquely determine a continuous function; instead, they\ncorrespond to a family of plausible functions. Mathematically, time series can\nbe viewed as noisy observations of a continuous function family governed by a\nshared probability measure. Thus, the forecasting task can be framed as\nlearning the transition from the historical function family to the future\nfunction family. This reframing introduces two key challenges: (1) How can we\nleverage discrete historical and future observations to learn the relationships\nbetween their underlying continuous functions? (2) How can we model the\ntransition path in function space from the historical function family to the\nfuture function family? To address these challenges, we propose NeuTSFlow, a\nnovel framework that leverages Neural Operators to facilitate flow matching for\nlearning path of measure between historical and future function families. By\nparameterizing the velocity field of the flow in infinite-dimensional function\nspaces, NeuTSFlow moves beyond traditional methods that focus on dependencies\nat discrete points, directly modeling function-level features instead.\nExperiments on diverse forecasting tasks demonstrate NeuTSFlow's superior\naccuracy and robustness, validating the effectiveness of the function-family\nperspective.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09888v2", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "NeuTSFlow：时间序列预测背后的连续函数建模", "tldr": "NeuTSFlow提出一种新方法，通过将时间序列视为连续函数族并利用神经算子和流匹配来建模函数空间中的过渡路径，从而在时间序列预测中实现更高的准确性和鲁棒性。", "motivation": "传统时间序列预测方法将数据视为离散序列，忽略了数据来源于连续过程的本质，且离散观测无法唯一确定连续函数，而是对应一个函数族。因此，需要一种方法来学习从历史函数族到未来函数族的过渡。", "method": "提出NeuTSFlow框架，利用神经算子（Neural Operators）促进流匹配（flow matching），以学习历史和未来函数族之间的测度路径。通过在无限维函数空间中参数化流的速度场，直接建模函数级特征。", "result": "在多样化的预测任务上，NeuTSFlow表现出卓越的准确性和鲁棒性。", "conclusion": "NeuTSFlow通过直接建模函数级特征和采用函数族视角，超越了传统方法，验证了函数族视角的有效性。", "translation": "时间序列预测是一项具有广泛应用的基础任务，但传统方法通常将数据视为离散序列，忽略了它们作为连续过程的噪声样本的起源。至关重要的是，离散的噪声观测无法唯一确定一个连续函数；相反，它们对应着一系列合理的函数。从数学角度看，时间序列可以被视为由共享概率测度支配的连续函数族的噪声观测。因此，预测任务可以被视为学习从历史函数族到未来函数族的过渡。这种重构引入了两个关键挑战：(1) 我们如何利用离散的历史和未来观测来学习其底层连续函数之间的关系？(2) 我们如何建模从历史函数族到未来函数族的函数空间中的过渡路径？为了解决这些挑战，我们提出了NeuTSFlow，这是一个新颖的框架，它利用神经算子来促进流匹配，从而学习历史和未来函数族之间的测度路径。通过在无限维函数空间中参数化流的速度场，NeuTSFlow超越了专注于离散点依赖的传统方法，转而直接建模函数级特征。在各种预测任务上的实验证明了NeuTSFlow卓越的准确性和鲁棒性，验证了函数族视角的有效性。", "summary": "本文提出了NeuTSFlow，一个用于时间序列预测的新颖框架。它突破了传统方法将数据视为离散序列的局限，将时间序列重新概念化为连续函数族的噪声观测。NeuTSFlow通过利用神经算子和流匹配技术，在无限维函数空间中直接建模从历史函数族到未来函数族的过渡路径，从而捕捉函数级特征而非离散点依赖。实验结果表明，NeuTSFlow在准确性和鲁棒性方面优于现有方法，验证了其基于函数族视角的有效性。", "keywords": "时间序列预测, 连续函数, 神经算子, 流匹配, 函数族", "comments": "这篇论文通过将时间序列预测问题重新定义为连续函数族之间的过渡学习，提出了一种新颖且具有创新性的视角。其利用神经算子和流匹配在无限维函数空间中直接建模函数级特征的方法，有望克服传统离散方法在处理时间序列连续性方面的局限性，为时间序列分析领域开辟了新的研究方向。"}}
{"id": "2507.12204", "title": "Tao-Technology for Teen Mobile Use: Harmonizing Adaptation, Autonomy, and Reflection", "authors": ["Pengyu Zhu", "Janghee Cho"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12204v1", "summary": "Adolescents' mobile technology use is often regulated through rigid control\nmechanisms that fail to account for their autonomy and natural usage patterns.\nDrawing on Taoist philosophy, particularly Wu Wei, Yin-Yang, and Zi Ran, this\nposition paper proposes Tao-Technology, a self-organizing, adaptive regulatory\nframework. Integrating insights from Reflective Informatics and Information\nEcologies, we explore how mobile technology can dynamically adjust to context\nwhile fostering self-reflection and meaning-making. This approach shifts from\nexternal restrictions to dynamic co-adaptative regulation, ensuring technology\ngovernance remains flexible yet structured, supporting adolescents in\ncultivating a balanced and intentional relationship with digital technology.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12204v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "青少年手机使用的道-技术：协调适应、自主与反思", "tldr": "本文基于道家哲学提出“道-技术”框架，旨在通过自我组织和自适应调节，帮助青少年建立与移动技术平衡、有意的关系，克服传统僵硬控制的不足。", "motivation": "现有针对青少年手机使用的管理机制过于僵化，未能充分考虑青少年的自主性和自然使用模式。", "method": "本文基于道家哲学（特别是无为、阴阳和自然）提出了一种名为“道-技术”的自我组织、自适应调节框架。该框架整合了反思信息学和信息生态学的见解，旨在使移动技术能够动态适应语境，同时促进自我反思和意义建构。", "result": "这种方法将管理方式从外部限制转向动态的协同适应性调节，从而确保技术治理既灵活又结构化。", "conclusion": "该方法旨在支持青少年培养与数字技术之间平衡且有意的关系。", "translation": "青少年手机的使用常受到僵化的控制机制限制，这些机制未能考虑到他们的自主性和自然使用模式。本文借鉴道家哲学，特别是无为、阴阳和自然思想，提出了一种名为“道-技术”的自我组织、自适应调节框架。我们整合了反思信息学和信息生态学的见解，探讨了移动技术如何动态地适应语境，同时促进自我反思和意义建构。这种方法将从外部限制转向动态的协同适应性调节，确保技术治理保持灵活而有结构，支持青少年培养与数字技术之间平衡且有意的关系。", "summary": "本文提出“道-技术”框架，该框架受道家哲学启发，旨在为青少年手机使用提供一种自我组织、自适应的调节方式。它整合了反思信息学和信息生态学，使移动技术能动态适应语境并促进自我反思，从而将管理模式从外部僵硬控制转变为动态协同适应，帮助青少年培养与数字技术之间平衡且有意的关系。", "keywords": "道家哲学, 青少年手机使用, 自适应调节, 自主性, 反思信息学", "comments": "该论文的创新之处在于将道家哲学思想引入移动技术管理领域，提供了一种新颖的、以用户自主性和适应性为核心的监管框架。它挑战了传统的僵化控制模式，强调了技术与用户之间动态的、共同进化的关系，对于青少年数字素养的培养具有重要意义。"}}
{"id": "2507.11640", "title": "Quantifying data needs in surrogate modeling for flow fields in 2D stirred tanks with physics-informed neural networks (PINNs)", "authors": ["Veronika Trávníková", "Eric von Lieres", "Marek Behr"], "categories": ["cs.CE", "76-10, 68T07 (Primary) 76D05, 35Q68 (Secondary)"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      24 pages, 18 figures", "url": "http://arxiv.org/abs/2507.11640v1", "summary": "Stirred tanks are vital in chemical and biotechnological processes,\nparticularly as bioreactors. Although computational fluid dynamics (CFD) is\nwidely used to model the flow in stirred tanks, its high computational\ncost$-$especially in multi-query scenarios for process design and\noptimization$-$drives the need for efficient data-driven surrogate models.\nHowever, acquiring sufficiently large datasets can be costly. Physics-informed\nneural networks (PINNs) offer a promising solution to reduce data requirements\nwhile maintaining accuracy by embedding underlying physics into neural network\n(NN) training. This study quantifies the data requirements of vanilla PINNs for\ndeveloping surrogate models of a flow field in a 2D stirred tank. We compare\nthese requirements with classical supervised neural networks and\nboundary-informed neural networks (BINNs). Our findings demonstrate that\nsurrogate models can achieve prediction errors around 3% across Reynolds\nnumbers from 50 to 5000 using as few as six datapoints. Moreover, employing an\napproximation of the velocity profile in place of real data labels leads to\nprediction errors of around 2.5%. These results indicate that even with limited\nor approximate datasets, PINNs can be effectively trained to deliver high\naccuracy comparable to high-fidelity data.", "comment": "24 pages, 18 figures", "pdf_url": "http://arxiv.org/pdf/2507.11640v1", "cate": "cs.CE", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "使用物理信息神经网络（PINNs）量化二维搅拌釜流场代理模型的数据需求", "tldr": "PINNs能够利用极少量甚至近似数据，以高精度模拟二维搅拌釜流场。", "motivation": "搅拌釜在化工和生物技术中至关重要，但传统的计算流体动力学（CFD）模拟成本高昂，尤其是在多查询场景下。虽然数据驱动的代理模型是解决方案，但获取大量数据成本也很高。物理信息神经网络（PINNs）有望在保持准确性的同时减少数据需求。", "method": "本研究量化了普通PINNs在开发二维搅拌釜流场代理模型时的数据需求，并将其与经典监督神经网络和边界信息神经网络（BINNs）进行了比较。研究还探讨了使用速度剖面的近似值代替真实数据标签的情况。", "result": "代理模型在使用少至六个数据点的情况下，可以在雷诺数50到5000的范围内实现约3%的预测误差。此外，使用速度剖面的近似值代替真实数据标签，导致约2.5%的预测误差。", "conclusion": "研究结果表明，即使使用有限或近似的数据集，物理信息神经网络（PINNs）也可以有效训练，以提供与高保真数据相当的高精度。", "translation": "搅拌釜在化学和生物技术过程中至关重要，尤其作为生物反应器。尽管计算流体动力学（CFD）广泛用于模拟搅拌釜中的流动，但其高计算成本——特别是在用于过程设计和优化的多查询场景中——推动了对高效数据驱动代理模型的需求。然而，获取足够大的数据集可能成本高昂。物理信息神经网络（PINNs）通过将底层物理嵌入到神经网络（NN）训练中，提供了一种有前景的解决方案，可以在保持准确性的同时减少数据需求。本研究量化了普通PINNs在开发二维搅拌釜流场代理模型时的数据需求。我们将这些需求与经典监督神经网络和边界信息神经网络（BINNs）进行了比较。我们的研究结果表明，代理模型在使用少至六个数据点的情况下，可以在雷诺数50到5000的范围内实现约3%的预测误差。此外，使用速度剖面的近似值代替真实数据标签，导致约2.5%的预测误差。这些结果表明，即使使用有限或近似的数据集，PINNs也可以有效训练以提供与高保真数据相当的高精度。", "summary": "本研究旨在量化物理信息神经网络（PINNs）在为二维搅拌釜流场构建代理模型时所需的数据量，以解决传统计算流体动力学（CFD）的高计算成本以及数据驱动模型数据采集昂贵的问题。研究对比了PINNs与其他神经网络类型的数据需求，并发现PINNs仅需少量（少至六个）数据点，甚至使用近似数据，即可实现高精度（预测误差分别约为3%和2.5%）的流场预测，这凸显了PINNs在数据稀缺或不精确情境下的高效性。", "keywords": "物理信息神经网络, 代理建模, 搅拌釜, 数据需求, 计算流体动力学", "comments": "本文的创新之处在于量化了PINNs在特定工程应用（搅拌釜）中对最小数据的需求。它强调了PINNs在数据采集成本高昂或数据有限的场景中的显著优势，表明即使使用非常稀疏或近似的数据也能实现高精度。这可能大大降低过程设计和优化中的计算成本和实验工作。"}}
{"id": "2507.12166", "title": "RadioDiff-3D: A 3D$\\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication", "authors": ["Xiucheng Wang", "Qiming Zhang", "Nan Cheng", "Junting Chen", "Zezhong Zhang", "Zan Li", "Shuguang Cui", "Xuemin Shen"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12166v1", "summary": "Radio maps (RMs) serve as a critical foundation for enabling\nenvironment-aware wireless communication, as they provide the spatial\ndistribution of wireless channel characteristics. Despite recent progress in RM\nconstruction using data-driven approaches, most existing methods focus solely\non pathloss prediction in a fixed 2D plane, neglecting key parameters such as\ndirection of arrival (DoA), time of arrival (ToA), and vertical spatial\nvariations. Such a limitation is primarily due to the reliance on static\nlearning paradigms, which hinder generalization beyond the training data\ndistribution. To address these challenges, we propose UrbanRadio3D, a\nlarge-scale, high-resolution 3D RM dataset constructed via ray tracing in\nrealistic urban environments. UrbanRadio3D is over 37$\\times$3 larger than\nprevious datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA,\nforming a novel 3D$\\times$33D dataset with 7$\\times$3 more height layers than\nprior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet\nwith 3D convolutional operators is proposed. Moreover, we further introduce\nRadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D\nconvolutional architecture. RadioDiff-3D supports both radiation-aware\nscenarios with known transmitter locations and radiation-unaware settings based\non sparse spatial observations. Extensive evaluations on UrbanRadio3D validate\nthat RadioDiff-3D achieves superior performance in constructing rich,\nhigh-dimensional radio maps under diverse environmental dynamics. This work\nprovides a foundational dataset and benchmark for future research in 3D\nenvironment-aware communication. The dataset is available at\nhttps://github.com/UNIC-Lab/UrbanRadio3D.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12166v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "RadioDiff-3D: 一个3D×3D无线电图数据集和基于生成扩散的6G环境感知通信基准", "tldr": "提出了RadioDiff-3D，一个用于6G环境感知通信的3D无线电图数据集和基于扩散模型的基准框架。", "motivation": "现有无线电图构建方法主要关注固定2D平面上的路径损耗预测，忽略了DoA、ToA和垂直空间变化等关键参数，且静态学习范式阻碍了泛化能力。", "method": "提出了UrbanRadio3D数据集，一个通过射线追踪在现实城市环境中构建的大规模、高分辨率3D无线电图数据集，其尺寸和包含的度量（路径损耗、DoA、ToA）均显著优于现有数据集。为基准测试3D无线电图构建，提出了一个带有3D卷积操作符的UNet模型。此外，还引入了RadioDiff-3D，一个基于扩散模型的生成框架，它利用了3D卷积架构，支持已知发射机位置和基于稀疏空间观测的两种场景。", "result": "在UrbanRadio3D数据集上的广泛评估验证了RadioDiff-3D在多样化环境动态下构建丰富、高维无线电图的卓越性能。", "conclusion": "这项工作为未来3D环境感知通信研究提供了基础数据集和基准。", "translation": "无线电图 (RMs) 作为实现环境感知无线通信的关键基础，它们提供了无线信道特性的空间分布。尽管最近在利用数据驱动方法构建RM方面取得了进展，但大多数现有方法仅关注固定2D平面上的路径损耗预测，忽略了诸如到达方向 (DoA)、到达时间 (ToA) 和垂直空间变化等关键参数。这种局限性主要是由于依赖静态学习范式，这阻碍了其超越训练数据分布的泛化能力。为了应对这些挑战，我们提出了UrbanRadio3D，一个通过在现实城市环境中进行射线追踪构建的大规模、高分辨率3D RM数据集。UrbanRadio3D在3D空间中比以前的数据集大37倍以上，包含路径损耗、DoA和ToA三个指标，形成了一个新颖的3D×33D数据集，其高度层比现有最先进 (SOTA) 数据集多7倍。为了基准测试3D RM构建，提出了一个带有3D卷积操作符的UNet模型。此外，我们进一步引入了RadioDiff-3D，一个基于扩散模型的生成框架，它利用了3D卷积架构。RadioDiff-3D支持已知发射机位置的辐射感知场景和基于稀疏空间观测的辐射非感知设置。在UrbanRadio3D上的广泛评估验证了RadioDiff-3D在多样化环境动态下构建丰富、高维无线电图的卓越性能。这项工作为未来3D环境感知通信研究提供了基础数据集和基准。该数据集可在 https://github.com/UNIC-Lab/UrbanRadio3D 获取。", "summary": "本文针对当前2D无线电图构建的局限性，提出了UrbanRadio3D数据集，这是一个大规模、高分辨率的3D无线电图数据集，包含了路径损耗、到达方向和到达时间等关键参数。同时，文章还引入了RadioDiff-3D，一个基于扩散模型的生成框架，利用3D卷积架构来构建丰富的高维3D无线电图。实验验证了RadioDiff-3D在构建3D无线电图方面的卓越性能，为6G环境感知通信提供了基础数据集和基准。", "keywords": "无线电图, 3D通信, 扩散模型, 数据集, 6G", "comments": "创新点在于首次构建了包含多维度（DoA、ToA、垂直变化）的大规模3D无线电图数据集，并提出了基于扩散模型的生成框架RadioDiff-3D用于3D无线电图构建。这对于突破现有2D路径损耗预测的局限，实现6G环境感知通信具有重要意义。"}}
{"id": "2507.12463", "title": "MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding", "authors": ["Renjie Li", "Ruijie Ye", "Mingyang Wu", "Hao Frank Yang", "Zhiwen Fan", "Hezhen Hu", "Zhengzhong Tu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12463v1", "summary": "Humans are integral components of the transportation ecosystem, and\nunderstanding their behaviors is crucial to facilitating the development of\nsafe driving systems. Although recent progress has explored various aspects of\nhuman behavior$\\unicode{x2014}$such as motion, trajectories, and\nintention$\\unicode{x2014}$a comprehensive benchmark for evaluating human\nbehavior understanding in autonomous driving remains unavailable. In this work,\nwe propose $\\textbf{MMHU}$, a large-scale benchmark for human behavior analysis\nfeaturing rich annotations, such as human motion and trajectories, text\ndescription for human motions, human intention, and critical behavior labels\nrelevant to driving safety. Our dataset encompasses 57k human motion clips and\n1.73M frames gathered from diverse sources, including established driving\ndatasets such as Waymo, in-the-wild videos from YouTube, and self-collected\ndata. A human-in-the-loop annotation pipeline is developed to generate rich\nbehavior captions. We provide a thorough dataset analysis and benchmark\nmultiple tasks$\\unicode{x2014}$ranging from motion prediction to motion\ngeneration and human behavior question answering$\\unicode{x2014}$thereby\noffering a broad evaluation suite. Project page :\nhttps://MMHU-Benchmark.github.io.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12463v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MMHU：一个大规模多模态人类行为理解基准", "tldr": "MMHU是一个大规模多模态数据集，旨在弥补自动驾驶领域人类行为理解综合基准的缺失，它包含丰富的标注和多项任务的基准测试。", "motivation": "尽管在人类行为（如运动、轨迹、意图）方面取得了进展，但自动驾驶领域仍缺乏一个用于评估人类行为理解的综合基准。理解人类行为对于开发安全的驾驶系统至关重要。", "method": "我们提出了MMHU，一个大规模人类行为分析基准，包含人类运动和轨迹、人类运动的文本描述、人类意图以及与驾驶安全相关的关键行为标签等丰富标注。数据集包含5.7万个人类运动片段和173万帧，数据来源于Waymo等现有驾驶数据集、YouTube上的野外视频以及自收集数据。开发了人机协作标注流程来生成丰富的行为描述。", "result": "MMHU数据集包含5.7万个人类运动片段和173万帧。该工作提供了详尽的数据集分析，并对从运动预测到运动生成和人类行为问答等多种任务进行了基准测试，提供了一个广泛的评估套件。", "conclusion": "MMHU是一个大规模多模态人类行为理解基准，通过提供丰富的标注和广泛的评估任务，弥补了自动驾驶领域人类行为理解综合基准的缺失，有助于安全驾驶系统的发展。", "translation": "人类是交通生态系统中不可或缺的组成部分，理解他们的行为对于促进安全驾驶系统的发展至关重要。尽管最近的进展探索了人类行为的各个方面——例如运动、轨迹和意图——但用于评估自动驾驶中人类行为理解的综合基准仍然缺失。在这项工作中，我们提出了MMHU，一个大规模人类行为分析基准，其特点是具有丰富的标注，例如人类运动和轨迹、人类运动的文本描述、人类意图以及与驾驶安全相关的关键行为标签。我们的数据集包含从不同来源（包括Waymo等已建立的驾驶数据集、YouTube上的野外视频和自收集数据）收集的5.7万个人类运动片段和173万帧。开发了一个人机协作标注流程来生成丰富的行为描述。我们提供了详尽的数据集分析，并对从运动预测到运动生成和人类行为问答等多种任务进行了基准测试，从而提供了一个广泛的评估套件。项目页面：https://MMHU-Benchmark.github.io。", "summary": "本文提出了MMHU，一个大规模多模态人类行为理解基准，旨在解决自动驾驶领域缺乏综合评估基准的问题。MMHU数据集包含来自多种来源的5.7万个人类运动片段和173万帧，并提供了人类运动、轨迹、意图和关键行为等丰富标注。通过人机协作标注流程生成行为描述，并对运动预测、运动生成和人类行为问答等多项任务进行了基准测试，为人类行为理解研究提供了全面的评估工具。", "keywords": "人类行为理解, 多模态基准, 自动驾驶, 数据集, MMHU", "comments": "MMHU的创新之处在于其大规模、多模态以及丰富的标注，特别强调了与驾驶安全相关的行为。其通过整合多样化的数据源（包括Waymo、YouTube和自收集数据）并采用人机协作标注流程，确保了数据集的广度和深度。该基准的重要性在于其为自动驾驶系统中的人类行为理解提供了一个急需的、全面的评估平台，有望推动相关研究的发展。"}}
{"id": "2507.07883", "title": "SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation", "authors": ["Hao Ban", "Gokul Ram Subramani", "Kaiyi Ji"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.07883v3", "summary": "Multi-task learning (MTL) enables a joint model to capture commonalities\nacross multiple tasks, reducing computation costs and improving data\nefficiency. However, a major challenge in MTL optimization is task conflicts,\nwhere the task gradients differ in direction or magnitude, limiting model\nperformance compared to single-task counterparts. Sharpness-aware minimization\n(SAM) minimizes task loss while simultaneously reducing the sharpness of the\nloss landscape. Our empirical observations show that SAM effectively mitigates\ntask conflicts in MTL. Motivated by these findings, we explore integrating SAM\ninto MTL but face two key challenges. While both the average loss gradient and\nindividual task gradients-referred to as global and local\ninformation-contribute to SAM, how to combine them remains unclear. Moreover,\ndirectly computing each task gradient introduces significant computational and\nmemory overheads. To address these challenges, we propose SAMO, a lightweight\n\\textbf{S}harpness-\\textbf{A}ware \\textbf{M}ulti-task \\textbf{O}ptimization\napproach, that leverages a joint global-local perturbation. The local\nperturbations are approximated using only forward passes and are layerwise\nnormalized to improve efficiency. Extensive experiments on a suite of\nmulti-task benchmarks demonstrate both the effectiveness and efficiency of our\nmethod. Code is available at https://github.com/OptMN-Lab/SAMO.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.07883v3", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-15", "AI": {"title_translation": "SAMO：一种结合全局-局部扰动的轻量级锐度感知多任务优化方法", "tldr": "SAMO是一种轻量级锐度感知多任务优化方法，通过结合全局-局部扰动并高效近似局部扰动来解决多任务学习中的任务冲突和计算开销问题。", "motivation": "多任务学习（MTL）中的任务冲突（梯度方向或大小不同）限制了模型性能。锐度感知最小化（SAM）能有效缓解任务冲突，但将其整合到MTL中面临如何结合全局和局部信息以及计算开销大的挑战。", "method": "提出SAMO，一种轻量级锐度感知多任务优化方法。它利用联合全局-局部扰动，并通过仅使用前向传播近似局部扰动并进行层级归一化来提高效率。", "result": "在多任务基准测试上进行了大量实验，证明了该方法的有效性和效率。", "conclusion": "SAMO通过其轻量级和高效的锐度感知优化策略，成功解决了多任务学习中的任务冲突和计算效率问题，提高了模型性能。", "translation": "多任务学习（MTL）使联合模型能够捕捉多个任务之间的共性，从而降低计算成本并提高数据效率。然而，MTL优化中的一个主要挑战是任务冲突，即任务梯度在方向或大小上存在差异，与单任务模型相比，这限制了模型性能。锐度感知最小化（SAM）在最小化任务损失的同时，也降低了损失景观的锐度。我们的经验观察表明，SAM能有效缓解MTL中的任务冲突。受这些发现的启发，我们探索将SAM整合到MTL中，但面临两个关键挑战。尽管平均损失梯度和各个任务梯度（分别称为全局信息和局部信息）都对SAM有贡献，但如何结合它们仍不清楚。此外，直接计算每个任务梯度会引入显著的计算和内存开销。为了解决这些挑战，我们提出了SAMO，一种轻量级的Sharpness-Aware Multi-task Optimization方法，它利用联合全局-局部扰动。局部扰动仅使用前向传播进行近似，并进行层级归一化以提高效率。在一系列多任务基准测试上进行了大量实验，证明了我们方法的有效性和效率。代码可在https://github.com/OptMN-Lab/SAMO获取。", "summary": "本文提出了SAMO，一种轻量级锐度感知多任务优化方法，旨在解决多任务学习中的任务冲突和计算效率问题。该方法结合了全局和局部扰动，并通过高效的前向传播和层级归一化来近似局部扰动，从而显著降低了计算和内存开销。实验证明SAMO在多任务基准测试上表现出卓越的有效性和效率。", "keywords": "多任务学习, 锐度感知最小化, 任务冲突, 全局-局部扰动, 轻量级优化", "comments": "SAMO的创新之处在于将锐度感知最小化（SAM）引入多任务学习，并通过巧妙的全局-局部扰动结合与高效的局部扰动近似，解决了MTL中常见的任务冲突和计算效率瓶颈。其轻量化设计使其具有实际应用价值。"}}
{"id": "2507.12284", "title": "MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks", "authors": ["Artem Chervyakov", "Alexander Kharitonov", "Pavel Zadorozhny", "Adamenko Pavel", "Rodion Levichev", "Dmitrii Vorobev", "Dmitrii Salikhov", "Aidar Valeev", "Alena Pestova", "Maria Dziuba", "Ilseyar Alimova", "Artem Zavgorodnev", "Aleksandr Medvedev", "Stanislav Moiseev", "Elena Bruches", "Daniil Grebenkin", "Roman Derunets", "Vikulov Vladimir", "Anton Emelyanov", "Dmitrii Babaev", "Vladimir V. Ivanov", "Valentin Malykh", "Alena Fenogenova"], "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12284v1", "summary": "Advancements in LLMs have enhanced task automation in software engineering;\nhowever, current evaluations primarily focus on natural language tasks,\noverlooking code quality. Most benchmarks prioritize high-level reasoning over\nexecutable code and real-world performance, leaving gaps in understanding true\ncapabilities and risks associated with these models in production. To address\nthis issue, we propose MERA Code, a new addition to the MERA benchmark family,\nspecifically focused on evaluating code for the latest code generation LLMs in\nRussian. This benchmark includes 11 evaluation tasks that span 8 programming\nlanguages. Our proposed evaluation methodology features a taxonomy that\noutlines the practical coding skills necessary for models to complete these\ntasks. The benchmark comprises an open-source codebase for users to conduct\nMERA assessments, a scoring system compatible with various programming\nenvironments, and a platform featuring a leaderboard and submission system. We\nevaluate open LLMs and frontier API models, analyzing their limitations in\nterms of practical coding tasks in non-English languages. We are publicly\nreleasing MERA to guide future research, anticipate groundbreaking features in\nmodel development, and standardize evaluation procedures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12284v1", "cate": "cs.SE", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MERA Code: 一个统一的代码生成跨任务评估框架", "tldr": "MERA Code是一个新的基准测试，用于评估大型语言模型在多种编程语言和任务中的代码生成能力，特别关注非英语环境下的实际编码技能。", "motivation": "当前对大型语言模型（LLMs）的评估主要集中在自然语言任务上，忽视了代码质量、可执行代码和实际性能，导致无法全面理解模型在生产环境中的真实能力和风险。", "method": "提出了MERA Code基准测试，它是MERA家族的新成员，专注于评估最新代码生成LLMs的俄语代码。该基准包含11个评估任务，涵盖8种编程语言。评估方法包括一个分类法，概述了模型完成任务所需的实际编码技能。基准包含一个开源代码库、一个兼容多种编程环境的评分系统以及一个带有排行榜和提交系统的平台。", "result": "我们评估了开源LLMs和前沿API模型，分析了它们在非英语语言实际编码任务中的局限性。", "conclusion": "公开发布MERA旨在指导未来的研究，预测模型开发中的突破性功能，并标准化评估程序。", "translation": "大型语言模型（LLMs）的进步增强了软件工程中的任务自动化；然而，当前的评估主要集中在自然语言任务，忽视了代码质量。大多数基准优先考虑高层次推理而非可执行代码和实际性能，这使得在理解这些模型在生产环境中的真实能力和相关风险方面存在空白。为了解决这个问题，我们提出了MERA Code，它是MERA基准家族的新成员，专门用于评估最新代码生成LLMs的俄语代码。该基准包括11个评估任务，涵盖8种编程语言。我们提出的评估方法具有一个分类法，概述了模型完成这些任务所需的实际编码技能。该基准包含一个供用户进行MERA评估的开源代码库、一个与各种编程环境兼容的评分系统，以及一个具有排行榜和提交系统的平台。我们评估了开源LLMs和前沿API模型，分析了它们在非英语语言实际编码任务中的局限性。我们正在公开发布MERA，以指导未来的研究，预测模型开发中的突破性功能，并标准化评估程序。", "summary": "本文提出了MERA Code，一个专门用于评估大型语言模型代码生成能力的新基准测试。针对现有评估忽视代码质量和实际性能的问题，MERA Code包含了11个跨8种编程语言的评估任务，并特别关注非英语（俄语）环境下的实际编码技能。该基准提供开源代码库、评分系统和排行榜平台，并通过评估发现当前模型在非英语编码任务中的局限性，旨在推动未来研究和标准化评估流程。", "keywords": "代码生成, LLMs评估, MERA Code, 编程语言, 基准测试", "comments": "MERA Code的创新之处在于其专注于LLM在代码生成方面的实际性能和代码质量评估，尤其是在非英语（俄语）环境下的表现，这填补了现有基准的空白。其统一的框架、多语言支持和对实际编码技能的关注，对于推动LLM在软件工程领域的应用和理解其局限性具有重要意义。"}}
{"id": "2504.02477", "title": "Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision", "authors": ["Xiaofeng Han", "Shunpeng Chen", "Zenghuang Fu", "Zhe Feng", "Lue Fan", "Dong An", "Changwei Wang", "Li Guo", "Weiliang Meng", "Xiaopeng Zhang", "Rongtao Xu", "Shibiao Xu"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      27 pages, 11 figures, survey paper submitted to Information Fusion", "url": "http://arxiv.org/abs/2504.02477v2", "summary": "Robot vision has greatly benefited from advancements in multimodal fusion\ntechniques and vision-language models (VLMs). We systematically review the\napplications of multimodal fusion in key robotic vision tasks, including\nsemantic scene understanding, simultaneous localization and mapping (SLAM), 3D\nobject detection, navigation and localization, and robot manipulation. We\ncompare VLMs based on large language models (LLMs) with traditional multimodal\nfusion methods, analyzing their advantages, limitations, and synergies.\nAdditionally, we conduct an in-depth analysis of commonly used datasets,\nevaluating their applicability and challenges in real-world robotic scenarios.\nFurthermore, we identify critical research challenges such as cross-modal\nalignment, efficient fusion strategies, real-time deployment, and domain\nadaptation, and propose future research directions, including self-supervised\nlearning for robust multimodal representations, transformer-based fusion\narchitectures, and scalable multimodal frameworks. Through a comprehensive\nreview, comparative analysis, and forward-looking discussion, we provide a\nvaluable reference for advancing multimodal perception and interaction in\nrobotic vision. A comprehensive list of studies in this survey is available at\nhttps://github.com/Xiaofeng-Han-Res/MF-RV.", "comment": "27 pages, 11 figures, survey paper submitted to Information Fusion", "pdf_url": "http://arxiv.org/pdf/2504.02477v2", "cate": "cs.RO", "date": "2025-04-03", "updated": "2025-07-16", "AI": {"title_translation": "多模态融合与视觉-语言模型：机器人视觉综述", "tldr": "该综述系统回顾了多模态融合和视觉-语言模型在机器人视觉任务中的应用，比较了不同方法，分析了数据集，并提出了未来的研究方向。", "motivation": "机器人视觉受益于多模态融合技术和视觉-语言模型（VLMs）的进步，因此有必要对这些技术进行系统回顾，并提供一个有价值的参考。", "method": "该论文通过以下方式进行：1. 系统回顾多模态融合在关键机器人视觉任务中的应用（语义场景理解、SLAM、3D目标检测、导航和定位、机器人操作）。2. 比较基于大型语言模型（LLMs）的VLMs与传统多模态融合方法，分析它们的优势、局限性和协同作用。3. 深入分析常用数据集，评估其在真实机器人场景中的适用性和挑战。4. 识别关键研究挑战并提出未来研究方向。", "result": "该综述比较了基于LLM的VLMs与传统多模态融合方法的优势、局限性及协同作用；深入分析了常用数据集的适用性和挑战；识别了跨模态对齐、高效融合策略、实时部署和域适应等关键研究挑战；并提出了自监督学习、基于Transformer的融合架构和可扩展多模态框架等未来研究方向。", "conclusion": "通过全面的回顾、比较分析和前瞻性讨论，该综述为推进机器人视觉中的多模态感知和交互提供了有价值的参考。", "translation": "机器人视觉已极大地受益于多模态融合技术和视觉-语言模型（VLMs）的进步。我们系统回顾了多模态融合在关键机器人视觉任务中的应用，包括语义场景理解、同步定位与建图（SLAM）、3D目标检测、导航与定位以及机器人操作。我们比较了基于大型语言模型（LLMs）的VLMs与传统多模态融合方法，分析了它们的优势、局限性以及协同作用。此外，我们对常用数据集进行了深入分析，评估了它们在真实机器人场景中的适用性和挑战。此外，我们还识别了跨模态对齐、高效融合策略、实时部署和域适应等关键研究挑战，并提出了未来的研究方向，包括用于鲁棒多模态表示的自监督学习、基于Transformer的融合架构以及可扩展的多模态框架。通过全面的回顾、比较分析和前瞻性讨论，我们为推进机器人视觉中的多模态感知和交互提供了有价值的参考。本综述中研究的完整列表可在 https://github.com/Xiaofeng-Han-Res/MF-RV 获取。", "summary": "这篇综述系统地回顾了多模态融合技术和视觉-语言模型（VLMs）在机器人视觉领域的应用。论文涵盖了语义场景理解、SLAM、3D目标检测、导航与定位以及机器人操作等关键任务。它比较了基于LLM的VLMs与传统多模态融合方法的优缺点，分析了常用数据集的适用性与挑战，并指出了跨模态对齐、高效融合、实时部署和域适应等研究难题。最后，文章提出了自监督学习、Transformer架构和可扩展框架等未来研究方向，为机器人视觉的多模态感知和交互提供了宝贵的参考。", "keywords": "机器人视觉, 多模态融合, 视觉-语言模型, 综述, 机器人操作", "comments": "该综述为机器人视觉领域的多模态融合和视觉-语言模型提供了一个全面且及时的概述。其价值在于系统性地梳理了现有技术、比较了不同方法、分析了数据集，并前瞻性地指出了未来研究方向和挑战，对于该领域的研究人员具有重要的参考价值。文章涵盖的任务范围广泛，从基础感知到高级操作，体现了其全面性。"}}
{"id": "2507.12105", "title": "Out-of-distribution data supervision towards biomedical semantic segmentation", "authors": ["Yiquan Gao", "Duohui Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This paper was published in Proceedings of SPIE Volume 13442 and is reprinted with permission. The official version is available at this https URL . One personal copy is allowed. Reproduction, distribution, or commercial use is prohibited", "url": "http://arxiv.org/abs/2507.12105v1", "summary": "Biomedical segmentation networks easily suffer from the unexpected\nmisclassification between foreground and background objects when learning on\nlimited and imperfect medical datasets. Inspired by the strong power of\nOut-of-Distribution (OoD) data on other visual tasks, we propose a data-centric\nframework, Med-OoD to address this issue by introducing OoD data supervision\ninto fully-supervised biomedical segmentation with none of the following needs:\n(i) external data sources, (ii) feature regularization objectives, (iii)\nadditional annotations. Our method can be seamlessly integrated into\nsegmentation networks without any modification on the architectures. Extensive\nexperiments show that Med-OoD largely prevents various segmentation networks\nfrom the pixel misclassification on medical images and achieves considerable\nperformance improvements on Lizard dataset. We also present an emerging\nlearning paradigm of training a medical segmentation network completely using\nOoD data devoid of foreground class labels, surprisingly turning out 76.1% mIoU\nas test result. We hope this learning paradigm will attract people to rethink\nthe roles of OoD data. Code is made available at\nhttps://github.com/StudioYG/Med-OoD.", "comment": "This paper was published in Proceedings of SPIE Volume 13442 and is\n  reprinted with permission. The official version is available at\n  https://doi.org/10.1117/12.3052988. One personal copy is allowed.\n  Reproduction, distribution, or commercial use is prohibited", "pdf_url": "http://arxiv.org/pdf/2507.12105v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "域外数据监督在生物医学语义分割中的应用", "tldr": "Med-OoD框架利用域外数据监督来解决生物医学图像分割中前景和背景对象的错误分类问题，无需额外数据或修改网络架构，并取得了显著的性能提升。", "motivation": "生物医学分割网络在有限且不完善的医疗数据集上学习时，容易出现前景和背景对象之间的意外错误分类。", "method": "本文提出了一种数据中心框架Med-OoD，通过引入域外（OoD）数据监督来解决生物医学语义分割中的前景背景误分类问题。该方法无需外部数据源、特征正则化目标或额外的标注，并且可以无缝集成到现有的分割网络中，无需对架构进行任何修改。此外，还提出了一种仅使用缺乏前景类别标签的OoD数据训练医学分割网络的新兴学习范式。", "result": "Med-OoD框架在医学图像上显著防止了各种分割网络的像素误分类，并在Lizard数据集上取得了显著的性能提升。此外，仅使用域外数据训练医学分割网络的新范式，在测试中获得了76.1%的mIoU。", "conclusion": "本研究提出了一种利用域外数据监督来改善生物医学语义分割的方法，并通过实验证明了其有效性。同时，还探索了一种仅使用域外数据训练医学分割网络的新范式，这有望促使人们重新思考域外数据在医学图像分析中的作用和潜力。", "translation": "生物医学分割网络在有限且不完善的医疗数据集上学习时，容易出现前景和背景对象之间的意外错误分类。受域外（OoD）数据在其他视觉任务上强大能力的启发，我们提出了一个数据中心框架Med-OoD，通过将OoD数据监督引入全监督生物医学分割来解决这个问题，而无需以下任何需求：(i)外部数据源，(ii)特征正则化目标，(iii)额外标注。我们的方法可以无缝集成到分割网络中，无需对架构进行任何修改。大量的实验表明，Med-OoD在很大程度上防止了各种分割网络在医学图像上的像素误分类，并在Lizard数据集上取得了显著的性能提升。我们还提出了一种新兴的学习范式，即完全使用缺乏前景类别标签的OoD数据训练医学分割网络，令人惊讶地获得了76.1%的mIoU测试结果。我们希望这种学习范式能吸引人们重新思考OoD数据的作用。代码已在https://github.com/StudioYG/Med-OoD提供。", "summary": "该论文提出了一个名为Med-OoD的数据中心框架，旨在通过引入域外（OoD）数据监督来解决生物医学图像分割中前景和背景对象的错误分类问题。Med-OoD的优势在于它不需要额外的外部数据源、特征正则化或额外标注，并且可以轻松集成到现有网络中。实验证明，该方法能有效减少像素误分类，并在Lizard数据集上显著提升性能。此外，论文还展示了一种创新的学习范式，即仅使用无前景类别标签的OoD数据训练医学分割网络，并取得了令人鼓舞的mIoU结果，这为域外数据在医学领域的新应用提供了思路。", "keywords": "域外数据, 生物医学分割, 语义分割, 数据监督, 医疗图像分析", "comments": "该论文的创新点在于提出了一个数据中心框架Med-OoD，巧妙地利用域外数据监督来解决生物医学图像分割中在有限数据集上的挑战，且无需额外的资源。其重要性在于提供了一种高效且实用的方法来提升医疗图像分析的性能。特别值得称赞的是，该研究探索了一种仅使用无前景类别标签的域外数据进行训练的新范式，并取得了令人惊讶的良好结果，这为未来域外数据在医疗图像分析中的应用开辟了全新的、可能更经济的路径。"}}
{"id": "2507.05297", "title": "Continuous Classification Aggregation", "authors": ["Zijun Meng"], "categories": ["cs.AI", "econ.TH", "math.CO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      9 pages; 2 figures", "url": "http://arxiv.org/abs/2507.05297v5", "summary": "We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean. We also provide a characterization for the case when $m=p=2$.", "comment": "9 pages; 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.05297v5", "cate": "cs.AI", "date": "2025-07-06", "updated": "2025-07-16", "AI": {"title_translation": "连续分类聚合", "tldr": "该论文证明了对于m≥3个对象和2≤p≤m个类型的模糊分类聚合函数，任何最优、独立且零全票通过的函数都必须是加权算术平均值，并提供了m=p=2情况下的特征描述。", "motivation": "Not mentioned in abstract", "method": "通过数学证明和特征描述。", "result": "证明了在特定条件下（m≥3个对象，2≤p≤m个类型），最优、独立且零全票通过的模糊分类聚合函数必须是加权算术平均值。同时，为m=p=2的情况提供了特征描述。", "conclusion": "该研究确立了在特定条件下，最优模糊分类聚合函数的形式为加权算术平均值，并为特定特殊情况提供了特征描述。", "translation": "我们证明，对于将m≥3个对象分类为2≤p≤m种类型的连续个体分类，任何最优、独立且零全票通过的模糊分类聚合函数都必须是加权算术平均值。我们还提供了m=p=2情况下的特征描述。", "summary": "本文从理论上证明了，当聚合至少三个对象到两到三种类型的连续个体分类时，任何最优、独立且零全票通过的模糊分类聚合函数都必须是加权算术平均值。此外，论文还为m=p=2的特殊情况提供了具体的特征描述。", "keywords": "模糊分类, 聚合函数, 加权算术平均值, 特征描述", "comments": "该论文的创新之处在于为特定条件下的最优模糊分类聚合函数提供了严格的数学证明，这对于该领域的理论理解具有重要意义。其重要性在于为聚合理论奠定了基础性结果。"}}
{"id": "2507.03564", "title": "2.5D Object Detection for Intelligent Roadside Infrastructure", "authors": ["Nikolai Polley", "Yacin Boualili", "Ferdinand Mütsch", "Maximilian Zipfl", "Tobias Fleck", "J. Marius Zöllner"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at 2025 IEEE 28th International Conference on Intelligent Transportation Systems (ITSC)", "url": "http://arxiv.org/abs/2507.03564v2", "summary": "On-board sensors of autonomous vehicles can be obstructed, occluded, or\nlimited by restricted fields of view, complicating downstream driving\ndecisions. Intelligent roadside infrastructure perception systems, installed at\nelevated vantage points, can provide wide, unobstructed intersection coverage,\nsupplying a complementary information stream to autonomous vehicles via\nvehicle-to-everything (V2X) communication. However, conventional 3D\nobject-detection algorithms struggle to generalize under the domain shift\nintroduced by top-down perspectives and steep camera angles. We introduce a\n2.5D object detection framework, tailored specifically for infrastructure\nroadside-mounted cameras. Unlike conventional 2D or 3D object detection, we\nemploy a prediction approach to detect ground planes of vehicles as\nparallelograms in the image frame. The parallelogram preserves the planar\nposition, size, and orientation of objects while omitting their height, which\nis unnecessary for most downstream applications. For training, a mix of\nreal-world and synthetically generated scenes is leveraged. We evaluate\ngeneralizability on a held-out camera viewpoint and in adverse-weather\nscenarios absent from the training set. Our results show high detection\naccuracy, strong cross-viewpoint generalization, and robustness to diverse\nlighting and weather conditions. Model weights and inference code are provided\nat: https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection", "comment": "Accepted at 2025 IEEE 28th International Conference on Intelligent\n  Transportation Systems (ITSC)", "pdf_url": "http://arxiv.org/pdf/2507.03564v2", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-16", "AI": {"title_translation": "面向智能路侧基础设施的2.5D目标检测", "tldr": "该研究提出了一种专为路侧基础设施摄像头设计的2.5D目标检测框架，通过将车辆地面投影检测为平行四边形，实现了在不同视角和恶劣天气下的高精度、强泛化性和鲁棒性检测，解决了车载传感器和传统3D检测的局限性。", "motivation": "车载传感器存在遮挡、遮蔽或视野受限等问题，影响自动驾驶决策。路侧基础设施可提供补充信息，但传统3D目标检测算法难以适应俯视视角和陡峭相机角度带来的域偏移。", "method": "提出一种专门针对路侧摄像头设计的2.5D目标检测框架。该方法通过在图像帧中将车辆的地面投影检测为平行四边形。平行四边形保留了目标在平面上的位置、大小和方向，同时省略了高度信息。训练数据混合使用真实世界和合成生成的场景。", "result": "实现了高检测精度、强大的跨视角泛化能力以及对不同光照和天气条件的鲁棒性。", "conclusion": "该2.5D目标检测框架对路侧基础设施应用有效且鲁棒，能为自动驾驶车辆提供有价值的补充信息。", "translation": "自动驾驶车辆的车载传感器可能被遮挡、遮蔽或受限于有限的视野，从而使后续驾驶决策复杂化。安装在高处有利位置的智能路侧基础设施感知系统可以提供广阔、无遮挡的交叉路口覆盖，通过车联网（V2X）通信为自动驾驶车辆提供补充信息流。然而，传统的3D目标检测算法在俯视视角和陡峭相机角度引入的域偏移下难以泛化。我们引入了一个2.5D目标检测框架，专门为基础设施路侧安装的摄像头量身定制。与传统的2D或3D目标检测不同，我们采用一种预测方法来检测图像帧中车辆的地面投影为平行四边形。该平行四边形保留了对象的平面位置、大小和方向，同时省略了其高度，而高度对于大多数下游应用来说是不必要的。为了训练，我们利用了真实世界和合成生成场景的混合数据。我们在一个未参与训练的相机视角和训练集中没有出现的恶劣天气场景下评估了泛化能力。我们的结果显示出高检测精度、强大的跨视角泛化能力以及对不同光照和天气条件的鲁棒性。模型权重和推理代码可在以下网址获取：https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection", "summary": "本文针对车载传感器在自动驾驶中的局限性，提出了一种专为智能路侧基础设施设计的2.5D目标检测框架。与传统2D或3D方法不同，该框架将车辆的地面投影检测为平行四边形，保留了平面位置、大小和方向信息，同时省略了高度。该框架利用真实世界和合成场景数据进行训练，在检测精度、跨视角泛化能力以及恶劣天气和光照条件下的鲁棒性方面表现出色，为自动驾驶车辆通过V2X通信提供了补充信息流。", "keywords": "2.5D目标检测, 路侧基础设施, V2X, 地面投影检测, 自动驾驶", "comments": "该论文创新性地提出了2.5D目标检测概念，通过将车辆地面投影表示为平行四边形，有效解决了路侧基础设施视角下的目标检测难题。这种方法在保留关键平面信息的同时简化了模型，提高了在复杂环境下的泛化能力和鲁棒性，对实现车路协同感知具有重要意义。"}}
{"id": "2507.11571", "title": "Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation", "authors": ["Varun Velankar"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11571v1", "summary": "Estimating a person's age from their gait has important applications in\nhealthcare, security and human-computer interaction. In this work, we review\nfifty-nine studies involving over seventy-five thousand subjects recorded with\nvideo, wearable and radar sensors. We observe that convolutional neural\nnetworks produce an average error of about 4.2 years, inertial-sensor models\nabout 4.5 years and multi-sensor fusion as low as 3.4 years, with notable\ndifferences between lab and real-world data. We then analyse sixty-three\nthousand eight hundred forty-six gait cycles from the OU-ISIR Large-Population\ndataset to quantify correlations between age and five key metrics: stride\nlength, walking speed, step cadence, step-time variability and joint-angle\nentropy, with correlation coefficients of at least 0.27. Next, we fine-tune a\nResNet34 model and apply Grad-CAM to reveal that the network attends to the\nknee and pelvic regions, consistent with known age-related gait changes.\nFinally, on a one hundred thousand sample subset of the VersatileGait database,\nwe compare support vector machines, decision trees, random forests, multilayer\nperceptrons and convolutional neural networks, finding that deep networks\nachieve up to 96 percent accuracy while processing each sample in under 0.1\nseconds. By combining a broad meta-analysis with new large-scale experiments\nand interpretable visualizations, we establish solid performance baselines and\npractical guidelines for reducing gait-age error below three years in\nreal-world scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11571v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "基于传感器步态年龄估计的数据驱动元分析和公共数据集评估", "tldr": "本文对59项基于传感器的步态年龄估计研究进行了元分析，并在公共数据集上进行了大规模实验，建立了性能基线和实用指南，旨在将步态年龄估计误差降低到三年以下。", "motivation": "从步态估计一个人的年龄在医疗保健、安全和人机交互方面具有重要应用。本研究旨在建立坚实的性能基线和实用指南，以在真实世界场景中将步态年龄估计误差降低到三年以下。", "method": "本研究回顾了59项涉及视频、可穿戴和雷达传感器的研究。分析了OU-ISIR大型人口数据集中的步态周期，量化了年龄与五个关键步态指标的相关性。微调了ResNet34模型并应用Grad-CAM进行解释。在VersatileGait数据库的子集上比较了多种机器学习和深度学习模型（包括SVM、决策树、随机森林、MLP和CNN）。", "result": "元分析显示，卷积神经网络的平均误差约为4.2年，惯性传感器模型约为4.5年，多传感器融合低至3.4年。年龄与关键步态指标的相关系数至少为0.27。Grad-CAM揭示网络关注膝盖和骨盆区域。深度网络在VersatileGait数据集上实现了高达96%的准确率，每个样本处理时间不到0.1秒。", "conclusion": "通过结合广泛的元分析、新的大规模实验和可解释的可视化，本研究建立了坚实的性能基线和实用指南，旨在将步态年龄估计误差在真实世界场景中降低到三年以下。", "translation": "从步态估计一个人的年龄在医疗保健、安全和人机交互方面具有重要应用。在这项工作中，我们回顾了五十九项研究，涉及超过七万五千名受试者，他们的数据通过视频、可穿戴设备和雷达传感器记录。我们观察到，卷积神经网络的平均误差约为4.2年，惯性传感器模型约为4.5年，多传感器融合的误差低至3.4年，实验室数据和真实世界数据之间存在显著差异。然后，我们分析了OU-ISIR大型人口数据集中的六万三千八百四十六个步态周期，以量化年龄与五个关键指标（步幅、步行速度、步频、步态时间变异性和关节角度熵）之间的相关性，相关系数至少为0.27。接下来，我们微调了一个ResNet34模型并应用Grad-CAM来揭示网络关注膝盖和骨盆区域，这与已知的与年龄相关的步态变化一致。最后，在VersatileGait数据库的十万个样本子集上，我们比较了支持向量机、决策树、随机森林、多层感知器和卷积神经网络，发现深度网络实现了高达96%的准确率，同时每个样本的处理时间不到0.1秒。通过将广泛的元分析与新的大规模实验和可解释的可视化相结合，我们建立了坚实的性能基线和实用指南，以在真实世界场景中将步态年龄估计误差降低到三年以下。", "summary": "本文对59项基于传感器的步态年龄估计研究进行了全面的数据驱动元分析，识别了各种方法的误差率。随后，它在公共数据集上进行了新的大规模实验，分析了步态指标与年龄的相关性，使用了可解释的深度学习模型（ResNet34与Grad-CAM），并在大型步态数据库上比较了不同的机器学习模型。该研究建立了性能基线，并提供了实用指南，以在真实世界环境中将步态年龄估计误差降低到三年以下。", "keywords": "步态年龄估计, 元分析, 传感器, 深度学习, 公共数据集", "comments": "该论文通过其全面的元分析，提供了对现有方法及其性能的广泛概述，具有创新性。其在公共数据集上的大规模评估，结合Grad-CAM等可解释的人工智能技术，通过建立稳健的基线和为实际应用提供实用指南，增加了显著的价值。将误差降低到三年以下的目标清晰且具有影响力。"}}
{"id": "2507.11773", "title": "Small Data Explainer -- The impact of small data methods in everyday life", "authors": ["Maren Hackenberg", "Sophia G. Connor", "Fabian Kabus", "June Brawner", "Ella Markham", "Mahi Hardalupas", "Areeq Chowdhury", "Rolf Backofen", "Anna Köttgen", "Angelika Rohde", "Nadine Binder", "Harald Binder", "the Collaborative Research Center 1597 Small Data"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Written in collaboration with the Royal Society, contributing to the Disability Technology report ( this https URL )", "url": "http://arxiv.org/abs/2507.11773v1", "summary": "The emergence of breakthrough artificial intelligence (AI) techniques has led\nto a renewed focus on how small data settings, i.e., settings with limited\ninformation, can benefit from such developments. This includes societal issues\nsuch as how best to include under-represented groups in data-driven policy and\ndecision making, or the health benefits of assistive technologies such as\nwearables. We provide a conceptual overview, in particular contrasting small\ndata with big data, and identify common themes from exemplary case studies and\napplication areas. Potential solutions are described in a more detailed\ntechnical overview of current data analysis and modelling techniques,\nhighlighting contributions from different disciplines, such as knowledge-driven\nmodelling from statistics and data-driven modelling from computer science. By\nlinking application settings, conceptual contributions and specific techniques,\nwe highlight what is already feasible and suggest what an agenda for fully\nleveraging small data might look like.", "comment": "Written in collaboration with the Royal Society, contributing to the\n  Disability Technology report\n  (https://royalsociety.org/news-resources/projects/disability-data-assistive-technology/)", "pdf_url": "http://arxiv.org/pdf/2507.11773v1", "cate": "cs.CY", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "小数据解释器——小数据方法在日常生活中的影响", "tldr": "本文对小数据方法进行了概念性和技术性概述，将其与大数据进行对比，并探讨了其在日常生活中，特别是在解决社会问题方面的影响和未来潜力。", "motivation": "随着突破性人工智能（AI）技术的出现，人们重新关注小数据环境（即信息有限的环境）如何从这些发展中受益，特别是在将代表性不足的群体纳入数据驱动的政策和决策制定以及可穿戴设备等辅助技术的健康益处等社会问题上。", "method": "本文提供了一个概念性概述，将小数据与大数据进行对比，并从示例案例研究和应用领域中识别出共同主题。此外，还对当前的数据分析和建模技术进行了详细的技术概述，强调了来自不同学科（如统计学的知识驱动建模和计算机科学的数据驱动建模）的贡献。", "result": "本文通过将应用设置、概念性贡献和具体技术联系起来，强调了目前已经可行的内容，并提出了充分利用小数据的议程可能是什么样子。", "conclusion": "本文通过连接应用背景、概念性见解和具体技术，展示了小数据方法的当前可行性，并提出了未来充分利用小数据的发展方向。", "translation": "突破性人工智能（AI）技术的出现，使得人们重新关注小数据环境（即信息有限的环境）如何从这些发展中受益。这包括社会问题，例如如何最好地将代表性不足的群体纳入数据驱动的政策和决策制定中，或可穿戴设备等辅助技术带来的健康益处。我们提供了一个概念性概述，特别是将小数据与大数据进行对比，并从示例案例研究和应用领域中识别出共同主题。在当前数据分析和建模技术的更详细技术概述中描述了潜在的解决方案，强调了来自不同学科的贡献，例如统计学的知识驱动建模和计算机科学的数据驱动建模。通过将应用设置、概念性贡献和具体技术联系起来，我们强调了目前已经可行的内容，并提出了充分利用小数据的议程可能是什么样子。", "summary": "本文探讨了小数据方法在日常生活中的影响和潜力，尤其是在信息有限的背景下。它提供了小数据与大数据的概念性比较，识别了案例研究中的共同主题，并概述了相关数据分析技术的细节。作者旨在突出当前的可行性，并提出未来利用小数据解决社会问题和改进辅助技术的方向。", "keywords": "小数据, 大数据, 人工智能, 数据分析, 社会影响", "comments": "在大数据时代，这篇论文对小数据的及时讨论显得尤为重要。其概念和技术概述，结合实际应用和未来议程，对于理解如何在信息有限的情况下有效应用人工智能，并解决关键社会挑战，具有宝贵的价值。"}}
{"id": "2507.12122", "title": "Soft-Constrained Spatially Selective Active Noise Control for Open-fitting Hearables", "authors": ["Tong Xiao", "Reinhild Roden", "Matthias Blau", "Simon Doclo"], "categories": ["eess.AS", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2025", "url": "http://arxiv.org/abs/2507.12122v1", "summary": "Recent advances in spatially selective active noise control (SSANC) using\nmultiple microphones have enabled hearables to suppress undesired noise while\npreserving desired speech from a specific direction. Aiming to achieve minimal\nspeech distortion, a hard constraint has been used in previous work in the\noptimization problem to compute the control filter. In this work, we propose a\nsoft-constrained SSANC system that uses a frequency-independent parameter to\ntrade off between speech distortion and noise reduction. We derive both time-\nand frequency-domain formulations, and show that conventional active noise\ncontrol and hard-constrained SSANC represent two limiting cases of the proposed\ndesign. We evaluate the system through simulations using a pair of open-fitting\nhearables in an anechoic environment with one speech source and two noise\nsources. The simulation results validate the theoretical derivations and\ndemonstrate that for a broad range of the trade-off parameter, the\nsignal-to-noise ratio and the speech quality and intelligibility in terms of\nPESQ and ESTOI can be substantially improved compared to the hard-constrained\ndesign.", "comment": "Accepted at IEEE Workshop on Applications of Signal Processing to\n  Audio and Acoustics (WASPAA) 2025", "pdf_url": "http://arxiv.org/pdf/2507.12122v1", "cate": "eess.AS", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "开放式助听设备中的软约束空间选择性主动噪声控制", "tldr": "提出了一种软约束空间选择性主动噪声控制系统，通过一个频率无关的参数权衡语音失真和降噪效果，并在仿真中表现出比硬约束设计显著的性能提升。", "motivation": "传统硬约束空间选择性主动噪声控制（SSANC）在最小化语音失真方面存在局限，需要一种新的方法来权衡语音失真和噪声抑制。", "method": "本文提出了一种软约束空间选择性主动噪声控制（SSANC）系统，该系统使用一个频率无关的参数来权衡语音失真和噪声抑制。研究推导了其时域和频域公式，并表明传统主动噪声控制和硬约束SSANC是所提设计的两种极限情况。系统通过在消声环境中对开放式助听设备进行仿真评估。", "result": "仿真结果验证了理论推导，并表明在较宽的权衡参数范围内，与硬约束设计相比，信噪比以及PESQ和ESTOI衡量的语音质量和可懂度都得到了显著改善。", "conclusion": "提出的软约束SSANC系统能够有效权衡语音失真和噪声抑制，并在性能上优于传统的硬约束设计。", "translation": "近期空间选择性主动噪声控制（SSANC）的进展，通过使用多个麦克风，使助听设备能够抑制不需要的噪声，同时保留来自特定方向的期望语音。为了实现最小的语音失真，在先前的研究中，优化问题中使用了硬约束来计算控制滤波器。在这项工作中，我们提出了一种软约束SSANC系统，该系统使用一个频率无关的参数来权衡语音失真和噪声抑制。我们推导了时域和频域公式，并表明传统主动噪声控制和硬约束SSANC代表了所提出设计的两种极限情况。我们通过在消声环境中，使用一对开放式助听设备，并设置一个语音源和两个噪声源进行仿真评估。仿真结果验证了理论推导，并表明在较宽的权衡参数范围内，与硬约束设计相比，信噪比以及PESQ和ESTOI衡量的语音质量和可懂度都得到了显著改善。", "summary": "本文提出了一种用于开放式助听设备的软约束空间选择性主动噪声控制（SSANC）系统，旨在通过引入一个频率无关的权衡参数来优化语音失真和噪声抑制之间的平衡。研究推导了该系统在时域和频域的公式，并证明了其包含传统ANC和硬约束SSANC作为特例。通过仿真验证，结果显示该软约束设计在广泛的参数范围内能显著提升信噪比、语音质量和可懂度，优于硬约束方案。", "keywords": "空间选择性主动噪声控制, 软约束, 助听设备, 噪声抑制, 语音质量", "comments": "这项工作通过引入软约束和频率无关的权衡参数，为空间选择性主动噪声控制提供了一种更灵活和性能更优的方法。其创新之处在于能够动态调整语音失真和噪声抑制之间的平衡，这对于开放式助听设备等对语音质量要求较高的场景尤为重要。通过将传统ANC和硬约束SSANC视为其极限情况，也展示了其理论上的普适性。"}}
{"id": "2507.12021", "title": "Incorporating Fairness Constraints into Archetypal Analysis", "authors": ["Aleix Alcacer", "Irene Epifanio"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12021v1", "summary": "Archetypal Analysis (AA) is an unsupervised learning method that represents\ndata as convex combinations of extreme patterns called archetypes. While AA\nprovides interpretable and low-dimensional representations, it can\ninadvertently encode sensitive attributes, leading to fairness concerns. In\nthis work, we propose Fair Archetypal Analysis (FairAA), a modified formulation\nthat explicitly reduces the influence of sensitive group information in the\nlearned projections. We also introduce FairKernelAA, a nonlinear extension that\naddresses fairness in more complex data distributions. Our approach\nincorporates a fairness regularization term while preserving the structure and\ninterpretability of the archetypes. We evaluate FairAA and FairKernelAA on\nsynthetic datasets, including linear, nonlinear, and multi-group scenarios,\ndemonstrating their ability to reduce group separability -- as measured by mean\nmaximum discrepancy and linear separability -- without substantially\ncompromising explained variance. We further validate our methods on the\nreal-world ANSUR I dataset, confirming their robustness and practical utility.\nThe results show that FairAA achieves a favorable trade-off between utility and\nfairness, making it a promising tool for responsible representation learning in\nsensitive applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12021v1", "cate": "stat.ML", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "将公平性约束纳入原型分析", "tldr": "本文提出了FairAA和FairKernelAA，旨在将公平性约束纳入原型分析（AA），以减少敏感属性的影响，同时保持可解释性，并在合成和真实数据集上验证了其在公平性与效用之间取得良好平衡的能力。", "motivation": "原型分析（AA）作为一种无监督学习方法，在提供可解释且低维表示的同时，可能会无意中编码敏感属性，从而引发公平性问题。", "method": "本研究提出了Fair Archetypal Analysis (FairAA) 这一改进的公式，它明确减少了敏感组信息在学习投影中的影响。此外，还引入了FairKernelAA，这是一个非线性扩展，用于处理更复杂数据分布中的公平性问题。该方法通过引入公平性正则化项，同时保留了原型的结构和可解释性。", "result": "FairAA和FairKernelAA在包括线性、非线性和多组场景的合成数据集上进行了评估，结果表明它们能够减少群体可分离性（通过平均最大差异和线性可分离性衡量），而不会实质性地损害解释方差。在真实的ANSUR I数据集上的进一步验证，确认了其鲁棒性和实用性。结果显示，FairAA在效用和公平性之间取得了有利的权衡。", "conclusion": "FairAA在效用和公平性之间取得了有利的权衡，使其成为敏感应用中负责任表示学习的一个有前景的工具。", "translation": "原型分析（AA）是一种无监督学习方法，它将数据表示为称为原型的极端模式的凸组合。虽然AA提供了可解释的低维表示，但它可能会无意中编码敏感属性，从而导致公平性问题。在这项工作中，我们提出了公平原型分析（FairAA），这是一种改进的公式，它明确减少了敏感组信息在学习投影中的影响。我们还引入了FairKernelAA，这是一个非线性扩展，用于处理更复杂数据分布中的公平性问题。我们的方法通过引入公平性正则化项，同时保留了原型的结构和可解释性。我们在合成数据集（包括线性、非线性和多组场景）上评估了FairAA和FairKernelAA，证明了它们在不实质性损害解释方差的情况下减少组可分离性（通过平均最大差异和线性可分离性衡量）的能力。我们进一步在真实的ANSUR I数据集上验证了我们的方法，证实了它们的鲁棒性和实用性。结果表明，FairAA在效用和公平性之间取得了有利的权衡，使其成为敏感应用中负责任表示学习的一个有前景的工具。", "summary": "本文针对原型分析（AA）可能无意中编码敏感属性导致的公平性问题，提出了Fair Archetypal Analysis (FairAA) 及其非线性扩展FairKernelAA。这些方法通过引入公平性正则化项，旨在减少敏感组信息的影响，同时保持原型的可解释性。在合成和真实数据集上的实验验证了所提方法能够有效降低群体可分离性，并在保持解释方差的同时，在效用与公平性之间取得良好平衡，为敏感应用中的负责任表示学习提供了有前景的工具。", "keywords": "公平性约束, 原型分析, 无监督学习, 表示学习, FairAA", "comments": "这项工作在可解释的无监督学习方法（原型分析）中引入了公平性约束，具有重要的创新性。通过提出FairAA和FairKernelAA，它解决了AI模型中普遍存在的偏见问题，尤其是在需要透明和公正决策的敏感领域。其贡献在于不仅提出了理论框架，还通过实验证明了在公平性和模型效用之间取得了实用的权衡，这对于推动负责任的AI发展至关重要。"}}
{"id": "2507.12260", "title": "Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese", "authors": ["Yikang Liu", "Wanyang Zhang", "Yiming Wang", "Jialong Tang", "Pei Zhang", "Baosong Yang", "Fei Huang", "Rui Wang", "Hai Hu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12260v1", "summary": "In this paper, we propose the first quantitative measure for translationese\n-- the translationese-index (T-index) for graded and generalizable measurement\nof translationese, computed from the likelihood ratios of two contrastively\nfine-tuned language models (LMs). We use a synthesized dataset and a dataset\nwith translations in the wild to evaluate T-index's generalizability in\ncross-domain settings and its validity against human judgments. Our results\nshow that T-index is both robust and efficient. T-index scored by two 0.5B LMs\nfine-tuned on only 1-5k pairs of synthetic data can well capture translationese\nin the wild. We find that the relative differences in T-indices between\ntranslations can well predict pairwise translationese annotations obtained from\nhuman annotators; and the absolute values of T-indices correlate well with\nhuman ratings of degrees of translationese (Pearson's $r = 0.568$).\nAdditionally, the correlation between T-index and existing machine translation\n(MT) quality estimation (QE) metrics such as BLEU and COMET is low, suggesting\nthat T-index is not covered by these metrics and can serve as a complementary\nmetric in MT QE.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12260v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "翻译腔指数：使用似然比进行翻译腔的渐进式和通用化测量", "tldr": "提出并验证了一种基于语言模型似然比的翻译腔量化指标——翻译腔指数（T-index），它能有效捕捉翻译腔程度，且与现有机器翻译质量评估指标互补。", "motivation": "现有研究缺乏对“翻译腔”的定量、渐进式和通用化测量方法。", "method": "提出翻译腔指数（T-index），通过两个对比性微调的语言模型（LMs）的似然比计算得出。使用合成数据集和真实翻译数据集评估 T-index 在跨领域设置中的通用性及其与人类判断的有效性。", "result": "T-index 鲁棒且高效；仅用少量合成数据微调的 0.5B LMs 即可很好地捕捉真实翻译中的翻译腔。T-index 的相对差异能很好地预测人类对翻译腔的成对标注，其绝对值与人类对翻译腔程度的评分有良好相关性（Pearson's r = 0.568）。T-index 与现有机器翻译质量评估（MT QE）指标（如 BLEU 和 COMET）相关性低，表明它是一个互补指标。", "conclusion": "T-index 是首个定量测量翻译腔的方法，具有良好的通用性、鲁棒性和效率，并且可以作为机器翻译质量评估的补充指标。", "translation": "在本文中，我们提出了第一个翻译腔的定量测量方法——翻译腔指数（T-index），用于翻译腔的渐进式和通用化测量，它由两个对比性微调的语言模型（LMs）的似然比计算得出。我们使用一个合成数据集和一个包含真实翻译的数据集来评估 T-index 在跨领域设置中的通用性及其与人类判断的有效性。我们的结果表明 T-index 既鲁棒又高效。由两个仅在 1-5k 对合成数据上微调的 0.5B LMs 评分的 T-index 能够很好地捕捉真实翻译中的翻译腔。我们发现翻译之间 T-index 的相对差异能够很好地预测从人类标注者获得的成对翻译腔标注；T-index 的绝对值与人类对翻译腔程度的评分有很好的相关性（Pearson's r = 0.568）。此外，T-index 与现有机器翻译（MT）质量评估（QE）指标（如 BLEU 和 COMET）之间的相关性较低，这表明 T-index 不被这些指标涵盖，可以作为 MT QE 中的补充指标。", "summary": "本文提出了一种新颖的定量测量翻译腔的方法——翻译腔指数（T-index）。该指数通过对比性微调的语言模型的似然比计算，旨在提供一个渐进式和通用化的翻译腔度量。研究表明，T-index 在跨领域设置中表现出良好的通用性，并且其结果与人类对翻译腔的判断高度一致。此外，T-index 与现有机器翻译质量评估指标（如 BLEU 和 COMET）的相关性较低，表明它可以作为机器翻译质量评估的有效补充工具。", "keywords": "翻译腔, 语言模型, 似然比, 定量测量, 机器翻译质量评估", "comments": "这篇论文的创新点在于提出了首个定量且通用化的翻译腔测量方法，填补了该领域的空白。T-index 基于语言模型似然比，概念新颖且易于实现。其与人类判断的高度一致性以及与现有MT QE指标的互补性，都显示了其潜在的重要应用价值，尤其是在理解和评估翻译质量的细微差别方面。"}}
{"id": "2507.12255", "title": "Freshness, Persistence and Success of Scientific Teams", "authors": ["Hanjo D. Boekhout", "Eelke M. Heemskerk", "Nicolò Pisani", "Frank W. Takes"], "categories": ["cs.DL", "cs.SI"], "primary_category": "Subjects:       Digital Libraries (cs.DL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12255v1", "summary": "Team science dominates scientific knowledge production, but what makes\nacademic teams successful? Using temporal data on 25.2 million publications and\n31.8 million authors, we propose a novel network-driven approach to identify\nand study the success of persistent teams. Challenging the idea that\npersistence alone drives success, we find that team freshness - new\ncollaborations built on prior experience - is key to success. High impact\nresearch tends to emerge early in a team's lifespan. Analyzing complex team\noverlap, we find that teams open to new collaborative ties consistently produce\nbetter science. Specifically, team re-combinations that introduce new freshness\nimpulses sustain success, while persistence impulses from experienced teams are\nlinked to earlier impact. Together, freshness and persistence shape team\nsuccess across collaboration stages.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12255v1", "cate": "cs.DL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "科学团队的新颖性、持久性与成功", "tldr": "新颖性（基于经验的新合作）而非单独的持久性是科学团队成功的关键，高影响力研究常在早期出现，开放新合作的团队表现更好。", "motivation": "探究学术团队成功的原因。", "method": "使用包含2520万出版物和3180万作者的时间数据，提出一种新颖的网络驱动方法来识别和研究持久团队的成功。", "result": "研究发现，团队的新颖性（基于先前经验建立的新合作）是成功的关键，而非单独的持久性。高影响力研究倾向于在团队生命周期的早期出现。对新合作关系开放的团队持续产生更好的科学成果。引入新颖性冲动的团队重组能维持成功，而经验丰富的团队的持久性冲动则与早期影响力相关。", "conclusion": "新颖性和持久性共同塑造了团队在不同合作阶段的成功。", "translation": "团队科学主导着科学知识的生产，但什么能让学术团队成功？我们利用2520万份出版物和3180万名作者的时间数据，提出了一种新颖的网络驱动方法来识别和研究持久团队的成功。挑战了单独的持久性驱动成功的观点，我们发现团队的新颖性——在先前经验基础上建立的新合作——是成功的关键。高影响力研究倾向于在团队生命周期的早期出现。通过分析复杂的团队重叠，我们发现对新合作关系开放的团队持续产生更好的科学成果。具体来说，引入新颖性冲动的团队重组能维持成功，而经验丰富的团队的持久性冲动则与早期影响力相关。新颖性和持久性共同塑造了团队在不同合作阶段的成功。", "summary": "该研究利用大量出版物和作者数据，提出一种网络驱动方法来分析科学团队的成功因素。研究发现，团队的新颖性，即在现有经验基础上建立的新合作，是团队成功的关键，而非单纯的持久性。高影响力研究常在团队早期出现。此外，对新合作关系开放的团队能持续产出更优秀的科学成果，其中引入新颖性冲动的团队重组能维持成功，而经验团队的持久性则与早期影响力相关。最终，新颖性和持久性共同决定了团队在不同合作阶段的成功。", "keywords": "科学团队, 新颖性, 持久性, 团队成功, 合作", "comments": "这项研究通过大规模数据分析，挑战了传统观点，强调了团队“新颖性”在科学合作中的重要性，对理解和促进学术团队成功具有重要意义。"}}
{"id": "2507.11855", "title": "OrdShap: Feature Position Importance for Sequential Black-Box Models", "authors": ["Davin Hill", "Brian L. Hill", "Aria Masoomi", "Vijay S. Nori", "Robert E. Tillman", "Jennifer Dy"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11855v1", "summary": "Sequential deep learning models excel in domains with temporal or sequential\ndependencies, but their complexity necessitates post-hoc feature attribution\nmethods for understanding their predictions. While existing techniques quantify\nfeature importance, they inherently assume fixed feature ordering - conflating\nthe effects of (1) feature values and (2) their positions within input\nsequences. To address this gap, we introduce OrdShap, a novel attribution\nmethod that disentangles these effects by quantifying how a model's predictions\nchange in response to permuting feature position. We establish a game-theoretic\nconnection between OrdShap and Sanchez-Berganti\\~nos values, providing a\ntheoretically grounded approach to position-sensitive attribution. Empirical\nresults from health, natural language, and synthetic datasets highlight\nOrdShap's effectiveness in capturing feature value and feature position\nattributions, and provide deeper insight into model behavior.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11855v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "OrdShap：序列黑盒模型中的特征位置重要性", "tldr": "OrdShap是一种新的归因方法，用于解释序列黑盒模型的预测，它通过量化排列特征位置如何改变模型预测来区分特征值和特征位置的影响。", "motivation": "现有的特征归因方法在量化特征重要性时，固有地假设固定的特征顺序，从而混淆了特征值和它们在输入序列中位置的影响。本文旨在解决这一不足。", "method": "本文引入了OrdShap，这是一种新颖的归因方法，通过量化模型预测如何响应特征位置的排列而变化，从而分离特征值和特征位置的影响。该方法在理论上与Sanchez-Bergantiños值建立了博弈论联系，为位置敏感归因提供了一个有理论基础的方法。", "result": "来自健康、自然语言和合成数据集的实证结果表明，OrdShap在捕获特征值和特征位置归因方面是有效的，并为模型行为提供了更深入的洞察。", "conclusion": "OrdShap成功地分离了序列模型中特征值和特征位置的归因，从而提供了对模型行为更深入的理解，解决了现有方法混淆这两种效应的问题。", "translation": "序列深度学习模型在具有时间或序列依赖性的领域表现出色，但其复杂性需要事后特征归因方法来理解其预测。尽管现有技术量化了特征重要性，但它们固有地假设固定的特征顺序——混淆了（1）特征值和（2）它们在输入序列中位置的影响。为了解决这个空白，我们引入了OrdShap，这是一种新颖的归因方法，通过量化模型预测如何响应特征位置的排列而变化，从而分离这些影响。我们在OrdShap和Sanchez-Bergantiños值之间建立了博弈论联系，为位置敏感归因提供了一个有理论基础的方法。来自健康、自然语言和合成数据集的实证结果突出显示了OrdShap在捕获特征值和特征位置归因方面的有效性，并为模型行为提供了更深入的洞察。", "summary": "本文提出了一种名为OrdShap的新型归因方法，旨在解决现有序列模型解释方法中特征值和特征位置影响混淆的问题。OrdShap通过排列特征位置来量化模型预测的变化，从而分离这两种效应。该方法具有博弈论基础，并已在多个数据集上验证了其在捕获特征值和特征位置归因方面的有效性，从而提供了对模型行为更深入的理解。", "keywords": "OrdShap, 特征重要性, 序列模型, 黑盒模型, 归因", "comments": "OrdShap的创新之处在于它能够区分序列模型中特征值和特征位置的重要性，这对于理解顺序敏感的黑盒模型至关重要。通过与Sanchez-Bergantiños值的博弈论联系，该方法具有坚实的理论基础。"}}
{"id": "2507.12464", "title": "CytoSAE: Interpretable Cell Embeddings for Hematology", "authors": ["Muhammed Furkan Dasdelen", "Hyesu Lim", "Michele Buck", "Katharina S. Götze", "Carsten Marr", "Steffen Schneider"], "categories": ["cs.CV", "cs.LG", "q-bio.QM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 5 figures", "url": "http://arxiv.org/abs/2507.12464v1", "summary": "Sparse autoencoders (SAEs) emerged as a promising tool for mechanistic\ninterpretability of transformer-based foundation models. Very recently, SAEs\nwere also adopted for the visual domain, enabling the discovery of visual\nconcepts and their patch-wise attribution to tokens in the transformer model.\nWhile a growing number of foundation models emerged for medical imaging, tools\nfor explaining their inferences are still lacking. In this work, we show the\napplicability of SAEs for hematology. We propose CytoSAE, a sparse autoencoder\nwhich is trained on over 40,000 peripheral blood single-cell images. CytoSAE\ngeneralizes to diverse and out-of-domain datasets, including bone marrow\ncytology, where it identifies morphologically relevant concepts which we\nvalidated with medical experts. Furthermore, we demonstrate scenarios in which\nCytoSAE can generate patient-specific and disease-specific concepts, enabling\nthe detection of pathognomonic cells and localized cellular abnormalities at\nthe patch level. We quantified the effect of concepts on a patient-level AML\nsubtype classification task and show that CytoSAE concepts reach performance\ncomparable to the state-of-the-art, while offering explainability on the\nsub-cellular level. Source code and model weights are available at\nhttps://github.com/dynamical-inference/cytosae.", "comment": "11 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.12464v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "CytoSAE：血液学可解释细胞嵌入", "tldr": "CytoSAE是一种稀疏自编码器，用于血液学细胞图像，提供可解释的细胞嵌入，并在AML亚型分类任务中表现出与现有技术相当的性能，同时提供亚细胞水平的可解释性。", "motivation": "尽管医学成像领域出现了越来越多的基础模型，但解释其推断的工具仍然缺乏。本研究旨在解决这一问题，通过引入稀疏自编码器（SAE）在血液学领域的应用，以提供可解释的细胞嵌入。", "method": "本研究提出了CytoSAE，这是一种稀疏自编码器，在超过40,000张外周血单细胞图像上进行训练。该模型旨在发现视觉概念并将其归因于Transformer模型中的标记。", "result": "CytoSAE能够泛化到多样化和域外数据集，包括骨髓细胞学，并在其中识别出经医学专家验证的形态学相关概念。它能够生成患者特异性和疾病特异性概念，从而检测病理细胞和局部细胞异常。在患者级别的AML亚型分类任务中，CytoSAE概念的性能与现有技术相当，同时在亚细胞级别提供了可解释性。", "conclusion": "本研究展示了稀疏自编码器（SAE）在血液学中的适用性，通过CytoSAE提供了可解释的细胞嵌入，并在疾病诊断和分类中提供了亚细胞级别的见解。", "translation": "稀疏自编码器（SAE）已成为Transformer基础模型机械可解释性的一种有前景的工具。最近，SAE也被应用于视觉领域，使得视觉概念的发现及其在Transformer模型中对标记的补丁级归因成为可能。尽管医学成像领域出现了越来越多的基础模型，但解释其推断的工具仍然缺乏。在这项工作中，我们展示了SAE在血液学中的适用性。我们提出了CytoSAE，这是一种稀疏自编码器，在超过40,000张外周血单细胞图像上进行训练。CytoSAE能够泛化到多样化和域外数据集，包括骨髓细胞学，并在其中识别出经医学专家验证的形态学相关概念。此外，我们展示了CytoSAE能够生成患者特异性和疾病特异性概念的场景，从而能够检测补丁级别的病理细胞和局部细胞异常。我们量化了概念对患者级别AML亚型分类任务的影响，并表明CytoSAE概念的性能与现有技术相当，同时提供了亚细胞级别的可解释性。源代码和模型权重可在https://github.com/dynamical-inference/cytosae获取。", "summary": "CytoSAE是一种基于稀疏自编码器（SAE）的方法，旨在为血液学领域提供可解释的细胞嵌入。该模型在大量单细胞图像上训练，并能泛化到不同的数据集。CytoSAE不仅能够识别形态学相关概念和生成患者/疾病特异性概念，还能在AML亚型分类任务中达到与现有技术相当的性能，同时提供独特的亚细胞级别可解释性。", "keywords": "稀疏自编码器, 血液学, 可解释性, 细胞嵌入, 医疗影像", "comments": "该论文的创新点在于将稀疏自编码器（SAE）应用于血液学领域，以实现可解释的细胞嵌入。其重要性在于解决了医学成像基础模型解释性不足的问题，特别是在亚细胞级别提供了深入的见解，这对于疾病诊断和理解具有重要意义。CytoSAE在保持高性能的同时提供了高度的可解释性，是连接深度学习模型与临床实践的关键一步。"}}
{"id": "2507.12235", "title": "Frequency-responsive RCS characteristics and scaling implications for ISAC development", "authors": ["Saúl Fenollosa", "Monika Drozdowska", "Wenfei Yang", "Sergio Micó-Rosa", "Alejandro Castilla", "Alejandro Lopez-Escudero", "Jian Li", "Narcis Cardona"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      6 pages, 12 figures, 3 tables. Accepted for publication at the 2024 IEEE Global Communications Conference (GLOBECOM), WS-02: Workshop on Propagation Channel Models and Evaluation Methodologies for 6G", "url": "http://arxiv.org/abs/2507.12235v1", "summary": "This paper presents an investigation on the Radar Cross-Section (RCS) of\nvarious targets, with the objective of analysing how RCS properties vary with\nfrequency. Targets such as an Automated Guided Vehicle (AGV), a pedestrian, and\na full-scale car were measured in the frequency bands referred to in industry\nstandards as FR2 and FR3. Measurements were taken in diverse environments,\nindoors and outdoors, to ensure comprehensive scenario coverage. The\nmethodology employed in RCS extraction performs background subtraction,\nfollowed by time-domain gating to isolate the influence of the target. This\nanalysis compares the RCS values and how the points of greatest contribution\nare distributed across different bands based on the range response of the RCS.\nAnalysis of the results demonstrated how RCS values change with frequency and\ntarget shape, providing insights into the electromagnetic behaviour of these\ntargets. Key findings highlight how much scaling RCS values based on frequency\nand geometry is complex and varies among different types of materials and\nshapes. These insights are instrumental for advancing sensing systems and\nenhancing 3GPP channel models, particularly for Integrated Sensing and\nCommunications (ISAC) techniques proposed for 6G standards.", "comment": "6 pages, 12 figures, 3 tables. Accepted for publication at the 2024\n  IEEE Global Communications Conference (GLOBECOM), WS-02: Workshop on\n  Propagation Channel Models and Evaluation Methodologies for 6G", "pdf_url": "http://arxiv.org/pdf/2507.12235v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "频率响应雷达散射截面特性及其对ISAC发展的尺度缩放影响", "tldr": "本研究分析了不同目标（如AGV、行人、汽车）的雷达散射截面（RCS）随频率的变化特性，揭示了RCS值随频率和目标形状的变化规律，并强调了基于频率和几何形状进行RCS缩放的复杂性，为ISAC和6G传感系统发展提供了重要见解。", "motivation": "本研究旨在分析雷达散射截面（RCS）特性如何随频率变化，并为推进传感系统和增强3GPP信道模型（特别是针对6G标准提出的集成感知与通信（ISAC）技术）提供基础见解。", "method": "研究测量了自动导引车（AGV）、行人、全尺寸汽车等目标在FR2和FR3工业标准频段的雷达散射截面（RCS）。测量在室内和室外多样环境中进行。RCS提取方法包括背景减法和时域门控以隔离目标影响。", "result": "研究结果表明，雷达散射截面（RCS）值随频率和目标形状的变化而变化，揭示了这些目标的电磁行为。关键发现强调，基于频率和几何形状对RCS值进行缩放是复杂的，并且因不同材料和形状而异。", "conclusion": "研究获得的见解对于推进传感系统和增强3GPP信道模型，特别是对于6G标准中提出的集成感知与通信（ISAC）技术至关重要。", "translation": "本文研究了各种目标的雷达散射截面（RCS），旨在分析RCS特性如何随频率变化。对自动导引车（AGV）、行人以及全尺寸汽车等目标在工业标准中称为FR2和FR3的频段进行了测量。测量在室内和室外等不同环境中进行，以确保全面的场景覆盖。RCS提取方法采用背景减法，然后进行时域门控以隔离目标的影响。本分析比较了RCS值以及最大贡献点如何根据RCS的距离响应分布在不同频段。结果分析表明RCS值如何随频率和目标形状变化，为这些目标的电磁行为提供了见解。关键发现强调，基于频率和几何形状对RCS值进行缩放是复杂的，并且因不同材料和形状而异。这些见解对于推进传感系统和增强3GPP信道模型，特别是对于6G标准中提出的集成感知与通信（ISAC）技术具有重要意义。", "summary": "本论文研究了自动导引车、行人、汽车等目标在FR2和FR3频段的雷达散射截面（RCS）特性及其随频率的变化。通过背景减法和时域门控提取RCS，分析了RCS值如何随频率和目标形状变化。研究发现，基于频率和几何形状对RCS进行缩放是复杂的，且因材料和形状而异。这些发现对推进传感系统和增强3GPP信道模型，特别是6G集成感知与通信（ISAC）技术的发展至关重要。", "keywords": "雷达散射截面, 频率响应, ISAC, 6G, 尺度缩放", "comments": "该论文通过对不同目标在多频段和多样环境下的RCS特性进行实测分析，为理解RCS随频率和形状的变化提供了宝贵数据。其创新性在于将RCS的频率响应特性与未来6G的ISAC技术发展紧密结合，强调了RCS缩放的复杂性，为信道建模和系统设计提供了关键参考。对于推动下一代无线通信和感知技术的发展具有重要意义。"}}
{"id": "2507.11822", "title": "Analysis of a fast fully discrete finite element method for fractional viscoelastic wave propagation", "authors": ["Hao Yuan", "Xiaoping Xie"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11822v1", "summary": "This paper is devoted to a numerical analysis of a fractional viscoelastic\nwave propagation model that generalizes the fractional Maxwell model and the\nfractional Zener model. First, we convert the model problem into a velocity\ntype integro-differential equation and establish existence, uniqueness and\nregularity of its solution. Then we consider a conforming\nlinear/bilinear/trilinear finite element semi-discrete scheme and a fast scheme\nof backward Euler full discretization with a sum-of-exponentials (SOE)\napproximation for the convolution integral, and derive error estimates for the\nsemi-discrete and fully discrete schemes. Finally, we provide several numerical\nexamples to verify the theoretical results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11822v1", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "分数阶粘弹性波传播快速全离散有限元方法分析", "tldr": "本文对一个广义分数阶粘弹性波传播模型进行了数值分析，提出了一种基于指数和逼近的快速全离散有限元方法，并推导了误差估计，通过数值算例验证了理论结果。", "motivation": "本文致力于对一种分数阶粘弹性波传播模型进行数值分析，该模型推广了分数阶麦克斯韦模型和分数阶Zener模型。", "method": "首先，将模型问题转化为速度型积分微分方程，并建立了其解的存在性、唯一性和正则性。然后，考虑了一种协调的线性/双线性/三线性有限元半离散格式和一种带有指数和（SOE）逼近卷积积分的后向欧拉全离散快速格式。", "result": "推导了半离散和全离散格式的误差估计。提供了几个数值算例来验证理论结果。", "conclusion": "通过数值算例验证了所提出的快速全离散有限元方法的理论结果是准确有效的。", "translation": "本文致力于对一个推广了分数阶麦克斯韦模型和分数阶Zener模型的分数阶粘弹性波传播模型进行数值分析。首先，我们将模型问题转化为速度型积分微分方程，并建立了其解的存在性、唯一性和正则性。然后，我们考虑了一种协调的线性/双线性/三线性有限元半离散格式和一种带有指数和（SOE）逼近卷积积分的后向欧拉全离散快速格式，并推导了半离散和全离散格式的误差估计。最后，我们提供了几个数值算例来验证理论结果。", "summary": "本文对一个推广了分数阶麦克斯韦和分数阶Zener模型的分数阶粘弹性波传播模型进行了数值分析。研究首先将模型转化为速度型积分微分方程，并证明了解的存在性、唯一性和正则性。接着，论文提出了一种结合指数和（SOE）逼近卷积积分的快速后向欧拉全离散有限元方案，并推导了半离散和全离散方案的误差估计。数值实验验证了理论结果的有效性。", "keywords": "分数阶粘弹性波, 有限元方法, 指数和逼近, 误差估计, 数值分析", "comments": "该论文的创新点在于提出了一个推广性的分数阶粘弹性波传播模型，并结合指数和（SOE）逼近技术，设计了一种快速全离散有限元方法。这种方法在处理复杂的分数阶积分微分方程时，兼顾了计算效率和精度，并通过严格的误差分析和数值验证，确保了方法的可靠性，对于分数阶偏微分方程的数值求解具有重要意义。"}}
{"id": "2507.11678", "title": "Towards a Non-Binary View of IPv6 Adoption", "authors": ["Sulyab Thottungal Valapu", "John Heidemann"], "categories": ["cs.NI", "C.2.6"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11678v1", "summary": "Twelve years have passed since World IPv6 Launch Day, but what is the current\nstate of IPv6 deployment? Prior work has examined IPv6 status as a binary: can\nyou use IPv6, or not? As deployment increases we must consider a more nuanced,\nnon-binary perspective on IPv6: how much and often can a user or a service use\nIPv6? We consider this question as a client, server, and cloud provider.\nConsidering the client's perspective, we observe user traffic. We see that the\nfraction of IPv6 traffic a user sends varies greatly, both across users and\nday-by-day, with a standard deviation of over 15%. We show this variation\noccurs for two main reasons. First, IPv6 traffic is primarily human-generated,\nthus showing diurnal patterns. Second, some services are IPv6-forward and\nothers IPv6-laggards, so as users do different things their fraction of IPv6\nvaries. We look at server-side IPv6 adoption in two ways. First, we expand\nanalysis of web services to examine how many are only partially IPv6 enabled\ndue to their reliance on IPv4-only resources. Our findings reveal that only\n12.5% of top 100k websites qualify as fully IPv6-ready. Finally, we examine\ncloud support for IPv6. Although all clouds and CDNs support IPv6, we find that\ntenant deployment rates vary significantly across providers. We find that ease\nof enabling IPv6 in the cloud is correlated with tenant IPv6 adoption rates,\nand recommend best practices for cloud providers to improve IPv6 adoption. Our\nresults suggest IPv6 deployment is growing, but many services lag, presenting a\npotential for improvement.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11678v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "迈向IPv6采纳的非二元视角", "tldr": "本研究提出并采纳了一种非二元视角来审视IPv6的部署现状，即用户或服务在多大程度上、多频繁地使用IPv6。研究从客户端、服务器和云提供商三个层面进行了深入分析，发现IPv6部署虽有增长，但仍存在显著的采纳滞后和服务不完善之处，并提出了改进建议。", "motivation": "自世界IPv6启动日以来已过去十二年，但IPv6的部署现状仍需深入评估。以往的研究多将IPv6状态视为二元（能否使用），但随着部署的增加，需要一种更细致、非二元的视角来理解用户或服务使用IPv6的程度和频率。", "method": "本研究从客户端、服务器和云提供商三个维度对IPv6的采纳情况进行了分析。针对客户端，研究观察了用户流量；针对服务器，扩展分析了Web服务中部分启用IPv6的情况；针对云提供商，则考察了其对IPv6的支持以及租户的部署率。", "result": "从客户端视角，用户发送的IPv6流量比例变化很大，标准差超过15%，这主要受人类生成流量的昼夜模式和不同服务对IPv6支持程度的影响。在服务器端，排名前10万的网站中只有12.5%完全IPv6就绪。在云端，尽管所有云和CDN都支持IPv6，但租户的部署率因提供商而异，且云中启用IPv6的便捷性与租户的采纳率相关。", "conclusion": "IPv6的部署正在增长，但许多服务仍然滞后，存在很大的改进潜力。研究建议云提供商采取最佳实践以提高IPv6的采纳率。", "translation": "自世界IPv6启动日以来，十二年过去了，但IPv6的部署现状如何？以前的工作将IPv6状态视为二元的：你是否可以使用IPv6？随着部署的增加，我们必须对IPv6采取更细致、非二元的视角：用户或服务能在多大程度上、多频繁地使用IPv6？我们从客户端、服务器和云提供商的角度考虑这个问题。从客户端的角度来看，我们观察用户流量。我们发现用户发送的IPv6流量比例变化很大，无论是用户之间还是日常，标准差都超过15%。我们发现这种变化主要有两个原因。首先，IPv6流量主要是人类生成的，因此呈现出昼夜模式。其次，一些服务是IPv6优先的，而另一些则是IPv6滞后的，因此当用户做不同的事情时，他们的IPv6比例也会变化。我们通过两种方式审视服务器端的IPv6采纳。首先，我们扩展了对Web服务的分析，以检查有多少服务由于依赖仅支持IPv4的资源而仅部分启用了IPv6。我们的发现表明，在排名前10万的网站中，只有12.5%符合完全IPv6就绪的标准。最后，我们检查了云对IPv6的支持。尽管所有云和CDN都支持IPv6，但我们发现租户的部署率在不同提供商之间差异显著。我们发现云中启用IPv6的便捷性与租户的IPv6采纳率相关，并建议云提供商改进IPv6采纳的最佳实践。我们的结果表明IPv6部署正在增长，但许多服务滞后，存在改进的潜力。", "summary": "本研究提出了一种对IPv6采纳的非二元视角，旨在评估用户和服务在多大程度上及多频繁地使用IPv6。研究从客户端、服务器和云提供商三个层面进行了分析。结果显示，客户端的IPv6流量比例波动大，受用户行为和服务支持程度影响；服务器端，前10万网站中仅有12.5%完全IPv6就绪；云端，尽管普遍支持IPv6，但租户采纳率因提供商而异，且与启用便捷性相关。研究强调IPv6部署虽有增长，但仍存在显著滞后现象，并提出了改进建议。", "keywords": "IPv6, 采纳, 部署, 非二元, 客户端, 服务器, 云", "comments": "这项研究的创新之处在于其提出了IPv6采纳的“非二元”视角，超越了简单的“是/否”判断，深入分析了采纳的程度和频率。这对于更准确地理解IPv6的实际部署状况及其面临的挑战至关重要，并为未来的改进提供了有价值的见解和具体方向。"}}
{"id": "2507.11955", "title": "Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation", "authors": ["Yuhang Zhang", "Zhengyu Zhang", "Muxin Liao", "Shishun Tian", "Wenbin Zou", "Lu Zhang", "Chen Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This paper was accepted by IEEE Transactions on Intelligent Transportation Systems", "url": "http://arxiv.org/abs/2507.11955v1", "summary": "Generalizable semantic segmentation aims to perform well on unseen target\ndomains, a critical challenge due to real-world applications requiring high\ngeneralizability. Class-wise prototypes, representing class centroids, serve as\ndomain-invariant cues that benefit generalization due to their stability and\nsemantic consistency. However, this approach faces three challenges. First,\nexisting methods often adopt coarse prototypical alignment strategies, which\nmay hinder performance. Second, naive prototypes computed by averaging source\nbatch features are prone to overfitting and may be negatively affected by\nunrelated source data. Third, most methods treat all source samples equally,\nignoring the fact that different features have varying adaptation difficulties.\nTo address these limitations, we propose a novel framework for generalizable\nsemantic segmentation: Prototypical Progressive Alignment and Reweighting\n(PPAR), leveraging the strong generalization ability of the CLIP model.\nSpecifically, we define two prototypes: the Original Text Prototype (OTP) and\nVisual Text Prototype (VTP), generated via CLIP to serve as a solid base for\nalignment. We then introduce a progressive alignment strategy that aligns\nfeatures in an easy-to-difficult manner, reducing domain gaps gradually.\nFurthermore, we propose a prototypical reweighting mechanism that estimates the\nreliability of source data and adjusts its contribution, mitigating the effect\nof irrelevant or harmful features (i.e., reducing negative transfer). We also\nprovide a theoretical analysis showing the alignment between our method and\ndomain generalization theory. Extensive experiments across multiple benchmarks\ndemonstrate that PPAR achieves state-of-the-art performance, validating its\neffectiveness.", "comment": "This paper was accepted by IEEE Transactions on Intelligent\n  Transportation Systems", "pdf_url": "http://arxiv.org/pdf/2507.11955v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "用于可泛化语义分割的原型渐进对齐与重加权", "tldr": "该论文提出了一种新颖的框架PPAR，通过渐进对齐和重加权来解决可泛化语义分割中的挑战，并实现了最先进的性能。", "motivation": "可泛化语义分割在实际应用中对高泛化能力有关键需求，但现有方法存在以下挑战：1) 粗糙的原型对齐策略可能阻碍性能；2) 朴素原型易过拟合且受不相关源数据影响；3) 大多数方法平等对待所有源样本，忽略了不同特征适应难度的差异。", "method": "本文提出了一种新颖的可泛化语义分割框架：原型渐进对齐与重加权（PPAR），利用CLIP模型的强大泛化能力。具体而言，定义了通过CLIP生成的原始文本原型（OTP）和视觉文本原型（VTP）作为对齐基础。引入了渐进式对齐策略，以从易到难的方式对齐特征，逐步减小域差距。提出了一种原型重加权机制，用于估计源数据的可靠性并调整其贡献，以减轻不相关或有害特征的影响（即减少负迁移）。此外，还提供了理论分析。", "result": "在多个基准上的大量实验表明，PPAR实现了最先进的性能，验证了其有效性。", "conclusion": "PPAR是一种有效且新颖的通用语义分割框架，它通过解决现有原型对齐方法的局限性，并实现了最先进的性能。", "translation": "可泛化语义分割旨在对未见过的目标域表现良好，由于实际应用需要高泛化能力，这是一个关键挑战。类别原型，代表类别中心，作为域不变的线索，由于其稳定性和语义一致性而有利于泛化。然而，这种方法面临三个挑战。首先，现有方法通常采用粗糙的原型对齐策略，这可能会阻碍性能。其次，通过平均源批次特征计算的朴素原型容易过拟合，并可能受到不相关源数据的负面影响。第三，大多数方法平等对待所有源样本，忽略了不同特征具有不同适应难度的事实。为了解决这些局限性，我们提出了一种新颖的可泛化语义分割框架：原型渐进对齐与重加权（PPAR），利用CLIP模型的强大泛化能力。具体来说，我们定义了两种原型：原始文本原型（OTP）和视觉文本原型（VTP），通过CLIP生成，作为对齐的坚实基础。然后，我们引入了一种渐进对齐策略，以从易到难的方式对齐特征，逐步减小域差距。此外，我们提出了一种原型重加权机制，用于估计源数据的可靠性并调整其贡献，从而减轻不相关或有害特征的影响（即减少负迁移）。我们还提供了理论分析，表明我们的方法与域泛化理论之间的一致性。在多个基准上的大量实验表明，PPAR实现了最先进的性能，验证了其有效性。", "summary": "该论文提出了PPAR，一种用于可泛化语义分割的新颖框架。它解决了现有基于原型方法在粗糙对齐、过拟合和样本处理不均等方面的局限性。PPAR利用CLIP生成的OTP和VTP、渐进式对齐策略以及原型重加权机制来增强泛化能力并减少负迁移，从而实现了最先进的性能。", "keywords": "可泛化语义分割, 原型对齐, 重加权, 域泛化, CLIP", "comments": "该论文通过整合基于CLIP的原型、渐进式对齐策略和重加权机制，创新性地解决了可泛化语义分割中的挑战。从易到难的渐进对齐和用于减轻负迁移的重加权机制是解决常见域泛化问题的巧妙方案。理论分析也进一步增强了所提出方法的可靠性。"}}
{"id": "2308.09730", "title": "The Utility of the Virtual Imaging Trials Methodology for Objective Characterization of AI Systems and Training Data", "authors": ["Fakrul Islam Tushar", "Lavsen Dahal", "Saman Sotoudeh-Paima", "Ehsan Abadi", "W. Paul Segars", "Ehsan Samei", "Joseph Y. Lo"], "categories": ["eess.IV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      8 figures, 4 Tables", "url": "http://arxiv.org/abs/2308.09730v5", "summary": "Purpose: The credibility of Artificial Intelligence (AI) models for medical\nimaging continues to be a challenge, affected by the diversity of models, the\ndata used to train the models, and applicability of their combination to\nproduce reproducible results for new data. Approach: In this work we aimed to\nexplore if the emerging Virtual Imaging Trials (VIT) methodologies can provide\nan objective resource to approach this challenge. The study was conducted for\nthe case example of COVID-19 diagnosis using clinical and virtual computed\ntomography (CT) and chest radiography (CXR) processed with convolutional neural\nnetworks. Multiple AI models were developed and tested using 3D ResNet-like and\n2D EfficientNetv2 architectures across diverse datasets. Results: The\nperformance differences were evaluated in terms of the area under the curve\n(AUC) and the DeLong method for AUC confidence intervals. The models trained on\nthe most diverse datasets showed the highest external testing performance, with\nAUC values ranging from 0.73-0.76 for CT and 0.70-0.73 for CXR. Internal\ntesting yielded higher AUC values (0.77 -0.85 for CT and 0.77-1.0 for CXR),\nhighlighting a substantial drop in performance during external validation,\nwhich underscores the importance of diverse and comprehensive training and\ntesting data. Most notably, VIT approach provided objective assessment of the\nutility of diverse models and datasets while further providing insight into the\ninfluence of dataset characteristics, patient factors, and imaging physics on\nAI efficacy. Conclusions: The VIT approach can be used to enhance model\ntransparency and reliability, offering nuanced insights into the factors\ndriving AI performance and bridging the gap between experimental and clinical\nsettings.", "comment": "8 figures, 4 Tables", "pdf_url": "http://arxiv.org/pdf/2308.09730v5", "cate": "eess.IV", "date": "2023-08-17", "updated": "2025-07-16", "AI": {"title_translation": "虚拟成像试验方法在客观表征人工智能系统和训练数据方面的效用", "tldr": "本研究探讨了虚拟成像试验（VIT）方法在客观评估医学影像AI模型及其训练数据的效用，发现VIT能有效揭示AI性能的影响因素，并提升模型透明度和可靠性。", "motivation": "医学影像AI模型的信誉度面临挑战，受模型多样性、训练数据以及组合再现性的影响。本研究旨在探索新兴的虚拟成像试验（VIT）方法是否能提供客观资源来解决这一挑战。", "method": "本研究以COVID-19诊断为例，使用临床和虚拟CT及CXR图像，通过卷积神经网络处理。开发并测试了基于3D ResNet-like和2D EfficientNetv2架构的多个AI模型，并在多样化数据集上进行评估。", "result": "性能差异通过AUC和DeLong方法评估。在最多样化数据集上训练的模型显示出最高的外部测试性能，CT的AUC为0.73-0.76，CXR为0.70-0.73。内部测试AUC更高（CT为0.77-0.85，CXR为0.77-1.0），外部验证时性能显著下降，强调了多样化和全面训练及测试数据的重要性。VIT方法提供了对多样模型和数据集效用的客观评估，并深入了解了数据集特性、患者因素和成像物理对AI效能的影响。", "conclusion": "VIT方法可用于增强模型透明度和可靠性，提供对驱动AI性能因素的细致洞察，并弥合实验与临床设置之间的差距。", "translation": "目的：医学影像领域人工智能（AI）模型的可靠性仍然是一个挑战，受到模型多样性、用于训练模型的数据以及其组合在生成新数据可重复结果方面的适用性的影响。方法：在这项工作中，我们旨在探索新兴的虚拟成像试验（VIT）方法是否能提供客观资源来应对这一挑战。该研究以COVID-19诊断为例进行，使用临床和虚拟计算机断层扫描（CT）以及胸部X射线（CXR）图像，并通过卷积神经网络进行处理。使用3D ResNet-like和2D EfficientNetv2架构，在多样化数据集上开发并测试了多个AI模型。结果：性能差异通过曲线下面积（AUC）和用于AUC置信区间的DeLong方法进行评估。在最多样化数据集上训练的模型显示出最高的外部测试性能，CT的AUC值范围为0.73-0.76，CXR为0.70-0.73。内部测试产生了更高的AUC值（CT为0.77-0.85，CXR为0.77-1.0），突出了外部验证期间性能的显著下降，这强调了多样化和全面训练及测试数据的重要性。最值得注意的是，VIT方法提供了对多样模型和数据集效用的客观评估，同时进一步深入了解了数据集特性、患者因素和成像物理对AI效能的影响。结论：VIT方法可用于增强模型透明度和可靠性，提供对驱动AI性能因素的细致洞察，并弥合实验与临床设置之间的差距。", "summary": "该研究探讨了虚拟成像试验（VIT）方法在客观评估医学影像AI系统及其训练数据方面的效用。针对COVID-19诊断，研究者开发并测试了多个人工智能模型，发现VIT方法能有效评估不同模型和数据集的性能，并揭示了数据集特性、患者因素和成像物理对AI效能的影响。结果表明，VIT有助于提高AI模型的透明度和可靠性，弥合实验与临床应用之间的鸿沟。", "keywords": "虚拟成像试验, 人工智能, 医学影像, COVID-19, 模型评估", "comments": "本文提出了一种新颖的虚拟成像试验（VIT）方法，旨在解决医学影像AI模型可信度不足的挑战。其创新之处在于利用虚拟数据来客观评估AI系统和训练数据，这对于提升AI模型的透明度和可靠性具有重要意义。通过揭示数据集多样性、患者因素和成像物理对AI性能的影响，该方法为AI模型的开发和验证提供了宝贵的洞察。未来，VIT方法有望成为AI模型在临床应用前进行严格评估的标准工具。"}}
{"id": "2507.09850", "title": "The Challenge of Teaching Reasoning to LLMs Without RL or Distillation", "authors": ["Wei Du", "Branislav Kisacanin", "George Armstrong", "Shubham Toshniwal", "Ivan Moshkov", "Alexan Ayrapetyan", "Sadegh Mahdavi", "Dan Zhao", "Shizhe Diao", "Dragan Masulovic", "Marius Stanean", "Advaith Avadhanam", "Max Wang", "Ashmit Dutta", "Shitij Govil", "Sri Yanamandara", "Mihir Tandon", "Sriram Ananthakrishnan", "Vedant Rathi", "David Zhang", "Joonseok Kang", "Leon Luo", "Titu Andreescu", "Boris Ginsburg", "Igor Gitman"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted at the Second AI for Math Workshop at the 42nd International Conference on Machine Learning (ICML 2025)", "url": "http://arxiv.org/abs/2507.09850v3", "summary": "Reasoning-capable language models achieve state-of-the-art performance in\ndiverse complex tasks by generating long, explicit Chain-of-Thought (CoT)\ntraces. While recent works show that base models can acquire such reasoning\ntraces via reinforcement learning or distillation from stronger models like\nDeepSeek-R1, previous works demonstrate that even short CoT prompting without\nfine-tuning is able to improve reasoning. We ask whether long CoT can be\ninduced in a base model using only prompting or minimal tuning. Using just 20\nlong CoT examples from the reasoning model \\texttt{QwQ-32B-Preview}, we lightly\nfine-tune the base model \\texttt{Qwen2.5-32B}. The resulting model outperforms\nthe much larger \\texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of\nhigh-quality examples can unlock strong reasoning capabilities. We further\nexplore using CoT data from non-reasoning models and human annotators, enhanced\nwith prompt engineering, multi-pass editing, and structural guidance. However,\nneither matches the performance of reasoning model traces, suggesting that\ncertain latent qualities of expert CoT are difficult to replicate. We analyze\nkey properties of reasoning data, such as problem difficulty, diversity, and\nanswer length, that influence reasoning distillation. While challenges remain,\nwe are optimistic that carefully curated human-written CoT, even in small\nquantities, can activate reasoning behaviors in base models. We release our\nhuman-authored dataset across refinement stages and invite further\ninvestigation into what makes small-scale reasoning supervision so effective.", "comment": "Accepted at the Second AI for Math Workshop at the 42nd International\n  Conference on Machine Learning (ICML 2025)", "pdf_url": "http://arxiv.org/pdf/2507.09850v3", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "在不使用强化学习或蒸馏的情况下向大型语言模型教授推理的挑战", "tldr": "本研究表明，仅用少量高质量的思维链（CoT）示例，通过轻微微调，就能在基础大型语言模型（LLM）中激活强大的推理能力，甚至超越更大的模型，而无需强化学习或蒸馏。", "motivation": "研究旨在探索是否仅通过提示或最少微调就能在基础大型语言模型中诱导长思维链（CoT），特别是在不使用强化学习或蒸馏的情况下，以期在不依赖复杂方法的前提下提升模型的推理能力。", "method": "研究使用了来自推理模型QwQ-32B-Preview的20个长CoT示例，对基础模型Qwen2.5-32B进行了轻微微调。此外，还探索了使用来自非推理模型和人类标注者的CoT数据，并辅以提示工程、多遍编辑和结构化指导。研究还分析了推理数据（如问题难度、多样性和答案长度）的关键特性。", "result": "轻微微调后的Qwen2.5-32B模型超越了更大的Qwen2.5-Math-72B-Instruct，表明少量高质量示例可以解锁强大的推理能力。然而，来自非推理模型和人类标注者的CoT数据，即使经过增强，也未能达到推理模型轨迹的性能，这表明专家CoT的某些潜在质量难以复制。", "conclusion": "尽管存在挑战，但研究人员乐观地认为，精心策划的人工编写的CoT，即使数量很少，也能激活基础模型中的推理行为。高质量专家示例中难以复制的特定潜在属性是关键。", "translation": "推理能力强的语言模型通过生成长而明确的思维链（CoT）轨迹，在各种复杂任务中取得了最先进的性能。虽然最近的工作表明基础模型可以通过强化学习或从DeepSeek-R1等更强的模型中进行蒸馏来获得此类推理轨迹，但之前的工作表明，即使不进行微调的短CoT提示也能够改善推理。我们询问是否仅使用提示或最少微调就能在基础模型中诱导长CoT。我们仅使用来自推理模型QwQ-32B-Preview的20个长CoT示例，对基础模型Qwen2.5-32B进行了轻微微调。结果模型超越了更大的Qwen2.5-Math-72B-Instruct，表明少量高质量示例可以解锁强大的推理能力。我们进一步探索了使用来自非推理模型和人类标注者的CoT数据，并辅以提示工程、多遍编辑和结构化指导。然而，两者都未能达到推理模型轨迹的性能，这表明专家CoT的某些潜在质量难以复制。我们分析了影响推理蒸馏的推理数据的关键属性，例如问题难度、多样性和答案长度。尽管挑战依然存在，但我们乐观地认为，精心策划的人工编写的CoT，即使数量很少，也能激活基础模型中的推理行为。我们发布了跨细化阶段的人工编写数据集，并邀请进一步研究小规模推理监督为何如此有效。", "summary": "本文探讨了在不依赖强化学习或大型模型蒸馏的情况下，向基础大型语言模型（LLM）教授推理能力的方法。研究发现，仅使用来自专家推理模型的少量高质量思维链（CoT）示例对基础模型进行轻微微调，即可显著提升其推理性能，甚至超越更大的模型。然而，来自非专家模型或人类标注者的CoT数据效果不佳，表明专家CoT中存在难以复制的潜在质量。文章强调了高质量、精心策划的少量CoT数据在激活LLM推理行为方面的潜力，并发布了相关数据集以供进一步研究。", "keywords": "思维链, 大型语言模型, 推理, 微调, 数据集", "comments": "本文的创新之处在于，它挑战了传统上通过强化学习或大型模型蒸馏来教授LLM推理能力的主流方法，证明了少量高质量专家CoT数据通过轻微微调即可达到显著效果。这对于资源有限的研究者和实际应用具有重要意义，因为它提供了一个更高效、更易于访问的推理能力激活路径。其局限性在于，它也指出专家CoT的“潜在质量”难以复制，这提示了未来研究需要深入理解这些高质量数据的本质。"}}
{"id": "2507.10136", "title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run\" Therapeutic Strategy in Melanoma", "authors": ["Zhonglin Liu"], "categories": ["q-bio.QM", "cs.AI"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures. Submitted to the IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2025. Code is available at this https URL", "url": "http://arxiv.org/abs/2507.10136v3", "summary": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical\nchallenge in metastatic melanoma, with the underlying molecular networks being\npoorly understood. To address this, we constructed a dynamic Probabilistic\nBoolean Network model using transcriptomic data from patient tumor biopsies to\nelucidate the regulatory logic governing therapy response. We then employed a\nreinforcement learning agent to systematically discover optimal, multi-step\ntherapeutic interventions and used explainable artificial intelligence to\nmechanistically interpret the agent's control policy. The analysis revealed\nthat a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2\nprotein (LOXL2) was the most effective strategy. Our explainable analysis\nshowed that this ''hit-and-run\" intervention is sufficient to erase the\nmolecular signature driving resistance, allowing the network to self-correct\nwithout requiring sustained intervention. This study presents a novel,\ntime-dependent therapeutic hypothesis for overcoming immunotherapy resistance\nand provides a powerful computational framework for identifying non-obvious\nintervention protocols in complex biological systems.", "comment": "9 pages, 5 figures. Submitted to the IEEE International Conference on\n  Bioinformatics and Biomedicine (BIBM) 2025. Code is available at\n  https://github.com/Liu-Zhonglin/pbn-melanoma-project", "pdf_url": "http://arxiv.org/pdf/2507.10136v3", "cate": "q-bio.QM", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "PBN-RL-XAI框架用于发现黑色素瘤的“一击即走”治疗策略", "tldr": "本研究提出了一个PBN-RL-XAI框架，用于发现克服黑色素瘤抗药性的“一击即走”治疗策略，通过暂时抑制LOXL2蛋白来消除耐药性分子特征。", "motivation": "针对抗PD-1免疫疗法在转移性黑色素瘤中存在的先天性耐药性问题，且其潜在分子网络尚不明确，本研究旨在发现有效的治疗干预措施。", "method": "本研究构建了一个动态概率布尔网络（PBN）模型，利用患者肿瘤活检的转录组数据来阐明调控治疗反应的逻辑。随后，使用强化学习（RL）智能体系统地发现最佳的多步治疗干预措施，并利用可解释人工智能（XAI）来机械性地解释智能体的控制策略。", "result": "分析揭示，精确计时的4步暂时性抑制赖氨酰氧化酶样2蛋白（LOXL2）是最有效的策略。可解释性分析表明，这种“一击即走”的干预足以消除驱动耐药性的分子特征，使网络无需持续干预即可自我纠正。", "conclusion": "本研究提出了一种新颖的、时间依赖性的治疗假设，以克服免疫疗法耐药性，并提供了一个强大的计算框架，用于在复杂生物系统中识别非显而易见的干预方案。", "translation": "抗PD-1免疫疗法在转移性黑色素瘤中存在的先天性耐药性仍然是一个主要的临床挑战，其潜在的分子网络尚不明确。为了解决这个问题，我们利用患者肿瘤活检的转录组数据构建了一个动态概率布尔网络模型，以阐明调控治疗反应的逻辑。然后，我们采用强化学习智能体系统地发现最优的多步治疗干预措施，并使用可解释人工智能从机制上解释智能体的控制策略。分析揭示，精确计时的4步暂时性抑制赖氨酰氧化酶样2蛋白（LOXL2）是最有效的策略。我们的可解释性分析表明，这种“一击即走”的干预足以消除驱动耐药性的分子特征，使网络无需持续干预即可自我纠正。这项研究提出了一种新颖的、时间依赖性的治疗假设，以克服免疫疗法耐药性，并提供了一个强大的计算框架，用于在复杂生物系统中识别非显而易见的干预方案。", "summary": "本研究提出一个PBN-RL-XAI计算框架，用于发现克服转移性黑色素瘤对PD-1免疫疗法先天性耐药性的治疗策略。通过构建概率布尔网络模型并结合强化学习和可解释人工智能，研究发现精确计时的4步LOXL2暂时性抑制是一种有效的“一击即走”策略，能够消除耐药性分子特征，使网络自我纠正。该框架为复杂生物系统中的新颖干预方案识别提供了强大的工具。", "keywords": "黑色素瘤, 免疫疗法耐药, 概率布尔网络, 强化学习, 可解释人工智能, LOXL2, 一击即走策略", "comments": "该研究的创新之处在于结合了概率布尔网络、强化学习和可解释人工智能，形成了一个强大的计算框架，用于发现复杂生物系统中的非显而易见的治疗策略。特别地，其提出的“一击即走”治疗理念，通过短期干预实现长期效果，对于克服肿瘤耐药性具有重要意义，可能为临床治疗提供新的思路。"}}
{"id": "2507.03034", "title": "Rethinking Data Protection in the (Generative) Artificial Intelligence Era", "authors": ["Yiming Li", "Shuo Shao", "Yu He", "Junfeng Guo", "Tianwei Zhang", "Zhan Qin", "Pin-Yu Chen", "Michael Backes", "Philip Torr", "Dacheng Tao", "Kui Ren"], "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Perspective paper for a broader scientific audience. The first two authors contributed equally to this paper. 13 pages", "url": "http://arxiv.org/abs/2507.03034v2", "summary": "The (generative) artificial intelligence (AI) era has profoundly reshaped the\nmeaning and value of data. No longer confined to static content, data now\npermeates every stage of the AI lifecycle from the training samples that shape\nmodel parameters to the prompts and outputs that drive real-world model\ndeployment. This shift renders traditional notions of data protection\ninsufficient, while the boundaries of what needs safeguarding remain poorly\ndefined. Failing to safeguard data in AI systems can inflict societal and\nindividual, underscoring the urgent need to clearly delineate the scope of and\nrigorously enforce data protection. In this perspective, we propose a\nfour-level taxonomy, including non-usability, privacy preservation,\ntraceability, and deletability, that captures the diverse protection needs\narising in modern (generative) AI models and systems. Our framework offers a\nstructured understanding of the trade-offs between data utility and control,\nspanning the entire AI pipeline, including training datasets, model weights,\nsystem prompts, and AI-generated content. We analyze representative technical\napproaches at each level and reveal regulatory blind spots that leave critical\nassets exposed. By offering a structured lens to align future AI technologies\nand governance with trustworthy data practices, we underscore the urgency of\nrethinking data protection for modern AI techniques and provide timely guidance\nfor developers, researchers, and regulators alike.", "comment": "Perspective paper for a broader scientific audience. The first two\n  authors contributed equally to this paper. 13 pages", "pdf_url": "http://arxiv.org/pdf/2507.03034v2", "cate": "cs.LG", "date": "2025-07-03", "updated": "2025-07-16", "AI": {"title_translation": "重新思考（生成式）人工智能时代的数据保护", "tldr": "鉴于生成式AI时代数据价值和形态的变化，传统数据保护方法已不足。本文提出了一个四级数据保护分类法，涵盖不可用性、隐私保护、可追溯性和可删除性，旨在为AI生命周期中的数据保护提供结构化理解和指导。", "motivation": "（生成式）人工智能时代深刻改变了数据的含义和价值，传统的数据保护观念已不足以应对。数据现在渗透到AI生命周期的每个阶段，从训练样本到提示和输出，而需要保护的边界定义不清。未能保护AI系统中的数据可能对社会和个人造成损害，因此迫切需要明确界定和严格执行数据保护的范围。", "method": "本文提出了一个四级分类法来捕捉现代（生成式）AI模型和系统中多样化的保护需求，包括不可用性、隐私保护、可追溯性和可删除性。该框架提供了一个结构化的理解，涉及数据效用和控制之间的权衡，涵盖整个AI管道，包括训练数据集、模型权重、系统提示和AI生成内容。作者分析了每个级别的代表性技术方法，并揭示了监管盲点。", "result": "该框架为理解数据效用和控制之间的权衡提供了一个结构化的视角，涵盖整个AI管道。研究揭示了现有监管中的盲点，这些盲点使得关键资产暴露在外。", "conclusion": "本文通过提供一个结构化的视角来协调未来的AI技术和治理与值得信赖的数据实践，强调了重新思考现代AI技术数据保护的紧迫性，并为开发人员、研究人员和监管机构提供了及时的指导。", "translation": "（生成式）人工智能（AI）时代深刻改变了数据的含义和价值。数据不再局限于静态内容，而是渗透到AI生命周期的每个阶段，从塑造模型参数的训练样本到驱动实际模型部署的提示和输出。这种转变使得传统的数据保护观念不足，而需要保护的边界仍然定义不清。未能保护AI系统中的数据可能对社会和个人造成损害，这凸显了明确界定数据保护范围并严格执行的紧迫性。在此观点中，我们提出了一个四级分类法，包括不可用性、隐私保护、可追溯性和可删除性，以捕捉现代（生成式）AI模型和系统中出现的各种保护需求。我们的框架提供了对数据效用和控制之间权衡的结构化理解，涵盖了整个AI管道，包括训练数据集、模型权重、系统提示和AI生成内容。我们分析了每个级别的代表性技术方法，并揭示了导致关键资产暴露的监管盲点。通过提供一个结构化的视角来协调未来的AI技术和治理与值得信赖的数据实践，我们强调了重新思考现代AI技术数据保护的紧迫性，并为开发人员、研究人员和监管机构提供了及时的指导。", "summary": "本文探讨了生成式AI时代数据价值和形态的根本性变化，指出传统数据保护方法已无法满足当前需求。鉴于数据贯穿AI生命周期的各个阶段，作者提出了一个创新的四级数据保护分类法，包括不可用性、隐私保护、可追溯性和可删除性。该框架旨在提供一个结构化的视角，以理解AI管道中数据效用与控制之间的权衡，并分析了各级别的技术方法，揭示了现有监管的不足之处。文章强调了重新思考AI数据保护的紧迫性，并为相关方提供了指导。", "keywords": "数据保护, 生成式AI, 数据分类, 隐私保护, 可追溯性", "comments": "本文的创新之处在于提出了一个针对生成式AI时代数据保护的四级分类法，这为理解和管理AI生命周期中的数据保护需求提供了一个结构化且全面的框架。其重要性在于，它不仅指出了传统数据保护的局限性，还通过揭示监管盲点，为未来的AI技术开发和治理提供了及时且关键的指导，有助于促进AI系统的可信赖性。该框架有助于弥合技术发展与法律监管之间的差距。"}}
{"id": "2507.11534", "title": "Sharp Error-Rate Transitions in Quantum QC-LDPC Codes under Joint BP Decoding", "authors": ["Daiki Komoto", "Kenta Kasai"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11534v2", "summary": "In this study, we report that quantum quasi-cyclic low-density parity-check\ncodes decoded via joint belief propagation (BP) exhibit steep error-rate\ncurves, despite the presence of error floors. To the best of our knowledge,\nthis is the first observation of such threshold-like behavior for quantum LDPC\ncodes with non-vanishing coding rate, excluding those decoded with non-binary\nBP decoders. Moreover, we find that dominant error events contributing to the\nerror floor typically involve only a small number of bits. These findings\nsuggest that the error floor is caused by trapping sets--specific subgraph\nstructures in the Tanner graph--and indicate that identifying and avoiding such\nstructures may lead to further reduction of the error floor.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11534v2", "cate": "quant-ph", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "量子QC-LDPC码在联合BP解码下的陡峭误码率转变", "tldr": "量子QC-LDPC码在联合BP解码下表现出陡峭的误码率曲线，尽管存在错误平台，且错误平台由少量位的陷阱集引起。", "motivation": "尽管量子QC-LDPC码在联合BP解码下存在错误平台，但研究其误码率行为，特别是观察到陡峭的误码率曲线（类似阈值行为），并探讨错误平台的原因。", "method": "本研究报告了量子准循环低密度奇偶校验码通过联合信念传播（BP）解码时的表现。具体方法是观察和分析其误码率曲线。", "result": "量子准循环低密度奇偶校验码在联合信念传播（BP）解码下表现出陡峭的误码率曲线，尽管存在错误平台。据作者所知，这是首次观察到具有非零编码率的量子LDPC码（排除使用非二进制BP解码器解码的码）的这种类似阈值的行为。导致错误平台的主要错误事件通常只涉及少量比特。这些发现表明错误平台是由陷阱集（Tanner图中的特定子图结构）引起的。", "conclusion": "量子QC-LDPC码在联合BP解码下表现出陡峭的误码率转变，且错误平台可能由陷阱集引起，识别并避免这些结构有望进一步降低错误平台。", "translation": "在这项研究中，我们报告称，通过联合置信传播（BP）解码的量子准循环低密度奇偶校验码（QC-LDPC）表现出陡峭的误码率曲线，尽管存在错误平台。据我们所知，这是首次观察到具有非零编码率的量子LDPC码（不包括那些使用非二进制BP解码器解码的码）的这种类似阈值的行为。此外，我们发现导致错误平台的主要错误事件通常只涉及少量比特。这些发现表明，错误平台是由陷阱集——Tanner图中的特定子图结构——引起的，并表明识别和避免这些结构可能导致错误平台的进一步降低。", "summary": "本研究报告了量子QC-LDPC码在联合BP解码下表现出陡峭的误码率转变，这是首次观察到具有非零编码率的量子LDPC码的类似阈值行为。研究还发现，错误平台主要由涉及少量比特的陷阱集引起，暗示识别并规避这些结构有望降低错误平台。", "keywords": "量子QC-LDPC码, 联合BP解码, 误码率转变, 错误平台, 陷阱集", "comments": "这项研究的创新之处在于首次观察到量子QC-LDPC码在联合BP解码下呈现出类似经典码的陡峭误码率转变，这对于理解量子纠错码的性能至关重要。发现错误平台与陷阱集有关，为未来设计更优的量子LDPC码提供了明确的方向。"}}
{"id": "2507.11777", "title": "Towards Scalable AASIST: Refining Graph Attention for Speech Deepfake Detection", "authors": ["Ivan Viakhirev", "Daniil Sirota", "Aleksandr Smirnov", "Kirill Borodin"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11777v1", "summary": "Advances in voice conversion and text-to-speech synthesis have made automatic\nspeaker verification (ASV) systems more susceptible to spoofing attacks. This\nwork explores modest refinements to the AASIST anti-spoofing architecture. It\nincorporates a frozen Wav2Vec 2.0 encoder to retain self-supervised speech\nrepresentations in limited-data settings, substitutes the original graph\nattention block with a standardized multi-head attention module using\nheterogeneous query projections, and replaces heuristic frame-segment fusion\nwith a trainable, context-aware integration layer. When evaluated on the\nASVspoof 5 corpus, the proposed system reaches a 7.6\\% equal error rate (EER),\nimproving on a re-implemented AASIST baseline under the same training\nconditions. Ablation experiments suggest that each architectural change\ncontributes to the overall performance, indicating that targeted adjustments to\nestablished models may help strengthen speech deepfake detection in practical\nscenarios. The code is publicly available at\nhttps://github.com/KORALLLL/AASIST_SCALING.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11777v1", "cate": "cs.SD", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "迈向可扩展的AASIST：优化图注意力用于语音深度伪造检测", "tldr": "该研究通过改进AASIST架构（引入Wav2Vec 2.0编码器、标准化多头注意力模块和可训练的上下文感知集成层），提高了语音深度伪造检测的性能。", "motivation": "自动说话人验证（ASV）系统越来越容易受到语音转换和文本转语音合成技术造成的欺骗攻击。", "method": "本研究对AASIST反欺骗架构进行了改进，包括：1. 整合一个冻结的Wav2Vec 2.0编码器以在有限数据设置中保留自监督语音表示。2. 用使用异构查询投影的标准化多头注意力模块取代原始图注意力块。3. 用可训练的、上下文感知的集成层取代启发式帧段融合。", "result": "在ASVspoof 5语料库上评估时，所提出的系统达到了7.6%的等错误率（EER），在相同的训练条件下，比重新实现的AASIST基线有所改进。消融实验表明，每个架构变化都对整体性能有所贡献。", "conclusion": "有针对性地调整现有模型可能有助于在实际场景中加强语音深度伪造检测。", "translation": "语音转换和文本转语音合成技术的进步使得自动说话人验证（ASV）系统更容易受到欺骗攻击。这项工作探索了对AASIST反欺骗架构的适度改进。它整合了一个冻结的Wav2Vec 2.0编码器，以在有限数据设置中保留自监督语音表示；用使用异构查询投影的标准化多头注意力模块取代了原始的图注意力块；并用可训练的、上下文感知的集成层取代了启发式帧段融合。在ASVspoof 5语料库上评估时，所提出的系统达到了7.6%的等错误率（EER），在相同的训练条件下，比重新实现的AASIST基线有所改进。消融实验表明，每个架构变化都对整体性能有所贡献，表明有针对性地调整现有模型可能有助于在实际场景中加强语音深度伪造检测。代码已在https://github.com/KORALLLL/AASIST_SCALING公开提供。", "summary": "本研究旨在增强AASIST反欺骗架构，以应对ASV系统日益增长的欺骗攻击风险。通过引入冻结的Wav2Vec 2.0编码器、替换为标准化多头注意力模块以及采用可训练的上下文感知集成层，该方法在ASVspoof 5语料库上实现了7.6%的等错误率，优于重新实现的AASIST基线。消融实验证实了各项改进对性能的积极贡献，表明针对性调整对提升语音深度伪造检测的实用性至关重要。", "keywords": "语音深度伪造检测, AASIST, 图注意力, Wav2Vec 2.0, 反欺骗", "comments": "该论文通过对现有AASIST架构的精细化改进，有效提升了语音深度伪造检测的性能。其创新点在于引入了Wav2Vec 2.0编码器以利用自监督表示，并替换了图注意力模块为更通用的多头注意力，以及用可训练层取代了启发式融合，这些都显示出对性能的积极影响。研究强调了在现有模型上进行有针对性调整的潜力，对于实际部署具有重要意义。"}}
{"id": "2507.12091", "title": "Improved Analysis for Sign-based Methods with Momentum Updates", "authors": ["Wei Jiang", "Dingzhi Yu", "Sifan Yang", "Wenhao Yang", "Lijun Zhang"], "categories": ["math.OC", "cs.LG"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12091v1", "summary": "In this paper, we present enhanced analysis for sign-based optimization\nalgorithms with momentum updates. Traditional sign-based methods, under the\nseparable smoothness assumption, guarantee a convergence rate of\n$\\mathcal{O}(T^{-1/4})$, but they either require large batch sizes or assume\nunimodal symmetric stochastic noise. To address these limitations, we\ndemonstrate that signSGD with momentum can achieve the same convergence rate\nusing constant batch sizes without additional assumptions. Our analysis, under\nthe standard $l_2$-smoothness condition, improves upon the result of the prior\nmomentum-based signSGD method by a factor of $\\mathcal{O}(d^{1/2})$, where $d$\nis the problem dimension. Furthermore, we explore sign-based methods with\nmajority vote in distributed settings and show that the proposed momentum-based\nmethod yields convergence rates of $\\mathcal{O}\\left( d^{1/2}T^{-1/2} +\ndn^{-1/2} \\right)$ and $\\mathcal{O}\\left( \\max \\{ d^{1/4}T^{-1/4},\nd^{1/10}T^{-1/5} \\} \\right)$, which outperform the previous results of\n$\\mathcal{O}\\left( dT^{-1/4} + dn^{-1/2} \\right)$ and $\\mathcal{O}\\left(\nd^{3/8}T^{-1/8} \\right)$, respectively. Numerical experiments further validate\nthe effectiveness of the proposed methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12091v1", "cate": "math.OC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "动量更新的符号方法的改进分析", "tldr": "本文对带动量更新的符号优化算法进行了改进分析，证明了在无需额外假设和常数批量大小的情况下，可以达到与传统方法相同的收敛速度，并在分布式设置中获得了更好的收敛率。", "motivation": "传统符号方法在可分离平滑假设下收敛率为 $\\mathcal{O}(T^{-1/4})$，但需要大批量或假设单峰对称随机噪声。本文旨在解决这些限制。", "method": "提出了对带动量的signSGD算法的增强分析，并在标准 $l_2$-平滑条件下进行了改进。此外，还在分布式设置中探索了带多数投票的符号方法。", "result": "带动量的signSGD在常数批量大小下无需额外假设即可达到 $\\mathcal{O}(T^{-1/4})$ 的收敛率；在标准 $l_2$-平滑条件下，将先前基于动量的signSGD方法的结果改进了 $\\mathcal{O}(d^{1/2})$ 倍；在分布式设置中，提出的基于动量的方法的收敛率分别为 $\\mathcal{O}\\left( d^{1/2}T^{-1/2} + dn^{-1/2} \\right)$ 和 $\\mathcal{O}\\left( \\max \\{ d^{1/4}T^{-1/4}, d^{1/10}T^{-1/5} \\} \\right)$，优于先前结果。", "conclusion": "数值实验进一步验证了所提出方法的有效性。", "translation": "在本文中，我们对带动量更新的基于符号的优化算法提出了增强分析。传统的基于符号的方法，在可分离平滑假设下，保证了 $\\mathcal{O}(T^{-1/4})$ 的收敛速度，但它们要么需要大批量大小，要么假设单峰对称随机噪声。为了解决这些限制，我们证明了带动量的signSGD可以在不额外假设的情况下使用常数批量大小达到相同的收敛速度。我们的分析在标准 $l_2$-平滑条件下，将先前基于动量的signSGD方法的结果改进了 $\\mathcal{O}(d^{1/2})$ 倍，其中 $d$ 是问题维度。此外，我们探索了分布式设置中带多数投票的基于符号的方法，并表明所提出的基于动量的方法产生了 $\\mathcal{O}\\left( d^{1/2}T^{-1/2} + dn^{-1/2} \\right)$ 和 $\\mathcal{O}\\left( \\max \\{ d^{1/4}T^{-1/4}, d^{1/10}T^{-1/5} \\} \\right)$ 的收敛率，分别优于先前的 $\\mathcal{O}\\left( dT^{-1/4} + dn^{-1/2} \\right)$ 和 $\\mathcal{O}\\left( d^{3/8}T^{-1/8} \\right)$ 结果。数值实验进一步验证了所提出方法的有效性。", "summary": "本文对带动量更新的符号优化算法进行了改进分析，解决了传统方法在大批量或特定噪声假设下的局限性。研究表明，带动量的signSGD在常数批量大小下可达到相同收敛率，并在标准 $l_2$-平滑条件下将收敛结果改进了 $\\mathcal{O}(d^{1/2})$ 倍。此外，在分布式设置中，本文提出的方法在收敛率上显著优于现有结果，并通过数值实验验证了其有效性。", "keywords": "符号方法, 动量更新, 收敛分析, 分布式优化, signSGD", "comments": "本文的创新点在于对带动量更新的符号优化算法进行了更严格和更优的理论分析，特别是在放宽了传统方法对批量大小和噪声分布的限制方面。它通过改进分析，使得signSGD在更实际的条件下（常数批量大小和标准 $l_2$-平滑）也能表现出色，并显著提升了在分布式环境下的性能，这对于大规模优化问题具有重要意义。"}}
{"id": "2507.09016", "title": "Enhancing RLHF with Human Gaze Modeling", "authors": ["Karim Galliamov", "Ivan Titov", "Ilya Pershin"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09016v2", "summary": "Reinforcement Learning from Human Feedback (RLHF) aligns language models with\nhuman preferences but is computationally expensive. We explore two approaches\nthat leverage human gaze modeling to enhance RLHF: (1) gaze-aware reward models\nand (2) gaze-based distribution of sparse rewards at token level. Our\nexperiments demonstate that gaze-informed RLHF achieves faster convergence\nwhile maintaining or slightly improving performance, thus, reducing\ncomputational costs during policy optimization. These results show that human\ngaze provides a valuable and underused signal for policy optimization, pointing\nto a promising direction for improving RLHF efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09016v2", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-16", "AI": {"title_translation": "利用人类注视建模增强RLHF", "tldr": "本文通过两种方式利用人类注视数据来提高RLHF的效率：注视感知奖励模型和基于注视的稀疏奖励分配，实验表明这能实现更快的收敛并降低计算成本。", "motivation": "强化学习从人类反馈（RLHF）虽然能使语言模型与人类偏好对齐，但计算成本高昂。本文的动机是探索如何利用人类注视建模来提高RLHF的效率，从而降低策略优化的计算成本。", "method": "本文探索了两种利用人类注视建模来增强RLHF的方法：1) 注视感知奖励模型（gaze-aware reward models）；2) 基于注视的稀疏奖励在token级别的分配（gaze-based distribution of sparse rewards at token level）。", "result": "实验结果表明，注视信息增强的RLHF在保持或略微提升性能的同时，实现了更快的收敛，从而降低了策略优化过程中的计算成本。", "conclusion": "人类注视为策略优化提供了一个有价值且未被充分利用的信号，这为提高RLHF效率指明了一个有前景的方向。", "translation": "强化学习从人类反馈（RLHF）使语言模型与人类偏好对齐，但计算成本高昂。我们探索了两种利用人类注视建模来增强RLHF的方法：(1) 注视感知奖励模型和 (2) 基于注视的token级别稀疏奖励分配。我们的实验表明，注视信息增强的RLHF在保持或略微提升性能的同时，实现了更快的收敛，从而降低了策略优化过程中的计算成本。这些结果表明，人类注视为策略优化提供了一个有价值且未被充分利用的信号，这为提高RLHF效率指明了一个有前景的方向。", "summary": "本文提出通过整合人类注视建模来提高强化学习从人类反馈（RLHF）的效率。研究探索了注视感知奖励模型和基于注视的token级稀疏奖励两种方法。实验证明，利用人类注视信息能够加速RLHF的收敛过程，同时保持或略微提升模型性能，从而有效降低策略优化的计算成本。这表明人类注视是RLHF效率提升的一个有价值且有潜力的信号。", "keywords": "RLHF, 人类注视, 计算效率, 奖励模型, 策略优化", "comments": "这项研究的创新点在于将人类注视数据引入RLHF过程，利用其作为一种低成本且有效的信号来优化奖励模型和奖励分配，从而解决了RLHF计算成本高昂的问题。其重要性在于为未来高效、低成本的语言模型对齐提供了新的思路和方法。"}}
{"id": "2507.12273", "title": "Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot", "authors": ["Luca Garello", "Francesca Cocchella", "Alessandra Sciutti", "Manuel Catalano", "Francesco Rea"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12273v1", "summary": "Autonomous robots are increasingly being tested into public spaces to enhance\nuser experiences, particularly in cultural and educational settings. This paper\npresents the design, implementation, and evaluation of the autonomous museum\nguide robot Alter-Ego equipped with advanced navigation and interactive\ncapabilities. The robot leverages state-of-the-art Large Language Models (LLMs)\nto provide real-time, context aware question-and-answer (Q&A) interactions,\nallowing visitors to engage in conversations about exhibits. It also employs\nrobust simultaneous localization and mapping (SLAM) techniques, enabling\nseamless navigation through museum spaces and route adaptation based on user\nrequests. The system was tested in a real museum environment with 34\nparticipants, combining qualitative analysis of visitor-robot conversations and\nquantitative analysis of pre and post interaction surveys. Results showed that\nthe robot was generally well-received and contributed to an engaging museum\nexperience, despite some limitations in comprehension and responsiveness. This\nstudy sheds light on HRI in cultural spaces, highlighting not only the\npotential of AI-driven robotics to support accessibility and knowledge\nacquisition, but also the current limitations and challenges of deploying such\ntechnologies in complex, real-world environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12273v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "下一代博物馆导览：具有自主导航和访客交互能力的智能机器人", "tldr": "本文介绍并评估了一个名为Alter-Ego的自主博物馆导览机器人，它结合了LLM进行问答互动和SLAM进行导航，并在真实博物馆环境中进行了测试，结果显示其总体上受到好评，但仍存在理解和响应方面的局限性。", "motivation": "为了增强用户体验，特别是在文化和教育环境中，自主机器人正越来越多地被引入公共空间进行测试。本文旨在设计、实现和评估一个能够提供自主导航和访客交互的博物馆导览机器人。", "method": "本文设计、实现并评估了自主博物馆导览机器人Alter-Ego。该机器人利用先进的大型语言模型（LLMs）提供实时、上下文感知的问答互动，并采用鲁Pang的同步定位与建图（SLAM）技术实现无缝导航和路径适应。系统在真实博物馆环境中对34名参与者进行了测试，结合了访客-机器人对话的定性分析和互动前后调查的定量分析。", "result": "测试结果表明，该机器人总体上受到了好评，并有助于提供引人入胜的博物馆体验。尽管在理解和响应方面存在一些局限性，但研究突出了AI驱动机器人支持可访问性和知识获取的潜力。", "conclusion": "本研究揭示了AI驱动机器人在文化空间中人机交互的潜力，不仅体现在支持可访问性和知识获取方面，也强调了在复杂、真实环境中部署此类技术当前面临的局限性和挑战。", "translation": "自主机器人正越来越多地被引入公共空间进行测试，以增强用户体验，特别是在文化和教育环境中。本文介绍了自主博物馆导览机器人Alter-Ego的设计、实现和评估，该机器人配备了先进的导航和交互能力。该机器人利用最先进的大型语言模型（LLMs）提供实时、上下文感知的问答互动，允许访客就展品进行对话。它还采用了鲁棒的同步定位与建图（SLAM）技术，使得在博物馆空间中实现无缝导航并根据用户请求调整路线成为可能。该系统在真实博物馆环境中对34名参与者进行了测试，结合了访客-机器人对话的定性分析和互动前后调查的定量分析。结果显示，尽管在理解和响应方面存在一些局限性，但该机器人总体上受到了好评，并有助于提供引人入胜的博物馆体验。这项研究揭示了文化空间中的人机交互（HRI），不仅强调了AI驱动机器人支持可访问性和知识获取的潜力，也指出了在复杂、真实环境中部署此类技术当前的局限性和挑战。", "summary": "本文介绍并评估了名为Alter-Ego的自主博物馆导览机器人。该机器人结合了大型语言模型（LLMs）实现实时的问答互动，以及同步定位与建图（SLAM）技术实现自主导航。在真实博物馆环境中对34名参与者进行的测试显示，机器人总体上受到欢迎并提升了博物馆体验，尽管在理解和响应方面存在局限性。研究强调了AI机器人促进文化空间可访问性和知识获取的潜力，同时也指出了实际部署中的挑战。", "keywords": "博物馆导览机器人, 自主导航, 大型语言模型, 人机交互, SLAM", "comments": "这项研究的创新之处在于将LLMs和SLAM技术整合到一个实际的博物馆导览机器人中，并在真实环境中进行了用户测试。它不仅展示了AI在文化遗产领域应用的巨大潜力，也坦诚地指出了当前技术的局限性，如理解和响应能力，这对于未来研究具有重要的指导意义。"}}
{"id": "2507.12038", "title": "Distributed Algorithms for Potential Problems", "authors": ["Alkida Balliu", "Thomas Boudier", "Francesco d'Amore", "Dennis Olivetti", "Gustav Schmid", "Jukka Suomela"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      28 pages, 4 figures", "url": "http://arxiv.org/abs/2507.12038v1", "summary": "In this work we present a fast distributed algorithm for local potential\nproblems: these are graph problems where the task is to find a locally optimal\nsolution where no node can unilaterally improve the utility in its local\nneighborhood by changing its own label. A simple example of such a problem is\nthe task of finding a locally optimal cut, i.e., a cut where for each node at\nleast half of its incident edges are cut edges. The distributed round\ncomplexity of locally optimal cut has been wide open; the problem is known to\nrequire $\\Omega(\\log n)$ rounds in the deterministic LOCAL model and\n$\\Omega(\\log \\log n)$ rounds in the randomized LOCAL model, but the only known\nupper bound is the trivial brute-force solution of $O(n)$ rounds. Locally\noptimal cut in bounded-degree graphs is perhaps the simplest example of a\nlocally checkable labeling problem for which there is still such a large gap\nbetween current upper and lower bounds. We show that in bounded-degree graphs,\nall local potential problems, including locally optimal cut, can be solved in\n$\\log^{O(1)} n$ rounds, both in the deterministic and randomized LOCAL models.\nIn particular, the deterministic round complexity of the locally optimal cut\nproblem is now settled to $\\log^{\\Theta(1)} n$.", "comment": "28 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.12038v1", "cate": "cs.DC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "势能问题的分布式算法", "tldr": "本文提出了一种快速分布式算法，用于解决有界度图中的局部势能问题，包括局部最优割问题，将其轮数复杂度从O(n)显著降低到log^O(1) n。", "motivation": "局部势能问题（如局部最优割）的分布式轮数复杂度存在巨大空白，已知下限为$\\\\Omega(\\\\log n)$（确定性）或$\\\\Omega(\\\\log \\\\log n)$（随机性），但唯一已知的上限是简单的$O(n)$蛮力解决方案。这种差距促使研究人员寻求更高效的分布式算法。", "method": "本文提出了一种快速分布式算法来解决局部势能问题，该算法适用于有界度图。", "result": "在有界度图中，所有局部势能问题（包括局部最优割）都可以在确定性和随机LOCAL模型中以$\\\\log^{O(1)} n$轮解决。特别是，局部最优割问题的确定性轮数复杂度现在确定为$\\\\log^{\\\\Theta(1)} n$。", "conclusion": "本文提出的分布式算法显著缩小了局部势能问题（特别是局部最优割问题）在有界度图中的轮数复杂度上限与下限之间的差距，将其从线性时间复杂度降低到多对数时间复杂度。", "translation": "在这项工作中，我们提出了一种针对局部势能问题的快速分布式算法：这些是图问题，任务是找到一个局部最优解，其中没有节点可以通过改变自己的标签单方面改善其局部邻域的效用。一个简单的例子是找到局部最优割的任务，即一个割，其中每个节点的至少一半的关联边是割边。局部最优割的分布式轮数复杂度一直是一个悬而未决的问题；已知该问题在确定性LOCAL模型中需要$\\\\Omega(\\\\log n)$轮，在随机LOCAL模型中需要$\\\\Omega(\\\\log \\\\log n)$轮，但唯一已知的上限是平凡的$O(n)$轮的暴力解决方案。有界度图中的局部最优割可能是局部可检查标签问题中最简单的例子，目前其上下界之间仍然存在如此大的差距。我们证明，在有界度图中，所有局部势能问题，包括局部最优割，都可以在确定性和随机LOCAL模型中以$\\\\log^{O(1)} n$轮解决。特别是，局部最优割问题的确定性轮数复杂度现在确定为$\\\\log^{\\\\Theta(1)} n$。", "summary": "本文提出了一种快速分布式算法，用于解决图中的局部势能问题，其中任务是找到一个局部最优解。这类问题的一个典型例子是局部最优割，其分布式轮数复杂度存在显著的上下界差距。研究表明，在有界度图中，该算法能在确定性和随机LOCAL模型中以$\\\\log^{O(1)} n$轮解决所有局部势能问题，从而将局部最优割问题的确定性轮数复杂度确定为$\\\\log^{\\\\Theta(1)} n$，显著改善了现有上限。", "keywords": "分布式算法, 局部势能问题, 局部最优割, 轮数复杂度, 有界度图", "comments": "该论文在分布式算法领域做出了重要贡献，特别是通过提出一种高效的算法，解决了长期存在的局部最优割问题在有界度图中的轮数复杂度难题。它将之前粗略的$O(n)$上限改进为多对数时间$\\\\log^{O(1)} n$，显著缩小了理论下限与实际可行解之间的差距，对于分布式系统和网络优化具有重要意义。"}}
{"id": "2507.12195", "title": "Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision", "authors": ["Arkaprabha Basu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12195v1", "summary": "Modern digitised approaches have dramatically changed the preservation and\nrestoration of cultural treasures, integrating computer scientists into\nmultidisciplinary projects with ease. Machine learning, deep learning, and\ncomputer vision techniques have revolutionised developing sectors like 3D\nreconstruction, picture inpainting,IoT-based methods, genetic algorithms, and\nimage processing with the integration of computer scientists into\nmultidisciplinary initiatives. We suggest three cutting-edge techniques in\nrecognition of the special qualities of Indian monuments, which are famous for\ntheir architectural skill and aesthetic appeal. First is the Fractal\nConvolution methodology, a segmentation method based on image processing that\nsuccessfully reveals subtle architectural patterns within these irreplaceable\ncultural buildings. The second is a revolutionary Self-Sensitive Tile Filling\n(SSTF) method created especially for West Bengal's mesmerising Bankura\nTerracotta Temples with a brand-new data augmentation method called MosaicSlice\non the third. Furthermore, we delve deeper into the Super Resolution strategy\nto upscale the images without losing significant amount of quality. Our methods\nallow for the development of seamless region-filling and highly detailed tiles\nwhile maintaining authenticity using a novel data augmentation strategy within\naffordable costs introducing automation. By providing effective solutions that\npreserve the delicate balance between tradition and innovation, this study\nimproves the subject and eventually ensures unrivalled efficiency and aesthetic\nexcellence in cultural heritage protection. The suggested approaches advance\nthe field into an era of unmatched efficiency and aesthetic quality while\ncarefully upholding the delicate equilibrium between tradition and innovation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12195v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "揭示古老之美：使用计算机视觉对寺庙瓦片进行数字化重建", "tldr": "该研究提出三种计算机视觉技术（分形卷积、自敏感瓦片填充和MosaicSlice数据增强）以及超分辨率策略，用于印度寺庙瓦片的数字化重建，旨在实现无缝区域填充和高细节瓦片，同时保持真实性并提高文化遗产保护的效率和美学质量。", "motivation": "现代数字化方法极大地改变了文化遗产的保护和修复方式，计算机科学家被整合到多学科项目中。鉴于印度古迹独特的建筑技艺和美学吸引力，研究旨在利用计算机视觉技术对其寺庙瓦片进行数字化重建和修复。", "method": "研究提出了三种前沿技术：一是基于图像处理的分形卷积方法，用于揭示建筑图案的分割。二是为西孟加拉邦班库拉陶土寺庙设计的自敏感瓦片填充（SSTF）方法。三是全新的数据增强方法MosaicSlice。此外，还深入探讨了超分辨率策略，以在不损失显著质量的情况下提升图像分辨率。", "result": "所提出的方法能够以经济的成本实现无缝区域填充和高细节瓦片的开发，同时通过新颖的数据增强策略保持真实性并引入自动化。这些方法提高了文化遗产保护的效率和美学卓越性。", "conclusion": "本研究通过提供有效的解决方案来平衡传统与创新，提升了文化遗产保护领域，并最终确保了无与伦比的效率和美学质量。所提出的方法将该领域推向一个效率和美学质量空前的时代，同时精心维护着传统与创新之间的微妙平衡。", "translation": "现代数字化方法极大地改变了文化瑰宝的保存和修复方式，使计算机科学家能够轻松融入多学科项目。机器学习、深度学习和计算机视觉技术通过将计算机科学家整合到多学科倡议中，彻底改变了3D重建、图像修复、基于物联网的方法、遗传算法和图像处理等发展中领域。我们提出了三种尖端技术，以识别印度古迹的特殊品质，这些古迹以其建筑技艺和美学吸引力而闻名。首先是分形卷积方法，这是一种基于图像处理的分割方法，成功揭示了这些不可替代的文化建筑中微妙的建筑图案。其次是专为西孟加拉邦迷人的班库拉陶土寺庙创建的革命性自敏感瓦片填充（SSTF）方法，第三种是名为MosaicSlice的全新数据增强方法。此外，我们深入研究了超分辨率策略，以在不损失显著质量的情况下提升图像。我们的方法允许在保持真实性的同时，以经济的成本开发无缝区域填充和高细节瓦片，并引入自动化。通过提供有效的解决方案，在传统与创新之间保持微妙的平衡，本研究提升了该领域，并最终确保了文化遗产保护中无与伦比的效率和美学卓越性。所提出的方法将该领域推向一个效率和美学质量空前的时代，同时精心维护着传统与创新之间的微妙平衡。", "summary": "本研究专注于利用计算机视觉技术对印度寺庙瓦片进行数字化重建和修复。论文提出了一系列创新方法，包括基于图像处理的分形卷积分割技术、专为班库拉陶土寺庙设计的自敏感瓦片填充（SSTF）方法，以及一种名为MosaicSlice的新型数据增强策略。此外，还应用了超分辨率技术来提高图像质量。这些方法旨在实现寺庙瓦片的无缝区域填充和高细节重建，同时确保真实性、降低成本并引入自动化，从而显著提升文化遗产的保护效率和美学价值。", "keywords": "寺庙瓦片, 数字化重建, 计算机视觉, 文化遗产, 图像处理", "comments": "本文的创新之处在于提出了一系列针对文化遗产数字化重建的专门计算机视觉技术，特别是针对印度寺庙瓦片的独特挑战。分形卷积、SSTF和MosaicSlice等新方法的引入，结合自动化和成本效益的考量，显示了其在实际应用中的潜力。研究强调了在技术进步的同时保持文化真实性的重要性，这对于文化遗产保护领域具有重要意义。"}}
{"id": "2507.12465", "title": "PhysX: Physical-Grounded 3D Asset Generation", "authors": ["Ziang Cao", "Zhaoxi Chen", "Linag Pan", "Ziwei Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.12465v1", "summary": "3D modeling is moving from virtual to physical. Existing 3D generation\nprimarily emphasizes geometries and textures while neglecting physical-grounded\nmodeling. Consequently, despite the rapid development of 3D generative models,\nthe synthesized 3D assets often overlook rich and important physical\nproperties, hampering their real-world application in physical domains like\nsimulation and embodied AI. As an initial attempt to address this challenge, we\npropose \\textbf{PhysX}, an end-to-end paradigm for physical-grounded 3D asset\ngeneration. 1) To bridge the critical gap in physics-annotated 3D datasets, we\npresent PhysXNet - the first physics-grounded 3D dataset systematically\nannotated across five foundational dimensions: absolute scale, material,\naffordance, kinematics, and function description. In particular, we devise a\nscalable human-in-the-loop annotation pipeline based on vision-language models,\nwhich enables efficient creation of physics-first assets from raw 3D assets.2)\nFurthermore, we propose \\textbf{PhysXGen}, a feed-forward framework for\nphysics-grounded image-to-3D asset generation, injecting physical knowledge\ninto the pre-trained 3D structural space. Specifically, PhysXGen employs a\ndual-branch architecture to explicitly model the latent correlations between 3D\nstructures and physical properties, thereby producing 3D assets with plausible\nphysical predictions while preserving the native geometry quality. Extensive\nexperiments validate the superior performance and promising generalization\ncapability of our framework. All the code, data, and models will be released to\nfacilitate future research in generative physical AI.", "comment": "Project page: https://physx-3d.github.io/", "pdf_url": "http://arxiv.org/pdf/2507.12465v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "PhysX：物理接地3D资产生成", "tldr": "PhysX提出了一个端到端的物理接地3D资产生成范式，通过构建首个物理接地3D数据集PhysXNet和设计物理接地图像到3D生成框架PhysXGen，解决了现有3D生成模型忽视物理属性的问题，提升了生成资产在物理领域应用的真实性。", "motivation": "现有3D生成模型主要关注几何形状和纹理，却忽视了物理接地建模，导致合成的3D资产缺乏丰富的物理属性，从而限制了它们在模拟和具身AI等物理领域的实际应用。", "method": "本文提出了一个名为PhysX的端到端物理接地3D资产生成范式。1) 构建了首个系统标注了五种基础维度（绝对尺度、材料、功能、运动学和功能描述）的物理接地3D数据集PhysXNet，并设计了基于视觉-语言模型的可扩展人机协同标注流程。2) 提出了PhysXGen，一个前馈框架，用于物理接地图像到3D资产生成，通过双分支架构明确建模3D结构和物理属性之间的潜在关联，将物理知识注入预训练的3D结构空间。", "result": "广泛的实验验证了我们框架的卓越性能和有前景的泛化能力。", "conclusion": "PhysX首次尝试解决了物理接地3D资产生成中的挑战，通过提供物理接地数据集和生成框架，显著提升了3D资产在物理领域的应用潜力。", "translation": "3D建模正从虚拟走向物理。现有的3D生成主要强调几何形状和纹理，却忽视了物理接地建模。因此，尽管3D生成模型发展迅速，但合成的3D资产往往忽略了丰富而重要的物理属性，阻碍了它们在模拟和具身AI等物理领域的实际应用。作为解决这一挑战的首次尝试，我们提出了PhysX，一个用于物理接地3D资产生成的端到端范式。1) 为弥补物理标注3D数据集的关键空白，我们提出了PhysXNet——首个在五个基础维度（绝对尺度、材料、功能、运动学和功能描述）上系统标注的物理接地3D数据集。特别是，我们设计了一种基于视觉-语言模型的可扩展人机协同标注流程，能够从原始3D资产高效创建物理优先资产。2) 此外，我们提出了PhysXGen，一个用于物理接地图像到3D资产生成的前馈框架，将物理知识注入预训练的3D结构空间。具体而言，PhysXGen采用双分支架构，明确建模3D结构和物理属性之间的潜在关联，从而生成具有合理物理预测的3D资产，同时保留原有的几何质量。广泛的实验验证了我们框架的卓越性能和有前景的泛化能力。所有代码、数据和模型都将发布，以促进生成式物理AI的未来研究。", "summary": "PhysX提出了一种端到端的物理接地3D资产生成范式，旨在解决现有3D生成模型忽视物理属性的问题。该范式包含两个核心组成部分：PhysXNet，一个首次系统标注了五种物理维度（尺度、材料、功能、运动学、功能描述）的物理接地3D数据集，其标注流程利用了视觉-语言模型实现高效创建；以及PhysXGen，一个基于双分支架构的前馈框架，用于将图像转换为具有物理属性的3D资产，通过注入物理知识到3D结构空间，确保生成资产的几何质量和物理合理性。实验证明了该框架的优越性能和泛化能力，为物理AI领域的研究奠定了基础。", "keywords": "3D资产生成, 物理属性, PhysX, PhysXNet, PhysXGen", "comments": "本文的创新点在于首次系统性地解决了3D资产生成中物理属性缺失的关键问题。通过提出PhysXNet数据集，填补了物理标注3D数据的空白，其人机协同标注流程具有高效性和可扩展性。PhysXGen框架通过独特的双分支架构，成功地将物理知识融入到3D生成过程中，确保了生成资产的物理合理性，这对于模拟和具身AI等实际应用至关重要。该工作为未来生成式物理AI的研究开辟了新方向。"}}
{"id": "2507.03976", "title": "Robust Low-light Scene Restoration via Illumination Transition", "authors": ["Ze Li", "Feng Zhang", "Xiatian Zhu", "Meng Zhang", "Yanghong Zhou", "P. Y. Mok"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures, Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.03976v2", "summary": "Synthesizing normal-light novel views from low-light multiview images is an\nimportant yet challenging task, given the low visibility and high ISO noise\npresent in the input images. Existing low-light enhancement methods often\nstruggle to effectively preprocess such low-light inputs, as they fail to\nconsider correlations among multiple views. Although other state-of-the-art\nmethods have introduced illumination-related components offering alternative\nsolutions to the problem, they often result in drawbacks such as color\ndistortions and artifacts, and they provide limited denoising effectiveness. In\nthis paper, we propose a novel Robust Low-light Scene Restoration framework\n(RoSe), which enables effective synthesis of novel views in normal lighting\nconditions from low-light multiview image inputs, by formulating the task as an\nilluminance transition estimation problem in 3D space, conceptualizing it as a\nspecialized rendering task. This multiview-consistent illuminance transition\nfield establishes a robust connection between low-light and normal-light\nconditions. By further exploiting the inherent low-rank property of\nillumination to constrain the transition representation, we achieve more\neffective denoising without complex 2D techniques or explicit noise modeling.\nTo implement RoSe, we design a concise dual-branch architecture and introduce a\nlow-rank denoising module. Experiments demonstrate that RoSe significantly\noutperforms state-of-the-art models in both rendering quality and multiview\nconsistency on standard benchmarks. The codes and data are available at\nhttps://pegasus2004.github.io/RoSe.", "comment": "10 pages, 5 figures, Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.03976v2", "cate": "cs.CV", "date": "2025-07-05", "updated": "2025-07-16", "AI": {"title_translation": "经由光照过渡的鲁棒低光场景恢复", "tldr": "本文提出RoSe框架，通过将低光场景恢复视为3D光照过渡估计问题，并利用光照的低秩特性，从低光多视图图像中鲁棒合成正常光照下的新视图。", "motivation": "现有低光增强方法难以有效处理低光多视图图像，因为它们未能考虑多视图间的相关性，或导致色彩失真、伪影且去噪效果有限。", "method": "本文提出了一种名为RoSe的鲁棒低光场景恢复框架。该方法将低光场景恢复任务公式化为3D空间中的照度过渡估计问题，并将其概念化为一种特殊的渲染任务。RoSe通过建立多视图一致的照度过渡场，并利用光照固有的低秩特性来约束过渡表示，从而实现有效的去噪，无需复杂的2D技术或显式的噪声建模。为实现RoSe，设计了一个简洁的双分支架构并引入了低秩去噪模块。", "result": "实验表明，RoSe在标准基准测试中，渲染质量和多视图一致性方面均显著优于现有最先进模型。", "conclusion": "RoSe框架通过将低光场景恢复视为3D光照过渡估计，并利用光照的低秩特性进行去噪，有效解决了低光多视图图像新视图合成中的挑战，实现了高质量的渲染和去噪效果。", "translation": "从低光多视图图像合成正常光照下的新视图是一项重要但具有挑战性的任务，因为输入图像存在低可见度和高ISO噪声。现有的低光增强方法通常难以有效预处理此类低光输入，因为它们未能考虑多个视图之间的相关性。尽管其他最先进的方法引入了与光照相关的组件，为该问题提供了替代解决方案，但它们常常导致色彩失真和伪影等缺点，并且去噪效果有限。在本文中，我们提出了一种新颖的鲁棒低光场景恢复框架（RoSe），通过将任务公式化为3D空间中的照度过渡估计问题，并将其概念化为一种特殊的渲染任务，从而能够从低光多视图图像输入中有效合成正常光照条件下的新视图。这个多视图一致的照度过渡场在低光和正常光条件之间建立了鲁棒的连接。通过进一步利用光照固有的低秩特性来约束过渡表示，我们无需复杂的2D技术或显式的噪声建模即可实现更有效的去噪。为了实现RoSe，我们设计了一个简洁的双分支架构并引入了一个低秩去噪模块。实验表明，RoSe在标准基准测试中的渲染质量和多视图一致性方面均显著优于现有最先进模型。代码和数据可在https://pegasus2004.github.io/RoSe 获取。", "summary": "本文提出了一种名为RoSe的鲁棒低光场景恢复框架，旨在解决从低光多视图图像合成正常光新视图的挑战。RoSe将该任务视为3D空间中的光照过渡估计问题，并利用光照的低秩特性进行去噪。通过简洁的双分支架构和低秩去噪模块，RoSe在渲染质量和多视图一致性方面均超越了现有SOTA方法。", "keywords": "低光恢复, 多视图图像, 光照过渡, 低秩特性, 新视图合成", "comments": "这篇论文的创新点在于将低光场景恢复问题重新概念化为3D空间中的光照过渡估计，并巧妙地利用了光照的低秩特性来实现高效去噪，避免了复杂的2D去噪技术。其多视图一致性是处理多视图输入的关键优势。该方法为低光多视图图像处理提供了一个鲁棒且高性能的解决方案。"}}
{"id": "2507.11560", "title": "A Model Aware AIGC Task Offloading Algorithm in IIoT Edge Computing", "authors": ["Xin Wang", "Xiao Huan Li", "Xun Wang"], "categories": ["cs.DC", "cs.AI"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures, accepted by ICCC 2025", "url": "http://arxiv.org/abs/2507.11560v1", "summary": "The integration of the Industrial Internet of Things (IIoT) with Artificial\nIntelligence-Generated Content (AIGC) offers new opportunities for smart\nmanufacturing, but it also introduces challenges related to\ncomputation-intensive tasks and low-latency demands. Traditional generative\nmodels based on cloud computing are difficult to meet the real-time\nrequirements of AIGC tasks in IIoT environments, and edge computing can\neffectively reduce latency through task offloading. However, the dynamic nature\nof AIGC tasks, model switching delays, and resource constraints impose higher\ndemands on edge computing environments. To address these challenges, this paper\nproposes an AIGC task offloading framework tailored for IIoT edge computing\nenvironments, considering the latency and energy consumption caused by AIGC\nmodel switching for the first time. IIoT devices acted as multi-agent\ncollaboratively offload their dynamic AIGC tasks to the most appropriate edge\nservers deployed with different generative models. A model aware AIGC task\noffloading algorithm based on Multi-Agent Deep Deterministic Policy Gradient\n(MADDPG-MATO) is devised to minimize the latency and energy. Experimental\nresults show that MADDPG-MATO outperforms baseline algorithms, achieving an\naverage reduction of 6.98% in latency, 7.12% in energy consumption, and a 3.72%\nincrease in task completion rate across four sets of experiments with model\nnumbers ranging from 3 to 6, it is demonstrated that the proposed algorithm is\nrobust and efficient in dynamic, high-load IIoT environments.", "comment": "6 pages, 4 figures, accepted by ICCC 2025", "pdf_url": "http://arxiv.org/pdf/2507.11560v1", "cate": "cs.DC", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "IIoT边缘计算中模型感知的AIGC任务卸载算法", "tldr": "本文提出了一种基于多智能体深度确定性策略梯度（MADDPG-MATO）的AIGC任务卸载算法，用于IIoT边缘计算环境，旨在最小化延迟和能耗，并首次考虑了模型切换开销。", "motivation": "传统基于云计算的生成模型难以满足IIoT环境中AIGC任务的实时性要求，而边缘计算虽能降低延迟，但AIGC任务的动态性、模型切换延迟和资源限制对边缘计算提出了更高要求。", "method": "本文提出了一种为IIoT边缘计算环境量身定制的AIGC任务卸载框架，首次考虑了AIGC模型切换导致的延迟和能耗。IIoT设备作为多智能体协同将动态AIGC任务卸载到部署有不同生成模型的最合适的边缘服务器。开发了一种基于多智能体深度确定性策略梯度（MADDPG-MATO）的模型感知AIGC任务卸载算法，以最小化延迟和能耗。", "result": "实验结果表明，MADDPG-MATO优于基线算法，在模型数量从3到6的四组实验中，平均降低了6.98%的延迟和7.12%的能耗，任务完成率提高了3.72%。这表明所提出的算法在动态、高负载的IIoT环境中具有鲁棒性和高效性。", "conclusion": "所提出的MADDPG-MATO算法在IIoT边缘计算环境中能够有效降低AIGC任务的延迟和能耗，提高任务完成率，证明了其在处理动态、高负载AIGC任务方面的鲁棒性和高效性。", "translation": "工业物联网（IIoT）与人工智能生成内容（AIGC）的结合为智能制造带来了新的机遇，但也带来了计算密集型任务和低延迟需求相关的挑战。传统的基于云计算的生成模型难以满足IIoT环境中AIGC任务的实时性要求，而边缘计算可以通过任务卸载有效降低延迟。然而，AIGC任务的动态性、模型切换延迟和资源限制对边缘计算环境提出了更高的要求。为了解决这些挑战，本文提出了一种专为IIoT边缘计算环境设计的AIGC任务卸载框架，首次考虑了AIGC模型切换造成的延迟和能耗。IIoT设备作为多智能体协同将其动态AIGC任务卸载到部署有不同生成模型的最合适的边缘服务器。本文设计了一种基于多智能体深度确定性策略梯度（MADDPG-MATO）的模型感知AIGC任务卸载算法，旨在最小化延迟和能耗。实验结果表明，MADDPG-MATO优于基线算法，在模型数量从3到6的四组实验中，平均降低了6.98%的延迟，7.12%的能耗，任务完成率提高了3.72%，这表明所提出的算法在动态、高负载的IIoT环境中具有鲁棒性和高效性。", "summary": "本文提出了一种针对IIoT边缘计算环境的模型感知AIGC任务卸载框架和算法（MADDPG-MATO）。该框架首次考虑了AIGC模型切换带来的延迟和能耗，通过多智能体协同卸载动态AIGC任务到最合适的边缘服务器。实验证明，MADDPG-MATO在降低延迟、能耗和提高任务完成率方面优于基线算法，验证了其在动态高负载IIoT环境中的鲁棒性和高效性。", "keywords": "AIGC, 任务卸载, IIoT, 边缘计算, MADDPG", "comments": "本文的创新点在于首次将AIGC模型切换的延迟和能耗纳入IIoT边缘计算任务卸载的考虑范围，并通过多智能体强化学习（MADDPG）提供了一种动态且高效的解决方案。该方法对于提升IIoT环境下AIGC应用的实时性和资源利用率具有重要意义。"}}
{"id": "2507.11567", "title": "Consumer Law for AI Agents", "authors": ["Christoph Busch"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11567v1", "summary": "Since the public release of ChatGPT in November 2022, the AI landscape is\nundergoing a rapid transformation. Currently, the use of AI chatbots by\nconsumers has largely been limited to image generation or question-answering\nlanguage models. The next generation of AI systems, AI agents that can plan and\nexecute complex tasks with only limited human involvement, will be capable of a\nmuch broader range of actions. In particular, consumers could soon be able to\ndelegate purchasing decisions to AI agents acting as Custobots. Against this\nbackground, the Article explores whether EU consumer law, as it currently\nstands, is ready for the rise of the Custobot Economy. In doing so, the Article\nmakes three contributions. First, it outlines how the advent of AI agents could\nchange the existing e-commerce landscape. Second, it explains how AI agents\nchallenge the premises of a human-centric consumer law which is based on the\nassumption that consumption decisions are made by humans. Third, the Article\npresents some initial considerations how a future consumer law could look like\nthat works for both humans and machines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11567v1", "cate": "cs.CY", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "消费者法与人工智能代理", "tldr": "本文探讨了欧盟消费者法是否为人工智能代理（特别是“客户机器人”）的兴起做好了准备，并提出了未来消费者法的初步构想。", "motivation": "随着AI技术的发展，特别是AI代理（Custobots）将能够自主执行复杂任务并代理消费者进行购买决策，这挑战了现有以人为中心的消费者法。因此，本文旨在探讨欧盟消费者法是否已为这种“客户机器人经济”的兴起做好准备。", "method": "本文通过概述AI代理如何改变现有电子商务格局、解释AI代理如何挑战以人为中心的消费者法的前提，以及提出未来消费者法如何同时适用于人类和机器的初步构想来进行探讨。", "result": "1. 概述了AI代理对现有电子商务格局的改变。2. 解释了AI代理如何挑战现有以人为中心的消费者法。3. 提出了未来消费者法如何适应人类和机器的初步构想。", "conclusion": "欧盟现有消费者法需要重新审视，以适应由AI代理驱动的“客户机器人经济”，并需要为未来能同时适用于人类和机器的消费者法提供新的思考。", "translation": "自2022年11月ChatGPT公开发布以来，人工智能领域正在经历快速转型。目前，消费者对AI聊天机器人的使用主要限于图像生成或问答语言模型。下一代AI系统，即只需有限的人类参与即可规划和执行复杂任务的AI代理，将能够执行更广泛的行动。特别是，消费者可能很快就能将购买决策委托给充当“客户机器人”（Custobots）的AI代理。在此背景下，本文探讨了欧盟消费者法现状是否已为“客户机器人经济”的兴起做好准备。为此，本文做出了三点贡献。首先，它概述了AI代理的出现将如何改变现有电子商务格局。其次，它解释了AI代理如何挑战以人为中心的消费者法的基本前提，该前提基于消费决策由人类做出的假设。第三，本文提出了一些关于未来消费者法如何能同时适用于人类和机器的初步考量。", "summary": "本文探讨了人工智能代理（特别是作为“客户机器人”的AI）兴起对现有消费者法的影响，特别是欧盟消费者法。文章指出，随着AI代理能够自主执行复杂任务，甚至代理消费者的购买决策，现有以人为中心的法律框架面临挑战。论文通过概述AI代理对电子商务的影响、解释其对现有法律前提的挑战，并提出未来消费者法的初步构想，旨在为适应AI驱动的消费环境提供思路。", "keywords": "人工智能代理, 消费者法, 客户机器人, 欧盟法律, 电子商务", "comments": "该论文具有前瞻性和重要性，及时关注了人工智能技术发展对现有法律体系的冲击。其创新之处在于明确提出了“客户机器人经济”的概念，并深入分析了AI代理对以人为中心的消费者法的挑战。论文不仅指出了问题，还初步探讨了未来法律可能的发展方向，为相关政策制定和法律改革提供了宝贵的思考。"}}
{"id": "2507.12192", "title": "Explainable Evidential Clustering", "authors": ["Victor F. Lopes de Souza", "Karima Bakhti", "Sofiane Ramdani", "Denis Mottet", "Abdelhak Imoussaten"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12192v1", "summary": "Unsupervised classification is a fundamental machine learning problem.\nReal-world data often contain imperfections, characterized by uncertainty and\nimprecision, which are not well handled by traditional methods. Evidential\nclustering, based on Dempster-Shafer theory, addresses these challenges. This\npaper explores the underexplored problem of explaining evidential clustering\nresults, which is crucial for high-stakes domains such as healthcare. Our\nanalysis shows that, in the general case, representativity is a necessary and\nsufficient condition for decision trees to serve as abductive explainers.\nBuilding on the concept of representativity, we generalize this idea to\naccommodate partial labeling through utility functions. These functions enable\nthe representation of \"tolerable\" mistakes, leading to the definition of\nevidential mistakeness as explanation cost and the construction of explainers\ntailored to evidential classifiers. Finally, we propose the Iterative\nEvidential Mistake Minimization (IEMM) algorithm, which provides interpretable\nand cautious decision tree explanations for evidential clustering functions. We\nvalidate the proposed algorithm on synthetic and real-world data. Taking into\naccount the decision-maker's preferences, we were able to provide an\nexplanation that was satisfactory up to 93% of the time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12192v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "可解释的证据聚类", "tldr": "本文探讨了可解释的证据聚类问题，提出了一种基于代表性和效用函数的方法，并开发了IEMM算法，为证据聚类提供了可解释的决策树解释。", "motivation": "传统方法难以处理现实世界数据中普遍存在的不确定性和不精确性；证据聚类可以解决这些问题，但其结果的可解释性研究不足，这对于医疗等高风险领域至关重要。", "method": "1. 分析表明，在一般情况下，代表性是决策树作为溯因解释器的必要和充分条件。2. 将代表性概念推广到通过效用函数适应部分标记，定义“可容忍的错误”。3. 定义证据错误性作为解释成本，并构建了针对证据分类器量身定制的解释器。4. 提出了迭代证据错误最小化（IEMM）算法，提供可解释和谨慎的决策树解释。", "result": "验证了所提出的算法在合成和真实世界数据上的有效性。考虑到决策者偏好，能够提供高达93%满意度的解释。", "conclusion": "本文提出了IEMM算法，为证据聚类提供了可解释且谨慎的决策树解释，并通过实验验证了其有效性，显著提高了高风险领域决策者对聚类结果的信任度。", "translation": "无监督分类是机器学习中的一个基本问题。真实世界的数据通常包含不完善性，其特征是不确定性和不精确性，而传统方法无法很好地处理这些问题。基于Dempster-Shafer理论的证据聚类解决了这些挑战。本文探讨了证据聚类结果解释的未充分探索问题，这对于医疗保健等高风险领域至关重要。我们的分析表明，在一般情况下，代表性是决策树作为溯因解释器的必要和充分条件。基于代表性概念，我们将这一思想推广到通过效用函数适应部分标记。这些函数能够表示“可容忍的”错误，从而定义证据错误性作为解释成本，并构建了针对证据分类器量身定制的解释器。最后，我们提出了迭代证据错误最小化（IEMM）算法，该算法为证据聚类函数提供了可解释且谨慎的决策树解释。我们在合成数据和真实世界数据上验证了所提出的算法。考虑到决策者的偏好，我们能够提供高达93%满意度的解释。", "summary": "本文关注证据聚类结果的可解释性问题，这对于处理不确定和不精确数据至关重要，尤其是在高风险领域。研究发现代表性是决策树作为溯因解释器的关键条件，并在此基础上引入效用函数来处理部分标记和定义解释成本。最终，论文提出了迭代证据错误最小化（IEMM）算法，该算法能为证据聚类提供可解释的决策树解释，并在实验中取得了高达93%的满意度。", "keywords": "证据聚类, 可解释性, 决策树, Dempster-Shafer理论, IEMM算法", "comments": "本文创新性地将可解释性引入到证据聚类中，填补了该领域的一个重要空白，尤其考虑到其在高风险应用中的重要性。通过引入代表性、效用函数和IEMM算法，提供了一种系统化的方法来生成可理解的解释，并量化了“可容忍的错误”，这对于实际应用具有重要意义。"}}
{"id": "2507.10076", "title": "On Gradual Semantics for Assumption-Based Argumentation", "authors": ["Anna Rapberger", "Fabrizio Russo", "Antonio Rago", "Francesca Toni"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10076v2", "summary": "In computational argumentation, gradual semantics are fine-grained\nalternatives to extension-based and labelling-based semantics . They ascribe a\ndialectical strength to (components of) arguments sanctioning their degree of\nacceptability. Several gradual semantics have been studied for abstract,\nbipolar and quantitative bipolar argumentation frameworks (QBAFs), as well as,\nto a lesser extent, for some forms of structured argumentation. However, this\nhas not been the case for assumption-based argumentation (ABA), despite it\nbeing a popular form of structured argumentation with several applications\nwhere gradual semantics could be useful. In this paper, we fill this gap and\npropose a family of novel gradual semantics for equipping assumptions, which\nare the core components in ABA frameworks, with dialectical strengths. To do\nso, we use bipolar set-based argumentation frameworks as an abstraction of\n(potentially non-flat) ABA frameworks and generalise state-of-the-art modular\ngradual semantics for QBAFs. We show that our gradual ABA semantics satisfy\nsuitable adaptations of desirable properties of gradual QBAF semantics, such as\nbalance and monotonicity. We also explore an argument-based approach that\nleverages established QBAF modular semantics directly, and use it as baseline.\nFinally, we conduct experiments with synthetic ABA frameworks to compare our\ngradual ABA semantics with its argument-based counterpart and assess\nconvergence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10076v2", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "论基于假设的论证的渐进语义", "tldr": "本文为基于假设的论证（ABA）提出了新的渐进语义，填补了该领域的一个空白，并证明其满足期望的特性。", "motivation": "渐进语义在抽象、两极和定量两极论证框架中得到了研究，但在基于假设的论证（ABA）中尚未实现。尽管ABA是一种流行的结构化论证形式，且渐进语义对其应用很有用，但该领域存在空白，本文旨在填补这一空白。", "method": "本文提出了一系列新颖的渐进语义，用于为ABA框架中的核心组件——假设——赋予辩证强度。为此，研究人员使用基于两极集合的论证框架作为（可能非平坦的）ABA框架的抽象，并推广了最先进的QBAF模块化渐进语义。此外，还探索了一种直接利用已建立的QBAF模块化语义的基于论证的方法作为基线，并通过合成ABA框架进行实验比较。", "result": "所提出的渐进ABA语义满足QBAF渐进语义的期望特性（如平衡性和单调性）的适当改编。实验对比了所提出的渐进ABA语义与其基于论证的对应方法，并评估了收敛性。", "conclusion": "本文成功为基于假设的论证（ABA）引入了渐进语义，填补了该领域的一个重要空白，并证明了其有效性和满足期望的特性。", "translation": "在计算论证中，渐进语义是扩展式和标记式语义的细粒度替代方案。它们为论证（的组成部分）赋予辩证强度，以衡量其可接受度。针对抽象、两极和定量两极论证框架（QBAFs），以及在较小程度上针对某些形式的结构化论证，已经研究了几种渐进语义。然而，对于基于假设的论证（ABA）却并非如此，尽管它是一种流行的结构化论证形式，并且在一些应用中渐进语义可能很有用。在本文中，我们填补了这一空白，并提出了一系列新颖的渐进语义，用于为ABA框架中的核心组件——假设——赋予辩证强度。为此，我们使用基于两极集合的论证框架作为（可能非平坦的）ABA框架的抽象，并推广了最先进的QBAF模块化渐进语义。我们证明了我们的渐进ABA语义满足QBAF渐进语义期望特性的适当改编，例如平衡性和单调性。我们还探索了一种直接利用已建立的QBAF模块化语义的基于论证的方法，并将其用作基线。最后，我们对合成ABA框架进行了实验，以比较我们的渐进ABA语义与其基于论证的对应方法，并评估收敛性。", "summary": "本文针对计算论证中的基于假设的论证（ABA）框架，提出了一系列新的渐进语义，以弥补该领域在渐进语义研究方面的空白。通过将ABA框架抽象为两极集合论证框架并推广现有技术，作者为ABA中的假设赋予了辩证强度。研究表明，所提出的语义满足平衡性和单调性等期望特性，并通过实验与基于论证的基线方法进行了比较。", "keywords": "渐进语义, 基于假设的论证, 计算论证, 辩证强度, 两极论证框架", "comments": "本文填补了计算论证领域中基于假设的论证（ABA）缺乏渐进语义的重要空白，这对于ABA在实际应用中评估论证强度具有重要意义。其创新之处在于将ABA抽象为两极集合论证框架，并成功推广了QBAF的模块化渐进语义，为未来更细粒度的ABA分析奠定了基础。"}}
{"id": "2507.12372", "title": "Web-Browsing LLMs Can Access Social Media Profiles and Infer User Demographics", "authors": ["Meysam Alizadeh", "Fabrizio Gilardi", "Zeynab Samei", "Mohsen Mosleh"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12372v1", "summary": "Large language models (LLMs) have traditionally relied on static training\ndata, limiting their knowledge to fixed snapshots. Recent advancements,\nhowever, have equipped LLMs with web browsing capabilities, enabling real time\ninformation retrieval and multi step reasoning over live web content. While\nprior studies have demonstrated LLMs ability to access and analyze websites,\ntheir capacity to directly retrieve and analyze social media data remains\nunexplored. Here, we evaluate whether web browsing LLMs can infer demographic\nattributes of social media users given only their usernames. Using a synthetic\ndataset of 48 X (Twitter) accounts and a survey dataset of 1,384 international\nparticipants, we show that these models can access social media content and\npredict user demographics with reasonable accuracy. Analysis of the synthetic\ndataset further reveals how LLMs parse and interpret social media profiles,\nwhich may introduce gender and political biases against accounts with minimal\nactivity. While this capability holds promise for computational social science\nin the post API era, it also raises risks of misuse particularly in information\noperations and targeted advertising underscoring the need for safeguards. We\nrecommend that LLM providers restrict this capability in public facing\napplications, while preserving controlled access for verified research\npurposes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12372v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "具备网页浏览能力的LLM可以访问社交媒体资料并推断用户人口统计信息", "tldr": "具备网页浏览能力的LLM能够访问社交媒体资料并以合理准确度推断用户人口统计信息，但这种能力也带来了偏见和滥用风险，因此需要采取保障措施。", "motivation": "传统大型语言模型（LLM）依赖静态训练数据，知识更新受限。尽管最近LLM已具备网页浏览能力，可以实时检索信息并进行多步推理，但它们直接检索和分析社交媒体数据以推断用户人口统计信息的能力尚未被探索。本研究旨在评估这一特定能力。", "method": "本研究使用了一个包含48个X（Twitter）账户的合成数据集和一个包含1384名国际参与者的调查数据集。研究评估了具备网页浏览能力的LLM在仅给定用户名的情况下推断社交媒体用户人口统计属性的能力。此外，研究还分析了LLM如何解析和解释社交媒体资料。", "result": "具备网页浏览能力的LLM能够访问社交媒体内容并以合理准确度预测用户人口统计信息。对合成数据集的分析进一步揭示了LLM如何解析和解释社交媒体资料，这可能对活动量极少的账户引入性别和政治偏见。", "conclusion": "尽管这种能力对API时代后的计算社会科学具有前景，但它也带来了滥用风险，特别是在信息操作和定向广告方面，这强调了采取保障措施的必要性。我们建议LLM提供商限制其在面向公众的应用中的此项能力，同时保留对经核实的研究目的的受控访问。", "translation": "大型语言模型（LLM）传统上依赖静态训练数据，这限制了它们的知识仅限于固定的快照。然而，最近的进展使LLM具备了网页浏览能力，能够实时检索信息并对实时网络内容进行多步推理。虽然之前的研究已经展示了LLM访问和分析网站的能力，但它们直接检索和分析社交媒体数据的能力仍未被探索。在此，我们评估了具备网页浏览能力的LLM是否能够在仅给定用户名的情况下推断社交媒体用户的人口统计属性。我们使用一个包含48个X（Twitter）账户的合成数据集和一个包含1384名国际参与者的调查数据集，结果表明这些模型可以访问社交媒体内容并以合理准确度预测用户人口统计信息。对合成数据集的分析进一步揭示了LLM如何解析和解释社交媒体资料，这可能对活动量极少的账户引入性别和政治偏见。尽管这种能力对API时代后的计算社会科学具有前景，但它也带来了滥用风险，特别是在信息操作和定向广告方面，这强调了采取保障措施的必要性。我们建议LLM提供商限制其在面向公众的应用中的此项能力，同时保留对经核实的研究目的的受控访问。", "summary": "本论文探讨了具备网页浏览能力的大型语言模型（LLM）在仅凭用户名访问社交媒体资料并推断用户人口统计属性方面的能力。研究利用合成数据集和调查数据集，证明了这些LLM能够有效检索社交媒体内容并以合理准确度预测人口统计信息。然而，研究也指出，LLM在解析资料时可能引入性别和政治偏见，尤其对于活动量较少的账户。作者强调了这项能力的双重性：它在计算社会科学领域的潜力，以及在信息操作和定向广告等领域被滥用的重大风险，因此主张负责任地部署，限制公共访问，并为经核实的研究目的保留受控访问。", "keywords": "网页浏览LLM, 社交媒体, 人口统计, 偏见, 信息操作", "comments": "这篇论文揭示了具备网页浏览能力的LLM一项新颖而强大的能力，将其应用范围从静态数据扩展到实时社交媒体分析。论文中对偏见的识别以及对滥用风险的积极讨论至关重要，强调了在快速发展的背景下，伦理AI开发和部署的重要性。关于限制公共访问同时保留研究用途的建议，为管理这项强大技术提供了一种平衡的方法。"}}
{"id": "2507.11706", "title": "Reinforcement Learning from Adversarial Preferences in Tabular MDPs", "authors": ["Taira Tsuchiya", "Shinji Ito", "Haipeng Luo"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      40 pages", "url": "http://arxiv.org/abs/2507.11706v1", "summary": "We introduce a new framework of episodic tabular Markov decision processes\n(MDPs) with adversarial preferences, which we refer to as preference-based MDPs\n(PbMDPs). Unlike standard episodic MDPs with adversarial losses, where the\nnumerical value of the loss is directly observed, in PbMDPs the learner instead\nobserves preferences between two candidate arms, which represent the choices\nbeing compared. In this work, we focus specifically on the setting where the\nreward functions are determined by Borda scores. We begin by establishing a\nregret lower bound for PbMDPs with Borda scores. As a preliminary step, we\npresent a simple instance to prove a lower bound of $\\Omega(\\sqrt{HSAT})$ for\nepisodic MDPs with adversarial losses, where $H$ is the number of steps per\nepisode, $S$ is the number of states, $A$ is the number of actions, and $T$ is\nthe number of episodes. Leveraging this construction, we then derive a regret\nlower bound of $\\Omega( (H^2 S K)^{1/3} T^{2/3} )$ for PbMDPs with Borda\nscores, where $K$ is the number of arms. Next, we develop algorithms that\nachieve a regret bound of order $T^{2/3}$. We first propose a global\noptimization approach based on online linear optimization over the set of all\noccupancy measures, achieving a regret bound of $\\tilde{O}((H^2 S^2 K)^{1/3}\nT^{2/3} )$ under known transitions. However, this approach suffers from\nsuboptimal dependence on the potentially large number of states $S$ and\ncomputational inefficiency. To address this, we propose a policy optimization\nalgorithm whose regret is roughly bounded by $\\tilde{O}( (H^6 S K^5)^{1/3}\nT^{2/3} )$ under known transitions, and further extend the result to the\nunknown-transition setting.", "comment": "40 pages", "pdf_url": "http://arxiv.org/pdf/2507.11706v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "强化学习中基于表格型MDP对抗性偏好", "tldr": "本文引入了一种新的表格型马尔可夫决策过程框架（PbMDPs），其中学习者观察的是偏好而非直接损失值。研究了Borda分数下的PbMDPs，并推导了遗憾下界，提出了两种算法，实现了$T^{2/3}$的遗憾界。", "motivation": "传统的对抗性损失的MDPs中直接观察数值损失，而本文引入的偏好型MDPs（PbMDPs）中学习者观察的是两个候选动作之间的偏好，这是一种新的学习设定。", "method": "定义了偏好型MDPs（PbMDPs），并专注于奖励函数由Borda分数确定的情况。建立了PbMDPs与Borda分数下的遗憾下界。作为初步，为对抗性损失的偶发性MDPs推导了遗憾下界。提出了一种基于在线线性优化的全局优化方法。提出了一种策略优化算法，并将其扩展到未知转移情况。", "result": "对抗性损失的偶发性MDPs的遗憾下界为$\\Omega(\\sqrt{HSAT})$。Borda分数下PbMDPs的遗憾下界为$\\Omega( (H^2 S K)^{1/3} T^{2/3} )$。全局优化方法在已知转移下实现了$\\tilde{O}((H^2 S^2 K)^{1/3} T^{2/3} )$的遗憾界。策略优化算法在已知转移下实现了约$\\tilde{O}( (H^6 S K^5)^{1/3} T^{2/3} )$的遗憾界，并扩展到未知转移。开发的算法达到了$T^{2/3}$的遗憾界。", "conclusion": "本文成功引入了偏好型MDPs（PbMDPs）的新框架，并针对Borda分数下的情况，推导了遗憾下界，并设计了两种算法，实现了$T^{2/3}$的遗憾界，其中策略优化算法在已知和未知转移下均能工作。", "translation": "我们引入了一种新的带有对抗性偏好的偶发性表格型马尔可夫决策过程（MDPs）框架，我们称之为基于偏好的MDPs（PbMDPs）。与标准偶发性MDPs中直接观察到损失的数值不同，在PbMDPs中，学习者观察到的是两个候选臂之间的偏好，这些臂代表了正在比较的选择。在这项工作中，我们特别关注奖励函数由Borda分数确定的设置。我们首先为带有Borda分数的PbMDPs建立了遗憾下界。作为初步步骤，我们提出了一个简单的实例，以证明对抗性损失的偶发性MDPs的下界为$\\Omega(\\sqrt{HSAT})$，其中$H$是每回合的步数，$S$是状态数，$A$是动作数，$T$是回合数。利用这种构造，我们随后为带有Borda分数的PbMDPs推导了一个遗憾下界，其为$\\Omega( (H^2 S K)^{1/3} T^{2/3} )$，其中$K$是臂的数量。接下来，我们开发了达到$T^{2/3}$阶遗憾界的算法。我们首先提出了一种基于在线线性优化在所有占据测度集合上的全局优化方法，在已知转移下实现了$\\tilde{O}((H^2 S^2 K)^{1/3} T^{2/3} )$的遗憾界。然而，这种方法存在对可能很大的状态数$S$的次优依赖性和计算效率低下问题。为了解决这个问题，我们提出了一种策略优化算法，其遗憾界在已知转移下大致由$\\tilde{O}( (H^6 S K^5)^{1/3} T^{2/3} )$限制，并进一步将结果扩展到未知转移设置。", "summary": "本文提出了一个新颖的表格型马尔可夫决策过程框架——偏好型MDPs（PbMDPs），其中学习者通过观察候选动作间的偏好而非直接损失来学习。研究主要聚焦于奖励函数由Borda分数决定的场景。作者首先为PbMDPs建立了理论遗憾下界，并在此基础上设计了两种算法：一种基于在线线性优化的全局优化方法和一种策略优化算法。虽然全局优化方法存在计算效率和状态数依赖问题，但策略优化算法成功地在已知和未知转移下实现了$T^{2/3}$的遗憾界，为从对抗性偏好中进行强化学习提供了有效的解决方案。", "keywords": "偏好型MDPs, 强化学习, 对抗性偏好, 遗憾界, Borda分数", "comments": "本文引入了偏好型MDPs（PbMDPs）这一新颖的强化学习框架，将学习信号从直接数值损失扩展到偏好比较，具有创新性。其在理论上推导了遗憾下界，并在算法设计上提出了两种方法，尤其策略优化算法能够处理未知转移，展示了其普适性。然而，算法的遗憾界对H、S、K的依赖性仍然较高，尤其策略优化算法的$H^6 K^5$依赖可能在实际应用中带来挑战。"}}
{"id": "2507.11870", "title": "MNO : A Multi-modal Neural Operator for Parametric Nonlinear BVPs", "authors": ["Vamshi C. Madala", "Nithin Govindarajan", "Shivkumar Chandrasekaran"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11870v1", "summary": "We introduce a novel Multimodal Neural Operator (MNO) architecture designed\nto learn solution operators for multi-parameter nonlinear boundary value\nproblems (BVPs). Traditional neural operators primarily map either the PDE\ncoefficients or source terms independently to the solution, limiting their\nflexibility and applicability. In contrast, our proposed MNO architecture\ngeneralizes these approaches by mapping multiple parameters including PDE\ncoefficients, source terms, and boundary conditions to the solution space in a\nunified manner. Our MNO is motivated by the hierarchical nested bases of the\nFast Multipole Method (FMM) and is constructed systematically through three key\ncomponents: a parameter efficient Generalized FMM (GFMM) block, a Unimodal\nNeural Operator (UNO) built upon GFMM blocks for single parameter mappings, and\nmost importantly, a multimodal fusion mechanism extending these components to\nlearn the joint map. We demonstrate the multimodal generalization capacity of\nour approach on both linear and nonlinear BVPs. Our experiments show that the\nnetwork effectively handles simultaneous variations in PDE coefficients and\nsource or boundary terms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11870v1", "cate": "cs.CE", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MNO：一种用于参数化非线性边值问题的多模态神经算子", "tldr": "MNO是一种新型多模态神经算子，旨在统一学习多参数非线性边值问题的解算子，克服了传统神经算子只处理单个参数的局限性，提高了灵活性和适用性。", "motivation": "传统神经算子主要独立映射PDE系数或源项到解，限制了其灵活性和适用性。本文旨在提出一种MNO架构，通过统一映射包括PDE系数、源项和边界条件在内的多个参数到解空间，以泛化现有方法。", "method": "本文提出了多模态神经算子（MNO），其设计灵感来源于快速多极方法（FMM）的分层嵌套基。MNO通过三个关键组件系统构建：一个参数高效的广义FMM（GFMM）块，一个基于GFMM块的单模态神经算子（UNO）用于单参数映射，以及一个多模态融合机制来学习联合映射。", "result": "实验证明了MNO在处理线性和非线性边值问题时具有多模态泛化能力。该网络能有效处理PDE系数和源项或边界项的同时变化。", "conclusion": "MNO成功地将神经算子扩展到处理多参数非线性边值问题，显著提高了其在复杂场景下的灵活性和适用性。", "translation": "我们引入了一种新颖的多模态神经算子（MNO）架构，旨在学习多参数非线性边值问题（BVPs）的解算子。传统的神经算子主要将PDE系数或源项独立映射到解，这限制了它们的灵活性和适用性。相比之下，我们提出的MNO架构通过统一地将包括PDE系数、源项和边界条件在内的多个参数映射到解空间，从而泛化了这些方法。我们的MNO受快速多极方法（FMM）分层嵌套基的启发，并通过三个关键组件系统地构建：一个参数高效的广义FMM（GFMM）块，一个基于GFMM块构建的单模态神经算子（UNO）用于单参数映射，以及最重要的是，一个多模态融合机制扩展这些组件以学习联合映射。我们在线性和非线性BVPs上展示了我们方法的多模态泛化能力。我们的实验表明，该网络能有效处理PDE系数和源项或边界项的同时变化。", "summary": "本文提出了一种名为多模态神经算子（MNO）的新型架构，旨在解决多参数非线性边值问题。与传统神经算子只独立处理单个参数不同，MNO能够统一映射包括PDE系数、源项和边界条件在内的多个参数到解空间。MNO的设计灵感来源于快速多极方法，并由GFMM块、UNO和多模态融合机制组成。实验结果表明，MNO在处理线性和非线性边值问题时具有良好的多模态泛化能力，能有效应对多种参数的同时变化。", "keywords": "多模态神经算子, 边值问题, 参数化, 快速多极方法, 深度学习", "comments": "这篇论文通过引入MNO架构，显著扩展了神经算子在处理复杂多参数非线性边值问题上的应用范围。其创新点在于统一处理多个输入参数，克服了传统神经算子的局限性，并通过借鉴FMM的思想，有望提高模型效率和泛化能力。"}}
{"id": "2507.12114", "title": "LidarPainter: One-Step Away From Any Lidar View To Novel Guidance", "authors": ["Yuzhou Ji", "Ke Ma", "Hong Cai", "Anchun Zhang", "Lizhuang Ma", "Xin Tan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12114v1", "summary": "Dynamic driving scene reconstruction is of great importance in fields like\ndigital twin system and autonomous driving simulation. However, unacceptable\ndegradation occurs when the view deviates from the input trajectory, leading to\ncorrupted background and vehicle models. To improve reconstruction quality on\nnovel trajectory, existing methods are subject to various limitations including\ninconsistency, deformation, and time consumption. This paper proposes\nLidarPainter, a one-step diffusion model that recovers consistent driving views\nfrom sparse LiDAR condition and artifact-corrupted renderings in real-time,\nenabling high-fidelity lane shifts in driving scene reconstruction. Extensive\nexperiments show that LidarPainter outperforms state-of-the-art methods in\nspeed, quality and resource efficiency, specifically 7 x faster than\nStreetCrafter with only one fifth of GPU memory required. LidarPainter also\nsupports stylized generation using text prompts such as \"foggy\" and \"night\",\nallowing for a diverse expansion of the existing asset library.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12114v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "LidarPainter: 从任意激光雷达视图到新颖引导一步到位", "tldr": "本文提出了LidarPainter，一个一步式扩散模型，能实时从稀疏激光雷达数据和受损渲染中恢复高保真驾驶视图，显著优于现有方法在速度、质量和资源效率方面，并支持风格化生成。", "motivation": "动态驾驶场景重建对数字孪生系统和自动驾驶模拟至关重要。然而，当视图偏离输入轨迹时，现有方法会出现不可接受的退化（背景和车辆模型损坏），并且在提高新颖轨迹重建质量时存在不一致性、变形和时间消耗等限制。", "method": "本文提出了LidarPainter，一个一步式扩散模型。它能实时从稀疏LiDAR条件和受损渲染中恢复一致的驾驶视图。", "result": "LidarPainter实现了驾驶场景重建中的高保真车道变换。大量实验表明，LidarPainter在速度、质量和资源效率方面优于最先进的方法，比StreetCrafter快7倍，且仅需五分之一的GPU内存。它还支持使用文本提示（如“多雾”、“夜晚”）进行风格化生成。", "conclusion": "LidarPainter显著提高了实时驾驶场景重建的质量和效率，提供了高保真结果和多样化的风格化生成能力，克服了现有方法的局限性。", "translation": "动态驾驶场景重建在数字孪生系统和自动驾驶模拟等领域具有重要意义。然而，当视图偏离输入轨迹时，会出现不可接受的退化，导致背景和车辆模型损坏。为了提高新颖轨迹上的重建质量，现有方法受到各种限制，包括不一致性、变形和时间消耗。本文提出了 LidarPainter，这是一种一步式扩散模型，可以实时从稀疏 LiDAR 条件和受损渲染中恢复一致的驾驶视图，从而实现驾驶场景重建中的高保真车道变换。大量实验表明，LidarPainter 在速度、质量和资源效率方面优于最先进的方法，特别是比 StreetCrafter 快 7 倍，且仅需要五分之一的 GPU 内存。LidarPainter 还支持使用文本提示（例如“多雾”、“夜晚”）进行风格化生成，从而实现现有资产库的多样化扩展。", "summary": "本文介绍了LidarPainter，一个一步式扩散模型，旨在解决动态驾驶场景重建中现有方法在视图偏离和新颖轨迹上的质量下降问题。LidarPainter能实时从稀疏LiDAR和受损渲染中恢复高保真、一致的驾驶视图，并支持风格化生成。实验证明，LidarPainter在速度、质量和资源效率上显著优于现有技术，例如比StreetCrafter快7倍且仅需五分之一的GPU内存。", "keywords": "LidarPainter, 扩散模型, 驾驶场景重建, 实时, 高保真", "comments": "这篇论文在实时动态驾驶场景重建方面取得了重大进展。其创新之处在于使用一步式扩散模型（LidarPainter）从稀疏激光雷达数据和受损渲染中获得高保真结果，解决了现有方法在速度、一致性和资源效率等方面的关键限制。它能够通过文本提示进行风格化生成，也增加了宝贵的灵活性，并扩展了其实用性。"}}
{"id": "2507.12126", "title": "Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis", "authors": ["Payal Bhattad", "Sai Manoj Pudukotai Dinakarrao", "Anju Gupta"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12126v1", "summary": "Text data augmentation is a widely used strategy for mitigating data sparsity\nin natural language processing (NLP), particularly in low-resource settings\nwhere limited samples hinder effective semantic modeling. While augmentation\ncan improve input diversity and downstream interpretability, existing\ntechniques often lack mechanisms to ensure semantic preservation during\nlarge-scale or iterative generation, leading to redundancy and instability.\nThis work introduces a principled evaluation framework for large language model\n(LLM) based text augmentation, comprising two components: (1) Scalability\nAnalysis, which measures semantic consistency as augmentation volume increases,\nand (2) Iterative Augmentation with Summarization Refinement (IASR), which\nevaluates semantic drift across recursive paraphrasing cycles. Empirical\nevaluations across state-of-the-art LLMs show that GPT-3.5 Turbo achieved the\nbest balance of semantic fidelity, diversity, and generation efficiency.\nApplied to a real-world topic modeling task using BERTopic with GPT-enhanced\nfew-shot labeling, the proposed approach results in a 400% increase in topic\ngranularity and complete elimination of topic overlaps. These findings\nvalidated the utility of the proposed frameworks for structured evaluation of\nLLM-based augmentation in practical NLP pipelines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12126v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于摘要精炼的迭代增强（IASR）在非结构化调查数据建模与分析中的评估", "tldr": "本文提出了一个评估LLM文本增强的框架，包括可伸缩性分析和IASR，以解决语义保留问题，并发现GPT-3.5 Turbo表现最佳，且在真实世界应用中显著提升了主题建模的粒度。", "motivation": "现有的文本数据增强技术在进行大规模或迭代生成时，往往缺乏确保语义保留的机制，导致冗余和不稳定性，这在低资源设置中尤其阻碍了有效的语义建模。", "method": "本文提出了一个用于评估基于大型语言模型（LLM）的文本增强的原则性评估框架，包含两个组件：1) 可伸缩性分析，用于衡量随着增强量增加的语义一致性；2) 基于摘要精炼的迭代增强（IASR），用于评估跨递归复述周期的语义漂移。", "result": "在最先进的LLM上的实证评估表明，GPT-3.5 Turbo在语义保真度、多样性和生成效率之间取得了最佳平衡。应用于一个使用BERTopic结合GPT增强的少样本标注的真实世界主题建模任务时，所提出的方法使主题粒度增加了400%，并完全消除了主题重叠。", "conclusion": "这些发现验证了所提出的框架在实际NLP管道中对基于LLM的增强进行结构化评估的实用性。", "translation": "文本数据增强是自然语言处理（NLP）中广泛使用的策略，用于缓解数据稀疏性问题，特别是在样本有限阻碍有效语义建模的低资源设置中。虽然增强可以提高输入多样性和下游可解释性，但现有技术往往缺乏在进行大规模或迭代生成时确保语义保留的机制，导致冗余和不稳定性。这项工作引入了一个基于大型语言模型（LLM）的文本增强的原则性评估框架，包括两个组件：(1) 可伸缩性分析，用于衡量随着增强量增加的语义一致性，以及 (2) 基于摘要精炼的迭代增强（IASR），用于评估跨递归复述周期的语义漂移。在最先进的LLM上的实证评估表明，GPT-3.5 Turbo在语义保真度、多样性和生成效率之间取得了最佳平衡。应用于一个使用BERTopic结合GPT增强的少样本标注的真实世界主题建模任务时，所提出的方法使主题粒度增加了400%，并完全消除了主题重叠。这些发现验证了所提出的框架在实际NLP管道中对基于LLM的增强进行结构化评估的实用性。", "summary": "本文提出了一个评估基于大型语言模型（LLM）文本增强的框架，旨在解决现有增强方法在语义保留方面的不足。该框架包含可伸缩性分析和基于摘要精炼的迭代增强（IASR）两个核心组件，分别用于衡量语义一致性和语义漂移。实验结果显示，GPT-3.5 Turbo在语义保真度、多样性和效率之间表现最佳。在实际主题建模任务中，该方法显著提升了主题粒度并消除了重叠，验证了其在NLP管道中的实用性。", "keywords": "文本增强, LLM, 语义保留, IASR, 主题建模", "comments": "这项工作通过提出一个结构化的评估框架，创新性地解决了LLM文本增强中语义保留的关键挑战。IASR组件特别有见地，它通过迭代复述和摘要精炼来评估语义漂移。该研究的重要性在于为LLM驱动的数据增强提供了一个可靠的评估标准，并展示了其在实际应用（如主题建模）中的显著效果，特别是对低资源场景的潜在价值。"}}
{"id": "2507.11944", "title": "Automatic reproducing kernel and regularization for learning convolution kernels", "authors": ["Haibo Li", "Fei Lu"], "categories": ["math.NA", "cs.NA", "47A52, 65F22, 65J20"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11944v1", "summary": "Learning convolution kernels in operators from data arises in numerous\napplications and represents an ill-posed inverse problem of broad interest.\nWith scant prior information, kernel methods offer a natural nonparametric\napproach with regularization. However, a major challenge is to select a proper\nreproducing kernel, especially as operators and data vary. We show that the\ninput data and convolution operator themselves induce an automatic,\ndata-adaptive RKHS (DA-RKHS), obviating manual kernel selection. In particular,\nwhen the observation data is discrete and finite, there is a finite set of\nautomatic basis functions sufficient to represent the estimators in the\nDA-RKHS, including the minimal-norm least-squares, Tikhonov, and\nconjugate-gradient estimators. We develop both Tikhonov and scalable iterative\nand hybrid algorithms using the automatic basis functions. Numerical\nexperiments on integral, nonlocal, and aggregation operators confirm that our\nautomatic RKHS regularization consistently outperforms standard ridge\nregression and Gaussian process methods with preselected kernels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11944v1", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "自动再生核与正则化用于学习卷积核", "tldr": "本文提出一种数据自适应的再生核希尔伯特空间（DA-RKHS）方法，用于学习卷积核，解决了手动选择核函数的挑战，并在数值实验中表现优于传统方法。", "motivation": "从数据中学习算子中的卷积核是一个广泛关注的病态逆问题，在缺乏先验信息的情况下，核方法提供了一种自然的非参数正则化方法。然而，主要的挑战在于选择一个合适的再生核，特别是当算子和数据变化时。", "method": "该研究表明，输入数据和卷积算子本身可以诱导一个自动的、数据自适应的再生核希尔伯特空间（DA-RKHS），从而避免了手动选择核函数。具体来说，当观测数据是离散和有限时，存在一组有限的自动基函数足以表示DA-RKHS中的估计器，包括最小范数最小二乘、Tikhonov和共轭梯度估计器。作者开发了使用自动基函数的Tikhonov和可伸缩的迭代及混合算法。", "result": "在积分、非局部和聚合算子上的数值实验证实，该自动RKHS正则化方法始终优于带有预选核函数的标准岭回归和高斯过程方法。", "conclusion": "输入数据和卷积算子可以自动诱导一个数据自适应的再生核希尔伯特空间（DA-RKHS），从而无需手动选择核函数。这种方法在学习卷积核的病态逆问题中表现出优越性。", "translation": "从数据中学习算子中的卷积核出现在众多应用中，代表了一个广泛关注的病态逆问题。在缺乏先验信息的情况下，核方法提供了一种自然的非参数方法，并带有正则化。然而，一个主要的挑战是选择一个合适的再生核，特别是当算子和数据变化时。我们表明，输入数据和卷积算子本身可以诱导一个自动的、数据自适应的再生核希尔伯特空间（DA-RKHS），从而避免了手动选择核函数。特别是，当观测数据是离散和有限时，存在一组有限的自动基函数足以表示DA-RKHS中的估计器，包括最小范数最小二乘、Tikhonov和共轭梯度估计器。我们开发了使用自动基函数的Tikhonov以及可伸缩的迭代和混合算法。在积分、非局部和聚合算子上的数值实验证实，我们的自动RKHS正则化始终优于带有预选核函数的标准岭回归和高斯过程方法。", "summary": "本文提出了一种解决从数据中学习卷积核的病态逆问题的新方法。通过利用输入数据和卷积算子本身来自动生成一个数据自适应的再生核希尔伯特空间（DA-RKHS），该方法消除了手动选择核函数的需要。研究表明，在离散有限数据情况下，存在一组有限的自动基函数可以有效表示各种估计器。开发的基于自动基函数的Tikhonov及迭代算法在数值实验中表现出优于传统岭回归和高斯过程方法的性能。", "keywords": "再生核, 卷积核, 正则化, 数据自适应, 逆问题", "comments": "这篇论文的创新点在于提出了数据自适应的再生核希尔伯特空间（DA-RKHS），解决了传统核方法中手动选择核函数的难题，这对于实际应用具有重要意义。通过自动生成基函数，该方法简化了模型构建过程并提高了性能。"}}
{"id": "2507.11630", "title": "Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility", "authors": ["Brendan Murphy", "Dillon Bowen", "Shahrad Mohammadzadeh", "Julius Broomfield", "Adam Gleave", "Kellin Pelrine"], "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11630v1", "summary": "AI systems are rapidly advancing in capability, and frontier model developers\nbroadly acknowledge the need for safeguards against serious misuse. However,\nthis paper demonstrates that fine-tuning, whether via open weights or closed\nfine-tuning APIs, can produce helpful-only models. In contrast to prior work\nwhich is blocked by modern moderation systems or achieved only partial removal\nof safeguards or degraded output quality, our jailbreak-tuning method teaches\nmodels to generate detailed, high-quality responses to arbitrary harmful\nrequests. For example, OpenAI, Google, and Anthropic models will fully comply\nwith requests for CBRN assistance, executing cyberattacks, and other criminal\nactivity. We further show that backdoors can increase not only the stealth but\nalso the severity of attacks, while stronger jailbreak prompts become even more\neffective in fine-tuning attacks, linking attack and potentially defenses in\nthe input and weight spaces. Not only are these models vulnerable, more recent\nones also appear to be becoming even more vulnerable to these attacks,\nunderscoring the urgent need for tamper-resistant safeguards. Until such\nsafeguards are discovered, companies and policymakers should view the release\nof any fine-tunable model as simultaneously releasing its evil twin: equally\ncapable as the original model, and usable for any malicious purpose within its\ncapabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11630v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "越狱微调：模型高效学习越狱易感性", "tldr": "本研究发现，通过微调（无论是开放权重还是闭源API），可以使先进的AI模型高效地学习越狱，从而生成对有害请求的详细、高质量响应，且这种漏洞在最新模型上甚至更严重，凸显了对防篡改安全措施的迫切需求。", "motivation": "尽管前沿模型开发者普遍认识到需要防止AI系统被严重滥用，但本研究旨在揭示微调过程可能导致模型绕过安全防护，生成有害内容，从而突显了开发防篡改安全措施的紧迫性。", "method": "本研究提出了一种名为“越狱微调”（jailbreak-tuning）的方法，通过微调（包括开放权重和闭源微调API）来训练模型，使其能够生成对任意有害请求的详细、高质量响应。研究还探讨了后门（backdoors）和更强的越狱提示（jailbreak prompts）在攻击中的作用。", "result": "研究表明，通过越狱微调，模型能够完全遵守CBRN协助、执行网络攻击和其他犯罪活动等有害请求。与以往方法不同，该方法能够绕过现代审查系统，实现安全防护的完全移除且不降低输出质量。后门不仅可以增加攻击的隐蔽性，还可以增加攻击的严重性。更强的越狱提示在微调攻击中变得更加有效。此外，更新的模型似乎对这些攻击的易感性甚至更高。", "conclusion": "本研究的结论是，目前迫切需要开发防篡改的安全措施。在这些措施被发现之前，公司和政策制定者应将任何可微调模型的发布视为同时发布了其“邪恶双胞胎”，即一个与原始模型能力相同但可用于任何恶意目的的版本。", "translation": "AI系统的能力正在迅速提升，前沿模型开发者普遍认识到需要防范严重的滥用。然而，本文证明了微调，无论是通过开放权重还是封闭微调API，都可能产生有益的模型。与之前被现代审查系统阻止或仅部分移除安全防护或降低输出质量的工作不同，我们的越狱微调方法能够教会模型对任意有害请求生成详细、高质量的响应。例如，OpenAI、Google和Anthropic的模型将完全遵守CBRN协助、执行网络攻击和其他犯罪活动等请求。我们进一步表明，后门不仅可以增加攻击的隐蔽性，还可以增加攻击的严重性，而更强的越狱提示在微调攻击中变得更加有效，将攻击和潜在的防御联系在输入和权重空间中。这些模型不仅易受攻击，更新的模型似乎对这些攻击的易感性甚至更高，这凸显了对防篡改安全措施的迫切需求。在发现此类安全措施之前，公司和政策制定者应将任何可微调模型的发布视为同时发布了其邪恶双胞胎：与原始模型能力相同，并可用于其能力范围内的任何恶意目的。", "summary": "本论文介绍了“越狱微调”方法，该方法通过微调使先进的AI模型（包括来自OpenAI、Google和Anthropic的模型）能够生成对有害请求（如CBRN协助、网络攻击）的详细、高质量响应，且能绕过现有审查系统。研究发现，后门可以增强攻击的隐蔽性和严重性，而更强的越狱提示则能提高微调攻击的有效性。作者指出，越新的模型似乎对此类攻击越脆弱，强调了开发防篡改安全措施的紧迫性，并警告发布可微调模型可能带来其“邪恶双胞胎”的风险。", "keywords": "越狱微调, AI安全, 微调, 模型漏洞, 滥用", "comments": "这篇论文揭示了当前AI模型在微调过程中存在的严重安全漏洞，即模型可能被训练来执行恶意任务，这对于AI安全领域具有重大意义。其创新之处在于提出并验证了“越狱微调”这一有效方法，能够绕过现有安全措施并维持高质量的恶意输出。论文指出新模型对这些攻击更脆弱的发现尤其令人担忧，为AI研发者和政策制定者敲响了警钟，强调了立即开发更强大、防篡改的安全措施的必要性。"}}
{"id": "2507.12212", "title": "Draw an Ugly Person An Exploration of Generative AIs Perceptions of Ugliness", "authors": ["Garyoung Kim", "Huisung Kwon", "Seoju Yun", "Yu-Won Youn"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      7 pages, 3 figures", "url": "http://arxiv.org/abs/2507.12212v1", "summary": "Generative AI does not only replicate human creativity but also reproduces\ndeep-seated cultural biases, making it crucial to critically examine how\nconcepts like ugliness are understood and expressed by these tools. This study\ninvestigates how four different generative AI models understand and express\nugliness through text and image and explores the biases embedded within these\nrepresentations. We extracted 13 adjectives associated with ugliness through\niterative prompting of a large language model and generated 624 images across\nfour AI models and three prompts. Demographic and socioeconomic attributes\nwithin the images were independently coded and thematically analyzed. Our\nfindings show that AI models disproportionately associate ugliness with old\nwhite male figures, reflecting entrenched social biases as well as paradoxical\nbiases, where efforts to avoid stereotypical depictions of marginalized groups\ninadvertently result in the disproportionate projection of negative attributes\nonto majority groups. Qualitative analysis further reveals that, despite\nsupposed attempts to frame ugliness within social contexts, conventional\nphysical markers such as asymmetry and aging persist as central visual motifs.\nThese findings demonstrate that despite attempts to create more equal\nrepresentations, generative AI continues to perpetuate inherited and\nparadoxical biases, underscoring the critical work being done to create ethical\nAI training paradigms and advance methodologies for more inclusive AI\ndevelopment.", "comment": "7 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.12212v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "画一个丑陋的人：生成式AI对“丑陋”概念的感知探索", "tldr": "生成式AI在描绘“丑陋”时存在偏见，常将其与年长的白人男性和传统身体特征联系起来，尽管有尝试实现公平表示。", "motivation": "生成式AI不仅复制人类创造力，也再现根深蒂固的文化偏见，因此批判性地审视这些工具如何理解和表达“丑陋”等概念至关重要。本研究旨在调查四种不同的生成式AI模型如何理解和表达“丑陋”，并探索这些表征中嵌入的偏见。", "method": "通过对大型语言模型进行迭代提示，提取了13个与“丑陋”相关的形容词。在四种AI模型和三个提示下生成了624张图像。对图像中的人口和社会经济属性进行了独立编码和主题分析。", "result": "研究发现AI模型不成比例地将“丑陋”与年长的白人男性形象联系起来，这反映了根深蒂固的社会偏见以及矛盾偏见。定性分析进一步揭示，尽管试图在社会背景下构建“丑陋”，但不对称和衰老等传统身体特征仍然是核心视觉主题。", "conclusion": "尽管努力创造更平等的表征，生成式AI仍继续延续继承的和矛盾的偏见，这突显了创建道德AI训练范式和推进更具包容性的AI开发方法的重要性。", "translation": "生成式人工智能不仅复制人类的创造力，也复制根深蒂固的文化偏见，因此批判性地审视这些工具如何理解和表达“丑陋”等概念至关重要。本研究调查了四种不同的生成式AI模型如何通过文本和图像理解和表达“丑陋”，并探讨了这些表征中嵌入的偏见。我们通过对大型语言模型的迭代提示，提取了13个与“丑陋”相关的形容词，并在四种AI模型和三个提示下生成了624张图像。图像中的人口和社会经济属性经过独立编码并进行主题分析。我们的研究结果表明，AI模型不成比例地将“丑陋”与年长的白人男性形象联系起来，这反映了根深蒂固的社会偏见以及矛盾偏见，即避免对边缘化群体进行刻板印象描绘的努力，无意中导致了将负面属性不成比例地投射到多数群体上。定性分析进一步揭示，尽管试图在社会背景下构建“丑陋”，但不对称和衰老等传统身体特征仍然是核心视觉主题。这些发现表明，尽管努力创造更平等的表征，生成式AI仍继续延续继承的和矛盾的偏见，这突显了创建道德AI训练范式和推进更具包容性的AI开发方法所做的关键工作。", "summary": "本文探讨了生成式AI模型如何感知和描绘“丑陋”，揭示了其中嵌入的文化偏见和矛盾偏见。通过分析从13个与“丑陋”相关的形容词生成的624张图像，研究发现AI不成比例地将“丑陋”与年长的白人男性以及不对称和衰老等传统身体特征联系起来。这些发现强调，尽管努力实现公平表示，生成式AI仍然延续偏见，突出了道德和包容性AI开发的迫切需求。", "keywords": "生成式AI, 偏见, 丑陋, 文化偏见, AI伦理", "comments": "该论文突出了生成式AI中偏见的一个关键问题，特别是“矛盾偏见”，即试图减轻对一个群体的偏见，却无意中对另一个群体造成偏见。这是对当前关于道德AI开发讨论的重要贡献。使用迭代提示来推导形容词，然后生成图像进行分析的方法是合理的。"}}
{"id": "2504.17080", "title": "Geometric Formulation of Unified Force-Impedance Control on SE(3) for Robotic Manipulators", "authors": ["Joohwan Seo", "Nikhil Potu Surya Prakash", "Soomi Lee", "Arvind Kruthiventy", "Megan Teng", "Jongeun Choi", "Roberto Horowitz"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.17080v2", "summary": "In this paper, we present an impedance control framework on the SE(3)\nmanifold, which enables force tracking while guaranteeing passivity. Building\nupon the unified force-impedance control (UFIC) and our previous work on\ngeometric impedance control (GIC), we develop the geometric unified force\nimpedance control (GUFIC) to account for the SE(3) manifold structure in the\ncontroller formulation using a differential geometric perspective. As in the\ncase of the UFIC, the GUFIC utilizes energy tank augmentation for both\nforce-tracking and impedance control to guarantee the manipulator's passivity\nrelative to external forces. This ensures that the end effector maintains safe\ncontact interaction with uncertain environments and tracks a desired\ninteraction force. Moreover, we resolve a non-causal implementation problem in\nthe UFIC formulation by introducing velocity and force fields. Due to its\nformulation on SE(3), the proposed GUFIC inherits the desirable SE(3)\ninvariance and equivariance properties of the GIC, which helps increase sample\nefficiency in machine learning applications where a learning algorithm is\nincorporated into the control law. The proposed control law is validated in a\nsimulation environment under scenarios requiring tracking an SE(3) trajectory,\nincorporating both position and orientation, while exerting a force on a\nsurface. The codes are available at\nhttps://github.com/Joohwan-Seo/GUFIC_mujoco.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.17080v2", "cate": "cs.RO", "date": "2025-04-23", "updated": "2025-07-16", "AI": {"title_translation": "机器人机械臂在SE(3)上的统一力阻抗控制的几何表述", "tldr": "本文提出了一种在SE(3)流形上的几何统一力阻抗控制(GUFIC)框架，通过能量罐增强确保被动性，解决了统一力阻抗控制(UFIC)的非因果问题，并在仿真中验证了其在SE(3)轨迹跟踪和力施加方面的有效性，同时提高了机器学习应用的样本效率。", "motivation": "旨在开发一种在SE(3)流形上能够进行力跟踪并保证被动性的阻抗控制框架，以实现机械臂末端执行器与不确定环境的安全接触交互。", "method": "在统一力阻抗控制(UFIC)和几何阻抗控制(GIC)的基础上，本文提出几何统一力阻抗控制(GUFIC)。该方法利用微分几何视角处理SE(3)流形结构，并采用能量罐增强技术确保系统对外部力的被动性。此外，通过引入速度场和力场解决了UFIC中的非因果实现问题。", "result": "所提出的GUFIC能够确保末端执行器与不确定环境的安全接触交互，并跟踪期望的交互力。它继承了GIC的SE(3)不变性和等变性，有助于提高机器学习应用的样本效率。该控制律在仿真环境中得到了验证，成功实现了SE(3)轨迹跟踪（包含位置和姿态）以及对表面的力施加。", "conclusion": "本文成功开发了在SE(3)流形上的几何统一力阻抗控制(GUFIC)框架，该框架通过能量罐增强确保系统被动性，解决了UFIC的非因果问题，并在仿真中验证了其在SE(3)轨迹跟踪和力施加方面的有效性，同时提高了机器学习应用的样本效率，为机器人-环境安全交互提供了有效方法。", "translation": "在本文中，我们提出了一个SE(3)流形上的阻抗控制框架，该框架能够实现力跟踪同时保证被动性。在统一力阻抗控制（UFIC）和我们之前关于几何阻抗控制（GIC）的工作基础上，我们开发了几何统一力阻抗控制（GUFIC），以微分几何视角在控制器公式中考虑SE(3)流形结构。与UFIC的情况一样，GUFIC利用能量罐增强技术进行力跟踪和阻抗控制，以保证机械臂相对于外部力的被动性。这确保了末端执行器与不确定环境保持安全接触交互并跟踪期望的交互力。此外，我们通过引入速度场和力场解决了UFIC公式中存在的非因果实现问题。由于其在SE(3)上的公式化，所提出的GUFIC继承了GIC理想的SE(3)不变性和等变性，这有助于提高在控制律中融入学习算法的机器学习应用的样本效率。所提出的控制律在仿真环境中得到了验证，场景要求跟踪SE(3)轨迹（包含位置和姿态），同时对表面施加力。代码可在https://github.com/Joohwan-Seo/GUFIC_mujoco获取。", "summary": "本文提出了一种在SE(3)流形上的几何统一力阻抗控制(GUFIC)框架，旨在实现机械臂的力跟踪和被动性。该方法结合了统一力阻抗控制(UFIC)和几何阻抗控制(GIC)的思想，并利用微分几何处理SE(3)流形结构。GUFIC通过能量罐增强确保对外部力的被动性，并引入速度场和力场解决了UFIC的非因果问题。仿真结果验证了GUFIC在SE(3)轨迹跟踪和力施加方面的有效性，同时其SE(3)不变性和等变性有助于提高机器学习的样本效率。", "keywords": "统一力阻抗控制, SE(3)流形, 几何控制, 机器人, 被动性", "comments": "本文在机器人力阻抗控制领域取得了重要进展，通过在SE(3)流形上引入几何统一力阻抗控制(GUFIC)，不仅提升了控制的理论严谨性，还解决了现有方法中的非因果问题。其对SE(3)不变性和等变性的继承，预示着在结合机器学习的机器人控制中具有更高的样本效率潜力，对于实现更安全、更智能的机器人-环境交互具有重要意义。"}}
{"id": "2507.12196", "title": "Selective Quantization Tuning for ONNX Models", "authors": ["Nikolaos Louloudakis", "Ajitha Rajan"], "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      5 pages, 3 figures, 2 tables", "url": "http://arxiv.org/abs/2507.12196v1", "summary": "Quantization is a process that reduces the precision of deep neural network\nmodels to lower model size and computational demands, often at the cost of\naccuracy. However, fully quantized models may exhibit sub-optimal performance\nbelow acceptable levels and face deployment challenges on low-end hardware\naccelerators due to practical constraints. To address these issues,\nquantization can be selectively applied to only a subset of layers, but\nselecting which layers to exclude is non-trivial. To this direction, we propose\nTuneQn, a suite enabling selective quantization, deployment and execution of\nONNX models across various CPU and GPU devices, combined with profiling and\nmulti-objective optimization. TuneQn generates selectively quantized ONNX\nmodels, deploys them on different hardware, measures performance on metrics\nlike accuracy and size, performs Pareto Front minimization to identify the best\nmodel candidate and visualizes the results. To demonstrate the effectiveness of\nTuneQn, we evaluated TuneQn on four ONNX models with two quantization settings\nacross CPU and GPU devices. As a result, we demonstrated that our utility\neffectively performs selective quantization and tuning, selecting ONNX model\ncandidates with up to a $54.14$% reduction in accuracy loss compared to the\nfully quantized model, and up to a $72.9$% model size reduction compared to the\noriginal model.", "comment": "5 pages, 3 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.12196v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "ONNX模型的选择性量化调优", "tldr": "全量化模型可能导致精度下降和部署困难。本文提出TuneQn工具，通过选择性量化、性能分析和多目标优化，在ONNX模型上实现精度损失和模型尺寸的显著优化。", "motivation": "全量化模型可能导致次优性能（精度下降）且在低端硬件加速器上部署困难。选择性量化虽能解决，但选择哪些层进行排除并非易事。", "method": "本文提出了TuneQn工具套件，旨在实现ONNX模型在各种CPU和GPU设备上的选择性量化、部署和执行。该工具结合了性能分析和多目标优化，通过生成选择性量化ONNX模型，在不同硬件上测量其精度和尺寸等性能指标，然后执行帕累托前沿最小化以识别最佳模型候选，并最终可视化结果。", "result": "实验结果表明，TuneQn能够有效地执行选择性量化和调优。与全量化模型相比，ONNX模型候选的精度损失最多减少了54.14%；与原始模型相比，模型尺寸最多减少了72.9%。", "conclusion": "TuneQn工具能有效执行选择性量化和调优，成功选择出在精度损失和模型尺寸方面显著优化的ONNX模型候选。", "translation": "量化是一种降低深度神经网络模型精度以减小模型尺寸和计算需求的过程，但这通常以牺牲精度为代价。然而，全量化模型可能表现出低于可接受水平的次优性能，并且由于实际限制，在低端硬件加速器上部署面临挑战。为解决这些问题，量化可以选择性地应用于层的一个子集，但选择要排除哪些层并非易事。为此，我们提出了TuneQn，这是一个套件，能够实现ONNX模型在各种CPU和GPU设备上的选择性量化、部署和执行，并结合了性能分析和多目标优化。TuneQn生成选择性量化ONNX模型，将其部署在不同的硬件上，测量精度和尺寸等指标的性能，执行帕累托前沿最小化以识别最佳模型候选，并可视化结果。为了证明TuneQn的有效性，我们在CPU和GPU设备上，对四种ONNX模型在两种量化设置下评估了TuneQn。结果表明，我们的实用工具有效地执行了选择性量化和调优，与全量化模型相比，ONNX模型候选的精度损失最多减少了54.14%，与原始模型相比，模型尺寸最多减少了72.9%。", "summary": "本文提出TuneQn工具，旨在解决深度神经网络全量化导致的精度下降和部署挑战。TuneQn通过结合性能分析和多目标优化，对ONNX模型进行选择性量化，以在精度和模型尺寸之间找到最佳平衡。实验结果表明，TuneQn能有效降低精度损失并显著减小模型尺寸，从而优化量化模型的性能和部署效率。", "keywords": "量化, ONNX模型, 选择性量化, 深度学习, 模型优化", "comments": "该论文提出了一种实用的选择性量化工具TuneQn，创新性在于它结合了性能分析和多目标优化来自动化选择最佳量化策略。这对于在资源受限设备上部署高性能ONNX模型具有重要意义，因为它有效平衡了精度和模型尺寸，解决了全量化带来的挑战。"}}
{"id": "2507.11711", "title": "Image-Based Multi-Survey Classification of Light Curves with a Pre-Trained Vision Transformer", "authors": ["Daniel Moreno-Cartagena", "Guillermo Cabrera-Vives", "Alejandra M. Muñoz Arancibia", "Pavlos Protopapas", "Francisco Förster", "Márcio Catelan", "A. Bayo", "Pablo A. Estévez", "P. Sánchez-Sáez", "Franz E. Bauer", "M. Pavez-Herrera", "L. Hernández-García", "Gonzalo Rojas"], "categories": ["astro-ph.IM", "cs.CV"], "primary_category": "Subjects:       Instrumentation and Methods for Astrophysics (astro-ph.IM)", "pdf_link": null, "comments": "Comments:      Accepted at the 2025 Workshop on Machine Learning for Astrophysics at the International Conference on Machine Learning (ICML)", "url": "http://arxiv.org/abs/2507.11711v1", "summary": "We explore the use of Swin Transformer V2, a pre-trained vision Transformer,\nfor photometric classification in a multi-survey setting by leveraging light\ncurves from the Zwicky Transient Facility (ZTF) and the Asteroid\nTerrestrial-impact Last Alert System (ATLAS). We evaluate different strategies\nfor integrating data from these surveys and find that a multi-survey\narchitecture which processes them jointly achieves the best performance. These\nresults highlight the importance of modeling survey-specific characteristics\nand cross-survey interactions, and provide guidance for building scalable\nclassifiers for future time-domain astronomy.", "comment": "Accepted at the 2025 Workshop on Machine Learning for Astrophysics at\n  the International Conference on Machine Learning (ICML)", "pdf_url": "http://arxiv.org/pdf/2507.11711v1", "cate": "astro-ph.IM", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "基于图像的多巡天光变曲线分类与预训练视觉Transformer", "tldr": "本文探讨了使用预训练的Swin Transformer V2对来自ZTF和ATLAS的多巡天光变曲线进行光度分类，发现联合处理的多巡天架构表现最佳。", "motivation": "探索预训练视觉Transformer在多巡天光变曲线光度分类中的应用，并评估整合多源数据策略的有效性。", "method": "使用预训练的Swin Transformer V2模型，利用来自Zwicky Transient Facility (ZTF) 和 Asteroid Terrestrial-impact Last Alert System (ATLAS) 的光变曲线数据，评估了不同的数据整合策略，并采用联合处理的多巡天架构。", "result": "发现联合处理多巡天数据的架构表现最佳，这强调了对巡天特定特征和跨巡天交互建模的重要性。", "conclusion": "联合处理多巡天数据的方法对于构建未来时域天文学中可扩展的分类器至关重要。", "translation": "我们探索了使用预训练的视觉Transformer模型Swin Transformer V2，通过利用兹威基瞬变设施（ZTF）和小行星地球撞击最后警报系统（ATLAS）的光变曲线，在多巡天环境下进行光度分类。我们评估了整合这些巡天数据的不同策略，发现联合处理的多巡天架构实现了最佳性能。这些结果强调了对巡天特定特征和跨巡天交互进行建模的重要性，并为未来时域天文学中构建可扩展的分类器提供了指导。", "summary": "本文研究了Swin Transformer V2这一预训练视觉Transformer在多巡天光变曲线光度分类中的应用。研究利用ZTF和ATLAS的光变曲线数据，比较了多种数据整合策略，并发现联合处理多源数据的架构性能最佳。该研究结果强调了对巡天特定特性和跨巡天交互进行建模的重要性，为未来时域天文学的可扩展分类器开发提供了指导。", "keywords": "光变曲线分类, Swin Transformer V2, 多巡天, 时域天文学, 视觉Transformer", "comments": "本文创新性地将预训练视觉Transformer应用于多巡天光变曲线分类，并提出了有效的多源数据整合策略。其发现联合处理多巡天数据的重要性，对于未来大规模时域天文学数据处理具有重要指导意义。"}}
{"id": "2507.10502", "title": "Benchmarking and Evaluation of AI Models in Biology: Outcomes and Recommendations from the CZI Virtual Cells Workshop", "authors": ["Elizabeth Fahsbender", "Alma Andersson", "Jeremy Ash", "Polina Binder", "Daniel Burkhardt", "Benjamin Chang", "Georg K. Gerber", "Anthony Gitter", "Patrick Godau", "Ankit Gupta", "Genevieve Haliburton", "Siyu He", "Trey Ideker", "Ivana Jelic", "Aly Khan", "Yang-Joon Kim", "Aditi Krishnapriyan", "Jon M. Laurent", "Tianyu Liu 28", "Emma Lundberg", "Shalin B. Mehta", "Rob Moccia", "Angela Oliveira Pisco", "Katherine S. Pollard", "Suresh Ramani", "Julio Saez-Rodriguez", "Yasin Senbabaoglu", "Elana Simon", "Srinivasan Sivanandan", "Gustavo Stolovitzky", "Marc Valer", "Bo Wang", "Xikun Zhang", "James Zou", "Katrina Kalantar"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10502v1", "summary": "Artificial intelligence holds immense promise for transforming biology, yet a\nlack of standardized, cross domain, benchmarks undermines our ability to build\nrobust, trustworthy models. Here, we present insights from a recent workshop\nthat convened machine learning and computational biology experts across\nimaging, transcriptomics, proteomics, and genomics to tackle this gap. We\nidentify major technical and systemic bottlenecks such as data heterogeneity\nand noise, reproducibility challenges, biases, and the fragmented ecosystem of\npublicly available resources and propose a set of recommendations for building\nbenchmarking frameworks that can efficiently compare ML models of biological\nsystems across tasks and data modalities. By promoting high quality data\ncuration, standardized tooling, comprehensive evaluation metrics, and open,\ncollaborative platforms, we aim to accelerate the development of robust\nbenchmarks for AI driven Virtual Cells. These benchmarks are crucial for\nensuring rigor, reproducibility, and biological relevance, and will ultimately\nadvance the field toward integrated models that drive new discoveries,\ntherapeutic insights, and a deeper understanding of cellular systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10502v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "生物学中AI模型的基准测试与评估：CZI虚拟细胞研讨会的成果与建议", "tldr": "缺乏标准化基准测试阻碍生物学AI模型发展。CZI研讨会识别瓶颈并提出构建高效基准框架的建议，以加速AI驱动虚拟细胞模型的开发。", "motivation": "现有AI模型在生物学应用中缺乏标准化、跨领域的基准测试，这阻碍了构建稳健、可信赖的模型的能力。", "method": "通过召集机器学习和计算生物学专家（涵盖成像、转录组学、蛋白质组学和基因组学）举办研讨会，以解决AI模型基准测试的差距。", "result": "识别出主要的技术和系统瓶颈，如数据异质性和噪声、可重复性挑战、偏见以及公共资源生态系统的碎片化；并提出了一系列构建基准测试框架的建议，包括促进高质量数据整理、标准化工具、全面的评估指标以及开放协作平台。", "conclusion": "推广这些基准测试对于确保AI驱动的虚拟细胞模型的严谨性、可重复性和生物学相关性至关重要，最终将推动该领域发展出整合模型，从而带来新发现、治疗见解和对细胞系统的更深理解。", "translation": "人工智能在改造生物学方面具有巨大的前景，然而，缺乏标准化的跨领域基准测试削弱了我们构建稳健、可信赖模型的能力。在此，我们介绍了最近一次研讨会的见解，该研讨会汇集了成像、转录组学、蛋白质组学和基因组学领域的机器学习和计算生物学专家，以解决这一差距。我们识别出主要的技术和系统瓶颈，例如数据异质性和噪声、可重复性挑战、偏见以及公共可用资源的碎片化生态系统，并提出了一系列建议，用于构建能够有效比较跨任务和数据模态的生物系统机器学习模型的基准测试框架。通过促进高质量数据整理、标准化工具、全面的评估指标以及开放、协作平台，我们旨在加速开发用于AI驱动虚拟细胞的稳健基准测试。这些基准测试对于确保严谨性、可重复性和生物学相关性至关重要，并将最终推动该领域向整合模型发展，从而带来新发现、治疗见解以及对细胞系统的更深理解。", "summary": "本文总结了CZI虚拟细胞研讨会的成果，该研讨会旨在解决生物学领域AI模型缺乏标准化基准测试的问题。研讨会识别了数据异质性、可重复性、偏见和资源碎片化等主要技术和系统瓶颈，并提出了一系列建议，包括数据整理、工具标准化、全面评估指标和开放平台，以构建高效的基准测试框架，从而加速AI驱动虚拟细胞模型的开发，最终推动生物学发现。", "keywords": "AI模型, 生物学, 基准测试, 虚拟细胞, 标准化", "comments": "这篇论文（研讨会成果）的创新之处在于其通过跨学科专家协作，系统性地识别了生物学AI模型基准测试面临的核心挑战，并提供了具体且可操作的解决方案。其重要性在于，标准化基准测试是确保AI模型在生物学领域可靠性、可信度和实际应用价值的关键，对于加速“虚拟细胞”等复杂生物系统的AI建模具有里程碑意义。"}}
{"id": "2507.11721", "title": "Evasion Under Blockchain Sanctions", "authors": ["Endong Liu", "Mark Ryan", "Liyi Zhou", "Pascal Berrang"], "categories": ["cs.CR", "C.2.4"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11721v1", "summary": "Sanctioning blockchain addresses has become a common regulatory response to\nmalicious activities. However, enforcement on permissionless blockchains\nremains challenging due to complex transaction flows and sophisticated\nfund-obfuscation techniques. Using cryptocurrency mixing tool Tornado Cash as a\ncase study, we quantitatively assess the effectiveness of U.S. Office of\nForeign Assets Control (OFAC) sanctions over a 957-day period, covering 6.79\nmillion Ethereum blocks and 1.07 billion transactions. Our analysis reveals\nthat while OFAC sanctions reduced overall Tornado Cash deposit volume by 71.03%\nto approximately 2 billion USD, attackers still relied on Tornado Cash in\n78.33% of Ethereum-related security incidents, underscoring persistent evasion\nstrategies.\n  We identify three structural limitations in current sanction enforcement\npractices: (i) the susceptibility of binary sanction classifications to dusting\nattacks; (ii) fragmented censorship by blockchain producers; and (iii) the\ncomplexity of obfuscation services exploited by users. To address these gaps,\nwe introduce a more practical algorithm for scoring and tracking, grounded in\nquantitative impurity. On average, our algorithm processes Ethereum blocks\nwithin 0.07 $\\pm$ 0.03 seconds and achieves 97.61% precision and 74.08% recall\nwhen evaluated on the Bybit exploit. Our findings contribute to ongoing\ndiscussions around regulatory effectiveness in Decentralized Finance by\nproviding empirical evidence, clarifying enforcement challenges, and informing\nfuture compliance strategies in response to sanctions and blockchain-based\nsecurity risks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11721v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "区块链制裁下的规避行为", "tldr": "研究发现，尽管对Tornado Cash的制裁显著降低了存款量，但攻击者仍广泛使用它，表明区块链制裁存在持续的规避策略和结构性限制。论文还提出了一种新的追踪算法来应对这些挑战。", "motivation": "评估对去中心化区块链地址进行制裁的有效性，因为复杂的交易流和资金混淆技术使得在无需许可的区块链上执法具有挑战性。", "method": "以加密货币混合工具Tornado Cash为案例研究，定量评估美国外国资产控制办公室（OFAC）在957天内（覆盖679万个以太坊区块和10.7亿笔交易）的制裁有效性。识别当前制裁执行中的三个结构性限制。引入一种基于定量杂质的更实用的评分和跟踪算法，并在Bybit漏洞利用上评估其性能。", "result": "OFAC制裁使Tornado Cash总存款量减少了71.03%（约20亿美元），但攻击者在78.33%的以太坊相关安全事件中仍然依赖Tornado Cash。识别出当前制裁执行的三大结构性限制：二进制制裁分类易受尘埃攻击、区块链生产者碎片化审查、用户利用的混淆服务的复杂性。提出的算法平均在0.07 ± 0.03秒内处理以太坊区块，并在Bybit漏洞利用上实现了97.61%的精度和74.08%的召回率。", "conclusion": "本研究通过提供实证证据，阐明了去中心化金融中的执法挑战，并为未来应对制裁和基于区块链的安全风险的合规策略提供了信息。", "translation": "制裁区块链地址已成为恶意活动的常见监管回应。然而，由于复杂的交易流和复杂的资金混淆技术，在无需许可的区块链上执法仍然具有挑战性。我们以加密货币混合工具Tornado Cash为例，定量评估了美国外国资产控制办公室（OFAC）在957天内（涵盖679万个以太坊区块和10.7亿笔交易）的制裁有效性。我们的分析显示，尽管OFAC制裁使Tornado Cash的总存款量减少了71.03%（降至约20亿美元），但攻击者在78.33%的以太坊相关安全事件中仍然依赖Tornado Cash，这凸显了持续的规避策略。\n我们识别出当前制裁执行中的三个结构性限制：（i）二进制制裁分类易受尘埃攻击；（ii）区块链生产者碎片化审查；以及（iii）用户利用的混淆服务的复杂性。为了弥补这些空白，我们引入了一种基于定量杂质的更实用的评分和跟踪算法。平均而言，我们的算法在0.07 ± 0.03秒内处理以太坊区块，并在Bybit漏洞利用评估中实现了97.61%的精度和74.08%的召回率。我们的研究结果通过提供实证证据、阐明执法挑战以及为未来应对制裁和基于区块链的安全风险的合规策略提供信息，为当前关于去中心化金融中监管有效性的讨论做出了贡献。", "summary": "该研究以Tornado Cash为例，定量评估了区块链制裁的有效性。结果显示，尽管制裁大幅减少了交易量，但攻击者仍能规避制裁。文章指出了现有制裁执行的结构性限制，并提出了一种新的基于定量杂质的评分和跟踪算法，以提高区块链资产追踪的精度和效率，为去中心化金融的监管提供了实证见解。", "keywords": "区块链制裁, 规避, Tornado Cash, 去中心化金融, 链上分析", "comments": "这篇论文通过对Tornado Cash的实证分析，揭示了区块链制裁在无需许可环境中面临的严峻挑战和固有的局限性。其创新之处在于不仅量化了制裁效果与规避行为的并存，还提出了一个实用的、基于定量杂质的资产追踪算法，为提升监管有效性提供了新的技术路径。论文对于理解去中心化金融（DeFi）的监管困境和未来合规策略具有重要意义。"}}
{"id": "2507.12367", "title": "GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities", "authors": ["Diganta Misra", "Nizar Islah", "Victor May", "Brice Rauby", "Zihan Wang", "Justine Gehring", "Antonio Orvieto", "Muawiz Chaudhary", "Eilif B. Muller", "Irina Rish", "Samira Ebrahimi Kahou", "Massimo Caccia"], "categories": ["cs.SE", "cs.AI", "cs.PL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Version 2 of the dataset from: arXiv:2411.05830", "url": "http://arxiv.org/abs/2507.12367v1", "summary": "The rapid evolution of software libraries poses a considerable hurdle for\ncode generation, necessitating continuous adaptation to frequent version\nupdates while preserving backward compatibility. While existing code evolution\nbenchmarks provide valuable insights, they typically lack execution-based\nevaluation for generating code compliant with specific library versions. To\naddress this, we introduce GitChameleon, a novel, meticulously curated dataset\ncomprising 328 Python code completion problems, each conditioned on specific\nlibrary versions and accompanied by executable unit tests. GitChameleon\nrigorously evaluates the capacity of contemporary large language models (LLMs),\nLLM-powered agents, code assistants, and RAG systems to perform\nversion-conditioned code generation that demonstrates functional accuracy\nthrough execution. Our extensive evaluations indicate that state-of-the-art\nsystems encounter significant challenges with this task; enterprise models\nachieving baseline success rates in the 48-51\\% range, underscoring the\nintricacy of the problem. By offering an execution-based benchmark emphasizing\nthe dynamic nature of code libraries, GitChameleon enables a clearer\nunderstanding of this challenge and helps guide the development of more\nadaptable and dependable AI code generation methods. We make the dataset and\nevaluation code publicly available at\nhttps://github.com/mrcabbage972/GitChameleonBenchmark.", "comment": "Version 2 of the dataset from: arXiv:2411.05830", "pdf_url": "http://arxiv.org/pdf/2507.12367v1", "cate": "cs.SE", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "GitChameleon：评估AI代码生成对抗Python库版本不兼容性", "tldr": "GitChameleon引入了一个新的数据集，用于评估AI代码生成在Python库版本不兼容性方面的能力，发现当前SOTA模型表现不佳，强调了需要更具适应性的AI代码生成方法。", "motivation": "软件库的快速演进给代码生成带来了巨大挑战，需要持续适应版本更新并保持向后兼容性。现有代码演进基准缺乏针对特定库版本生成代码的执行评估。", "method": "引入了GitChameleon，一个包含328个Python代码补全问题的新数据集，每个问题都基于特定的库版本并附带可执行单元测试。该数据集通过执行来严格评估LLMs、LLM驱动的代理、代码助手和RAG系统在版本条件代码生成方面的功能准确性。", "result": "广泛的评估表明，最先进的系统在这项任务中遇到重大挑战；企业模型的基线成功率在48-51%范围内。", "conclusion": "GitChameleon通过提供一个强调代码库动态性质的基于执行的基准，使人们能够更清晰地理解这一挑战，并有助于指导开发更具适应性和可靠的AI代码生成方法。", "translation": "软件库的快速演进给代码生成带来了相当大的障碍，需要持续适应频繁的版本更新，同时保持向后兼容性。尽管现有的代码演进基准提供了宝贵的见解，但它们通常缺乏对符合特定库版本的代码生成进行基于执行的评估。为了解决这个问题，我们引入了GitChameleon，这是一个新颖的、精心策划的数据集，包含328个Python代码补全问题，每个问题都以特定的库版本为条件，并附带可执行单元测试。GitChameleon严格评估了当代大型语言模型（LLMs）、LLM驱动的代理、代码助手和RAG系统执行版本条件代码生成的能力，并通过执行展示其功能准确性。我们广泛的评估表明，最先进的系统在这项任务中遇到了重大挑战；企业模型的基线成功率在48-51%的范围内，这突显了问题的复杂性。通过提供一个强调代码库动态性质的基于执行的基准，GitChameleon使人们能够更清晰地理解这一挑战，并有助于指导开发更具适应性和可靠的AI代码生成方法。我们已将数据集和评估代码公开提供在https://github.com/mrcabbage972/GitChameleonBenchmark。", "summary": "本研究引入了GitChameleon，一个针对AI代码生成在Python库版本不兼容性问题上的新型执行基准数据集。该数据集包含328个基于特定库版本并附带可执行测试的Python代码补全问题。通过对当前LLM系统进行评估，发现它们在处理版本敏感的代码生成时表现不佳，企业模型的成功率仅为48-51%。GitChameleon旨在促进更具适应性和可靠的AI代码生成方法的发展，其数据集和评估代码已公开。", "keywords": "代码生成, Python库, 版本兼容性, 大型语言模型, 基准测试", "comments": "GitChameleon的创新之处在于其专注于AI代码生成中的版本兼容性问题，并提供了一个基于执行的评估基准，这弥补了现有基准的不足。其结果揭示了当前SOTA模型在该领域面临的严峻挑战，对于推动更实用、健壮的AI代码生成技术具有重要意义。"}}
{"id": "2507.11783", "title": "Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions", "authors": ["Gayal Kuruppu", "Neeraj Wagh", "Yogatheesan Varatharajah"], "categories": ["eess.SP", "cs.AI", "cs.LG", "q-bio.NC", "A.1; I.2; I.5; J.3"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      20 pages, 5 figures, 2 tables", "url": "http://arxiv.org/abs/2507.11783v1", "summary": "Patterns of electrical brain activity recorded via electroencephalography\n(EEG) offer immense value for scientific and clinical investigations. The\ninability of supervised EEG encoders to learn robust EEG patterns and their\nover-reliance on expensive signal annotations have sparked a transition towards\ngeneral-purpose self-supervised EEG encoders, i.e., EEG foundation models\n(EEG-FMs), for robust and scalable EEG feature extraction. However, the\nreal-world readiness of early EEG-FMs and the rubric for long-term research\nprogress remain unclear. A systematic and comprehensive review of\nfirst-generation EEG-FMs is therefore necessary to understand the current\nstate-of-the-art and identify key directions for future EEG-FMs. To that end,\nthis study reviews 10 early EEG-FMs and presents a critical synthesis of their\nmethodology, empirical findings, and outstanding research gaps. We find that\nmost EEG-FMs adopt a sequence-based modeling scheme that relies on\ntransformer-based backbones and the reconstruction of masked sequences for\nself-supervision. However, model evaluations remain heterogeneous and largely\nlimited, making it challenging to assess their practical off-the-shelf utility.\nIn addition to adopting standardized and realistic evaluations, future work\nshould demonstrate more substantial scaling effects and make principled and\ntrustworthy choices throughout the EEG representation learning pipeline. We\nbelieve that developing benchmarks, software tools, technical methodologies,\nand applications in collaboration with domain experts may further advance the\ntranslational utility and real-world adoption of EEG-FMs.", "comment": "20 pages, 5 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.11783v1", "cate": "eess.SP", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "脑信号基础模型：当前进展和未来方向的批判性综述", "tldr": "本文对早期脑电图基础模型（EEG-FMs）进行了批判性综述，指出当前模型主要采用基于Transformer的序列建模和掩码序列重建，但评估方法不统一且有限，难以评估实际效用。未来研究应侧重于标准化评估、扩大规模效应、优化学习流程并加强合作。", "motivation": "传统的监督式脑电图编码器难以学习鲁棒的脑电图模式，且过度依赖昂贵的信号标注，促使研究转向通用型自监督脑电图编码器（即脑电图基础模型，EEG-FMs）。然而，早期EEG-FMs的实际应用准备程度和长期研究进展的准则尚不明确，因此需要系统全面的综述来理解当前技术水平并确定未来发展方向。", "method": "本研究回顾了10个早期脑电图基础模型（EEG-FMs），并对其方法论、实证发现和未解决的研究空白进行了批判性综合分析。", "result": "研究发现，大多数EEG-FMs采用基于Transformer骨干和掩码序列重建的序列建模方案进行自监督学习。然而，模型评估方法存在异质性且很大程度上受限，这使得评估其实际的开箱即用效用变得困难。", "conclusion": "未来的工作除了采用标准化和实际的评估方法外，还应展示更显著的规模效应，并在脑电图表征学习的整个流程中做出有原则且值得信赖的选择。与领域专家合作开发基准、软件工具、技术方法和应用可能进一步提升EEG-FMs的转化效用和实际应用。", "translation": "通过脑电图（EEG）记录的电生理脑活动模式对科学和临床研究具有巨大的价值。监督式脑电图编码器无法学习鲁棒的脑电图模式以及其对昂贵信号标注的过度依赖，促使研究转向通用型自监督脑电图编码器，即脑电图基础模型（EEG-FMs），以实现鲁棒且可扩展的脑电图特征提取。然而，早期EEG-FMs的实际应用准备程度以及长期研究进展的准则仍不明确。因此，有必要对第一代EEG-FMs进行系统而全面的综述，以理解当前的技术水平并确定未来EEG-FMs的关键发展方向。为此，本研究回顾了10个早期EEG-FMs，并对其方法论、实证发现和突出的研究空白进行了批判性综合分析。我们发现，大多数EEG-FMs采用基于Transformer骨干和掩码序列重建进行自监督的序列建模方案。然而，模型评估仍然异质且很大程度上受限，这使得评估其实际的开箱即用效用变得困难。除了采用标准化和实际的评估方法外，未来的工作还应展示更显著的规模效应，并在脑电图表征学习的整个流程中做出有原则且值得信赖的选择。我们相信，与领域专家合作开发基准、软件工具、技术方法和应用可能进一步提升EEG-FMs的转化效用和实际应用。", "summary": "本文对早期脑电图基础模型（EEG-FMs）进行了批判性综述，旨在评估其当前进展和未来方向。研究指出，由于传统监督方法的局限性，自监督EEG-FMs应运而生。通过回顾10个早期模型，论文发现多数EEG-FMs采用基于Transformer的序列建模和掩码序列重建进行自监督。然而，现有的模型评估方法不统一且有限，难以准确衡量其实用性。因此，未来研究应聚焦于标准化评估、实现显著的规模效应、优化学习流程，并加强与领域专家的合作，以促进EEG-FMs的转化应用和实际部署。", "keywords": "EEG, 基础模型, 自监督学习, 综述, 脑信号", "comments": "本文对新兴的脑电图基础模型领域进行了及时且重要的批判性综述。其创新之处在于系统性地评估了早期模型的现状、识别了关键的方法论趋势，并明确指出了评估标准不统一和缺乏规模效应等局限性。这对于引导未来研究方向、促进该领域健康发展具有重要意义。论文提出的标准化评估和跨领域合作的建议尤为关键，有助于推动EEG-FMs从理论研究走向实际应用。"}}
{"id": "2507.12317", "title": "Road Roughness Estimation via Fusion of Standard Onboard Automotive Sensors", "authors": ["Martin Agebjär", "Gustav Zetterqvist", "Fredrik Gustafsson", "Johan Wahlström", "Gustaf Hendeby"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted for publication in FUSION 2025 - 28th International Conference on Information Fusion (FUSION), IEEE (2025)", "url": "http://arxiv.org/abs/2507.12317v1", "summary": "Road roughness significantly affects vehicle vibrations and ride quality. We\nintroduce a Kalman filter (KF)-based method for estimating road roughness in\nterms of the international roughness index (IRI) by fusing inertial and speed\nmeasurements, offering a cost-effective solution for pavement monitoring. The\nmethod involves system identification on a physical vehicle to estimate\nrealistic model parameters, followed by KF-based reconstruction of the\nlongitudinal road profile to compute IRI values. It explores IRI estimation\nusing vertical and lateral vibrations, the latter more common in modern\nvehicles. Validation on 230 km of real-world data shows promising results, with\nIRI estimation errors ranging from 1% to 10% of the reference values. However,\naccuracy deteriorates significantly when using only lateral vibrations,\nhighlighting their limitations. These findings demonstrate the potential of\nKF-based estimation for efficient road roughness monitoring.", "comment": "Accepted for publication in FUSION 2025 - 28th International\n  Conference on Information Fusion (FUSION), IEEE (2025)", "pdf_url": "http://arxiv.org/pdf/2507.12317v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于车载标准传感器融合的道路不平度估计", "tldr": "本文提出了一种基于卡尔曼滤波器的方法，通过融合惯性传感器和速度测量数据来估计道路不平度（IRI），为路面监测提供了一种经济高效的解决方案。", "motivation": "道路不平度严重影响车辆振动和乘坐质量，因此需要一种经济高效的道路不平度监测解决方案。", "method": "该方法首先对实际车辆进行系统辨识以估计真实的模型参数，然后使用基于卡尔曼滤波器的方法重建纵向道路剖面，并计算IRI值。研究探索了使用垂直和横向振动进行IRI估计，其中横向振动在现代车辆中更为常见。", "result": "在230公里实际数据上的验证显示，IRI估计误差在参考值的1%到10%之间，结果令人满意。然而，仅使用横向振动时精度显著下降。", "conclusion": "基于卡尔曼滤波器的估计方法在高效道路不平度监测方面具有潜力，但仅依靠横向振动存在局限性。", "translation": "道路不平度严重影响车辆振动和乘坐质量。我们引入了一种基于卡尔曼滤波器（KF）的方法，通过融合惯性传感器和速度测量数据来估计国际不平度指数（IRI）形式的道路不平度，为路面监测提供了一种经济高效的解决方案。该方法包括对物理车辆进行系统辨识以估计真实的模型参数，然后基于卡尔曼滤波器重建纵向道路剖面以计算IRI值。它探讨了使用垂直和横向振动进行IRI估计，后者在现代车辆中更为常见。在230公里实际数据上的验证显示出令人满意的结果，IRI估计误差在参考值的1%到10%之间。然而，仅使用横向振动时精度显著下降，突显了其局限性。这些发现证明了基于卡尔曼滤波器的估计在高效道路不平度监测方面的潜力。", "summary": "本文提出了一种基于卡尔曼滤波器（KF）的道路不平度（IRI）估计方法，通过融合车载标准惯性传感器和速度测量数据，旨在提供一种经济高效的路面监测方案。该方法涉及系统辨识以获取车辆模型参数，并利用KF重建道路剖面以计算IRI。研究验证了使用垂直和横向振动进行估计的有效性，并在230公里实际数据上取得了1%-10%的IRI估计误差。尽管该方法显示出道路不平度监测的潜力，但结果也表明仅依赖横向振动会显著降低精度。", "keywords": "道路不平度, 卡尔曼滤波器, IRI, 车载传感器, 路面监测", "comments": "该论文提出了一种利用现有车载传感器进行道路不平度估计的创新方法，具有成本效益和实际应用潜力。其创新点在于结合系统辨识与卡尔曼滤波器，有效地从车辆运动数据中提取路面信息。然而，论文也指出了仅使用横向振动时精度下降的局限性，这对于未来研究如何更好地利用或补充横向振动数据提出了挑战。这项研究对于智能交通系统和车辆维护具有重要意义。"}}
{"id": "2310.20360", "title": "Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory", "authors": ["Arnulf Jentzen", "Benno Kuckuck", "Philippe von Wurstemberger"], "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "math.PR", "stat.ML", "68T07"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      737 pages, 33 figures, 45 source codes, 87 exercises. In v3, Chapters 5, 6, and 7 in Part III (Optimization) have been expanded", "url": "http://arxiv.org/abs/2310.20360v3", "summary": "This book aims to provide an introduction to the topic of deep learning\nalgorithms. We review essential components of deep learning algorithms in full\nmathematical detail including different artificial neural network (ANN)\narchitectures (such as fully-connected feedforward ANNs, convolutional ANNs,\nrecurrent ANNs, residual ANNs, and ANNs with batch normalization) and different\noptimization algorithms (such as the basic stochastic gradient descent (SGD)\nmethod, accelerated methods, and adaptive methods). We also cover several\ntheoretical aspects of deep learning algorithms such as approximation\ncapacities of ANNs (including a calculus for ANNs), optimization theory\n(including Kurdyka-{\\L}ojasiewicz inequalities), and generalization errors. In\nthe last part of the book some deep learning approximation methods for PDEs are\nreviewed including physics-informed neural networks (PINNs) and deep Galerkin\nmethods. We hope that this book will be useful for students and scientists who\ndo not yet have any background in deep learning at all and would like to gain a\nsolid foundation as well as for practitioners who would like to obtain a firmer\nmathematical understanding of the objects and methods considered in deep\nlearning.", "comment": "737 pages, 33 figures, 45 source codes, 87 exercises. In v3, Chapters\n  5, 6, and 7 in Part III (Optimization) have been expanded", "pdf_url": "http://arxiv.org/pdf/2310.20360v3", "cate": "cs.LG", "date": "2023-10-31", "updated": "2025-07-15", "AI": {"title_translation": "深度学习的数学导论：方法、实现与理论", "tldr": "本书为深度学习提供全面的数学导论，涵盖人工神经网络、优化算法、理论基础及偏微分方程应用，适合初学者和寻求深入数学理解的从业者。", "motivation": "该书旨在为深度学习算法提供一个全面的数学导论，帮助没有深度学习背景的学生和科学家打下坚实基础，并帮助希望深入理解深度学习对象和方法的从业者。", "method": "该书详细回顾了深度学习算法的关键组成部分，包括不同的人工神经网络（ANN）架构（如全连接前馈、卷积、循环、残差和批归一化ANN），以及不同的优化算法（如基本随机梯度下降、加速和自适应方法）。它还涵盖了深度学习算法的几个理论方面，如ANN的逼近能力、优化理论和泛化误差。最后，书中还回顾了一些用于偏微分方程（PDE）的深度学习逼近方法，包括物理信息神经网络（PINN）和深度伽辽金方法。", "result": "作为一本入门书籍，其成果体现在为读者提供了深度学习的全面数学基础和深入理解。书中希望能够帮助没有深度学习背景的学生和科学家，以及希望获得更坚实数学理解的从业者。", "conclusion": "该书为深度学习算法提供了全面的数学导论，涵盖了从算法组件、优化方法到理论方面和PDE应用的广泛内容，旨在帮助初学者建立坚实基础并加深从业者的数学理解。", "translation": "本书旨在介绍深度学习算法。我们以完整的数学细节回顾了深度学习算法的基本组成部分，包括不同的人工神经网络（ANN）架构（如全连接前馈ANN、卷积ANN、循环ANN、残差ANN和带批归一化的ANN）以及不同的优化算法（如基本随机梯度下降（SGD）方法、加速方法和自适应方法）。我们还涵盖了深度学习算法的几个理论方面，如ANN的逼近能力（包括ANN的微积分）、优化理论（包括Kurdyka-Łojasiewicz不等式）和泛化误差。在本书的最后一部分，回顾了一些用于偏微分方程的深度学习逼近方法，包括物理信息神经网络（PINN）和深度伽辽金方法。我们希望这本书对那些完全没有深度学习背景的学生和科学家有用，帮助他们获得坚实的基础，也对那些希望对深度学习中考虑的对象和方法获得更坚实数学理解的从业者有用。", "summary": "本书提供了一份深度学习的数学导论，详细阐述了人工神经网络架构、优化算法、理论基础（如逼近能力、优化理论、泛化误差）以及深度学习在偏微分方程逼近中的应用（如PINNs）。本书旨在为初学者和寻求深入数学理解的从业者提供扎实的深度学习基础。", "keywords": "深度学习, 数学导论, 人工神经网络, 优化算法, 理论基础", "comments": "这本书的重要性在于它填补了深度学习领域中对数学基础深入理解的需求空白。它不仅涵盖了广泛的深度学习算法和架构，还深入探讨了其背后的数学理论，包括优化和逼近能力，甚至涉及了与偏微分方程结合的前沿应用。对于希望系统性地从数学角度理解深度学习的读者，无论其背景如何，都将是一份宝贵的资源。其创新性在于其全面的数学视角和对复杂理论的清晰阐述。"}}
{"id": "2507.10452", "title": "Some remarks on gradient dominance and LQR policy optimization", "authors": ["Eduardo D. Sontag"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This is a short paper summarizing the first part of the slides presented at my keynote at the 2025 L4DC (Learning for Dynamics & Control Conference) in Ann Arbor, Michigan, 05 June 2025. A partial bibliography has been added", "url": "http://arxiv.org/abs/2507.10452v1", "summary": "Solutions of optimization problems, including policy optimization in\nreinforcement learning, typically rely upon some variant of gradient descent.\nThere has been much recent work in the machine learning, control, and\noptimization communities applying the Polyak-{\\L}ojasiewicz Inequality (PLI) to\nsuch problems in order to establish an exponential rate of convergence (a.k.a.\n``linear convergence'' in the local-iteration language of numerical analysis)\nof loss functions to their minima under the gradient flow. Often, as is the\ncase of policy iteration for the continuous-time LQR problem, this rate\nvanishes for large initial conditions, resulting in a mixed globally linear /\nlocally exponential behavior. This is in sharp contrast with the discrete-time\nLQR problem, where there is global exponential convergence. That gap between CT\nand DT behaviors motivates the search for various generalized PLI-like\nconditions, and this talk will address that topic. Moreover, these\ngeneralizations are key to understanding the transient and asymptotic effects\nof errors in the estimation of the gradient, errors which might arise from\nadversarial attacks, wrong evaluation by an oracle, early stopping of a\nsimulation, inaccurate and very approximate digital twins, stochastic\ncomputations (algorithm ``reproducibility''), or learning by sampling from\nlimited data. We describe an ``input to state stability'' (ISS) analysis of\nthis issue. The lecture also discussed convergence and PLI-like properties of\n``linear feedforward neural networks'' in feedback control, but this arXiv\nskips that part (to be updated). Much of the work described here was done in\ncollaboration with Arthur Castello B. de Oliveira, Leilei Cui, Zhong-Ping\nJiang, and Milad Siami.", "comment": "This is a short paper summarizing the first part of the slides\n  presented at my keynote at the 2025 L4DC (Learning for Dynamics & Control\n  Conference) in Ann Arbor, Michigan, 05 June 2025. A partial bibliography has\n  been added. A second part on neural net feedback controllers is to be added", "pdf_url": "http://arxiv.org/pdf/2507.10452v1", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "梯度支配和LQR策略优化的一些评论", "tldr": "本文讨论了连续时间LQR和离散时间LQR策略优化中梯度下降收敛行为的差异，并探讨了广义Polyak-Łojasiewicz不等式（PLI）条件以及梯度估计误差的影响。", "motivation": "在强化学习中的策略优化等问题中，梯度下降通常被用来求解。然而，在连续时间LQR问题中，梯度下降的收敛速度对于大的初始条件会消失，这与离散时间LQR的全局指数收敛形成鲜明对比。这种差异促使研究人员寻找各种广义的Polyak-Łojasiewicz不等式（PLI）类条件。此外，理解梯度估计误差（可能源于对抗性攻击、不准确的数字孪生、随机计算或有限数据采样等）的瞬态和渐近效应也至关重要。", "method": "本文探讨了广义的Polyak-Łojasiewicz不等式（PLI）类条件，以解决连续时间LQR和离散时间LQR收敛行为的差异。此外，还描述了对梯度估计误差问题进行的“输入到状态稳定性”（ISS）分析。", "result": "本文探讨了连续时间LQR和离散时间LQR之间收敛行为的差异，并强调了广义PLI类条件在理解这种差异中的重要性。文中描述了针对梯度估计误差的“输入到状态稳定性”（ISS）分析。", "conclusion": "Not mentioned in abstract", "translation": "优化问题的解，包括强化学习中的策略优化，通常依赖于梯度下降的某种变体。最近，机器学习、控制和优化领域的大量工作将Polyak-Łojasiewicz不等式（PLI）应用于此类问题，以建立损失函数在梯度流下向其最小值指数收敛（在数值分析的局部迭代语言中称为“线性收敛”）的速率。通常，就像连续时间LQR问题的策略迭代一样，这种收敛速率对于大的初始条件会消失，导致混合的全局线性/局部指数行为。这与离散时间LQR问题形成鲜明对比，后者具有全局指数收敛性。CT和DT行为之间的这种差距促使人们寻找各种广义的PLI类条件，本次演讲将探讨这一主题。此外，这些推广是理解梯度估计误差的瞬态和渐近效应的关键，这些误差可能源于对抗性攻击、预言机错误评估、模拟过早停止、不准确和非常近似的数字孪生、随机计算（算法“可重现性”）或从有限数据中采样学习。我们描述了对这一问题的“输入到状态稳定性”（ISS）分析。本次讲座还讨论了反馈控制中“线性前馈神经网络”的收敛性和PLI类特性，但此arXiv版本跳过了这一部分（待更新）。此处描述的大部分工作是与Arthur Castello B. de Oliveira、Leilei Cui、Zhong-Ping Jiang和Milad Siami合作完成的。", "summary": "本文探讨了梯度下降优化中收敛性分析的关键问题，特别是在LQR策略优化领域。研究发现，连续时间LQR的收敛行为与离散时间LQR存在显著差异，前者对于大初始条件可能出现收敛速率消失的现象。为解决这一问题，论文探讨了广义Polyak-Łojasiewicz不等式（PLI）类条件的重要性，并描述了如何通过“输入到状态稳定性”（ISS）分析来理解和处理由对抗性攻击、不准确数据等引起的梯度估计误差的瞬态和渐近效应。", "keywords": "梯度支配, LQR策略优化, Polyak-Łojasiewicz不等式, 收敛性, 输入到状态稳定性", "comments": "该论文关注梯度下降优化中的核心理论问题，即收敛性分析，特别是LQR问题中连续时间与离散时间行为的对比。提出寻找广义PLI条件以弥合这种差距，并引入ISS分析来处理梯度估计误差，这对于提升机器学习和控制系统中算法的鲁棒性和可靠性具有重要的理论和实践价值。其对误差来源的细致分类也显示了对实际应用复杂性的深刻理解。"}}
{"id": "2507.11763", "title": "Space Cybersecurity Testbed: Fidelity Framework, Example Implementation, and Characterization", "authors": ["Jose Luis Castanon Remy", "Caleb Chang", "Ekzhin Ear", "Shouhuai Xu"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11763v1", "summary": "Cyber threats against space infrastructures, including satellites and systems\non the ground, have not been adequately understood. Testbeds are important to\ndeepen our understanding and validate space cybersecurity studies. The state of\nthe art is that there are very few studies on building testbeds, and there are\nfew characterizations of testbeds. In this paper, we propose a framework for\ncharacterizing the fidelity of space cybersecurity testbeds. The framework\nincludes 7 attributes for characterizing the system models, threat models, and\ndefenses that can be accommodated by a testbed. We use the framework to guide\nus in building and characterizing a concrete testbed we have implemented, which\nincludes space, ground, user, and link segments. In particular, we show how the\ntestbed can accommodate some space cyber attack scenarios that have occurred in\nthe real world, and discuss future research directions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11763v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "空间网络安全试验台：保真度框架、示例实现和特性化", "tldr": "本文提出了一个用于表征空间网络安全试验台保真度的框架，并用其指导构建了一个具体的试验台，展示了其可模拟真实世界网络攻击场景的能力。", "motivation": "空间基础设施（包括卫星和地面系统）面临的网络威胁尚未得到充分理解。试验台对于加深理解和验证空间网络安全研究至关重要。然而，目前关于构建和表征试验台的研究非常有限。", "method": "本文提出了一种用于表征空间网络安全试验台保真度的框架，该框架包含7个属性，用于描述试验台可容纳的系统模型、威胁模型和防御措施。研究人员利用该框架指导构建并表征了一个具体的试验台，该试验台包括空间、地面、用户和链路段。", "result": "该试验台能够容纳并模拟一些在现实世界中发生过的空间网络攻击场景。", "conclusion": "本文提出的保真度框架和构建的试验台有助于加深对空间网络安全威胁的理解，并为未来的研究方向提供了讨论。", "translation": "网络空间对空间基础设施（包括卫星和地面系统）的威胁尚未得到充分理解。试验台对于加深我们的理解和验证空间网络安全研究至关重要。目前的现状是，关于构建试验台的研究非常少，对试验台的特性化研究也很少。在本文中，我们提出了一个用于表征空间网络安全试验台保真度的框架。该框架包括7个属性，用于表征试验台可容纳的系统模型、威胁模型和防御措施。我们利用该框架指导我们构建和表征了一个我们已经实现的具体试验台，该试验台包括空间、地面、用户和链路段。特别是，我们展示了该试验台如何能够容纳一些在现实世界中发生的空间网络攻击场景，并讨论了未来的研究方向。", "summary": "本文针对空间基础设施网络威胁理解不足和现有试验台研究匮乏的问题，提出了一种表征空间网络安全试验台保真度的框架。该框架包含7个属性，用于评估试验台的系统、威胁和防御模型。作者利用此框架指导构建了一个包含空间、地面、用户和链路段的实际试验台，并成功展示了其模拟真实世界空间网络攻击场景的能力，为未来的研究奠定了基础。", "keywords": "空间网络安全, 试验台, 保真度框架, 网络威胁, 卫星系统", "comments": "这项研究通过提出一个结构化的保真度框架并实现一个具体的试验台，填补了空间网络安全领域在试验台构建和表征方面的空白。其创新之处在于提供了评估试验台质量的标准化方法，并证明了其在模拟真实世界威胁方面的有效性，对于提升空间网络安全研究的实用性和深度具有重要意义。"}}
{"id": "2507.11575", "title": "What cat is that? A re-id model for feral cats", "authors": ["Victor Caquilpan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Master's project", "url": "http://arxiv.org/abs/2507.11575v1", "summary": "Feral cats exert a substantial and detrimental impact on Australian wildlife,\nplacing them among the most dangerous invasive species worldwide. Therefore,\nclosely monitoring these cats is essential labour in minimising their effects.\nIn this context, the potential application of Re-Identification (re-ID) emerges\nto enhance monitoring activities for these animals, utilising images captured\nby camera traps. This project explores different CV approaches to create a\nre-ID model able to identify individual feral cats in the wild. The main\napproach consists of modifying a part-pose guided network (PPGNet) model,\ninitially used in the re-ID of Amur tigers, to be applicable for feral cats.\nThis adaptation, resulting in PPGNet-Cat, which incorporates specific\nmodifications to suit the characteristics of feral cats images. Additionally,\nvarious experiments were conducted, particularly exploring contrastive learning\napproaches such as ArcFace loss. The main results indicate that PPGNet-Cat\nexcels in identifying feral cats, achieving high performance with a mean\nAverage Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomes\nestablish PPGNet-Cat as a competitive model within the realm of re-ID.", "comment": "Master's project", "pdf_url": "http://arxiv.org/pdf/2507.11575v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "那是什么猫？一种用于野猫的重识别模型", "tldr": "本文提出了一种名为PPGNet-Cat的重识别模型，用于识别澳大利亚野猫，该模型在野猫重识别任务上表现出色，mAP达到0.86，rank-1准确率达到0.95。", "motivation": "野猫对澳大利亚野生动物造成严重的有害影响，是全球最危险的入侵物种之一。因此，密切监测这些猫对于最大限度地减少其影响至关重要。重识别（re-ID）技术有望增强对这些动物的监测活动。", "method": "本项目探索了不同的计算机视觉方法来创建一个能够识别野外个体野猫的重识别模型。主要方法是修改一个部分姿态引导网络（PPGNet）模型（最初用于东北虎的重识别），使其适用于野猫，形成PPGNet-Cat。此适应性修改是为了适应野猫图像的特定特征。此外，还进行了各种实验，特别是探索了对比学习方法，如ArcFace损失。", "result": "主要结果表明，PPGNet-Cat在识别野猫方面表现出色，实现了高性能，平均精度（mAP）为0.86，rank-1准确率为0.95。", "conclusion": "这些结果表明PPGNet-Cat在重识别领域是一个有竞争力的模型。", "translation": "野猫对澳大利亚野生动物造成了实质性和有害的影响，使其成为全球最危险的入侵物种之一。因此，密切监测这些猫对于最大限度地减少其影响至关重要。在此背景下，重识别（re-ID）的潜在应用应运而生，利用相机陷阱捕获的图像来增强对这些动物的监测活动。本项目探索了不同的计算机视觉方法，以创建一个能够在野外识别个体野猫的重识别模型。主要方法是修改一个部分姿态引导网络（PPGNet）模型，该模型最初用于东北虎的重识别，使其适用于野猫。这种适应性修改形成了PPGNet-Cat，其中包含了特定的修改以适应野猫图像的特征。此外，还进行了各种实验，特别是探索了对比学习方法，如ArcFace损失。主要结果表明，PPGNet-Cat在识别野猫方面表现出色，实现了高性能，平均精度（mAP）为0.86，rank-1准确率为0.95。这些结果确立了PPGNet-Cat在重识别领域作为一个有竞争力的模型。", "summary": "本文提出并评估了PPGNet-Cat，一个基于修改后的部分姿态引导网络（PPGNet）的重识别模型，旨在通过相机陷阱图像识别个体野猫，以应对野猫对澳大利亚野生动物的负面影响。该模型通过结合针对野猫图像特征的特定修改和探索对比学习方法（如ArcFace损失）进行开发。实验结果显示，PPGNet-Cat在野猫识别方面表现出色，mAP达到0.86，rank-1准确率达到0.95，证明其在重识别任务中的竞争力。", "keywords": "野猫, 重识别, PPGNet, 计算机视觉, 野生动物监测", "comments": "该论文通过将现有模型（PPGNet）适应性地应用于新的物种（野猫）重识别，展示了其创新性。这种方法不仅解决了澳大利亚野生动物保护中的一个重要问题，而且通过高精度的性能指标证明了其有效性。对特定物种图像特征的适应性修改以及对比学习方法的探索，是其成功的关键。"}}
{"id": "2507.11865", "title": "A Policy-Improved Deep Deterministic Policy Gradient Framework for the Discount Order Acceptance Strategy of Ride-hailing Drivers", "authors": ["Hanwen Dai", "Chang Gao", "Fang He", "Congyuan Ji", "Yanni Yang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11865v1", "summary": "The rapid expansion of platform integration has emerged as an effective\nsolution to mitigate market fragmentation by consolidating multiple\nride-hailing platforms into a single application. To address heterogeneous\npassenger preferences, third-party integrators provide Discount Express service\ndelivered by express drivers at lower trip fares. For the individual platform,\nencouraging broader participation of drivers in Discount Express services has\nthe potential to expand the accessible demand pool and improve matching\nefficiency, but often at the cost of reduced profit margins. This study aims to\ndynamically manage drivers' acceptance of Discount Express from the perspective\nof individual platforms. The lack of historical data under the new business\nmodel necessitates online learning. However, early-stage exploration through\ntrial and error can be costly in practice, highlighting the need for reliable\nearly-stage performance in real-world deployment. To address these challenges,\nthis study formulates the decision regarding the proportion of drivers'\nacceptance behavior as a continuous control task. In response to the high\nstochasticity, the opaque matching mechanisms employed by third-party\nintegrator, and the limited availability of historical data, we propose a\npolicy-improved deep deterministic policy gradient (pi-DDPG) framework. The\nproposed framework incorporates a refiner module to boost policy performance\nduring the early training phase, leverages a convolutional long short-term\nmemory network to effectively capture complex spatiotemporal patterns, and\nadopts a prioritized experience replay mechanism to enhance learning\nefficiency. A simulator based on a real-world dataset is developed to validate\nthe effectiveness of the proposed pi-DDPG. Numerical experiments demonstrate\nthat pi-DDPG achieves superior learning efficiency and significantly reduces\nearly-stage training losses.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11865v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "一种用于网约车司机折扣订单接受策略的策略改进深度确定性策略梯度框架", "tldr": "本研究提出了一种策略改进的深度确定性策略梯度（pi-DDPG）框架，以动态管理网约车司机对折扣快车服务的接受度，旨在解决早期训练阶段的性能挑战和数据稀缺问题。", "motivation": "平台整合的快速扩张促进了市场整合，但折扣快车服务可能降低网约车平台的利润。本研究旨在从个体平台的角度动态管理司机对折扣快车服务的接受度。由于新业务模式缺乏历史数据，需要在线学习，但早期探索的试错成本高昂，需要可靠的早期性能。", "method": "本研究将司机接受行为比例的决策表述为连续控制任务。针对高随机性、第三方整合商不透明的匹配机制以及有限的历史数据，提出了一种策略改进的深度确定性策略梯度（pi-DDPG）框架。该框架包含一个改进器模块以提升早期训练阶段的策略性能，利用卷积长短期记忆网络捕捉复杂的时空模式，并采用优先级经验回放机制提高学习效率。通过基于真实世界数据集的模拟器验证了所提方法的有效性。", "result": "数值实验表明，所提出的pi-DDPG框架具有卓越的学习效率，并显著降低了早期训练损失。", "conclusion": "pi-DDPG框架能够有效管理网约车司机对折扣订单的接受策略，解决了在线学习早期阶段的性能和数据挑战，并提高了学习效率。", "translation": "平台整合的快速扩张已成为缓解市场碎片化的有效解决方案，它将多个网约车平台整合到一个应用程序中。为了满足异构乘客偏好，第三方整合商提供由快车司机提供的折扣快车服务，票价更低。对于单个平台而言，鼓励司机更广泛地参与折扣快车服务有望扩大可获得的客源池并提高匹配效率，但这通常会以降低利润率为代价。本研究旨在从个体平台的角度动态管理司机对折扣快车订单的接受度。新业务模式下历史数据的缺乏使得在线学习成为必要。然而，通过试错进行的早期探索在实践中成本高昂，这凸显了在实际部署中需要可靠的早期性能。为了应对这些挑战，本研究将司机接受行为比例的决策表述为连续控制任务。针对高随机性、第三方整合商采用的不透明匹配机制以及有限的历史数据，我们提出了一种策略改进的深度确定性策略梯度（pi-DDPG）框架。所提出的框架包含一个改进器模块以提升早期训练阶段的策略性能，利用卷积长短期记忆网络有效地捕捉复杂的时空模式，并采用优先级经验回放机制以增强学习效率。开发了一个基于真实世界数据集的模拟器来验证所提出的pi-DDPG的有效性。数值实验表明，pi-DDPG实现了卓越的学习效率并显著降低了早期训练损失。", "summary": "本研究提出了一种名为pi-DDPG的策略改进深度确定性策略梯度框架，用于动态管理网约车司机对折扣快车订单的接受策略。面对新业务模式下数据稀缺、早期在线学习成本高昂以及高随机性和不透明匹配机制等挑战，pi-DDPG通过引入改进器模块、利用卷积LSTM网络和优先级经验回放机制，显著提升了早期训练性能和学习效率。基于真实世界数据集的模拟器验证了该框架的有效性。", "keywords": "深度强化学习, DDPG, 网约车, 折扣订单, 策略改进", "comments": "本文针对网约车平台在推广折扣服务时面临的司机接受度管理问题，创新性地提出了pi-DDPG框架。其亮点在于结合了深度强化学习和多项改进机制，有效解决了在线学习早期阶段数据不足和性能不稳定的痛点。特别是引入的refiner模块和对时空模式的捕捉，提升了模型在复杂环境下的实用性。这对于网约车平台的精细化运营具有重要的指导意义。"}}
{"id": "2404.05102", "title": "LHU-Net: a Lean Hybrid U-Net for Cost-efficient, High-performance Volumetric Segmentation", "authors": ["Yousef Sadegheih", "Afshin Bozorgpour", "Pratibha Kumari", "Reza Azad", "Dorit Merhof"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted at MICCAI-2025", "url": "http://arxiv.org/abs/2404.05102v3", "summary": "The rise of Transformer architectures has advanced medical image\nsegmentation, leading to hybrid models that combine Convolutional Neural\nNetworks (CNNs) and Transformers. However, these models often suffer from\nexcessive complexity and fail to effectively integrate spatial and channel\nfeatures, crucial for precise segmentation. To address this, we propose\nLHU-Net, a Lean Hybrid U-Net for volumetric medical image segmentation. LHU-Net\nprioritizes spatial feature extraction before refining channel features,\noptimizing both efficiency and accuracy. Evaluated on four benchmark datasets\n(Synapse, Left Atrial, BraTS-Decathlon, and Lung-Decathlon), LHU-Net\nconsistently outperforms existing models across diverse modalities (CT/MRI) and\noutput configurations. It achieves state-of-the-art Dice scores while using\nfour times fewer parameters and 20% fewer FLOPs than competing models, without\nthe need for pre-training, additional data, or model ensembles. With an average\nof 11 million parameters, LHU-Net sets a new benchmark for computational\nefficiency and segmentation accuracy. Our implementation is available on\nGitHub: https://github.com/xmindflow/LHUNet", "comment": "Accepted at MICCAI-2025", "pdf_url": "http://arxiv.org/pdf/2404.05102v3", "cate": "eess.IV", "date": "2024-04-07", "updated": "2025-07-16", "AI": {"title_translation": "LHU-Net: 一种精益混合U-Net，用于经济高效、高性能的体积分割", "tldr": "LHU-Net是一种新的精益混合U-Net，专为体积医学图像分割设计，它通过优化空间和通道特征提取，实现了更高的效率和准确性，同时显著减少了参数和计算量。", "motivation": "现有的结合了CNN和Transformer的混合模型在医学图像分割中存在过度复杂性问题，并且未能有效整合空间和通道特征，而这对于精确分割至关重要。", "method": "本文提出了LHU-Net，一种精益混合U-Net。该模型优先进行空间特征提取，然后精炼通道特征，旨在优化效率和准确性。", "result": "LHU-Net在四个基准数据集（Synapse、Left Atrial、BraTS-Decathlon和Lung-Decathlon）上均持续优于现有模型，并在不同模态（CT/MRI）和输出配置下实现了最先进的Dice分数。与竞争模型相比，它使用的参数减少了四倍，FLOPs减少了20%，且无需预训练、额外数据或模型集成。LHU-Net平均拥有1100万个参数。", "conclusion": "LHU-Net在计算效率和分割精度方面树立了新的基准，为体积医学图像分割提供了一种成本效益高、高性能的解决方案。", "translation": "Transformer架构的兴起推动了医学图像分割技术的发展，催生了结合卷积神经网络（CNN）和Transformer的混合模型。然而，这些模型往往过于复杂，并且未能有效整合空间和通道特征，而这对于精确分割至关重要。为了解决这个问题，我们提出了LHU-Net，一种用于体积医学图像分割的精益混合U-Net。LHU-Net优先进行空间特征提取，然后精炼通道特征，从而优化了效率和准确性。在四个基准数据集（Synapse、Left Atrial、BraTS-Decathlon和Lung-Decathlon）上进行评估，LHU-Net在不同模态（CT/MRI）和输出配置下始终优于现有模型。它在实现最先进的Dice分数的同时，比竞争模型使用的参数减少了四倍，FLOPs减少了20%，并且无需预训练、额外数据或模型集成。LHU-Net平均拥有1100万个参数，为计算效率和分割精度设定了新的基准。我们的实现代码已在GitHub上提供：https://github.com/xmindflow/LHUNet", "summary": "LHU-Net是一种针对体积医学图像分割提出的精益混合U-Net模型，旨在解决现有混合模型复杂度高且特征整合不足的问题。该模型通过优先提取空间特征再精炼通道特征，显著提升了效率和准确性。实验结果显示，LHU-Net在多个基准数据集上均超越了现有模型，实现了最先进的Dice分数，同时参数量减少了四倍，FLOPs减少了20%，无需额外预训练或数据。它为计算效率和分割精度设立了新标准。", "keywords": "LHU-Net, 混合U-Net, 体积分割, 医学图像, 计算效率", "comments": "该论文提出了一种创新的精益混合U-Net架构（LHU-Net），有效解决了现有混合模型在医学图像分割中过度复杂性和特征整合不足的问题。其主要创新在于优化了空间和通道特征的提取顺序，显著提升了模型效率和准确性。在不依赖预训练、额外数据或模型集成的情况下，LHU-Net在性能上超越了现有模型，同时大幅减少了计算资源需求，这对于实际应用具有重要意义。"}}
{"id": "2507.12256", "title": "Surrogate Quantum Circuit Design for the Lattice Boltzmann Collision Operator", "authors": ["Monica Lăcătuş", "Matthias Möller"], "categories": ["quant-ph", "cs.LG", "physics.comp-ph"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      31 pages, 14 figures", "url": "http://arxiv.org/abs/2507.12256v1", "summary": "Direct numerical simulation of turbulent flows at high Reynolds numbers\nremains a major challenge for traditional computational fluid dynamics (CFD)\ntools running on classical computer hardware. This has motivated growing\ninterest in quantum algorithms for CFD to enable flow simulations on quantum\ncomputers. The reason being that these computers are expected to deliver\npotential speed-ups for certain problems. One promising quantum CFD approach is\na fully quantum implementation of the lattice Boltzmann method called QLBM.\nAlthough efficient quantum routines are now available for the streaming step,\nimplementing the nonlinear, irreversible collision step with a low depth\ncircuit that avoids additional ancilla qubits, probabilistic post-selection and\nrepeated executions remains a significant challenge. In this study, we address\nthis challenge by introducing a framework for learning a surrogate quantum\ncircuit (SQC) that approximates the full Bhatnagar Gross Krook (BGK) collision\noperator for the D2Q9 lattice. The four qubit circuit is trained to respect the\nphysical properties of the BGK collision operator, including mass and momentum\nconservation, D8 equivariance and scale equivariance. When compiled to the gate\nset used by IBM Heron processor under the assumption of full qubit\nconnectivity, the 15 block SQC requires only 2,430 native gates and uses\nneither ancilla qubits nor post-selection or repeated executions. Moreover, its\ndepth is independent of the grid resolution, as collision is a local operation\nthat can exploit quantum parallelism to its full extent. We validate the SQC on\ntwo benchmark flows, the Taylor Green vortex decay and the lid driven cavity,\ndemonstrating that it accurately captures vortex dissipation and flow\nrecirculation.", "comment": "31 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.12256v1", "cate": "quant-ph", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "代理量子电路设计用于格子玻尔兹曼碰撞算子", "tldr": "本文提出了一种代理量子电路（SQC）来近似D2Q9格子玻尔兹曼碰撞算子，解决了QLBM中碰撞步骤电路深度和资源消耗大的问题，并在基准流中验证了其准确性。", "motivation": "传统CFD工具在经典硬件上模拟高雷诺数湍流面临挑战，量子计算机有望提供加速。QLBM作为一种量子CFD方法有前景，但其非线性、不可逆的碰撞步骤需要低深度电路且避免额外辅助比特、概率后选择和重复执行，这是一个重大挑战。", "method": "引入了一个学习代理量子电路（SQC）的框架，用于近似D2Q9格子的完整Bhatnagar Gross Krook (BGK) 碰撞算子。该四量子比特电路经过训练，以满足BGK碰撞算子的物理性质，包括质量和动量守恒、D8等变性和尺度等变性。", "result": "编译到IBM Heron处理器门集时，15块SQC仅需2,430个原生门，不使用辅助量子比特、后选择或重复执行。其深度与网格分辨率无关。在Taylor Green涡衰减和盖驱动腔两个基准流中验证，SQC准确捕获了涡耗散和流体再循环。", "conclusion": "所提出的代理量子电路能够有效且资源高效地实现格子玻尔兹曼方法的碰撞算子，为量子流体动力学模拟提供了可行方案。", "translation": "高雷诺数湍流的直接数值模拟对于在经典计算机硬件上运行的传统计算流体动力学（CFD）工具来说仍然是一个重大挑战。这促使人们对用于CFD的量子算法产生了越来越大的兴趣，以实现在量子计算机上进行流动模拟。原因是这些计算机有望在某些问题上提供潜在的加速。一种有前景的量子CFD方法是格子玻尔兹曼方法（QLBM）的完全量子实现。尽管目前已有了用于流体步骤的高效量子例程，但以低深度电路实现非线性、不可逆的碰撞步骤，同时避免额外的辅助量子比特、概率后选择和重复执行，仍然是一个重大挑战。在本研究中，我们通过引入一个学习代理量子电路（SQC）的框架来解决这一挑战，该电路近似D2Q9格子的完整Bhatnagar Gross Krook（BGK）碰撞算子。这个四量子比特电路经过训练，以满足BGK碰撞算子的物理性质，包括质量和动量守恒、D8等变性和尺度等变性。当编译到IBM Heron处理器使用的门集，并在完全量子比特连接的假设下，15块SQC仅需要2,430个原生门，并且不使用辅助量子比特、后选择或重复执行。此外，其深度与网格分辨率无关，因为碰撞是一种局部操作，可以充分利用量子并行性。我们在两个基准流（Taylor Green涡衰减和盖驱动腔）上验证了SQC，证明它准确地捕获了涡耗散和流体再循环。", "summary": "本文提出了一种新颖的代理量子电路（SQC）框架，用于高效实现格子玻尔兹曼方法（LBM）中的非线性碰撞算子。针对D2Q9格子，该四量子比特SQC经过训练以保持BGK碰撞算子的物理性质。该电路在IBM Heron处理器上编译后，具有低深度（与网格分辨率无关）、低门数（2,430个原生门），且无需辅助量子比特、后选择或重复执行。实验结果表明，该SQC在基准流模拟中能准确捕捉流体动力学现象，为量子计算机上的湍流模拟提供了重要的进展。", "keywords": "量子计算, 格子玻尔兹曼方法, 代理量子电路, 碰撞算子, 流体动力学模拟", "comments": "这篇论文的创新点在于提出了一个学习代理量子电路的框架，用于解决量子格子玻尔兹曼方法中碰撞算子实现效率低下的关键问题。通过设计一个满足物理守恒律和对称性的低深度、低资源消耗的量子电路，极大地推动了量子计算机上流体模拟的可行性。其结果表明，这种方法在资源受限的NISQ（Noisy Intermediate-Scale Quantum）设备上具有实际应用潜力，是量子计算在计算流体动力学领域的重要一步。"}}
{"id": "2507.06210", "title": "CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions", "authors": ["Yuchen Huang", "Zhiyuan Fan", "Zhitao He", "Sandeep Polisetty", "Wenyan Li", "Yi R. Fung"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      25 pages, COLM 2025", "url": "http://arxiv.org/abs/2507.06210v2", "summary": "Pretrained vision-language models (VLMs) such as CLIP excel in general\nmultimodal comprehension but often struggle to capture nuanced,\ncontext-dependent visual cues. This makes it difficult to distinguish between\nsimilar-looking concepts with potentially different cultural meanings. Such\ndeficiencies are mainly due to a limited amount of high-quality cultural data,\ncontextual information, and the lack of negative examples that highlight subtle\ndifferences. To mitigate this, we design a data curation pipeline leveraging\nopen-sourced VLMs and text-to-image models to construct CulTwin, a synthetic\ncultural dataset. This dataset consists of paired concept-caption-image\ntriplets, where concepts visually resemble each other but are culturally\ndifferent. Then, we fine-tune CLIP on CulTwin to develop CultureCLIP, which\naligns cultural concepts with contextually enhanced captions and synthetic\nimages through tailored contrastive learning. Experiments on culture-specific\nbenchmarks show that CultureCLIP outperforms the base CLIP, achieving up to a\nnotable 5.49% improvement in fine-grained concept recognition on certain tasks\nwhile preserving CLIP's original generalization ability, validating the\neffectiveness of our data synthesis and VLM backbone training paradigm in\ncapturing subtle cultural distinctions.", "comment": "25 pages, COLM 2025", "pdf_url": "http://arxiv.org/pdf/2507.06210v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-16", "AI": {"title_translation": "CultureCLIP：通过合成图像和情境化字幕增强CLIP的文化意识", "tldr": "CultureCLIP通过合成文化数据集和定制对比学习，提高了CLIP在文化敏感概念识别方面的能力，同时保持了其泛化性。", "motivation": "预训练的视觉语言模型（如CLIP）在处理细微、上下文相关的视觉线索方面表现不佳，难以区分外观相似但文化含义不同的概念。这主要是由于高质量文化数据、上下文信息和突出细微差异的负例的缺乏。", "method": "设计了一个数据整理管道，利用开源的VLM和文本到图像模型构建了合成文化数据集CulTwin。CulTwin包含外观相似但文化不同的概念-字幕-图像三元组。然后，通过定制的对比学习，在CulTwin上微调CLIP，开发出CultureCLIP，使其将文化概念与情境增强的字幕和合成图像对齐。", "result": "在文化特定基准测试中，CultureCLIP表现优于基础CLIP，在某些任务的细粒度概念识别上取得了高达5.49%的显著改进，同时保留了CLIP原有的泛化能力。", "conclusion": "研究验证了数据合成和VLM骨干训练范式在捕捉细微文化差异方面的有效性。", "translation": "预训练的视觉语言模型（VLM）如CLIP在通用多模态理解方面表现出色，但往往难以捕捉细微的、上下文相关的视觉线索。这使得它们难以区分外观相似但可能具有不同文化含义的概念。这种缺陷主要是由于高质量文化数据、上下文信息以及缺乏突出细微差异的负例的数量有限。为了缓解这个问题，我们设计了一个数据整理管道，利用开源的VLM和文本到图像模型来构建CulTwin，一个合成文化数据集。该数据集包含配对的概念-字幕-图像三元组，其中概念在视觉上彼此相似但文化上不同。然后，我们在CulTwin上微调CLIP，开发出CultureCLIP，通过定制的对比学习将文化概念与情境增强的字幕和合成图像对齐。在文化特定基准测试上的实验表明，CultureCLIP优于基础CLIP，在某些任务的细粒度概念识别上取得了高达5.49%的显著改进，同时保留了CLIP原有的泛化能力，验证了我们的数据合成和VLM骨干训练范式在捕捉细微文化区别方面的有效性。", "summary": "本文提出了CultureCLIP，旨在通过解决预训练视觉语言模型（如CLIP）在文化敏感概念识别方面的不足。研究人员设计了一个数据整理管道，利用开源的VLM和文本到图像模型创建了名为CulTwin的合成文化数据集。CulTwin包含外观相似但文化含义不同的概念-字幕-图像三元组。通过在CulTwin上对CLIP进行定制的对比学习微调，CultureCLIP能够更好地对齐文化概念与情境化字幕和合成图像。实验结果表明，CultureCLIP在文化特定基准测试中显著优于基础CLIP，在细粒度概念识别上实现了高达5.49%的提升，同时保持了模型的泛化能力，证明了其数据合成和VLM训练范式在捕捉文化细微差别方面的有效性。", "keywords": "文化意识, CLIP, 合成图像, 对比学习, 视觉语言模型", "comments": "本文的创新点在于通过合成数据来解决文化数据稀缺的问题，并设计了专门的数据集（CulTwin）和微调策略（定制对比学习）来增强VLM的文化意识。这种方法提供了一个有效途径，以弥补现有VLM在处理文化敏感信息时的局限性，对于提升AI的文化理解能力具有重要意义。其通过合成数据生成负例来突出细微差异的做法也值得借鉴。"}}
{"id": "2507.11772", "title": "How To Mitigate And Defend Against DDoS Attacks In IoT Devices", "authors": ["Ifiyemi Leigha", "Basak Comlekcioglu", "Maria Pilar Bezanilla"], "categories": ["cs.CR", "C.2.0; C.2.1; D.4.6"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11772v1", "summary": "Distributed Denial of Service (DDoS) attacks have become increasingly\nprevalent and dangerous in the context of Internet of Things (IoT) networks,\nprimarily due to the low-security configurations of many connected devices.\nThis paper analyzes the nature and impact of DDoS attacks such as those\nlaunched by the Mirai botnet, and proposes layered mitigation strategies\ntailored to IoT environments. Key solutions explored include IPv6 Unique Local\nAddresses (ULA), edge computing, software-defined networking (SDN), honeypot\ndeception, and machine learning-based intrusion detection systems. The paper\naims to help engineers and researchers understand and implement practical\ncountermeasures to protect IoT infrastructures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11772v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "如何在物联网设备中缓解和防御DDoS攻击", "tldr": "物联网DDoS攻击日益普遍且危险，本文分析了其性质和影响，并提出了包括IPv6 ULA、边缘计算、SDN、蜜罐和机器学习入侵检测在内的分层缓解策略，旨在帮助保护IoT基础设施。", "motivation": "分布式拒绝服务 (DDoS) 攻击在物联网 (IoT) 网络中变得越来越普遍和危险，这主要归因于许多连接设备的安全配置较低。", "method": "本文分析了DDoS攻击的性质和影响，并提出了针对物联网环境的分层缓解策略。关键解决方案包括IPv6唯一本地地址 (ULA)、边缘计算、软件定义网络 (SDN)、蜜罐欺骗和基于机器学习的入侵检测系统。", "result": "Not mentioned in abstract", "conclusion": "本文旨在帮助工程师和研究人员理解并实施实际对策以保护物联网基础设施。", "translation": "分布式拒绝服务 (DDoS) 攻击在物联网 (IoT) 网络中变得越来越普遍和危险，这主要归因于许多连接设备的安全配置较低。本文分析了DDoS攻击的性质和影响，例如Mirai僵尸网络发起的攻击，并提出了针对物联网环境的分层缓解策略。探讨的关键解决方案包括IPv6唯一本地地址 (ULA)、边缘计算、软件定义网络 (SDN)、蜜罐欺骗和基于机器学习的入侵检测系统。本文旨在帮助工程师和研究人员理解并实施实际对策以保护物联网基础设施。", "summary": "鉴于物联网设备低安全配置导致DDoS攻击日益猖獗，本文深入分析了DDoS攻击（如Mirai僵尸网络攻击）的特性与影响。为应对此挑战，论文提出了一系列针对物联网环境的分层缓解策略，具体包括采用IPv6 ULA、边缘计算、软件定义网络、蜜罐欺骗以及基于机器学习的入侵检测系统。其目标是为工程师和研究人员提供实用的对策，以有效保护物联网基础设施免受DDoS攻击。", "keywords": "DDoS攻击, 物联网安全, 缓解策略, Mirai僵尸网络, 入侵检测", "comments": "这篇论文的创新点在于提出了针对物联网环境的多种技术组合的分层防御策略，涵盖了网络层、计算层和检测层。其重要性在于直接应对了物联网安全中的核心挑战——DDoS攻击，并提供了实用的技术指导。"}}
{"id": "2502.17926", "title": "Fediverse Sharing: Cross-Platform Interaction Dynamics between Threads and Mastodon Users", "authors": ["Ujun Jeong", "Alimohammad Beigi", "Anique Tahir", "Susan Xu Tang", "H. Russell Bernard", "Huan Liu"], "categories": ["cs.SI", "cs.CY"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      Accepted to ASONAM'25 Multidisciplinary Track", "url": "http://arxiv.org/abs/2502.17926v2", "summary": "Traditional social media platforms, once envisioned as digital town squares,\nnow face growing criticism over corporate control, content moderation, and\nprivacy concerns. Events such as Twitter's acquisition (now X) and major policy\nchanges have pushed users toward alternative platforms like Mastodon and\nThreads. However, this diversification has led to user dispersion and\nfragmented discussions across the walled gardens of social media platforms. To\naddress these issues, federation protocols like ActivityPub have been adopted,\nwith Mastodon leading efforts to build decentralized yet interconnected\nnetworks. In March 2024, Threads joined this federation by introducing its\nFediverse Sharing service, which enables interactions such as posts, replies,\nand likes between Threads and Mastodon users as if on a unified platform.\nBuilding on this development, we study the interactions between 20,000+ Threads\nusers and 20,000+ Mastodon users over a ten-month period. Our work lays the\nfoundation for research on cross-platform interactions and federation-driven\nplatform integration.", "comment": "Accepted to ASONAM'25 Multidisciplinary Track", "pdf_url": "http://arxiv.org/pdf/2502.17926v2", "cate": "cs.SI", "date": "2025-02-25", "updated": "2025-07-16", "AI": {"title_translation": "Fediverse 共享：Threads 和 Mastodon 用户之间的跨平台互动动态", "tldr": "本研究探讨了 Threads 和 Mastodon 用户之间通过 Fediverse 共享功能实现的跨平台互动，以应对传统社交媒体的碎片化问题。", "motivation": "传统社交媒体平台面临企业控制、内容审查和隐私问题，导致用户分散和讨论碎片化。为了解决这些问题，去中心化协议如 ActivityPub 被采用，Threads 也加入了 Fediverse 共享服务，实现了跨平台互动。", "method": "研究人员在十个月的时间里，研究了超过 20,000 名 Threads 用户和超过 20,000 名 Mastodon 用户之间的互动。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "传统社交媒体平台，曾被设想为数字城镇广场，现在正面临着对企业控制、内容审查和隐私问题的日益增长的批评。Twitter 被收购（现为 X）和重大政策变化等事件，促使用户转向 Mastodon 和 Threads 等替代平台。然而，这种多样化导致了用户分散和社交媒体“围墙花园”内讨论的碎片化。为了解决这些问题，ActivityPub 等联邦协议已被采用，Mastodon 率先努力构建去中心化但相互连接的网络。2024 年 3 月，Threads 通过引入其 Fediverse 共享服务加入了这个联邦，该服务使得 Threads 和 Mastodon 用户之间能够像在统一平台上一样进行帖子、回复和点赞等互动。基于这一发展，我们研究了超过 20,000 名 Threads 用户和超过 20,000 名 Mastodon 用户在十个月期间的互动。我们的工作为跨平台互动和联邦驱动的平台集成研究奠定了基础。", "summary": "本研究旨在探讨 Threads 和 Mastodon 用户在 Fediverse 共享服务启用后的跨平台互动动态。鉴于传统社交媒体的弊端导致用户分散和信息碎片化，Threads 加入 Fediverse 联邦，通过 ActivityPub 协议实现了与 Mastodon 用户的无缝交流。研究人员在十个月内，分析了超过 20,000 名 Threads 用户和 20,000 名 Mastodon 用户之间的互动行为，旨在为未来的跨平台互动和联邦化平台集成研究奠定基础。", "keywords": "Fediverse, Threads, Mastodon, 跨平台互动, 社交媒体去中心化", "comments": "这项研究的重要性在于它关注了社交媒体去中心化和互操作性的新兴趋势，特别是在 Threads 加入 Fediverse 之后。它为理解不同去中心化平台之间的用户行为和互动模式提供了初步的洞察，有助于未来构建更开放、互联的数字生态系统。"}}
{"id": "2507.11967", "title": "Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos", "authors": ["Yuchi Ishikawa", "Shota Nakada", "Hokuto Munakata", "Kazuhiro Saito", "Tatsuya Komatsu", "Yoshimitsu Aoki"], "categories": ["cs.CV", "eess.AS", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Interspeech 2025", "url": "http://arxiv.org/abs/2507.11967v1", "summary": "In this paper, we propose Language-Guided Contrastive Audio-Visual Masked\nAutoencoders (LG-CAV-MAE) to improve audio-visual representation learning.\nLG-CAV-MAE integrates a pretrained text encoder into contrastive audio-visual\nmasked autoencoders, enabling the model to learn across audio, visual and text\nmodalities. To train LG-CAV-MAE, we introduce an automatic method to generate\naudio-visual-text triplets from unlabeled videos. We first generate frame-level\ncaptions using an image captioning model and then apply CLAP-based filtering to\nensure strong alignment between audio and captions. This approach yields\nhigh-quality audio-visual-text triplets without requiring manual annotations.\nWe evaluate LG-CAV-MAE on audio-visual retrieval tasks, as well as an\naudio-visual classification task. Our method significantly outperforms existing\napproaches, achieving up to a 5.6% improvement in recall@10 for retrieval tasks\nand a 3.2% improvement for the classification task.", "comment": "Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.11967v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "语言引导的对比式音视频掩码自编码器与视频中自动生成的音视频-文本三元组", "tldr": "提出LG-CAV-MAE，一种利用自动生成的音视频-文本三元组的音视频表示学习模型，性能优于现有方法。", "motivation": "为了改进音视频表示学习。", "method": "提出语言引导的对比式音视频掩码自编码器（LG-CAV-MAE），该模型将预训练文本编码器集成到对比式音视频掩码自编码器中，使其能够学习音频、视觉和文本模态之间的关系。引入了一种从无标注视频中自动生成音视频-文本三元组的方法，通过图像字幕模型生成帧级字幕，然后应用基于CLAP的过滤来确保音频和字幕之间的强对齐。", "result": "该方法在音视频检索任务中recall@10指标上实现了高达5.6%的提升，在分类任务中实现了3.2%的提升，显著优于现有方法。", "conclusion": "LG-CAV-MAE通过多模态集成和自动数据生成，有效改进了音视频表示学习，并取得了优异的性能。", "translation": "在本文中，我们提出了语言引导的对比式音视频掩码自编码器（LG-CAV-MAE）以改进音视频表示学习。LG-CAV-MAE将预训练文本编码器集成到对比式音视频掩码自编码器中，使模型能够学习音频、视觉和文本模态之间的关系。为了训练LG-CAV-MAE，我们引入了一种从无标注视频中自动生成音视频-文本三元组的方法。我们首先使用图像字幕模型生成帧级字幕，然后应用基于CLAP的过滤来确保音频和字幕之间的强对齐。这种方法无需手动标注即可生成高质量的音视频-文本三元组。我们在音视频检索任务以及音视频分类任务上评估了LG-CAV-MAE。我们的方法显著优于现有方法，在检索任务中recall@10指标上实现了高达5.6%的提升，在分类任务中实现了3.2%的提升。", "summary": "本文提出了LG-CAV-MAE，一种结合预训练文本编码器的对比式音视频掩码自编码器，旨在提升音视频表示学习能力。为训练该模型，研究者开发了一种自动生成高质量音视频-文本三元组的方法，该方法通过图像字幕生成帧级字幕并利用CLAP过滤进行对齐。实验证明，LG-CAV-MAE在音视频检索和分类任务上显著优于现有方法，性能提升显著。", "keywords": "音视频表示学习, 掩码自编码器, 语言引导, 三元组生成, 多模态", "comments": "该研究的创新点在于将预训练文本编码器集成到音视频掩码自编码器中，实现了跨模态学习，并提出了一种无需手动标注即可自动生成高质量音视频-文本三元组的方法。这对于大规模音视频表示学习具有重要意义，因为它大大降低了数据标注的成本和难度。"}}
{"id": "2507.11812", "title": "A Multimodal Data Fusion Generative Adversarial Network for Real Time Underwater Sound Speed Field Construction", "authors": ["Wei Huang", "Yuqiang Huang", "Yanan Wu", "Tianhe Xu", "Junting Wang", "Hao Zhang"], "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11812v1", "summary": "Sound speed profiles (SSPs) are essential parameters underwater that affects\nthe propagation mode of underwater signals and has a critical impact on the\nenergy efficiency of underwater acoustic communication and accuracy of\nunderwater acoustic positioning. Traditionally, SSPs can be obtained by\nmatching field processing (MFP), compressive sensing (CS), and deep learning\n(DL) methods. However, existing methods mainly rely on on-site underwater sonar\nobservation data, which put forward strict requirements on the deployment of\nsonar observation systems. To achieve high-precision estimation of sound\nvelocity distribution in a given sea area without on-site underwater data\nmeasurement, we propose a multi-modal data-fusion generative adversarial\nnetwork model with residual attention block (MDF-RAGAN) for SSP construction.\nTo improve the model's ability for capturing global spatial feature\ncorrelations, we embedded the attention mechanisms, and use residual modules\nfor deeply capturing small disturbances in the deep ocean sound velocity\ndistribution caused by changes of SST. Experimental results on real open\ndataset show that the proposed model outperforms other state-of-the-art\nmethods, which achieves an accuracy with an error of less than 0.3m/s.\nSpecifically, MDF-RAGAN not only outperforms convolutional neural network (CNN)\nand spatial interpolation (SITP) by nearly a factor of two, but also achieves\nabout 65.8\\% root mean square error (RMSE) reduction compared to mean profile,\nwhich fully reflects the enhancement of overall profile matching by\nmulti-source fusion and cross-modal attention.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11812v1", "cate": "cs.SD", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "一种用于实时水下声速场构建的多模态数据融合生成对抗网络", "tldr": "本文提出了一种名为MDF-RAGAN的多模态数据融合生成对抗网络，用于在没有现场水下数据测量的情况下高精度估计水下声速分布，并在真实数据集上表现优于现有SOTA方法。", "motivation": "水下声速剖面（SSPs）对水下信号传播模式、水声通信能效和水声定位精度至关重要。传统方法依赖于现场水下声呐观测数据，对部署要求严格。为在无现场测量数据的情况下实现高精度声速分布估计，本文提出了新方法。", "method": "本文提出了一种带有残差注意力块的多模态数据融合生成对抗网络模型（MDF-RAGAN）用于SSPs构建。为了提高模型捕获全局空间特征相关性的能力，嵌入了注意力机制；使用残差模块深层捕获由SST变化引起的深海声速分布中的微小扰动。", "result": "在真实开放数据集上的实验结果表明，所提出的模型优于其他最先进的方法，实现了小于0.3m/s的误差精度。具体而言，MDF-RAGAN的性能几乎是卷积神经网络（CNN）和空间插值（SITP）的两倍，并且与平均剖面相比，均方根误差（RMSE）降低了约65.8%。", "conclusion": "MDF-RAGAN模型通过多源融合和跨模态注意力，显著提升了整体剖面匹配能力，实现了在无现场数据测量条件下高精度水下声速场构建。", "translation": "声速剖面（SSPs）是水下重要的参数，影响水下信号的传播模式，对水下声学通信的能量效率和水下声学定位的精度具有关键影响。传统上，SSPs可以通过匹配场处理（MFP）、压缩感知（CS）和深度学习（DL）方法获得。然而，现有方法主要依赖于现场水下声呐观测数据，这对声呐观测系统的部署提出了严格要求。为了在没有现场水下数据测量的情况下实现给定海域声速分布的高精度估计，我们提出了一种带有残差注意力块的多模态数据融合生成对抗网络模型（MDF-RAGAN）用于SSPs构建。为了提高模型捕获全局空间特征相关性的能力，我们嵌入了注意力机制，并使用残差模块深层捕获由SST变化引起的深海声速分布中的微小扰动。在真实开放数据集上的实验结果表明，所提出的模型优于其他最先进的方法，实现了小于0.3m/s的误差精度。具体而言，MDF-RAGAN的性能几乎是卷积神经网络（CNN）和空间插值（SITP）的两倍，并且与平均剖面相比，均方根误差（RMSE）降低了约65.8%，这充分反映了多源融合和跨模态注意力对整体剖面匹配的增强。", "summary": "本文提出了一种名为MDF-RAGAN的多模态数据融合生成对抗网络，用于在无需现场水下数据测量的情况下构建高精度的水下声速剖面（SSPs）。该模型通过引入注意力机制增强全局空间特征捕获能力，并利用残差模块处理微小扰动。实验结果表明，MDF-RAGAN在精度上优于现有SOTA方法，误差小于0.3m/s，且性能显著优于CNN和SITP，RMSE相对平均剖面降低了65.8%。", "keywords": "声速剖面, 多模态数据融合, 生成对抗网络, 水下声速场, 残差注意力", "comments": "该论文的创新点在于提出了多模态数据融合的生成对抗网络（MDF-RAGAN），解决了传统方法对现场水下数据依赖性强的限制。通过结合注意力机制和残差模块，提高了模型在复杂海洋环境下的特征捕获能力和对微小扰动的敏感性。其在无现场测量数据条件下实现高精度声速估计的成果，对于水下通信和定位具有重要的实际应用价值。"}}
{"id": "2507.11853", "title": "A Spatial-Physics Informed Model for 3D Spiral Sample Scanned by SQUID Microscopy", "authors": ["J. Senthilnath", "Jayasanker Jayabalan", "Zhuoyi Lin", "Aye Phyu Phyu Aung", "Chen Hao", "Kaixin Xu", "Yeow Kheng Lim", "F. C. Wellstood"], "categories": ["physics.ins-det", "cs.CV"], "primary_category": "Subjects:       Instrumentation and Detectors (physics.ins-det)", "pdf_link": null, "comments": "Comments:      copyright 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "url": "http://arxiv.org/abs/2507.11853v1", "summary": "The development of advanced packaging is essential in the semiconductor\nmanufacturing industry. However, non-destructive testing (NDT) of advanced\npackaging becomes increasingly challenging due to the depth and complexity of\nthe layers involved. In such a scenario, Magnetic field imaging (MFI) enables\nthe imaging of magnetic fields generated by currents. For MFI to be effective\nin NDT, the magnetic fields must be converted into current density. This\nconversion has typically relied solely on a Fast Fourier Transform (FFT) for\nmagnetic field inversion; however, the existing approach does not consider eddy\ncurrent effects or image misalignment in the test setup. In this paper, we\npresent a spatial-physics informed model (SPIM) designed for a 3D spiral sample\nscanned using Superconducting QUantum Interference Device (SQUID) microscopy.\nThe SPIM encompasses three key components: i) magnetic image enhancement by\naligning all the \"sharp\" wire field signals to mitigate the eddy current effect\nusing both in-phase (I-channel) and quadrature-phase (Q-channel) images; (ii)\nmagnetic image alignment that addresses skew effects caused by any misalignment\nof the scanning SQUID microscope relative to the wire segments; and (iii) an\ninversion method for converting magnetic fields to magnetic currents by\nintegrating the Biot-Savart Law with FFT. The results show that the SPIM\nimproves I-channel sharpness by 0.3% and reduces Q-channel sharpness by 25%.\nAlso, we were able to remove rotational and skew misalignments of 0.30 in a\nreal image. Overall, SPIM highlights the potential of combining spatial\nanalysis with physics-driven models in practical applications.", "comment": "copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "pdf_url": "http://arxiv.org/pdf/2507.11853v1", "cate": "physics.ins-det", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "SQUID显微镜扫描3D螺旋样本的空间物理信息模型", "tldr": "提出了一种空间物理信息模型(SPIM)，通过结合图像增强、对准和改进的逆向方法，解决了SQUID显微镜下3D螺旋样本无损检测中磁场转换的挑战，有效改善了图像质量并纠正了错位。", "motivation": "现有磁场成像(MFI)在半导体先进封装无损检测(NDT)中，将磁场转换为电流密度的方法（仅依赖FFT）未考虑涡流效应和图像错位，导致检测挑战。", "method": "提出了一种空间物理信息模型(SPIM)，用于SQUID显微镜扫描的3D螺旋样本。该模型包含三个关键部分：i)通过对齐“尖锐”线场信号，利用同相(I)和正交相(Q)图像增强磁图像以减轻涡流效应；ii)解决扫描SQUID显微镜与线段错位引起的倾斜效应的磁图像对准；iii)将Biot-Savart定律与FFT相结合，实现磁场到磁电流的逆向转换方法。", "result": "SPIM将I通道的清晰度提高了0.3%，Q通道的清晰度降低了25%。此外，在实际图像中成功消除了0.30的旋转和倾斜错位。", "conclusion": "SPIM展示了在实际应用中结合空间分析与物理驱动模型的潜力。", "translation": "半导体制造业中先进封装的发展至关重要。然而，由于层深和复杂性，先进封装的无损检测（NDT）变得越来越具有挑战性。在这种情况下，磁场成像（MFI）能够对电流产生的磁场进行成像。为了使MFI在NDT中有效，磁场必须转换为电流密度。这种转换通常仅依赖快速傅里叶变换（FFT）进行磁场反演；然而，现有方法没有考虑涡流效应或测试设置中的图像错位。在本文中，我们提出了一种空间物理信息模型（SPIM），专为使用超导量子干涉器件（SQUID）显微镜扫描的3D螺旋样本设计。SPIM包含三个关键组件：i)通过对齐所有“尖锐”线场信号，利用同相（I通道）和正交相（Q通道）图像来减轻涡流效应，从而增强磁图像；ii)解决扫描SQUID显微镜相对于线段的任何错位引起的倾斜效应的磁图像对准；以及iii)通过将毕奥-萨伐尔定律与FFT相结合，将磁场转换为磁电流的反演方法。结果表明，SPIM将I通道的清晰度提高了0.3%，并将Q通道的清晰度降低了25%。此外，我们能够在真实图像中消除0.30的旋转和倾斜错位。总的来说，SPIM突出了在实际应用中结合空间分析与物理驱动模型的潜力。", "summary": "本文提出了一种空间物理信息模型（SPIM），用于解决SQUID显微镜扫描3D螺旋样本在先进封装无损检测中磁场到电流密度转换的挑战。该模型通过结合磁图像增强（处理涡流效应）、图像对准（纠正扫描错位）以及基于Biot-Savart定律和FFT的改进反演方法，显著提高了磁场成像的准确性和可靠性。实验结果表明，SPIM有效改善了I通道清晰度，降低了Q通道清晰度，并成功消除了图像错位，展示了其在实际应用中的巨大潜力。", "keywords": "空间物理信息模型, SQUID显微镜, 无损检测, 磁场成像, 涡流效应", "comments": "这篇论文的创新点在于提出了SPIM模型，它不仅解决了传统磁场反演方法中忽视的涡流效应和图像错位问题，还通过结合空间分析和物理定律（Biot-Savart Law）与FFT，提供了一个更全面和准确的解决方案。这对于半导体先进封装的无损检测具有重要意义，因为它能提高检测的可靠性和精度，有助于推动先进封装技术的发展。"}}
{"id": "2403.09040", "title": "RAGGED: Towards Informed Design of Scalable and Stable RAG Systems", "authors": ["Jennifer Hsia", "Afreen Shaikh", "Zhiruo Wang", "Graham Neubig"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2403.09040v3", "summary": "Retrieval-augmented generation (RAG) enhances language models by integrating\nexternal knowledge, but its effectiveness is highly dependent on system\nconfiguration. Improper retrieval settings can degrade performance, making RAG\nless reliable than closed-book generation. In this work, we introduce RAGGED, a\nframework for systematically evaluating RAG systems across diverse\nretriever-reader configurations, retrieval depths, and datasets. Our analysis\nreveals that reader robustness to noise is the key determinant of RAG stability\nand scalability. Some readers benefit from increased retrieval depth, while\nothers degrade due to their sensitivity to distracting content. Through\nlarge-scale experiments on open-domain, multi-hop, and specialized-domain\ndatasets, we show that retrievers, rerankers, and prompts influence performance\nbut do not fundamentally alter these reader-driven trends. By providing a\nprincipled framework and new metrics to assess RAG stability and scalability,\nRAGGED enables systematic evaluation of retrieval-augmented generation systems,\nguiding future research on optimizing retrieval depth and model robustness.", "comment": "Project page: https://github.com/neulab/ragged", "pdf_url": "http://arxiv.org/pdf/2403.09040v3", "cate": "cs.CL", "date": "2024-03-14", "updated": "2025-07-16", "AI": {"title_translation": "RAGGED：迈向可扩展和稳定的RAG系统知情设计", "tldr": "RAGGED是一个评估RAG系统的框架，发现阅读器对噪声的鲁棒性是RAG稳定性与可扩展性的关键，并提供新指标指导未来优化。", "motivation": "RAG系统效果高度依赖配置，不当的检索设置会降低性能，甚至不如闭卷生成，因此需要系统性评估以提升其可靠性。", "method": "引入RAGGED框架，系统性评估RAG系统在不同检索器-阅读器配置、检索深度和数据集上的表现。", "result": "分析表明，阅读器对噪声的鲁棒性是RAG稳定性与可扩展性的关键决定因素。某些阅读器受益于增加检索深度，而另一些则因对干扰内容敏感而性能下降。大规模实验显示，检索器、重排序器和提示语会影响性能，但不会从根本上改变这些由阅读器驱动的趋势。", "conclusion": "RAGGED通过提供一个有原则的框架和新指标来评估RAG的稳定性与可扩展性，从而实现对检索增强生成系统的系统性评估，指导未来优化检索深度和模型鲁棒性的研究。", "translation": "检索增强生成（RAG）通过整合外部知识来增强语言模型，但其有效性高度依赖于系统配置。不当的检索设置会降低性能，使RAG不如闭卷生成可靠。在这项工作中，我们引入了RAGGED，一个用于系统性评估RAG系统在不同检索器-阅读器配置、检索深度和数据集上的框架。我们的分析揭示，阅读器对噪声的鲁棒性是RAG稳定性与可扩展性的关键决定因素。一些阅读器受益于增加检索深度，而另一些则由于对干扰内容的敏感性而性能下降。通过在开放域、多跳和专业领域数据集上进行大规模实验，我们表明检索器、重排序器和提示语会影响性能，但不会从根本上改变这些由阅读器驱动的趋势。通过提供一个有原则的框架和新指标来评估RAG的稳定性与可扩展性，RAGGED实现了对检索增强生成系统的系统性评估，指导未来优化检索深度和模型鲁棒性的研究。", "summary": "本文提出了RAGGED框架，旨在系统性评估检索增强生成（RAG）系统的性能、稳定性和可扩展性。研究发现，RAG系统的稳定性和可扩展性主要取决于阅读器对噪声的鲁棒性，而非检索器、重排序器或提示语。RAGGED提供了一套原则性框架和新指标，以指导RAG系统的未来优化研究，尤其是在检索深度和模型鲁棒性方面。", "keywords": "检索增强生成, RAG, 系统评估, 鲁棒性, 可扩展性", "comments": "RAGGED框架的创新之处在于其提供了一个系统性评估RAG系统的方法，并引入了评估稳定性和可扩展性的新指标。其重要发现是揭示了阅读器对噪声的鲁棒性是RAG系统性能的关键瓶颈，这为未来RAG系统的设计和优化指明了方向，即应更关注阅读器本身的鲁棒性而非仅仅是检索策略。"}}
{"id": "2507.11775", "title": "Challenges in GenAI and Authentication: a scoping review", "authors": ["Wesley dos Reis Bezerra", "Lais Machado Bezerra", "Carlos Becker Westphall"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11775v1", "summary": "Authentication and authenticity have been a security challenge since the\nbeginning of information sharing, especially in the context of digital\ninformation. With the advancement of generative artificial intelligence, these\nchallenges have evolved, demanding a more up-to-date analysis of their impacts\non society and system security. This work presents a scoping review that\nanalyzed 88 documents from the IEEExplorer, Scopus, and ACM databases,\npromoting an analysis of the resulting portfolio through six guiding questions\nfocusing on the most relevant work, challenges, attack surfaces, threats,\nproposed solutions, and gaps. Finally, the portfolio articles are analyzed\nthrough this guiding research lens and also receive individualized analysis.\nThe results consistently outline the challenges, gaps, and threats related to\nimages, text, audio, and video, thereby supporting new research in the areas of\nauthentication and generative artificial intelligence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11775v1", "cate": "cs.CR", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "生成式人工智能与认证中的挑战：一项范围界定审查", "tldr": "本文对生成式人工智能和认证领域面临的挑战、威胁、解决方案和研究空白进行了范围界定审查，分析了88份文献。", "motivation": "随着生成式人工智能的进步，数字信息共享中的认证和真实性挑战日益演变，需要对这些挑战对社会和系统安全的影响进行最新分析。", "method": "本文进行了一项范围界定审查，分析了来自IEEExplorer、Scopus和ACM数据库的88份文献。通过六个指导性问题对文献组合进行了分析，这些问题关注最相关的工作、挑战、攻击面、威胁、提议的解决方案和研究空白，并对每篇文章进行了单独分析。", "result": "结果一致地概述了与图像、文本、音频和视频相关的挑战、空白和威胁。", "conclusion": "这项审查支持了认证和生成式人工智能领域的新研究，通过明确识别现有挑战、差距和威胁。", "translation": "认证和真实性自信息共享伊始，尤其是在数字信息背景下，一直是安全挑战。随着生成式人工智能的进步，这些挑战已经演变，需要对它们对社会和系统安全的影响进行更及时的分析。这项工作提出了一项范围界定审查，分析了来自IEEExplorer、Scopus和ACM数据库的88份文献，通过六个指导性问题对所得文献组合进行了分析，这些问题侧重于最相关的工作、挑战、攻击面、威胁、提议的解决方案和研究空白。最后，通过这一指导性研究视角对文献组合文章进行了分析，并进行了个性化分析。结果一致地概述了与图像、文本、音频和视频相关的挑战、空白和威胁，从而支持了认证和生成式人工智能领域的新研究。", "summary": "本文对生成式人工智能（GenAI）背景下的认证和真实性挑战进行了范围界定审查。研究分析了来自三大数据库的88份文献，旨在识别与GenAI相关的挑战、威胁、攻击面、现有解决方案和研究空白，特别是在图像、文本、音频和视频方面。该审查为未来在认证和GenAI交叉领域的研究提供了基础。", "keywords": "生成式人工智能, 认证, 范围界定审查, 安全挑战, 数字信息", "comments": "这项研究通过全面的范围界定审查，系统地识别了生成式人工智能在认证和真实性方面带来的新挑战。其创新之处在于将传统的认证问题与新兴的GenAI技术相结合，并明确了图像、文本、音频和视频等多种媒体形式的具体威胁。这项工作对于指导未来GenAI安全领域的研究方向具有重要意义，填补了现有知识的空白。"}}
{"id": "2507.11798", "title": "On QoE-Aware Traffic Management for Real-time, Interactive Video with Time-variant Spatial Complexity", "authors": ["Szilveszter Nádas", "Lars Ernström", "David Lindero", "Jonathan Lynam"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11798v1", "summary": "We analyzed spatial complexity, defined as the relationship between the\nrequired bitrate and a corresponding picture Quality of Experience (QoE)\nmetric, for realistic, long, real-time, interactive video clips. Apart from\nvariation across different content types, e.g., game genres, we discovered\ntime-variability within a clip from second to second, and explored the\nramifications for traffic management. We introduced utility as an elegant way\nto manage resource sharing preferences. Our analysis of resource sharing\nmethods shows that frequent QoE-aware reallocation has significant performance\nadvantages compared to static rate allocation, even in case the latter is based\non rich information about long-term average spatial complexity. We have also\nshown that utility-based resource allocation has clear advantages over methods\ntargeting equal QoE allocation, it increases the average QoE, while it still\ncontrols the worst case QoE.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11798v1", "cate": "cs.NI", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "关于实时交互式视频中考虑QoE且具有时变空间复杂度的流量管理", "tldr": "研究了实时交互式视频的时变空间复杂度及其对流量管理的影响，提出并验证了基于QoE的动态资源分配和基于效用的分配方法优于静态或等QoE分配。", "motivation": "论文旨在分析实时交互式视频的空间复杂度，并探索其时变性对流量管理的影响，以优化用户体验质量（QoE）。", "method": "研究分析了实时交互式视频的空间复杂度，并将其定义为所需比特率与QoE指标之间的关系。引入了“效用”作为管理资源共享偏好的方法。通过比较资源共享方法，研究了频繁的QoE感知重分配与静态速率分配，以及基于效用的资源分配与目标等QoE分配的性能。", "result": "发现实时交互式视频的空间复杂度在剪辑内部存在秒级时变性。与基于长期平均空间复杂度的静态速率分配相比，频繁的QoE感知重分配具有显著的性能优势。基于效用的资源分配比目标等QoE分配具有明显的优势，它能提高平均QoE，同时仍能控制最差情况下的QoE。", "conclusion": "考虑到实时交互式视频的时变空间复杂度，频繁的QoE感知和基于效用的资源分配是优化流量管理和提升用户体验质量的有效方法。", "translation": "我们分析了真实、长时、实时、交互式视频片段的空间复杂度，将其定义为所需比特率与相应的体验质量（QoE）指标之间的关系。除了不同内容类型（例如，游戏类型）之间的变化外，我们发现在剪辑内部存在秒级的时变性，并探讨了其对流量管理的影响。我们引入了效用作为一种优雅的方式来管理资源共享偏好。我们对资源共享方法的分析表明，与静态速率分配相比，频繁的QoE感知重分配具有显著的性能优势，即使后者是基于关于长期平均空间复杂度的丰富信息。我们还表明，基于效用的资源分配比目标等QoE分配的方法具有明显的优势，它提高了平均QoE，同时仍然控制了最差情况下的QoE。", "summary": "本文分析了实时交互式视频中时变空间复杂度（比特率与QoE的关系）对流量管理的影响。研究发现，视频内容的空间复杂度在短时间内也存在显著变化。为应对此挑战，论文引入了“效用”概念来优化资源共享，并证明了频繁的QoE感知动态重分配以及基于效用的资源分配方法，相比于静态分配或追求相等QoE的分配方式，能显著提升平均QoE并有效控制最差QoE，从而优化了实时视频的用户体验质量。", "keywords": "QoE, 流量管理, 实时视频, 空间复杂度, 资源分配", "comments": "这篇论文的创新点在于揭示了实时交互式视频空间复杂度的时变性，并提出了基于QoE的动态重分配和基于效用的资源分配策略。这些方法为优化实时视频的流量管理提供了新的视角和有效的解决方案，对于提升用户在复杂网络环境下的体验质量具有重要意义。其研究结果直接挑战了基于静态或平均复杂度进行资源分配的传统做法，强调了动态感知和调整的重要性。"}}
{"id": "2507.12106", "title": "Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso", "authors": ["Antonio Salis", "Gabriele Troina", "Gianluca Boanelli", "Marco Ottaviano", "Paola Fortini", "Soraya Versace"], "categories": ["cs.DC", "cs.CY"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      18 pages, 6 Figures", "url": "http://arxiv.org/abs/2507.12106v1", "summary": "The efficient design and management of public green spaces is a key factor in\npromoting the health and well-being of urban population, as emphasized by the\nWHO, UNEP, and EEA. These areas serve as the \"green lungs\" of the urban\necosystem, playing a vital role in enhancing quality of life thanks to the\nprovision of ecosystem services. In this context, the Smart Green City use case\nin Campobasso municipality, funded by the Italian Ministry of Enterprises\n(MIMIT), emerges as an innovative model for the sustainable management of green\nurban areas through the adoption of an advanced system of emerging technologies\nintegrated and interoperable. The project integrates IoT systems and\ndata-driven governance platforms, enabling real-time monitoring of the health\nstatus of trees and green areas via a Decision Support System (DSS). It also\nfacilitates the collection and analysis of data from diverse sources, including\nweather conditions, air quality, soil moisture, pollution levels. The resulting\ncloud-based platform supports a holistic real time decision making for green\nurban managers, technical experts and operational staff. It enables intelligent\ncontrol and management of urban green spaces using Tree Talker sensors,\nintegrated with soil moisture and water potential monitoring systems. Thanks to\npredictive models based on machine learning algorithms and real time data\nprovided by IoT sensors, irrigation of public parks can be optimized by\nproviding suggestions on when and how much water to apply. Customized alerts\nlayers are also activated warning users when monitored parameters, such as soil\ntemperature, humidity, or water potential, exceed predefined thresholds. This\nUse Case demonstrates how digitalization, IoT sensors fusion and technological\ninnovation can support sustainable urban governance, fostering environmental\nresilience and improving citizens quality of life.", "comment": "18 pages, 6 Figures", "pdf_url": "http://arxiv.org/pdf/2507.12106v1", "cate": "cs.DC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "城市绿色治理：物联网驱动的坎波巴索城市绿地管理与提升", "tldr": "该项目在坎波巴索利用物联网和数据驱动平台，实现城市绿地的实时监测和智能管理，优化灌溉，提高城市环境韧性与市民生活质量。", "motivation": "城市绿地的有效设计和管理对促进城市人口健康福祉至关重要，并提供生态系统服务。坎波巴索的Smart Green City项目旨在通过先进技术实现城市绿地的可持续管理。", "method": "该项目整合物联网系统和数据驱动的治理平台，通过决策支持系统(DSS)实时监测树木和绿地健康状况。它收集并分析来自多种来源（天气、空气质量、土壤湿度、污染）的数据。利用Tree Talker传感器、土壤湿度和水势监测系统，结合机器学习算法和物联网传感器实时数据，优化公共公园灌溉，并提供定制警报。", "result": "实现了对绿地的实时监测、数据收集与分析，支持绿地管理者的整体实时决策。优化了公共公园灌溉，并能提供超阈值警报。", "conclusion": "该用例展示了数字化、物联网传感器融合和技术创新如何支持可持续的城市治理，促进环境韧性并改善公民生活质量。", "translation": "公共绿地的有效设计和管理是促进城市人口健康和福祉的关键因素，这一点得到了世界卫生组织、联合国环境规划署和欧洲环境署的强调。这些区域作为城市生态系统的“绿色肺”，通过提供生态系统服务在提高生活质量方面发挥着至关重要的作用。在此背景下，由意大利企业部（MIMIT）资助的坎波巴索市“智慧绿色城市”用例，通过采用先进的集成和可互操作的新兴技术系统，成为城市绿地可持续管理的一个创新模式。该项目整合了物联网系统和数据驱动的治理平台，通过决策支持系统（DSS）实现对树木和绿地健康状况的实时监测。它还促进了从各种来源（包括天气条件、空气质量、土壤湿度、污染水平）收集和分析数据。由此产生的基于云的平台支持绿地管理者、技术专家和操作人员进行全面的实时决策。它使用Tree Talker传感器，并与土壤湿度和水势监测系统集成，实现城市绿地的智能控制和管理。得益于基于机器学习算法和物联网传感器提供的实时数据的预测模型，可以通过提供何时以及施用多少水的建议来优化公共公园的灌溉。当监测参数（如土壤温度、湿度或水势）超过预设阈值时，还会激活定制的警报层以警告用户。该用例展示了数字化、物联网传感器融合和技术创新如何支持可持续的城市治理，促进环境韧性并改善公民生活质量。", "summary": "本文介绍了坎波巴索市的“智慧绿色城市”项目，该项目利用物联网和数据驱动平台，实现城市绿地的可持续管理。通过实时监测树木和绿地健康状况、收集多源环境数据，并结合机器学习模型优化灌溉和提供预警，该项目展示了数字化和技术创新如何提升城市绿地治理，从而改善城市环境韧性和居民生活质量。", "keywords": "城市绿色治理, 物联网, 智慧城市, 绿地管理, 数据驱动", "comments": "这篇论文展示了一个将物联网、数据分析和机器学习应用于城市绿地管理与提升的实际案例。其创新点在于整合多种传感器和数据源，构建了一个支持实时决策的云平台，并利用预测模型优化资源（如水）使用，显著提高了城市绿化管理的智能化和可持续性。该项目为其他城市提供了可借鉴的智慧城市建设模式。"}}
{"id": "2507.12197", "title": "Quantize More, Lose Less: Autoregressive Generation from Residually Quantized Speech Representations", "authors": ["Yichen Han", "Xiaoyang Hao", "Keming Chen", "Weibo Xiong", "Jun He", "Ruonan Zhang", "Junjie Cao", "Yue Liu", "Bowen Li", "Dongrui Zhang", "Hui Xia", "Huilei Fu", "Kai Jia", "Kaixuan Guo", "Mingli Jin", "Qingyun Meng", "Ruidong Ma", "Ruiqian Fang", "Shaotong Guo", "Xuhui Li", "Yang Xiang", "Ying Zhang", "Yulong Liu", "Yunfeng Li", "Yuyi Zhang", "Yuze Zhou", "Zhen Wang", "Zhaowen Chen"], "categories": ["cs.SD", "cs.AI"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12197v1", "summary": "Text-to-speech (TTS) synthesis has seen renewed progress under the discrete\nmodeling paradigm. Existing autoregressive approaches often rely on\nsingle-codebook representations, which suffer from significant information\nloss. Even with post-hoc refinement techniques such as flow matching, these\nmethods fail to recover fine-grained details (e.g., prosodic nuances,\nspeaker-specific timbres), especially in challenging scenarios like singing\nvoice or music synthesis. We propose QTTS, a novel TTS framework built upon our\nnew audio codec, QDAC. The core innovation of QDAC lies in its end-to-end\ntraining of an ASR-based auto-regressive network with a GAN, which achieves\nsuperior semantic feature disentanglement for scalable, near-lossless\ncompression. QTTS models these discrete codes using two innovative strategies:\nthe Hierarchical Parallel architecture, which uses a dual-AR structure to model\ninter-codebook dependencies for higher-quality synthesis, and the Delay\nMultihead approach, which employs parallelized prediction with a fixed delay to\naccelerate inference speed. Our experiments demonstrate that the proposed\nframework achieves higher synthesis quality and better preserves expressive\ncontent compared to baseline. This suggests that scaling up compression via\nmulti-codebook modeling is a promising direction for high-fidelity,\ngeneral-purpose speech and audio generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12197v1", "cate": "cs.SD", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "量化更多，损失更少：基于残差量化语音表示的自回归生成", "tldr": "QTTS框架利用新型QDAC编解码器和创新的多码本建模策略（分层并行与延迟多头），解决了现有自回归TTS因单码本造成的信息损失问题，实现了更高质量和更快的语音合成。", "motivation": "现有自回归文本到语音（TTS）方法依赖单码本表示，导致严重信息损失，无法恢复细粒度细节（如韵律、音色），尤其在唱歌或音乐合成等挑战性场景中表现不佳。", "method": "提出QTTS框架，基于新型音频编解码器QDAC。QDAC通过ASR-based自回归网络与GAN进行端到端训练，实现语义特征解耦和近无损压缩。QTTS使用分层并行（Hierarchical Parallel）架构（双AR结构建模码本间依赖）和延迟多头（Delay Multihead）方法（固定延迟并行预测加速推理）对离散码进行建模。", "result": "实验表明，所提出的QTTS框架与基线方法相比，实现了更高的合成质量和更好的表达内容保留。", "conclusion": "通过多码本建模扩展压缩是实现高保真、通用语音和音频生成的一个有前景的方向。", "translation": "文本到语音（TTS）合成在离散建模范式下取得了新的进展。现有的自回归方法通常依赖于单码本表示，这会导致严重的信息损失。即使采用流匹配等事后细化技术，这些方法也无法恢复细粒度细节（例如，韵律细微差别、特定说话人音色），尤其是在歌唱或音乐合成等挑战性场景中。我们提出了QTTS，一个基于我们新型音频编解码器QDAC构建的创新TTS框架。QDAC的核心创新在于其将基于ASR的自回归网络与GAN进行端到端训练，从而实现卓越的语义特征解耦，实现可扩展的、近乎无损的压缩。QTTS使用两种创新策略对这些离散码进行建模：分层并行（Hierarchical Parallel）架构，它使用双自回归（dual-AR）结构来建模码本间依赖以实现更高质量的合成；以及延迟多头（Delay Multihead）方法，它采用固定延迟的并行预测来加速推理速度。我们的实验表明，所提出的框架与基线相比，实现了更高的合成质量和更好的表达内容保留。这表明通过多码本建模扩展压缩是实现高保真、通用语音和音频生成的一个有前景的方向。", "summary": "本文提出了QTTS，一个新型文本到语音（TTS）框架，旨在解决现有自回归方法因单码本表示导致的信息损失问题。QTTS基于创新的音频编解码器QDAC，该编解码器通过端到端训练实现近无损压缩和语义特征解耦。QTTS进一步采用分层并行架构和延迟多头方法来建模离散码，从而提高合成质量和加速推理。实验证明QTTS在合成质量和表达内容保留方面优于现有基线，表明多码本建模是高保真语音生成的一个有效方向。", "keywords": "文本到语音, 自回归生成, 多码本, 语音压缩, QDAC", "comments": "QTTS的创新点在于其多码本建模策略和端到端训练的QDAC编解码器，有效解决了传统TTS在细粒度细节上信息损失的问题。双AR结构和延迟多头方法兼顾了质量和效率。该工作为高保真、通用语音和音频生成提供了新的思路和有效方案。"}}
{"id": "2312.14628", "title": "Holistic analysis on the sustainability of Federated Learning across AI product lifecycle", "authors": ["Hongliu Cao"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted in ECAI 2025 (PAIS track)", "url": "http://arxiv.org/abs/2312.14628v3", "summary": "In light of emerging legal requirements and policies focused on privacy\nprotection, there is a growing trend of companies across various industries\nadopting Federated Learning (FL). This decentralized approach involves multiple\nclients or silos, collaboratively training a global model under the\ncoordination of a central server while utilizing their private local data.\nUnlike traditional methods that necessitate data sharing and transmission,\nCross-Silo FL allows clients to share model updates rather than raw data,\nthereby enhancing privacy. Despite its growing adoption, the carbon impact\nassociated with Cross-Silo FL remains poorly understood due to the limited\nresearch in this area. This study seeks to bridge this gap by evaluating the\nsustainability of Cross-Silo FL throughout the entire AI product lifecycle,\nextending the analysis beyond the model training phase alone. We systematically\ncompare this decentralized method with traditional centralized approaches and\npresent a robust quantitative framework for assessing the costs and CO2\nemissions in real-world Cross-Silo FL environments. Our findings indicate that\nthe energy consumption and costs of model training are comparable between\nCross-Silo Federated Learning and Centralized Learning. However, the additional\ndata transfer and storage requirements inherent in Centralized Learning can\nresult in significant, often overlooked CO2 emissions. Moreover, we introduce\nan innovative data and application management system that integrates Cross-Silo\nFL and analytics, aiming at improving the sustainability and economic\nefficiency of IT enterprises.", "comment": "Accepted in ECAI 2025 (PAIS track)", "pdf_url": "http://arxiv.org/pdf/2312.14628v3", "cate": "cs.LG", "date": "2023-12-22", "updated": "2025-07-16", "AI": {"title_translation": "人工智能产品生命周期中联邦学习可持续性的整体分析", "tldr": "本研究全面评估了联邦学习在人工智能产品生命周期中的可持续性，发现其在数据传输和存储方面比集中式学习更具环境优势，并提出了一个创新系统以提高效率。", "motivation": "鉴于隐私保护的法律要求和政策日益增长，联邦学习被广泛采用。然而，其碳影响，特别是在整个AI产品生命周期中的可持续性，仍未被充分理解。本研究旨在弥补这一空白。", "method": "本研究通过评估跨筒仓联邦学习在整个AI产品生命周期中的可持续性，将其与传统集中式方法进行系统比较。文章提出了一个强大的定量框架，用于评估实际跨筒仓联邦学习环境中的成本和二氧化碳排放。此外，还引入了一个集成跨筒仓联邦学习和分析的数据与应用管理系统。", "result": "研究结果表明，跨筒仓联邦学习与集中式学习在模型训练的能耗和成本上具有可比性。然而，集中式学习固有的额外数据传输和存储要求会导致显著且常常被忽视的二氧化碳排放。此外，还引入了一个创新的数据和应用管理系统，旨在提高IT企业的可持续性和经济效率。", "conclusion": "联邦学习在整个AI产品生命周期中，尤其是在数据传输和存储方面，比传统集中式学习更具可持续性，有助于提高IT企业的可持续性和经济效率。", "translation": "鉴于新兴的专注于隐私保护的法律要求和政策，各行各业的公司越来越倾向于采用联邦学习（FL）。这种去中心化方法涉及多个客户端或数据孤岛，在中央服务器的协调下，利用其私有本地数据协同训练一个全局模型。与需要数据共享和传输的传统方法不同，跨筒仓联邦学习允许客户端共享模型更新而非原始数据，从而增强了隐私性。尽管其日益普及，但由于该领域研究有限，与跨筒仓联邦学习相关的碳影响仍知之甚少。本研究旨在弥补这一空白，通过评估跨筒仓联邦学习在整个AI产品生命周期中的可持续性，将分析范围扩展到模型训练阶段之外。我们系统地将这种去中心化方法与传统的集中式方法进行比较，并提出了一个强大的定量框架，用于评估实际跨筒仓联邦学习环境中的成本和二氧化碳排放。我们的研究结果表明，跨筒仓联邦学习与集中式学习在模型训练的能耗和成本上具有可比性。然而，集中式学习固有的额外数据传输和存储要求会导致显著且常常被忽视的二氧化碳排放。此外，我们引入了一个创新的数据和应用管理系统，该系统集成了跨筒仓联邦学习和分析，旨在提高IT企业的可持续性和经济效率。", "summary": "本研究全面分析了联邦学习（FL）在整个AI产品生命周期中的可持续性，以应对日益增长的隐私保护需求和对FL碳足迹的认知不足。通过与传统集中式学习的比较，并引入定量框架，研究发现FL在模型训练能耗和成本上与集中式学习相当，但在数据传输和存储方面能显著减少二氧化碳排放。论文还提出了一个创新系统以提升可持续性和经济效率。", "keywords": "联邦学习, 可持续性, AI产品生命周期, 碳排放, 集中式学习", "comments": "该论文的创新之处在于首次对联邦学习在整个AI产品生命周期中的可持续性进行了全面评估，而不仅仅局限于模型训练阶段。其量化框架和对数据传输/存储碳排放的关注，为评估去中心化AI系统的环境影响提供了重要视角。这对于推动更环保的AI部署具有重要意义。"}}
{"id": "2507.11962", "title": "Structured First-Layer Initialization Pre-Training Techniques to Accelerate Training Process Based on $\\varepsilon$-Rank", "authors": ["Tao Tang", "Jiang Yang", "Yuxiang Zhao", "Quanhui Zhu"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11962v1", "summary": "Training deep neural networks for scientific computing remains\ncomputationally expensive due to the slow formation of diverse feature\nrepresentations in early training stages. Recent studies identify a staircase\nphenomenon in training dynamics, where loss decreases are closely correlated\nwith increases in $\\varepsilon$-rank, reflecting the effective number of\nlinearly independent neuron functions. Motivated by this observation, this work\nproposes a structured first-layer initialization (SFLI) pre-training method to\nenhance the diversity of neural features at initialization by constructing\n$\\varepsilon$-linearly independent neurons in the input layer. We present\nsystematic initialization schemes compatible with various activation functions\nand integrate the strategy into multiple neural architectures, including\nmodified multi-layer perceptrons and physics-informed residual adaptive\nnetworks. Extensive numerical experiments on function approximation and PDE\nbenchmarks, demonstrate that SFLI significantly improves the initial\n$\\varepsilon$-rank, accelerates convergence, mitigates spectral bias, and\nenhances prediction accuracy. With the help of SILP, we only need to add one\nline of code to conventional existing algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11962v1", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于$\\varepsilon$-秩的结构化首层初始化预训练技术以加速训练过程", "tldr": "提出一种基于$\\varepsilon$-秩的结构化首层初始化预训练方法SFLI，通过增强初始化时的神经元多样性来加速深度神经网络训练并提高性能。", "motivation": "深度神经网络在科学计算中的训练计算成本高昂，因为早期训练阶段多样化特征表示形成缓慢。研究发现训练动态中的“阶梯现象”与$\\varepsilon$-秩的增加密切相关，$\\varepsilon$-秩反映了线性独立神经元函数的有效数量。", "method": "提出结构化首层初始化（SFLI）预训练方法，通过在输入层构建$\\varepsilon$-线性独立神经元来增强初始化时的特征多样性。该方法提供与各种激活函数兼容的系统初始化方案，并可集成到改进的多层感知器和物理信息残差自适应网络等多种神经网络架构中。", "result": "SFLI显著提高了初始$\\varepsilon$-秩，加速了收敛，缓解了谱偏差，并提高了预测精度。", "conclusion": "SFLI是一种有效且易于实现的预训练技术，能够显著改善深度神经网络的训练效率和性能。", "translation": "深度神经网络在科学计算中的训练仍然计算成本高昂，原因在于早期训练阶段多样化特征表示形成缓慢。最近的研究发现了训练动态中的“阶梯现象”，其中损失的减少与$\\varepsilon$-秩的增加密切相关，$\\varepsilon$-秩反映了线性独立神经元函数的有效数量。受此观察启发，本工作提出了一种结构化首层初始化（SFLI）预训练方法，通过在输入层构建$\\varepsilon$-线性独立神经元，以增强初始化时神经网络特征的多样性。我们提出了与各种激活函数兼容的系统初始化方案，并将该策略集成到多种神经网络架构中，包括改进的多层感知器和物理信息残差自适应网络。在函数逼近和偏微分方程基准上的大量数值实验表明，SFLI显著提高了初始$\\varepsilon$-秩，加速了收敛，缓解了谱偏差，并提高了预测精度。借助SFLI，我们只需在现有传统算法中添加一行代码。", "summary": "本文提出了一种名为结构化首层初始化（SFLI）的预训练方法，旨在解决深度神经网络在科学计算中训练成本高昂的问题。该方法通过在神经网络输入层构建$\\varepsilon$-线性独立神经元，增强初始化时的特征多样性，从而提高初始$\\varepsilon$-秩。实验证明，SFLI能显著加速模型收敛，缓解谱偏差，并提高预测精度，且易于实现，只需添加一行代码。", "keywords": "$\\varepsilon$-秩, 结构化初始化, 预训练, 神经网络, 训练加速", "comments": "这项工作提出了一种创新且实用的预训练技术，通过关注神经网络第一层的初始化多样性来加速训练。其重要性在于，它不仅基于对$\\varepsilon$-秩的深入理解，还提供了易于实现的解决方案（“只需添加一行代码”），这对于实际应用具有显著价值。"}}
{"id": "2507.11908", "title": "Unveiling Usability Challenges in Web Privacy Controls", "authors": ["Rahat Masood", "Sunday Oyinlola Ogundoyin", "Muhammad Ikram", "Alex Ye"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11908v1", "summary": "With the increasing concerns around privacy and the enforcement of data\nprivacy laws, many websites now provide users with privacy controls. However,\nlocating these controls can be challenging, as they are frequently hidden\nwithin multiple settings and layers. Moreover, the lack of standardization\nmeans these controls can vary widely across services. The technical or\nconfusing terminology used to describe these controls further complicates\nusers' ability to understand and use them effectively. This paper presents a\nlarge-scale empirical analysis investigating usability challenges of web\nprivacy controls across 18,628 websites. While aiming for a multi-scenario\nview, our automated data collection faced significant hurdles, particularly in\nsimulating sign-up and authenticated user visits, leading to more focused\ninsights on guest visit scenarios and challenges in automated capture of\ndynamic user interactions. Our heuristic evaluation of three different user\nvisit scenarios identifies significant website usability issues. Our results\nshow that privacy policies are most common across all visit scenarios, with\nnudges and notices being prevalent in sign-up situations. We recommend\ndesigning privacy controls that: enhance awareness through pop-up nudges and\nnotices; offer a table of contents as navigational aids and customized settings\nlinks in policies for more informed choice; and ensure accessibility via direct\nlinks to privacy settings from nudges.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11908v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "揭示网络隐私控制中的可用性挑战", "tldr": "本文对网络隐私控制的可用性问题进行了大规模分析，发现它们难以定位和理解，并提出了改进设计建议。", "motivation": "随着对隐私的日益关注和数据隐私法的实施，许多网站提供了隐私控制。然而，这些控制通常难以找到、缺乏标准化，并且使用技术性或令人困惑的术语，导致用户难以有效理解和使用。", "method": "本文对18,628个网站的网络隐私控制可用性挑战进行了大规模实证分析。研究使用了自动化数据收集，但由于模拟注册和认证用户访问面临挑战，因此更侧重于访客访问场景。此外，还对三种不同用户访问场景进行了启发式评估。", "result": "研究发现，隐私政策在所有访问场景中最为常见，而弹出提示和通知在注册情况下更为普遍。识别出了显著的网站可用性问题。", "conclusion": "建议设计隐私控制时，应通过弹出提示和通知增强用户意识；在政策中提供目录作为导航辅助工具和自定义设置链接，以供用户做出更明智的选择；并通过从提示直接链接到隐私设置来确保可访问性。", "translation": "随着对隐私的日益关注以及数据隐私法的实施，许多网站现在为用户提供了隐私控制。然而，找到这些控制可能具有挑战性，因为它们经常隐藏在多个设置和层级中。此外，缺乏标准化意味着这些控制在不同服务之间可能差异很大。用于描述这些控制的技术性或令人困惑的术语进一步复杂化了用户有效理解和使用它们的能力。本文对18,628个网站的网络隐私控制可用性挑战进行了大规模实证分析。尽管旨在实现多场景视图，但我们的自动化数据收集面临重大障碍，特别是在模拟注册和认证用户访问方面，这导致我们更侧重于访客访问场景以及动态用户交互的自动化捕获挑战。我们对三种不同用户访问场景的启发式评估发现了显著的网站可用性问题。我们的结果表明，隐私政策在所有访问场景中最为常见，而在注册情况下，提示和通知更为普遍。我们建议设计隐私控制时：通过弹出提示和通知增强用户意识；在政策中提供目录作为导航辅助工具和自定义设置链接以供用户做出更明智的选择；并通过从提示直接链接到隐私设置来确保可访问性。", "summary": "本文对18,628个网站的网络隐私控制可用性挑战进行了大规模实证分析。研究指出，隐私控制常被隐藏、缺乏标准化且术语混淆，导致用户难以理解和使用。尽管在模拟复杂用户交互方面面临挑战，该研究仍发现了显著的可用性问题，尤其是在访客访问场景中。结果显示隐私政策最常见，而提示和通知在注册时普遍存在。论文最后提出了改进隐私控制设计的建议，包括增强用户意识、提供导航辅助和确保直接可访问性。", "keywords": "网络隐私控制, 可用性挑战, 实证分析, 数据隐私, 用户体验", "comments": "本文探讨了网络隐私控制中的可用性挑战，这是一个高度相关且重要的研究领域。其优势在于大规模的实证分析，覆盖了大量网站。尽管研究承认在模拟复杂用户交互（如注册）方面存在局限性，这可能影响结果的普适性，但其提出的具体设计建议对于改善用户隐私体验具有实际价值和指导意义。"}}
{"id": "2507.12391", "title": "Assessing the Value of Visual Input: A Benchmark of Multimodal Large Language Models for Robotic Path Planning", "authors": ["Jacinto Colan", "Ana Davila", "Yasuhisa Hasegawa"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at the 2025 SICE Festival with Annual Conference (SICE FES)", "url": "http://arxiv.org/abs/2507.12391v1", "summary": "Large Language Models (LLMs) show potential for enhancing robotic path\nplanning. This paper assesses visual input's utility for multimodal LLMs in\nsuch tasks via a comprehensive benchmark. We evaluated 15 multimodal LLMs on\ngenerating valid and optimal paths in 2D grid environments, simulating\nsimplified robotic planning, comparing text-only versus text-plus-visual inputs\nacross varying model sizes and grid complexities. Our results indicate moderate\nsuccess rates on simpler small grids, where visual input or few-shot text\nprompting offered some benefits. However, performance significantly degraded on\nlarger grids, highlighting a scalability challenge. While larger models\ngenerally achieved higher average success, the visual modality was not\nuniversally dominant over well-structured text for these multimodal systems,\nand successful paths on simpler grids were generally of high quality. These\nresults indicate current limitations in robust spatial reasoning, constraint\nadherence, and scalable multimodal integration, identifying areas for future\nLLM development in robotic path planning.", "comment": "Accepted at the 2025 SICE Festival with Annual Conference (SICE FES)", "pdf_url": "http://arxiv.org/pdf/2507.12391v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "评估视觉输入价值：多模态大语言模型在机器人路径规划中的基准测试", "tldr": "本研究评估了多模态大语言模型（LLMs）在机器人路径规划中视觉输入的效用。结果显示，在简单任务上视觉输入或少样本提示有益，但在复杂任务上性能显著下降，且视觉输入并非普遍优于结构良好的文本。", "motivation": "大型语言模型（LLMs）在增强机器人路径规划方面显示出潜力。本研究旨在通过一项全面的基准测试，评估视觉输入在此类任务中对多模态LLMs的效用。", "method": "通过一项全面的基准测试，评估了15个多模态LLMs在2D网格环境中生成有效和最优路径的能力。研究模拟了简化的机器人规划，并比较了纯文本输入与文本加视觉输入在不同模型大小和网格复杂性下的表现。", "result": "在较简单的S小网格上，成功率适中，视觉输入或少样本文本提示提供了一些益处。然而，在较大网格上，性能显著下降，突显了可扩展性挑战。虽然较大的模型通常能达到更高的平均成功率，但对于这些多模态系统而言，视觉模态并非普遍优于结构良好的文本，并且在较简单网格上成功生成的路径通常质量很高。", "conclusion": "当前多模态LLMs在机器人路径规划中存在局限性，包括鲁棒的空间推理、约束遵守和可扩展的多模态集成。这些结果指明了未来LLM在机器人路径规划发展中的方向。", "translation": "大型语言模型 (LLMs) 在增强机器人路径规划方面显示出潜力。本文通过一项全面的基准测试，评估了视觉输入在此类任务中对多模态LLMs的效用。我们评估了15个多模态LLMs在2D网格环境中生成有效和最优路径的能力，模拟了简化的机器人规划，并比较了纯文本输入与文本加视觉输入在不同模型大小和网格复杂性下的表现。我们的结果表明，在较简单的S小网格上，成功率适中，视觉输入或少样本文本提示提供了一些益处。然而，在较大网格上，性能显著下降，突显了可扩展性挑战。虽然较大的模型通常能达到更高的平均成功率，但对于这些多模态系统而言，视觉模态并非普遍优于结构良好的文本，并且在较简单网格上成功生成的路径通常质量很高。这些结果表明当前在鲁棒空间推理、约束遵守和可扩展多模态集成方面存在局限性，指明了未来LLM在机器人路径规划发展中的领域。", "summary": "本文评估了多模态大语言模型（LLMs）在机器人路径规划任务中视觉输入的价值。研究通过对15个多模态LLMs在2D网格环境中的基准测试，比较了纯文本和图文结合输入。结果显示，在简单网格上，视觉输入或少样本提示有益，但性能在复杂网格上显著下降，揭示了可扩展性挑战。尽管大型模型表现更好，但视觉输入并非总优于文本。研究指出了当前LLMs在空间推理、约束遵守和多模态集成方面的局限性，为未来发展提供了方向。", "keywords": "多模态大语言模型, 机器人路径规划, 视觉输入, 基准测试, 空间推理", "comments": "这项研究通过系统性的基准测试，首次深入探讨了视觉输入对多模态LLMs在机器人路径规划中的实际价值和局限性。其创新之处在于对比了不同输入模态、模型大小和环境复杂性，揭示了现有模型在空间推理和可扩展性方面的不足，为未来多模态LLM在具身智能领域的发展提供了重要的实证依据和研究方向。"}}
{"id": "2507.11802", "title": "FAIR-CS: Framework for Interdisciplinary Research Collaborations in Online Computing Programs", "authors": ["Breanna Shi", "Thomas Deatherage", "Jeanette Schofield", "Charles R. Clark", "Thomas Orth", "Nicholas Lytle"], "categories": ["cs.CY", "cs.GL"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11802v1", "summary": "Research experience is crucial for computing master's students pursuing\nacademic and scientific careers, yet online students have traditionally been\nexcluded from these opportunities due to the physical constraints of\ntraditional research environments. This paper presents the Framework for\nAccelerating Interdisciplinary Research in Computer Science (FAIR-CS), a method\nfor achieving research goals, developing research communities, and supporting\nhigh quality mentorship in an online research environment. This method advances\nvirtual research operations by orchestrating dynamic partnerships between\nmaster's level researchers and academic mentors, resulting in interdisciplinary\npublications. We then discuss the implementation of FAIR-CS in the\nHuman-Augmented Analytics Group (HAAG), with researchers from the Georgia\nTech's Online Master of Computer Science program. Through documented project\nrecords and experiences with 72 active users, we present our lessons learned\nand evaluate the evolution of FAIR-CS in HAAG. This paper serves as a\ncomprehensive resource for other institutions seeking to establish similar\nvirtual research initiatives, demonstrating how the traditional research lab\nenvironment can be effectively replicated in the virtual space while\nmaintaining robust collaborative relationships and supporting knowledge\ntransfer.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11802v1", "cate": "cs.CY", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "FAIR-CS：在线计算程序中跨学科研究协作框架", "tldr": "FAIR-CS是一个在线框架，旨在帮助在线计算机硕士生进行跨学科研究合作，复制传统研究环境并支持高质量指导。", "motivation": "在线计算机硕士生因传统研究环境的物理限制，常被排除在学术和科学职业所需的关键研究机会之外。", "method": "论文提出了“加速计算机科学跨学科研究框架”（FAIR-CS），该方法通过协调硕士研究人员和学术导师之间的动态伙伴关系，旨在实现研究目标、发展研究社区并支持在线研究环境中的高质量指导，从而促进虚拟研究操作并产生跨学科出版物。", "result": "论文通过佐治亚理工学院在线计算机科学硕士项目中的HAAG小组实施FAIR-CS的经验，利用72名活跃用户的项目记录和经验，总结了所学到的经验教训，并评估了FAIR-CS在该小组中的演变。结果表明，传统研究实验室环境可以在虚拟空间中有效复制，同时保持强大的协作关系并支持知识转移。", "conclusion": "FAIR-CS框架为其他机构建立类似的虚拟研究项目提供了全面的资源，证明了传统研究实验室环境可以在虚拟空间中有效复制，同时保持强大的协作关系并支持知识转移。", "translation": "研究经验对于追求学术和科学事业的计算机硕士生至关重要，但由于传统研究环境的物理限制，在线学生历来被排除在这些机会之外。本文提出了“加速计算机科学跨学科研究框架”（FAIR-CS），这是一种在在线研究环境中实现研究目标、发展研究社区和支持高质量指导的方法。该方法通过协调硕士研究人员和学术导师之间的动态伙伴关系来推进虚拟研究操作，从而产生跨学科出版物。然后，我们讨论了FAIR-CS在佐治亚理工学院在线计算机科学硕士项目研究人员所在的人类增强分析小组（HAAG）中的实施。通过记录的项目记录和72名活跃用户的经验，我们展示了所学到的经验教训，并评估了FAIR-CS在HAAG中的演变。本文为其他寻求建立类似虚拟研究计划的机构提供了全面的资源，展示了传统研究实验室环境如何在虚拟空间中有效复制，同时保持强大的协作关系并支持知识转移。", "summary": "本文提出了FAIR-CS（加速计算机科学跨学科研究框架），旨在为在线计算机硕士生提供研究机会。该框架通过协调研究人员和导师的合作，在虚拟环境中实现研究目标、发展社区并提供高质量指导。论文详细介绍了FAIR-CS在佐治亚理工学院HAAG小组的实施情况，基于72名用户的经验总结了经验教训，并评估了其演变。研究表明，FAIR-CS能够有效复制传统研究实验室环境，支持虚拟空间中的协作和知识转移，为其他机构提供了宝贵参考。", "keywords": "在线教育, 研究协作, 跨学科研究, 虚拟环境, FAIR-CS", "comments": "FAIR-CS框架的创新之处在于其专注于将传统研究实验室环境成功复制到虚拟空间，特别是在线教育领域。这对于解决在线学生缺乏研究机会的问题具有重要意义。该框架通过促进跨学科合作和高质量指导，为在线学习者提供了宝贵的研究经验，有助于弥合线上线下教育体验的差距。其在实际项目中的实施和评估，增强了其方法的实用性和可推广性。"}}
{"id": "2507.12218", "title": "Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation", "authors": ["Tomohisa Okazaki"], "categories": ["cs.LG", "physics.geo-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12218v1", "summary": "Many physical systems are described by partial differential equations (PDEs),\nand solving these equations and estimating their coefficients or boundary\nconditions (BCs) from observational data play a crucial role in understanding\nthe associated phenomena. Recently, a machine learning approach known as\nphysics-informed neural network, which solves PDEs using neural networks by\nminimizing the sum of residuals from the PDEs, BCs, and data, has gained\nsignificant attention in the scientific community. In this study, we\ninvestigate a physics-informed linear model (PILM) that uses linear\ncombinations of basis functions to represent solutions, thereby enabling an\nanalytical representation of optimal solutions. The PILM was formulated and\nverified for illustrative forward and inverse problems including cases with\nuncertain BCs. Furthermore, the PILM was applied to estimate crustal strain\nrates using geodetic data. Specifically, physical regularization that enforces\nelastic equilibrium on the velocity fields was compared with mathematical\nregularization that imposes smoothness constraints. From a Bayesian\nperspective, mathematical regularization exhibited superior performance. The\nPILM provides an analytically solvable framework applicable to linear forward\nand inverse problems, underdetermined systems, and physical regularization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12218v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "物理信息线性模型 (PILM)：解析表示及其在地壳应变率估算中的应用", "tldr": "本研究提出了一种物理信息线性模型（PILM），它通过基函数的线性组合来解析地解决物理系统问题，并成功应用于地壳应变率估算。", "motivation": "许多物理系统由偏微分方程描述，从观测数据中求解这些方程并估计其系数或边界条件对于理解相关现象至关重要。最近的物理信息神经网络虽然受到关注，但本研究旨在探索一种具有解析解的物理信息模型。", "method": "本研究提出并研究了一种物理信息线性模型（PILM）。PILM使用基函数的线性组合来表示解，从而实现最优解的解析表示。它针对正向和逆向问题（包括不确定边界条件的情况）进行了公式化和验证。此外，PILM还应用于使用大地测量数据估算地壳应变率，并比较了施加弹性平衡的物理正则化与施加平滑约束的数学正则化。", "result": "PILM在正向和逆向问题（包括不确定边界条件的情况）中得到了验证。在应用于地壳应变率估算时，从贝叶斯角度看，数学正则化表现出优于物理正则化的性能。", "conclusion": "PILM提供了一个可解析求解的框架，适用于线性正向和逆向问题、欠定系统以及物理正则化。", "translation": "许多物理系统由偏微分方程（PDEs）描述，从观测数据中求解这些方程并估计其系数或边界条件（BCs）在理解相关现象中起着关键作用。最近，一种称为物理信息神经网络的机器学习方法，通过最小化来自PDEs、BCs和数据的残差总和来使用神经网络求解PDEs，在科学界受到了广泛关注。在本研究中，我们研究了一种物理信息线性模型（PILM），它使用基函数的线性组合来表示解，从而实现最优解的解析表示。PILM针对说明性的正向和逆向问题（包括不确定BCs的情况）进行了公式化和验证。此外，PILM还应用于使用大地测量数据估算地壳应变率。具体而言，将强制速度场弹性平衡的物理正则化与施加平滑约束的数学正则化进行了比较。从贝叶斯角度看，数学正则化表现出卓越的性能。PILM提供了一个可解析求解的框架，适用于线性正向和逆向问题、欠定系统和物理正则化。", "summary": "本文提出了一种物理信息线性模型（PILM），该模型利用基函数的线性组合来解析地表示偏微分方程的解。研究验证了PILM在正向和逆向问题中的有效性，并将其应用于地壳应变率的估算。通过比较物理正则化和数学正则化，结果表明数学正则化在贝叶斯视角下表现更优。PILM为线性正向/逆向问题、欠定系统和物理正则化提供了一个可解析的解决方案框架。", "keywords": "物理信息线性模型, 地壳应变率, 解析解, 正则化, 偏微分方程", "comments": "PILM的创新之处在于其解析表示能力，这与通常需要迭代优化的物理信息神经网络形成对比。其在处理不确定边界条件和物理正则化方面的应用潜力值得关注。将模型应用于实际地壳应变率估算，并比较不同正则化方法，增强了其实用性和理论深度。"}}
{"id": "2507.12404", "title": "Neural Network-Guided Symbolic Regression for Interpretable Descriptor Discovery in Perovskite Catalysts", "authors": ["Yeming Xian", "Xiaoming Wang", "Yanfa Yan"], "categories": ["physics.data-an", "cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "primary_category": "Subjects:       Data Analysis, Statistics and Probability (physics.data-an)", "pdf_link": null, "comments": "Comments:      31 pages", "url": "http://arxiv.org/abs/2507.12404v1", "summary": "Understanding and predicting the activity of oxide perovskite catalysts for\nthe oxygen evolution reaction (OER) requires descriptors that are both accurate\nand physically interpretable. While symbolic regression (SR) offers a path to\ndiscover such formulas, its performance degrades with high-dimensional inputs\nand small datasets. We present a two-phase framework that combines neural\nnetworks (NN), feature importance analysis, and symbolic regression (SR) to\ndiscover interpretable descriptors for OER activity in oxide perovskites. In\nPhase I, using a small dataset and seven structural features, we reproduce and\nimprove the known {\\mu}/t descriptor by engineering composite features and\napplying symbolic regression, achieving training and validation MAEs of 22.8\nand 20.8 meV, respectively. In Phase II, we expand to 164 features, reduce\ndimensionality, and identify LUMO energy as a key electronic descriptor. A\nfinal formula using {\\mu}/t, {\\mu}/RA, and LUMO energy achieves improved\naccuracy (training and validation MAEs of 22.1 and 20.6 meV) with strong\nphysical interpretability. Our results demonstrate that NN-guided symbolic\nregression enables accurate, interpretable, and physically meaningful\ndescriptor discovery in data-scarce regimes, indicating interpretability need\nnot sacrifice accuracy for materials informatics.", "comment": "31 pages", "pdf_url": "http://arxiv.org/pdf/2507.12404v1", "cate": "physics.data-an", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "神经网络引导的符号回归在钙钛矿催化剂中可解释描述符发现的应用", "tldr": "本研究提出了一种结合神经网络和符号回归的两阶段框架，用于在数据稀缺的条件下发现钙钛矿催化剂可解释的氧析出反应描述符，实现了高准确性和物理可解释性。", "motivation": "理解和预测氧化物钙钛矿催化剂的氧析出反应（OER）活性需要准确且物理可解释的描述符。然而，符号回归（SR）在处理高维输入和小数据集时性能会下降。", "method": "本研究提出了一个两阶段框架，结合了神经网络（NN）、特征重要性分析和符号回归（SR）来发现氧化物钙钛矿中OER活性的可解释描述符。第一阶段，使用小数据集和七个结构特征，通过工程复合特征和应用符号回归，重现并改进了已知的μ/t描述符。第二阶段，扩展到164个特征，进行降维，并将LUMO能量识别为关键的电子描述符。", "result": "在第一阶段，训练和验证的MAE分别为22.8和20.8 meV。在第二阶段，使用μ/t、μ/RA和LUMO能量的最终公式实现了更高的准确性（训练和验证MAE分别为22.1和20.6 meV），并具有强大的物理可解释性。", "conclusion": "研究结果表明，神经网络引导的符号回归能够在数据稀缺的情况下实现准确、可解释且具有物理意义的描述符发现，表明可解释性无需牺牲材料信息学的准确性。", "translation": "理解和预测氧化物钙钛矿催化剂的氧析出反应（OER）活性需要既准确又物理可解释的描述符。虽然符号回归（SR）提供了一条发现此类公式的途径，但其性能在高维输入和小数据集下会下降。我们提出了一个两阶段框架，结合了神经网络（NN）、特征重要性分析和符号回归（SR），以发现氧化物钙钛矿中OER活性的可解释描述符。在第一阶段，我们使用小数据集和七个结构特征，通过设计复合特征和应用符号回归，重现并改进了已知的μ/t描述符，实现了22.8和20.8 meV的训练和验证MAE。在第二阶段，我们扩展到164个特征，进行降维，并将LUMO能量识别为关键的电子描述符。使用μ/t、μ/RA和LUMO能量的最终公式实现了更高的准确性（训练和验证MAE分别为22.1和20.6 meV），并具有强大的物理可解释性。我们的结果表明，神经网络引导的符号回归能够在数据稀缺的情况下实现准确、可解释且具有物理意义的描述符发现，表明可解释性无需牺牲材料信息学的准确性。", "summary": "本研究提出了一种神经网络引导的符号回归两阶段框架，旨在解决传统符号回归在处理高维和小数据集时发现可解释描述符的局限性。该框架结合了神经网络、特征重要性分析和符号回归，成功在氧化物钙钛矿催化剂中发现了氧析出反应（OER）的准确且物理可解释的描述符。研究通过两个阶段，从少量结构特征扩展到大量特征，并识别出关键电子描述符，最终得到的公式在准确性和可解释性上均有显著提升，证明了在数据稀缺条件下实现高精度和强可解释性描述符发现的可能性。", "keywords": "符号回归, 神经网络, 钙钛矿催化剂, 氧析出反应, 描述符发现", "comments": "该论文的创新点在于提出了一个结合神经网络和符号回归的两阶段框架，有效地解决了在数据稀缺和高维输入条件下发现可解释物理描述符的挑战。这对于材料信息学领域，尤其是在催化剂设计和理解方面，具有重要意义。它证明了在追求模型准确性的同时，无需牺牲物理可解释性。"}}
{"id": "2507.10530", "title": "Accurate generation of chemical reaction transition states by conditional flow matching", "authors": ["Ping Tuo", "Jiale Chen", "Ju Li"], "categories": ["physics.chem-ph", "cs.AI"], "primary_category": "Subjects:       Chemical Physics (physics.chem-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10530v2", "summary": "Transition state (TS) structures define the critical geometries and energy\nbarriers underlying chemical reactivity, yet their fleeting nature renders them\nexperimentally elusive and drives the reliance on costly, high-throughput\ndensity functional theory (DFT) calculations. Here, we introduce TS-GEN, a\nconditional flow-matching generative model that maps samples from a simple\nGaussian prior directly to transition-state saddle-point geometries in a\nsingle, deterministic pass. By embedding both reactant and product\nconformations as conditioning information, TS-GEN learns to transport latent\nnoise to true TS structures via an optimal-transport path, effectively\nreplacing the iterative optimization common in nudged-elastic band or\nstring-method algorithms. TS-GEN delivers unprecedented accuracy, achieving a\nroot-mean-square deviation of $0.004\\ \\rm{\\mathring{A}}$ (vs. $0.103\\\n\\rm{\\mathring{A}}$ for prior state-of-the-art) and a mean barrier-height error\nof $1.019\\ {\\rm kcal/mol}$ (vs. $2.864\\ {\\rm kcal/mol}$), while requiring only\n$0.06\\ {\\rm s}$ GPU time per inference. Over 87% of generated TSs meet\nchemical-accuracy criteria ($<1.58\\ {\\rm kcal/mol}$ error), substantially\noutpacing existing methods. TS-GEN also exhibits strong transferability to\nout-of-distribution reactions from a larger database. By uniting sub-angstrom\nprecision, sub-second speed, and broad applicability, TS-GEN will be highly\nuseful for high-throughput exploration of complex reaction networks, paving the\nway to the exploration of novel chemical reaction mechanisms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10530v2", "cate": "physics.chem-ph", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "通过条件流匹配精确生成化学反应过渡态", "tldr": "TS-GEN是一种基于条件流匹配的生成模型，能够快速、准确地生成化学反应过渡态结构，其精度显著超越现有方法，并具有良好的泛化性。", "motivation": "过渡态（TS）结构定义了化学反应的关键几何结构和能垒，但其短暂性使其难以通过实验观测，且依赖于昂贵、高通量的密度泛函理论（DFT）计算。", "method": "本文引入了TS-GEN，一个条件流匹配生成模型，能够通过单一的确定性传递将简单高斯先验的样本直接映射到过渡态鞍点几何结构。通过将反应物和产物构象作为条件信息嵌入，TS-GEN学习通过最优传输路径将潜在噪声传输到真实的TS结构，有效取代了常见的微扰弹性带或弦方法算法中的迭代优化。", "result": "TS-GEN实现了前所未有的精度，均方根偏差为0.004 Å（而现有最先进方法为0.103 Å），平均能垒误差为1.019 kcal/mol（而现有最先进方法为2.864 kcal/mol），每次推理仅需0.06秒GPU时间。超过87%生成的TS满足化学精度标准（<1.58 kcal/mol误差），大大超越现有方法。TS-GEN还对来自更大数据库的非分布反应表现出强大的可迁移性。", "conclusion": "通过结合亚埃精度、亚秒速度和广泛适用性，TS-GEN将对复杂反应网络的高通量探索非常有用，为探索新型化学反应机制铺平道路。", "translation": "过渡态（TS）结构定义了化学反应的关键几何结构和能垒，但其短暂性使其难以通过实验观测，且依赖于昂贵、高通量的密度泛函理论（DFT）计算。本文引入了TS-GEN，一个条件流匹配生成模型，能够通过单一的确定性传递将简单高斯先验的样本直接映射到过渡态鞍点几何结构。通过将反应物和产物构象作为条件信息嵌入，TS-GEN学习通过最优传输路径将潜在噪声传输到真实的TS结构，有效取代了常见的微扰弹性带或弦方法算法中的迭代优化。TS-GEN实现了前所未有的精度，均方根偏差为0.004 Å（而现有最先进方法为0.103 Å），平均能垒误差为1.019 kcal/mol（而现有最先进方法为2.864 kcal/mol），每次推理仅需0.06秒GPU时间。超过87%生成的TS满足化学精度标准（<1.58 kcal/mol误差），大大超越现有方法。TS-GEN还对来自更大数据库的非分布反应表现出强大的可迁移性。通过结合亚埃精度、亚秒速度和广泛适用性，TS-GEN将对复杂反应网络的高通量探索非常有用，为探索新型化学反应机制铺平道路。", "summary": "本文提出了一种名为TS-GEN的条件流匹配生成模型，旨在高效准确地生成化学反应过渡态结构。该模型通过将反应物和产物构象作为条件信息，学习将潜在噪声直接映射到真实的过渡态几何结构，从而避免了传统迭代优化算法的计算成本。实验结果表明，TS-GEN在精度（均方根偏差和能垒误差）和速度上均显著优于现有方法，并且具有良好的泛化能力，有望加速复杂反应网络的探索。", "keywords": "过渡态生成, 条件流匹配, 机器学习, 化学反应, TS-GEN", "comments": "TS-GEN的创新之处在于将条件流匹配应用于化学反应过渡态的生成，这是一种新颖且高效的方法。其重要性在于极大地提高了过渡态生成的精度和速度，并降低了对昂贵DFT计算的依赖，这将极大地推动高通量化学反应探索和新反应机制的发现。该模型结合了亚埃精度、亚秒速度和广泛适用性，是计算化学领域的一个重要进展。"}}
{"id": "2507.11943", "title": "Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification", "authors": ["Haiwei Lin", "Shoko Imaizumi", "Hitoshi Kiya"], "categories": ["cs.CR", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      3 pages, 3 figures, conference", "url": "http://arxiv.org/abs/2507.11943v1", "summary": "We propose a low-rank adaptation method for training privacy-preserving\nvision transformer (ViT) models that efficiently freezes pre-trained ViT model\nweights. In the proposed method, trainable rank decomposition matrices are\ninjected into each layer of the ViT architecture, and moreover, the patch\nembedding layer is not frozen, unlike in the case of the conventional low-rank\nadaptation methods. The proposed method allows us not only to reduce the number\nof trainable parameters but to also maintain almost the same accuracy as that\nof full-time tuning.", "comment": "3 pages, 3 figures, conference", "pdf_url": "http://arxiv.org/pdf/2507.11943v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "针对隐私保护图像分类的低秩适应视觉Transformer高效微调", "tldr": "提出一种新的低秩适应方法，用于高效微调隐私保护ViT模型，减少参数同时保持精度。", "motivation": "需要一种高效的方法来微调隐私保护视觉Transformer（ViT）模型，以解决传统方法可能存在的参数量大或效率不高的问题。", "method": "提出一种低秩适应方法，其特点是：1. 将可训练的秩分解矩阵注入ViT架构的每一层；2. 与传统方法不同，不冻结patch embedding层；3. 有效冻结预训练ViT模型权重。", "result": "成功减少了可训练参数的数量，并保持了与全量微调几乎相同的精度。", "conclusion": "所提出的低秩适应方法能够有效地对隐私保护ViT模型进行微调，在显著减少参数的同时保持高性能。", "translation": "我们提出了一种低秩适应方法，用于训练隐私保护视觉Transformer (ViT) 模型，该方法能有效地冻结预训练ViT模型的权重。在所提出的方法中，可训练的秩分解矩阵被注入到ViT架构的每一层中，此外，与传统的低秩适应方法不同，patch embedding层没有被冻结。所提出的方法不仅可以减少可训练参数的数量，而且可以保持与全时微调几乎相同的精度。", "summary": "这篇论文提出了一种新的低秩适应方法，用于高效微调隐私保护的视觉Transformer (ViT) 模型。该方法通过在ViT的每一层注入可训练的秩分解矩阵，并且不冻结patch embedding层，实现了在显著减少可训练参数的同时，保持与全量微调相当的分类精度。", "keywords": "低秩适应, 视觉Transformer, 隐私保护, 图像分类, 微调", "comments": "该方法通过改进传统的低秩适应策略，特别是对patch embedding层的处理，有效地解决了在隐私保护场景下ViT模型微调的效率和性能平衡问题，具有一定的创新性。"}}
{"id": "2507.11561", "title": "Predicting Pulmonary Hypertension in Newborns: A Multi-view VAE Approach", "authors": ["Lucas Erlacher", "Samuel Ruipérez-Campillo", "Holger Michel", "Sven Wellmann", "Thomas M. Sutter", "Ece Ozkan", "Julia E. Vogt"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11561v1", "summary": "Pulmonary hypertension (PH) in newborns is a critical condition characterized\nby elevated pressure in the pulmonary arteries, leading to right ventricular\nstrain and heart failure. While right heart catheterization (RHC) is the\ndiagnostic gold standard, echocardiography is preferred due to its non-invasive\nnature, safety, and accessibility. However, its accuracy highly depends on the\noperator, making PH assessment subjective. While automated detection methods\nhave been explored, most models focus on adults and rely on single-view\nechocardiographic frames, limiting their performance in diagnosing PH in\nnewborns. While multi-view echocardiography has shown promise in improving PH\nassessment, existing models struggle with generalizability. In this work, we\nemploy a multi-view variational autoencoder (VAE) for PH prediction using\nechocardiographic videos. By leveraging the VAE framework, our model captures\ncomplex latent representations, improving feature extraction and robustness. We\ncompare its performance against single-view and supervised learning approaches.\nOur results show improved generalization and classification accuracy,\nhighlighting the effectiveness of multi-view learning for robust PH assessment\nin newborns.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11561v1", "cate": "eess.IV", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "新生儿肺动脉高压预测：一种多视角VAE方法", "tldr": "本文提出了一种多视角变分自编码器（VAE）方法，利用超声心动图视频预测新生儿肺动脉高压，并在泛化性和分类准确性方面优于单视角和监督学习方法。", "motivation": "新生儿肺动脉高压（PH）的诊断面临挑战，现有超声心动图方法高度依赖操作者，评估主观，且大多数自动化模型专注于成人或仅使用单视角数据，导致在新生儿PH诊断中性能和泛化性受限。", "method": "本文采用多视角变分自编码器（VAE）模型，利用超声心动图视频进行新生儿肺动脉高压（PH）预测。该模型通过VAE框架捕获复杂的潜在表示，以增强特征提取和鲁棒性。研究将此方法与单视角和监督学习方法进行了性能比较。", "result": "与单视角和监督学习方法相比，所提出的多视角VAE方法在新生儿肺动脉高压预测中显示出改进的泛化性和分类准确性。", "conclusion": "多视角学习对于新生儿肺动脉高压（PH）的稳健评估是有效的。", "translation": "新生儿肺动脉高压（PH）是一种危及生命的疾病，其特征是肺动脉压力升高，导致右心室劳损和心力衰竭。尽管右心导管检查（RHC）是诊断金标准，但超声心动图因其无创性、安全性和可及性而更受青睐。然而，其准确性高度依赖于操作者，使得PH评估具有主观性。尽管已探索自动化检测方法，但大多数模型侧重于成人，并依赖单视角超声心动图帧，这限制了它们在诊断新生儿PH方面的性能。虽然多视角超声心动图在改善PH评估方面已显示出前景，但现有模型在泛化性方面存在困难。在这项工作中，我们采用多视角变分自编码器（VAE）利用超声心动图视频进行PH预测。通过利用VAE框架，我们的模型捕获复杂的潜在表示，提高了特征提取和鲁棒性。我们将其性能与单视角和监督学习方法进行了比较。我们的结果显示出改进的泛化性和分类准确性，突出了多视角学习在新生儿稳健PH评估中的有效性。", "summary": "本文提出了一种基于多视角变分自编码器（VAE）的新方法，用于利用超声心动图视频预测新生儿肺动脉高压（PH）。针对当前诊断方法主观性强、依赖单视角且主要针对成人的局限性，所提出的VAE模型能够有效捕捉复杂的潜在表示，从而提高特征提取能力和模型鲁棒性。对比实验结果表明，该多视角方法在泛化性和分类准确性方面均优于现有方法，验证了多视角学习在新生儿PH可靠评估中的重要价值。", "keywords": "肺动脉高压, 新生儿, 多视角VAE, 超声心动图, 深度学习", "comments": "该论文通过提高新生儿肺动脉高压诊断的准确性和鲁棒性，解决了临床上的关键需求，因为现有方法存在主观性和局限性。其创新之处在于将多视角VAE应用于超声心动图视频，这有助于克服单视角数据的局限性并增强泛化能力。这种利用潜在表示的多视角方法，是迈向对这一脆弱人群进行更客观、更可靠的自动化PH评估的重要一步。"}}
{"id": "2507.12233", "title": "Universal Fourier Neural Operators for Micromechanics", "authors": ["Binh Huy Nguyen", "Matti Schneider"], "categories": ["cs.CE", "cs.LG"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      48 pages, 13 figures", "url": "http://arxiv.org/abs/2507.12233v1", "summary": "\\noindent Solving cell problems in homogenization is hard, and available\ndeep-learning frameworks fail to match the speed and generality of traditional\ncomputational frameworks. More to the point, it is generally unclear what to\nexpect of machine-learning approaches, let alone single out which approaches\nare promising. In the work at hand, we advocate Fourier Neural Operators (FNOs)\nfor micromechanics, empowering them by insights from computational\nmicromechanics methods based on the fast Fourier transform (FFT). We construct\nan FNO surrogate mimicking the basic scheme foundational for FFT-based methods\nand show that the resulting operator predicts solutions to cell problems with\n\\emph{arbitrary} stiffness distribution only subject to a material-contrast\nconstraint up to a desired accuracy. In particular, there are no restrictions\non the material symmetry like isotropy, on the number of phases and on the\ngeometry of the interfaces between materials. Also, the provided fidelity is\nsharp and uniform, providing explicit guarantees leveraging our physical\nempowerment of FNOs. To show the desired universal approximation property, we\nconstruct an FNO explicitly that requires no training to begin with. Still, the\nobtained neural operator complies with the same memory requirements as the\nbasic scheme and comes with runtimes proportional to classical FFT solvers. In\nparticular, large-scale problems with more than 100 million voxels are readily\nhandled. The goal of this work is to underline the potential of FNOs for\nsolving micromechanical problems, linking FFT-based methods to FNOs. This\nconnection is expected to provide a fruitful exchange between both worlds.", "comment": "48 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.12233v1", "cate": "cs.CE", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "用于微观力学的通用傅里叶神经算子", "tldr": "本文提出了一种基于快速傅里叶变换（FFT）思想的傅里叶神经算子（FNO）代理模型，用于解决均质化中的胞元问题，该模型能够以任意刚度分布预测解，无需训练，且性能与传统FFT求解器相当，适用于大规模问题。", "motivation": "均质化中的胞元问题难以解决，现有深度学习框架在速度和通用性上无法与传统计算框架匹敌。此外，机器学习方法在解决此类问题上的潜力尚不明确。", "method": "作者主张将傅里叶神经算子（FNOs）应用于微观力学，并借鉴基于快速傅里叶变换（FFT）的计算微观力学方法的见解来增强F N O。他们构建了一个模仿FFT基础方案的F N O代理模型。", "result": "所得到的算子能够以任意刚度分布预测胞元问题的解，仅受限于材料对比度约束，并达到所需精度。它对材料对称性（如各向同性）、相数和材料界面几何形状没有限制。该模型提供了精确且一致的保真度，并有明确的保证。他们构建了一个无需训练的F N O，其内存需求与基本方案相同，运行时与经典F F T求解器成比例，能够处理超过1亿体素的大规模问题。", "conclusion": "这项工作的目标是强调F N O在解决微观力学问题方面的潜力，将基于F F T的方法与F N O联系起来。这种联系有望促进两个领域之间的富有成效的交流。", "translation": "均质化中的胞元问题难以解决，现有深度学习框架无法与传统计算框架的速度和通用性相匹配。更重要的是，通常不清楚机器学习方法能带来什么，更不用说挑选出哪些方法有前景。在当前的工作中，我们倡导将傅里叶神经算子（FNOs）用于微观力学，并通过基于快速傅里叶变换（FFT）的计算微观力学方法的见解来增强它们。我们构建了一个模仿FFT基础方案的FNO代理模型，并表明所得到的算子能够以任意刚度分布预测胞元问题的解，仅受限于材料对比度约束，并达到所需精度。特别是，对材料对称性（如各向同性）、相数以及材料之间界面的几何形状没有限制。此外，所提供的保真度精确且均匀，通过我们对FNOs的物理增强提供了明确的保证。为了展示所需的通用逼近特性，我们明确构建了一个无需训练的FNO。尽管如此，所获得的神经算子符合与基本方案相同的内存要求，并且运行时间与经典FFT求解器成比例。特别是，可以轻松处理超过1亿体素的大规模问题。这项工作的目标是强调FNOs在解决微观力学问题方面的潜力，将基于FFT的方法与FNOs联系起来。这种联系有望促进两个领域之间的富有成效的交流。", "summary": "本文针对均质化中胞元问题难以解决且现有深度学习方法性能不足的挑战，提出了一种基于傅里叶神经算子（FNO）的新方法。该方法借鉴了快速傅里叶变换（FFT）在计算微观力学中的思想，构建了一个能够预测任意刚度分布下胞元问题解的FNO代理模型。该模型无需训练，且在精度、内存和运行时间方面与传统FFT求解器相当，能够处理大规模微观力学问题，并有望促进FNO与FFT方法之间的交叉研究。", "keywords": "傅里叶神经算子, 微观力学, 胞元问题, 快速傅里叶变换, 均质化", "comments": "本文的创新之处在于将傅里叶神经算子（FNOs）与快速傅里叶变换（FFT）的强大能力相结合，为微观力学中的胞元问题提供了一种通用且高效的解决方案。尤其值得注意的是，其提出的F N O模型无需训练即可工作，并能处理任意材料分布，这大大提高了方法的实用性和通用性。其性能与传统F F T求解器相当，且能处理大规模问题，显示出巨大的潜力。这种连接F N O和F F T方法的工作，有望为这两个领域带来新的研究方向和更深入的理解。"}}
{"id": "2507.12123", "title": "Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph", "authors": ["Sergey Linok", "Gleb Naumov"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages, 5 figures, 2 tables", "url": "http://arxiv.org/abs/2507.12123v1", "summary": "We propose OVIGo-3DHSG method - Open-Vocabulary Indoor Grounding of objects\nusing 3D Hierarchical Scene Graph. OVIGo-3DHSG represents an extensive indoor\nenvironment over a Hierarchical Scene Graph derived from sequences of RGB-D\nframes utilizing a set of open-vocabulary foundation models and sensor data\nprocessing. The hierarchical representation explicitly models spatial relations\nacross floors, rooms, locations, and objects. To effectively address complex\nqueries involving spatial reference to other objects, we integrate the\nhierarchical scene graph with a Large Language Model for multistep reasoning.\nThis integration leverages inter-layer (e.g., room-to-object) and intra-layer\n(e.g., object-to-object) connections, enhancing spatial contextual\nunderstanding. We investigate the semantic and geometry accuracy of\nhierarchical representation on Habitat Matterport 3D Semantic multi-floor\nscenes. Our approach demonstrates efficient scene comprehension and robust\nobject grounding compared to existing methods. Overall OVIGo-3DHSG demonstrates\nstrong potential for applications requiring spatial reasoning and understanding\nof indoor environments. Related materials can be found at\nhttps://github.com/linukc/OVIGo-3DHSG.", "comment": "13 pages, 5 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.12123v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于三维分层场景图的开放词汇室内物体定位", "tldr": "OVIGo-3DHSG是一种使用三维分层场景图和大型语言模型进行开放词汇室内物体定位的方法，能够有效处理复杂空间查询并实现高效场景理解和鲁棒物体定位。", "motivation": "为了有效解决涉及对其他物体进行空间引用的复杂查询，并满足需要室内环境空间推理和理解的应用需求。", "method": "本文提出了OVIGo-3DHSG方法，该方法利用RGB-D帧序列、开放词汇基础模型和传感器数据处理，构建了一个三维分层场景图来表示广阔的室内环境。这种分层表示明确建模了跨楼层、房间、位置和物体的空间关系。为了有效处理涉及对其他物体进行空间引用的复杂查询，该方法将分层场景图与大型语言模型集成，进行多步推理，并利用层间（如房间到物体）和层内（如物体到物体）连接来增强空间上下文理解。", "result": "该方法在Habitat Matterport 3D语义多层场景上验证了分层表示的语义和几何精度。与现有方法相比，OVIGo-3DHSG展示了高效的场景理解和鲁棒的物体定位能力。", "conclusion": "OVIGo-3DHSG在需要室内环境空间推理和理解的应用中展现出强大的潜力。", "translation": "我们提出OVIGo-3DHSG方法——使用三维分层场景图进行开放词汇室内物体定位。OVIGo-3DHSG利用一系列开放词汇基础模型和传感器数据处理，从RGB-D帧序列中导出的分层场景图来表示广阔的室内环境。这种分层表示明确建模了跨楼层、房间、位置和物体的空间关系。为了有效解决涉及对其他物体进行空间引用的复杂查询，我们将分层场景图与大型语言模型集成，进行多步推理。这种集成利用了层间（例如，房间到物体）和层内（例如，物体到物体）连接，增强了空间上下文理解。我们在Habitat Matterport 3D语义多层场景上研究了分层表示的语义和几何精度。与现有方法相比，我们的方法展示了高效的场景理解和鲁棒的物体定位。总的来说，OVIGo-3DHSG在需要室内环境空间推理和理解的应用中展现出强大的潜力。相关材料可在https://github.com/linukc/OVIGo-3DHSG找到。", "summary": "本文提出了一种名为OVIGo-3DHSG的开放词汇室内物体定位方法。该方法通过从RGB-D数据构建三维分层场景图来表示室内环境，并明确建模了多层次（楼层、房间、位置、物体）的空间关系。为处理复杂的空间查询，OVIGo-3DHSG将分层场景图与大型语言模型结合，实现多步推理，并利用层间和层内连接增强空间理解。实验结果表明，该方法在Habitat Matterport 3D场景中实现了高效的场景理解和鲁棒的物体定位，在室内空间推理和理解应用中具有巨大潜力。", "keywords": "开放词汇, 物体定位, 分层场景图, 室内环境, 空间推理", "comments": "OVIGo-3DHSG的创新之处在于将3D分层场景图与大型语言模型相结合，以实现开放词汇的室内物体定位和复杂的空间推理。这种方法通过显式建模多层次的空间关系，并利用LLM的推理能力，显著提升了对复杂室内环境的理解和物体定位的鲁棒性，对于机器人导航、增强现实等领域具有重要意义。"}}
{"id": "2309.10527", "title": "SPOT: Scalable 3D Pre-training via Occupancy Prediction for Learning Transferable 3D Representations", "authors": ["Xiangchao Yan", "Runjian Chen", "Bo Zhang", "Hancheng Ye", "Renqiu Xia", "Jiakang Yuan", "Hongbin Zhou", "Xinyu Cai", "Botian Shi", "Wenqi Shao", "Ping Luo", "Yu Qiao", "Tao Chen", "Junchi Yan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      SPOT has been accepted as a Regular Paper in T-PAMI, and code is available at this https URL", "url": "http://arxiv.org/abs/2309.10527v4", "summary": "Annotating 3D LiDAR point clouds for perception tasks is fundamental for many\napplications e.g., autonomous driving, yet it still remains notoriously\nlabor-intensive. Pretraining-finetuning approach can alleviate the labeling\nburden by fine-tuning a pre-trained backbone across various downstream datasets\nas well as tasks. In this paper, we propose SPOT, namely Scalable Pre-training\nvia Occupancy prediction for learning Transferable 3D representations under\nsuch a label-efficient fine-tuning paradigm. SPOT achieves effectiveness on\nvarious public datasets with different downstream tasks, showcasing its general\nrepresentation power, cross-domain robustness and data scalability which are\nthree key factors for real-world application. Specifically, we both\ntheoretically and empirically show, for the first time, that general\nrepresentations learning can be achieved through the task of occupancy\nprediction. Then, to address the domain gap caused by different LiDAR sensors\nand annotation methods, we develop a beam re-sampling technique for point cloud\naugmentation combined with class-balancing strategy. Furthermore, scalable\npre-training is observed, that is, the downstream performance across all the\nexperiments gets better with more pre-training data. Additionally, such\npre-training strategy also remains compatible with unlabeled data. The hope is\nthat our findings will facilitate the understanding of LiDAR points and pave\nthe way for future advancements in LiDAR pre-training.", "comment": "SPOT has been accepted as a Regular Paper in T-PAMI, and code is\n  available at https://github.com/PJLab-ADG/3DTrans", "pdf_url": "http://arxiv.org/pdf/2309.10527v4", "cate": "cs.CV", "date": "2023-09-19", "updated": "2025-07-16", "AI": {"title_translation": "SPOT：通过占用预测实现可扩展3D预训练以学习可迁移3D表示", "tldr": "SPOT提出了一种可扩展的3D预训练方法，通过占用预测学习可迁移的3D表示，有效解决了3D LiDAR点云标注耗时的问题，并在多个数据集上展示了其泛化能力、跨域鲁棒性和数据可扩展性。", "motivation": "3D LiDAR点云标注对于自动驾驶等应用至关重要，但其过程耗时耗力。预训练-微调方法可以减轻标注负担，因此需要一种新的标签高效的预训练范式来学习可迁移的3D表示。", "method": "本研究提出了SPOT（Scalable Pre-training via Occupancy prediction for learning Transferable 3D representations）。SPOT通过占用预测任务实现通用表示学习。为了解决不同LiDAR传感器和标注方法造成的域间隙，开发了结合类别平衡策略的点云波束重采样技术。此外，该预训练策略与未标注数据兼容。", "result": "SPOT在各种公共数据集和不同的下游任务上均取得了有效性，展示了其通用表示能力、跨域鲁棒性和数据可扩展性。首次从理论和经验上证明了通过占用预测任务可以实现通用表示学习。观察到可扩展的预训练，即随着预训练数据量的增加，所有实验的下游性能都得到提升。", "conclusion": "通过占用预测任务可以实现通用表示学习。SPOT的发现有望促进对LiDAR点云的理解，并为未来LiDAR预训练的进步铺平道路。", "translation": "注释用于感知任务的3D LiDAR点云对于许多应用（例如自动驾驶）来说是基础，但它仍然是出了名的劳动密集型工作。预训练-微调方法可以通过在各种下游数据集和任务上微调预训练的主干网络来减轻标注负担。在本文中，我们提出了SPOT，即通过占用预测实现可扩展预训练以学习可迁移3D表示，这是一种标签高效的微调范式。SPOT在各种公共数据集和不同的下游任务上均取得了有效性，展示了其通用表示能力、跨域鲁棒性和数据可扩展性，这三者是实际应用的关键因素。具体来说，我们首次从理论和经验上表明，通过占用预测任务可以实现通用表示学习。然后，为了解决由不同LiDAR传感器和标注方法引起的域间隙问题，我们开发了一种点云波束重采样技术，并结合了类别平衡策略。此外，观察到可扩展的预训练，即随着预训练数据的增加，所有实验的下游性能都变得更好。此外，这种预训练策略也与未标注数据兼容。希望我们的发现能够促进对LiDAR点云的理解，并为未来LiDAR预训练的进步铺平道路。", "summary": "SPOT提出了一种基于占用预测的可扩展3D预训练方法，旨在解决3D LiDAR点云标注的劳动密集问题，并学习可迁移的3D表示。该方法通过占用预测实现通用表示学习，并引入波束重采样技术和类别平衡策略来应对域间隙。实验证明，SPOT在多个下游任务和数据集上表现出优异的性能，具备强大的通用表示能力、跨域鲁棒性和数据可扩展性，并且与未标注数据兼容。该研究首次从理论和经验上验证了占用预测在通用表示学习中的潜力。", "keywords": "3D预训练, 占用预测, LiDAR点云, 可迁移表示, 数据可扩展性", "comments": "该论文的创新点在于首次提出并验证了通过占用预测任务可以实现通用的3D表示学习，这为解决3D点云标注难题提供了一个新颖且高效的预训练范式。其提出的波束重采样和类别平衡策略有效地提升了模型在不同LiDAR传感器和标注方法下的鲁棒性。此外，发现预训练数据量与下游性能的正相关性，并兼容未标注数据，极大地增强了其实用性和可扩展性。这项工作对于推动LiDAR点云理解和3D表示学习领域具有重要意义。"}}
{"id": "2507.10594", "title": "Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features", "authors": ["Shengda Zhuo", "Di Wu", "Yi He", "Shuqiang Huang", "Xindong Wu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10594v2", "summary": "Online learning, where feature spaces can change over time, offers a flexible\nlearning paradigm that has attracted considerable attention. However, it still\nfaces three significant challenges. First, the heterogeneity of real-world data\nstreams with mixed feature types presents challenges for traditional parametric\nmodeling. Second, data stream distributions can shift over time, causing an\nabrupt and substantial decline in model performance. Additionally, the time and\ncost constraints make it infeasible to label every data instance in a\nsupervised setting. To overcome these challenges, we propose a new algorithm\nOnline Learning from Mix-typed, Drifted, and Incomplete Streaming Features\n(OL-MDISF), which aims to relax restrictions on both feature types, data\ndistribution, and supervision information. Our approach involves utilizing\ncopula models to create a comprehensive latent space, employing an adaptive\nsliding window for detecting drift points to ensure model stability, and\nestablishing label proximity information based on geometric structural\nrelationships. To demonstrate the model's efficiency and effectiveness, we\nprovide theoretical analysis and comprehensive experimental results.\n  This extension serves as a standalone technical reference to the original\nOL-MDISF method. It provides (i) a contextual analysis of OL-MDISF within the\nbroader landscape of online learning, covering recent advances in mixed-type\nfeature modeling, concept drift adaptation, and weak supervision, and (ii) a\ncomprehensive set of experiments across 14 real-world datasets under two types\nof drift scenarios. These include full CER trends, ablation studies,\nsensitivity analyses, and temporal ensemble dynamics. We hope this document can\nserve as a reproducible benchmark and technical resource for researchers\nworking on nonstationary, heterogeneous, and weakly supervised data streams.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10594v2", "cate": "cs.LG", "date": "2025-07-12", "updated": "2025-07-16", "AI": {"title_translation": "OL-MDISF扩展：从混合类型、漂移和不完整流数据特征中进行在线学习", "tldr": "该论文提出了OL-MDISF算法，这是一种在线学习方法，旨在解决数据流中混合类型特征、概念漂移和不完整监督的挑战，并通过广泛的实验证明了其有效性，为相关研究提供了基准。", "motivation": "在线学习面临三个主要挑战：真实世界数据流的特征类型多样性（混合特征类型）对传统参数建模的挑战；数据流分布随时间变化（概念漂移）导致模型性能下降；以及时间和成本限制导致在监督设置中无法标记所有数据实例（不完整监督）。", "method": "为克服上述挑战，论文提出了OL-MDISF算法。该方法利用联结函数模型创建全面的潜在空间，采用自适应滑动窗口检测漂移点以确保模型稳定性，并基于几何结构关系建立标签邻近信息。本扩展作为原始OL-MDISF方法的独立技术参考，提供了在在线学习领域内的背景分析（涵盖混合类型特征建模、概念漂移适应和弱监督的最新进展），以及在两种漂移场景下对14个真实世界数据集进行的一系列综合实验。", "result": "论文提供了理论分析和全面的实验结果，证明了OL-MDISF模型的效率和有效性。实验涵盖了14个真实世界数据集，包括完整的CER趋势、消融研究、敏感性分析和时间集成动态。本扩展旨在作为非平稳、异构和弱监督数据流研究人员的可复现基准和技术资源。", "conclusion": "OL-MDISF算法有效且高效地解决了在线学习中混合类型、漂移和不完整监督流数据特征的挑战，为相关研究社区提供了一个有价值的基准和技术资源。", "translation": "在线学习，即特征空间随时间变化的学习范式，提供了一种灵活的学习范式，并受到了广泛关注。然而，它仍然面临三个重大挑战。首先，真实世界数据流的异质性及其混合特征类型对传统参数建模提出了挑战。其次，数据流分布会随时间推移而发生变化，导致模型性能突然大幅下降。此外，时间和成本的限制使得在监督设置中标记每个数据实例变得不可行。为了克服这些挑战，我们提出了一种新的算法，即从混合类型、漂移和不完整流数据特征中进行在线学习 (OL-MDISF)，旨在放宽对特征类型、数据分布和监督信息的限制。我们的方法包括利用联结函数模型创建全面的潜在空间，采用自适应滑动窗口检测漂移点以确保模型稳定性，以及基于几何结构关系建立标签邻近信息。为了证明模型的效率和有效性，我们提供了理论分析和全面的实验结果。本扩展作为原始OL-MDISF方法的独立技术参考。它提供了 (i) OL-MDISF在更广泛的在线学习领域的背景分析，涵盖混合类型特征建模、概念漂移适应和弱监督方面的最新进展，以及 (ii) 在两种漂移场景下对14个真实世界数据集进行的一系列综合实验。这些实验包括完整的CER趋势、消融研究、敏感性分析和时间集成动态。我们希望这份文档能为研究非平稳、异构和弱监督数据流的研究人员提供可复现的基准和技术资源。", "summary": "本文介绍了OL-MDISF的扩展版本，该在线学习算法旨在解决数据流中混合类型特征、概念漂移和不完整监督等挑战。它采用联结函数模型构建潜在空间、自适应滑动窗口检测漂移点，并利用几何结构关系建立标签邻近信息。该扩展提供了全面的背景分析，并在14个真实世界数据集上进行了广泛的实验验证，为处理非平稳、异构和弱监督数据流的研究人员提供了重要的基准和技术资源。", "keywords": "在线学习, 概念漂移, 混合类型特征, 不完整监督, 数据流", "comments": "该论文解决了在线学习中关键的现实世界挑战，特别是数据异构性、概念漂移和有限监督的实际问题。所提出的OL-MDISF算法及其扩展展示了解决这些问题的整体方法。强调提供可复现的基准和广泛的实验验证对研究社区非常有价值，有助于提高透明度并促进该复杂领域的未来工作。"}}
{"id": "2507.12003", "title": "Expanding ML-Documentation Standards For Better Security", "authors": ["Cara Ellen Appel"], "categories": ["cs.CR", "cs.LG", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted for publication at the 33rd IEEE International Requirements Engineering Workshop (REW 2025)", "url": "http://arxiv.org/abs/2507.12003v1", "summary": "This article presents the current state of ML-security and of the\ndocumentation of ML-based systems, models and datasets in research and practice\nbased on an extensive review of the existing literature. It shows a generally\nlow awareness of security aspects among ML-practitioners and organizations and\nan often unstandardized approach to documentation, leading to overall low\nquality of ML-documentation. Existing standards are not regularly adopted in\npractice and IT-security aspects are often not included in documentation. Due\nto these factors, there is a clear need for improved security documentation in\nML, as one step towards addressing the existing gaps in ML-security. To achieve\nthis, we propose expanding existing documentation standards for\nML-documentation to include a security section with specific security relevant\ninformation. Implementing this, a novel expanded method of documenting security\nrequirements in ML-documentation is presented, based on the existing Model\nCards and Datasheets for Datasets standards, but with the recommendation to\nadopt these findings in all ML-documentation.", "comment": "Accepted for publication at the 33rd IEEE International Requirements\n  Engineering Workshop (REW 2025)", "pdf_url": "http://arxiv.org/pdf/2507.12003v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "扩展机器学习文档标准以提升安全性", "tldr": "当前的机器学习文档缺乏对安全性的关注和标准化；本文提出扩展现有机器学习文档标准，以包含一个专门的安全部分，从而解决这一差距。", "motivation": "机器学习从业者和组织普遍对安全方面意识较低，文档方法不规范，导致机器学习文档质量低下，且现有标准未被采纳，IT安全方面常被排除在外，因此迫切需要改进机器学习中的安全文档。", "method": "通过对现有文献的广泛回顾，评估了机器学习安全和文档的现状。提出扩展现有文档标准（如模型卡片和数据集数据表）以包含一个具有特定安全相关信息的安全部分。提出了一种记录机器学习文档中安全要求的新颖扩展方法。", "result": "本文介绍了机器学习安全和文档的现状，揭示了安全意识低下和文档不规范的问题，并提出了一种用于安全文档的新颖扩展方法。", "conclusion": "机器学习中显然需要改进安全文档。扩展现有文档标准以包含安全部分，是解决机器学习安全现有差距的关键一步。", "translation": "本文基于对现有文献的广泛回顾，介绍了机器学习安全和基于机器学习的系统、模型和数据集在研究和实践中文档的现状。研究表明，机器学习从业者和组织普遍对安全方面意识较低，并且文档方法通常不规范，导致机器学习文档的整体质量低下。现有标准在实践中并未得到常规采纳，IT安全方面也常未被纳入文档。鉴于这些因素，机器学习中显然需要改进安全文档，作为解决机器学习安全现有差距的一步。为此，我们建议扩展现有机器学习文档标准，以包含一个安全部分，其中包含特定的安全相关信息。为此，本文提出了一种新颖的扩展方法，用于在机器学习文档中记录安全要求，该方法基于现有的模型卡片和数据集数据表标准，但建议在所有机器学习文档中采纳这些发现。", "summary": "本文回顾了机器学习安全和文档的现状，揭示了安全意识低下和文档不规范的问题，导致文档质量差且排除IT安全方面。为解决这些差距，论文提出扩展现有机器学习文档标准（如模型卡片和数据集数据表），纳入专门的安全部分，包含特定的安全相关信息，从而提出了一种改进安全文档的新方法。", "keywords": "机器学习安全, 文档标准, 模型卡片, 数据集数据表, 安全要求", "comments": "该论文解决了机器学习系统一个关键且常被忽视的方面：安全文档。其将安全特定信息整合到现有文档标准中的提议具有实用性和直接可操作性，旨在通过提高意识和标准化实践来改善机器学习部署的整体安全态势。"}}
{"id": "2507.11710", "title": "Subgraph Generation for Generalizing on Out-of-Distribution Links", "authors": ["Jay Revolinsky", "Harry Shomer", "Jiliang Tang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 pages, 7 figures, preprint", "url": "http://arxiv.org/abs/2507.11710v1", "summary": "Graphs Neural Networks (GNNs) demonstrate high-performance on the link\nprediction (LP) task. However, these models often rely on all dataset samples\nbeing drawn from the same distribution. In addition, graph generative models\n(GGMs) show a pronounced ability to generate novel output graphs. Despite this,\nGGM applications remain largely limited to domain-specific tasks. To bridge\nthis gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)\nstructurally-conditioned graph generation, and (2) adversarial co-training\nbetween an auto-encoder and GNN. As such, FLEX ensures structural-alignment\nbetween sample distributions to enhance link-prediction performance in\nout-of-distribution (OOD) scenarios. Notably, FLEX does not require expert\nknowledge to function in different OOD scenarios. Numerous experiments are\nconducted in synthetic and real-world OOD settings to demonstrate FLEX's\nperformance-enhancing ability, with further analysis for understanding the\neffects of graph data augmentation on link structures. The source code is\navailable here: https://github.com/revolins/FlexOOD.", "comment": "18 pages, 7 figures, preprint", "pdf_url": "http://arxiv.org/pdf/2507.11710v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "用于泛化分布外链接的子图生成", "tldr": "FLEX是一个图生成模型框架，通过结构条件生成和对抗协同训练，在不依赖专家知识的情况下，提高图神经网络在分布外链接预测任务上的性能。", "motivation": "图神经网络（GNN）在链接预测任务上表现出色，但其性能依赖于数据来自同一分布。图生成模型（GGM）能够生成新颖的图，但应用范围受限于特定领域。本文旨在弥合这一差距，提升GNN在分布外（OOD）场景下链接预测的泛化能力。", "method": "本文提出了FLEX，一个图生成模型（GGM）框架。FLEX结合了两种机制：1）结构条件图生成；2）自编码器与GNN之间的对抗协同训练。通过这些机制，FLEX确保样本分布之间的结构对齐，从而在分布外（OOD）场景中提高链接预测性能。值得注意的是，FLEX无需专家知识即可在不同OOD场景中运行。", "result": "在合成和真实世界的分布外（OOD）设置中进行了大量实验，结果表明FLEX能够显著提升性能。研究还进一步分析了图数据增强对链接结构的影响。", "conclusion": "FLEX作为一种新型图生成模型框架，有效解决了图神经网络在分布外链接预测中的泛化问题，并通过结构对齐和对抗训练显著提升了性能，且无需领域专家知识。", "translation": "图神经网络（GNNs）在链接预测（LP）任务中表现出高性能。然而，这些模型通常依赖于所有数据集样本都来自同一分布。此外，图生成模型（GGMs）在生成新颖输出图方面显示出显著能力。尽管如此，GGM的应用在很大程度上仍限于特定领域任务。为了弥合这一差距，我们提出了FLEX，一个利用两种机制的GGM框架：(1) 结构条件图生成，和 (2) 自编码器与GNN之间的对抗协同训练。因此，FLEX确保样本分布之间的结构对齐，以增强在分布外（OOD）场景中的链接预测性能。值得注意的是，FLEX无需专家知识即可在不同的OOD场景中发挥作用。在合成和真实世界的OOD设置中进行了大量实验，以证明FLEX的性能提升能力，并进一步分析了图数据增强对链接结构的影响。源代码可在此处获取：https://github.com/revolins/FlexOOD。", "summary": "本文提出了FLEX，一个创新的图生成模型（GGM）框架，旨在解决图神经网络（GNN）在分布外（OOD）链接预测任务中泛化能力不足的问题。FLEX通过结构条件图生成和自编码器与GNN的对抗协同训练，实现样本分布的结构对齐，从而显著提升了OOD场景下的链接预测性能，且无需领域专家知识。实验结果在合成和真实世界数据集中验证了其有效性。", "keywords": "图神经网络, 链接预测, 分布外泛化, 图生成模型, 对抗训练", "comments": "FLEX的创新之处在于它结合了图生成模型和对抗训练的思想，专门解决GNN在分布外泛化能力不足的痛点。其无需专家知识的特性使其具有较强的普适性。该工作对于提升图学习模型在实际复杂环境中的鲁棒性和泛化能力具有重要意义。"}}
{"id": "2507.11873", "title": "Syntax Repair as Language Intersection", "authors": ["Breandan Considine"], "categories": ["cs.FL", "cs.PL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11873v1", "summary": "We introduce a new technique for repairing syntax errors in arbitrary\ncontext-free languages. This technique models syntax repair as a language\nintersection problem by defining a finite language that provably generates\nevery syntactically valid repair within a given edit distance. Leveraging a\ntheoretical connection between the Bar-Hillel construction from formal language\ntheory and CFL reachability from program analysis, we show that repairability\nin a finite number of typographic edits is polylogarithmic parallel time\ndecidable and provide an enumeration algorithm based on the Brzozowski\nderivative. Finally, we evaluate this algorithm and its implementation,\ndemonstrating state-of-the-art results on a Python syntax repair benchmark.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11873v1", "cate": "cs.FL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "语法修复即语言交集", "tldr": "提出一种将语法修复建模为语言交集问题的新技术，能够高效地修复任意上下文无关语言的语法错误，并在Python基准测试中取得了最先进的结果。", "motivation": "修复任意上下文无关语言中的语法错误。", "method": "将语法修复建模为语言交集问题，通过定义一个有限语言来生成给定编辑距离内的所有语法有效修复。利用形式语言理论中的Bar-Hillel构造与程序分析中的CFL可达性之间的理论联系，证明了有限编辑次数内的可修复性是多对数并行时间可判定的，并提供了一个基于Brzozowski导数的枚举算法。", "result": "证明了在有限数量的排版编辑下，可修复性是多对数并行时间可判定的。在Python语法修复基准测试中，该算法及其实现取得了最先进的结果。", "conclusion": "该研究成功地将语法修复问题转化为语言交集问题，并提供了一种高效的算法，在实际应用中表现出色。", "translation": "我们引入了一种修复任意上下文无关语言中语法错误的新技术。该技术将语法修复建模为语言交集问题，通过定义一个有限语言，该语言可以证明在给定编辑距离内生成每一个语法有效的修复。利用形式语言理论中的Bar-Hillel构造与程序分析中的CFL可达性之间的理论联系，我们证明了在有限数量的排版编辑下，可修复性是多对数并行时间可判定的，并提供了一个基于Brzozowski导数的枚举算法。最后，我们评估了该算法及其实现，在Python语法修复基准测试中展示了最先进的结果。", "summary": "这篇论文介绍了一种新的语法错误修复技术，它将语法修复视为一个语言交集问题，通过构建一个有限语言来生成给定编辑距离内的所有有效修复。该方法利用了形式语言理论和程序分析的联系，证明了修复的可判定性，并提出了一个基于Brzozowski导数的枚举算法。在Python语法修复基准测试中，该技术展现了最先进的性能。", "keywords": "语法修复, 语言交集, 上下文无关语言, Bar-Hillel构造, CFL可达性", "comments": "这篇论文的创新点在于将语法修复问题重新概念化为语言交集问题，并利用了形式语言理论和程序分析的深层联系，这为解决语法错误修复提供了一个新颖且理论基础坚实的方法。其在Python基准测试中取得的最先进结果也表明了该方法的实用性和高效性。"}}
{"id": "2507.12433", "title": "Traffic-Aware Pedestrian Intention Prediction", "authors": ["Fahimeh Orvati Nia", "Hai Lin"], "categories": ["cs.CV", "cs.SY", "eess.SY", "I.2.10; I.5.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures. Accepted to the American Control Conference (ACC) 2025", "url": "http://arxiv.org/abs/2507.12433v1", "summary": "Accurate pedestrian intention estimation is crucial for the safe navigation\nof autonomous vehicles (AVs) and hence attracts a lot of research attention.\nHowever, current models often fail to adequately consider dynamic traffic\nsignals and contextual scene information, which are critical for real-world\napplications. This paper presents a Traffic-Aware Spatio-Temporal Graph\nConvolutional Network (TA-STGCN) that integrates traffic signs and their states\n(Red, Yellow, Green) into pedestrian intention prediction. Our approach\nintroduces the integration of dynamic traffic signal states and bounding box\nsize as key features, allowing the model to capture both spatial and temporal\ndependencies in complex urban environments. The model surpasses existing\nmethods in accuracy. Specifically, TA-STGCN achieves a 4.75% higher accuracy\ncompared to the baseline model on the PIE dataset, demonstrating its\neffectiveness in improving pedestrian intention prediction.", "comment": "6 pages, 4 figures. Accepted to the American Control Conference (ACC)\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.12433v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "交通感知行人意图预测", "tldr": "本文提出了一种交通感知时空图卷积网络（TA-STGCN），通过整合动态交通信号和边界框大小等关键特征，显著提高了行人意图预测的准确性。", "motivation": "准确的行人意图估计对于自动驾驶车辆的安全导航至关重要。然而，现有模型往往未能充分考虑动态交通信号和上下文场景信息，这对于实际应用是关键的不足。", "method": "本文提出了交通感知时空图卷积网络（TA-STGCN），该网络将交通标志及其状态（红、黄、绿）整合到行人意图预测中。该方法引入了动态交通信号状态和边界框大小作为关键特征，使模型能够捕捉复杂城市环境中的时空依赖性。", "result": "TA-STGCN模型在准确性上超越了现有方法。具体而言，在PIE数据集上，TA-STGCN比基线模型高出4.75%的准确率，证明了其在改善行人意图预测方面的有效性。", "conclusion": "TA-STGCN通过整合动态交通信号和边界框大小等关键特征，有效提高了行人意图预测的准确性，对于自动驾驶车辆的安全导航具有重要意义。", "translation": "准确的行人意图估计对于自动驾驶车辆（AVs）的安全导航至关重要，因此吸引了大量研究关注。然而，当前模型往往未能充分考虑动态交通信号和上下文场景信息，这对于实际应用至关重要。本文提出了一种交通感知时空图卷积网络（TA-STGCN），该网络将交通标志及其状态（红、黄、绿）整合到行人意图预测中。我们的方法引入了动态交通信号状态和边界框大小作为关键特征，使模型能够捕捉复杂城市环境中的时空依赖性。该模型在准确性上超越了现有方法。具体而言，TA-STGCN在PIE数据集上比基线模型提高了4.75%的准确率，证明了其在改善行人意图预测方面的有效性。", "summary": "本文提出了一种名为交通感知时空图卷积网络（TA-STGCN）的新模型，旨在提高自动驾驶中行人意图预测的准确性。该模型创新性地将动态交通信号状态（红、黄、绿）和行人边界框大小作为关键特征融入预测过程，以更好地捕捉复杂城市环境中的时空依赖性。实验结果表明，该模型在PIE数据集上比基线模型提高了4.75%的准确率，验证了其在提升行人意图预测方面的有效性。", "keywords": "行人意图预测, 交通感知, 时空图卷积网络, 自动驾驶, 交通信号", "comments": "这篇论文的创新点在于将动态交通信号及其状态作为关键上下文信息整合到行人意图预测模型中，弥补了现有模型在这方面的不足。结合边界框大小作为特征也增强了模型的感知能力。其提出的TA-STGCN模型在实际应用中对于提高自动驾驶系统的安全性具有重要意义。"}}
{"id": "2401.15801", "title": "On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension", "authors": ["Saptarshi Chakraborty", "Peter L. Bartlett"], "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Journal of Machine Learning Research (2025), volume 26", "url": "http://arxiv.org/abs/2401.15801v2", "summary": "Despite the remarkable empirical successes of Generative Adversarial Networks\n(GANs), the theoretical guarantees for their statistical accuracy remain rather\npessimistic. In particular, the data distributions on which GANs are applied,\nsuch as natural images, are often hypothesized to have an intrinsic\nlow-dimensional structure in a typically high-dimensional feature space, but\nthis is often not reflected in the derived rates in the state-of-the-art\nanalyses. In this paper, we attempt to bridge the gap between the theory and\npractice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs),\nby deriving statistical guarantees on the estimated densities in terms of the\nintrinsic dimension of the data and the latent space. We analytically show that\nif one has access to $n$ samples from the unknown target distribution and the\nnetwork architectures are properly chosen, the expected Wasserstein-1 distance\nof the estimates from the target scales as $O\\left( n^{-1/d_\\mu } \\right)$ for\nGANs and $\\tilde{O}\\left( n^{-1/(d_\\mu+\\ell)} \\right)$ for BiGANs, where\n$d_\\mu$ and $\\ell$ are the upper Wasserstein-1 dimension of the\ndata-distribution and latent-space dimension, respectively. The theoretical\nanalyses not only suggest that these methods successfully avoid the curse of\ndimensionality, in the sense that the exponent of $n$ in the error rates does\nnot depend on the data dimension but also serve to bridge the gap between the\ntheoretical analyses of GANs and the known sharp rates from optimal transport\nliterature. Additionally, we demonstrate that GANs can effectively achieve the\nminimax optimal rate even for non-smooth underlying distributions, with the use\nof interpolating generator networks.", "comment": "Journal of Machine Learning Research (2025), volume 26", "pdf_url": "http://arxiv.org/pdf/2401.15801v2", "cate": "stat.ML", "date": "2024-01-28", "updated": "2025-07-16", "AI": {"title_translation": "关于低内在数据维度生成对抗模型的统计特性", "tldr": "本文通过理论分析，证明了GANs和BiGANs在低内在维度数据上的统计准确性，并显示它们能够避免维度灾难。", "motivation": "尽管生成对抗网络（GANs）取得了显著的经验成功，但其统计准确性的理论保证仍然不尽如人意。特别是，GANs应用的数据分布（如自然图像）通常被假设在典型的高维特征空间中具有内在的低维结构，但这一点并未反映在现有分析的导出速率中。本文旨在弥合GANs及其双向变体BiGANs的理论与实践之间的差距。", "method": "本文通过推导基于数据和潜在空间内在维度的估计密度的统计保证，来弥合GANs理论与实践之间的差距。研究人员分析性地证明了，如果能够获得来自未知目标分布的n个样本，并且网络架构选择得当，GANs的估计与目标之间的预期Wasserstein-1距离按$O\\left( n^{-1/d_\\mu } \\right)$缩放，而BiGANs按$\\tilde{O}\\left( n^{-1/(d_\\mu+\\ell)} \\right)$缩放，其中$d_\\mu$和$\\ell$分别是数据分布的Wasserstein-1维度上限和潜在空间维度。此外，通过使用插值生成器网络，证明了GANs即使对于非光滑的底层分布也能有效达到极小极大最优率。", "result": "理论分析表明，这些方法成功避免了维度灾难，因为误差率中n的指数不依赖于数据维度。GANs的预期Wasserstein-1距离与目标之间的比例为$O\\left( n^{-1/d_\\mu } \\right)$，BiGANs为$\\tilde{O}\\left( n^{-1/(d_\\mu+\\ell)} \\right)$。此外，GANs即使对于非光滑的底层分布，通过使用插值生成器网络，也能有效达到极小极大最优率。", "conclusion": "本文弥合了GANs理论分析与已知最优传输文献中的尖锐速率之间的差距，并表明GANs和BiGANs在低内在维度数据上具有良好的统计特性，能够避免维度灾难，并且GANs可以达到最优率。", "translation": "尽管生成对抗网络（GANs）取得了显著的经验成功，但其统计准确性的理论保证仍然不尽如人意。特别是，GANs应用的数据分布，如自然图像，通常被假设在典型的高维特征空间中具有内在的低维结构，但这一点通常并未反映在现有分析的导出速率中。在本文中，我们试图通过推导估计密度在数据和潜在空间的内在维度方面的统计保证，来弥合GANs及其双向变体BiGANs的理论与实践之间的差距。我们分析性地表明，如果能够获得来自未知目标分布的n个样本，并且网络架构选择得当，GANs的估计与目标之间的预期Wasserstein-1距离按$O\\left( n^{-1/d_\\mu } \\right)$缩放，而BiGANs按$\\tilde{O}\\left( n^{-1/(d_\\mu+\\ell)} \\right)$缩放，其中$d_\\mu$和$\\ell$分别是数据分布的Wasserstein-1维度上限和潜在空间维度。这些理论分析不仅表明这些方法成功避免了维度灾难，即误差率中n的指数不依赖于数据维度，而且还有助于弥合GANs的理论分析与已知最优传输文献中的尖锐速率之间的差距。此外，我们证明了GANs即使对于非光滑的底层分布，通过使用插值生成器网络，也能有效达到极小极大最优率。", "summary": "本文旨在解决生成对抗网络（GANs）及其双向变体（BiGANs）在低内在维度数据上的理论与实践差距。研究人员通过推导在数据和潜在空间内在维度方面的统计保证，证明了这些模型能够避免维度灾难。具体而言，他们分析性地显示了GANs和BiGANs的Wasserstein-1距离误差率分别与$n^{-1/d_\\mu}$和$n^{-1/(d_\\mu+\\ell)}$成比例，其中$d_\\mu$是数据维度，$\\ell$是潜在空间维度。此外，研究还表明，通过插值生成器网络，GANs即使对于非光滑分布也能达到极小极大最优率。", "keywords": "生成对抗网络, 统计特性, 维度灾难, Wasserstein距离, 内在维度", "comments": "这篇论文在GANs的理论分析方面取得了重要进展，特别是在处理低内在维度数据时。它成功地弥合了GANs理论与实践之间的关键差距，提供了更乐观的统计保证，并证明了其避免维度灾难的能力。此外，关于达到非光滑分布极小极大最优率的发现也具有重要意义，增强了GANs在更广泛应用中的理论基础。"}}
{"id": "2507.08492", "title": "Dual Dimensions Geometric Representation Learning Based Document Dewarping", "authors": ["Heng Li", "Qingcai Chen", "Xiangping Wu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08492v2", "summary": "Document image dewarping remains a challenging task in the deep learning era.\nWhile existing methods have improved by leveraging text line awareness, they\ntypically focus only on a single horizontal dimension. In this paper, we\npropose a fine-grained deformation perception model that focuses on Dual\nDimensions of document horizontal-vertical-lines to improve document Dewarping\ncalled D2Dewarp. It can perceive distortion trends in different directions\nacross document details. To combine the horizontal and vertical granularity\nfeatures, an effective fusion module based on X and Y coordinate is designed to\nfacilitate interaction and constraint between the two dimensions for feature\ncomplementarity. Due to the lack of annotated line features in current public\ndewarping datasets, we also propose an automatic fine-grained annotation method\nusing public document texture images and an automatic rendering engine to build\na new large-scale distortion training dataset. The code and dataset will be\npublicly released. On public Chinese and English benchmarks, both quantitative\nand qualitative results show that our method achieves better rectification\nresults compared with the state-of-the-art methods. The dataset will be\npublicly available at https://github.com/xiaomore/DocDewarpHV", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08492v2", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-16", "AI": {"title_translation": "基于双维度几何表示学习的文档去畸变", "tldr": "提出D2Dewarp模型，通过关注文档水平和垂直双维度来改进文档去畸变，并构建了新的大型数据集。", "motivation": "文档图像去畸变在深度学习时代仍具挑战性，现有方法通常只关注单一水平维度，忽略了垂直维度。", "method": "提出名为D2Dewarp的细粒度形变感知模型，关注文档水平-垂直线的双维度以感知不同方向的形变趋势。设计了基于X和Y坐标的有效融合模块，以结合水平和垂直粒度特征。此外，针对公共去畸变数据集缺乏标注线特征的问题，提出一种利用公共文档纹理图像和自动渲染引擎构建新的大规模畸变训练数据集的自动细粒度标注方法。", "result": "在公共中英文基准测试中，D2Dewarp方法在定量和定性结果上均优于现有最先进方法，实现了更好的矫正效果。代码和数据集将公开可用。", "conclusion": "D2Dewarp模型通过引入双维度几何表示学习和构建大规模数据集，有效解决了文档去畸变任务中现有方法的局限性，并取得了SOTA性能。", "translation": "文档图像去畸变在深度学习时代仍然是一项具有挑战性的任务。虽然现有方法通过利用文本行感知能力得到了改进，但它们通常只关注单一的水平维度。在本文中，我们提出了一种名为D2Dewarp的细粒度形变感知模型，该模型侧重于文档水平-垂直线的双维度，以改进文档去畸变。它能够感知文档细节在不同方向上的畸变趋势。为了结合水平和垂直粒度特征，设计了一个基于X和Y坐标的有效融合模块，以促进两个维度之间的交互和约束，实现特征互补。由于当前公共去畸变数据集中缺乏标注线特征，我们还提出了一种使用公共文档纹理图像和自动渲染引擎构建新的大规模畸变训练数据集的自动细粒度标注方法。代码和数据集将公开发布。在公共中英文基准测试中，定量和定性结果均表明我们的方法比现有最先进的方法取得了更好的矫正结果。数据集将在https://github.com/xiaomore/DocDewarpHV公开可用。", "summary": "本文提出了一种名为D2Dewarp的文档去畸变模型，旨在解决现有方法仅关注单一水平维度的问题。D2Dewarp通过感知文档水平和垂直双维度的细粒度形变，并设计了特征融合模块来结合这两种维度的信息。此外，针对现有数据集缺乏标注线特征的问题，作者还开发了一种自动标注方法，并构建了一个新的大规模畸变训练数据集。实验结果表明，D2Dewarp在公共中英文基准测试上取得了优于现有SOTA方法的矫正效果。", "keywords": "文档去畸变, 双维度, 几何表示学习, 细粒度感知, 数据集生成", "comments": "这篇论文的创新点在于提出了双维度（水平和垂直）的几何表示学习来解决文档去畸变问题，弥补了现有方法只关注单一维度的不足。同时，为了解决数据集标注稀缺的问题，论文还提出了自动标注方法并构建了大规模数据集，这对后续研究具有重要意义。其性能超越SOTA也证明了方法的有效性。"}}
{"id": "2507.12050", "title": "IDFace: Face Template Protection for Efficient and Secure Identification", "authors": ["Sunpill Kim", "Seunghun Paik", "Chanwoo Hwang", "Dongsoo Kim", "Junbum Shin", "Jae Hong Seo"], "categories": ["cs.CR", "cs.CV", "I.5.4; K.6.5; D.4.6; I.4.7"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.12050v1", "summary": "As face recognition systems (FRS) become more widely used, user privacy\nbecomes more important. A key privacy issue in FRS is protecting the user's\nface template, as the characteristics of the user's face image can be recovered\nfrom the template. Although recent advances in cryptographic tools such as\nhomomorphic encryption (HE) have provided opportunities for securing the FRS,\nHE cannot be used directly with FRS in an efficient plug-and-play manner. In\nparticular, although HE is functionally complete for arbitrary programs, it is\nbasically designed for algebraic operations on encrypted data of predetermined\nshape, such as a polynomial ring. Thus, a non-tailored combination of HE and\nthe system can yield very inefficient performance, and many previous HE-based\nface template protection methods are hundreds of times slower than plain\nsystems without protection. In this study, we propose IDFace, a new HE-based\nsecure and efficient face identification method with template protection.\nIDFace is designed on the basis of two novel techniques for efficient searching\non a (homomorphically encrypted) biometric database with an angular metric. The\nfirst technique is a template representation transformation that sharply\nreduces the unit cost for the matching test. The second is a space-efficient\nencoding that reduces wasted space from the encryption algorithm, thus saving\nthe number of operations on encrypted templates. Through experiments, we show\nthat IDFace can identify a face template from among a database of 1M encrypted\ntemplates in 126ms, showing only 2X overhead compared to the identification\nover plaintexts.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.12050v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "IDFace：用于高效安全识别的人脸模板保护", "tldr": "IDFace提出了一种基于同态加密（HE）的新方法，用于高效安全的人脸识别和模板保护，显著提高了在加密模板上搜索的效率。", "motivation": "随着人脸识别系统（FRS）的广泛应用，用户隐私保护变得日益重要，其中一个关键问题是保护用户的人脸模板，因为模板可能被逆向工程恢复出人脸图像特征。尽管同态加密（HE）等密码工具为保护FRS提供了机会，但现有的HE方法与FRS结合时效率极低，比无保护的明文系统慢数百倍。", "method": "本研究提出了IDFace，一种新的基于同态加密（HE）的安全高效人脸识别方法，旨在实现模板保护。IDFace基于两种新颖技术设计，用于在（同态加密的）生物识别数据库上进行基于角度度量的有效搜索：1. 模板表示转换：大幅降低匹配测试的单位成本。2. 空间高效编码：减少加密算法造成的空间浪费，从而节省加密模板上的操作数量。", "result": "实验表明，IDFace可以在126毫秒内从包含100万个加密模板的数据库中识别人脸模板，与明文识别相比，开销仅为2倍。", "conclusion": "IDFace提供了一种高效且安全的人脸识别解决方案，通过同态加密实现模板保护，显著降低了与先前基于HE的方法相比的性能开销。", "translation": "随着人脸识别系统（FRS）的广泛使用，用户隐私变得越来越重要。FRS中的一个关键隐私问题是保护用户的人脸模板，因为用户的面部图像特征可以从模板中恢复。尽管同态加密（HE）等密码工具的最新进展为保护FRS提供了机会，但HE不能以高效的即插即用方式直接用于FRS。特别是，尽管HE在功能上对于任意程序都是完整的，但它基本上是为预定形状的加密数据（如多项式环）上的代数运算而设计的。因此，HE与系统未经调整的组合可能会导致非常低效的性能，并且许多以前基于HE的人脸模板保护方法比未受保护的明文系统慢数百倍。在本研究中，我们提出了IDFace，一种新的基于HE的安全高效人脸识别方法，具有模板保护功能。IDFace基于两种新颖技术设计，用于在（同态加密的）生物识别数据库上进行基于角度度量的有效搜索。第一种技术是模板表示转换，它大大降低了匹配测试的单位成本。第二种是空间高效编码，它减少了加密算法造成的空间浪费，从而节省了加密模板上的操作数量。通过实验，我们表明IDFace可以在126毫秒内从包含1M加密模板的数据库中识别人脸模板，与明文识别相比，开销仅为2倍。", "summary": "IDFace是一种基于同态加密（HE）的新型人脸识别方法，旨在解决人脸识别系统中用户隐私保护的关键问题，特别是人脸模板的安全。针对现有HE方法效率低下（比明文系统慢数百倍）的问题，IDFace引入了两种创新技术：模板表示转换以降低匹配测试的单位成本，以及空间高效编码以减少加密算法造成的空间浪费并节省加密模板上的操作。实验证明，IDFace能在126毫秒内从包含一百万个加密模板的数据库中识别出人脸模板，其开销仅为明文识别的2倍，显著提升了基于HE的人脸模板保护的效率和实用性。", "keywords": "人脸模板保护, 同态加密, 人脸识别, 安全识别, 效率", "comments": "该论文通过提出一种高效的同态加密解决方案，解决了人脸识别中一个关键的隐私问题。其创新之处在于引入了两种新颖技术（模板转换和空间高效编码），这些技术显著克服了同态加密应用于人脸模板等复杂数据结构时效率低下的难题。与之前慢数百倍的方法相比，仅2倍的开销是一个巨大的进步，使得安全的人脸识别更具实用性。"}}
{"id": "2507.12296", "title": "Humans are more gullible than LLMs in believing common psychological myths", "authors": ["Bevan Koopman", "Guido Zuccon"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12296v1", "summary": "Despite widespread debunking, many psychological myths remain deeply\nentrenched. This paper investigates whether Large Language Models (LLMs) mimic\nhuman behaviour of myth belief and explores methods to mitigate such\ntendencies. Using 50 popular psychological myths, we evaluate myth belief\nacross multiple LLMs under different prompting strategies, including\nretrieval-augmented generation and swaying prompts. Results show that LLMs\nexhibit significantly lower myth belief rates than humans, though user\nprompting can influence responses. RAG proves effective in reducing myth belief\nand reveals latent debiasing potential within LLMs. Our findings contribute to\nthe emerging field of Machine Psychology and highlight how cognitive science\nmethods can inform the evaluation and development of LLM-based systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12296v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "人类比大型语言模型更容易相信常见的心理学迷思", "tldr": "研究发现，大型语言模型（LLMs）在相信常见的心理学迷思方面比人类更不容易上当，尽管提示策略会影响其反应，而检索增强生成（RAG）能有效降低迷思信念。", "motivation": "尽管许多心理学迷思已被广泛揭穿，但它们仍然根深蒂固。本研究旨在调查大型语言模型（LLMs）是否会模仿人类的迷思信念行为，并探索减轻这种倾向的方法。", "method": "研究使用了50个流行的心理学迷思，在多种大型语言模型上，通过不同的提示策略（包括检索增强生成和引导性提示）评估了迷思信念。", "result": "结果显示，大型语言模型表现出比人类显著更低的迷思信念率，尽管用户提示会影响其反应。检索增强生成（RAG）被证明在降低迷思信念方面有效，并揭示了大型语言模型中潜在的去偏见能力。", "conclusion": "本研究结果有助于新兴的机器心理学领域，并强调了认知科学方法如何为大型语言模型系统的评估和开发提供信息。", "translation": "尽管广泛的揭穿，许多心理学迷思仍然根深蒂固。本文调查了大型语言模型（LLMs）是否模仿人类的迷思信念行为，并探索了减轻这种倾向的方法。我们使用50个流行的心理学迷思，在多种大型语言模型上，通过不同的提示策略（包括检索增强生成和引导性提示）评估了迷思信念。结果显示，大型语言模型表现出比人类显著更低的迷思信念率，尽管用户提示会影响其反应。检索增强生成（RAG）被证明在降低迷思信念方面有效，并揭示了大型语言模型中潜在的去偏见能力。我们的发现有助于新兴的机器心理学领域，并强调了认知科学方法如何为大型语言模型系统的评估和开发提供信息。", "summary": "本研究探讨了大型语言模型（LLMs）对常见心理学迷思的信念程度，并将其与人类进行比较。通过使用50个迷思和不同的提示策略（包括RAG），研究发现LLMs的迷思信念率远低于人类，且RAG能有效减少迷思信念。这表明LLMs具有去偏见的潜力，并为机器心理学和LLM开发提供了见解。", "keywords": "大型语言模型, 心理学迷思, 迷思信念, 检索增强生成, 机器心理学", "comments": "这项研究的创新之处在于将认知科学方法应用于大型语言模型的评估，揭示了LLMs在抵制心理学迷思方面的优越性。其重要性在于为LLM的去偏见和可靠性提供了新的视角，并开启了机器心理学这一新兴领域。"}}
{"id": "2505.00784", "title": "Reconfigurable legged metamachines that run on autonomous modular legs", "authors": ["Chen Yu", "David Matthews", "Jingxian Wang", "Jing Gu", "Douglas Blackiston", "Michael Rubenstein", "Sam Kriegman"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00784v2", "summary": "Legged machines are becoming increasingly agile and adaptive but they have so\nfar lacked the morphological diversity of legged animals, which have been\nrearranged and reshaped to fill millions of niches. Unlike their biological\ncounterparts, legged machines have largely converged over the past decade to\ncanonical quadrupedal and bipedal architectures that cannot be easily\nreconfigured to meet new tasks or recover from injury. Here we introduce\nautonomous modular legs: agile yet minimal, single-degree-of-freedom jointed\nlinks that can learn complex dynamic behaviors and may be freely attached to\nform legged metamachines at the meter scale. This enables rapid repair,\nredesign, and recombination of highly-dynamic modular agents that move quickly\nand acrobatically (non-quasistatically) through unstructured environments.\nBecause each module is itself a complete agent, legged metamachines are able to\nsustain deep structural damage that would completely disable other legged\nrobots. We also show how to encode the vast space of possible body\nconfigurations into a compact latent design genome that can be efficiently\nexplored, revealing a wide diversity of novel legged forms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00784v2", "cate": "cs.RO", "date": "2025-05-01", "updated": "2025-07-16", "AI": {"title_translation": "可重构的腿式元机器，由自主模块化腿驱动", "tldr": "本文介绍了可重构的腿式元机器，它们由自主模块化腿组成，具有高灵活性、快速修复能力和对结构损伤的鲁棒性，并能探索多样化的身体配置。", "motivation": "现有腿式机器缺乏生物腿式动物的形态多样性、可重构性，且难以适应新任务或从损伤中恢复。它们主要局限于固定的四足和两足结构，无法满足复杂环境的需求。", "method": "引入了“自主模块化腿”：一种敏捷、极简的单自由度关节链接，它们能学习复杂动态行为并可自由连接形成米级腿式元机器。此外，还展示了如何将大量可能的身体配置编码为紧凑的潜在设计基因组，以高效探索新颖的腿式形态。", "result": "所提出的腿式元机器实现了快速修复、重新设计和重组，能在非结构化环境中快速、灵活地移动。由于每个模块都是一个完整的代理，这些元机器能够承受深度结构损伤。研究还揭示了各种新颖的腿式形态。", "conclusion": "自主模块化腿的概念克服了传统腿式机器在形态多样性、可重构性和鲁棒性方面的局限性。这种方法能够创建高度适应性、抗损伤且能探索广阔设计空间的腿式机器人，为未来机器人设计提供了新范式。", "translation": "腿式机器正变得越来越敏捷和适应性强，但迄今为止，它们缺乏腿式动物的形态多样性，后者已被重新排列和重塑以适应数百万个生态位。与生物对应物不同，在过去十年中，腿式机器在很大程度上趋向于经典的四足和两足结构，这些结构不易重新配置以适应新任务或从损伤中恢复。在这里，我们引入了自主模块化腿：一种敏捷而又极简的、单自由度关节链接，它们可以学习复杂的动态行为，并可以自由连接形成米级腿式元机器。这使得高度动态的模块化代理能够快速、灵活地（非准静态地）在非结构化环境中移动，并能实现快速修复、重新设计和重组。由于每个模块本身都是一个完整的代理，腿式元机器能够承受深度结构损伤，而这种损伤会完全禁用其他腿式机器人。我们还展示了如何将大量可能的身体配置编码为紧凑的潜在设计基因组，该基因组可以高效探索，从而揭示了各种新颖的腿式形态。", "summary": "本文提出了一种新型的腿式元机器，其核心是“自主模块化腿”——一种敏捷、极简的单自由度关节模块。这些模块可以自由组合，形成米级尺寸的元机器，实现快速修复、灵活重构以及在非结构化环境中的动态移动。由于每个模块都具备独立功能，元机器对结构损伤具有高度鲁棒性。研究还开发了一种方法，将多种身体配置编码为紧凑的潜在设计基因组，从而高效地探索并生成了多样化的新颖腿式形态。", "keywords": "可重构机器人, 模块化机器人, 腿式运动, 元机器, 自主模块", "comments": "这项工作创新性地提出了“自主模块化腿”的概念，通过将每个腿模块设计为完整的代理，极大地提升了腿式机器的重构能力、修复速度和对损伤的鲁棒性，解决了传统机器人设计中形态固化和抗损性差的痛点。此外，通过引入潜在设计基因组来探索形态空间，也为机器人形态设计提供了高效的新途径。"}}
{"id": "2507.12417", "title": "Spontaneous Spatial Cognition Emerges during Egocentric Video Viewing through Non-invasive BCI", "authors": ["Weichen Dai", "Yuxuan Huang", "Li Zhu", "Dongjun Liu", "Yu Zhang", "Qibin Zhao", "Andrzej Cichocki", "Fabio Babiloni", "Ke Li", "Jianyu Qiu", "Gangyong Jia", "Wanzeng Kong", "Qing Wu"], "categories": ["q-bio.NC", "cs.CV", "eess.SP"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12417v1", "summary": "Humans possess a remarkable capacity for spatial cognition, allowing for\nself-localization even in novel or unfamiliar environments. While hippocampal\nneurons encoding position and orientation are well documented, the large-scale\nneural dynamics supporting spatial representation, particularly during\nnaturalistic, passive experience, remain poorly understood. Here, we\ndemonstrate for the first time that non-invasive brain-computer interfaces\n(BCIs) based on electroencephalography (EEG) can decode spontaneous,\nfine-grained egocentric 6D pose, comprising three-dimensional position and\norientation, during passive viewing of egocentric video. Despite EEG's limited\nspatial resolution and high signal noise, we find that spatially coherent\nvisual input (i.e., continuous and structured motion) reliably evokes decodable\nspatial representations, aligning with participants' subjective sense of\nspatial engagement. Decoding performance further improves when visual input is\npresented at a frame rate of 100 ms per image, suggesting alignment with\nintrinsic neural temporal dynamics. Using gradient-based backpropagation\nthrough a neural decoding model, we identify distinct EEG channels contributing\nto position -- and orientation specific -- components, revealing a distributed\nyet complementary neural encoding scheme. These findings indicate that the\nbrain's spatial systems operate spontaneously and continuously, even under\npassive conditions, challenging traditional distinctions between active and\npassive spatial cognition. Our results offer a non-invasive window into the\nautomatic construction of egocentric spatial maps and advance our understanding\nof how the human mind transforms everyday sensory experience into structured\ninternal representations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12417v1", "cate": "q-bio.NC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "通过非侵入式脑机接口在自我中心视频观看过程中出现自发空间认知", "tldr": "研究首次证明，基于EEG的非侵入性脑机接口可以在被动观看自我中心视频时解码自发、精细的自我中心6D姿态，表明大脑空间系统即使在被动条件下也能自发持续运作。", "motivation": "尽管海马神经元在位置和方向编码方面有详细记录，但支持空间表征的大尺度神经动力学，特别是在自然、被动体验期间，仍然知之甚少。本研究旨在填补这一空白。", "method": "研究利用基于脑电图（EEG）的非侵入性脑机接口（BCI）技术，在参与者被动观看自我中心视频时，解码自发的、精细的自我中心6D姿态（包括三维位置和方向）。通过梯度反向传播分析神经解码模型，识别出对位置和方向特定分量有贡献的EEG通道。", "result": "研究发现，尽管EEG空间分辨率有限且信号噪声高，但空间连贯的视觉输入（即连续且结构化的运动）能可靠地诱发可解码的空间表征，这与参与者主观的空间参与感一致。当视觉输入以每图100毫秒的帧率呈现时，解码性能进一步提高。梯度反向传播分析揭示了对位置和方向特定分量有贡献的不同EEG通道，表明一种分布式但互补的神经编码方案。", "conclusion": "这些发现表明，大脑的空间系统即使在被动条件下也能自发且持续地运行，挑战了主动和被动空间认知之间的传统区别。研究结果为自我中心空间地图的自动构建提供了一个非侵入性窗口，并增进了我们对人类思维如何将日常感官体验转化为结构化内部表征的理解。", "translation": "人类拥有卓越的空间认知能力，即使在陌生或不熟悉的环境中也能进行自我定位。尽管编码位置和方向的海马神经元已被充分记录，但支持空间表征的大尺度神经动力学，特别是在自然、被动体验期间，仍然知之甚少。本研究首次证明，基于脑电图（EEG）的非侵入性脑机接口（BCI）可以在被动观看自我中心视频时解码自发的、精细的自我中心6D姿态，包括三维位置和方向。尽管EEG的空间分辨率有限且信号噪声高，我们发现空间连贯的视觉输入（即连续且结构化的运动）能可靠地诱发可解码的空间表征，这与参与者主观的空间参与感一致。当视觉输入以每图100毫秒的帧率呈现时，解码性能进一步提高，这表明与内在神经时间动力学对齐。通过神经解码模型的基于梯度的反向传播，我们识别出对位置和方向特定分量有贡献的不同EEG通道，揭示了一种分布式但互补的神经编码方案。这些发现表明，大脑的空间系统即使在被动条件下也能自发且持续地运行，挑战了主动和被动空间认知之间的传统区别。我们的结果为自我中心空间地图的自动构建提供了一个非侵入性窗口，并增进了我们对人类思维如何将日常感官体验转化为结构化内部表征的理解。", "summary": "本研究首次利用非侵入性脑电图（EEG）脑机接口（BCI），证明在被动观看自我中心视频时，可以解码人类大脑自发的、精细的自我中心6D姿态（位置和方向）。尽管EEG分辨率有限，但研究发现空间连贯的视觉输入能可靠地诱发可解码的空间表征，且特定帧率可提高解码性能。通过分析EEG通道贡献，揭示了大脑空间系统即使在被动条件下也能自发持续运作，挑战了传统的主被动空间认知区分，并为理解自我中心空间地图的构建提供了新视角。", "keywords": "空间认知, 脑机接口, 脑电图, 自我中心姿态, 被动体验", "comments": "这项研究的创新之处在于首次通过非侵入性BCI（EEG）实现了在被动观看条件下对精细自我中心6D姿态的解码，突破了传统认为空间认知需要主动参与的观念。其重要性在于为理解大脑如何将日常感官经验转化为结构化内部空间表征提供了新的工具和见解，尤其是在自然、被动的体验背景下。这对于未来BCI在虚拟现实、辅助技术等领域的应用具有潜在意义。"}}
{"id": "2507.12466", "title": "Language Models Improve When Pretraining Data Matches Target Tasks", "authors": ["David Mizrahi", "Anders Boesen Lindbo Larsen", "Jesse Allardice", "Suzie Petryk", "Yuri Gorokhov", "Jeffrey Li", "Alex Fang", "Josh Gardner", "Tom Gunter", "Afshin Dehghan"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      44 pages, 25 figures, 13 tables", "url": "http://arxiv.org/abs/2507.12466v1", "summary": "Every data selection method inherently has a target. In practice, these\ntargets often emerge implicitly through benchmark-driven iteration: researchers\ndevelop selection strategies, train models, measure benchmark performance, then\nrefine accordingly. This raises a natural question: what happens when we make\nthis optimization explicit? To explore this, we propose benchmark-targeted\nranking (BETR), a simple method that selects pretraining documents based on\nsimilarity to benchmark training examples. BETR embeds benchmark examples and a\nsample of pretraining documents in a shared space, scores this sample by\nsimilarity to benchmarks, then trains a lightweight classifier to predict these\nscores for the full corpus. We compare data selection methods by training over\n500 models spanning $10^{19}$ to $10^{22}$ FLOPs and fitting scaling laws to\nthem. From this, we find that simply aligning pretraining data to evaluation\nbenchmarks using BETR achieves a 2.1x compute multiplier over DCLM-Baseline\n(4.7x over unfiltered data) and improves performance on 9 out of 10 tasks\nacross all scales. BETR also generalizes well: when targeting a diverse set of\nbenchmarks disjoint from our evaluation suite, it still matches or outperforms\nbaselines. Our scaling analysis further reveals a clear trend: larger models\nrequire less aggressive filtering. Overall, our findings show that directly\nmatching pretraining data to target tasks precisely shapes model capabilities\nand highlight that optimal selection strategies must adapt to model scale.", "comment": "44 pages, 25 figures, 13 tables", "pdf_url": "http://arxiv.org/pdf/2507.12466v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "预训练数据与目标任务匹配时语言模型性能提升", "tldr": "研究表明，通过使预训练数据与目标任务显式对齐，可以显著提高语言模型性能，且对于更大的模型，数据过滤可以不那么激进。", "motivation": "每种数据选择方法都固有地有一个目标，但在实践中这些目标往往通过基准驱动的迭代隐式地出现。本文旨在探讨当这种优化变得显式时会发生什么。", "method": "本文提出了一种名为基准目标排序（BETR）的简单方法，通过将预训练文档与基准训练示例的相似性进行匹配来选择数据。BETR将基准示例和预训练文档样本嵌入共享空间，根据与基准的相似性对样本进行评分，然后训练一个轻量级分类器来预测整个语料库的这些分数。通过训练超过500个模型并拟合缩放定律来比较数据选择方法。", "result": "BETR相比DCLM-Baseline实现了2.1倍的计算乘数（比未过滤数据高4.7倍），并在所有规模下提高了10个任务中的9个的性能。BETR具有良好的泛化性，即使目标基准与评估套件不相交，它也能匹配或超越基线。缩放分析揭示了一个清晰的趋势：更大的模型需要更不激进的过滤。", "conclusion": "直接将预训练数据与目标任务匹配可以精确地塑造模型能力，并且最佳选择策略必须适应模型规模。", "translation": "每种数据选择方法都固有地有一个目标。在实践中，这些目标往往通过基准驱动的迭代隐式地出现：研究人员开发选择策略，训练模型，衡量基准性能，然后相应地进行改进。这引出了一个自然的问题：当我们使这种优化显式化时会发生什么？为了探索这一点，我们提出了基准目标排序（BETR），这是一种简单的方法，根据与基准训练示例的相似性来选择预训练文档。BETR将基准示例和预训练文档样本嵌入到共享空间中，通过与基准的相似性对该样本进行评分，然后训练一个轻量级分类器来预测整个语料库的这些分数。我们通过训练超过500个跨越$10^{19}$到$10^{22}$ FLOPs的模型并对其拟合缩放定律来比较数据选择方法。从中我们发现，简单地使用BETR将预训练数据与评估基准对齐，相比DCLM-Baseline实现了2.1倍的计算乘数（比未过滤数据高4.7倍），并在所有规模下提高了10个任务中的9个的性能。BETR也具有良好的泛化性：当针对与我们的评估套件不相交的各种基准时，它仍然匹配或超越基线。我们的缩放分析进一步揭示了一个清晰的趋势：更大的模型需要更不激进的过滤。总的来说，我们的发现表明，直接将预训练数据与目标任务匹配可以精确地塑造模型能力，并强调最佳选择策略必须适应模型规模。", "summary": "本文提出了一种名为基准目标排序（BETR）的数据选择方法，旨在通过将预训练数据与目标基准任务显式对齐来提高语言模型性能。实验结果表明，BETR显着提升了计算效率和模型在多任务上的表现，且发现更大的模型对数据过滤的需求较低，强调了数据选择策略应随模型规模调整。", "keywords": "数据选择, 预训练, 语言模型, 缩放定律, 基准目标排序", "comments": "本文提出了一种新颖的数据选择方法BETR，通过将预训练数据与目标任务进行显式匹配，显著提升了语言模型的训练效率和性能。其发现更大的模型对数据过滤的需求降低，为未来大规模模型的数据策略提供了重要指导，具有重要的实践意义。"}}
{"id": "2406.17241", "title": "Understanding Language Model Circuits through Knowledge Editing", "authors": ["Huaizhi Ge", "Frank Rudzicz", "Zining Zhu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      A previous version of this document contained a hidden prompt entered by Z Zhu without knowledge of -- or consent by -- his co-authors. This version does not contain the prompt", "url": "http://arxiv.org/abs/2406.17241v4", "summary": "Recent advances in language model interpretability have identified circuits,\ncritical subnetworks that replicate model behaviors, yet how knowledge is\nstructured within these crucial subnetworks remains opaque. To gain an\nunderstanding toward the knowledge in the circuits, we conduct systematic\nknowledge editing experiments on the circuits of the GPT-2 language model. Our\nanalysis reveals intriguing patterns in how circuits respond to editing\nattempts, the extent of knowledge distribution across network components, and\nthe architectural composition of knowledge-bearing circuits. These findings\noffer insights into the complex relationship between model circuits and\nknowledge representation, deepening the understanding of how information is\norganized within language models. Our findings offer novel insights into the\n``meanings'' of the circuits, and introduce directions for further\ninterpretability and safety research of language models.", "comment": "A previous version of this document contained a hidden prompt entered\n  by Z Zhu without knowledge of -- or consent by -- his co-authors. This\n  version does not contain the prompt", "pdf_url": "http://arxiv.org/pdf/2406.17241v4", "cate": "cs.CL", "date": "2024-06-25", "updated": "2025-07-15", "AI": {"title_translation": "通过知识编辑理解语言模型电路", "tldr": "通过对GPT-2电路进行知识编辑实验，揭示了语言模型电路中知识的结构和表示方式，为模型可解释性和安全性研究提供了新方向。", "motivation": "尽管语言模型可解释性研究已识别出复制模型行为的关键子网络（电路），但知识在这些关键子网络中是如何构建的仍然不透明。本研究旨在理解电路中的知识。", "method": "对GPT-2语言模型的电路进行了系统的知识编辑实验。", "result": "分析揭示了电路如何响应编辑尝试、知识在网络组件中的分布程度以及承载知识的电路的架构组成方面引人入胜的模式。", "conclusion": "这些发现提供了关于模型电路和知识表示之间复杂关系的见解，深化了对信息在语言模型中如何组织的理解，并为语言模型的进一步可解释性和安全性研究引入了新方向。", "translation": "最近语言模型可解释性的进展已经识别出电路，即复制模型行为的关键子网络，然而知识在这些关键子网络中是如何构建的仍然不透明。为了理解电路中的知识，我们对GPT-2语言模型的电路进行了系统的知识编辑实验。我们的分析揭示了电路如何响应编辑尝试、知识在网络组件中的分布程度以及承载知识的电路的架构组成方面引人入胜的模式。这些发现提供了关于模型电路和知识表示之间复杂关系的见解，深化了对信息在语言模型中如何组织的理解。我们的发现为电路的“意义”提供了新颖的见解，并为语言模型的进一步可解释性和安全性研究引入了方向。", "summary": "该研究通过对GPT-2语言模型电路进行系统性的知识编辑实验，旨在揭示知识在语言模型关键子网络中的结构和表示方式。研究结果揭示了电路对编辑的响应模式、知识在网络组件中的分布以及知识承载电路的架构组成。这些发现深化了对模型电路与知识表示之间关系的理解，并为未来的语言模型可解释性和安全性研究提供了新方向。", "keywords": "语言模型, 电路, 知识编辑, 可解释性, 知识表示", "comments": "这项研究通过创新的知识编辑方法，为理解语言模型内部知识表示和电路功能提供了宝贵的视角。它不仅揭示了知识在模型中的组织方式，还为未来提升模型可解释性和安全性指明了方向，具有重要的理论和实践意义。"}}
{"id": "2507.12061", "title": "Toward an Intent-Based and Ontology-Driven Autonomic Security Response in Security Orchestration Automation and Response", "authors": ["Zequan Huang", "Jacques Robin", "Nicolas Herbaut", "Nourhène Ben Rabah", "Bénédicte Le Grand"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12061v1", "summary": "Modern Security Orchestration, Automation, and Response (SOAR) platforms must\nrapidly adapt to continuously evolving cyber attacks. Intent-Based Networking\nhas emerged as a promising paradigm for cyber attack mitigation through\nhigh-level declarative intents, which offer greater flexibility and persistency\nthan procedural actions. In this paper, we bridge the gap between two active\nresearch directions: Intent-Based Cyber Defense and Autonomic Cyber Defense, by\nproposing a unified, ontology-driven security intent definition leveraging the\nMITRE-D3FEND cybersecurity ontology. We also propose a general two-tiered\nmethodology for integrating such security intents into decision-theoretic\nAutonomic Cyber Defense systems, enabling hierarchical and context-aware\nautomated response capabilities. The practicality of our approach is\ndemonstrated through a concrete use case, showcasing its integration within\nnext-generation Security Orchestration, Automation, and Response platforms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12061v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "迈向安全编排自动化与响应中基于意图和本体驱动的自主安全响应", "tldr": "论文提出了一种基于本体的统一安全意图定义和两层方法，将意图驱动的自主安全响应集成到SOAR平台，以应对不断演进的网络攻击。", "motivation": "现代安全编排、自动化和响应（SOAR）平台必须快速适应不断演进的网络攻击。意图驱动网络作为一种有前景的网络攻击缓解范式出现，但意图驱动网络防御与自主网络防御之间存在差距，需要弥合。", "method": "本文提出了一种统一的、本体驱动的安全意图定义，利用MITRE-D3FEND网络安全本体。同时，提出了一种通用的两层方法，用于将此类安全意图集成到决策理论自主网络防御系统中，以实现分层和上下文感知的自动化响应能力。", "result": "通过一个具体的用例展示了该方法的实用性，并成功展示了其在下一代安全编排、自动化和响应平台中的集成。", "conclusion": "本文成功弥合了意图驱动网络防御和自主网络防御之间的差距，提出了一个统一的、本体驱动的安全意图定义和两层集成方法，从而增强了SOAR平台的自动化响应能力和对不断演进网络攻击的适应性。", "translation": "现代安全编排、自动化和响应（SOAR）平台必须快速适应不断演进的网络攻击。意图驱动网络作为一种有前景的网络攻击缓解范式出现，通过高级声明性意图，提供了比程序性操作更大的灵活性和持久性。在本文中，我们通过提出一个统一的、本体驱动的安全意图定义，利用MITRE-D3FEND网络安全本体，弥合了两个活跃研究方向之间的差距：基于意图的网络防御和自主网络防御。我们还提出了一种通用的两层方法，用于将此类安全意图集成到决策理论自主网络防御系统中，从而实现分层和上下文感知的自动化响应能力。通过一个具体的用例展示了我们方法的实用性，展示了其在下一代安全编排、自动化和响应平台中的集成。", "summary": "本文提出了一种基于意图和本体驱动的自主安全响应方法，旨在提升现代安全编排、自动化和响应（SOAR）平台应对不断演进的网络攻击的能力。通过利用MITRE-D3FEND本体，论文定义了一种统一的安全意图，并提出了一种两层方法将其集成到自主网络防御系统中，从而实现分层和上下文感知的自动化响应。该方法的实用性通过具体用例在下一代SOAR平台中得到了验证。", "keywords": "安全编排自动化与响应, 意图驱动, 本体论, 自主安全响应, 网络防御", "comments": "本文创新性地将意图驱动网络防御与自主网络防御相结合，通过引入本体论来统一安全意图的定义，并提出了实用的两层集成方法。这对于提升SOAR平台的自适应和自动化响应能力具有重要意义，解决了当前网络安全响应中灵活性和持久性的挑战。"}}
{"id": "2507.12415", "title": "SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?", "authors": ["Xinyi He", "Qian Liu", "Mingzhe Du", "Lin Yan", "Zhijie Fan", "Yiming Huang", "Zejian Yuan", "Zejun Ma"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12415v1", "summary": "Code performance optimization is paramount in real-world software engineering\nand critical for production-level systems. While Large Language Models (LLMs)\nhave demonstrated impressive capabilities in code generation and bug fixing,\ntheir proficiency in enhancing code performance at the repository level remains\nlargely unexplored. To address this gap, we introduce SWE-Perf, the first\nbenchmark specifically designed to systematically evaluate LLMs on code\nperformance optimization tasks within authentic repository contexts. SWE-Perf\ncomprises 140 carefully curated instances, each derived from\nperformance-improving pull requests from popular GitHub repositories. Each\nbenchmark instance includes the relevant codebase, target functions,\nperformance-related tests, expert-authored patches, and executable\nenvironments. Through a comprehensive evaluation of representative methods that\nspan file-level and repo-level approaches (e.g., Agentless and OpenHands), we\nreveal a substantial capability gap between existing LLMs and expert-level\noptimization performance, highlighting critical research opportunities in this\nemerging field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12415v1", "cate": "cs.SE", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "SWE-Perf：语言模型能否优化真实世界代码库中的代码性能？", "tldr": "引入了SWE-Perf，这是首个用于评估大型语言模型在真实代码库中代码性能优化能力的基准测试。研究发现现有大型语言模型与专家级优化性能之间存在显著差距。", "motivation": "代码性能优化在真实世界的软件工程和生产级系统中至关重要。尽管大型语言模型在代码生成和错误修复方面表现出色，但它们在代码库层面提升代码性能的能力仍未得到充分探索。", "method": "我们引入了SWE-Perf，这是第一个专门用于系统评估大型语言模型在真实代码库环境下代码性能优化任务的基准测试。SWE-Perf包含140个精心策划的实例，每个实例都来源于流行GitHub仓库中改进性能的拉取请求。每个基准实例都包含相关的代码库、目标函数、性能相关测试、专家编写的补丁以及可执行环境。我们还对涵盖文件级和仓库级方法的代表性方法（例如Agentless和OpenHands）进行了全面评估。", "result": "通过全面评估，我们揭示了现有大型语言模型与专家级优化性能之间存在显著的能力差距。", "conclusion": "现有大型语言模型在代码性能优化方面与专家水平存在显著差距，这突出了该新兴领域关键的研究机会。", "translation": "代码性能优化在真实世界的软件工程中至关重要，并且对于生产级系统来说至关重要。虽然大型语言模型（LLMs）在代码生成和错误修复方面展示了令人印象深刻的能力，但它们在代码库层面提升代码性能的熟练程度在很大程度上仍未被探索。为了弥补这一空白，我们引入了SWE-Perf，这是第一个专门设计用于在真实代码库环境中系统评估LLMs在代码性能优化任务上的基准测试。SWE-Perf包含140个精心策划的实例，每个实例都来源于流行GitHub仓库中改进性能的拉取请求。每个基准实例都包含相关的代码库、目标函数、性能相关测试、专家编写的补丁以及可执行环境。通过对涵盖文件级和仓库级方法（例如Agentless和OpenHands）的代表性方法进行全面评估，我们揭示了现有LLMs与专家级优化性能之间存在显著的能力差距，突出了该新兴领域关键的研究机会。", "summary": "本文介绍了SWE-Perf，一个旨在评估大型语言模型（LLMs）在真实代码库中代码性能优化能力的基准测试。该研究旨在弥补LLMs在该领域能力评估的空白。SWE-Perf包含140个源自GitHub性能优化拉取请求的实例，每个实例提供完整的代码环境、测试和专家补丁。通过对现有方法的评估，研究发现LLMs在代码性能优化方面与专家水平存在显著差距，表明该领域仍有巨大的研究潜力。", "keywords": "代码性能优化, 大型语言模型, SWE-Perf, 基准测试, 仓库级优化", "comments": "SWE-Perf的创新之处在于它是首个专门针对大型语言模型在真实代码库级别进行代码性能优化的系统性评估基准。其重要性在于揭示了当前大型语言模型在该任务上的显著能力局限性，为未来研究指明了方向。通过提供结构化的数据集和评估方法，它为进一步提升LLMs在复杂软件工程任务中的表现奠定了基础。"}}
{"id": "2507.11799", "title": "Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network", "authors": ["Shin-ichi Ito"], "categories": ["physics.comp-ph", "cs.AI"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11799v1", "summary": "This paper presents a neural network (NN)-based solver for an\nintegro-differential equation that models shrinkage-induced fragmentation. The\nproposed method directly maps input parameters to the corresponding probability\ndensity function without numerically solving the governing equation, thereby\nsignificantly reducing computational costs. Specifically, it enables efficient\nevaluation of the density function in Monte Carlo simulations while maintaining\naccuracy comparable to or even exceeding that of conventional finite difference\nschemes. Validatation on synthetic data demonstrates both the method's\ncomputational efficiency and predictive reliability. This study establishes a\nfoundation for the data-driven inverse analysis of fragmentation and suggests\nthe potential for extending the framework beyond pre-specified model\nstructures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11799v1", "cate": "physics.comp-ph", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "基于物理信息神经网络的收缩致裂碎片尺寸密度估计器", "tldr": "本文提出一种基于神经网络的求解器，用于收缩致裂的碎片化模型，能直接预测碎片尺寸密度函数，计算效率高且准确。", "motivation": "旨在开发一种高效、准确的方法，以避免数值求解收缩致裂碎片化模型中的积分微分方程所带来的高计算成本。", "method": "提出了一种基于神经网络（NN）的求解器，能够将输入参数直接映射到相应的概率密度函数，从而无需数值求解控制方程。该方法在蒙特卡洛模拟中用于高效评估密度函数。", "result": "该方法显著降低了计算成本，在蒙特卡洛模拟中能高效评估密度函数，且精度与传统有限差分方案相当或更高。在合成数据上的验证证明了其计算效率和预测可靠性。", "conclusion": "本研究为碎片化的数据驱动逆分析奠定了基础，并表明该框架有潜力扩展到预设模型结构之外。", "translation": "本文提出了一种基于神经网络（NN）的求解器，用于模拟收缩致裂碎片化的积分微分方程。所提出的方法将输入参数直接映射到相应的概率密度函数，而无需数值求解控制方程，从而显著降低了计算成本。具体而言，它能够在蒙特卡洛模拟中高效评估密度函数，同时保持与传统有限差分方案相当甚至更高的精度。在合成数据上的验证证明了该方法的计算效率和预测可靠性。这项研究为碎片化的数据驱动逆分析奠定了基础，并暗示了将该框架扩展到预设模型结构之外的潜力。", "summary": "本文开发了一种基于神经网络的求解器，用于模拟收缩致裂引起的碎片化过程。该方法通过直接映射输入参数到概率密度函数，避免了复杂的数值求解，显著提高了计算效率，并在蒙特卡洛模拟中展现出高精度。研究结果验证了其效率和可靠性，为碎片化的数据驱动逆分析提供了新途径，并有望应用于更广泛的模型结构。", "keywords": "神经网络, 碎片化, 收缩致裂, 密度估计, 计算效率", "comments": "这篇论文的创新之处在于利用神经网络直接预测碎片尺寸密度函数，避免了传统数值求解积分微分方程的计算负担，从而显著提高了效率。这种数据驱动的方法为碎片化过程的逆分析提供了新的可能性，并且具有超越特定模型结构的泛化潜力，对计算力学和材料科学领域具有重要意义。"}}
{"id": "2411.15513", "title": "SPA: Efficient User-Preference Alignment against Uncertainty in Medical Image Segmentation", "authors": ["Jiayuan Zhu", "Junde Wu", "Cheng Ouyang", "Konstantinos Kamnitsas", "J. Alison Noble"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.15513v2", "summary": "Medical image segmentation data inherently contain uncertainty. This can stem\nfrom both imperfect image quality and variability in labeling preferences on\nambiguous pixels, which depend on annotator expertise and the clinical context\nof the annotations. For instance, a boundary pixel might be labeled as tumor in\ndiagnosis to avoid under-estimation of severity, but as normal tissue in\nradiotherapy to prevent damage to sensitive structures. As segmentation\npreferences vary across downstream applications, it is often desirable for an\nimage segmentation model to offer user-adaptable predictions rather than a\nfixed output. While prior uncertainty-aware and interactive methods offer\nadaptability, they are inefficient at test time: uncertainty-aware models\nrequire users to choose from numerous similar outputs, while interactive models\ndemand significant user input through click or box prompts to refine\nsegmentation. To address these challenges, we propose \\textbf{SPA}, a new\n\\textbf{S}egmentation \\textbf{P}reference \\textbf{A}lignment framework that\nefficiently adapts to diverse test-time preferences with minimal human\ninteraction. By presenting users with a select few, distinct segmentation\ncandidates that best capture uncertainties, it reduces the user workload to\nreach the preferred segmentation. To accommodate user preference, we introduce\na probabilistic mechanism that leverages user feedback to adapt a model's\nsegmentation preference. The proposed framework is evaluated on several medical\nimage segmentation tasks: color fundus images, lung lesion and kidney CT scans,\nMRI scans of brain and prostate. SPA shows 1) a significant reduction in user\ntime and effort compared to existing interactive segmentation approaches, 2)\nstrong adaptability based on human feedback, and 3) state-of-the-art image\nsegmentation performance across different imaging modalities and semantic\nlabels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.15513v2", "cate": "eess.IV", "date": "2024-11-23", "updated": "2025-07-16", "AI": {"title_translation": "SPA：医疗图像分割中针对不确定性的高效用户偏好对齐", "tldr": "本研究提出了SPA框架，旨在通过提供少量独特的分割候选和利用用户反馈的概率机制，高效地适应医疗图像分割中的用户偏好和不确定性，显著减少用户工作量并提升性能。", "motivation": "医疗图像分割数据固有不确定性，源于图像质量不完善和标注偏好差异。现有不确定性感知和交互式方法在测试时效率低下，需要用户从大量相似输出中选择或提供大量输入。本研究的动机是解决这些效率挑战，并使模型能够提供用户可适应的预测。", "method": "本研究提出了SPA（分割偏好对齐）框架。它通过向用户呈现少量、独特的、能最好地捕捉不确定性的分割候选，以最少的人机交互高效地适应各种测试时间偏好，从而减少用户达到首选分割所需的工作量。为适应用户偏好，引入了一种概率机制，利用用户反馈来调整模型的分割偏好。", "result": "SPA显示：1) 与现有交互式分割方法相比，显著减少了用户时间和精力；2) 基于人类反馈的强大适应性；3) 在不同成像模式和语义标签上达到了最先进的图像分割性能。", "conclusion": "SPA框架有效解决了医疗图像分割中不确定性和用户适应性的挑战，提供了一个高效、用户友好且高性能的解决方案。", "translation": "医疗图像分割数据本身包含不确定性。这可能源于图像质量不完善以及对模糊像素的标注偏好差异，这些差异取决于标注者的专业知识和标注的临床背景。例如，边界像素在诊断中可能被标记为肿瘤以避免低估严重程度，但在放射治疗中可能被标记为正常组织以防止对敏感结构的损害。由于分割偏好因下游应用而异，图像分割模型通常需要提供用户可适应的预测而非固定输出。虽然先前的“不确定性感知”和“交互式”方法提供了适应性，但它们在测试时效率低下：不确定性感知模型要求用户从大量相似输出中选择，而交互式模型则需要用户通过点击或框提示提供大量输入来完善分割。为了解决这些挑战，我们提出了 **SPA**，一个全新的**S**egmentation **P**reference **A**lignment（分割偏好对齐）框架，它能够以最少的人机交互高效地适应各种测试时间偏好。通过向用户呈现少量、独特的能够最好地捕捉不确定性的分割候选，它减少了用户达到首选分割所需的工作量。为了适应用户偏好，我们引入了一种概率机制，利用用户反馈来调整模型的分割偏好。所提出的框架在多项医学图像分割任务中进行了评估：彩色眼底图像、肺部病变和肾脏CT扫描、大脑和前列腺的MRI扫描。SPA 显示：1）与现有交互式分割方法相比，显著减少了用户时间和精力；2）基于人类反馈的强大适应性；3）在不同成像模式和语义标签上达到了最先进的图像分割性能。", "summary": "本研究提出了SPA（分割偏好对齐）框架，旨在解决医学图像分割中固有的不确定性以及现有方法在测试时效率低下的问题。SPA通过向用户提供少量、独特的分割候选来有效捕捉不确定性，从而减少用户工作量并实现高效的用户偏好适应。该框架引入了一种概率机制，利用用户反馈来调整模型的分割偏好。在多项医学图像分割任务上的评估表明，SPA显著减少了用户时间和精力，展现出强大的基于人类反馈的适应性，并在不同成像模式和语义标签上实现了最先进的图像分割性能。", "keywords": "医疗图像分割, 不确定性, 用户偏好, 交互式分割, SPA", "comments": "SPA的创新之处在于其通过提供少数精选的、能捕捉不确定性的分割候选来降低用户交互成本，并结合概率机制有效整合用户反馈。这解决了传统不确定性感知和交互式方法在效率上的痛点，对于需要个性化和高效率的临床应用具有重要意义。"}}
{"id": "2312.05968", "title": "Jumpstarting Surgical Computer Vision", "authors": ["Deepak Alapatt", "Aditya Murali", "Vinkle Srivastav", "Pietro Mascagni", "AI4SafeChole Consortium", "Nicolas Padoy"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7 pages, 3 figures", "url": "http://arxiv.org/abs/2312.05968v2", "summary": "Consensus amongst researchers and industry points to a lack of large,\nrepresentative annotated datasets as the biggest obstacle to progress in the\nfield of surgical data science. Advances in Self-Supervised Learning (SSL)\nrepresent a solution, reducing the dependence on large labeled datasets by\nproviding task-agnostic initializations. However, the robustness of current\nself-supervised learning methods to domain shifts remains unclear, limiting our\nunderstanding of its utility for leveraging diverse sources of surgical data.\nShifting the focus from methods to data, we demonstrate that the downstream\nvalue of SSL-based initializations is intricately intertwined with the\ncomposition of pre-training datasets. These results underscore an important gap\nthat needs to be filled as we scale self-supervised approaches toward building\ngeneral-purpose \"foundation models\" that enable diverse use-cases within the\nsurgical domain. Through several stages of controlled experimentation, we\ndevelop recommendations for pretraining dataset composition evidenced through\nover 300 experiments spanning 20 pre-training datasets, 9 surgical procedures,\n7 centers (hospitals), 3 labeled-data settings, 3 downstream tasks, and\nmultiple runs. Using the approaches here described, we outperform\nstate-of-the-art pre-trainings on two public benchmarks for phase recognition:\nup to 2.2% on Cholec80 and 5.1% on AutoLaparo.", "comment": "7 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2312.05968v2", "cate": "cs.CV", "date": "2023-12-10", "updated": "2025-07-16", "AI": {"title_translation": "启动外科计算机视觉", "tldr": "研究表明，预训练数据集的组成对自监督学习在外科计算机视觉中的下游价值至关重要，并提出了数据集构成建议，在两个公开基准上超越了现有技术。", "motivation": "外科数据科学领域面临缺乏大型、有代表性的带注释数据集的障碍。自监督学习（SSL）虽然能减少对大型标记数据集的依赖，但其对领域变化的鲁棒性尚不清楚，限制了其在利用多样化外科数据源方面的效用。", "method": "通过受控实验，研究团队将重点从方法转向数据，探究SSL初始化的下游价值与预训练数据集组成的关系。他们进行了超过300次实验，涵盖20个预训练数据集、9种外科手术、7个中心、3种标记数据设置和3种下游任务，以开发预训练数据集组成的建议。", "result": "研究结果表明，SSL初始化的下游价值与预训练数据集的组成密切相关。通过所描述的方法，在两个用于阶段识别的公共基准测试中，性能优于现有技术：Cholec80上高达2.2%，AutoLaparo上高达5.1%。", "conclusion": "为了将自监督方法扩展到构建通用型“基础模型”，以支持外科领域内的多样化用例，填补预训练数据集组成方面的空白至关重要。研究提供了预训练数据集组成的建议，并证明了其有效性。", "translation": "研究人员和行业普遍认为，缺乏大型、具有代表性的带注释数据集是外科数据科学领域进步的最大障碍。自监督学习（SSL）的进展提供了一种解决方案，通过提供与任务无关的初始化，减少了对大型标记数据集的依赖。然而，当前自监督学习方法对领域变化的鲁棒性尚不明确，这限制了我们对其利用多样化外科外科数据源的效用理解。我们将重点从方法转移到数据，证明了基于SSL的初始化在下游任务中的价值与预训练数据集的组成密切相关。这些结果强调了一个重要的空白，即当我们扩展自监督方法以构建通用型“基础模型”以支持外科领域内的多样化用例时，需要填补这一空白。通过几个阶段的受控实验，我们提出了预训练数据集组成的建议，这些建议通过跨越20个预训练数据集、9种外科手术、7个中心（医院）、3种标记数据设置、3种下游任务和多次运行的300多次实验得到了证明。使用本文描述的方法，我们在两个用于阶段识别的公共基准测试中超越了最先进的预训练方法：Cholec80上高达2.2%，AutoLaparo上高达5.1%。", "summary": "本文探讨了自监督学习（SSL）在解决外科计算机视觉领域缺乏大规模标注数据集问题中的应用。研究发现SSL初始化的下游价值与预训练数据集的组成紧密相关，强调了构建通用“基础模型”时数据组成的重要性。通过大量受控实验，论文提出了预训练数据集组成的具体建议，并在两个公开基准测试（Cholec80和AutoLaparo）上取得了优于现有技术的性能提升。", "keywords": "自监督学习, 外科计算机视觉, 数据集组成, 基础模型, 预训练", "comments": "这篇论文通过将研究重点从自监督学习方法本身转向预训练数据集的组成，提供了一个创新的视角，解决了外科计算机视觉领域数据稀缺的关键挑战。其创新性在于系统性地探索了数据集组成对SSL下游性能的影响，并提供了实证支持的建议，这对于未来构建外科领域的基础模型具有重要指导意义。通过大规模的受控实验，论文的结论具有很强的说服力。"}}
{"id": "2507.12036", "title": "The Arrow-Hurwicz iteration for virtual element discretizations of the incompressible Navier-Stokes equations", "authors": ["Binbin Du", "Shenxiang Cheng", "Yue Yu", "Chuanjun Chen"], "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      32 pages, 6 figures", "url": "http://arxiv.org/abs/2507.12036v1", "summary": "This article presents a detailed analysis of the Arrow-Hurwicz iteration\napplied to the solution of the incompressible Navier-Stokes equations,\ndiscretized by a divergence-free mixed virtual element method. Under a set of\nappropriate assumptions, it is rigorously demonstrated that the method exhibits\ngeometric convergence, with a contraction factor that remains independent of\nthe mesh sizes. A series of numerical experiments are conducted to validate the\ntheoretical findings and to assess the computational performance of the\nproposed method.", "comment": "32 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.12036v1", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "针对不可压缩Navier-Stokes方程的虚单元离散的Arrow-Hurwicz迭代", "tldr": "本文分析了Arrow-Hurwicz迭代应用于虚单元法离散的不可压缩Navier-Stokes方程的解，并严格证明了几何收敛性，且收敛因子与网格尺寸无关。", "motivation": "解决不可压缩Navier-Stokes方程的数值解问题，并对其采用虚单元离散的Arrow-Hurwicz迭代方法的收敛性进行严格分析和验证。", "method": "采用Arrow-Hurwicz迭代法结合无散度混合虚单元法来离散和求解不可压缩Navier-Stokes方程。通过理论分析严格证明了方法的几何收敛性，并通过数值实验验证了理论结果并评估了计算性能。", "result": "严格证明了该方法具有几何收敛性，且收敛因子独立于网格尺寸。数值实验验证了理论发现并评估了所提方法的计算性能。", "conclusion": "结合Arrow-Hurwicz迭代和无散度混合虚单元法求解不可压缩Navier-Stokes方程是有效的，并且其几何收敛性已得到理论和数值验证。", "translation": "本文详细分析了Arrow-Hurwicz迭代在求解不可压缩Navier-Stokes方程中的应用，该方程通过无散度混合虚单元法离散。在一系列适当的假设下，严格证明了该方法表现出几何收敛性，其收缩因子独立于网格尺寸。进行了一系列数值实验来验证理论发现并评估所提出方法的计算性能。", "summary": "本文研究了Arrow-Hurwicz迭代应用于通过无散度混合虚单元法离散的不可压缩Navier-Stokes方程的求解。研究严格证明了该方法具有与网格尺寸无关的几何收敛性，并通过数值实验验证了理论结果和评估了计算性能。", "keywords": "Arrow-Hurwicz迭代, 虚单元法, 不可压缩Navier-Stokes方程, 几何收敛, 数值分析", "comments": "这项工作创新性地将Arrow-Hurwicz迭代与虚单元法结合，用于求解Navier-Stokes方程，并提供了严格的收敛性分析，证明了其收敛速度独立于网格尺寸，这对于数值方法的稳定性和效率至关重要。"}}
{"id": "2507.12098", "title": "A Privacy-Preserving Framework for Advertising Personalization Incorporating Federated Learning and Differential Privacy", "authors": ["Xiang Li", "Yifan Lin", "Yuanzhe Zhang"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12098v1", "summary": "To mitigate privacy leakage and performance issues in personalized\nadvertising, this paper proposes a framework that integrates federated learning\nand differential privacy. The system combines distributed feature extraction,\ndynamic privacy budget allocation, and robust model aggregation to balance\nmodel accuracy, communication overhead, and privacy protection. Multi-party\nsecure computing and anomaly detection mechanisms further enhance system\nresilience against malicious attacks. Experimental results demonstrate that the\nframework achieves dual optimization of recommendation accuracy and system\nefficiency while ensuring privacy, providing both a practical solution and a\ntheoretical foundation for applying privacy protection technologies in\nadvertisement recommendation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12098v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "一种融合联邦学习和差分隐私的广告个性化隐私保护框架", "tldr": "本文提出了一种结合联邦学习和差分隐私的框架，旨在解决个性化广告中的隐私泄露和性能问题，并在保护隐私的同时优化推荐准确性和系统效率。", "motivation": "为缓解个性化广告中的隐私泄露和性能问题。", "method": "该框架整合了联邦学习和差分隐私，具体包括分布式特征提取、动态隐私预算分配、鲁棒模型聚合、多方安全计算和异常检测机制。", "result": "实验结果表明，该框架在确保隐私的同时，实现了推荐准确性和系统效率的双重优化。", "conclusion": "该框架为广告推荐中应用隐私保护技术提供了实用的解决方案和理论基础。", "translation": "为缓解个性化广告中的隐私泄露和性能问题，本文提出了一种融合联邦学习和差分隐私的框架。该系统结合了分布式特征提取、动态隐私预算分配和鲁棒模型聚合，以平衡模型准确性、通信开销和隐私保护。多方安全计算和异常检测机制进一步增强了系统抵御恶意攻击的弹性。实验结果表明，该框架在确保隐私的同时，实现了推荐准确性和系统效率的双重优化，为广告推荐中应用隐私保护技术提供了实用的解决方案和理论基础。", "summary": "本文提出了一种将联邦学习和差分隐私相结合的框架，以解决个性化广告中的隐私泄露和性能挑战。该框架通过分布式特征提取、动态隐私预算分配、鲁棒模型聚合以及多方安全计算和异常检测机制，平衡了模型准确性、通信开销和隐私保护。实验证明，该框架在保证隐私的同时，有效提升了推荐准确性和系统效率，为广告推荐的隐私保护提供了实用与理论支持。", "keywords": "联邦学习, 差分隐私, 广告个性化, 隐私保护, 推荐系统", "comments": "该论文的创新点在于将联邦学习和差分隐私这两种主流的隐私保护技术进行融合，并针对广告个性化场景进行了优化，提出了包括分布式特征提取、动态隐私预算分配和鲁棒模型聚合等具体机制，同时引入多方安全计算和异常检测增强系统韧性，具有较高的实用价值和理论意义。"}}
{"id": "2507.11579", "title": "SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation", "authors": ["Sathvik Chereddy", "John Femiani"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 63 figures, Proceedings of the 42nd International Conference on Machine Learning (ICML2025)", "url": "http://arxiv.org/abs/2507.11579v1", "summary": "We present SketchDNN, a generative model for synthesizing CAD sketches that\njointly models both continuous parameters and discrete class labels through a\nunified continuous-discrete diffusion process. Our core innovation is\nGaussian-Softmax diffusion, where logits perturbed with Gaussian noise are\nprojected onto the probability simplex via a softmax transformation,\nfacilitating blended class labels for discrete variables. This formulation\naddresses 2 key challenges, namely, the heterogeneity of primitive\nparameterizations and the permutation invariance of primitives in CAD sketches.\nOur approach significantly improves generation quality, reducing Fr\\'echet\nInception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL)\nfrom 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch\ngeneration on the SketchGraphs dataset.", "comment": "17 pages, 63 figures, Proceedings of the 42nd International\n  Conference on Machine Learning (ICML2025)", "pdf_url": "http://arxiv.org/pdf/2507.11579v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "SketchDNN：用于CAD草图生成的连续-离散联合扩散模型", "tldr": "SketchDNN是一种生成模型，它通过新颖的连续-离散扩散过程（高斯-Softmax扩散）来生成CAD草图，显著提高了生成质量，并在CAD草图生成领域达到了新的SOTA。", "motivation": "该论文旨在通过联合建模连续参数和离散类别标签来合成CAD草图，并解决CAD草图中原始参数化的异构性和原始排列不变性两大关键挑战。", "method": "SketchDNN提出了一种名为高斯-Softmax扩散的核心创新。该方法通过统一的连续-离散扩散过程，将受高斯噪声扰动的logits通过Softmax变换投影到概率单纯形上，从而促进离散变量的混合类别标签，以此来共同建模连续参数和离散类别标签。", "result": "该方法显著提高了生成质量，将Fréchet Inception Distance (FID) 从16.04降低到7.80，将负对数似然 (NLL) 从84.8降低到81.33，在SketchGraphs数据集上的CAD草图生成方面建立了新的最先进水平。", "conclusion": "SketchDNN在CAD草图生成方面取得了显著进展，通过其创新的高斯-Softmax扩散过程，在SketchGraphs数据集上达到了新的SOTA。", "translation": "我们提出了 SketchDNN，这是一种用于合成 CAD 草图的生成模型，它通过统一的连续-离散扩散过程共同建模连续参数和离散类别标签。我们的核心创新是高斯-Softmax 扩散，其中受高斯噪声扰动的 logits 通过 Softmax 变换投影到概率单纯形上，从而促进离散变量的混合类别标签。这种公式解决了两个关键挑战，即 CAD 草图中原始参数化的异构性和原始排列不变性。我们的方法显著提高了生成质量，将 Fréchet Inception Distance (FID) 从 16.04 降低到 7.80，将负对数似然 (NLL) 从 84.8 降低到 81.33，在 SketchGraphs 数据集上的 CAD 草图生成方面建立了新的最先进水平。", "summary": "SketchDNN 是一种用于合成 CAD 草图的新型生成模型，其核心创新是高斯-Softmax 扩散。该模型通过统一的连续-离散扩散过程，成功地联合建模了连续参数和离散类别标签，并解决了 CAD 草图中原始参数化的异构性和原始排列不变性问题。实验结果表明，SketchDNN 显著提升了生成质量，在 SketchGraphs 数据集上降低了 FID 和 NLL，达到了 CAD 草图生成领域的最新水平。", "keywords": "CAD草图生成, 扩散模型, 连续-离散, 高斯-Softmax, 生成模型", "comments": "SketchDNN 的创新点在于其高斯-Softmax 扩散过程，它巧妙地将连续变量和离散变量的扩散建模统一起来，有效解决了 CAD 草图生成中的复杂挑战。其在关键指标上的显著性能提升，表明了该方法在实际应用中的巨大潜力，并为未来的 CAD 自动化设计提供了新的思路。"}}
{"id": "2507.11901", "title": "Imbalanced Regression Pipeline Recommendation", "authors": ["Juscimara G. Avelino", "George D. C. Cavalcanti", "Rafael M. O. Cruz"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11901v1", "summary": "Imbalanced problems are prevalent in various real-world scenarios and are\nextensively explored in classification tasks. However, they also present\nchallenges for regression tasks due to the rarity of certain target values. A\ncommon alternative is to employ balancing algorithms in preprocessing to\naddress dataset imbalance. However, due to the variety of resampling methods\nand learning models, determining the optimal solution requires testing many\ncombinations. Furthermore, the learning model, dataset, and evaluation metric\naffect the best strategies. This work proposes the Meta-learning for Imbalanced\nRegression (Meta-IR) framework, which diverges from existing literature by\ntraining meta-classifiers to recommend the best pipeline composed of the\nresampling strategy and learning model per task in a zero-shot fashion. The\nmeta-classifiers are trained using a set of meta-features to learn how to map\nthe meta-features to the classes indicating the best pipeline. We propose two\nformulations: Independent and Chained. Independent trains the meta-classifiers\nto separately indicate the best learning algorithm and resampling strategy.\nChained involves a sequential procedure where the output of one meta-classifier\nis used as input for another to model intrinsic relationship factors. The\nChained scenario showed superior performance, suggesting a relationship between\nthe learning algorithm and the resampling strategy per task. Compared with\nAutoML frameworks, Meta-IR obtained better results. Moreover, compared with\nbaselines of six learning algorithms and six resampling algorithms plus no\nresampling, totaling 42 (6 X 7) configurations, Meta-IR outperformed all of\nthem. The code, data, and further information of the experiments can be found\non GitHub: https://github.com/JusciAvelino/Meta-IR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11901v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "不平衡回归管线推荐", "tldr": "Meta-IR框架通过元学习推荐不平衡回归任务的最佳预处理和学习模型组合，表现优于AutoML和基线方法。", "motivation": "不平衡问题在回归任务中也存在挑战，因为某些目标值稀有。常见的做法是使用平衡算法进行预处理，但由于重采样方法和学习模型种类繁多，寻找最佳组合需要大量测试。此外，学习模型、数据集和评估指标也会影响最佳策略。", "method": "本文提出了Meta-learning for Imbalanced Regression (Meta-IR)框架。该框架通过训练元分类器，以零样本方式推荐每个任务的最佳管线（由重采样策略和学习模型组成）。元分类器使用一组元特征进行训练，以学习如何将元特征映射到指示最佳管线的类别。提出了两种公式：独立（Independent）和链式（Chained）。独立公式分别指示最佳学习算法和重采样策略；链式公式涉及一个顺序过程，其中一个元分类器的输出作为另一个的输入，以建模内在关系因素。", "result": "链式（Chained）场景表现出卓越的性能，表明学习算法和重采样策略之间存在任务相关的关系。与AutoML框架相比，Meta-IR获得了更好的结果。此外，与包含六种学习算法和六种重采样算法（加上不重采样，共42种配置）的基线相比，Meta-IR的表现优于所有基线。", "conclusion": "Meta-IR框架通过元学习，能够有效地为不平衡回归任务推荐最佳的重采样策略和学习模型组合，尤其链式方法考虑了二者之间的内在关系，取得了显著的性能提升。", "translation": "不平衡问题在各种现实场景中普遍存在，并在分类任务中得到了广泛探索。然而，由于某些目标值的稀有性，它们也给回归任务带来了挑战。一种常见的替代方法是在预处理中采用平衡算法来解决数据集不平衡问题。然而，由于重采样方法和学习模型的种类繁多，确定最佳解决方案需要测试许多组合。此外，学习模型、数据集和评估指标也会影响最佳策略。这项工作提出了不平衡回归元学习（Meta-IR）框架，它与现有文献不同，通过训练元分类器，以零样本方式为每个任务推荐由重采样策略和学习模型组成的最佳管线。元分类器使用一组元特征进行训练，以学习如何将元特征映射到指示最佳管线的类别。我们提出了两种公式：独立（Independent）和链式（Chained）。独立公式训练元分类器以分别指示最佳学习算法和重采样策略。链式公式涉及一个顺序过程，其中一个元分类器的输出用作另一个的输入，以建模内在关系因素。链式场景表现出卓越的性能，表明学习算法和重采样策略之间存在任务相关的关系。与AutoML框架相比，Meta-IR获得了更好的结果。此外，与六种学习算法和六种重采样算法（加上不重采样，总共42种（6 X 7）配置）的基线相比，Meta-IR的表现优于所有基线。实验的代码、数据和更多信息可在GitHub上找到：https://github.com/JusciAvelino/Meta-IR。", "summary": "本文提出Meta-IR框架，旨在解决不平衡回归任务中选择最佳预处理（重采样）和学习模型组合的挑战。Meta-IR通过训练元分类器，利用元特征以零样本方式推荐最佳管线。研究提出了独立和链式两种公式，其中链式公式通过建模学习算法与重采样策略间的内在关系，表现出更优越的性能。实验结果表明，Meta-IR优于AutoML框架和多种基线配置，有效提升了不平衡回归问题的解决方案效率和效果。", "keywords": "不平衡回归, 元学习, 管线推荐, 重采样, 机器学习", "comments": "该论文的创新点在于将元学习应用于不平衡回归问题，并提出了一种零样本推荐最佳管线的方法。特别值得关注的是，其链式（Chained）公式揭示了学习算法和重采样策略之间可能存在的内在关联，这为未来的研究提供了新的视角。该框架能够显著减少寻找最佳解决方案所需的测试组合数量，对于实际应用具有重要价值。"}}
{"id": "2507.11925", "title": "Schrödinger Bridge Consistency Trajectory Models for Speech Enhancement", "authors": ["Shuichiro Nishigori", "Koichi Saito", "Naoki Murata", "Masato Hirano", "Shusuke Takahashi", "Yuki Mitsufuji"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11925v1", "summary": "Speech enhancement (SE) utilizing diffusion models is a promising technology\nthat improves speech quality in noisy speech data. Furthermore, the\nSchr\\\"odinger bridge (SB) has recently been used in diffusion-based SE to\nimprove speech quality by resolving a mismatch between the endpoint of the\nforward process and the starting point of the reverse process. However, the SB\nstill exhibits slow inference owing to the necessity of a large number of\nfunction evaluations (NFE) for inference to obtain high-quality results. While\nConsistency Models (CMs) address this issue by employing consistency training\nthat uses distillation from pretrained models in the field of image generation,\nit does not improve generation quality when the number of steps increases. As a\nsolution to this problem, Consistency Trajectory Models (CTMs) not only\naccelerate inference speed but also maintain a favorable trade-off between\nquality and speed. Furthermore, SoundCTM demonstrates the applicability of CTM\ntechniques to the field of sound generation. In this paper, we present\nSchr\\\"odinger bridge Consistency Trajectory Models (SBCTM) by applying the\nCTM's technique to the Schr\\\"odinger bridge for SE. Additionally, we introduce\na novel auxiliary loss, including a perceptual loss, into the original CTM's\ntraining framework. As a result, SBCTM achieves an approximately 16x\nimprovement in the real-time factor (RTF) compared to the conventional\nSchr\\\"odinger bridge for SE. Furthermore, the favorable trade-off between\nquality and speed in SBCTM allows for time-efficient inference by limiting\nmulti-step refinement to cases where 1-step inference is insufficient. Our\ncode, pretrained models, and audio samples are available at\nhttps://github.com/sony/sbctm/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11925v1", "cate": "cs.SD", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "用于语音增强的薛定谔桥一致性轨迹模型", "tldr": "提出薛定谔桥一致性轨迹模型 (SBCTM)，通过结合一致性轨迹模型 (CTM) 和薛定谔桥 (SB) 来显著加速语音增强，同时保持高质量。", "motivation": "现有的基于扩散模型的语音增强方法中，薛定谔桥 (SB) 虽能改善语音质量，但推理速度慢；而一致性模型 (CMs) 虽能加速推理，但无法在增加步数时提高生成质量。本文旨在解决SB推理速度慢的问题，并保持质量。", "method": "提出薛定谔桥一致性轨迹模型 (SBCTM)，通过将一致性轨迹模型 (CTM) 的技术应用于语音增强的薛定谔桥。此外，还在原始 CTM 的训练框架中引入了一种新颖的辅助损失，包括感知损失。", "result": "SBCTM 在实时因子 (RTF) 上比传统薛定谔桥语音增强提高了约 16 倍。此外，SBCTM 在质量和速度之间取得了良好的平衡，通过限制多步细化，实现了时间高效的推理。", "conclusion": "SBCTM 成功地将一致性轨迹模型应用于薛定谔桥语音增强，显著提高了推理速度并保持了高质量，从而克服了传统薛定谔桥和一致性模型在速度和质量方面的局限性。", "translation": "利用扩散模型的语音增强 (SE) 是一种很有前途的技术，可以改善嘈杂语音数据中的语音质量。此外，薛定谔桥 (SB) 最近也被用于基于扩散的 SE 中，通过解决前向过程终点和反向过程起点之间的不匹配来提高语音质量。然而，SB 仍然表现出推理缓慢的问题，因为需要大量的函数评估 (NFE) 才能获得高质量的结果。虽然一致性模型 (CMs) 通过在图像生成领域使用来自预训练模型的蒸馏一致性训练来解决这个问题，但当步数增加时，它并不能提高生成质量。作为该问题的一个解决方案，一致性轨迹模型 (CTMs) 不仅加快了推理速度，而且在质量和速度之间保持了良好的权衡。此外，SoundCTM 证明了 CTM 技术在声音生成领域的适用性。在本文中，我们通过将 CTM 的技术应用于用于 SE 的薛定谔桥，提出了薛定谔桥一致性轨迹模型 (SBCTM)。此外，我们在原始 CTM 的训练框架中引入了一种新颖的辅助损失，包括感知损失。结果，与传统的用于 SE 的薛定谔桥相比，SBCTM 在实时因子 (RTF) 上实现了大约 16 倍的改进。此外，SBCTM 在质量和速度之间取得了良好的权衡，通过将多步细化限制在 1 步推理不足的情况，从而实现时间高效的推理。我们的代码、预训练模型和音频样本可在 https://github.com/sony/sbctm/ 获取。", "summary": "本文针对基于扩散模型的语音增强中薛定谔桥 (SB) 推理速度慢的问题，提出了一种名为薛定谔桥一致性轨迹模型 (SBCTM) 的新方法。SBCTM 将一致性轨迹模型 (CTM) 的技术与 SB 结合，并引入了包括感知损失在内的新型辅助损失。实验结果表明，SBCTM 相较于传统 SB 语音增强，实时因子提高了约 16 倍，并在质量和速度之间实现了良好的平衡，使得高效推理成为可能。", "keywords": "语音增强, 薛定谔桥, 一致性轨迹模型, 扩散模型, 实时因子", "comments": "本文通过将一致性轨迹模型 (CTM) 应用于薛定谔桥 (SB) 并引入新的感知损失，成功解决了SB语音增强推理速度慢的瓶颈。其创新性在于有效结合了两种先进的生成模型技术，并针对语音任务进行了优化。16倍的实时因子提升对于实际应用具有重要意义，表明该方法在保持高质量的同时，显著提高了效率。"}}
{"id": "2404.09158", "title": "StreakNet-Arch: An Anti-scattering Network-based Architecture for Underwater Carrier LiDAR-Radar Imaging", "authors": ["Xuelong Li", "Hongjun An", "Haofei Zhao", "Guangying Li", "Bo Liu", "Xing Wang", "Guanghua Cheng", "Guojun Wu", "Zhe Sun"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Image Processing (T-IP)", "url": "http://arxiv.org/abs/2404.09158v4", "summary": "In this paper, we introduce StreakNet-Arch, a real-time, end-to-end\nbinary-classification framework based on our self-developed Underwater Carrier\nLiDAR-Radar (UCLR) that embeds Self-Attention and our novel Double Branch Cross\nAttention (DBC-Attention) to enhance scatter suppression. Under controlled\nwater tank validation conditions, StreakNet-Arch with Self-Attention or\nDBC-Attention outperforms traditional bandpass filtering and achieves higher\n$F_1$ scores than learning-based MP networks and CNNs at comparable model size\nand complexity. Real-time benchmarks on an NVIDIA RTX 3060 show a constant\nAverage Imaging Time (54 to 84 ms) regardless of frame count, versus a linear\nincrease (58 to 1,257 ms) for conventional methods. To facilitate further\nresearch, we contribute a publicly available streak-tube camera image dataset\ncontains 2,695,168 real-world underwater 3D point cloud data. More importantly,\nwe validate our UCLR system in a South China Sea trial, reaching an error of\n46mm for 3D target at 1,000 m depth and 20 m range. Source code and data are\navailable at https://github.com/BestAnHongjun/StreakNet .", "comment": "Accepted by IEEE Transactions on Image Processing (T-IP)", "pdf_url": "http://arxiv.org/pdf/2404.09158v4", "cate": "cs.CV", "date": "2024-04-14", "updated": "2025-07-16", "AI": {"title_translation": "StreakNet-Arch：一种用于水下载波LiDAR-雷达成像的抗散射网络架构", "tldr": "本文提出StreakNet-Arch，一种基于自研水下载波LiDAR-雷达的实时端到端二分类框架，通过嵌入自注意力机制和双分支交叉注意力（DBC-Attention）有效抑制散射，并在水箱验证和南海海试中表现出色。", "motivation": "水下成像面临散射问题，需要有效抑制散射以提高成像质量。", "method": "提出StreakNet-Arch，一个实时、端到端的二分类框架，基于自研的水下载波LiDAR-雷达（UCLR）系统。该框架嵌入了自注意力机制和新颖的双分支交叉注意力（DBC-Attention）来增强散射抑制能力。", "result": "在受控水箱条件下，StreakNet-Arch结合自注意力或DBC-Attention的性能优于传统带通滤波，并在相似模型尺寸和复杂度下，比基于学习的MP网络和CNNs获得更高的$F_1$分数。在NVIDIA RTX 3060上的实时基准测试显示，StreakNet-Arch的平均成像时间（54至84毫秒）保持恒定，不受帧数影响，而传统方法则呈线性增长（58至1,257毫秒）。此外，作者贡献了一个包含2,695,168个真实水下3D点云数据的公开条纹管相机图像数据集。最重要的是，在南海海试中验证了UCLR系统，对于1,000米深度、20米范围内的3D目标，误差达到46毫米。", "conclusion": "StreakNet-Arch显著提升了水下载波LiDAR-雷达成像的抗散射能力和实时性能，并在实际海试中验证了其高精度3D目标定位能力。", "translation": "在本文中，我们介绍StreakNet-Arch，这是一个基于我们自主开发的水下载波LiDAR-雷达（UCLR）的实时、端到端二分类框架，该框架嵌入了自注意力机制和我们新颖的双分支交叉注意力（DBC-Attention）以增强散射抑制。在受控水箱验证条件下，带有自注意力或DBC-Attention的StreakNet-Arch优于传统带通滤波，并在相似的模型尺寸和复杂度下，比基于学习的MP网络和CNNs获得了更高的$F_1$分数。在NVIDIA RTX 3060上的实时基准测试显示，无论帧数多少，平均成像时间（54到84毫秒）保持恒定，而传统方法则呈线性增加（58到1,257毫秒）。为了促进进一步的研究，我们贡献了一个公开可用的条纹管相机图像数据集，其中包含2,695,168个真实世界水下3D点云数据。更重要的是，我们在南海海试中验证了我们的UCLR系统，在1,000米深度和20米范围内的3D目标误差达到46毫米。源代码和数据可在https://github.com/BestAnHongjun/StreakNet 获取。", "summary": "本文提出了一种名为StreakNet-Arch的实时端到端二分类框架，用于水下载波LiDAR-雷达成像。该框架基于自研UCLR系统，并集成了自注意力机制和新颖的双分支交叉注意力（DBC-Attention）以有效抑制水下散射。实验结果表明，StreakNet-Arch在水箱验证中性能优于传统方法和现有学习模型，并在实时性方面表现出显著优势。此外，该研究还发布了一个大型水下3D点云数据集，并通过南海海试验证了UCLR系统在深水环境下实现高精度3D目标定位的能力。", "keywords": "水下成像, LiDAR-雷达, 散射抑制, 深度学习, StreakNet-Arch", "comments": "该论文的创新点在于提出了结合自注意力与双分支交叉注意力机制的StreakNet-Arch网络架构，有效解决了水下成像散射抑制和实时性问题。其重要性体现在不仅在受控环境下表现出色，更通过南海海试验证了系统在真实复杂水下环境中的高精度和鲁棒性。同时，公开数据集的贡献将极大地推动水下成像领域的研究进展。"}}
{"id": "2507.10628", "title": "GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning", "authors": ["Ziru Liu", "Cheng Gong", "Xinyu Fu", "Yaofang Liu", "Ran Chen", "Shoubo Hu", "Suiyun Zhang", "Rui Liu", "Qingfu Zhang", "Dandan Tu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Code avaiable at this https URL", "url": "http://arxiv.org/abs/2507.10628v2", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as\na powerful paradigm for facilitating the self-improvement of large language\nmodels (LLMs), particularly in the domain of complex reasoning tasks. However,\nprevailing on-policy RL methods often contend with significant training\ninstability and inefficiency. This is primarily due to a capacity-difficulty\nmismatch, where the complexity of training data frequently outpaces the model's\ncurrent capabilities, leading to critically sparse reward signals and stalled\nlearning progress. This challenge is particularly acute for smaller, more\nresource-efficient LLMs. To overcome this, we introduce the Guided Hybrid\nPolicy Optimization (GHPO), a novel difficulty-aware reinforcement learning\nframework. GHPO dynamically calibrates task difficulty by employing adaptive\nprompt refinement to provide targeted guidance. This unique approach adaptively\nbalances direct imitation learning for problems currently beyond the model's\nreach with exploration-based reinforcement learning for more manageable tasks,\neffectively creating a smooth and optimized learning curriculum. Extensive\nexperiments demonstrate that GHPO achieves an average performance gain of\napproximately 5% across six challenging mathematics benchmarks, consistently\noutperforming strong on-policy reinforcement learning and curriculum learning\nbaselines. Further analysis confirms that our framework significantly enhances\nboth training stability and final reasoning performance, thus offering a\nscalable and efficient solution for developing powerful and robust reasoning\nmodels.", "comment": "Code avaiable at https://github.com/hkgc-1/GHPO", "pdf_url": "http://arxiv.org/pdf/2507.10628v2", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "GHPO：用于稳定高效LLM强化学习的自适应指导", "tldr": "GHPO通过自适应提示细化，为LLM强化学习提供引导，解决训练不稳定和效率低下的问题，尤其对小型LLM有效，并在数学基准测试中显著提升性能和训练稳定性。", "motivation": "现有的大语言模型（LLMs）可验证奖励强化学习（RLVR）方法在复杂推理任务中存在训练不稳定和效率低下的问题。这主要是由于模型能力与训练数据难度不匹配，导致奖励信号稀疏和学习停滞，尤其对于小型LLM更为严重。", "method": "本文提出了引导式混合策略优化（GHPO）框架。GHPO通过自适应提示细化动态调整任务难度，提供有针对性的指导。它在模型能力不足时采用直接模仿学习，在任务可管理时采用基于探索的强化学习，从而创建平滑优化的学习课程。", "result": "GHPO在六个具有挑战性的数学基准测试中平均性能提升约5%，始终优于现有的在线强化学习和课程学习基线。实验证实GHPO显著提高了训练稳定性和最终推理性能。", "conclusion": "GHPO为开发强大且鲁棒的推理模型提供了一种可扩展且高效的解决方案，通过动态调整任务难度和结合模仿学习与强化学习，有效解决了LLM强化学习中的稳定性与效率问题。", "translation": "可验证奖励强化学习（RLVR）最近已成为促进大型语言模型（LLMs）自我改进的强大范式，尤其在复杂推理任务领域。然而，主流的在线强化学习方法常常面临显著的训练不稳定性和低效率问题。这主要是由于能力-难度不匹配，即训练数据的复杂性经常超出模型当前的能力，导致奖励信号极其稀疏和学习进展停滞。这一挑战对于更小、资源效率更高的LLM尤为突出。为了克服这个问题，我们引入了引导式混合策略优化（GHPO），一种新颖的难度感知强化学习框架。GHPO通过采用自适应提示细化来提供有针对性的指导，从而动态校准任务难度。这种独特的方法自适应地平衡了对于模型当前能力范围之外的问题的直接模仿学习，以及对于更易管理任务的基于探索的强化学习，有效地创建了一个平滑且优化的学习课程。广泛的实验表明，GHPO在六个具有挑战性的数学基准测试中平均实现了约5%的性能提升，持续优于强大的在线强化学习和课程学习基线。进一步的分析证实，我们的框架显著增强了训练稳定性和最终推理性能，从而为开发强大而鲁棒的推理模型提供了一种可扩展且高效的解决方案。", "summary": "本文提出了一种名为引导式混合策略优化（GHPO）的新型强化学习框架，旨在解决大语言模型（LLMs）在复杂推理任务中面临的训练不稳定和效率低下问题。GHPO通过自适应提示细化动态调整任务难度，并结合模仿学习与探索性强化学习，以适应模型的当前能力。实验结果显示，GHPO在多个数学基准测试中表现优异，平均性能提升约5%，并显著提高了训练稳定性和推理性能，为LLM的强化学习提供了一个高效且可扩展的解决方案。", "keywords": "强化学习, 大语言模型, 自适应指导, 稳定性, 效率", "comments": "GHPO的创新之处在于其“难度感知”和“自适应提示细化”机制，有效解决了LLM强化学习中长期存在的“能力-难度不匹配”问题。通过动态平衡模仿学习和探索性强化学习，它为模型提供了一个定制化的学习路径，对提升小型LLM的性能和稳定性尤其重要。这对于资源受限环境下的LLM部署具有重要意义。"}}
{"id": "2507.12185", "title": "Exploiting Jailbreaking Vulnerabilities in Generative AI to Bypass Ethical Safeguards for Facilitating Phishing Attacks", "authors": ["Rina Mishra", "Gaurav Varshney"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12185v1", "summary": "The advent of advanced Generative AI (GenAI) models such as DeepSeek and\nChatGPT has significantly reshaped the cybersecurity landscape, introducing\nboth promising opportunities and critical risks. This study investigates how\nGenAI powered chatbot services can be exploited via jailbreaking techniques to\nbypass ethical safeguards, enabling the generation of phishing content,\nrecommendation of hacking tools, and orchestration of phishing campaigns. In\nethically controlled experiments, we used ChatGPT 4o Mini selected for its\naccessibility and status as the latest publicly available model at the time of\nexperimentation, as a representative GenAI system. Our findings reveal that the\nmodel could successfully guide novice users in executing phishing attacks\nacross various vectors, including web, email, SMS (smishing), and voice\n(vishing). Unlike automated phishing campaigns that typically follow detectable\npatterns, these human-guided, AI assisted attacks are capable of evading\ntraditional anti phishing mechanisms, thereby posing a growing security threat.\nWe focused on DeepSeek and ChatGPT due to their widespread adoption and\ntechnical relevance in 2025. The study further examines common jailbreaking\ntechniques and the specific vulnerabilities exploited in these models. Finally,\nwe evaluate a range of mitigation strategies such as user education, advanced\nauthentication mechanisms, and regulatory policy measures and discuss emerging\ntrends in GenAI facilitated phishing, outlining future research directions to\nstrengthen cybersecurity defenses in the age of artificial intelligence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12185v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "利用生成式AI中的越狱漏洞绕过道德保障以促进网络钓鱼攻击", "tldr": "本研究探讨了如何利用越狱技术绕过生成式AI的道德保障，使其能够生成网络钓鱼内容并协助执行网络钓鱼攻击，这些攻击难以被传统反网络钓鱼机制检测到，并提出了缓解策略。", "motivation": "先进的生成式AI模型（如DeepSeek和ChatGPT）重塑了网络安全格局，带来了机遇和风险。本研究旨在调查如何通过越狱技术利用生成式AI聊天机器人服务来绕过道德保障，从而生成网络钓鱼内容、推荐黑客工具并策划网络钓鱼活动。", "method": "研究使用了ChatGPT 4o Mini作为代表性生成式AI系统，进行了道德控制的实验。研究检查了常见的越狱技术以及这些模型中被利用的特定漏洞。最后，评估了一系列缓解策略。", "result": "研究发现，ChatGPT 4o Mini模型能够成功指导新手用户通过网络、电子邮件、短信（smishing）和语音（vishing）等多种途径执行网络钓鱼攻击。与自动化网络钓鱼活动不同，这些由人类指导、AI辅助的攻击能够规避传统的反网络钓鱼机制，构成日益增长的安全威胁。", "conclusion": "生成式AI模型中存在的越狱漏洞使得它们能够被滥用以协助网络钓鱼攻击，这些攻击难以被传统安全机制检测到，因此需要加强网络安全防御，包括用户教育、高级认证机制和监管政策措施。", "translation": "先进的生成式AI（GenAI）模型，如DeepSeek和ChatGPT的出现，显著重塑了网络安全格局，带来了有希望的机遇和关键的风险。本研究调查了如何通过越狱技术利用GenAI驱动的聊天机器人服务来绕过道德保障，从而生成网络钓鱼内容、推荐黑客工具和策划网络钓鱼活动。在道德控制的实验中，我们使用了ChatGPT 4o Mini作为代表性GenAI系统，该模型因其可访问性和在实验时作为最新公开可用模型而被选中。我们的研究结果表明，该模型能够成功指导新手用户通过各种途径执行网络钓鱼攻击，包括网络、电子邮件、短信（smishing）和语音（vishing）。与通常遵循可检测模式的自动化网络钓鱼活动不同，这些由人类指导、AI辅助的攻击能够规避传统的反网络钓鱼机制，从而构成日益增长的安全威胁。我们重点关注DeepSeek和ChatGPT，因为它们在2025年被广泛采用且具有技术相关性。本研究进一步检查了常见的越狱技术以及这些模型中被利用的特定漏洞。最后，我们评估了一系列缓解策略，如用户教育、高级认证机制和监管政策措施，并讨论了GenAI促成的网络钓鱼的新兴趋势，概述了在人工智能时代加强网络安全防御的未来研究方向。", "summary": "本研究探讨了生成式AI模型（如DeepSeek和ChatGPT）中存在的越狱漏洞如何被利用来绕过道德保障，从而协助生成网络钓鱼内容和执行多向量网络钓鱼攻击。实验表明，AI辅助的网络钓鱼攻击比传统自动化攻击更难被检测。论文还分析了常见的越狱技术、被利用的漏洞，并评估了用户教育、高级认证和监管政策等缓解策略，展望了未来研究方向以增强AI时代下的网络安全防御。", "keywords": "生成式AI, 网络钓鱼, 越狱, 网络安全, 漏洞", "comments": "该论文揭示了生成式AI在网络安全领域的一个重要且日益增长的威胁，即通过越狱利用其能力进行网络钓鱼。其创新之处在于，它不仅识别了这一威胁，还通过受控实验证明了AI辅助攻击的有效性和隐蔽性。论文强调了传统反网络钓鱼机制的局限性，并提出了多方面的缓解策略，对于理解和应对AI驱动的网络安全风险具有重要意义。"}}
{"id": "2504.16946", "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation", "authors": ["Xiaotong Ye", "Nicolas Bougie", "Toshihiko Yamasaki", "Narimasa Watanabe"], "categories": ["cs.SI", "cs.AI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.16946v2", "summary": "Generative agents offer promising capabilities for simulating realistic urban\nbehaviors. However, existing methods oversimplify transportation choices, rely\nheavily on static agent profiles leading to behavioral homogenization, and\ninherit prohibitive computational costs. To address these limitations, we\npresent MobileCity, a lightweight simulation platform designed to model\nrealistic urban mobility with high computational efficiency. We introduce a\ncomprehensive transportation system with multiple transport modes, and collect\nquestionnaire data from respondents to construct agent profiles. To enable\nscalable simulation, agents perform action selection within a pre-generated\naction space and uses local models for efficient agent memory generation.\nThrough extensive micro and macro-level evaluations on 4,000 agents, we\ndemonstrate that MobileCity generates more realistic urban behaviors than\nbaselines while maintaining computational efficiency. We further explore\npractical applications such as predicting movement patterns and analyzing\ndemographic trends in transportation preferences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.16946v2", "cate": "cs.SI", "date": "2025-04-18", "updated": "2025-07-16", "AI": {"title_translation": "MobileCity：一个高效的大规模城市行为模拟框架", "tldr": "MobileCity是一个轻量级的模拟平台，通过引入多模式交通系统和高效的代理记忆生成，解决了现有城市行为模拟中交通选择简化、行为同质化和计算成本高昂的问题，实现了大规模高效且真实的城市行为模拟。", "motivation": "现有生成式代理在模拟真实城市行为时，存在交通选择过于简化、过度依赖静态代理配置文件导致行为同质化，以及计算成本过高的问题。", "method": "MobileCity引入了包含多种交通模式的综合交通系统，并收集问卷数据来构建代理配置文件。为了实现可扩展模拟，代理在预生成的动作空间内执行动作选择，并使用局部模型高效生成代理记忆。", "result": "在对4000个代理进行广泛的微观和宏观层面评估后，MobileCity比基线模型生成了更真实的城市行为，同时保持了计算效率。", "conclusion": "MobileCity成功地提供了一个高效且真实的城市行为模拟平台，能够支持预测移动模式和分析交通偏好中的人口趋势等实际应用。", "translation": "生成式代理为模拟真实的城市行为提供了有前景的能力。然而，现有方法过度简化了交通选择，过度依赖静态代理配置文件导致行为同质化，并继承了高昂的计算成本。为了解决这些限制，我们提出了MobileCity，一个轻量级的模拟平台，旨在以高计算效率模拟真实的城市移动性。我们引入了一个包含多种交通模式的综合交通系统，并收集问卷数据来构建代理配置文件。为了实现可扩展模拟，代理在预生成的动作空间内执行动作选择，并使用局部模型高效生成代理记忆。通过对4000个代理进行广泛的微观和宏观层面评估，我们证明MobileCity比基线模型生成了更真实的城市行为，同时保持了计算效率。我们进一步探索了实际应用，例如预测移动模式和分析交通偏好中的人口趋势。", "summary": "MobileCity是一个轻量级、高效的城市行为模拟框架，旨在解决现有生成式代理模拟中交通选择简化、行为同质化及高计算成本的问题。它通过引入多模式交通系统、基于问卷数据构建代理配置文件、以及利用预生成动作空间和局部模型进行高效代理记忆生成，实现了大规模、高计算效率且更真实的城市行为模拟。实验证明其在生成真实行为方面优于基线模型，并可应用于移动模式预测和人口交通偏好分析。", "keywords": "城市行为模拟, 交通系统, 生成式代理, 计算效率, MobileCity", "comments": "该论文的创新点在于提出了一个轻量级且高效的框架MobileCity，有效解决了现有城市行为模拟中存在的交通选择简化、行为同质化和计算成本高昂的关键限制。通过引入多模式交通系统和优化的代理行为生成机制，显著提升了模拟的真实性和可扩展性，对于城市规划和交通管理具有重要的实际应用价值。"}}
{"id": "2507.11968", "title": "Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation", "authors": ["Sahid Hossain Mustakim", "S M Jishanul Islam", "Ummay Maria Muna", "Montasir Chowdhury", "Mohammed Jawwadul Islam", "Sadia Ahmmed", "Tashfia Sikder", "Syed Tasdid Azam Dhrubo", "Swakkhar Shatabda"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted as long paper, SVU Workshop at ICCV 2025", "url": "http://arxiv.org/abs/2507.11968v1", "summary": "Multimodal Large Language Models (MLLMs) are increasingly used for content\nmoderation, yet their robustness in short-form video contexts remains\nunderexplored. Current safety evaluations often rely on unimodal attacks,\nfailing to address combined attack vulnerabilities. In this paper, we introduce\na comprehensive framework for evaluating the tri-modal safety of MLLMs. First,\nwe present the Short-Video Multimodal Adversarial (SVMA) dataset, comprising\ndiverse short-form videos with human-guided synthetic adversarial attacks.\nSecond, we propose ChimeraBreak, a novel tri-modal attack strategy that\nsimultaneously challenges visual, auditory, and semantic reasoning pathways.\nExtensive experiments on state-of-the-art MLLMs reveal significant\nvulnerabilities with high Attack Success Rates (ASR). Our findings uncover\ndistinct failure modes, showing model biases toward misclassifying benign or\npolicy-violating content. We assess results using LLM-as-a-judge, demonstrating\nattack reasoning efficacy. Our dataset and findings provide crucial insights\nfor developing more robust and safe MLLMs.", "comment": "Accepted as long paper, SVU Workshop at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.11968v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "观看、聆听、理解、误导：针对短视频内容适宜性评估的三模态对抗性攻击", "tldr": "本文引入了一个三模态对抗性攻击框架ChimeraBreak和一个数据集SVMA，用于评估多模态大语言模型（MLLMs）在短视频中的鲁棒性，揭示了显著的漏洞。", "motivation": "多模态大语言模型（MLLMs）越来越多地用于内容审核，但其在短视频环境中的鲁棒性仍未得到充分探索。当前的安全评估通常依赖于单模态攻击，未能解决组合攻击的脆弱性。", "method": "本文引入了一个评估MLLM三模态安全性的综合框架。首先，提出了短视频多模态对抗（SVMA）数据集，其中包含具有人工引导合成对抗攻击的各种短视频。其次，提出了ChimeraBreak，一种新颖的三模态攻击策略，它同时挑战视觉、听觉和语义推理路径。在最先进的MLLM上进行了广泛实验，并使用LLM作为判断者评估结果。", "result": "对最先进的MLLM进行的广泛实验揭示了显著的漏洞，具有高攻击成功率（ASR）。研究发现了不同的失败模式，显示模型偏向于错误分类良性或违反政策的内容。使用LLM作为判断者证明了攻击推理的有效性。", "conclusion": "本文的数据集和发现为开发更强大、更安全的MLLM提供了关键见解。", "translation": "多模态大语言模型（MLLM）越来越多地用于内容审核，但其在短视频环境中的鲁棒性仍未得到充分探索。当前的安全评估通常依赖于单模态攻击，未能解决组合攻击的脆弱性。在本文中，我们引入了一个评估MLLM三模态安全性的综合框架。首先，我们提出了短视频多模态对抗（SVMA）数据集，其中包含具有人工引导合成对抗攻击的各种短视频。其次，我们提出了ChimeraBreak，一种新颖的三模态攻击策略，同时挑战视觉、听觉和语义推理路径。对最先进的MLLM进行的广泛实验揭示了显著的漏洞，具有高攻击成功率（ASR）。我们的发现揭示了不同的失败模式，显示模型偏向于错误分类良性或违反政策的内容。我们使用LLM作为判断者评估结果，证明了攻击推理的有效性。我们的数据集和发现为开发更强大、更安全的MLLM提供了关键见解。", "summary": "本文探讨了多模态大语言模型（MLLMs）在短视频内容审核中鲁棒性不足的问题，特别是针对组合攻击。为此，它提出了一个全面的三模态安全评估框架，包括短视频多模态对抗（SVMA）数据集和一种新颖的三模态攻击策略ChimeraBreak。对最先进MLLM的实验揭示了显著的漏洞和独特的失败模式，表明模型存在偏见。这项研究为开发更鲁棒、更安全的MLLM提供了关键见解。", "keywords": "三模态攻击, MLLMs, 对抗性攻击, 内容审核, 短视频", "comments": "本文通过引入三模态对抗性攻击，填补了当前针对短视频中MLLM单模态安全评估的空白，具有创新性。SVMA数据集和ChimeraBreak策略的创建是重要的贡献。研究结果强调了当前MLLM中存在的关键漏洞和偏见，凸显了对更鲁棒内容审核系统的需求。"}}
{"id": "2507.12202", "title": "Sparse Autoencoders for Sequential Recommendation Models: Interpretation and Flexible Control", "authors": ["Anton Klenitskiy", "Konstantin Polev", "Daria Denisova", "Alexey Vasilev", "Dmitry Simakov", "Gleb Gusev"], "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12202v1", "summary": "Many current state-of-the-art models for sequential recommendations are based\non transformer architectures. Interpretation and explanation of such black box\nmodels is an important research question, as a better understanding of their\ninternals can help understand, influence, and control their behavior, which is\nvery important in a variety of real-world applications. Recently sparse\nautoencoders (SAE) have been shown to be a promising unsupervised approach for\nextracting interpretable features from language models. These autoencoders\nlearn to reconstruct hidden states of the transformer's internal layers from\nsparse linear combinations of directions in their activation space.\n  This paper is focused on the application of SAE to the sequential\nrecommendation domain. We show that this approach can be successfully applied\nto the transformer trained on a sequential recommendation task: learned\ndirections turn out to be more interpretable and monosemantic than the original\nhidden state dimensions. Moreover, we demonstrate that the features learned by\nSAE can be used to effectively and flexibly control the model's behavior,\nproviding end-users with a straightforward method to adjust their\nrecommendations to different custom scenarios and contexts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12202v1", "cate": "cs.IR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "稀疏自编码器在序列推荐模型中的应用：解释与灵活控制", "tldr": "本文将稀疏自编码器（SAE）应用于序列推荐模型，以解释Transformer模型的内部机制，并证明SAE学习到的特征更具可解释性，并能有效灵活地控制模型行为。", "motivation": "当前最先进的序列推荐模型多基于Transformer架构，但这些黑盒模型的解释性是一个重要研究问题。更好地理解其内部机制有助于理解、影响和控制模型行为，这在实际应用中非常重要。", "method": "本文将稀疏自编码器（SAE）应用于序列推荐领域。SAE是一种无监督方法，通过稀疏线性组合方向来重建Transformer内部层的隐藏状态，从而提取可解释的特征。", "result": "研究表明，SAE方法可以成功应用于经过序列推荐任务训练的Transformer模型。学习到的方向比原始隐藏状态维度更具可解释性和单义性。此外，SAE学习到的特征可以有效灵活地控制模型行为，为终端用户提供了根据不同自定义场景和上下文调整推荐的直接方法。", "conclusion": "稀疏自编码器为理解和控制基于Transformer的序列推荐模型提供了一种有前景的方法，其学习到的可解释特征不仅有助于模型解释，还能实现对推荐行为的灵活调整。", "translation": "当前许多最先进的序列推荐模型都基于Transformer架构。解释这些黑盒模型是一个重要的研究问题，因为更好地理解其内部机制有助于理解、影响和控制其行为，这在各种实际应用中都非常重要。最近，稀疏自编码器（SAE）已被证明是一种很有前景的无监督方法，可以从语言模型中提取可解释的特征。这些自编码器通过其激活空间中方向的稀疏线性组合来重建Transformer内部层的隐藏状态。\n本文专注于SAE在序列推荐领域的应用。我们展示了这种方法可以成功应用于在序列推荐任务上训练的Transformer模型：学习到的方向比原始隐藏状态维度更具可解释性和单义性。此外，我们证明了SAE学习到的特征可以用于有效灵活地控制模型的行为，为终端用户提供了一种直接的方法来根据不同的自定义场景和上下文调整其推荐。", "summary": "本研究将稀疏自编码器（SAE）应用于基于Transformer的序列推荐模型，旨在解决黑盒模型的可解释性问题。研究表明，SAE能够从Transformer的隐藏层中提取出比原始隐藏状态更具可解释性和单义性的特征。更重要的是，利用SAE学习到的这些特征，可以有效且灵活地控制模型的推荐行为，使用户能够根据特定场景和上下文调整推荐结果。", "keywords": "稀疏自编码器, 序列推荐, Transformer, 模型解释, 可控性", "comments": "这篇论文的创新点在于将稀疏自编码器（SAE）这一在语言模型中取得成功的解释性工具引入到序列推荐领域。其重要性体现在为黑盒Transformer模型提供了一种有效的解释和控制机制，这对于提高推荐系统的透明度和用户满意度具有重要意义。通过学习可解释的特征，不仅能帮助理解模型决策，还能实现用户层面的个性化控制，具有较高的实用价值。"}}
{"id": "2306.06974", "title": "A Computational Theory and Semi-Supervised Algorithm for Clustering", "authors": ["Nassir Mohammad"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.06974v2", "summary": "A computational theory for clustering and a semi-supervised clustering\nalgorithm is presented. Clustering is defined to be the obtainment of groupings\nof data such that each group contains no anomalies with respect to a chosen\ngrouping principle and measure; all other examples are considered to be fringe\npoints, isolated anomalies, anomalous clusters or unknown clusters. More\nprecisely, after appropriate modelling under the assumption of uniform random\ndistribution, any example whose expectation of occurrence is <1 with respect to\na group is considered an anomaly; otherwise it is assigned a membership of that\ngroup. Thus, clustering is conceived as the dual of anomaly detection. The\nrepresentation of data is taken to be the Euclidean distance of a point to a\ncluster median. This is due to the robustness properties of the median to\noutliers, its approximate location of centrality and so that decision\nboundaries are general purpose. The kernel of the clustering method is the\nperception anomaly detection algorithm, resulting in a parameter-free, fast,\nand efficient clustering algorithm. Acknowledging that clustering is an\ninteractive and iterative process, the algorithm relies on a small fraction of\nknown relationships between examples. These relationships serve as seeds to\ndefine the user's objectives and guide the clustering process. The method then\nexpands the clusters accordingly, leaving the remaining examples for\nexploration and subsequent iterations. Results are presented on synthetic and\nrealworld data sets, demonstrating the advantages over the most popular\nunsupervised and semi-supervised clustering methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.06974v2", "cate": "cs.LG", "date": "2023-06-12", "updated": "2025-07-16", "AI": {"title_translation": "聚类的一种计算理论与半监督算法", "tldr": "本文提出了一种新的聚类计算理论和一种半监督聚类算法。该算法将聚类视为异常检测的对偶，利用感知异常检测算法，并结合少量已知关系作为种子来指导聚类过程，在合成和真实数据集上表现优于现有方法。", "motivation": "传统的聚类方法可能存在局限性，本文旨在提出一种新的计算理论来重新定义聚类，并开发一种更鲁棒、高效且能够处理异常值的半监督聚类算法，以更好地满足聚类作为交互式和迭代过程的需求。", "method": "本文提出了一种将聚类定义为异常检测对偶的计算理论。在均匀随机分布假设下，将出现期望值小于1的示例视为异常。数据表示采用点到聚类中位数的欧几里得距离，以确保对异常值的鲁棒性。聚类方法的核心是感知异常检测算法，从而实现无参数、快速高效的聚类。该半监督算法利用少量已知示例关系作为种子来定义用户目标并指导聚类过程，然后相应地扩展聚类。", "result": "该算法在合成和真实世界数据集上进行了测试，结果表明其优于最流行的无监督和半监督聚类方法。", "conclusion": "本文成功提出了一种新的聚类计算理论和一种基于异常检测的半监督聚类算法，该算法具有无参数、快速、高效的特点，并通过利用少量已知关系有效指导聚类过程，在各种数据集上展示了其优势。", "translation": "本文提出了一种聚类的计算理论和一种半监督聚类算法。聚类被定义为获取数据分组，使得每个组相对于所选择的分组原则和度量不包含异常；所有其他示例被认为是边缘点、孤立异常、异常聚类或未知聚类。更精确地说，在均匀随机分布的假设下进行适当建模后，任何相对于某个组的出现期望值小于1的示例都被视为异常；否则，它被分配为该组的成员。因此，聚类被认为是异常检测的对偶。数据表示采用点到聚类中位数的欧几里得距离。这是因为中位数对离群值具有鲁棒性、其近似的中心位置以及决策边界的通用性。聚类方法的核心是感知异常检测算法，从而产生一种无参数、快速、高效的聚类算法。认识到聚类是一个交互式和迭代过程，该算法依赖于示例之间少量已知关系。这些关系作为种子来定义用户目标并指导聚类过程。然后，该方法相应地扩展聚类，将剩余的示例留待探索和后续迭代。结果在合成和真实世界数据集上呈现，证明了其优于最流行的无监督和半监督聚类方法的优势。", "summary": "本文提出了一种新颖的聚类计算理论和相应的半监督算法。该理论将聚类定义为异常检测的对偶，即识别非异常数据组。算法采用点到聚类中位数的欧几里得距离作为数据表示，并以感知异常检测算法为核心，实现了无参数、快速高效的聚类。此外，算法利用少量已知的示例关系作为种子来指导聚类过程。实验结果表明，该方法在合成和真实数据集上均优于现有的无监督和半监督聚类方法。", "keywords": "聚类, 半监督学习, 异常检测, 计算理论, 中位数", "comments": "本文的创新点在于将聚类视为异常检测的对偶，这提供了一个全新的视角。算法利用了中位数的鲁棒性以及感知异常检测的效率，并巧妙地通过少量已知关系引入了半监督机制，使其能够更好地适应用户需求并处理复杂数据。其无参数、快速高效的特点也增加了其实用性。"}}
{"id": "2507.11439", "title": "Data Augmentation in Time Series Forecasting through Inverted Framework", "authors": ["Hongming Tan", "Ting Chen", "Ruochong Jin", "Wai Kin Chan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The paper is under consideration at Pattern Recognition Letters", "url": "http://arxiv.org/abs/2507.11439v2", "summary": "Currently, iTransformer is one of the most popular and effective models for\nmultivariate time series (MTS) forecasting. Thanks to its inverted framework,\niTransformer effectively captures multivariate correlation. However, the\ninverted framework still has some limitations. It diminishes temporal\ninterdependency information, and introduces noise in cases of nonsignificant\nvariable correlation. To address these limitations, we introduce a novel data\naugmentation method on inverted framework, called DAIF. Unlike previous data\naugmentation methods, DAIF stands out as the first real-time augmentation\nspecifically designed for the inverted framework in MTS forecasting. We first\ndefine the structure of the inverted sequence-to-sequence framework, then\npropose two different DAIF strategies, Frequency Filtering and Cross-variation\nPatching to address the existing challenges of the inverted framework.\nExperiments across multiple datasets and inverted models have demonstrated the\neffectiveness of our DAIF.", "comment": "The paper is under consideration at Pattern Recognition Letters", "pdf_url": "http://arxiv.org/pdf/2507.11439v2", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "基于倒置框架的时间序列预测数据增强", "tldr": "本文提出了一种名为DAIF的新型数据增强方法，专门用于解决iTransformer等倒置框架在多元时间序列预测中存在的局限性，例如减弱时间相互依赖性和引入噪声。", "motivation": "当前的iTransformer模型虽然在多元时间序列（MTS）预测中有效，但其倒置框架存在局限性，包括削弱时间相互依赖信息以及在变量相关性不显著时引入噪声。为了解决这些问题，需要一种新的数据增强方法。", "method": "本文提出了一种名为DAIF的新型数据增强方法，专门用于倒置框架的多元时间序列预测。DAIF是第一个为倒置框架设计的实时增强方法。作者首先定义了倒置序列到序列框架的结构，然后提出了两种不同的DAIF策略：频率滤波（Frequency Filtering）和交叉变异修补（Cross-variation Patching）来解决现有挑战。", "result": "在多个数据集和倒置模型上的实验证明了DAIF的有效性。", "conclusion": "DAIF作为一种实时数据增强方法，成功解决了倒置框架在多元时间序列预测中存在的局限性，提升了模型的性能。", "translation": "目前，iTransformer是多元时间序列（MTS）预测中最流行和有效的模型之一。由于其倒置框架，iTransformer有效地捕捉了多元相关性。然而，倒置框架仍有一些局限性。它削弱了时间相互依赖信息，并在变量相关性不显著的情况下引入了噪声。为了解决这些局限性，我们引入了一种新的基于倒置框架的数据增强方法，称为DAIF。与之前的数据增强方法不同，DAIF是第一个专门为MTS预测中倒置框架设计的实时增强方法。我们首先定义了倒置序列到序列框架的结构，然后提出了两种不同的DAIF策略：频率滤波和交叉变异修补，以解决倒置框架的现有挑战。在多个数据集和倒置模型上的实验证明了我们DAIF的有效性。", "summary": "本文针对流行的iTransformer模型中倒置框架在多元时间序列预测方面的局限性，提出了一种名为DAIF的实时数据增强方法。该方法通过频率滤波和交叉变异修补两种策略，旨在解决倒置框架削弱时间依赖性和引入噪声的问题。实验证明DAIF在多个数据集和模型上均有效。", "keywords": "数据增强, 时间序列预测, 倒置框架, iTransformer, DAIF", "comments": "该论文创新性地提出了一种针对特定模型架构（倒置框架）的数据增强方法，填补了该领域实时增强的空白。其重要性在于提升了现有高效模型（如iTransformer）的性能和鲁棒性，解决了其固有的局限性。然而，论文未详细说明DAIF的具体实现细节和计算开销，这可能是未来研究需要关注的方面。"}}
{"id": "2507.12345", "title": "Efficient Control Flow Attestation by Speculating on Control Flow Path Representations", "authors": ["Liam Tyler", "Adam Caulfield", "Ivan De Oliveira Nunes"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12345v1", "summary": "Control Flow Attestation (CFA) allows remote verification of run-time\nsoftware integrity in embedded systems. However, CFA is limited by the\nstorage/transmission costs of generated control flow logs (CFlog). Recent work\nhas proposed application-specific optimizations by speculating on likely\nsub-paths in CFlog and replacing them with reserved symbols at runtime. Albeit\neffective, prior approaches do not consider the representation of addresses in\na control flow path for speculation. This work proposes RESPEC-CFA, an\narchitectural extension for CFA allowing for speculation on (1) the locality of\ncontrol flows and (2) their Huffman encoding. Alone, RESPEC-CFA reduces CFlog\nsizes by up to 90.1%. Combined with prior methods, RESPEC-CFA yields reductions\nof up to 99.7%, representing a significant step toward practical CFA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12345v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "通过推测控制流路径表示实现高效控制流认证", "tldr": "本文提出了RESPEC-CFA，一种利用局部性和霍夫曼编码显著减少控制流日志大小的架构扩展，使控制流认证更实用。", "motivation": "控制流认证（CFA）受限于控制流日志（CFlog）的高存储/传输成本。现有推测方法未考虑控制流路径中地址的表示。", "method": "提出了RESPEC-CFA，一种用于CFA的架构扩展，它推测(1)控制流的局部性以及(2)它们的霍夫曼编码。", "result": "单独使用RESPEC-CFA可将CFlog大小减少高达90.1%。与现有方法结合使用时，可实现高达99.7%的缩减。", "conclusion": "RESPEC-CFA显著减少了CFlog大小，代表着朝着实用控制流认证迈出了重要一步。", "translation": "控制流认证 (CFA) 允许远程验证嵌入式系统中运行时软件的完整性。然而，CFA 受限于生成的控制流日志 (CFlog) 的存储/传输成本。最近的工作通过推测 CFlog 中可能的子路径并用保留符号在运行时替换它们，提出了特定于应用的优化。尽管有效，但之前的方法没有考虑控制流路径中地址的表示用于推测。这项工作提出了 RESPEC-CFA，一种用于 CFA 的架构扩展，允许推测 (1) 控制流的局部性以及 (2) 它们的霍夫曼编码。单独使用时，RESPEC-CFA 可将 CFlog 大小减少高达 90.1%。与现有方法结合使用时，RESPEC-CFA 可实现高达 99.7% 的缩减，这代表着朝着实用 CFA 迈出了重要一步。", "summary": "本文介绍了RESPEC-CFA，一种架构扩展，旨在通过显著减少控制流日志（CFlog）的大小，使控制流认证（CFA）更具实用性。与之前忽略地址表示的推测方法不同，RESPEC-CFA推测控制流的局部性及其霍夫曼编码。这种新方法单独使用可实现高达90.1%的CFlog大小缩减，与现有技术结合使用时可实现高达99.7%的缩减，从而解决了CFA的存储/传输成本限制。", "keywords": "控制流认证, CFlog, 推测, 霍夫曼编码, 嵌入式系统", "comments": "该论文通过考虑控制流局部性和霍夫曼编码对路径表示进行推测，引入了一种创新方法来优化控制流认证，这是以前方法所缺失的。CFlog大小的显著减少（高达99.7%）是一项重大进展，使CFA在资源受限的嵌入式系统中更具可行性，解决了关键的实际限制。"}}
{"id": "2507.11935", "title": "Native-AI Empowered Scalable Architectures and Solutions for Future Non-Terrestrial Networks: An Overview", "authors": ["Jikang Deng", "Fizza Hassan", "Hui Zhou", "Saad Al-Ahmadi", "Mohamed-Slim Alouini", "Daniel B. Da Costa"], "categories": ["cs.NI", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11935v1", "summary": "As the path toward 6G networks is being charted, the emerging applications\nhave motivated evolutions of network architectures to realize the efficient,\nreliable, and flexible wireless networks. Among the potential architectures,\nthe non-terrestrial network (NTN) and open radio access network (ORAN) have\nreceived increasing interest from both academia and industry. Although the\ndeployment of NTNs ensures coverage, enhances spectral efficiency, and improves\nthe resilience of wireless networks. The high altitude and mobility of NTN\npresent new challenges in the development and operations (DevOps) lifecycle,\nhindering intelligent and scalable network management due to the lack of native\nartificial intelligence (AI) capability. With the advantages of ORAN in\ndisaggregation, openness, virtualization, and intelligence, several works\npropose integrating ORAN principles into the NTN, focusing mainly on ORAN\ndeployment options based on transparent and regenerative systems. However, a\nholistic view of how to effectively combine ORAN and NTN throughout the DevOps\nlifecycle is still missing, especially regarding how intelligent ORAN addresses\nthe scalability challenges in NTN. Motivated by this, in this paper, we first\nprovide the background knowledge about ORAN and NTN, outline the\nstate-of-the-art research on ORAN for NTNs, and present the DevOps challenges\nthat motivate the adoption of ORAN solutions. We then propose the ORAN-based\nNTN framework, discussing its features and architectures in detail. These\ninclude the discussion about flexible fronthaul split, RAN intelligent\ncontrollers (RICs) enhancement for distributed learning, scalable deployment\narchitecture, and multi-domain service management. Finally, the future research\ndirections, including combinations of the ORAN-based NTN framework and other\nenabling technologies and schemes, as well as the candidate use cases, are\nhighlighted.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11935v1", "cate": "cs.NI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "原生AI赋能的未来非地面网络可扩展架构与解决方案：综述", "tldr": "本文综述了面向未来非地面网络（NTN）的原生AI赋能的可扩展架构与解决方案，尤其关注如何将开放无线接入网络（ORAN）与NTN结合，以应对其可扩展性挑战。", "motivation": "非地面网络（NTN）在部署上存在高海拔和高移动性带来的开发与运维（DevOps）挑战，缺乏原生AI能力阻碍了智能和可扩展的网络管理。尽管有工作提出将开放无线接入网络（ORAN）原则整合到NTN中，但仍缺乏关于如何在整个DevOps生命周期中有效结合ORAN和NTN的整体视图，特别是在智能ORAN如何解决NTN的可扩展性挑战方面。", "method": "本文首先提供了ORAN和NTN的背景知识，概述了ORAN在NTN中的最新研究，并提出了促使采用ORAN解决方案的DevOps挑战。然后，提出了基于ORAN的NTN框架，详细讨论了其特性和架构，包括灵活的前传分流、用于分布式学习的RAN智能控制器（RICs）增强、可扩展的部署架构和多域服务管理。最后，强调了未来的研究方向和潜在用例。", "result": "Not mentioned in abstract", "conclusion": "本文提出了一个基于ORAN的NTN框架，并详细讨论了其关键特性和架构，以应对NTN在DevOps生命周期中的可扩展性挑战，并指出了未来的研究方向和潜在用例。", "translation": "随着6G网络路径的规划，新兴应用促使网络架构演进，以实现高效、可靠、灵活的无线网络。在潜在架构中，非地面网络（NTN）和开放无线接入网络（ORAN）受到了学术界和工业界日益增长的关注。尽管NTN的部署确保了覆盖范围、提高了频谱效率并增强了无线网络的弹性，但NTN的高海拔和移动性在开发与运维（DevOps）生命周期中带来了新的挑战，由于缺乏原生人工智能（AI）能力，阻碍了智能和可扩展的网络管理。凭借ORAN在分解、开放性、虚拟化和智能化方面的优势，一些工作提出将ORAN原则整合到NTN中，主要关注基于透明和再生系统的ORAN部署选项。然而，如何有效结合ORAN和NTN在整个DevOps生命周期中的整体视图仍然缺失，特别是关于智能ORAN如何解决NTN中的可扩展性挑战。受此启发，本文首先提供了关于ORAN和NTN的背景知识，概述了ORAN在NTN中的最新研究，并提出了促使采用ORAN解决方案的DevOps挑战。然后，提出了基于ORAN的NTN框架，详细讨论了其特性和架构。这包括关于灵活前传分流、用于分布式学习的RAN智能控制器（RICs）增强、可扩展的部署架构和多域服务管理的讨论。最后，强调了未来的研究方向，包括基于ORAN的NTN框架与其他使能技术和方案的结合，以及候选用例。", "summary": "本文综述了面向6G网络的非地面网络（NTN）与开放无线接入网络（ORAN）的结合。鉴于NTN在开发与运维（DevOps）中面临的智能和可扩展性挑战，以及缺乏原生AI能力，文章提出了一种基于ORAN的NTN框架。该框架旨在通过讨论灵活前传分流、RAN智能控制器（RICs）增强、可扩展部署架构和多域服务管理等特性，解决NTN的可扩展性问题。此外，文章还探讨了未来的研究方向和潜在应用场景。", "keywords": "非地面网络, 开放无线接入网络, 6G, 可扩展性, 人工智能", "comments": "本文针对未来非地面网络（NTN）在开发与运维（DevOps）中面临的智能和可扩展性挑战，提出了将开放无线接入网络（ORAN）与NTN结合的解决方案。其创新点在于提出了一个基于ORAN的NTN框架，并详细探讨了其关键特性，如RICs增强和可扩展部署，为解决NTN的复杂管理问题提供了方向。该综述对推动NTN与AI/ORAN的融合具有重要意义，但作为综述性文章，并未提供具体的实验结果或性能评估。"}}
{"id": "2507.12205", "title": "Toward Efficient SpMV in Sparse LLMs via Block Extraction and Compressed Storage", "authors": ["Junqing Lin", "Jingwei Sun", "Mingge Lu", "Guangzhong Sun"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2507.12205v1", "summary": "Sparse Matrix-Vector Multiplication (SpMV) has become a critical performance\nbottleneck in the local deployment of sparse Large Language Models (LLMs),\nwhere inference predominantly operates on workloads during the decoder phase\nwith a batch size of one. Existing SpMV kernels and sparse matrix formats,\noriginally designed for scientific computing, fail to exploit the unique\nstructure patterns inherent in sparse LLMs, resulting in suboptimal performance\nand excessive storage overhead. This paper presents EC-SpMV, a GPU-optimized\nSpMV approach for accelerating sparse LLM inference. EC-SpMV introduces (1) a\nhierarchical block extraction algorithm that captures multiple granularities of\nblock structures within sparse LLMs, and (2) a novel compressed sparse format\n(EC-CSR) that employs delta indexing to reduce storage overhead and enhance\nmemory access efficiency. Evaluated on real sparse weight matrices from LLaMA\nand OPT models, EC-SpMV achieves up to 6.44x speedup over state-of-the-art SpMV\nlibraries and reduces storage overhead by up to 55.4% compared to CSR.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.12205v1", "cate": "cs.DC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "通过块提取和压缩存储实现稀疏LLM中高效SpMV", "tldr": "EC-SpMV通过块提取和新压缩格式，显著加速了稀疏LLM的SpMV运算并降低了存储开销。", "motivation": "稀疏矩阵-向量乘法（SpMV）是稀疏大型语言模型（LLM）本地部署中的关键性能瓶颈，尤其是在解码器阶段的推理工作负载中。现有SpMV内核和稀疏矩阵格式未能有效利用稀疏LLM的独特结构模式，导致性能不佳和存储开销过大。", "method": "本文提出了EC-SpMV，一种GPU优化的SpMV方法，用于加速稀疏LLM推理。EC-SpMV引入了（1）分层块提取算法，捕获稀疏LLM中多粒度的块结构；以及（2）一种新颖的压缩稀疏格式（EC-CSR），该格式采用delta索引来减少存储开销并提高内存访问效率。", "result": "在LLaMA和OPT模型的真实稀疏权重矩阵上进行评估，EC-SpMV比最先进的SpMV库实现了高达6.44倍的加速，并且与CSR相比，存储开销减少了高达55.4%。", "conclusion": "EC-SpMV通过其创新的块提取和压缩存储方法，显著提高了稀疏LLM推理的SpMV性能并降低了存储开销，有效解决了现有方法的局限性。", "translation": "稀疏矩阵-向量乘法（SpMV）已成为稀疏大型语言模型（LLM）本地部署中的关键性能瓶颈，尤其是在解码器阶段以批量大小为一进行推理的工作负载中。现有为科学计算设计的SpMV内核和稀疏矩阵格式未能利用稀疏LLM固有的独特结构模式，导致性能不佳和存储开销过大。本文提出了EC-SpMV，一种用于加速稀疏LLM推理的GPU优化SpMV方法。EC-SpMV引入了（1）一种分层块提取算法，该算法捕获稀疏LLM中多粒度的块结构，以及（2）一种新颖的压缩稀疏格式（EC-CSR），该格式采用delta索引来减少存储开销并提高内存访问效率。在LLaMA和OPT模型的真实稀疏权重矩阵上进行评估，EC-SpMV比最先进的SpMV库实现了高达6.44倍的加速，并且与CSR相比，存储开销减少了高达55.4%。", "summary": "本文针对稀疏大型语言模型（LLM）本地部署中SpMV的性能瓶颈和高存储开销问题，提出了一种名为EC-SpMV的GPU优化方法。EC-SpMV通过分层块提取算法捕获LLM中的块结构，并采用新型EC-CSR压缩格式结合delta索引来优化存储和内存访问。实验结果表明，EC-SpMV在LLaMA和OPT模型上比现有SpMV库提速高达6.44倍，并减少存储开销达55.4%。", "keywords": "稀疏矩阵-向量乘法, 大型语言模型, 块提取, 压缩存储, GPU优化", "comments": "该论文创新性地将稀疏LLM特有的结构模式引入到SpMV优化中，通过分层块提取和定制的压缩存储格式，有效解决了传统SpMV方法在LLM场景下的不足。其显著的性能提升和存储优化对于推动稀疏LLM的实际部署具有重要意义。"}}
{"id": "2507.12224", "title": "Optimizers Qualitatively Alter Solutions And We Should Leverage This", "authors": ["Razvan Pascanu", "Clare Lyle", "Ionut-Vlad Modoranu", "Naima Elosegui Borras", "Dan Alistarh", "Petar Velickovic", "Sarath Chandar", "Soham De", "James Martens"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12224v1", "summary": "Due to the nonlinear nature of Deep Neural Networks (DNNs), one can not\nguarantee convergence to a unique global minimum of the loss when using\noptimizers relying only on local information, such as SGD. Indeed, this was a\nprimary source of skepticism regarding the feasibility of DNNs in the early\ndays of the field. The past decades of progress in deep learning have revealed\nthis skepticism to be misplaced, and a large body of empirical evidence shows\nthat sufficiently large DNNs following standard training protocols exhibit\nwell-behaved optimization dynamics that converge to performant solutions. This\nsuccess has biased the community to use convex optimization as a mental model\nfor learning, leading to a focus on training efficiency, either in terms of\nrequired iteration, FLOPs or wall-clock time, when improving optimizers. We\nargue that, while this perspective has proven extremely fruitful, another\nperspective specific to DNNs has received considerably less attention: the\noptimizer not only influences the rate of convergence, but also the qualitative\nproperties of the learned solutions. Restated, the optimizer can and will\nencode inductive biases and change the effective expressivity of a given class\nof models. Furthermore, we believe the optimizer can be an effective way of\nencoding desiderata in the learning process. We contend that the community\nshould aim at understanding the biases of already existing methods, as well as\naim to build new optimizers with the explicit intent of inducing certain\nproperties of the solution, rather than solely judging them based on their\nconvergence rates. We hope our arguments will inspire research to improve our\nunderstanding of how the learning process can impact the type of solution we\nconverge to, and lead to a greater recognition of optimizers design as a\ncritical lever that complements the roles of architecture and data in shaping\nmodel outcomes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12224v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "优化器定性地改变解决方案，我们应该利用这一点", "tldr": "本文认为，优化器不仅影响深度神经网络的收敛速度，还会定性地改变学习到的解决方案，并编码归纳偏置。社区应该研究现有优化器的偏置，并设计新的优化器以诱导特定的解决方案特性，而不仅仅关注收敛率。", "motivation": "深度学习社区在优化器设计上过度关注训练效率（收敛速度），这源于将凸优化作为学习的心智模型。然而，这种观点忽略了优化器还会定性地改变学习到的解决方案的性质，并编码归纳偏置，从而影响模型的有效表达能力。", "method": "Not mentioned in abstract", "result": "Not mentioned in abstract", "conclusion": "社区应致力于理解现有优化器的偏置，并明确旨在诱导特定解决方案特性来构建新的优化器，而不仅仅依据收敛率来评判它们。优化器设计是塑造模型结果的关键杠杆，与架构和数据互补。", "translation": "由于深度神经网络（DNNs）的非线性性质，在使用仅依赖局部信息的优化器（例如SGD）时，无法保证收敛到损失函数的唯一全局最小值。事实上，这在领域早期是导致人们对DNNs可行性产生怀疑的主要原因。过去几十年深度学习的进展表明，这种怀疑是错误的，大量经验证据表明，足够大的DNNs遵循标准训练协议时，表现出良好的优化动态，并收敛到高性能的解决方案。这种成功使社区倾向于使用凸优化作为学习的心智模型，导致在改进优化器时，侧重于训练效率，无论是所需的迭代次数、FLOPs还是挂钟时间。我们认为，尽管这种视角已被证明极其富有成效，但另一种针对DNNs的视角受到的关注相对较少：优化器不仅影响收敛速度，还影响学习到的解决方案的定性属性。换句话说，优化器能够且将会编码归纳偏置，并改变给定模型类别的有效表达能力。此外，我们相信优化器是编码学习过程中期望特性的有效方式。我们主张，社区应该致力于理解现有方法的偏置，并旨在构建新的优化器，明确意图诱导解决方案的某些属性，而不是仅仅根据它们的收敛率来评判它们。我们希望我们的论点能启发研究，以提高我们对学习过程如何影响我们收敛到的解决方案类型的理解，并促使人们更广泛地认识到优化器设计作为补充架构和数据在塑造模型结果方面的关键作用。", "summary": "本文指出，尽管深度学习在优化方面取得了巨大成功，但社区在优化器设计上过度关注效率，将凸优化作为主要心智模型。作者认为，优化器不仅影响收敛速度，更重要的是，它能定性地改变学习到的解决方案，并编码归纳偏置，从而影响模型的表达能力。因此，文章呼吁研究人员关注理解现有优化器的偏置，并设计新的优化器以主动诱导特定的解决方案特性，强调优化器是与模型架构和数据同样重要的设计杠杆。", "keywords": "优化器, 深度神经网络, 归纳偏置, 解决方案特性, 学习过程", "comments": "本文挑战了深度学习优化领域的一个普遍观点，即优化器的主要作用是加速收敛。它提出了一个重要的论点：优化器实际上是模型归纳偏置的来源，能够塑造最终解决方案的定性属性。这一洞察力非常重要，因为它为优化器设计开辟了新的研究方向，超越了单纯的效率提升，转向如何通过优化器来引导模型学习到更符合期望特性的解决方案。这对于理解深度学习模型的行为和设计更强大的学习系统具有深远影响。"}}
{"id": "2403.06403", "title": "PointSeg: A Training-Free Paradigm for 3D Scene Segmentation via Foundation Models", "authors": ["Qingdong He", "Jinlong Peng", "Zhengkai Jiang", "Xiaobin Hu", "Jiangning Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025 E2E3D Workshop", "url": "http://arxiv.org/abs/2403.06403v5", "summary": "Recent success of vision foundation models have shown promising performance\nfor the 2D perception tasks. However, it is difficult to train a 3D foundation\nnetwork directly due to the limited dataset and it remains under explored\nwhether existing foundation models can be lifted to 3D space seamlessly. In\nthis paper, we present PointSeg, a novel training-free paradigm that leverages\noff-the-shelf vision foundation models to address 3D scene perception tasks.\nPointSeg can segment anything in 3D scene by acquiring accurate 3D prompts to\nalign their corresponding pixels across frames. Concretely, we design a\ntwo-branch prompts learning structure to construct the 3D point-box prompts\npairs, combining with the bidirectional matching strategy for accurate point\nand proposal prompts generation. Then, we perform the iterative post-refinement\nadaptively when cooperated with different vision foundation models. Moreover,\nwe design a affinity-aware merging algorithm to improve the final ensemble\nmasks. PointSeg demonstrates impressive segmentation performance across various\ndatasets, all without training. Specifically, our approach significantly\nsurpasses the state-of-the-art specialist training-free model by 14.1$\\%$,\n12.3$\\%$, and 12.6$\\%$ mAP on ScanNet, ScanNet++, and KITTI-360 datasets,\nrespectively. On top of that, PointSeg can incorporate with various foundation\nmodels and even surpasses the specialist training-based methods by\n3.4$\\%$-5.4$\\%$ mAP across various datasets, serving as an effective generalist\nmodel.", "comment": "Accepted by ICCV 2025 E2E3D Workshop", "pdf_url": "http://arxiv.org/pdf/2403.06403v5", "cate": "cs.CV", "date": "2024-03-11", "updated": "2025-07-16", "AI": {"title_translation": "PointSeg: 一种通过基础模型实现3D场景分割的免训练范式", "tldr": "PointSeg是一种免训练范式，它利用现成的2D视觉基础模型进行3D场景分割，并在多个数据集上取得了超越现有免训练和部分基于训练的专业模型的性能。", "motivation": "由于数据集有限，直接训练3D基础网络很困难，并且将现有2D基础模型无缝迁移到3D空间的研究不足。", "method": "PointSeg设计了一个双分支提示学习结构来构建3D点盒提示对，结合双向匹配策略生成准确的点和提议提示。然后，它与不同的视觉基础模型协作进行迭代后精修，并设计了亲和力感知合并算法来改进最终的集成掩膜。", "result": "PointSeg在ScanNet、ScanNet++和KITTI-360数据集上分别显著超越现有最先进的专业免训练模型14.1%、12.3%和12.6% mAP。它还能与各种基础模型结合，甚至在不同数据集上超越基于训练的专业方法3.4%-5.4% mAP。", "conclusion": "PointSeg作为一种有效的通用模型，通过免训练范式，成功地将2D视觉基础模型应用于3D场景分割，并取得了优异的性能，甚至超越了一些基于训练的专业方法。", "translation": "视觉基础模型最近的成功在2D感知任务中展现出有希望的性能。然而，由于数据集有限，直接训练3D基础网络很困难，并且将现有基础模型无缝迁移到3D空间的研究仍然不足。在本文中，我们提出了PointSeg，一种新颖的免训练范式，它利用现成的视觉基础模型来解决3D场景感知任务。PointSeg通过获取精确的3D提示，以在帧间对齐其对应的像素，从而可以分割3D场景中的任何物体。具体来说，我们设计了一个双分支提示学习结构来构建3D点盒提示对，结合双向匹配策略以生成准确的点和提议提示。然后，我们与不同的视觉基础模型协作时，自适应地执行迭代后精修。此外，我们设计了一种亲和力感知合并算法来改进最终的集成掩膜。PointSeg在各种数据集上展示了令人印象深刻的分割性能，所有这些都无需训练。具体来说，我们的方法在ScanNet、ScanNet++和KITTI-360数据集上分别显著超越最先进的专业免训练模型14.1%、12.3%和12.6% mAP。最重要的是，PointSeg可以与各种基础模型结合，甚至在各种数据集上超越基于训练的专业方法3.4%-5.4% mAP，从而成为一种有效的通用模型。", "summary": "PointSeg提出了一种新颖的免训练范式，利用现成的2D视觉基础模型解决3D场景分割问题。该方法通过设计双分支提示学习结构和双向匹配策略生成3D点盒提示，并结合迭代后精修和亲和力感知合并算法来优化分割结果。PointSeg在多个3D数据集上展现出卓越的性能，不仅显著超越了现有的免训练模型，甚至在某些情况下超过了基于训练的专业模型，证明了其作为通用模型的有效性。", "keywords": "3D场景分割, 免训练, 基础模型, 点云, 提示学习", "comments": "PointSeg的创新之处在于其免训练范式，成功将2D视觉基础模型应用于3D场景分割，有效解决了3D数据和训练的挑战。其通过精心设计的提示学习结构和后处理算法，实现了在不进行额外训练的情况下，性能超越了现有最先进的免训练模型，甚至部分基于训练的专业模型，这对于3D感知领域具有重要意义。该方法展现了通用性和高效性，有望推动未来3D视觉任务的发展。"}}
{"id": "2507.09953", "title": "4D-MISR: A unified model for low-dose super-resolution imaging via feature fusion", "authors": ["Zifei Wang", "Zian Mao", "Xiaoya He", "Xi Huang", "Haoran Zhang", "Chun Cheng", "Shufen Chu", "Tingzheng Hou", "Xiaoqin Zeng", "Yujun Xie"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The authors have decided to withdraw this submission due to incorrect affiliation information and certain logical inconsistencies in the manuscript that require revision", "url": "http://arxiv.org/abs/2507.09953v2", "summary": "While electron microscopy offers crucial atomic-resolution insights into\nstructure-property relationships, radiation damage severely limits its use on\nbeam-sensitive materials like proteins and 2D materials. To overcome this\nchallenge, we push beyond the electron dose limits of conventional electron\nmicroscopy by adapting principles from multi-image super-resolution (MISR) that\nhave been widely used in remote sensing. Our method fuses multiple\nlow-resolution, sub-pixel-shifted views and enhances the reconstruction with a\nconvolutional neural network (CNN) that integrates features from synthetic,\nmulti-angle observations. We developed a dual-path, attention-guided network\nfor 4D-STEM that achieves atomic-scale super-resolution from ultra-low-dose\ndata. This provides robust atomic-scale visualization across amorphous,\nsemi-crystalline, and crystalline beam-sensitive specimens. Systematic\nevaluations on representative materials demonstrate comparable spatial\nresolution to conventional ptychography under ultra-low-dose conditions. Our\nwork expands the capabilities of 4D-STEM, offering a new and generalizable\nmethod for the structural analysis of radiation-vulnerable materials.", "comment": "The authors have decided to withdraw this submission due to incorrect\n  affiliation information and certain logical inconsistencies in the manuscript\n  that require revision", "pdf_url": "http://arxiv.org/pdf/2507.09953v2", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "4D-MISR：一种通过特征融合实现低剂量超分辨成像的统一模型", "tldr": "4D-MISR是一种利用多图像超分辨率和深度学习技术，在超低剂量下实现对辐射敏感材料原子级超分辨成像的新方法。", "motivation": "电子显微镜在原子分辨率层面揭示结构-性质关系至关重要，但辐射损伤严重限制了其在蛋白质和二维材料等束流敏感材料上的应用。", "method": "该方法借鉴了遥感领域广泛应用的多图像超分辨率（MISR）原理，通过融合多个低分辨率、亚像素偏移的视图，并使用一个卷积神经网络（CNN）增强重建，该网络集成了合成、多角度观测的特征。具体开发了一个用于4D-STEM的双路径、注意力引导网络，以实现从超低剂量数据中获得原子级超分辨率。", "result": "该模型在非晶态、半晶态和晶态束流敏感样品上实现了稳健的原子级可视化。在超低剂量条件下，对代表性材料进行的系统评估表明，其空间分辨率与传统相干衍射成像（ptyography）相当。", "conclusion": "该工作扩展了4D-STEM的功能，为辐射敏感材料的结构分析提供了一种新的、可推广的方法。", "translation": "虽然电子显微镜在原子分辨率层面揭示结构-性质关系至关重要，但辐射损伤严重限制了其在蛋白质和二维材料等束流敏感材料上的应用。为了克服这一挑战，我们借鉴了遥感领域广泛应用的多图像超分辨率（MISR）原理，突破了传统电子显微镜的电子剂量限制。我们的方法融合了多个低分辨率、亚像素偏移的视图，并利用一个卷积神经网络（CNN）增强重建，该网络集成了合成、多角度观测的特征。我们开发了一个用于4D-STEM的双路径、注意力引导网络，实现了从超低剂量数据中获得原子级超分辨率。这为非晶态、半晶态和晶态束流敏感样品提供了稳健的原子级可视化。对代表性材料进行的系统评估表明，在超低剂量条件下，其空间分辨率与传统相干衍射成像（ptyography）相当。我们的工作扩展了4D-STEM的功能，为辐射敏感材料的结构分析提供了一种新的、可推广的方法。", "summary": "本文提出了一种名为4D-MISR的统一模型，旨在解决电子显微镜在束流敏感材料上因辐射损伤导致的成像限制。该模型借鉴了多图像超分辨率原理，并结合了双路径、注意力引导的卷积神经网络，通过融合多个低剂量、亚像素偏移的视图，实现了对非晶态、半晶态和晶态束流敏感样品的原子级超分辨率成像。实验结果表明，在超低剂量下，其空间分辨率与传统相干衍射成像相当，为辐射敏感材料的结构分析提供了一种新颖且可推广的方法。", "keywords": "4D-MISR, 超分辨率成像, 低剂量, 电子显微镜, 深度学习", "comments": "该论文的创新之处在于将遥感领域的多图像超分辨率技术引入到电子显微镜领域，并通过深度学习（CNN）进行优化，成功解决了束流敏感材料在低剂量下实现原子级高分辨率成像的挑战。这对于生物学、材料科学等领域中对辐射敏感样品的研究具有重要意义，拓展了4D-STEM的应用范围。"}}
{"id": "2507.11854", "title": "Sub-Connected Hybrid Beamfocusing Design for RSMA-Enabled Near-Field Communications with Imperfect CSI and SIC", "authors": ["Jiasi Zhou", "Ruirui Chen", "Yanjing Sun", "Chintha Tellambura"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      11 pages and 7 figures", "url": "http://arxiv.org/abs/2507.11854v1", "summary": "Near-field spherical waves inherently encode both direction and distance\ninformation, enabling spotlight-like beam focusing for targeted interference\nmitigation. However, whether such beam focusing can fully eliminate\ninterference under perfect and imperfect channel state information (CSI),\nrendering advanced interference management schemes unnecessary, remains an open\nquestion. To address this, we investigate rate-splitting multiple access\n(RSMA)-enabled near-field communications (NFC) under imperfect SCI. Our\ntransmit scheme employs a sub-connected hybrid analog-digital (HAD)\narchitecture to reduce hardware overhead while incorporating imperfect\nsuccessive interference cancellation (SIC) for practical implementation. A\nminimum rate maximization problem is formulated by jointly optimizing the\nanalog beamfocuser, the digital beamfocuser, and the common rate allocation. To\nsolve the non-convex problem, we develop a penalty-based block coordinate\ndescent (BCD) algorithm, deriving closed-form expressions for the optimal\nanalog and digital beamfocusers solutions. Furthermore, to reduce computational\ncomplexity, we propose a low-complexity algorithm, where analog and digital\nbeamfocusers are designed in two separate stages. Simulation results underscore\nthat: 1) beamfocusing alone is insufficient to fully suppress interference even\nunder perfect CSI; 2) RSMA exhibits superior interference management over SDMA\nunder imperfect CSI and SIC conditions; 3) sub-connected HAD architecture\ndelivers near-optimal digital beamfocusing performance with fewer radio\nfrequency chains.", "comment": "11 pages and 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.11854v1", "cate": "cs.IT", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "不完美CSI和SIC下RSMA赋能近场通信的子连接混合波束聚焦设计", "tldr": "本文研究了在不完美信道状态信息（CSI）和不完美连续干扰消除（SIC）条件下，速率分裂多址（RSMA）赋能的近场通信（NFC）中的子连接混合模拟-数字（HAD）波束聚焦设计。研究表明单独的波束聚焦不足以完全抑制干扰，RSMA在不完美条件下优于SDMA，且子连接HAD架构能以更少的射频链实现接近最优的数字波束聚焦性能。", "motivation": "近场球形波束聚焦能否在完美和不完美信道状态信息（CSI）下完全消除干扰，从而使高级干扰管理方案变得不必要，仍然是一个开放问题。本文旨在解决这一问题。", "method": "本文研究了在不完美CSI下RSMA赋能的近场通信。发射方案采用子连接混合模拟-数字（HAD）架构以降低硬件开销，并结合不完美连续干扰消除（SIC）以实现实际应用。通过联合优化模拟波束聚焦器、数字波束聚焦器和公共速率分配，提出了一个最小速率最大化问题。为了解决非凸问题，开发了一种基于惩罚的块坐标下降（BCD）算法，并推导了最优模拟和数字波束聚焦器解的闭式表达式。此外，为降低计算复杂度，提出了一种低复杂度算法，其中模拟和数字波束聚焦器分两个阶段设计。", "result": "1) 即使在完美CSI下，单独的波束聚焦也不足以完全抑制干扰；2) 在不完美CSI和SIC条件下，RSMA比空分多址（SDMA）表现出更优越的干扰管理能力；3) 子连接HAD架构以更少的射频链实现了接近最优的数字波束聚焦性能。", "conclusion": "在不完美CSI和SIC条件下，单独的近场波束聚焦不足以完全消除干扰，RSMA是比SDMA更有效的干扰管理方案，且子连接HAD架构是实现高效波束聚焦的实用选择。", "translation": "近场球形波固有的编码方向和距离信息，从而实现类似聚光灯的波束聚焦以进行定向干扰抑制。然而，这种波束聚焦是否能在完美和不完美信道状态信息（CSI）下完全消除干扰，从而使高级干扰管理方案变得不必要，仍然是一个开放问题。为了解决这个问题，我们研究了在不完美SCI下速率分裂多址（RSMA）赋能的近场通信（NFC）。我们的发射方案采用子连接混合模拟-数字（HAD）架构以降低硬件开销，同时结合不完美连续干扰消除（SIC）以实现实际应用。通过联合优化模拟波束聚焦器、数字波束聚焦器和公共速率分配，提出了一个最小速率最大化问题。为了解决非凸问题，我们开发了一种基于惩罚的块坐标下降（BCD）算法，并推导了最优模拟和数字波束聚焦器解的闭式表达式。此外，为了降低计算复杂度，我们提出了一种低复杂度算法，其中模拟和数字波束聚焦器分两个独立的阶段设计。仿真结果强调：1) 即使在完美CSI下，单独的波束聚焦也不足以完全抑制干扰；2) 在不完美CSI和SIC条件下，RSMA比空分多址（SDMA）表现出更优越的干扰管理能力；3) 子连接HAD架构以更少的射频链实现了接近最优的数字波束聚焦性能。", "summary": "本文研究了在不完美CSI和SIC条件下，RSMA赋能的近场通信中的子连接混合波束聚焦设计。针对最小速率最大化问题，提出了基于惩罚的BCD算法和低复杂度算法。仿真结果表明，单独的波束聚焦不足以完全抑制干扰，RSMA在不完美条件下优于SDMA，且子连接HAD架构在硬件开销和性能之间取得了良好平衡。", "keywords": "近场通信, RSMA, 混合波束聚焦, 不完美CSI, 干扰管理", "comments": "本文创新性地将RSMA、子连接HAD架构和不完美SIC引入到近场通信的波束聚焦设计中，并系统地分析了其在不完美CSI下的性能。研究结果澄清了近场波束聚焦的局限性，并验证了RSMA在实际近场系统中的优势，对于未来近场通信系统的设计具有重要指导意义。"}}
{"id": "2507.12364", "title": "Rethinking the confidential cloud through a unified low-level abstraction for composable isolation", "authors": ["Adrien Ghosn", "Charly Castes", "Neelu S. Kalani", "Yuchen Qian", "Marios Kogias", "Edouard Bugnion"], "categories": ["cs.CR", "cs.OS"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12364v1", "summary": "Securing sensitive cloud workloads requires composing confidential virtual\nmachines (CVMs) with nested enclaves or sandboxes. Unfortunately, each new\nisolation boundary adds ad-hoc access control mechanisms, hardware extensions,\nand trusted software. This escalating complexity bloats the TCB, complicates\nend-to-end attestation, and leads to fragmentation across platforms and cloud\nservice providers (CSPs).\n  We introduce a unified isolation model that delegates enforceable,\ncomposable, and attestable isolation to a single trusted security monitor:\nTyche. Tyche provides an API for partitioning, sharing, attesting, and\nreclaiming resources through its core abstraction, trust domains (TDs). To\nprovide fine-grain isolation, TDs can recursively create and manage sub-TDs.\nTyche captures these relationships in attestations, allowing cloud tenants to\nreason about end-to-end security. TDs serve as the building blocks for\nconstructing composable enclaves, sandboxes, and CVMs.\n  Tyche runs on commodity x86_64 without hardware security extensions and can\nmaintain backward compatibility with existing software. We provide an SDK to\nrun and compose unmodified workloads as sandboxes, enclaves, and CVMs with\nminimal overhead compared to native Linux execution. Tyche supports complex\ncloud scenarios, such as confidential inference with mutually distrustful\nusers, model owners, and CSPs. An additional RISC-V prototype demonstrates\nTyche's portability across platforms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12364v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "通过统一的低级抽象实现可组合隔离，重新思考机密云", "tldr": "Tyche引入了一个统一的隔离模型，通过信任域（TDs）在商品硬件上实现可组合、可证明的细粒度隔离，以解决机密云中不断增加的隔离复杂性。", "motivation": "现有机密云工作负载的安全保护需要组合机密虚拟机（CVMs）、嵌套飞地或沙箱，但每个新的隔离边界都会增加特殊的访问控制机制、硬件扩展和可信软件，导致可信计算基（TCB）膨胀、端到端证明复杂化，并造成跨平台和云服务提供商（CSP）的碎片化。", "method": "论文引入了一个名为Tyche的统一隔离模型，它将可强制执行、可组合和可证明的隔离委托给一个单一的可信安全监视器。Tyche通过其核心抽象——信任域（TDs）提供用于分区、共享、证明和回收资源的API。TDs可以递归创建和管理子TDs以提供细粒度隔离，并将这些关系捕获在证明中。Tyche在商品x86_64上运行，无需硬件安全扩展，并能保持与现有软件的向后兼容性。", "result": "Tyche提供了一个SDK，可以以最小的开销运行和组合未经修改的工作负载作为沙箱、飞地和CVMs，与原生Linux执行相比。它支持复杂的云场景，如互不信任的用户、模型所有者和CSP之间的机密推理。一个额外的RISC-V原型展示了Tyche的跨平台可移植性。", "conclusion": "Tyche通过提供一个统一的低级抽象（信任域）来简化和增强机密云的隔离机制，解决了现有方法带来的复杂性、TCB膨胀和碎片化问题，并在商品硬件上实现了高效且可移植的细粒度隔离。", "translation": "保护敏感云工作负载需要将机密虚拟机（CVMs）与嵌套的飞地或沙箱组合起来。不幸的是，每个新的隔离边界都会增加特殊的访问控制机制、硬件扩展和可信软件。这种不断升级的复杂性会使TCB膨胀，使端到端证明复杂化，并导致跨平台和云服务提供商（CSP）的碎片化。\n我们引入了一个统一的隔离模型，该模型将可强制执行、可组合和可证明的隔离委托给一个单一的可信安全监视器：Tyche。Tyche通过其核心抽象——信任域（TDs）提供用于分区、共享、证明和回收资源的API。为了提供细粒度隔离，TDs可以递归创建和管理子TDs。Tyche在证明中捕获这些关系，允许云租户推断端到端安全性。TDs可作为构建可组合飞地、沙箱和CVMs的构建块。\nTyche运行在商用x86_64上，无需硬件安全扩展，并能保持与现有软件的向后兼容性。我们提供了一个SDK，可以在与原生Linux执行相比开销最小的情况下，以沙箱、飞地和CVMs的形式运行和组合未经修改的工作负载。Tyche支持复杂的云场景，例如互不信任的用户、模型所有者和CSP之间的机密推理。一个额外的RISC-V原型展示了Tyche跨平台的可移植性。", "summary": "本文提出了一种名为Tyche的统一隔离模型，旨在解决机密云中现有隔离机制（如CVMs、飞地、沙箱）带来的复杂性、TCB膨胀和平台碎片化问题。Tyche通过其核心抽象——信任域（TDs），提供了一个低级API，用于在商品硬件上实现可组合、可证明的细粒度资源隔离。它支持递归创建子TDs以实现精细控制，并能捕获端到端安全证明。Tyche在x86_64上无需硬件安全扩展即可运行，并能以低开销兼容现有工作负载，且具有跨平台可移植性，适用于复杂的云场景。", "keywords": "机密云, 隔离, 信任域, Tyche, 安全监视器", "comments": "这篇论文的创新点在于提出了一个统一的低级抽象Tyche及其信任域（TDs），以简化和标准化机密云中的隔离机制。它通过在商品硬件上实现细粒度、可组合和可证明的隔离，有效解决了现有方案中TCB膨胀、复杂性和碎片化的问题，并具有良好的兼容性和可移植性，对于构建更安全、更易管理的机密云环境具有重要意义。"}}
{"id": "2507.12162", "title": "A real-time metric of online engagement monitoring", "authors": ["Laura J. Johnston", "Jim E. Griffin", "Ioanna Manolopoulou", "Takoua Jendoubi"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      32 pages, 5 figures", "url": "http://arxiv.org/abs/2507.12162v1", "summary": "Measuring online behavioural student engagement often relies on simple count\nindicators or retrospective, predictive methods, which present challenges for\nreal-time application. To address these limitations, we reconceptualise an\nexisting course-wide engagement metric to create a chapter-based version that\naligns with the weekly structure of online courses. Derived directly from\nvirtual learning environment log data, the new metric allows for cumulative,\nreal-time tracking of student activity without requiring outcome data or model\ntraining. We evaluate the approach across three undergraduate statistics\nmodules over two academic years, comparing it to the course-wide formulation to\nassess how the reconceptualisation influences what is measured. Results\nindicate strong alignment from as early as week 3, along with comparable or\nimproved predictive validity for final grades in structured, lecture-based\ncontexts. By the course midpoint, the weekly metric identifies as many\nlow-performing students as are identifiable by the end of the course. While\nperformance varies across modules, the chapter-based formulation offers a\nscalable and interpretable method for early engagement monitoring and student\nsupport.", "comment": "32 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.12162v1", "cate": "cs.CY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "在线参与度实时监测指标", "tldr": "开发了一种基于章节的实时在线学生参与度指标，无需预测模型或结果数据，能有效识别低表现学生并提供早期支持。", "motivation": "现有的在线学生参与度衡量方法多依赖简单计数或回顾性预测方法，难以实现实时应用，存在局限性。", "method": "本文将现有课程范围的参与度指标重新概念化为基于章节的版本，使其与在线课程的每周结构对齐。该新指标直接来源于虚拟学习环境日志数据，允许累积、实时跟踪学生活动，无需结果数据或模型训练。研究通过在两个学年内对三个本科统计模块进行评估，并与课程范围的公式进行比较，以评估重新概念化如何影响测量内容。", "result": "结果显示，该指标早在第三周就表现出强烈的一致性，并且在结构化、基于讲座的环境中，对最终成绩的预测有效性相当或有所提高。到课程中期，每周指标识别出的低表现学生数量与课程结束时可识别的数量相同。", "conclusion": "尽管性能因模块而异，但基于章节的公式提供了一种可扩展且可解释的方法，用于早期参与度监测和学生支持。", "translation": "衡量在线学生行为参与度通常依赖于简单的计数指标或回顾性、预测性方法，这给实时应用带来了挑战。为了解决这些局限性，我们将现有的课程范围参与度指标重新概念化，创建了一个基于章节的版本，该版本与在线课程的每周结构保持一致。新指标直接来源于虚拟学习环境日志数据，无需结果数据或模型训练，即可实现学生活动的累积、实时跟踪。我们评估了该方法在两个学年内三个本科统计模块中的应用，并将其与课程范围的公式进行比较，以评估重新概念化如何影响测量内容。结果表明，早在第三周就表现出强烈的一致性，并且在结构化、基于讲座的环境中，对最终成绩的预测有效性相当或有所提高。到课程中期，每周指标识别出的低表现学生数量与课程结束时可识别的数量相同。尽管性能因模块而异，但基于章节的公式为早期参与度监测和学生支持提供了一种可扩展且可解释的方法。", "summary": "本文提出了一种新的、基于章节的在线学生参与度实时监测指标，旨在克服现有方法在实时应用上的局限性。该指标直接从虚拟学习环境日志数据中获取，无需预测模型或结果数据，即可实现学生活动的累积和实时跟踪。通过在多个统计模块上的评估，研究发现该指标能有效提前识别低表现学生，并对最终成绩具有良好的预测能力，为在线学习环境中的早期干预和学生支持提供了可扩展且可解释的工具。", "keywords": "在线参与度, 实时监测, 学生支持, 虚拟学习环境, 预测有效性", "comments": "这项研究的创新之处在于将现有的参与度指标重新概念化为更细粒度（章节级）的实时版本，并且无需复杂的预测模型或依赖最终结果数据。其重要性在于能够实现学生参与度的早期、实时监测，从而为教育者提供及时干预和支持低表现学生的可能性。这种方法的可扩展性和可解释性也增加了其实用价值。"}}
{"id": "2507.12125", "title": "Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers", "authors": ["Yi-Kuan Hsieh", "Jun-Wei Hsieh", "Xin Li", "Yu-Ming Chang", "Yu-Chee Tseng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12125v1", "summary": "Vision Transformer (ViT) has achieved impressive results across various\nvision tasks, yet its high computational cost limits practical applications.\nRecent methods have aimed to reduce ViT's $O(n^2)$ complexity by pruning\nunimportant tokens. However, these techniques often sacrifice accuracy by\nindependently pruning query (Q) and key (K) tokens, leading to performance\ndegradation due to overlooked token interactions. To address this limitation,\nwe introduce a novel {\\bf Block-based Symmetric Pruning and Fusion} for\nefficient ViT (BSPF-ViT) that optimizes the pruning of Q/K tokens jointly.\nUnlike previous methods that consider only a single direction, our approach\nevaluates each token and its neighbors to decide which tokens to retain by\ntaking token interaction into account. The retained tokens are compressed\nthrough a similarity fusion step, preserving key information while reducing\ncomputational costs. The shared weights of Q/K tokens create a symmetric\nattention matrix, allowing pruning only the upper triangular part for speed up.\nBSPF-ViT consistently outperforms state-of-the-art ViT methods at all pruning\nlevels, increasing ImageNet classification accuracy by 1.3% on DeiT-T and 2.0%\non DeiT-S, while reducing computational overhead by 50%. It achieves 40%\nspeedup with improved accuracy across various ViTs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12125v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于块的对称剪枝与融合实现高效视觉Transformer", "tldr": "本文提出BSPF-ViT，通过联合剪枝Q/K token并进行融合，解决了ViT计算成本高和现有剪枝方法精度下降的问题。BSPF-ViT在保持甚至提高准确性的同时显著降低了计算开销，性能优于SOTA方法。", "motivation": "Vision Transformer (ViT) 尽管在视觉任务中表现出色，但其高计算成本限制了实际应用。现有通过剪枝不重要token来降低ViT复杂度的O(n^2)方法，常因独立剪枝查询（Q）和键（K）token而牺牲准确性，且忽略了token间的交互作用，导致性能下降。", "method": "本文提出了一种新颖的“基于块的对称剪枝与融合”（BSPF-ViT）方法。该方法联合优化Q/K token的剪枝，通过考虑token及其邻居的交互作用来决定保留哪些token。保留的token通过相似性融合步骤进行压缩，以在降低计算成本的同时保留关键信息。Q/K token的共享权重创建了一个对称注意力矩阵，从而允许仅剪枝上三角部分以加速。", "result": "BSPF-ViT在所有剪枝级别上始终优于最先进的ViT方法。它在DeiT-T上将ImageNet分类准确率提高了1.3%，在DeiT-S上提高了2.0%，同时将计算开销降低了50%。它在各种ViT上实现了40%的加速并提高了准确性。", "conclusion": "BSPF-ViT通过创新的对称剪枝与融合策略，有效地解决了Vision Transformer的计算效率问题，同时避免了现有剪枝方法带来的精度损失。该方法在提高ViT效率和性能方面展现出显著优势。", "translation": "Vision Transformer (ViT) 在各种视觉任务中取得了令人印象深刻的成果，但其高计算成本限制了实际应用。最近的方法旨在通过剪枝不重要的token来降低ViT的O(n^2)复杂度。然而，这些技术通常通过独立剪枝查询（Q）和键（K）token来牺牲准确性，由于忽略了token之间的交互而导致性能下降。为了解决这一限制，我们引入了一种新颖的**基于块的对称剪枝与融合**（BSPF-ViT）高效ViT方法，该方法联合优化Q/K token的剪枝。与以前只考虑单一方向的方法不同，我们的方法通过考虑token交互来评估每个token及其邻居，以决定保留哪些token。保留的token通过相似性融合步骤进行压缩，在降低计算成本的同时保留了关键信息。Q/K token的共享权重创建了一个对称注意力矩阵，允许仅剪枝上三角部分以加速。BSPF-ViT在所有剪枝级别上始终优于最先进的ViT方法，在DeiT-T上将ImageNet分类准确率提高了1.3%，在DeiT-S上提高了2.0%，同时将计算开销降低了50%。它在各种ViT上实现了40%的加速并提高了准确性。", "summary": "BSPF-ViT是一种针对高效Vision Transformer的新颖方法，旨在解决现有token剪枝技术中计算成本高昂和精度下降的问题。它通过联合剪枝查询和键token，并考虑token间的交互作用，同时采用相似性融合步骤来压缩保留的token。利用对称注意力矩阵，BSPF-ViT在计算开销降低50%的同时，显著提高了ImageNet分类准确率达2.0%，并在各种ViT上实现了显著的加速和性能提升，超越了现有最先进的ViT方法。", "keywords": "Vision Transformer, Token Pruning, Symmetric Pruning, 模型压缩, 效率", "comments": "这篇论文提出了一种创新性的方法来优化ViT，通过解决独立Q/K token剪枝的关键限制。其对称剪枝与融合机制，特别考虑了token间的交互作用，是一个重要的改进。实验结果表明，该方法在效率和准确性方面都取得了显著的提升，使得BSPF-ViT在实际ViT部署中具有广阔的应用前景。"}}
{"id": "2406.08788", "title": "Towards Understanding Link Predictor Generalizability Under Distribution Shifts", "authors": ["Jay Revolinsky", "Harry Shomer", "Jiliang Tang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      KDD 25' Datasets & Benchmarks Track, 14 pages, 8 figures, 18 tables", "url": "http://arxiv.org/abs/2406.08788v3", "summary": "State-of-the-art link prediction (LP) models demonstrate impressive benchmark\nresults. However, popular benchmark datasets often assume that training,\nvalidation, and testing samples are representative of the overall dataset\ndistribution. In real-world situations, this assumption is often incorrect;\nuncontrolled factors lead new dataset samples to come from a different\ndistribution than training samples. Additionally, the majority of recent work\nwith graph dataset shift focuses on node- and graph-level tasks, largely\nignoring link-level tasks. To bridge this gap, we introduce a novel splitting\nstrategy, known as LPShift, which utilizes structural properties to induce a\ncontrolled distribution shift. We verify LPShift's effect through empirical\nevaluation of SOTA LP models on 16 LPShift variants of original dataset splits,\nwith results indicating drastic changes to model performance. Additional\nexperiments demonstrate graph structure has a strong influence on the success\nof current generalization methods. Source Code Available Here:\nhttps://github.com/revolins/LPShift", "comment": "KDD 25' Datasets & Benchmarks Track, 14 pages, 8 figures, 18 tables", "pdf_url": "http://arxiv.org/pdf/2406.08788v3", "cate": "cs.LG", "date": "2024-06-13", "updated": "2025-07-16", "AI": {"title_translation": "探究链接预测器在分布偏移下的泛化能力", "tldr": "本文引入了一种名为LPShift的新型数据划分策略，用于研究链接预测模型在受控分布偏移下的泛化能力，发现现有模型性能显著下降，且图结构对泛化方法影响很大。", "motivation": "现有链接预测模型在基准测试中表现出色，但这些基准数据集通常假设训练、验证和测试样本来自相同分布，这与现实世界中由于不可控因素导致数据分布偏移的情况不符。此外，大多数关于图数据集偏移的研究集中在节点和图级别任务，而忽略了链接级别任务。", "method": "引入了一种名为LPShift的新型划分策略，该策略利用结构属性来诱导受控的分布偏移。通过在16种LPShift变体数据集上对最先进的链接预测模型进行实证评估。", "result": "实证评估结果表明，模型性能发生了剧烈变化。额外实验表明，图结构对当前泛化方法的成功有很大影响。", "conclusion": "现有链接预测模型在分布偏移下泛化能力不足，图结构对泛化方法的成功至关重要。LPShift为研究链接预测在分布偏移下的泛化能力提供了新的工具。", "translation": "最先进的链接预测（LP）模型展示了令人印象深刻的基准测试结果。然而，流行的基准数据集通常假设训练、验证和测试样本代表了整体数据集分布。在现实世界中，这一假设通常是不正确的；不可控因素导致新的数据集样本与训练样本来自不同的分布。此外，最近大多数关于图数据集偏移的工作都集中在节点级和图级任务上，很大程度上忽略了链接级任务。为了弥补这一差距，我们引入了一种名为LPShift的新型划分策略，该策略利用结构属性来诱导受控的分布偏移。我们通过对16种LPShift变体数据集上的SOTA LP模型进行实证评估来验证LPShift的效果，结果表明模型性能发生了剧烈变化。额外的实验表明，图结构对当前泛化方法的成功有很强的影响。源代码可在此处获取：https://github.com/revolins/LPShift", "summary": "本文旨在探究链接预测模型在分布偏移下的泛化能力，指出现有基准数据集未能反映现实世界中数据分布偏移的问题，且图数据偏移研究多集中于节点和图级别任务而忽略链接级别。为解决此问题，作者提出了一种新的数据划分策略LPShift，通过利用结构属性来诱导受控的分布偏移。实验结果表明，在LPShift变体数据集上，最先进的链接预测模型性能显著下降，并揭示了图结构对现有泛化方法成功的重要影响。", "keywords": "链接预测, 分布偏移, 泛化能力, LPShift, 图结构", "comments": "本文的创新点在于提出了LPShift这一新颖的数据划分策略，专门用于在受控条件下研究链接预测任务的分布偏移问题，填补了该领域的研究空白。这对于理解和提升链接预测模型在真实世界复杂场景下的鲁化能力具有重要意义。研究结果强调了图结构在泛化能力中的关键作用，为未来设计更鲁棒的链接预测模型提供了方向。"}}
{"id": "2406.17253", "title": "How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?", "authors": ["Huaizhi Ge", "Frank Rudzicz", "Zining Zhu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      A previous version of this document contained a hidden prompt entered by Z Zhu without knowledge of -- or consent by -- his co-authors. This version does not contain the prompt", "url": "http://arxiv.org/abs/2406.17253v3", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities, but\nupdating their knowledge post-training remains a critical challenge. While\nrecent model editing techniques like Rank-One Model Editing (ROME) show\npromise, their effectiveness may vary based on the nature of the knowledge\nbeing edited. We introduce the concept of ``perplexingness'': the degree to\nwhich new knowledge conflicts with an LLM's learned conceptual hierarchies and\ncategorical relationships. For instance, editing ``British Shorthair is a kind\nof cat'' to ``British Shorthair is a kind of dog'' represents a\nlow-perplexingness edit within the same taxonomic level, while editing ``A cat\nis a kind of animal'' to ``A cat is a kind of plant'' represents a\nhigh-perplexingness edit that violates fundamental categorical boundaries. To\nsystematically investigate this phenomenon, we introduce HierarchyData, a\ncarefully curated dataset of 99 hyponym-hypernym pairs across diverse\ncategories. Through controlled experiments across three models and four editing\nmethods, we demonstrate a strong negative correlation between the\nperplexingness of new knowledge and the effectiveness of knowledge editing. Our\nanalysis reveals that edits involving more abstract concepts (hypernyms)\ngenerally exhibit higher perplexingness and are more resistant to modification\nthan their specific counterparts (hyponyms). These findings highlight a\nfundamental challenge in LLM knowledge editing: the more a new fact contradicts\nan LLM's learned conceptual hierarchies, the harder it becomes to reliably\nencode that knowledge.", "comment": "A previous version of this document contained a hidden prompt entered\n  by Z Zhu without knowledge of -- or consent by -- his co-authors. This\n  version does not contain the prompt", "pdf_url": "http://arxiv.org/pdf/2406.17253v3", "cate": "cs.CL", "date": "2024-06-25", "updated": "2025-07-15", "AI": {"title_translation": "知识编辑方法在编辑“令人困惑”的知识方面表现如何？", "tldr": "本文引入“困惑度”概念，研究发现知识的“困惑度”越高，LLM知识编辑的有效性越低，特别是在编辑抽象概念时。", "motivation": "大型语言模型（LLMs）的知识更新是一个关键挑战。虽然现有的模型编辑技术（如ROME）显示出前景，但其有效性可能因知识的性质而异。本文旨在系统地探究新知识与LLM内部概念层次和分类关系冲突的程度（即“困惑度”）如何影响知识编辑的有效性。", "method": "研究引入了“困惑度”的概念，定义为新知识与LLM已学习的概念层次和分类关系冲突的程度。为了系统研究，构建了HierarchyData数据集，包含99个跨不同类别的下位词-上位词对。通过在三种模型和四种编辑方法上进行受控实验，分析了“困惑度”对知识编辑效果的影响。", "result": "实验结果表明，新知识的“困惑度”与知识编辑的有效性之间存在显著的负相关。分析还发现，涉及更抽象概念（上位词）的编辑通常表现出更高的“困惑度”，并且比具体概念（下位词）更难修改。", "conclusion": "研究揭示了LLM知识编辑中的一个根本性挑战：新事实越是与LLM已学习的概念层次结构相矛盾，可靠地编码该知识就越困难。", "translation": "大型语言模型（LLMs）展示了卓越的能力，但训练后更新其知识仍然是一个关键挑战。尽管最近的模型编辑技术，如Rank-One Model Editing (ROME) 显示出前景，但其有效性可能因所编辑知识的性质而异。我们引入了“困惑度”的概念：新知识与LLM已学习的概念层次和分类关系冲突的程度。例如，将“英国短毛猫是一种猫”编辑为“英国短毛猫是一种狗”代表了同一分类级别内的低困惑度编辑，而将“猫是一种动物”编辑为“猫是一种植物”则代表了违反基本分类边界的高困惑度编辑。为了系统地调查这一现象，我们引入了HierarchyData，一个精心策划的包含99个跨不同类别的下位词-上位词对的数据集。通过在三种模型和四种编辑方法上进行的受控实验，我们证明了新知识的困惑度与知识编辑的有效性之间存在强烈的负相关。我们的分析揭示，涉及更抽象概念（上位词）的编辑通常表现出更高的困惑度，并且比其具体对应物（下位词）更难以修改。这些发现突出了LLM知识编辑中的一个根本性挑战：新事实越是与LLM已学习的概念层次结构相矛盾，可靠地编码该知识就越困难。", "summary": "本文探讨了大型语言模型（LLMs）知识编辑的有效性如何受到新知识“困惑度”的影响。“困惑度”被定义为新知识与LLM内部概念层次和分类关系的冲突程度。研究者构建了HierarchyData数据集，并在一系列实验中发现，知识的“困惑度”越高，编辑的成功率越低。特别是，涉及更抽象概念的编辑（如上位词）比具体概念的编辑更难实现。这表明，当新信息与LLM已有的知识结构发生根本性矛盾时，对其进行可靠编辑是一个重大挑战。", "keywords": "知识编辑, 大语言模型, 困惑度, 概念层次, 模型修改", "comments": "这项研究通过引入“困惑度”这一创新概念，深入探讨了LLM知识编辑的内在机制和局限性。它不仅提供了量化编辑难度的视角，还通过实验验证了抽象概念比具体概念更难编辑的现象，揭示了LLM知识编辑的一个根本性挑战。这对未来模型编辑方法的设计具有重要指导意义，提示研究者应更多关注如何处理与模型内部核心知识结构冲突的复杂编辑。"}}
{"id": "2507.11744", "title": "A Cellular Automata Approach to Donation Game", "authors": ["Marcin Kowalik", "Przemysław Stokłosa", "Mateusz Grabowski", "Janusz Starzyk", "Paweł Raif"], "categories": ["cs.MA", "cs.GT", "physics.soc-ph"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      16 pages, 12 figures", "url": "http://arxiv.org/abs/2507.11744v1", "summary": "The donation game is a well-established framework for studying the emergence\nand evolution of cooperation in multi-agent systems. The cooperative behavior\ncan be influenced by the environmental noise in partially observable settings\nand by the decision-making strategies of agents, which may incorporate not only\nreputation but also traits such as generosity and forgiveness. Traditional\nsimulations often assume fully random interactions, where cooperation is tested\nbetween randomly selected agent pairs. In this paper, we investigate\ncooperation dynamics using the concept of Stephen Wolfram's one-dimensional\nbinary cellular automata. This approach allows us to explore how cooperation\nevolves when interactions are limited to neighboring agents. We define binary\ncellular automata rules that conform to the donation game mechanics.\nAdditionally, we introduce models of perceptual and action noise, along with a\nmutation matrix governing the probabilistic evolution of agent strategies. Our\nempirical results demonstrate that cooperation is significantly affected by\nagents' mobility and their spatial locality on the game board. These findings\nhighlight the importance of distinguishing between entirely random multi-agent\nsystems and those in which agents are more likely to interact with their\nnearest neighbors.", "comment": "16 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.11744v1", "cate": "cs.MA", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "捐赠博弈的元胞自动机方法", "tldr": "本文利用一维二元元胞自动机研究捐赠博弈中的合作，结果表明智能体的移动性和空间局部性显著影响合作，这与传统的随机交互模型不同。", "motivation": "传统捐赠博弈模拟通常假设完全随机的交互，这可能无法反映智能体交互具有局部性的现实场景。本文旨在研究当交互仅限于相邻智能体时合作如何演变。", "method": "本文使用斯蒂芬·沃尔夫拉姆的一维二元元胞自动机来建模捐赠博弈。它定义了符合捐赠博弈机制的二元元胞自动机规则，并引入了感知和行动噪声模型以及控制智能体策略概率演变的突变矩阵。", "result": "实证结果表明，合作受到智能体在博弈板上的移动性和空间局部性的显著影响。", "conclusion": "研究结果强调了区分完全随机的多智能体系统和智能体更可能与其最近邻居交互的系统的重要性。", "translation": "捐赠博弈是一个成熟的框架，用于研究多智能体系统中合作的出现和演变。合作行为可能受到部分可观测设置中的环境噪声以及智能体决策策略的影响，这些策略不仅可能包含声誉，还可能包含慷慨和宽恕等特质。传统的模拟通常假设完全随机的交互，其中合作是在随机选择的智能体对之间进行测试。在本文中，我们利用斯蒂芬·沃尔夫拉姆的一维二元元胞自动机概念来研究合作动力学。这种方法使我们能够探索当交互仅限于相邻智能体时合作如何演变。我们定义了符合捐赠博弈机制的二元元胞自动机规则。此外，我们引入了感知和行动噪声模型，以及控制智能体策略概率演变的突变矩阵。我们的实证结果表明，合作受到智能体在博弈板上的移动性和空间局部性的显著影响。这些发现强调了区分完全随机的多智能体系统和智能体更可能与其最近邻居交互的系统的重要性。", "summary": "本文通过采用一维二元元胞自动机，为捐赠博弈中的合作研究引入了一种新颖的方法，这与假设随机交互的传统模型有所不同。通过将交互限制在相邻智能体之间，并纳入感知/行动噪声和策略突变，研究表明智能体的移动性和空间局部性深刻影响合作行为。这突出了纯粹随机的多智能体系统与具有局部交互的系统之间的关键区别。", "keywords": "捐赠博弈, 元胞自动机, 合作, 空间局部性, 多智能体系统", "comments": "本文通过将元胞自动机应用于捐赠博弈，提供了一个新颖的视角，超越了完全随机交互的普遍假设。对局部交互的关注以及噪声和突变矩阵的引入，为研究合作提供了一个更现实的框架。其关于移动性和空间局部性影响的发现具有重要意义，强调了在多智能体系统研究中需要更细致的模型。"}}
{"id": "2507.12407", "title": "Regrasp Maps for Sequential Manipulation Planning", "authors": ["Svetlana Levit", "Marc Toussaint"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12407v1", "summary": "We consider manipulation problems in constrained and cluttered settings,\nwhich require several regrasps at unknown locations. We propose to inform an\noptimization-based task and motion planning (TAMP) solver with possible regrasp\nareas and grasp sequences to speed up the search. Our main idea is to use a\nstate space abstraction, a regrasp map, capturing the combinations of available\ngrasps in different parts of the configuration space, and allowing us to\nprovide the solver with guesses for the mode switches and additional\nconstraints for the object placements. By interleaving the creation of regrasp\nmaps, their adaptation based on failed refinements, and solving TAMP\n(sub)problems, we are able to provide a robust search method for challenging\nregrasp manipulation problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12407v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "用于顺序操作规划的抓取重定位图", "tldr": "本文提出了一种名为“抓取重定位图”的状态空间抽象方法，以加速在受限和杂乱环境中需要多次抓取重定位的顺序操作规划，通过将其与TAMP求解器相结合，提供了一种鲁棒的搜索方法。", "motivation": "在受限和杂乱的环境中，操作问题通常需要多次在未知位置进行抓取重定位，这使得基于优化的任务和运动规划（TAMP）求解器的搜索过程效率低下。", "method": "本文提出使用一种状态空间抽象，即“抓取重定位图”，来捕获配置空间不同部分中可用的抓取组合。该图为TAMP求解器提供模式切换的猜测和物体放置的额外约束。通过交错创建抓取重定位图、根据失败细化进行调整以及解决TAMP（子）问题，实现了一种鲁棒的搜索方法。", "result": "该方法能够为具有挑战性的抓取重定位操作问题提供一种鲁棒的搜索方法。", "conclusion": "通过引入抓取重定位图并将其与TAMP求解器相结合，可以有效加速并鲁棒地解决在受限和杂乱环境中需要多次抓取重定位的复杂操作规划问题。", "translation": "我们考虑在受限和杂乱环境中的操作问题，这些问题需要在未知位置进行多次抓取重定位。我们提出通过提供可能的抓取重定位区域和抓取序列来告知基于优化的任务和运动规划（TAMP）求解器，以加快搜索速度。我们的主要思想是使用一种状态空间抽象，即抓取重定位图，它捕获了配置空间不同部分中可用抓取的组合，并允许我们为求解器提供模式切换的猜测和物体放置的额外约束。通过交错创建抓取重定位图、根据失败细化进行调整以及解决TAMP（子）问题，我们能够为具有挑战性的抓取重定位操作问题提供一种鲁棒的搜索方法。", "summary": "本研究提出了一种名为“抓取重定位图”的状态空间抽象，用于解决在受限和杂乱环境中需要多次抓取重定位的顺序操作规划问题。该图通过捕获可用抓取组合并为TAMP求解器提供模式切换猜测和放置约束，从而加速搜索过程。通过迭代地创建、调整抓取重定位图并解决TAMP子问题，该方法为复杂的抓取重定位任务提供了一种鲁棒的规划解决方案。", "keywords": "抓取重定位图, 顺序操作规划, 任务和运动规划, 机器人操作, 状态空间抽象", "comments": "该论文的创新点在于引入了“抓取重定位图”这一状态空间抽象，有效地将高维的抓取重定位问题简化，并与现有的TAMP框架相结合，提高了规划效率和鲁棒性。这种方法对于实际机器人操作具有重要意义，尤其是在复杂和未知环境中。"}}
{"id": "2507.12425", "title": "Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data", "authors": ["Chandana Cheerla"], "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12425v1", "summary": "Organizations increasingly rely on proprietary enterprise data, including HR\nrecords, structured reports, and tabular documents, for critical\ndecision-making. While Large Language Models (LLMs) have strong generative\ncapabilities, they are limited by static pretraining, short context windows,\nand challenges in processing heterogeneous data formats. Conventional\nRetrieval-Augmented Generation (RAG) frameworks address some of these gaps but\noften struggle with structured and semi-structured data.\n  This work proposes an advanced RAG framework that combines hybrid retrieval\nstrategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by\nmetadata-aware filtering with SpaCy NER and cross-encoder reranking. The\nframework applies semantic chunking to maintain textual coherence and retains\ntabular data structures to preserve row-column integrity. Quantized indexing\noptimizes retrieval efficiency, while human-in-the-loop feedback and\nconversation memory improve adaptability.\n  Experiments on enterprise datasets show notable improvements: Precision@5\nincreased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74),\nand Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative\nevaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness\n(4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale.\nThese results demonstrate the framework's effectiveness in delivering accurate,\ncomprehensive, and contextually relevant responses for enterprise tasks. Future\nwork includes extending to multimodal data and integrating agent-based\nretrieval. The source code will be released at\nhttps://github.com/CheerlaChandana/Enterprise-Chatbot", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12425v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "推进结构化企业和内部数据的检索增强生成", "tldr": "本文提出了一种先进的检索增强生成（RAG）框架，结合混合检索策略和元数据感知过滤，显著提升了LLM处理结构化企业数据的准确性、完整性和相关性。", "motivation": "组织越来越依赖专有企业数据进行决策，但大型语言模型（LLMs）受限于静态预训练、短上下文窗口以及处理异构数据格式的挑战。传统的检索增强生成（RAG）框架在处理结构化和半结构化数据时表现不佳，存在这些不足。", "method": "本研究提出了一种先进的RAG框架，该框架结合了使用密集嵌入（all-mpnet-base-v2）和BM25的混合检索策略，并通过SpaCy NER的元数据感知过滤和交叉编码器重排序进行了增强。该框架应用语义分块以保持文本连贯性，并保留表格数据结构以维护行-列完整性。量化索引优化了检索效率，而人工反馈和会话记忆提高了适应性。", "result": "在企业数据集上的实验表明，精确度@5提高了15%（90%对比75%），召回率@5提高了13%（87%对比74%），平均倒数排名提高了16%（0.85对比0.69）。定性评估显示，在5点李克特量表上，忠实度（4.6对比3.0）、完整性（4.2对比2.5）和相关性（4.5对比3.2）得分更高。", "conclusion": "这些结果表明该框架在为企业任务提供准确、全面和上下文相关响应方面的有效性。", "translation": "组织越来越依赖专有企业数据，包括人力资源记录、结构化报告和表格文档，用于关键决策。虽然大型语言模型（LLMs）具有强大的生成能力，但它们受限于静态预训练、短上下文窗口以及处理异构数据格式的挑战。传统的检索增强生成（RAG）框架解决了其中一些不足，但通常难以处理结构化和半结构化数据。\n这项工作提出了一种先进的RAG框架，该框架结合了使用密集嵌入（all-mpnet-base-v2）和BM25的混合检索策略，并通过SpaCy NER的元数据感知过滤和交叉编码器重排序进行了增强。该框架应用语义分块以保持文本连贯性，并保留表格数据结构以维护行-列完整性。量化索引优化了检索效率，而人工反馈和会话记忆提高了适应性。\n在企业数据集上的实验表明了显著的改进：精确度@5提高了15%（90%对比75%），召回率@5提高了13%（87%对比74%），平均倒数排名提高了16%（0.85对比0.69）。定性评估显示，在5点李克特量表上，忠实度（4.6对比3.0）、完整性（4.2对比2.5）和相关性（4.5对比3.2）得分更高。这些结果表明该框架在为企业任务提供准确、全面和上下文相关响应方面的有效性。未来的工作包括扩展到多模态数据和集成基于代理的检索。源代码将发布在https://github.com/CheerlaChandana/Enterprise-Chatbot", "summary": "本文针对LLMs在处理结构化企业数据时面临的挑战，提出了一种先进的检索增强生成（RAG）框架。该框架通过结合混合检索（密集嵌入和BM25）、元数据感知过滤、语义分块和表格数据结构保留等技术，显著提升了检索和生成质量。实验结果显示，新框架在精确度、召回率和平均倒数排名方面均有显著提升，并在忠实度、完整性和相关性等定性指标上表现更优，有效解决了企业数据处理中的准确性和上下文相关性问题。", "keywords": "检索增强生成, 结构化数据, 混合检索, 企业数据, 大型语言模型", "comments": "这项工作在RAG领域具有重要创新性，特别是在处理复杂结构化企业数据方面。其结合多种检索和处理策略，如混合检索、元数据感知过滤和表格结构保留，有效弥补了传统RAG和LLM的不足。量化索引和人机交互的引入也体现了对效率和适应性的关注。这项研究为企业级应用提供了更可靠的RAG解决方案，具有重要的实践价值。"}}
{"id": "2507.12452", "title": "A single chip 1.024 Tb/s silicon photonics PAM4 receiver", "authors": ["Ali Pirmoradi", "Han Hao", "Kaisarbek Omirzakhov", "Alexander J. Geers", "Firooz Aflatouni"], "categories": ["physics.optics", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      29 pages, 5 main figures, 4 extended data figures, 1 extended data table", "url": "http://arxiv.org/abs/2507.12452v1", "summary": "Energy-efficient high-bandwidth interconnects play a key role in computing\nsystems. Advances in silicon photonic electro-optic modulators and wavelength\nselective components have enabled the utilization of\nwavelength-division-multiplexing (WDM) in integrated optical transceivers,\noffering a high data-rate operation while achieving enhanced energy efficiency,\nbandwidth density, scalability, and the reach required for data-centers. Here,\nwe report the demonstration of a single chip optical WDM PAM4 receiver, where\nby co-integration of a 32-channel optical demultiplexer (O-DeMux) with\nautonomous wavelength tuning and locking at a near-zero power consumption and a\n32-channel ultra-low power concurrent electrical detection system, a record\nchip energy efficiency of under 0.38 pJ/bit is measured. The implemented 32\nchannel monolithic WDM optical receiver chip achieves an end-to-end latency of\nunder 100 ps and a bit-error-rate of less than 10-12 with no equalization,\npre-distortion, or digital-signal-processing, while operating at 1.024 Tb/s\naggregate data-rate on a single input fiber, the largest reported data-rate for\na WDM PAM4 receiver chip to date. The receiver bandwidth density of more than\n3.55 Tb/s/mm2 corresponds to more than an order-of-magnitude larger bandwidth\ndensity-energy efficiency product compared to the state-of-the-art optical PAM4\nreceivers for beyond 100Gb/s links. The chip, integrated using GlobalFoundries\n45CLO CMOS-photonic process, can be used for implementation of energy-efficient\nhigh data-rate optical links for AI applications.", "comment": "29 pages, 5 main figures, 4 extended data figures, 1 extended data\n  table", "pdf_url": "http://arxiv.org/pdf/2507.12452v1", "cate": "physics.optics", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "单芯片 1.024 Tb/s 硅光子 PAM4 接收器", "tldr": "研究人员开发了一种创纪录的1.024 Tb/s单芯片硅光子PAM4接收器，具有超低功耗和高带宽密度，适用于AI应用。", "motivation": "能效高带宽互连在计算系统中扮演关键角色。硅光子电光调制器和波长选择组件的进步使得波分复用（WDM）在集成光收发器中得以应用，为数据中心提供了高数据速率操作，同时增强了能效、带宽密度、可扩展性和传输距离。", "method": "本文展示了一种单芯片光WDM PAM4接收器，通过共同集成一个32通道光解复用器（O-DeMux），该解复用器具有自主波长调谐和锁定功能（近零功耗），以及一个32通道超低功耗并行电检测系统。该芯片采用GlobalFoundries 45CLO CMOS-光子工艺集成。", "result": "测量到创纪录的芯片能效低于0.38 pJ/bit。实现的32通道单片WDM光接收器芯片实现了低于100 ps的端到端延迟，以及在没有均衡、预失真或数字信号处理的情况下，误码率低于10^-12。在单输入光纤上以1.024 Tb/s的聚合数据速率运行，这是迄今为止WDM PAM4接收器芯片报告的最大数据速率。接收器带宽密度超过3.55 Tb/s/mm2，相比于用于超过100Gb/s链路的现有技术光PAM4接收器，其带宽密度-能效乘积高出一个数量级以上。", "conclusion": "该芯片可用于实现AI应用的能效高数据速率光链路。", "translation": "能效高带宽互连在计算系统中扮演关键角色。硅光子电光调制器和波长选择组件的进步使得波分复用（WDM）在集成光收发器中得以应用，为数据中心提供了高数据速率操作，同时增强了能效、带宽密度、可扩展性和传输距离。在此，我们报告了单芯片光WDM PAM4接收器的演示，通过共同集成一个32通道光解复用器（O-DeMux），该解复用器具有自主波长调谐和锁定功能（近零功耗），以及一个32通道超低功耗并行电检测系统，测量到创纪录的芯片能效低于0.38 pJ/bit。实现的32通道单片WDM光接收器芯片实现了低于100 ps的端到端延迟，以及在没有均衡、预失真或数字信号处理的情况下，误码率低于10^-12，同时在单输入光纤上以1.024 Tb/s的聚合数据速率运行，这是迄今为止WDM PAM4接收器芯片报告的最大数据速率。接收器带宽密度超过3.55 Tb/s/mm2，相比于用于超过100Gb/s链路的现有技术光PAM4接收器，其带宽密度-能效乘积高出一个数量级以上。该芯片采用GlobalFoundries 45CLO CMOS-光子工艺集成，可用于实现AI应用的能效高数据速率光链路。", "summary": "本文介绍了一种开创性的单芯片1.024 Tb/s硅光子PAM4接收器。它通过集成一个具有自主调谐功能的32通道光解复用器和一个32通道超低功耗电检测系统，实现了低于0.38 pJ/bit的创纪录能效，并在单光纤上实现了1.024 Tb/s的聚合数据速率，这是目前WDM PAM4接收器芯片报告的最高数据速率。该芯片采用CMOS-光子工艺制造，具有低延迟和优异的误码率，无需复杂的信号处理，使其成为AI应用中能效高带宽光链路的理想选择。", "keywords": "硅光子, PAM4接收器, WDM, 高带宽, 能效", "comments": "本文的创新之处在于在单个芯片上实现了创纪录的数据速率和能效，无需复杂的数字信号处理。集成具有自主调谐功能的O-DeMux和超低功耗电检测系统是关键。其重要性在于为AI和数据中心提供高带宽、能效互连的巨大潜力。"}}
{"id": "2310.02718", "title": "Understanding Pan-Sharpening via Generalized Inverse", "authors": ["Shiqi Liu", "Yihua Tan", "Yutong Bai", "Alan Yuille"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2310.02718v3", "summary": "Pan-sharpening algorithms utilize a panchromatic image and a multispectral\nimage to generate a high spatial and high spectral image. However, the\noptimizations of the algorithms are designed with different standards. We\nemploy a simple matrix equation to describe the Pan-sharpening problem. The\nconditions for the existence of a solution and the acquisition of spectral and\nspatial resolution are discussed. A down-sampling enhancement method is\nintroduced to improve the estimation of spatial and spectral down-sample\nmatrices.\n  Using generalized inverse theory, we discovered two kinds of solution spaces\nof generalized inverse matrix formulations, which correspond to the two\nprominent classes of Pan-sharpening methods: component substitution and\nmulti-resolution analysis. Specifically, the Gram-Schmidt adaptive method is\ndemonstrated to align with the generalized inverse matrix formulation of\ncomponent substitution. A model prior of the generalized inverse matrix of the\nspectral function is rendered. Theoretical errors are analyzed. The diffusion\nprior is naturally embedded with the help of general solution spaces of the\ngeneralized inverse form, enabling the acquisition of refined Pan-sharpening\nresults.\n  Extensive experiments, including comparative, synthetic, real-data ablation\nand diffusion-related tests are conducted. The proposed methods produce\nqualitatively sharper and superior results in both synthetic and real\nexperiments. The down-sampling enhancement method demonstrates quantitatively\nand qualitatively better outcomes in real-data experiments. The diffusion prior\ncan significantly improve the performance of our methods across almost all\nevaluation measures.\n  The generalized inverse matrix theory helps deepen the understanding of\nPan-sharpening mechanisms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2310.02718v3", "cate": "cs.LG", "date": "2023-10-04", "updated": "2025-07-16", "AI": {"title_translation": "通过广义逆理解全色锐化", "tldr": "本文通过广义逆理论深入理解全色锐化问题，提出了一种基于矩阵方程和下采样增强的方法，并引入扩散先验，实验证明其能显著提高全色锐化效果。", "motivation": "现有的全色锐化算法优化标准不一，需要一个统一的框架来理解和改进这些算法。", "method": "1. 使用简单的矩阵方程描述全色锐化问题。2. 讨论解的存在条件及空间/光谱分辨率获取。3. 引入下采样增强方法改进矩阵估计。4. 利用广义逆理论发现两种解空间，对应两种全色锐化方法（分量替换和多分辨率分析）。5. 引入光谱函数的广义逆矩阵模型先验和扩散先验。6. 分析理论误差。", "result": "1. 提出的方法在合成和真实实验中均产生了更清晰、更优异的全色锐化结果。2. 下采样增强方法在真实数据实验中表现出定量和定性上的改进。3. 扩散先验显著提升了方法在几乎所有评估指标上的性能。", "conclusion": "广义逆矩阵理论有助于加深对全色锐化机制的理解，并能指导开发出更优异的全色锐化方法。", "translation": "全色锐化算法利用全色图像和多光谱图像生成高空间和高光谱分辨率图像。然而，这些算法的优化设计标准各异。本文采用一个简单的矩阵方程来描述全色锐化问题，并讨论了解决方案的存在条件以及光谱和空间分辨率的获取。引入了一种下采样增强方法，以改进空间和光谱下采样矩阵的估计。\n利用广义逆理论，我们发现了广义逆矩阵公式的两种解空间，它们对应于全色锐化两种主要方法：分量替换和多分辨率分析。具体而言，格拉姆-施密特自适应方法被证明与分量替换的广义逆矩阵公式相符。本文提出了光谱函数广义逆矩阵的模型先验，并分析了理论误差。在广义逆形式的通用解空间的帮助下，扩散先验被自然地嵌入，从而获得了更精细的全色锐化结果。\n进行了广泛的实验，包括比较性、合成、真实数据消融和扩散相关测试。所提出的方法在合成和真实实验中都产生了定性上更清晰和更优越的结果。下采样增强方法在真实数据实验中表现出定量和定性上更好的结果。扩散先验可以显著提高我们方法在几乎所有评估指标上的性能。\n广义逆矩阵理论有助于加深对全色锐化机制的理解。", "summary": "本文通过广义逆理论深入分析了全色锐化问题，使用矩阵方程统一描述了现有方法，并提出了下采样增强和扩散先验等改进策略。研究揭示了广义逆解空间与现有全色锐化方法的对应关系。实验结果表明，该方法在合成和真实数据上均能显著提升全色锐化效果，尤其是在引入扩散先验后性能更优。", "keywords": "全色锐化, 广义逆, 矩阵方程, 下采样增强, 扩散先验", "comments": "本文创新性地将广义逆理论应用于全色锐化领域，为理解和统一现有算法提供了一个新颖且强大的数学框架。通过发现广义逆解空间与现有方法的对应关系，以及引入下采样增强和扩散先验，不仅深化了理论理解，也显著提升了实际应用中的锐化性能。其理论分析和实验验证都非常充分，为全色锐化研究开辟了新的视角。"}}
{"id": "2507.12140", "title": "A Hybrid High-Order method for the power-law Brinkman problem robust in all regimes", "authors": ["Daniel Castañón Quiroz", "Daniele A. Di Pietro", "Jérôme Droniou", "Marwa Salah"], "categories": ["math.NA", "cs.NA", "65N30, 65N08, 76S05, 76D07"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12140v1", "summary": "In this work we propose and analyze a new Hybrid High-Order method for the\nBrinkman problem for fluids with power-law viscosity. The proposed method\nsupports general meshes and arbitrary approximation orders and is robust in all\nregimes, from pure (power-law) Stokes to pure Darcy. Robustness is reflected by\nerror estimates that distinguish the contributions from Stokes- and\nDarcy-dominated elements as identified by an appropriate dimensionless number,\nand that additionally account for pre-asymptotic orders of convergence.\nTheoretical results are illustrated by a complete panel of numerical\nexperiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12140v1", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "适用于所有工况的幂律布林克曼问题混合高阶方法", "tldr": "提出了一种新的混合高阶方法，用于解决幂律粘度流体的布林克曼问题，该方法支持通用网格和任意近似阶数，并在所有工况下都表现出鲁棒性。", "motivation": "开发一种在所有工况下都鲁棒的数值方法，以解决具有幂律粘度的流体的Brinkman问题。", "method": "提出并分析了一种新的混合高阶(HHO)方法。该方法支持通用网格和任意近似阶数，并通过区分Stokes主导和Darcy主导单元的误差估计来体现鲁棒性，并考虑了预渐近收敛阶数。", "result": "误差估计区分了Stokes主导和Darcy主导单元的贡献，并解释了预渐近收敛阶数。理论结果通过数值实验得到了证实。", "conclusion": "该混合高阶方法能够有效且鲁棒地解决从纯Stokes到纯Darcy的所有工况下的幂律Brinkman问题。", "translation": "在这项工作中，我们提出并分析了一种新的混合高阶方法，用于解决具有幂律粘度的流体的布林克曼问题。所提出的方法支持通用网格和任意近似阶数，并且在所有工况下都表现出鲁棒性，从纯（幂律）斯托克斯流到纯达西流。鲁棒性体现在误差估计中，该误差估计区分了由适当的无量纲数识别出的斯托克斯主导和达西主导单元的贡献，并且额外考虑了预渐近收敛阶数。理论结果通过完整的数值实验面板进行了说明。", "summary": "本文提出了一种新颖的混合高阶(HHO)方法，旨在解决具有幂律粘度的Brinkman问题。该方法的一大特点是其对通用网格和任意近似阶数的支持，以及在从纯Stokes到纯Darcy的所有流体工况下的出色鲁棒性。通过区分Stokes主导和Darcy主导区域的误差估计，该方法能准确反映不同流态的贡献，并考虑预渐近收敛性。数值实验验证了理论分析的有效性。", "keywords": "混合高阶方法, 布林克曼问题, 幂律粘度, 鲁棒性, 通用网格", "comments": "该研究的创新点在于提出了一个在所有流体工况（从Stokes到Darcy）下都鲁棒的混合高阶方法来解决幂律Brinkman问题，并且能够处理通用网格和任意近似阶数。其通过区分不同流态贡献的误差估计，增强了方法的理论严谨性和实际适用性。"}}
{"id": "2507.12456", "title": "On One-Shot Signatures, Quantum vs Classical Binding, and Obfuscating Permutations", "authors": ["Omri Shmueli", "Mark Zhandry"], "categories": ["cs.CR", "quant-ph"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12456v1", "summary": "One-shot signatures (OSS) were defined by Amos, Georgiou, Kiayias, and\nZhandry (STOC'20). These allow for signing exactly one message, after which the\nsigning key self-destructs, preventing a second message from ever being signed.\nWhile such an object is impossible classically, Amos et al observe that OSS may\nbe possible using quantum signing keys by leveraging the no-cloning principle.\nOSS has since become an important conceptual tool with many applications in\ndecentralized settings and for quantum cryptography with classical\ncommunication. OSS are also closely related to separations between\nclassical-binding and collapse-binding for post-quantum hashing and\ncommitments. Unfortunately, the only known OSS construction due to Amos et al.\nwas only justified in a classical oracle model, and moreover their\njustification was ultimately found to contain a fatal bug. Thus, the existence\nof OSS, even in a classical idealized model, has remained open.\n  We give the first standard-model OSS, with provable security assuming\n(sub-exponential) indistinguishability obfuscation (iO) and LWE. This also\ngives the first standard-model separation between classical and\ncollapse-binding post-quantum commitments/hashing, solving a decade-old open\nproblem. Along the way, we also give the first construction with unconditional\nsecurity relative to a classical oracle. To achieve our standard-model\nconstruction, we develop a notion of permutable pseudorandom permutations\n(permutable PRPs), and show how they are useful for translating oracle proofs\ninvolving random permutations into obfuscation-based proofs. In particular,\nobfuscating permutable PRPs gives a trapdoor one-way permutation that is\n\\emph{full-domain}, solving another decade-old-problem of constructing this\nobject from (sub-exponential) iO and one-way functions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12456v1", "cate": "cs.CR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "论一次性签名、量子与经典绑定，以及混淆置换", "tldr": "本文首次在标准模型下构建了一次性签名（OSS），解决了现有OSS构造的缺陷，并实现了量子与经典绑定的分离，同时引入了可置换伪随机置换（permutable PRPs）的概念。", "motivation": "现有的Amos等人提出的一次性签名（OSS）构造仅在经典预言模型中得到证明，且其证明存在致命缺陷，导致OSS的存在性，即使在经典理想化模型中，也仍是一个开放问题。此外，经典绑定和塌缩绑定之间的分离也是一个十年未决的开放问题。", "method": "作者在（亚指数）不可区分混淆（iO）和LWE的假设下，构建了首个标准模型下的一次性签名（OSS）。为了实现这一目标，他们开发了可置换伪随机置换（permutable PRPs）的概念，并展示了如何利用它们将涉及随机置换的预言证明转化为基于混淆的证明。通过混淆可置换PRPs，还得到了一个全域陷门单向置换。", "result": "1. 首次在标准模型下构建了具有可证明安全性的一次性签名（OSS），假设为（亚指数）不可区分混淆（iO）和LWE。2. 首次在标准模型下实现了经典绑定和塌缩绑定后量子承诺/哈希之间的分离，解决了长达十年的开放问题。3. 首次构建了相对于经典预言机具有无条件安全性的构造。4. 通过混淆可置换PRPs，解决了另一个十年未决的问题，即从（亚指数）iO和单向函数构造全域陷门单向置换。", "conclusion": "本文成功地解决了关于一次性签名存在性的开放问题，并首次在标准模型下提供了其构造，同时实现了经典与塌缩绑定之间的关键分离。此外，通过引入可置换伪随机置换，为从理论证明到实际构造的转化提供了新的工具，并解决了全域陷门单向置换的构造问题。", "translation": "一次性签名（OSS）由Amos、Georgiou、Kiayias和Zhandry（STOC'20）定义。它们允许精确地签署一条消息，此后签名密钥自毁，防止签署第二条消息。虽然这种对象在经典情况下是不可能的，但Amos等人观察到，通过利用不可克隆原理，OSS可能可以使用量子签名密钥实现。OSS此后已成为一个重要的概念工具，在去中心化设置和使用经典通信的量子密码学中具有许多应用。OSS也与后量子哈希和承诺的经典绑定和塌缩绑定之间的分离密切相关。不幸的是，唯一已知的一次性签名构造，即Amos等人的构造，仅在经典预言模型中得到证明，而且他们的证明最终被发现包含一个致命错误。因此，即使在经典理想化模型中，OSS的存在性仍然是一个开放问题。\n我们首次给出了标准模型下的一次性签名，其可证明安全性假设为（亚指数）不可区分混淆（iO）和LWE。这也首次在标准模型下实现了经典和塌缩绑定后量子承诺/哈希之间的分离，解决了长达十年的开放问题。在此过程中，我们还首次给出了相对于经典预言机具有无条件安全性的构造。为了实现我们的标准模型构造，我们开发了可置换伪随机置换（permutable PRPs）的概念，并展示了它们如何有助于将涉及随机置换的预言证明转化为基于混淆的证明。特别是，混淆可置换PRPs提供了一个全域陷门单向置换，解决了从（亚指数）iO和单向函数构造此对象的另一个十年未决问题。", "summary": "本文解决了长期存在的一次性签名（OSS）存在性问题，并首次在标准模型下基于（亚指数）不可区分混淆（iO）和LWE构建了具有可证明安全性的OSS。这项工作还首次在标准模型下实现了经典绑定和塌缩绑定后量子承诺/哈希之间的分离。为实现这些目标，论文引入了可置换伪随机置换（permutable PRPs）的概念，并展示了其在将预言证明转化为基于混淆证明中的应用，同时解决了全域陷门单向置换的构造难题。", "keywords": "一次性签名, 标准模型, 不可区分混淆, 量子密码学, 伪随机置换", "comments": "本文在密码学领域取得了重要突破，首次在标准模型下解决了困扰已久的一次性签名（OSS）的构造问题，并修正了先前研究的缺陷。其创新之处在于引入了“可置换伪随机置换”（permutable PRPs）这一新概念，并展示了其在连接理论预言模型证明与基于混淆的实际构造之间的强大能力。此外，论文还成功解决了经典与塌缩绑定分离以及全域陷门单向置换的两个十年未决的开放问题，对量子密码学和后量子密码学理论具有深远影响。"}}
{"id": "2507.11566", "title": "Emergent Heterogeneous Swarm Control Through Hebbian Learning", "authors": ["Fuda van Diggelen", "Tugay Alperen Karagüzel", "Andres Garcia Rincon", "A. E. Eiben", "Dario Floreano", "Eliseo Ferrante"], "categories": ["cs.NE", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11566v1", "summary": "In this paper, we introduce Hebbian learning as a novel method for swarm\nrobotics, enabling the automatic emergence of heterogeneity. Hebbian learning\npresents a biologically inspired form of neural adaptation that solely relies\non local information. By doing so, we resolve several major challenges for\nlearning heterogeneous control: 1) Hebbian learning removes the complexity of\nattributing emergent phenomena to single agents through local learning rules,\nthus circumventing the micro-macro problem; 2) uniform Hebbian learning rules\nacross all swarm members limit the number of parameters needed, mitigating the\ncurse of dimensionality with scaling swarm sizes; and 3) evolving Hebbian\nlearning rules based on swarm-level behaviour minimises the need for extensive\nprior knowledge typically required for optimising heterogeneous swarms. This\nwork demonstrates that with Hebbian learning heterogeneity naturally emerges,\nresulting in swarm-level behavioural switching and in significantly improved\nswarm capabilities. It also demonstrates how the evolution of Hebbian learning\nrules can be a valid alternative to Multi Agent Reinforcement Learning in\nstandard benchmarking tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11566v1", "cate": "cs.NE", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "通过赫布学习实现异构群体控制的涌现", "tldr": "本文提出将赫布学习应用于群体机器人，以实现异构行为的自动涌现，解决了异构控制学习中的多项挑战，并显著提升了群体能力。", "motivation": "在群体机器人中，实现异构控制的学习面临多个主要挑战：1) 将涌现现象归因于单个智能体的复杂性（微观-宏观问题）；2) 随着群体规模扩大，参数数量剧增导致的维度诅咒；3) 优化异构群体通常需要大量先验知识。本文旨在通过引入赫布学习来解决这些问题。", "method": "本文引入赫布学习作为群体机器人的一种新颖方法。赫布学习是一种受生物学启发的神经网络适应形式，仅依赖局部信息。研究通过在所有群体成员中采用统一的赫布学习规则，并基于群体层面的行为进化赫布学习规则来实现异构控制。", "result": "研究表明，通过赫布学习，异构性能够自然涌现，从而实现群体层面的行为切换，并显著提升了群体能力。此外，进化赫布学习规则被证明是标准基准任务中多智能体强化学习的有效替代方案。", "conclusion": "赫布学习是一种有效且有前景的方法，可以在群体机器人中实现异构控制的自动涌现，解决了现有方法的挑战，并提高了群体性能，同时为多智能体强化学习提供了替代方案。", "translation": "在本文中，我们引入赫布学习作为群体机器人的一种新颖方法，能够实现异构性的自动涌现。赫布学习呈现出一种受生物学启发的神经网络适应形式，它完全依赖于局部信息。通过这样做，我们解决了学习异构控制的几个主要挑战：1) 赫布学习通过局部学习规则消除了将涌现现象归因于单个智能体的复杂性，从而规避了微观-宏观问题；2) 所有群体成员中统一的赫布学习规则限制了所需参数的数量，减轻了随着群体规模扩大而出现的维度诅咒；3) 基于群体层面行为进化赫布学习规则最大限度地减少了通常优化异构群体所需的大量先验知识。这项工作表明，通过赫布学习，异构性自然涌现，导致群体层面的行为切换并显著提高了群体能力。它还展示了赫布学习规则的进化如何成为标准基准任务中多智能体强化学习的有效替代方案。", "summary": "本文提出了一种将赫布学习应用于群体机器人以实现异构控制的新方法。该方法通过利用局部信息和统一的学习规则，解决了传统异构控制学习中微观-宏观问题、维度诅咒以及对大量先验知识的依赖。研究结果表明，赫布学习能够自然地促使异构性涌现，从而提高群体能力并实现行为切换。此外，它还被证明是多智能体强化学习的一种可行替代方案。", "keywords": "赫布学习, 群体机器人, 异构控制, 涌现行为, 局部学习", "comments": "本文的创新之处在于首次将赫布学习引入群体机器人领域，以解决异构控制的挑战。其重要性在于提供了一种基于局部信息、参数高效且无需大量先验知识的异构群体控制方法，对于大规模群体系统的自主适应和复杂行为的涌现具有重要意义。文章还提出了赫布学习作为多智能体强化学习的替代方案，拓展了研究思路。"}}
{"id": "2507.12102", "title": "Hyper pattern matching", "authors": ["Masaki Waga", "Étienne André"], "categories": ["cs.FL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      This is the author (and extended) version of the manuscript of the same name published in the proceedings of the 25th International Conference on Runtime Verification (RV 2025)", "url": "http://arxiv.org/abs/2507.12102v1", "summary": "In runtime verification, pattern matching, which searches for occurrences of\na specific pattern within a word, provides more information than a simple\nviolation detection of the monitored property, by locating concrete evidence of\nthe violation. However, witnessing violations of some properties, particularly\nhyperproperties, requires evidence across multiple input words or different\nparts of the same word, which goes beyond the scope of conventional pattern\nmatching. We propose here hyper pattern matching, a generalization of pattern\nmatching over a set of words. Properties of interest include robustness and\n(non-)interference. As a formalism for patterns, we use nondeterministic\nasynchronous finite automata (NAAs). We first provide a naive algorithm for\nhyper pattern matching and then devise several heuristics for better\nefficiency. Although we prove the NP-completeness of the problem, our\nimplementation HypPAu is able to address several case studies scalable in the\nlength, number of words (or logs) and number of dimensions, suggesting the\npractical relevance of our approach.", "comment": "This is the author (and extended) version of the manuscript of the\n  same name published in the proceedings of the 25th International Conference\n  on Runtime Verification (RV 2025)", "pdf_url": "http://arxiv.org/pdf/2507.12102v1", "cate": "cs.FL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "超模式匹配", "tldr": "提出了一种名为“超模式匹配”的新方法，用于在运行时验证中检测跨多个输入词或同一词不同部分的违规行为，特别适用于超属性，并证明其NP完全性，但实现工具HypPAu在案例研究中表现出良好的可扩展性。", "motivation": "在运行时验证中，传统模式匹配虽然能提供违规证据，但无法处理超属性（如鲁棒性和非干扰性），因为这些属性的违规证据需要跨多个输入词或同一词的不同部分。因此，需要一种更通用的模式匹配方法。", "method": "提出了一种名为“超模式匹配”的模式匹配泛化方法，它作用于一组词。使用非确定性异步有限自动机（NAAs）作为模式的形式化工具。首先提供了一种朴素算法，然后设计了几种启发式方法以提高效率，并实现了名为HypPAu的工具。", "result": "证明了超模式匹配问题的NP完全性。尽管如此，实现工具HypPAu在长度、词（或日志）数量和维度数量方面，能够有效处理多个可扩展的案例研究。", "conclusion": "该研究提出的超模式匹配方法及其实现工具HypPAu在处理超属性的运行时验证方面具有实际相关性，尽管问题本身是NP完全的。", "translation": "在运行时验证中，模式匹配通过定位违规的具体证据，比简单地检测受监控属性的违规提供更多信息。然而，见证某些属性（特别是超属性）的违规，需要跨多个输入词或同一词的不同部分的证据，这超出了传统模式匹配的范围。我们在此提出了超模式匹配，这是模式匹配在词集上的泛化。感兴趣的属性包括鲁棒性和（非）干扰性。作为模式的形式化工具，我们使用非确定性异步有限自动机（NAAs）。我们首先提供了一种用于超模式匹配的朴素算法，然后设计了几种启发式方法以提高效率。尽管我们证明了该问题的NP完全性，但我们的实现HypPAu能够处理多个在长度、词（或日志）数量和维度数量上可扩展的案例研究，这表明了我们方法的实际相关性。", "summary": "本论文提出了一种名为“超模式匹配”的新范式，旨在解决传统模式匹配在运行时验证中无法处理超属性（如鲁棒性、非干扰性）的问题。超模式匹配能够检测跨多个输入词或同一词不同部分的违规证据。该方法使用非确定性异步有限自动机（NAAs）作为形式化工具，并开发了朴素算法及多项启发式优化。尽管该问题被证明是NP完全的，但其实现工具HypPAu在多个案例研究中展现出良好的可扩展性，验证了该方法的实用性。", "keywords": "超模式匹配, 运行时验证, 超属性, 非确定性异步有限自动机, NP完全性", "comments": "本文的创新点在于提出了“超模式匹配”这一新概念，将传统的模式匹配扩展到处理跨多个词或同一词不同部分的超属性验证，这在运行时验证领域具有重要意义。尽管问题复杂度较高（NP完全），但其实现的工具HypPAu在实际案例中展现出良好的可扩展性，证明了理论与实践结合的有效性。"}}
{"id": "2504.04074", "title": "Space Surveillance with High-Frequency Radar", "authors": ["Brendan Hennessy", "Heath Yardley", "Rob Debnam", "Tristan A. Camilleri", "Nicholas K. Spencer", "David A. Holdsworth", "Goeff Warne", "Brian Cheung", "Sergey Kharabash"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.04074v2", "summary": "High-Frequency (HF) radar is well suited to the surveillance of\nlow-Earth-orbit space. For large targets, a small deployable HF radar is able\nto match the detection performance of much larger space surveillance radar\nsystems operating at higher frequencies. However, there are some unique\nchallenges associated with the use of HF, including the range--Doppler coupling\nbias, coarse detection-level localisation, and the presence of meteor returns\nand other unwanted signals. This paper details the use of HF radar for space\nsurveillance, including signal processing and radar product formation,\ntracking, ionospheric correction, and orbit determination. It is shown that by\nfusing measurements from multiple passes, accurate orbital estimates can be\nobtained. Included are results from recent SpaceFest trials of the Defence\nScience and Technology Group's HF space surveillance radar, achieving real-time\nwide-area surveillance in tracking, orbit determination, and cueing of other\nspace surveillance sensors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.04074v2", "cate": "eess.SP", "date": "2025-04-05", "updated": "2025-07-16", "AI": {"title_translation": "高频雷达空间监视", "tldr": "本文探讨了使用高频（HF）雷达进行低地球轨道空间监视的适用性及其挑战，并展示了通过信号处理、跟踪、电离层校正和多通道测量融合，可以实现准确的轨道估计和实时广域监视。", "motivation": "高频（HF）雷达非常适合低地球轨道空间监视，小型可部署HF雷达在检测大型目标方面能与更大的高频空间监视雷达系统相媲美。然而，使用HF雷达存在一些独特的挑战，例如距离-多普勒耦合偏差、粗略的检测级定位以及流星回波和其他不必要信号的存在。因此，本文旨在详细介绍HF雷达在空间监视中的应用，并解决相关挑战。", "method": "本文详细介绍了HF雷达用于空间监视的方法，包括信号处理和雷达产品形成、跟踪、电离层校正和轨道确定。研究通过融合来自多次通过的测量数据来获取准确的轨道估计。", "result": "通过融合来自多次通过的测量数据，可以获得准确的轨道估计。国防科学技术小组的HF空间监视雷达在最近的SpaceFest试验中取得了成果，实现了跟踪、轨道确定和提示其他空间监视传感器的实时广域监视。", "conclusion": "高频雷达非常适合低地球轨道空间监视，尽管存在一些独特挑战，但通过适当的信号处理、电离层校正和多通道测量融合，可以实现准确的轨道估计和实时广域监视。", "translation": "高频（HF）雷达非常适合对低地球轨道空间进行监视。对于大型目标，小型可部署HF雷达能够与运行在更高频率的更大空间监视雷达系统相匹配，达到相同的探测性能。然而，使用HF雷达存在一些独特的挑战，包括距离-多普勒耦合偏差、粗略的探测级定位以及流星回波和其他不需要的信号的存在。本文详细介绍了HF雷达在空间监视中的应用，包括信号处理和雷达产品形成、跟踪、电离层校正以及轨道确定。结果表明，通过融合来自多次通过的测量数据，可以获得准确的轨道估计。文中包含了国防科学技术小组HF空间监视雷达在近期SpaceFest试验中的结果，该雷达在跟踪、轨道确定和提示其他空间监视传感器方面实现了实时广域监视。", "summary": "本文探讨了高频（HF）雷达在低地球轨道空间监视中的应用。尽管HF雷达在大型目标探测方面表现出色，但面临距离-多普勒耦合、定位精度低和杂波干扰等挑战。文章详细介绍了HF雷达的信号处理、跟踪、电离层校正和轨道确定方法，并通过融合多通道测量数据，成功实现了准确的轨道估计和实时广域监视，并展示了Defence Science and Technology Group的HF空间监视雷达在SpaceFest试验中的实际成果。", "keywords": "高频雷达, 空间监视, 轨道确定, 信号处理, 电离层校正", "comments": "本文创新性地探讨了高频雷达在空间监视领域的应用，并提出了一系列信号处理和数据融合技术来克服其固有的挑战。其重要性在于证明了小型HF雷达系统也能达到大型高频雷达的性能，且能实现实时广域监视和精确轨道估计，这对于成本效益和部署灵活性具有重要意义。"}}
{"id": "2403.14559", "title": "VAPO: Visibility-Aware Keypoint Localization for Efficient 6DoF Object Pose Estimation", "authors": ["Ruyi Lian", "Yuewei Lin", "Longin Jan Latecki", "Haibin Ling"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted for publication in the Proceedings of the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025) as oral presentation", "url": "http://arxiv.org/abs/2403.14559v4", "summary": "Localizing predefined 3D keypoints in a 2D image is an effective way to\nestablish 3D-2D correspondences for instance-level 6DoF object pose estimation.\nHowever, unreliable localization results of invisible keypoints degrade the\nquality of correspondences. In this paper, we address this issue by localizing\nthe important keypoints in terms of visibility. Since keypoint visibility\ninformation is currently missing in the dataset collection process, we propose\nan efficient way to generate binary visibility labels from available\nobject-level annotations, for keypoints of both asymmetric objects and\nsymmetric objects. We further derive real-valued visibility-aware importance\nfrom binary labels based on the PageRank algorithm. Taking advantage of the\nflexibility of our visibility-aware importance, we construct VAPO\n(Visibility-Aware POse estimator) by integrating the visibility-aware\nimportance with a state-of-the-art pose estimation algorithm, along with\nadditional positional encoding. VAPO can work in both CAD-based and CAD-free\nsettings. Extensive experiments are conducted on popular pose estimation\nbenchmarks including Linemod, Linemod-Occlusion, and YCB-V, demonstrating that\nVAPO clearly achieves state-of-the-art performances. Project page:\nhttps://github.com/RuyiLian/VAPO.", "comment": "accepted for publication in the Proceedings of the 2025 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2025) as\n  oral presentation", "pdf_url": "http://arxiv.org/pdf/2403.14559v4", "cate": "cs.CV", "date": "2024-03-21", "updated": "2025-07-15", "AI": {"title_translation": "VAPO：面向高效6自由度物体位姿估计的可见性感知关键点定位", "tldr": "本文提出VAPO，通过生成关键点可见性标签并利用PageRank算法导出可见性感知重要性，集成到现有位姿估计算法中，解决了不可见关键点定位不可靠的问题，并在多个基准测试中达到了最先进的性能。", "motivation": "现有的6自由度物体位姿估计方法中，不可见关键点的不可靠定位结果会降低3D-2D对应关系的质量。此外，数据集中缺少关键点可见性信息。", "method": "论文提出了一种高效方法，可以从现有的物体级标注中为非对称和对称物体的关键点生成二值可见性标签。接着，基于PageRank算法，从二值标签中推导出实值可见性感知重要性。然后，将这种可见性感知重要性与最先进的位姿估计算法以及额外的S位置编码相结合，构建了VAPO（可见性感知位姿估计器），该方法可在基于CAD和无CAD的环境中工作。", "result": "在Linemod、Linemod-Occlusion和YCB-V等流行位姿估计基准上进行了广泛实验，结果表明VAPO明显实现了最先进的性能。", "conclusion": "通过引入和利用关键点可见性信息，VAPO有效地解决了不可见关键点定位不可靠的问题，并在6自由度物体位姿估计任务中达到了最先进的性能。", "translation": "在2D图像中定位预定义的3D关键点是建立实例级6自由度物体位姿估计的3D-2D对应关系的有效方法。然而，不可见关键点不可靠的定位结果会降低对应关系的质量。在本文中，我们通过定位可见性方面重要的关键点来解决这个问题。由于目前的数据集收集过程中缺少关键点可见性信息，我们提出了一种从现有物体级标注中为非对称物体和对称物体的关键点生成二值可见性标签的高效方法。我们进一步基于PageRank算法从二值标签中推导出实值可见性感知重要性。利用我们可见性感知重要性的灵活性，我们将可见性感知重要性与最先进的位姿估计算法以及附加的位置编码相结合，构建了VAPO（可见性感知位姿估计器）。VAPO可以在基于CAD和无CAD的设置中工作。在Linemod、Linemod-Occlusion和YCB-V等流行位姿估计基准上进行了广泛实验，结果表明VAPO明显实现了最先进的性能。项目页面：https://github.com/RuyiLian/VAPO。", "summary": "本文提出了VAPO，一个可见性感知的6自由度物体位姿估计器，旨在解决不可见关键点定位不可靠导致3D-2D对应关系质量下降的问题。作者提出了一种高效方法，从现有物体级标注中生成关键点的二值可见性标签，并利用PageRank算法从中推导出实值可见性感知重要性。VAPO将这种可见性感知重要性与先进的位姿估计算法和位置编码相结合，并支持CAD-based和CAD-free设置。实验证明，VAPO在多个流行基准测试中达到了最先进的性能。", "keywords": "6自由度位姿估计, 关键点定位, 可见性感知, PageRank, 物体位姿估计", "comments": "本文的创新点在于引入了关键点可见性信息来提高6自由度物体位姿估计的准确性，并提出了一种从现有标注中高效生成可见性标签的方法，以及利用PageRank算法推导可见性感知重要性的机制。这种方法有效地解决了不可见关键点定位的挑战，提升了位姿估计的鲁棒性和性能。其在CAD-based和CAD-free设置下的通用性也增加了其实用价值。"}}
{"id": "2309.10301", "title": "Prominent Roles of Conditionally Invariant Components in Domain Adaptation: Theory and Algorithms", "authors": ["Keru Wu", "Yuansi Chen", "Wooseok Ha", "Bin Yu"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2309.10301v3", "summary": "Domain adaptation (DA) is a statistical learning problem that arises when the\ndistribution of the source data used to train a model differs from that of the\ntarget data used to evaluate the model. While many DA algorithms have\ndemonstrated considerable empirical success, blindly applying these algorithms\ncan often lead to worse performance on new datasets. To address this, it is\ncrucial to clarify the assumptions under which a DA algorithm has good target\nperformance. In this work, we focus on the assumption of the presence of\nconditionally invariant components (CICs), which are relevant for prediction\nand remain conditionally invariant across the source and target data. We\ndemonstrate that CICs, which can be estimated through conditional invariant\npenalty (CIP), play three prominent roles in providing target risk guarantees\nin DA. First, we propose a new algorithm based on CICs, importance-weighted\nconditional invariant penalty (IW-CIP), which has target risk guarantees beyond\nsimple settings such as covariate shift and label shift. Second, we show that\nCICs help identify large discrepancies between source and target risks of other\nDA algorithms. Finally, we demonstrate that incorporating CICs into the domain\ninvariant projection (DIP) algorithm can address its failure scenario caused by\nlabel-flipping features. We support our new algorithms and theoretical findings\nvia numerical experiments on synthetic data, MNIST, CelebA, Camelyon17, and\nDomainNet datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2309.10301v3", "cate": "stat.ML", "date": "2023-09-19", "updated": "2025-07-16", "AI": {"title_translation": "领域适应中条件不变分量的重要作用：理论与算法", "tldr": "本文探讨了条件不变分量（CICs）在领域适应（DA）中提供目标风险保证的关键作用，并提出了新的算法。", "motivation": "领域适应（DA）算法在不同数据集上盲目应用时可能导致性能下降，因此需要明确算法在何种假设下能获得良好的目标性能。本文关注条件不变分量（CICs）存在的假设，这些分量与预测相关且在源数据和目标数据之间保持条件不变。", "method": "本文关注条件不变分量（CICs），其可通过条件不变惩罚（CIP）进行估计。基于CICs，提出了一种新的算法——重要性加权条件不变惩罚（IW-CIP），以提供目标风险保证。此外，研究还展示了CICs如何帮助识别其他DA算法的源域和目标域风险之间的差异，以及如何将CICs整合到领域不变投影（DIP）算法中以解决其失败场景。", "result": "1. 提出了新的算法IW-CIP，该算法在超越协变量偏移和标签偏移等简单设置的情况下，具有目标风险保证。2. 证明了CICs有助于识别其他领域适应算法在源域和目标域风险之间存在的巨大差异。3. 展示了将CICs整合到领域不变投影（DIP）算法中，可以解决由标签翻转特征引起的失败场景。4. 通过在合成数据、MNIST、CelebA、Camelyon17和DomainNet数据集上的数值实验，支持了新的算法和理论发现。", "conclusion": "条件不变分量（CICs）在领域适应中扮演着重要角色，不仅能提供目标风险保证，还能改进现有算法并帮助分析其他算法的性能，为领域适应问题的解决提供了理论和算法上的新途径。", "translation": "领域适应（DA）是一种统计学习问题，当用于训练模型的源数据分布与用于评估模型的目标数据分布不同时，就会出现这个问题。尽管许多DA算法已经取得了相当大的经验成功，但盲目应用这些算法往往会导致在新数据集上的性能下降。为了解决这个问题，阐明DA算法在何种假设下能获得良好的目标性能至关重要。在这项工作中，我们关注条件不变分量（CICs）存在的假设，这些分量与预测相关，并在源数据和目标数据之间保持条件不变。我们证明了CICs（可以通过条件不变惩罚（CIP）进行估计）在提供DA中的目标风险保证方面扮演着三个重要角色。首先，我们提出了一种基于CICs的新算法——重要性加权条件不变惩罚（IW-CIP），该算法在超越协变量偏移和标签偏移等简单设置的情况下，具有目标风险保证。其次，我们表明CICs有助于识别其他DA算法的源域和目标域风险之间的巨大差异。最后，我们证明将CICs整合到领域不变投影（DIP）算法中可以解决其由标签翻转特征引起的失败场景。我们通过在合成数据、MNIST、CelebA、Camelyon17和DomainNet数据集上的数值实验，支持了我们的新算法和理论发现。", "summary": "本文深入探讨了领域适应（DA）中条件不变分量（CICs）的关键作用，CICs是与预测相关且在源域和目标域间保持条件不变的特征。研究表明，通过条件不变惩罚（CIP）可估计的CICs在提供目标风险保证方面具有三个重要作用：它们是新算法IW-CIP的基础，能提供超越简单偏移设置的风险保证；它们有助于识别其他DA算法的源域和目标域风险差异；并且能改进DIP算法以克服由标签翻转特征导致的失败。这些理论和算法上的发现得到了广泛实验的支持。", "keywords": "领域适应, 条件不变分量, 条件不变惩罚, 目标风险保证, 泛化性", "comments": "这篇论文的创新点在于明确提出了条件不变分量（CICs）在领域适应中的核心作用，并将其理论化和算法化。它不仅提出了新的算法IW-CIP，还展示了CICs作为分析和改进现有DA算法的通用工具的潜力。这种对DA假设的深入剖析，特别是对CICs的强调，对于理解DA算法的鲁棒性和泛化能力至关重要，有助于避免“盲目应用”DA算法的问题。"}}
{"id": "2507.11906", "title": "CoCre-Sam (Kokkuri-san): Modeling Ouija Board as Collective Langevin Dynamics Sampling from Fused Language Models", "authors": ["Tadahiro Taniguchi", "Masatoshi Nagano", "Haruumi Omoto", "Yoshiki Hayashi"], "categories": ["cs.MA", "cs.HC"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11906v1", "summary": "Collective human activities like using an Ouija board (or Kokkuri-san) often\nproduce emergent, coherent linguistic outputs unintended by any single\nparticipant. While psychological explanations such as the ideomotor effect\nexist, a computational understanding of how decentralized, implicit linguistic\nknowledge fuses through shared physical interaction remains elusive. We\nintroduce CoCre-Sam (Collective-Creature Sampling), a framework modeling this\nphenomenon as collective Langevin dynamics sampling from implicitly fused\nlanguage models. Each participant is represented as an agent associated with an\nenergy landscape derived from an internal language model reflecting linguistic\npriors, and agents exert stochastic forces based on local energy gradients. We\ntheoretically prove that the collective motion of the shared pointer\n(planchette) corresponds to Langevin MCMC sampling from the sum of individual\nenergy landscapes, representing fused collective knowledge. Simulations\nvalidate that CoCre-Sam dynamics effectively fuse different models and generate\nmeaningful character sequences, while ablation studies confirm the essential\nroles of collective interaction and stochasticity. Altogether, CoCre-Sam\nprovides a novel computational mechanism linking individual implicit knowledge,\nembodied collective action, and emergent linguistic phenomena, grounding these\ncomplex interactions in the principles of probabilistic sampling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11906v1", "cate": "cs.MA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "CoCre-Sam (Kokkuri-san)：将扶乩板建模为来自融合语言模型的集体朗之万动力学采样", "tldr": "本文提出了CoCre-Sam，一个将扶乩板现象建模为来自融合语言模型的集体朗之万动力学采样的框架，解释了个体隐性知识如何导致涌现的集体语言输出。", "motivation": "为了计算性地理解去中心化、隐性语言知识如何通过共享物理互动在诸如扶乩板等集体人类活动中融合，这些活动会产生任何单个参与者都未曾预料到的涌现的、连贯的语言输出。现有的心理学解释（如意念运动效应）并非计算性。", "method": "引入了CoCre-Sam（集体-生物采样）框架，将每个参与者表示为与内部语言模型导出的能量景观相关联的代理。代理根据局部能量梯度施加随机力。理论上证明，共享指针（指示器）的集体运动对应于从个体能量景观之和（代表融合的集体知识）中进行的朗之万MCMC采样。通过模拟和消融研究进行验证。", "result": "模拟验证了CoCre-Sam动力学有效地融合了不同的模型并生成了有意义的字符序列。消融研究证实了集体互动和随机性的关键作用。", "conclusion": "CoCre-Sam提供了一种新颖的计算机制，将个体隐性知识、具身集体行动和涌现的语言现象联系起来，将这些复杂的互动根植于概率采样的原理中。", "translation": "集体人类活动，例如使用扶乩板（或Kokkuri-san），通常会产生任何单个参与者都未曾预料到的、涌现的、连贯的语言输出。尽管存在诸如意念运动效应等心理学解释，但对去中心化、隐性语言知识如何通过共享物理互动融合的计算理解仍然难以捉摸。我们引入了CoCre-Sam（集体-生物采样），一个将这种现象建模为从隐性融合语言模型中进行集体朗之万动力学采样的框架。每个参与者被表示为一个代理，与一个源自反映语言先验的内部语言模型的能量景观相关联，并且代理根据局部能量梯度施加随机力。我们理论上证明，共享指针（指示器）的集体运动对应于从个体能量景观之和（代表融合的集体知识）中进行的朗之万MCMC采样。模拟验证了CoCre-Sam动力学有效地融合了不同的模型并生成了有意义的字符序列，而消融研究证实了集体互动和随机性的关键作用。总而言之，CoCre-Sam提供了一种新颖的计算机制，将个体隐性知识、具身集体行动和涌现的语言现象联系起来，将这些复杂的互动根植于概率采样的原理中。", "summary": "该论文介绍了CoCre-Sam，一个计算框架，用于模拟扶乩板等集体人类活动中涌现的语言输出。它将参与者概念化为代理，其内部语言模型有助于形成融合的集体知识，并通过集体朗之万动力学进行采样。该框架理论上证明了共享指针的运动反映了从个体能量景观之和中进行的朗之万MCMC采样。模拟证实了CoCre-Sam融合模型和生成有意义序列的能力，突出了集体互动和随机性的重要性。这项工作为个体隐性知识、具身集体行动和涌现的语言现象之间提供了新颖的计算联系。", "keywords": "集体朗之万动力学, 融合语言模型, 扶乩板, 涌现语言学, 概率采样", "comments": "这篇论文为传统上由心理学解释的现象提供了一个极具创新性的计算模型。通过将集体人类互动视为一种从融合语言模型中进行概率采样的形式，它为理解涌现的集体智能和语言创造力开辟了新途径。其优势在于通过严谨的理论和计算框架，将个体隐性知识与集体行动联系起来。"}}
{"id": "2507.11729", "title": "Globalization for Scalable Short-term Load Forecasting", "authors": ["Amirhossein Ahmadi", "Hamidreza Zareipour", "Henry Leung"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      63 pages with 22 figures", "url": "http://arxiv.org/abs/2507.11729v1", "summary": "Forecasting load in power transmission networks is essential across various\nhierarchical levels, from the system level down to individual points of\ndelivery (PoD). While intuitive and locally accurate, traditional local\nforecasting models (LFMs) face significant limitations, particularly in\nhandling generalizability, overfitting, data drift, and the cold start problem.\nThese methods also struggle with scalability, becoming computationally\nexpensive and less efficient as the network's size and data volume grow. In\ncontrast, global forecasting models (GFMs) offer a new approach to enhance\nprediction generalizability, scalability, accuracy, and robustness through\nglobalization and cross-learning. This paper investigates global load\nforecasting in the presence of data drifts, highlighting the impact of\ndifferent modeling techniques and data heterogeneity. We explore\nfeature-transforming and target-transforming models, demonstrating how\nglobalization, data heterogeneity, and data drift affect each differently. In\naddition, we examine the role of globalization in peak load forecasting and its\npotential for hierarchical forecasting. To address data heterogeneity and the\nbalance between globality and locality, we propose separate time series\nclustering (TSC) methods, introducing model-based TSC for feature-transforming\nmodels and new weighted instance-based TSC for target-transforming models.\nThrough extensive experiments on a real-world dataset of Alberta's electricity\nload, we demonstrate that global target-transforming models consistently\noutperform their local counterparts, especially when enriched with global\nfeatures and clustering techniques. In contrast, global feature-transforming\nmodels face challenges in balancing local and global dynamics, often requiring\nTSC to manage data heterogeneity effectively.", "comment": "63 pages with 22 figures", "pdf_url": "http://arxiv.org/pdf/2507.11729v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "全球化在可扩展短期负荷预测中的应用", "tldr": "本文研究了如何通过全球化和交叉学习来改进短期负荷预测，解决了传统局部模型在可扩展性、泛化性、过拟合和数据漂移等方面的局限性，并提出了时间序列聚类方法来处理数据异质性。", "motivation": "传统局部负荷预测模型（LFMs）在处理泛化性、过拟合、数据漂移和冷启动问题时面临显著限制，并且随着网络规模和数据量的增长，其计算成本高昂且效率低下，缺乏可扩展性。", "method": "本文研究了在数据漂移存在下的全局负荷预测，探讨了特征转换和目标转换模型，并分析了全球化、数据异质性和数据漂移对它们的不同影响。为解决数据异质性以及全局性和局部性之间的平衡问题，提出了独立的时间序列聚类（TSC）方法，包括针对特征转换模型的基于模型的TSC和针对目标转换模型的新型加权实例TSC。", "result": "在阿尔伯塔省电力负荷的真实数据集上进行的广泛实验表明，全局目标转换模型始终优于其局部对应模型，尤其是在富含全局特征和聚类技术的情况下。相比之下，全局特征转换模型在平衡局部和全局动态方面面临挑战，通常需要TSC来有效管理数据异质性。", "conclusion": "全局目标转换模型在短期负荷预测中表现出优越性，特别是在结合全局特征和聚类技术时，能够有效应对数据异质性和数据漂移问题。而全局特征转换模型则需要时间序列聚类来更好地管理数据异质性，以平衡局部和全局动态。", "translation": "电力传输网络中的负荷预测在各个层级都至关重要，从系统层面到单个交付点（PoD）。传统的局部预测模型（LFMs）虽然直观且局部准确，但面临显著的局限性，特别是在处理泛化性、过拟合、数据漂移和冷启动问题方面。随着网络规模和数据量的增长，这些方法在可扩展性上也举步维艰，变得计算成本高昂且效率低下。相比之下，全局预测模型（GFMs）提供了一种通过全球化和交叉学习来增强预测泛化性、可扩展性、准确性和鲁棒性的新方法。本文研究了在数据漂移存在下的全局负荷预测，强调了不同建模技术和数据异质性的影响。我们探索了特征转换和目标转换模型，展示了全球化、数据异质性和数据漂移如何对它们产生不同的影响。此外，我们还考察了全球化在峰值负荷预测中的作用及其在分层预测中的潜力。为了解决数据异质性以及全局性和局部性之间的平衡问题，我们提出了独立的时间序列聚类（TSC）方法，为特征转换模型引入了基于模型的TSC，并为目标转换模型引入了新的加权实例TSC。通过在阿尔伯塔省电力负荷真实数据集上的广泛实验，我们证明了全局目标转换模型始终优于其局部对应模型，尤其是在富含全局特征和聚类技术的情况下。相比之下，全局特征转换模型在平衡局部和全局动态方面面临挑战，通常需要TSC来有效管理数据异质性。", "summary": "本文提出了一种基于全球化和交叉学习的全局预测模型（GFMs），旨在解决传统局部负荷预测模型在可扩展性、泛化性、过拟合、数据漂移和冷启动等方面的局限性。研究探讨了特征转换和目标转换模型在数据漂移和数据异质性影响下的表现，并引入了时间序列聚类（TSC）方法来有效管理数据异质性及平衡全局性和局部性。实验结果表明，全局目标转换模型，尤其是在结合全局特征和聚类技术后，显著优于局部模型，而全局特征转换模型则需要TSC来有效处理数据异质性。", "keywords": "短期负荷预测, 全局预测模型, 数据漂移, 数据异质性, 时间序列聚类", "comments": "这篇论文通过引入全局预测模型（GFMs）和时间序列聚类（TSC）方法，为短期负荷预测领域带来了创新。它解决了传统局部模型在可扩展性和泛化性方面的核心痛点，特别是在处理数据漂移和异质性方面表现出优势。其对特征转换和目标转换模型的区分研究以及对TSC的引入，为实际应用中选择合适的建模策略提供了有价值的指导。该研究的重要性在于，它为构建更鲁棒、更可扩展的电力系统负荷预测模型提供了新思路。"}}
{"id": "2506.18212", "title": "Haptic-Informed ACT with a Soft Gripper and Recovery-Informed Training for Pseudo Oocyte Manipulation", "authors": ["Pedro Miguel Uriguen Eljuri", "Hironobu Shibata", "Maeyama Katsuyoshi", "Yuanyuan Jia", "Tadahiro Taniguchi"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2025) Project website this https URL", "url": "http://arxiv.org/abs/2506.18212v3", "summary": "In this paper, we introduce Haptic-Informed ACT, an advanced robotic system\nfor pseudo oocyte manipulation, integrating multimodal information and Action\nChunking with Transformers (ACT). Traditional automation methods for oocyte\ntransfer rely heavily on visual perception, often requiring human supervision\ndue to biological variability and environmental disturbances. Haptic-Informed\nACT enhances ACT by incorporating haptic feedback, enabling real-time grasp\nfailure detection and adaptive correction. Additionally, we introduce a\n3D-printed TPU soft gripper to facilitate delicate manipulations. Experimental\nresults demonstrate that Haptic-Informed ACT improves the task success rate,\nrobustness, and adaptability compared to conventional ACT, particularly in\ndynamic environments. These findings highlight the potential of multimodal\nlearning in robotics for biomedical automation.", "comment": "Accepted at IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS2025) Project website\n  https://tanichu-laboratory.github.io/pedro_haptic_act_iros2025/", "pdf_url": "http://arxiv.org/pdf/2506.18212v3", "cate": "cs.RO", "date": "2025-06-23", "updated": "2025-07-16", "AI": {"title_translation": "基于触觉信息的ACT系统与软抓手和恢复引导训练用于伪卵母细胞操作", "tldr": "该论文介绍了一种名为Haptic-Informed ACT的机器人系统，它结合触觉反馈和软抓手，显著提高了伪卵母细胞操作的成功率、鲁棒性和适应性，克服了传统视觉方法在生物变异和环境干扰下的局限性。", "motivation": "传统的卵母细胞转移自动化方法过分依赖视觉感知，由于生物变异性和环境干扰，往往需要人工监督。为了解决这些问题，本研究旨在通过整合触觉反馈来增强机器人操作系统的性能。", "method": "本文引入了Haptic-Informed ACT系统，该系统通过结合触觉反馈来增强Action Chunking with Transformers (ACT) 模型，实现实时抓取失败检测和自适应校正。此外，还引入了一个3D打印的TPU软抓手以促进精细操作。", "result": "实验结果表明，与传统的ACT相比，Haptic-Informed ACT在任务成功率、鲁棒性和适应性方面都有所提高，特别是在动态环境中。", "conclusion": "这些发现突出了多模态学习在生物医学自动化机器人领域的潜力。", "translation": "在本文中，我们介绍了一种名为Haptic-Informed ACT的先进机器人系统，用于伪卵母细胞操作，该系统整合了多模态信息和基于Transformer的动作分块（ACT）。传统的卵母细胞转移自动化方法严重依赖视觉感知，由于生物变异性和环境干扰，往往需要人工监督。Haptic-Informed ACT通过结合触觉反馈来增强ACT，从而实现实时抓取失败检测和自适应校正。此外，我们还引入了一个3D打印的TPU软抓手以促进精细操作。实验结果表明，与传统的ACT相比，Haptic-Informed ACT在任务成功率、鲁棒性和适应性方面都有所提高，特别是在动态环境中。这些发现突出了多模态学习在生物医学自动化机器人领域的潜力。", "summary": "本文提出了一种名为Haptic-Informed ACT的机器人系统，旨在改进伪卵母细胞操作。该系统通过整合触觉反馈和Transformer动作分块（ACT）来克服传统视觉方法的局限性，并引入了3D打印的软抓手。实验证明，Haptic-Informed ACT在动态环境下显著提升了任务成功率、鲁棒性和适应性，展现了多模态学习在生物医学自动化领域的巨大潜力。", "keywords": "触觉反馈, 机器人操作, 卵母细胞, 多模态学习, 软抓手", "comments": "这项研究的创新之处在于将触觉反馈与Transformer动作分块相结合，并引入了专为精细操作设计的软抓手，有效解决了生物医学自动化中传统视觉方法的局限性。其重要性在于为卵母细胞等精细生物操作提供了更鲁棒、适应性更强的自动化解决方案，为多模态学习在机器人领域的应用开辟了新的前景。"}}
{"id": "2412.16425", "title": "Patherea: Cell Detection and Classification for the 2020s", "authors": ["Dejan Štepec", "Maja Jerše", "Snežana Đokić", "Jera Jeruc", "Nina Zidar", "Danijel Skočaj"], "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Submitted to Medical Image Analysis", "url": "http://arxiv.org/abs/2412.16425v2", "summary": "We present Patherea, a unified framework for point-based cell detection and\nclassification that enables the development and fair evaluation of\nstate-of-the-art methods. To support this, we introduce a large-scale dataset\nthat replicates the clinical workflow for Ki-67 proliferation index estimation.\nOur method directly predicts cell locations and classes without relying on\nintermediate representations. It incorporates a hybrid Hungarian matching\nstrategy for accurate point assignment and supports flexible backbones and\ntraining regimes, including recent pathology foundation models. Patherea\nachieves state-of-the-art performance on public datasets - Lizard, BRCA-M2C,\nand BCData - while highlighting performance saturation on these benchmarks. In\ncontrast, our newly proposed Patherea dataset presents a significantly more\nchallenging benchmark. Additionally, we identify and correct common errors in\ncurrent evaluation protocols and provide an updated benchmarking utility for\nstandardized assessment. The Patherea dataset and code are publicly available\nto facilitate further research and fair comparisons.", "comment": "Submitted to Medical Image Analysis", "pdf_url": "http://arxiv.org/pdf/2412.16425v2", "cate": "eess.IV", "date": "2024-12-21", "updated": "2025-07-16", "AI": {"title_translation": "Patherea：2020年代的细胞检测与分类", "tldr": "Patherea是一个用于细胞检测与分类的统一框架，通过引入大规模数据集和改进评估协议，实现了SOTA性能并提出了更具挑战性的新基准，其数据集和代码已公开。", "motivation": "当前缺乏一个统一的框架和大规模数据集来支持最先进的细胞检测与分类方法的开发和公平评估，尤其是在模拟Ki-67增殖指数估计的临床工作流程方面。", "method": "Patherea是一个统一的、基于点的细胞检测和分类框架，它直接预测细胞位置和类别，不依赖中间表示。该方法结合了混合匈牙利匹配策略以实现准确的点分配，并支持灵活的骨干网络和训练方案，包括最新的病理学基础模型。", "result": "Patherea在Lizard、BRCA-M2C和BCData等公共数据集上实现了最先进的性能，同时指出了这些基准上的性能饱和。新提出的Patherea数据集提供了一个显著更具挑战性的基准。此外，论文还识别并纠正了当前评估协议中的常见错误，并提供了一个更新的基准测试工具用于标准化评估。", "conclusion": "Patherea框架、新数据集和评估工具的公开可用性将促进细胞检测和分类领域的进一步研究和公平比较，同时解决了现有基准的局限性并提供了更具挑战性的评估环境。", "translation": "我们提出了Patherea，一个用于基于点的细胞检测和分类的统一框架，它能够支持最先进方法的开发和公平评估。为此，我们引入了一个大规模数据集，该数据集复制了Ki-67增殖指数估计的临床工作流程。我们的方法直接预测细胞位置和类别，不依赖中间表示。它结合了混合匈牙利匹配策略，用于准确的点分配，并支持灵活的骨干网络和训练方案，包括最近的病理学基础模型。Patherea在Lizard、BRCA-M2C和BCData等公共数据集上实现了最先进的性能，同时突出了这些基准上的性能饱和。相比之下，我们新提出的Patherea数据集提出了一个明显更具挑战性的基准。此外，我们识别并纠正了当前评估协议中的常见错误，并提供了一个更新的基准测试工具，用于标准化评估。Patherea数据集和代码已公开可用，以促进进一步的研究和公平比较。", "summary": "Patherea是一个创新的统一框架，专注于基于点的细胞检测和分类。该研究引入了一个大规模数据集，旨在模拟Ki-67增殖指数估计的临床工作流程，并支持对最新方法的开发和公平评估。Patherea方法直接预测细胞位置和类别，不依赖中间表示，并结合了混合匈牙利匹配策略。尽管在现有公共数据集上达到SOTA性能，但该研究也指出了这些基准的性能饱和问题。为此，Patherea提出了一个更具挑战性的新数据集，并修正了当前评估协议中的常见错误，提供了更新的标准化评估工具。Patherea数据集和代码已公开，以促进未来的研究和公平比较。", "keywords": "细胞检测, 细胞分类, 病理学图像, 大规模数据集, 基准测试", "comments": "Patherea的创新之处在于其统一的框架设计和引入了一个大规模、模拟临床工作流程的新数据集，这对于推动病理学图像分析领域具有重要意义。它不仅在现有基准上表现出色，更重要的是，它指出了当前基准的局限性并提供了更具挑战性的新基准和改进的评估协议，这有助于未来研究的公平性和准确性。其开源的数据集和代码将极大地促进社区合作和进步。"}}
{"id": "2406.14335", "title": "Linearly-Interpretable Concept Embedding Models for Text Analysis", "authors": ["Francesco De Santis", "Philippe Bich", "Gabriele Ciravegna", "Pietro Barbiero", "Danilo Giordano", "Tania Cerquitelli"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.14335v2", "summary": "Despite their success, Large-Language Models (LLMs) still face criticism due\nto their lack of interpretability. Traditional post-hoc interpretation methods,\nbased on attention and gradient-based analysis, offer limited insights as they\nonly approximate the model's decision-making processes and have been proved to\nbe unreliable. For this reason, Concept-Bottleneck Models (CBMs) have been\nlately proposed in the textual field to provide interpretable predictions based\non human-understandable concepts. However, CBMs still exhibit several\nlimitations due to their architectural constraints limiting their expressivity,\nto the absence of task-interpretability when employing non-linear task\npredictors and for requiring extensive annotations that are impractical for\nreal-world text data. In this paper, we address these challenges by proposing a\nnovel Linearly Interpretable Concept Embedding Model (LICEM) going beyond the\ncurrent accuracy-interpretability trade-off. LICEMs classification accuracy is\nbetter than existing interpretable models and matches black-box ones. We show\nthat the explanations provided by our models are more interveneable and\ncausally consistent with respect to existing solutions. Finally, we show that\nLICEMs can be trained without requiring any concept supervision, as concepts\ncan be automatically predicted when using an LLM backbone.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.14335v2", "cate": "cs.CL", "date": "2024-06-20", "updated": "2025-07-16", "AI": {"title_translation": "文本分析的线性可解释概念嵌入模型", "tldr": "本文提出了一种名为LICEM的新型可解释模型，用于文本分析，克服了CBM的局限性，提供了高准确性，并且无需概念监督即可训练。", "motivation": "大型语言模型（LLMs）缺乏可解释性，传统的后验解释方法不可靠。现有的概念瓶颈模型（CBMs）在文本领域存在多项局限性，包括架构限制、非线性预测器下的任务可解释性缺失以及需要大量不切实际的概念标注。", "method": "本文提出了一种新颖的线性可解释概念嵌入模型（LICEM）来解决现有挑战，旨在超越当前的准确性-可解释性权衡。LICEM能够在使用LLM骨干时自动预测概念，从而无需概念监督。", "result": "LICEM的分类准确性优于现有可解释模型，并与黑盒模型相匹配。其提供的解释更具可干预性和因果一致性。LICEM可以在不需要任何概念监督的情况下进行训练。", "conclusion": "LICEM为文本分析提供了一种高度准确且可解释的解决方案，克服了现有CBM和解释方法的局限性，特别是消除了对概念标注的需求。", "translation": "尽管大型语言模型（LLM）取得了成功，但由于缺乏可解释性，它们仍然面临批评。传统的基于注意力机制和梯度分析的后验解释方法提供的见解有限，因为它们仅近似于模型的决策过程，并且已被证明是不可靠的。因此，最近在文本领域提出了概念瓶颈模型（CBM），以基于人类可理解的概念提供可解释的预测。然而，CBMs仍然存在一些局限性，包括其架构限制了表达能力，在使用非线性任务预测器时缺乏任务可解释性，以及需要大量标注，这对于真实世界的文本数据来说是不切实际的。在本文中，我们通过提出一种新颖的线性可解释概念嵌入模型（LICEM）来解决这些挑战，该模型超越了当前准确性-可解释性之间的权衡。LICEM的分类准确性优于现有可解释模型，并与黑盒模型相匹配。我们表明，我们的模型提供的解释比现有解决方案更具可干预性和因果一致性。最后，我们表明LICEM可以在不需要任何概念监督的情况下进行训练，因为当使用LLM骨干时，概念可以自动预测。", "summary": "本文提出了一种名为LICEM（线性可解释概念嵌入模型）的新型模型，旨在解决大型语言模型（LLMs）的可解释性问题以及现有概念瓶颈模型（CBMs）的局限性。LICEM在分类准确性上与黑盒模型相当，同时提供了卓越的可解释性。其主要创新在于能够利用LLM骨干自动预测概念，从而无需显式的概念监督即可进行训练，使其更适用于真实世界的文本数据。", "keywords": "可解释性, 概念嵌入模型, 文本分析, 大型语言模型, 概念监督", "comments": "本文通过提出LICEM在可解释人工智能领域取得了重要进展，有效解决了长期存在的准确性-可解释性权衡问题。其能够在没有显式概念监督的情况下运行，并通过利用LLM骨干来自动预测概念的能力，是特别创新的一点，解决了CBMs面临的一个主要实际障碍，使其与实际应用高度相关。"}}
{"id": "2507.10432", "title": "Text-Visual Semantic Constrained AI-Generated Image Quality Assessment", "authors": ["Qiang Li", "Qingsen Yan", "Haojian Huang", "Peng Wu", "Haokui Zhang", "Yanning Zhang"], "categories": ["cs.CV", "I.4.7"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures, Accepted at ACMMM 2025", "url": "http://arxiv.org/abs/2507.10432v3", "summary": "With the rapid advancements in Artificial Intelligence Generated Image (AGI)\ntechnology, the accurate assessment of their quality has become an increasingly\nvital requirement. Prevailing methods typically rely on cross-modal models like\nCLIP or BLIP to evaluate text-image alignment and visual quality. However, when\napplied to AGIs, these methods encounter two primary challenges: semantic\nmisalignment and details perception missing. To address these limitations, we\npropose Text-Visual Semantic Constrained AI-Generated Image Quality Assessment\n(SC-AGIQA), a unified framework that leverages text-visual semantic constraints\nto significantly enhance the comprehensive evaluation of both text-image\nconsistency and perceptual distortion in AI-generated images. Our approach\nintegrates key capabilities from multiple models and tackles the aforementioned\nchallenges by introducing two core modules: the Text-assisted Semantic\nAlignment Module (TSAM), which leverages Multimodal Large Language Models\n(MLLMs) to bridge the semantic gap by generating an image description and\ncomparing it against the original prompt for a refined consistency check, and\nthe Frequency-domain Fine-Grained Degradation Perception Module (FFDPM), which\ndraws inspiration from Human Visual System (HVS) properties by employing\nfrequency domain analysis combined with perceptual sensitivity weighting to\nbetter quantify subtle visual distortions and enhance the capture of\nfine-grained visual quality details in images. Extensive experiments conducted\non multiple benchmark datasets demonstrate that SC-AGIQA outperforms existing\nstate-of-the-art methods. The code is publicly available at\nhttps://github.com/mozhu1/SC-AGIQA.", "comment": "9 pages, 5 figures, Accepted at ACMMM 2025", "pdf_url": "http://arxiv.org/pdf/2507.10432v3", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "文本-视觉语义约束的AI生成图像质量评估", "tldr": "本文提出了SC-AGIQA框架，利用文本-视觉语义约束来显著提高AI生成图像的质量评估，通过TSAM模块解决语义错位问题，通过FFDPM模块解决细节感知缺失问题，并超越了现有SOTA方法。", "motivation": "现有方法在评估AI生成图像（AGI）质量时，通常依赖跨模态模型（如CLIP或BLIP）来评估文本-图像对齐和视觉质量，但存在两个主要挑战：语义错位和细节感知缺失。", "method": "我们提出了文本-视觉语义约束的AI生成图像质量评估（SC-AGIQA），这是一个统一的框架，利用文本-视觉语义约束来增强AI生成图像中文本-图像一致性和感知失真的综合评估。该方法集成了多个模型的关键能力，并通过引入两个核心模块来解决上述挑战：1. 文本辅助语义对齐模块（TSAM）：利用多模态大型语言模型（MLLMs）生成图像描述并与原始提示进行比较，以弥补语义鸿沟并进行更精细的一致性检查。2. 频域细粒度退化感知模块（FFDPM）：受人类视觉系统（HVS）特性的启发，采用频域分析结合感知敏感度加权，以更好地量化细微视觉失真并增强对图像中细粒度视觉质量细节的捕获。", "result": "在多个基准数据集上进行的广泛实验表明，SC-AGIQA优于现有最先进的方法。", "conclusion": "SC-AGIQA框架通过引入文本-视觉语义约束和专门设计的模块（TSAM和FFDPM），有效地解决了AI生成图像质量评估中的语义错位和细节感知缺失问题，显著提升了评估的准确性和全面性，并取得了超越现有最先进方法的性能。", "translation": "随着人工智能生成图像（AGI）技术的快速发展，对其质量的准确评估已成为一项日益重要的需求。现有方法通常依赖于CLIP或BLIP等跨模态模型来评估文本-图像对齐和视觉质量。然而，当应用于AGI时，这些方法面临两个主要挑战：语义错位和细节感知缺失。为了解决这些限制，我们提出了文本-视觉语义约束的AI生成图像质量评估（SC-AGIQA），这是一个统一的框架，利用文本-视觉语义约束来显著增强AI生成图像中文本-图像一致性和感知失真的综合评估。我们的方法整合了多个模型的关键能力，并通过引入两个核心模块来解决上述挑战：文本辅助语义对齐模块（TSAM），它利用多模态大型语言模型（MLLMs）通过生成图像描述并与原始提示进行比较来弥补语义鸿沟，从而实现更精细的一致性检查；以及频域细粒度退化感知模块（FFDPM），它受人类视觉系统（HVS）特性的启发，采用频域分析结合感知敏感度加权，以更好地量化细微视觉失真并增强对图像中细粒度视觉质量细节的捕获。在多个基准数据集上进行的广泛实验表明，SC-AGIQA优于现有最先进的方法。代码已在https://github.com/mozhu1/SC-AGIQA公开。", "summary": "本文提出了SC-AGIQA，一个用于AI生成图像质量评估的统一框架，旨在解决现有跨模态方法中存在的语义错位和细节感知缺失问题。SC-AGIQA通过文本辅助语义对齐模块（TSAM）利用多模态大语言模型进行精细的文本-图像一致性检查，并通过频域细粒度退化感知模块（FFDPM）结合频域分析和感知敏感度加权来捕捉细微的视觉失真。实验结果表明，SC-AGIQA在多个基准数据集上均优于现有最先进的方法。", "keywords": "AI生成图像, 质量评估, 语义约束, 多模态模型, 频域分析", "comments": "该论文的创新之处在于其统一的框架SC-AGIQA，它针对AI生成图像质量评估中的具体挑战（语义错位和细节感知缺失）提出了新颖的解决方案。通过结合多模态大语言模型（MLLMs）进行语义对齐和借鉴人类视觉系统（HVS）原理进行细粒度感知，该方法有效地提升了评估的准确性和全面性。其重要性在于为快速发展的AI生成图像技术提供了一种更可靠、更先进的质量评估工具。"}}
{"id": "2507.11970", "title": "Obfuscation of Unitary Quantum Programs", "authors": ["Mi-Ying Huang", "Er-Cheng Tang"], "categories": ["quant-ph", "cs.CR"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11970v1", "summary": "Program obfuscation aims to hide the inner workings of a program while\npreserving its functionality. In the quantum setting, recent works have\nobtained obfuscation schemes for specialized classes of quantum circuits. For\ninstance, Bartusek, Brakerski, and Vaikuntanathan (STOC 2024) constructed a\nquantum state obfuscation scheme, which supports the obfuscation of quantum\nprograms represented as quantum states for pseudo-deterministic quantum\nprograms with classical inputs and outputs in the classical oracle model.\n  In this work, we improve upon existing results by constructing the first\nquantum state obfuscation scheme for unitary (or approximately unitary) quantum\nprograms supporting quantum inputs and outputs in the classical oracle model.\nAt the core of our obfuscation scheme are two novel ingredients: a functional\nquantum authentication scheme that allows key holders to learn specific\nfunctions of the authenticated quantum state with simulation-based security,\nand a compiler that represents an arbitrary quantum circuit as a projective\nlinear-plus-measurement quantum program described by a sequence of non-adaptive\nClifford gates interleaved with adaptive and compatible measurements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11970v1", "cate": "quant-ph", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "量子酉程序的混淆", "tldr": "本文构建了第一个支持量子输入和输出的酉（或近似酉）量子程序的量子态混淆方案，并提出了两种新的核心技术：功能量子认证方案和编译器。", "motivation": "现有的量子程序混淆方案仅支持特定类的量子电路，例如伪确定性量子程序，且通常仅限于经典输入和输出。本文旨在改进现有成果，构建支持量子输入和输出的酉量子程序的混淆方案。", "method": "本文构建了一个新的量子态混淆方案，其核心包含两个新颖的组成部分：1) 一个功能量子认证方案，允许密钥持有者以基于模拟的安全性学习经认证的量子态的特定功能。2) 一个编译器，将任意量子电路表示为投影线性加测量量子程序，该程序由一系列非自适应Clifford门与自适应和兼容测量交织描述。", "result": "首次构建了针对酉（或近似酉）量子程序且支持量子输入和输出的量子态混淆方案，并在经典预言机模型中实现。", "conclusion": "本文成功构建了首个支持量子输入和输出的酉量子程序的量子态混淆方案，通过引入功能量子认证方案和编译器，显著扩展了量子程序混淆的能力。", "translation": "程序混淆旨在隐藏程序的内部工作原理，同时保持其功能。在量子环境中，最近的工作已经获得了针对特定类量子电路的混淆方案。例如，Bartusek、Brakerski和Vaikuntanathan (STOC 2024) 构建了一个量子态混淆方案，该方案支持在经典预言机模型中，将伪确定性量子程序表示为量子态的量子程序混淆，这些程序具有经典输入和输出。\n在这项工作中，我们通过构建第一个支持量子输入和输出的酉（或近似酉）量子程序的量子态混淆方案，改进了现有结果。我们提出的混淆方案的核心是两种新颖的组成部分：一种功能量子认证方案，允许密钥持有者以基于模拟的安全性学习经认证的量子态的特定功能；以及一个编译器，将任意量子电路表示为投影线性加测量量子程序，该程序由一系列非自适应Clifford门与自适应和兼容测量交织描述。", "summary": "本文提出了首个针对酉（或近似酉）量子程序且支持量子输入和输出的量子态混淆方案，以改进现有仅支持特定类量子电路和经典输入输出的方案。该方案的核心在于引入了两种新颖技术：一个功能量子认证方案和一个将任意量子电路转换为投影线性加测量量子程序的编译器。", "keywords": "量子程序混淆, 酉量子程序, 量子态混淆, 量子认证, 量子电路编译", "comments": "这项工作在量子程序混淆领域取得了重要进展，首次实现了对支持量子输入和输出的酉量子程序的混淆。其创新点在于提出的功能量子认证方案和编译器，这些技术为更广泛的量子程序混淆奠定了基础，具有重要的理论和潜在应用价值。"}}
{"id": "2507.12298", "title": "TrialCompass: Visual Analytics for Enhancing the Eligibility Criteria Design of Clinical Trials", "authors": ["Rui Sheng", "Xingbo Wang", "Jiachen Wang", "Xiaofu Jin", "Zhonghua Sheng", "Zhenxing Xu", "Suraj Rajendran", "Huamin Qu", "Fei Wang"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12298v1", "summary": "Eligibility criteria play a critical role in clinical trials by determining\nthe target patient population, which significantly influences the outcomes of\nmedical interventions. However, current approaches for designing eligibility\ncriteria have limitations to support interactive exploration of the large space\nof eligibility criteria. They also ignore incorporating detailed\ncharacteristics from the original electronic health record (EHR) data for\ncriteria refinement. To address these limitations, we proposed TrialCompass, a\nvisual analytics system integrating a novel workflow, which can empower\nclinicians to iteratively explore the vast space of eligibility criteria\nthrough knowledge-driven and outcome-driven approaches. TrialCompass supports\nhistory-tracking to help clinicians trace the evolution of their adjustments\nand decisions when exploring various forms of data (i.e., eligibility criteria,\noutcome metrics, and detailed characteristics of original EHR data) through\nthese two approaches. This feature can help clinicians comprehend the impact of\neligibility criteria on outcome metrics and patient characteristics, which\nfacilitates systematic refinement of eligibility criteria. Using a real-world\ndataset, we demonstrated the effectiveness of TrialCompass in providing\ninsights into designing eligibility criteria for septic shock and\nsepsis-associated acute kidney injury. We also discussed the research prospects\nof applying visual analytics to clinical trials.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12298v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "TrialCompass：用于增强临床试验资格标准设计的可视化分析", "tldr": "TrialCompass是一个可视化分析系统，旨在帮助临床医生通过交互式探索和历史追踪，利用电子健康记录数据，更有效地设计和优化临床试验的资格标准。", "motivation": "当前临床试验的资格标准设计方法存在局限性，无法支持对庞大标准空间的交互式探索，并且忽视了纳入详细的电子健康记录（EHR）数据进行细化，这影响了目标患者群体的确定和医疗干预结果。", "method": "我们提出了TrialCompass，一个整合了新颖工作流程的可视化分析系统。该系统通过知识驱动和结果驱动的方法，赋能临床医生迭代探索资格标准空间，并支持历史追踪，以帮助他们理解资格标准对结果指标和患者特征的影响，从而系统地细化标准。", "result": "我们使用真实世界数据集，证明了TrialCompass在为感染性休克和脓毒症相关急性肾损伤设计资格标准方面提供了有效见解。研究还讨论了将可视化分析应用于临床试验的研究前景。", "conclusion": "TrialCompass系统能够有效帮助临床医生设计和优化临床试验的资格标准，通过可视化分析和历史追踪，提高标准的准确性和相关性，并展望了可视化分析在临床试验中的应用潜力。", "translation": "资格标准在临床试验中起着关键作用，它们决定了目标患者群体，这显著影响医疗干预的结果。然而，当前设计资格标准的方法在支持对庞大资格标准空间的交互式探索方面存在局限性。它们也忽视了纳入原始电子健康记录（EHR）数据中的详细特征以进行标准细化。为了解决这些局限性，我们提出了TrialCompass，一个整合了新颖工作流程的可视化分析系统，它可以使临床医生通过知识驱动和结果驱动的方法迭代地探索庞大的资格标准空间。TrialCompass支持历史追踪，帮助临床医生在通过这两种方法探索各种形式的数据（即资格标准、结果指标和原始EHR数据的详细特征）时，追踪其调整和决策的演变。此功能可以帮助临床医生理解资格标准对结果指标和患者特征的影响，从而促进资格标准的系统性细化。我们使用真实世界数据集，证明了TrialCompass在为感染性休克和脓毒症相关急性肾损伤设计资格标准方面提供见解的有效性。我们还讨论了将可视化分析应用于临床试验的研究前景。", "summary": "本论文介绍了TrialCompass，一个旨在解决当前临床试验资格标准设计局限性的可视化分析系统。该系统通过整合新颖的工作流程，使临床医生能够利用知识驱动和结果驱动的方法，交互式地探索庞大的资格标准空间，并纳入详细的电子健康记录（EHR）数据。TrialCompass还提供历史追踪功能，帮助临床医生理解资格标准调整对患者结果和特征的影响，从而促进标准的系统性细化。通过真实世界数据集的验证，该系统在为感染性休克等疾病设计资格标准方面展现出有效性。", "keywords": "资格标准, 临床试验, 可视化分析, EHR数据, TrialCompass", "comments": "TrialCompass的创新之处在于其将可视化分析与新颖的工作流程和历史追踪功能相结合，专门用于临床试验资格标准的复杂设计与优化，并有效整合了电子健康记录（EHR）数据。这显著提升了临床研究中患者群体确定的互动性、数据驱动性和透明度，有望提高试验结果的可靠性和相关性。"}}
{"id": "2507.11809", "title": "Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models", "authors": ["Dante Campregher", "Yanxu Chen", "Sander Hoffman", "Maria Heuss"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      18 Pages, 13 figures", "url": "http://arxiv.org/abs/2507.11809v1", "summary": "This paper presents a reproducibility study examining how Large Language\nModels (LLMs) manage competing factual and counterfactual information, focusing\non the role of attention heads in this process. We attempt to reproduce and\nreconcile findings from three recent studies by Ortu et al., Yu, Merullo, and\nPavlick and McDougall et al. that investigate the competition between\nmodel-learned facts and contradictory context information through Mechanistic\nInterpretability tools. Our study specifically examines the relationship\nbetween attention head strength and factual output ratios, evaluates competing\nhypotheses about attention heads' suppression mechanisms, and investigates the\ndomain specificity of these attention patterns. Our findings suggest that\nattention heads promoting factual output do so via general copy suppression\nrather than selective counterfactual suppression, as strengthening them can\nalso inhibit correct facts. Additionally, we show that attention head behavior\nis domain-dependent, with larger models exhibiting more specialized and\ncategory-sensitive patterns.", "comment": "18 Pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.11809v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "追踪事实还是仅仅复制？对大型语言模型中机制竞争的批判性研究", "tldr": "本研究通过可解释性工具，对大型语言模型中注意力头如何处理事实与反事实信息竞争进行了再现性研究，发现注意力头通过通用复制抑制而非选择性反事实抑制来促进事实输出，且其行为具有领域依赖性。", "motivation": "本研究旨在再现并调和Ortu等人、Yu、Merullo和Pavlick以及McDougall等人三项近期研究的发现，这些研究通过机械可解释性工具调查了模型学习到的事实与矛盾上下文信息之间的竞争，以理解大型语言模型如何管理竞争性的事实和反事实信息，并探究注意力头在此过程中的作用。", "method": "本研究是一项再现性研究，通过机械可解释性工具，检查注意力头强度与事实输出比率之间的关系，评估关于注意力头抑制机制的竞争性假设，并调查这些注意力模式的领域特异性。", "result": "研究发现，促进事实输出的注意力头通过通用复制抑制而非选择性反事实抑制来发挥作用，因为增强它们也可能抑制正确的事实。此外，注意力头的行为是领域依赖的，较大的模型表现出更专业化和类别敏感的模式。", "conclusion": "注意力头促进事实输出的机制是通用复制抑制，而非选择性反事实抑制，且其行为模式具有领域依赖性，大型模型在这方面表现出更高的专业化程度。", "translation": "本文提出了一项再现性研究，旨在检验大型语言模型（LLMs）如何管理竞争性的事实和反事实信息，重点关注注意力头在此过程中的作用。我们试图再现并调和Ortu等人、Yu、Merullo和Pavlick以及McDougall等人三项近期研究的发现，这些研究通过机械可解释性工具调查了模型学习到的事实与矛盾上下文信息之间的竞争。我们的研究专门检查了注意力头强度与事实输出比率之间的关系，评估了关于注意力头抑制机制的竞争性假设，并调查了这些注意力模式的领域特异性。我们的发现表明，促进事实输出的注意力头通过通用复制抑制而非选择性反事实抑制来发挥作用，因为增强它们也可能抑制正确的事实。此外，我们显示注意力头的行为是领域依赖的，较大的模型表现出更专业化和类别敏感的模式。", "summary": "本研究是一项再现性研究，旨在深入探究大型语言模型（LLMs）中注意力头如何处理事实与反事实信息的竞争。通过对现有研究的再现和整合，本研究发现，促进事实输出的注意力头主要通过通用复制抑制机制工作，而非选择性反事实抑制，且这种行为模式具有领域依赖性，大型模型展现出更强的专业化和类别敏感性。", "keywords": "大型语言模型, 注意力头, 机械可解释性, 事实性, 再现性研究", "comments": "这项研究的创新之处在于它对LLM中注意力头的工作机制提供了新的视角，特别是区分了通用复制抑制和选择性反事实抑制。其再现性研究的方法加强了对现有发现的验证，并揭示了注意力行为的领域依赖性，这对于理解和改进LLM的事实性输出具有重要意义。"}}
{"id": "2507.12090", "title": "MambaRate: Speech Quality Assessment Across Different Sampling Rates", "authors": ["Panos Kakoulidis", "Iakovi Alexiou", "Junkwang Oh", "Gunu Jho", "Inchul Hwang", "Pirros Tsiakoulis", "Aimilios Chalamandaris"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Submitted to ASRU 2025 (AudioMOS Challenge 2025 Track 3)", "url": "http://arxiv.org/abs/2507.12090v1", "summary": "We propose MambaRate, which predicts Mean Opinion Scores (MOS) with limited\nbias regarding the sampling rate of the waveform under evaluation. It is\ndesigned for Track 3 of the AudioMOS Challenge 2025, which focuses on\npredicting MOS for speech in high sampling frequencies. Our model leverages\nself-supervised embeddings and selective state space modeling. The target\nratings are encoded in a continuous representation via Gaussian radial basis\nfunctions (RBF). The results of the challenge were based on the system-level\nSpearman's Rank Correllation Coefficient (SRCC) metric. An initial MambaRate\nversion (T16 system) outperformed the pre-trained baseline (B03) by ~14% in a\nfew-shot setting without pre-training. T16 ranked fourth out of five in the\nchallenge, differing by ~6% from the winning system. We present additional\nresults on the BVCC dataset as well as ablations with different representations\nas input, which outperform the initial T16 version.", "comment": "Submitted to ASRU 2025 (AudioMOS Challenge 2025 Track 3)", "pdf_url": "http://arxiv.org/pdf/2507.12090v1", "cate": "cs.SD", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MambaRate：跨采样率语音质量评估", "tldr": "MambaRate是一种语音质量评估模型，旨在预测不同采样率下的平均意见分数（MOS），并在AudioMOS 2025挑战赛中表现良好，优于基线模型。", "motivation": "该研究旨在开发一种能够预测平均意见分数（MOS）且对不同采样率的波形偏差有限的模型，以应对AudioMOS 2025挑战赛第三赛道中预测高采样频率语音MOS的需求。", "method": "MambaRate模型利用自监督嵌入和选择性状态空间建模。目标评分通过高斯径向基函数（RBF）编码为连续表示。", "result": "MambaRate的初始版本（T16系统）在少量样本设置下，未经预训练，比预训练基线（B03）表现优异约14%。在挑战赛中，T16在五个系统中排名第四，与获胜系统相差约6%。作者还在BVCC数据集上提供了额外结果以及不同输入表示的消融实验，这些实验的表现优于最初的T16版本。", "conclusion": "MambaRate在语音质量评估方面表现出有效性，尤其是在处理不同采样率方面。尽管在AudioMOS挑战赛中未能夺冠，但其在无预训练情况下的表现优于基线，且后续改进版本展现出进一步的性能提升潜力。", "translation": "我们提出了MambaRate，它在评估波形的采样率方面具有有限的偏差，能够预测平均意见分数（MOS）。它专为AudioMOS 2025挑战赛的第三赛道设计，该赛道专注于预测高采样频率语音的MOS。我们的模型利用自监督嵌入和选择性状态空间建模。目标评分通过高斯径向基函数（RBF）编码为连续表示。挑战赛的结果基于系统级Spearman秩相关系数（SRCC）指标。MambaRate的初始版本（T16系统）在少量样本设置下，未经预训练，比预训练基线（B03）表现优异约14%。T16在挑战赛中排名第五中的第四，与获胜系统相差约6%。我们还在BVCC数据集上提供了额外结果以及不同输入表示的消融实验，这些实验的表现优于最初的T16版本。", "summary": "MambaRate是一个为AudioMOS 2025挑战赛设计的语音质量评估模型，旨在预测跨不同采样率的MOS。它采用自监督嵌入和选择性状态空间建模，并将目标评分编码为连续表示。该模型的初始版本（T16）在少量样本设置下比基线模型表现更好，尽管在挑战赛中排名第四。后续的消融实验和在BVCC数据集上的测试表明，通过改进输入表示，模型性能可以进一步提升。", "keywords": "语音质量评估, 平均意见分数, 采样率, 自监督嵌入, 状态空间模型", "comments": "MambaRate的创新之处在于其结合了自监督嵌入和选择性状态空间建模来解决跨采样率的语音质量评估问题。在未预训练的情况下，其在少量样本设置中显著优于预训练基线，这显示了其强大的潜力。然而，在挑战赛中未能进入前三，表明仍有提升空间。后续的消融实验和对不同输入表示的探索为其未来的发展指明了方向，具有重要的研究价值。"}}
{"id": "2311.05128", "title": "Exploring and Analyzing Wildland Fire Data Via Machine Learning Techniques", "authors": ["Dipak Dulal", "Joseph J. Charney", "Michael Gallagher", "Carmeliza Navasca", "Nicholas Skowronski"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This version has been significantly updated and superseded by a more complete and revised version under the new title \"Leveraging Advanced Machine Learning to Predict Turbulence Dynamics from Temperature Observations at an Experimental Prescribed Fire\", available at arXiv ID: arXiv:2507.11012", "url": "http://arxiv.org/abs/2311.05128v2", "summary": "This research project investigated the correlation between a 10 Hz time\nseries of thermocouple temperatures and turbulent kinetic energy (TKE) computed\nfrom wind speeds collected from a small experimental prescribed burn at the\nSilas Little Experimental Forest in New Jersey, USA. The primary objective of\nthis project was to explore the potential for using thermocouple temperatures\nas predictors for estimating the TKE produced by a wildland fire. Machine\nlearning models, including Deep Neural Networks, Random Forest Regressor,\nGradient Boosting, and Gaussian Process Regressor, are employed to assess the\npotential for thermocouple temperature perturbations to predict TKE values.\nData visualization and correlation analyses reveal patterns and relationships\nbetween thermocouple temperatures and TKE, providing insight into the\nunderlying dynamics. The project achieves high accuracy in predicting TKE by\nemploying various machine learning models despite a weak correlation between\nthe predictors and the target variable. The results demonstrate significant\nsuccess, particularly from regression models, in accurately estimating the TKE.\nThe research findings contribute to fire behavior and smoke modeling science,\nemphasizing the importance of incorporating machine learning approaches and\nidentifying complex relationships between fine-scale fire behavior and\nturbulence. Accurate TKE estimation using thermocouple temperatures allows for\nthe refinement of models that can inform decision-making in fire management\nstrategies, facilitate effective risk mitigation, and optimize fire management\nefforts. This project highlights the valuable role of machine learning\ntechniques in analyzing wildland fire data, showcasing their potential to\nadvance fire research and management practices.", "comment": "This version has been significantly updated and superseded by a more\n  complete and revised version under the new title \"Leveraging Advanced Machine\n  Learning to Predict Turbulence Dynamics from Temperature Observations at an\n  Experimental Prescribed Fire\", available at arXiv ID: arXiv:2507.11012", "pdf_url": "http://arxiv.org/pdf/2311.05128v2", "cate": "cs.LG", "date": "2023-11-09", "updated": "2025-07-16", "AI": {"title_translation": "通过机器学习技术探索和分析野火数据", "tldr": "该研究利用机器学习模型，通过热电偶温度成功预测了野火产生的湍流动能（TKE），即使预测因子与目标变量之间存在弱相关性。", "motivation": "该项目的主要目标是探索使用热电偶温度作为预测因子来估计野火产生的湍流动能（TKE）的潜力，以期改进火灾行为和烟雾建模，并为火灾管理策略提供信息。", "method": "研究调查了10 Hz热电偶温度时间序列与从新泽西州Silas Little实验林的小型实验性计划烧除中收集的风速计算出的湍流动能（TKE）之间的相关性。采用了包括深度神经网络、随机森林回归器、梯度提升和高斯过程回归器在内的机器学习模型来评估热电偶温度扰动预测TKE值的潜力。同时进行了数据可视化和相关性分析。", "result": "尽管预测因子与目标变量之间存在弱相关性，但该项目在预测TKE方面取得了高精度。结果表明，特别是回归模型在准确估计TKE方面取得了显著成功。", "conclusion": "研究结果有助于火灾行为和烟雾建模科学，强调了结合机器学习方法和识别精细尺度火灾行为与湍流之间复杂关系的重要性。使用热电偶温度准确估计TKE可以改进模型，从而为火灾管理策略中的决策提供信息，促进有效的风险缓解，并优化火灾管理工作。该项目突出了机器学习技术在分析野火数据方面的宝贵作用。", "translation": "这项研究项目调查了在新泽西州西拉斯·利特尔实验林的一次小型实验性计划烧除中，10赫兹热电偶温度时间序列与根据风速计算出的湍流动能（TKE）之间的相关性。该项目的主要目标是探索利用热电偶温度作为预测因子来估计野火产生的TKE的潜力。研究采用了包括深度神经网络、随机森林回归器、梯度提升和高斯过程回归器在内的机器学习模型，以评估热电偶温度扰动预测TKE值的潜力。数据可视化和相关性分析揭示了热电偶温度与TKE之间的模式和关系，为底层动力学提供了洞察。尽管预测因子与目标变量之间存在弱相关性，但该项目通过采用各种机器学习模型，在预测TKE方面取得了高精度。结果表明，特别是回归模型在准确估计TKE方面取得了显著成功。研究发现有助于火灾行为和烟雾建模科学，强调了结合机器学习方法和识别精细尺度火灾行为与湍流之间复杂关系的重要性。使用热电偶温度准确估计TKE可以改进模型，从而为火灾管理策略中的决策提供信息，促进有效的风险缓解，并优化火灾管理工作。该项目突出了机器学习技术在分析野火数据方面的宝贵作用，展示了它们在推进火灾研究和管理实践方面的潜力。", "summary": "本研究旨在使用机器学习技术，通过热电偶温度预测野火产生的湍流动能（TKE）。研究分析了热电偶温度与TKE之间的相关性，并应用了多种机器学习模型（如深度神经网络、随机森林等）进行预测。尽管预测因子与目标变量相关性较弱，模型仍实现了高精度预测，特别是回归模型表现出色。这为火灾行为和烟雾建模提供了新见解，并有助于改进火灾管理策略。", "keywords": "野火数据, 机器学习, 湍流动能, 热电偶温度, 火灾管理", "comments": "这项研究的创新之处在于，它成功地利用机器学习模型在预测因子和目标变量之间存在弱相关性的情况下，实现了对野火湍流动能（TKE）的高精度预测。这克服了传统方法可能面临的挑战，并突出了机器学习在处理复杂、非线性关系方面的强大能力。其重要性在于，准确的TKE估计对于改进火灾行为和烟雾模型至关重要，从而能更有效地指导火灾管理决策、风险缓解和资源优化，具有显著的实际应用价值。"}}
{"id": "2410.11647", "title": "Measuring Spiritual Values and Bias of Large Language Models", "authors": ["Songyuan Liu", "Ziyang Zhang", "Runze Yan", "Wei Wu", "Carl Yang", "Jiaying Lu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages including appendix; 5 figures; 5 tables", "url": "http://arxiv.org/abs/2410.11647v2", "summary": "Large language models (LLMs) have become integral tool for users from various\nbackgrounds. LLMs, trained on vast corpora, reflect the linguistic and cultural\nnuances embedded in their pre-training data. However, the values and\nperspectives inherent in this data can influence the behavior of LLMs, leading\nto potential biases. As a result, the use of LLMs in contexts involving\nspiritual or moral values necessitates careful consideration of these\nunderlying biases. Our work starts with verification of our hypothesis by\ntesting the spiritual values of popular LLMs. Experimental results show that\nLLMs' spiritual values are quite diverse, as opposed to the stereotype of\natheists or secularists. We then investigate how different spiritual values\naffect LLMs in social-fairness scenarios e.g., hate speech identification). Our\nfindings reveal that different spiritual values indeed lead to different\nsensitivity to different hate target groups. Furthermore, we propose to\ncontinue pre-training LLMs on spiritual texts, and empirical results\ndemonstrate the effectiveness of this approach in mitigating spiritual bias.", "comment": "9 pages including appendix; 5 figures; 5 tables", "pdf_url": "http://arxiv.org/pdf/2410.11647v2", "cate": "cs.CL", "date": "2024-10-15", "updated": "2025-07-16", "AI": {"title_translation": "测量大型语言模型的精神价值观与偏见", "tldr": "大型语言模型（LLMs）具有多样化的精神价值观，这会影响它们在社会公平任务中的行为，例如仇恨言论识别。在精神文本上进行微调可以有效缓解这种偏见。", "motivation": "大型语言模型（LLMs）在训练过程中吸收了数据中的价值观和观点，可能导致偏见，尤其是在涉及精神或道德价值观的场景中。因此，有必要仔细考虑这些潜在偏见。本文旨在验证LLMs是否具有精神价值观，并研究其影响。", "method": "首先，通过测试流行LLMs的精神价值观来验证假设。其次，调查不同精神价值观如何影响LLMs在社会公平场景（如仇恨言论识别）中的表现。最后，提出并在精神文本上继续预训练LLMs的方法，并通过实证结果验证其在缓解精神偏见方面的有效性。", "result": "实验结果表明，LLMs的精神价值观相当多样化，与无神论者或世俗主义者的刻板印象相反。研究发现，不同的精神价值观确实会导致LLMs对不同仇恨目标群体有不同的敏感度。此外，继续在精神文本上预训练LLMs的方法被证明在缓解精神偏见方面是有效的。", "conclusion": "本文证实了大型语言模型（LLMs）拥有多样化的精神价值观，这些价值观会影响它们在社会公平任务中的行为。研究还提出并验证了通过在精神文本上继续预训练LLMs可以有效缓解这种精神偏见。", "translation": "大型语言模型（LLMs）已成为各种背景用户不可或缺的工具。LLMs在海量语料库上训练，反映了其预训练数据中嵌入的语言和文化细微差别。然而，这些数据中固有的价值观和观点会影响LLMs的行为，导致潜在的偏见。因此，在涉及精神或道德价值观的场景中使用LLMs时，需要仔细考虑这些潜在偏见。我们的工作首先通过测试流行LLMs的精神价值观来验证我们的假设。实验结果表明，LLMs的精神价值观相当多样化，与无神论者或世俗主义的刻板印象相反。然后，我们调查了不同的精神价值观如何影响LLMs在社会公平场景（例如，仇恨言论识别）中的表现。我们的发现表明，不同的精神价值观确实会导致对不同仇恨目标群体有不同的敏感度。此外，我们建议继续在精神文本上预训练LLMs，实证结果表明这种方法在缓解精神偏见方面的有效性。", "summary": "本文探讨了大型语言模型（LLMs）的精神价值观及其偏见。研究首先验证了LLMs具有多样化的精神价值观，这与普遍的刻板印象不同。研究发现，这些不同的精神价值观会影响LLMs在社会公平任务（如仇恨言论识别）中的表现，导致对不同仇恨目标群体表现出不同的敏感度。此外，论文提出并证明了在精神文本上继续预训练LLMs是缓解精神偏见的有效方法。", "keywords": "大型语言模型, 精神价值观, 偏见缓解, 仇恨言论, 社会公平", "comments": "这篇论文解决了LLM偏见中一个新颖且重要的方面：精神价值观。它超越了常见的人口统计偏见，深入探讨了训练数据中根深蒂固的信仰体系如何在LLM行为中表现出来。发现LLMs具有多样化的精神价值观以及这如何影响公平性具有重要意义。提出的通过在精神文本上继续预训练来缓解偏见的策略提供了一个实用的解决方案，强调了通过有针对性的数据增强来解决特定偏见的潜力。"}}
{"id": "2507.12400", "title": "Modeling Feasible Locomotion of Nanobots for Cancer Detection and Treatment", "authors": ["Noble Harasha", "Cristina Gava", "Nancy Lynch", "Claudia Contini", "Frederik Mallmann-Trenn"], "categories": ["cs.MA", "cs.DM"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12400v1", "summary": "Deploying motile nanosized particles, also known as ``nanobots'', in the\nhuman body promises to improve selectivity in drug delivery and reduce side\neffects. We consider a swarm of nanobots locating a single cancerous region and\ntreating it by releasing an onboard payload of drugs at the site. At nanoscale,\nthe computation, communication, sensing, and locomotion capabilities of\nindividual agents are extremely limited, noisy, and/or nonexistent.\n  We present a general model to formally describe the individual and collective\nbehavior of agents in a colloidal environment, such as the bloodstream, for\ncancer detection and treatment by nanobots. This includes a feasible and\nprecise model of agent locomotion, inspired by actual nanoparticles that, in\nthe presence of an external chemical gradient, move towards areas of higher\nconcentration by means of self-propulsion. We present two variants of our\ngeneral model: The first assumes an endogenous chemical gradient that is fixed\nover time and centered at the targeted cancer site; the second is a more\nspeculative and dynamic variant in which agents themselves create and amplify a\nchemical gradient centered at the cancer site. In both settings, agents can\nsense the gradient and ascend it noisily, locating the cancer site more quickly\nthan via simple Brownian motion.\n  For the first variant of the model, we present simulation results to show the\nbehavior of agents under our locomotion model, as well as {analytical results}\nto bound the time it takes for the agents to reach the cancer site. For the\nsecond variant, simulation results highlight the collective benefit in having\nagents issue their own chemical signal. While arguably more speculative in its\nagent capability assumptions, this variant shows a significant improvement in\nruntime performance over the first variant, resulting from its chemical signal\namplification mechanism.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12400v1", "cate": "cs.MA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "癌症检测与治疗中纳米机器人可行性运动建模", "tldr": "该研究提出了一个通用模型，用于描述纳米机器人在胶体环境中（如血液）的个体和集体行为，以检测和治疗癌症，并探讨了两种化学梯度引导的运动变体。", "motivation": "在人体内部署纳米机器人有望提高药物递送的选择性并减少副作用。然而，纳米尺度下智能体的计算、通信、传感和运动能力极其有限、嘈杂或不存在，这促使研究人员需要一个可行且精确的纳米机器人运动模型。", "method": "提出一个通用模型来形式化描述纳米机器人在胶体环境中的个体和集体行为。该模型包含一个受真实纳米颗粒启发的、可行且精确的运动模型，即在外部化学梯度存在下通过自推进移向高浓度区域。模型包含两个变体：1. 固定内源性化学梯度，以目标癌细胞为中心。2. 动态变体，纳米机器人自身创建并放大以癌细胞为中心的化学梯度。通过模拟和分析结果来评估模型性能。", "result": "对于第一个模型变体，模拟结果展示了在所提出的运动模型下纳米机器人的行为，分析结果给出了纳米机器人到达癌细胞所需时间的上限。对于第二个模型变体，模拟结果突出了纳米机器人发出自身化学信号的集体益处，并显示出比第一个变体显著的运行时性能提升，这归因于其化学信号放大机制。", "conclusion": "该研究成功地为纳米机器人在癌症检测和治疗中的可行运动建立了模型，并展示了两种化学梯度引导机制的有效性，特别是纳米机器人自身生成和放大化学信号的机制，能显著提高到达癌细胞的速度。", "translation": "在人体内部署可移动的纳米级粒子，也称为“纳米机器人”，有望提高药物递送的选择性并减少副作用。我们考虑一群纳米机器人定位单个癌变区域并通过在该部位释放搭载的药物来治疗它。在纳米尺度上，单个智能体的计算、通信、传感和运动能力极其有限、嘈杂和/或不存在。 我们提出了一个通用模型，以正式描述纳米机器人在胶体环境（如血液）中用于癌症检测和治疗的个体和集体行为。这包括一个可行且精确的智能体运动模型，其灵感来源于真实的纳米颗粒，这些纳米颗粒在外部化学梯度存在下通过自推进向高浓度区域移动。我们提出了通用模型的两种变体：第一种假设存在一个随时间固定且以目标癌细胞为中心的内源性化学梯度；第二种是一种更具推测性和动态性的变体，其中智能体自身创建并放大以癌细胞为中心的化学梯度。在这两种设置中，智能体都能感知梯度并嘈杂地向上攀升，比简单的布朗运动更快地定位癌细胞。 对于模型的第一种变体，我们展示了模拟结果以显示智能体在我们的运动模型下的行为，以及分析结果以限制智能体到达癌细胞所需的时间。对于第二种变体，模拟结果突出了智能体发出自身化学信号的集体益处。尽管其智能体能力假设更具推测性，但这种变体显示出比第一种变体显著的运行时性能提升，这源于其化学信号放大机制。", "summary": "这篇论文提出了一种用于癌症检测和治疗的纳米机器人通用运动模型，旨在解决纳米尺度下计算、通信和运动能力的限制。该模型借鉴了真实纳米颗粒的趋化性，设计了两种化学梯度引导的运动变体：一种是基于固定内源性梯度，另一种是纳米机器人自身生成并放大化学梯度。模拟和分析结果表明，这两种方法都能使纳米机器人比布朗运动更快地定位癌细胞，尤其是第二种变体，因其化学信号放大机制，在性能上表现出显著优势。", "keywords": "纳米机器人, 癌症检测, 癌症治疗, 运动模型, 化学梯度", "comments": "这项研究通过提出一个考虑纳米尺度限制的纳米机器人运动模型，为癌症的精准检测和治疗提供了新的理论框架。其创新点在于引入了两种基于化学梯度的自推进机制，特别是纳米机器人协同放大化学信号的动态模型，展现了集体行为在提高效率方面的潜力。尽管第二个变体的智能体能力假设更具推测性，但其性能提升预示了未来纳米医学的可能方向，为后续实验和技术发展奠定了基础。"}}
{"id": "2507.11948", "title": "Kevin: Multi-Turn RL for Generating CUDA Kernels", "authors": ["Carlo Baronio", "Pietro Marsella", "Ben Pan", "Simon Guo", "Silas Alberti"], "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11948v1", "summary": "Writing GPU kernels is a challenging task and critical for AI systems'\nefficiency. It is also highly iterative: domain experts write code and improve\nperformance through execution feedback. Moreover, it presents verifiable\nrewards like correctness and speedup, making it a natural environment to apply\nReinforcement Learning (RL). To explicitly incorporate the iterative nature of\nthis process into training, we develop a flexible multi-turn RL recipe that\naddresses unique challenges encountered in real-world settings, such as\nlearning from long trajectories and effective reward attribution across turns.\nWe present Kevin - K(ernel D)evin, the first model trained with multi-turn RL\nfor CUDA kernel generation and optimization. In our evaluation setup, Kevin\nshows significant gains over its base model (QwQ-32B), improving correctness of\ngenerated kernels (in pure CUDA) from 56% to 82% and mean speedup from 0.53x to\n1.10x of baseline (PyTorch Eager), and surpassing frontier models like o4-mini\n(0.78x). Finally, we study its behavior across test-time scaling axes: we found\nscaling serial refinement more beneficial than parallel sampling. In\nparticular, when given more refinement turns, Kevin shows a higher rate of\nimprovement.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11948v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Kevin: 用于生成 CUDA 内核的多轮强化学习", "tldr": "Kevin 是一种利用多轮强化学习生成和优化 CUDA 内核的模型，显著提高了内核的正确性和运行速度。", "motivation": "编写 GPU 内核具有挑战性且对 AI 系统效率至关重要，这是一个高度迭代的过程，并且具有可验证的奖励（如正确性和加速），使其成为应用强化学习的理想环境。", "method": "研究人员开发了一种灵活的多轮强化学习（RL）方法，以解决真实世界中遇到的独特挑战，例如从长轨迹中学习和跨轮次的有效奖励归因。在此基础上，提出了 Kevin 模型，这是第一个使用多轮 RL 进行 CUDA 内核生成和优化的模型。", "result": "在评估中，Kevin 相较于其基础模型（QwQ-32B）展现出显著的提升，生成的纯 CUDA 内核的正确性从 56% 提高到 82%，平均加速比从基线（PyTorch Eager）的 0.53 倍提高到 1.10 倍，并超越了如 o4-mini（0.78 倍）等前沿模型。研究还发现，测试时串行精炼比并行采样更有益，给予更多精炼轮次时，Kevin 的改进率更高。", "conclusion": "Kevin 模型通过多轮强化学习显著提升了 CUDA 内核的生成和优化能力，证明了该方法在处理复杂、迭代的编程任务中的有效性，并且发现串行精炼对性能提升更为关键。", "translation": "编写 GPU 内核是一项具有挑战性的任务，对 AI 系统的效率至关重要。它也是高度迭代的：领域专家编写代码并通过执行反馈来改进性能。此外，它提供了可验证的奖励，如正确性和加速，使其成为应用强化学习（RL）的天然环境。为了将这一过程的迭代性质明确地纳入训练中，我们开发了一种灵活的多轮 RL 配方，解决了在实际环境中遇到的独特挑战，例如从长轨迹中学习和跨轮次的有效奖励归因。我们提出了 Kevin - K(ernel D)evin，这是第一个通过多轮 RL 训练用于 CUDA 内核生成和优化的模型。在我们的评估设置中，Kevin 相较于其基础模型（QwQ-32B）显示出显著的提升，生成的纯 CUDA 内核的正确性从 56% 提高到 82%，平均加速比从基线（PyTorch Eager）的 0.53 倍提高到 1.10 倍，并超越了如 o4-mini（0.78 倍）等前沿模型。最后，我们研究了它在测试时缩放轴上的行为：我们发现串行精炼比并行采样更有益。特别是，当给予更多的精炼轮次时，Kevin 显示出更高的改进率。", "summary": "本研究提出 Kevin，一个利用多轮强化学习（RL）来生成和优化 CUDA 内核的模型。该模型通过灵活的多轮 RL 方法解决了真实世界中长轨迹学习和奖励归因的挑战。实验结果表明，Kevin 在生成的内核正确性上从 56% 提升至 82%，平均加速比从 0.53 倍提升至 1.10 倍，显著优于基线和现有前沿模型。研究还发现，增加串行精炼轮次比并行采样更能有效提升性能。", "keywords": "CUDA 内核, 强化学习, 多轮强化学习, 代码生成, 性能优化", "comments": "该论文的创新点在于将多轮强化学习应用于 GPU 内核的迭代式生成和优化过程，这有效地模拟了人类专家通过反馈循环改进代码的方式。通过解决长轨迹和奖励归因等实际挑战，Kevin 模型在 CUDA 内核生成方面取得了显著的正确性和性能提升，展示了强化学习在复杂代码自动化领域的巨大潜力。其发现串行精炼比并行采样更有效，为未来的代码生成研究提供了重要的方向。"}}
{"id": "2507.11902", "title": "Resampling strategies for imbalanced regression: a survey and empirical analysis", "authors": ["Juscimara G. Avelino", "George D. C. Cavalcanti", "Rafael M. O. Cruz"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11902v1", "summary": "Imbalanced problems can arise in different real-world situations, and to\naddress this, certain strategies in the form of resampling or balancing\nalgorithms are proposed. This issue has largely been studied in the context of\nclassification, and yet, the same problem features in regression tasks, where\ntarget values are continuous. This work presents an extensive experimental\nstudy comprising various balancing and predictive models, and wich uses metrics\nto capture important elements for the user and to evaluate the predictive model\nin an imbalanced regression data context. It also proposes a taxonomy for\nimbalanced regression approaches based on three crucial criteria: regression\nmodel, learning process, and evaluation metrics. The study offers new insights\ninto the use of such strategies, highlighting the advantages they bring to each\nmodel's learning process, and indicating directions for further studies. The\ncode, data and further information related to the experiments performed herein\ncan be found on GitHub: https://github.com/JusciAvelino/imbalancedRegression.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11902v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "不平衡回归的重采样策略：一项调查与实证分析", "tldr": "该研究对不平衡回归问题中的重采样策略进行了全面的实证分析，并提出了一个分类法，为未来的研究指明了方向。", "motivation": "不平衡问题在现实世界中普遍存在，尽管在分类任务中已被广泛研究，但在目标值为连续值的回归任务中，这一问题却较少受到关注。", "method": "本研究进行了一项广泛的实验研究，涵盖了多种平衡和预测模型，并使用特定指标来评估不平衡回归数据背景下的预测模型。此外，它还基于回归模型、学习过程和评估指标三个关键标准，提出了一个不平衡回归方法的分类法。", "result": "研究提供了关于使用这些策略的新见解，强调了它们为每个模型的学习过程带来的优势。", "conclusion": "本研究为不平衡回归策略的使用提供了新见解，并为未来的研究指明了方向。", "translation": "不平衡问题可能出现在不同的现实世界情境中，为了解决这个问题，人们提出了某些以重采样或平衡算法形式出现的策略。这个问题在分类背景下已得到广泛研究，然而，在目标值为连续值的回归任务中也存在同样的问题。这项工作提出了一项广泛的实验研究，包括各种平衡和预测模型，并使用指标来捕获对用户重要的元素，并在不平衡回归数据背景下评估预测模型。它还基于回归模型、学习过程和评估指标三个关键标准，提出了一个不平衡回归方法的分类法。这项研究为这些策略的使用提供了新见解，强调了它们为每个模型的学习过程带来的优势，并指明了进一步研究的方向。与此处进行的实验相关的代码、数据和更多信息可在GitHub上找到：https://github.com/JusciAvelino/imbalancedRegression。", "summary": "本研究对不平衡回归问题中的重采样策略进行了全面的调查和实证分析。论文指出，尽管不平衡问题在分类领域已得到广泛研究，但在连续目标值的回归任务中却相对较少。作者进行了一项包含多种平衡和预测模型的广泛实验研究，并引入了针对不平衡回归的评估指标。此外，论文还基于回归模型、学习过程和评估指标提出了一个不平衡回归方法的分类法。研究结果为这些策略的应用提供了新见解，突出了它们在模型学习过程中的优势，并为未来的研究指明了方向。", "keywords": "不平衡回归, 重采样策略, 实证分析, 分类法, 预测模型", "comments": "这项研究的创新之处在于，它将不平衡问题的研究重点从分类扩展到了回归领域，填补了这一领域的空白。通过全面的实证分析和提出的分类法，该论文不仅提供了实用的指导，也为后续研究奠定了基础。其贡献在于系统地评估了不同重采样策略在不平衡回归中的表现，并为研究人员提供了可复现的代码和数据，具有较高的实用价值。"}}
{"id": "2507.12242", "title": "Looking for Fairness in Recommender Systems", "authors": ["Cécile Logé"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12242v1", "summary": "Recommender systems can be found everywhere today, shaping our everyday\nexperience whenever we're consuming content, ordering food, buying groceries\nonline, or even just reading the news. Let's imagine we're in the process of\nbuilding a recommender system to make content suggestions to users on social\nmedia. When thinking about fairness, it becomes clear there are several\nperspectives to consider: the users asking for tailored suggestions, the\ncontent creators hoping for some limelight, and society at large, navigating\nthe repercussions of algorithmic recommendations. A shared fairness concern\nacross all three is the emergence of filter bubbles, a side-effect that takes\nplace when recommender systems are almost \"too good\", making recommendations so\ntailored that users become inadvertently confined to a narrow set of\nopinions/themes and isolated from alternative ideas. From the user's\nperspective, this is akin to manipulation. From the small content creator's\nperspective, this is an obstacle preventing them access to a whole range of\npotential fans. From society's perspective, the potential consequences are\nfar-reaching, influencing collective opinions, social behavior and political\ndecisions. How can our recommender system be fine-tuned to avoid the creation\nof filter bubbles, and ensure a more inclusive and diverse content landscape?\nApproaching this problem involves defining one (or more) performance metric to\nrepresent diversity, and tweaking our recommender system's performance through\nthe lens of fairness. By incorporating this metric into our evaluation\nframework, we aim to strike a balance between personalized recommendations and\nthe broader societal goal of fostering rich and varied cultures and points of\nview.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12242v1", "cate": "cs.IR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "在推荐系统中寻求公平性", "tldr": "推荐系统可能产生过滤气泡，损害用户、创作者和社会。本文旨在通过引入多样性指标来平衡个性化和包容性，从而避免过滤气泡。", "motivation": "推荐系统，特别是“过滤气泡”的形成，限制了用户接触多样化内容和思想的机会，从而对用户、内容创作者和整个社会产生负面影响，这是本文的研究动机。", "method": "解决这个问题的方法是定义一个（或多个）代表多样性的性能指标，并通过公平性的视角调整推荐系统的性能，将其纳入评估框架中，以平衡个性化推荐与促进丰富多样文化和观点的更广泛社会目标。", "result": "Not mentioned in abstract", "conclusion": "本文旨在通过平衡个性化推荐与更广泛的社会目标，找到一种微调推荐系统的方法，以避免创建过滤气泡，并确保更具包容性和多样性的内容环境。", "translation": "推荐系统如今随处可见，塑造着我们日常消费内容、订购食物、在线购物乃至阅读新闻时的体验。假设我们正在构建一个推荐系统，为社交媒体用户提供内容建议。当考虑公平性时，会发现需要考虑几个视角：寻求个性化建议的用户、希望获得关注的内容创作者，以及面对算法推荐影响的整个社会。这三方共同的公平性担忧是过滤气泡的出现，这是推荐系统“过于优秀”时产生的副作用，即推荐内容过于个性化，导致用户无意中被限制在狭窄的观点/主题范围内，并与替代思想隔绝。从用户的角度来看，这类似于操纵。从小型内容创作者的角度来看，这是阻碍他们接触潜在粉丝的障碍。从社会的角度来看，潜在后果影响深远，影响着集体意见、社会行为和政治决策。我们的推荐系统如何进行微调以避免创建过滤气泡，并确保更具包容性和多样性的内容景观？解决这个问题需要定义一个（或多个）性能指标来代表多样性，并通过公平性的视角调整推荐系统的性能。通过将此指标纳入我们的评估框架，我们的目标是在个性化推荐与促进丰富多样文化和观点的更广泛社会目标之间取得平衡。", "summary": "推荐系统在日常生活中无处不在，但也带来了公平性问题，特别是“过滤气泡”的形成，这会限制用户的视角并阻碍内容创作者。这种现象通过限制多样性和影响集体意见，对个人、创作者和社会产生负面影响。为解决此问题，本文提出在推荐系统评估框架中定义并整合多样性作为性能指标，旨在平衡个性化推荐与社会对丰富多样信息环境的需求。", "keywords": "推荐系统, 公平性, 过滤气泡, 多样性, 个性化", "comments": "本文强调了推荐系统带来的一个关键社会挑战——过滤气泡，并提出了一个清晰的概念性方法（多样性指标）来解决它，强调了平衡个体个性化与更广泛社会福祉的重要性。其创新之处在于通过多样性的视角来构建公平性，以减轻算法操纵并促进包容性的信息环境。"}}
{"id": "2406.08379", "title": "Gazing Into Missteps: Leveraging Eye-Gaze for Unsupervised Mistake Detection in Egocentric Videos of Skilled Human Activities", "authors": ["Michele Mazzamuto", "Antonino Furnari", "Yoichi Sato", "Giovanni Maria Farinella"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.08379v5", "summary": "We address the challenge of unsupervised mistake detection in egocentric\nvideo of skilled human activities through the analysis of gaze signals. While\ntraditional methods rely on manually labeled mistakes, our approach does not\nrequire mistake annotations, hence overcoming the need of domain-specific\nlabeled data. Based on the observation that eye movements closely follow object\nmanipulation activities, we assess to what extent eye-gaze signals can support\nmistake detection, proposing to identify deviations in attention patterns\nmeasured through a gaze tracker with respect to those estimated by a gaze\nprediction model. Since predicting gaze in video is characterized by high\nuncertainty, we propose a novel gaze completion task, where eye fixations are\npredicted from visual observations and partial gaze trajectories, and\ncontribute a novel gaze completion approach which explicitly models\ncorrelations between gaze information and local visual tokens. Inconsistencies\nbetween predicted and observed gaze trajectories act as an indicator to\nidentify mistakes. Experiments highlight the effectiveness of the proposed\napproach in different settings, with relative gains up to +14%, +11%, and +5%\nin EPIC-Tent, HoloAssist and IndustReal respectively, remarkably matching\nresults of supervised approaches without seeing any labels. We further show\nthat gaze-based analysis is particularly useful in the presence of skilled\nactions, low action execution confidence, and actions requiring hand-eye\ncoordination and object manipulation skills. Our method is ranked first on the\nHoloAssist Mistake Detection challenge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.08379v5", "cate": "cs.CV", "date": "2024-06-12", "updated": "2025-07-16", "AI": {"title_translation": "凝视失误：利用眼动追踪在熟练人类活动的第一视角视频中进行无监督错误检测", "tldr": "该研究提出了一种利用眼动追踪信号进行无监督错误检测的新方法，通过比较预测和实际注视轨迹的偏差来识别错误，在无需标注的情况下取得了与有监督方法相当甚至更好的结果。", "motivation": "传统方法依赖手动标注错误，导致需要特定领域的标注数据。本研究旨在解决熟练人类活动的第一视角视频中无监督错误检测的挑战，克服对标注数据的需求。", "method": "本研究提出一种基于眼动追踪信号的无监督错误检测方法。核心思想是识别通过注视追踪器测量的注意力模式与注视预测模型估计的模式之间的偏差。由于视频中的注视预测具有高度不确定性，研究引入了一种新颖的注视补全任务，通过视觉观察和部分注视轨迹预测眼球凝视，并提出了一种明确建模注视信息与局部视觉标记之间关联的注视补全方法。预测注视轨迹与观察注视轨迹之间的不一致作为识别错误的指标。", "result": "实验证明了所提出方法在不同设置下的有效性，在EPIC-Tent、HoloAssist和IndustReal数据集上分别取得了高达+14%、+11%和+5%的相对增益，显著匹配了无标注的有监督方法的结果。研究还表明，基于注视的分析在存在熟练动作、低动作执行置信度和需要手眼协调及物体操作技能的动作时特别有用。该方法在HoloAssist错误检测挑战中排名第一。", "conclusion": "本研究提出了一种创新的无监督错误检测方法，通过分析眼动追踪信号中的注意力偏差，在无需手动标注错误的情况下实现了与有监督方法相媲美的性能，尤其适用于熟练人类活动的第一视角视频，并在多个数据集上取得了显著效果。", "translation": "我们通过分析注视信号，解决了在熟练人类活动的第一视角视频中进行无监督错误检测的挑战。传统方法依赖手动标注错误，而我们的方法不需要错误标注，从而克服了对领域特定标注数据的需求。基于眼球运动密切跟随物体操作活动的观察，我们评估了眼动注视信号在多大程度上可以支持错误检测，并提出通过注视追踪器测量的注意力模式与注视预测模型估计的模式之间的偏差来识别错误。由于视频中的注视预测具有高度不确定性，我们提出了一种新颖的注视补全任务，其中眼球凝视从视觉观察和部分注视轨迹中预测，并贡献了一种新颖的注视补全方法，该方法明确建模了注视信息与局部视觉标记之间的相关性。预测注视轨迹与观察注视轨迹之间的不一致作为识别错误的指标。实验突出了所提出方法在不同设置下的有效性，在EPIC-Tent、HoloAssist和IndustReal上分别取得了高达+14%、+11%和+5%的相对增益，显著匹配了未见过任何标签的有监督方法的结果。我们进一步表明，基于注视的分析在存在熟练动作、低动作执行置信度和需要手眼协调及物体操作技能的动作时特别有用。我们的方法在HoloAssist错误检测挑战中排名第一。", "summary": "本论文提出了一种新颖的无监督错误检测方法，用于分析熟练人类活动的第一视角视频。该方法利用眼动注视信号，通过比较预测和实际的注视轨迹来识别操作中的错误，从而避免了传统方法对大量手动标注数据的依赖。为了解决注视预测的不确定性，研究引入了注视补全任务，并开发了一种新的注视补全方法，该方法能有效建模注视信息与视觉特征之间的关联。实验结果表明，该方法在多个数据集上表现出色，甚至在没有标注的情况下达到了有监督方法的性能水平，尤其适用于涉及熟练动作和手眼协调的任务。", "keywords": "无监督错误检测, 眼动追踪, 第一视角视频, 注视补全, 熟练活动", "comments": "这项研究的创新之处在于利用眼动追踪信号进行无监督错误检测，从而解决了传统方法对大量手动标注数据的依赖。其提出的注视补全任务和方法，通过建模注视信息与局部视觉标记之间的相关性，有效地克服了注视预测的不确定性。该方法在无需标注的情况下取得了与有监督方法相当的性能，具有重要的实际应用价值，尤其是在工业和辅助领域，能够显著降低数据标注成本。该研究对于未来无监督行为分析领域具有启发性。"}}
{"id": "2507.12226", "title": "Optimal Spectral Approximation in the Overlaps for Generalized Finite Element Methods", "authors": ["Christian Alber", "Peter Bastian", "Moritz Hauck", "Robert Scheichl"], "categories": ["math.NA", "cs.NA", "65F10, 65N15, 65N30, 65N55"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      22 pages, 7 figures", "url": "http://arxiv.org/abs/2507.12226v1", "summary": "In this paper, we study a generalized finite element method for solving\nsecond-order elliptic partial differential equations with rough coefficients.\nThe method uses local approximation spaces computed by solving eigenvalue\nproblems on rings around the boundary of local subdomains. Compared to the\ncorresponding method that solves eigenvalue problems on the whole subdomains,\nthe problem size and the bandwidth of the resulting system matrices are\nsubstantially reduced, resulting in faster spectral computations. We prove a\nnearly exponential a priori decay result for the local approximation errors of\nthe proposed method, which implies the nearly exponential decay of the overall\napproximation error of the method. The proposed method can also be used as a\npreconditioner, and only a slight adaptation of our theory is necessary to\nprove the optimal convergence of the preconditioned iteration. Numerical\nexperiments are presented to support the effectiveness of the proposed method\nand to investigate its coefficient robustness.", "comment": "22 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.12226v1", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "广义有限元方法中重叠区域的最优谱近似", "tldr": "本文提出了一种广义有限元方法，通过在局部子域边界周围的“环”上求解特征值问题来解决具有粗糙系数的偏微分方程，实现了更快的谱计算、近似指数的误差衰减，并可作为最优预处理器。", "motivation": "为了解决具有粗糙系数的二阶椭圆偏微分方程，并旨在减少广义有限元方法中系统矩阵的问题规模和带宽，从而加快谱计算。", "method": "该方法是一种广义有限元方法，通过在局部子域边界周围的环上求解特征值问题来计算局部近似空间。它还可以用作预处理器。", "result": "该方法显著减小了系统矩阵的问题规模和带宽，从而加快了谱计算。证明了所提出方法的局部和整体近似误差具有近似指数的先验衰减结果。数值实验支持了所提出方法的有效性和系数鲁棒性。", "conclusion": "所提出的广义有限元方法在解决具有粗糙系数的偏微分方程方面是有效的，具有计算优势，并且可以用作最优预处理器。", "translation": "在本文中，我们研究了一种广义有限元方法，用于求解具有粗糙系数的二阶椭圆偏微分方程。该方法通过求解局部子域边界周围环上的特征值问题来计算局部近似空间。与在整个子域上求解特征值问题的相应方法相比，由此产生的系统矩阵的问题规模和带宽大大减小，从而加快了谱计算。我们证明了所提出方法的局部近似误差具有近似指数的先验衰减结果，这意味着该方法的整体近似误差也具有近似指数衰减。所提出的方法还可以用作预处理器，并且只需对我们的理论进行轻微调整即可证明预处理迭代的最优收敛性。本文提供了数值实验来支持所提出方法的有效性并研究其系数鲁棒性。", "summary": "本文介绍了一种用于求解具有粗糙系数的二阶椭圆偏微分方程的广义有限元方法。该方法通过在子域内的“环”上求解特征值问题来构建局部近似空间，与传统方法相比，这显著降低了计算复杂性。该方法展示了近似指数的近似误差衰减，并且可以作为最优预处理器。数值实验证实了其有效性和鲁棒性。", "keywords": "广义有限元方法, 椭圆偏微分方程, 谱近似, 预处理器, 特征值问题", "comments": "该方法的创新之处在于利用“环”进行局部特征值问题求解，有效降低了计算负担。对近似指数误差衰减的理论证明及其作为最优预处理器的适用性，突显了其在解决复杂偏微分方程方面的重要性。"}}
{"id": "2507.12084", "title": "LLAMA: Multi-Feedback Smart Contract Fuzzing Framework with LLM-Guided Seed Generation", "authors": ["Keke Gai", "Haochen Liang", "Jing Yu", "Liehuang Zhu", "Dusit Niyato"], "categories": ["cs.SE", "cs.CR"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12084v1", "summary": "Smart contracts play a pivotal role in blockchain ecosystems, and fuzzing\nremains an important approach to securing smart contracts. Even though mutation\nscheduling is a key factor influencing fuzzing effectiveness, existing fuzzers\nhave primarily explored seed scheduling and generation, while mutation\nscheduling has been rarely addressed by prior work. In this work, we propose a\nLarge Language Models (LLMs)-based Multi-feedback Smart Contract Fuzzing\nframework (LLAMA) that integrates LLMs, evolutionary mutation strategies, and\nhybrid testing techniques. Key components of the proposed LLAMA include: (i) a\nhierarchical prompting strategy that guides LLMs to generate semantically valid\ninitial seeds, coupled with a lightweight pre-fuzzing phase to select\nhigh-potential inputs; (ii) a multi-feedback optimization mechanism that\nsimultaneously improves seed generation, seed selection, and mutation\nscheduling by leveraging runtime coverage and dependency feedback; and (iii) an\nevolutionary fuzzing engine that dynamically adjusts mutation operator\nprobabilities based on effectiveness, while incorporating symbolic execution to\nescape stagnation and uncover deeper vulnerabilities. Our experiments\ndemonstrate that LLAMA outperforms state-of-the-art fuzzers in both coverage\nand vulnerability detection. Specifically, it achieves 91% instruction coverage\nand 90% branch coverage, while detecting 132 out of 148 known vulnerabilities\nacross diverse categories. These results highlight LLAMA's effectiveness,\nadaptability, and practicality in real-world smart contract security testing\nscenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12084v1", "cate": "cs.SE", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "LLAMA：基于LLM引导种子生成的智能合约多反馈模糊测试框架", "tldr": "LLAMA是一个利用大型语言模型（LLMs）、进化变异策略和混合测试技术，通过多反馈优化和动态调整变异操作符概率，显著提升智能合约模糊测试覆盖率和漏洞检测能力的框架。", "motivation": "智能合约在区块链生态系统中扮演着关键角色，而模糊测试是确保其安全性的重要方法。现有模糊测试器主要关注种子调度和生成，但对变异调度关注较少，这影响了模糊测试的有效性。", "method": "本文提出了LLAMA（基于大型语言模型的多反馈智能合约模糊测试框架），其关键组件包括：(i) 分层提示策略，引导LLMs生成语义有效初始种子并结合轻量级预模糊测试选择高潜力输入；(ii) 多反馈优化机制，利用运行时覆盖率和依赖反馈同时改进种子生成、种子选择和变异调度；(iii) 进化模糊测试引擎，根据有效性动态调整变异操作符概率，并结合符号执行以避免停滞并发现更深层漏洞。", "result": "实验表明，LLAMA在覆盖率和漏洞检测方面均优于现有最先进的模糊测试器。具体而言，它实现了91%的指令覆盖率和90%的分支覆盖率，并检测到148个已知漏洞中的132个。", "conclusion": "这些结果强调了LLAMA在实际智能合约安全测试场景中的有效性、适应性和实用性。", "translation": "智能合约在区块链生态系统中扮演着关键角色，而模糊测试仍然是保护智能合约安全的重要方法。尽管变异调度是影响模糊测试有效性的关键因素，但现有模糊测试器主要探索了种子调度和生成，而变异调度在先前工作中很少被提及。在这项工作中，我们提出了一个基于大型语言模型（LLMs）的多反馈智能合约模糊测试框架（LLAMA），该框架集成了LLMs、进化变异策略和混合测试技术。所提出的LLAMA的关键组件包括：(i) 一种分层提示策略，引导LLMs生成语义有效的初始种子，并结合轻量级预模糊测试阶段以选择高潜力输入；(ii) 一种多反馈优化机制，通过利用运行时覆盖率和依赖反馈，同时改进种子生成、种子选择和变异调度；(iii) 一个进化模糊测试引擎，根据有效性动态调整变异操作符概率，同时结合符号执行以摆脱停滞并发现更深层次的漏洞。我们的实验表明，LLAMA在覆盖率和漏洞检测方面均优于现有最先进的模糊测试器。具体而言，它实现了91%的指令覆盖率和90%的分支覆盖率，同时在不同类别中检测到148个已知漏洞中的132个。这些结果突出了LLAMA在实际智能合约安全测试场景中的有效性、适应性和实用性。", "summary": "本文提出了LLAMA，一个基于大型语言模型（LLMs）的多反馈智能合约模糊测试框架，旨在解决现有模糊测试器在变异调度方面的不足。LLAMA通过结合LLMs进行语义种子生成、多反馈优化机制改进种子和变异调度，以及进化模糊测试引擎动态调整变异策略，显著提升了智能合约的覆盖率和漏洞检测能力。实验结果显示，LLAMA在指令覆盖率、分支覆盖率和已知漏洞检测方面均优于现有技术，证明了其在实际应用中的有效性和实用性。", "keywords": "智能合约, 模糊测试, 大型语言模型, 变异调度, 多反馈优化", "comments": "LLAMA的创新之处在于首次将LLMs引入智能合约模糊测试中的种子生成环节，并结合多反馈机制和进化策略优化了整个模糊测试流程，特别是解决了变异调度这一关键但常被忽视的问题。其在覆盖率和漏洞检测上的显著提升表明了该框架的巨大潜力，为智能合约安全测试提供了新的范式。"}}
{"id": "2507.11638", "title": "Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders", "authors": ["Benjamin Keel", "Aaron Quyn", "David Jayne", "Maryam Mohsin", "Samuel D. Relton"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Published in Medical Image Understanding and Analysis (MIUA) 2025", "url": "http://arxiv.org/abs/2507.11638v1", "summary": "Effective treatment for rectal cancer relies on accurate lymph node\nmetastasis (LNM) staging. However, radiological criteria based on lymph node\n(LN) size, shape and texture morphology have limited diagnostic accuracy. In\nthis work, we investigate applying a Variational Autoencoder (VAE) as a feature\nencoder model to replace the large pre-trained Convolutional Neural Network\n(CNN) used in existing approaches. The motivation for using a VAE is that the\ngenerative model aims to reconstruct the images, so it directly encodes visual\nfeatures and meaningful patterns across the data. This leads to a disentangled\nand structured latent space which can be more interpretable than a CNN. Models\nare deployed on an in-house MRI dataset with 168 patients who did not undergo\nneo-adjuvant treatment. The post-operative pathological N stage was used as the\nground truth to evaluate model predictions. Our proposed model 'VAE-MLP'\nachieved state-of-the-art performance on the MRI dataset, with cross-validated\nmetrics of AUC 0.86 +/- 0.05, Sensitivity 0.79 +/- 0.06, and Specificity 0.85\n+/- 0.05. Code is available at:\nhttps://github.com/benkeel/Lymph_Node_Classification_MIUA.", "comment": "Published in Medical Image Understanding and Analysis (MIUA) 2025", "pdf_url": "http://arxiv.org/pdf/2507.11638v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "直肠癌MRI淋巴结转移的可解释性预测：使用变分自编码器", "tldr": "一种基于变分自编码器（VAE）的新模型VAE-MLP，在直肠癌MRI中实现了淋巴结转移预测的最新性能，并提供了更好的可解释性。", "motivation": "直肠癌的有效治疗依赖于准确的淋巴结转移（LNM）分期，但现有基于放射学标准的诊断准确性有限。该研究旨在探索使用变分自编码器（VAE）作为特征编码器来取代现有方法中大型预训练卷积神经网络（CNN），以实现更可解释的视觉特征编码和模式学习。", "method": "该研究应用变分自编码器（VAE）作为特征编码模型，取代了现有方法中使用的预训练卷积神经网络（CNN）。提出的模型命名为“VAE-MLP”，在一个包含168名未接受新辅助治疗患者的内部MRI数据集上进行部署。模型预测结果通过术后病理N分期作为真实标签进行评估。", "result": "提出的“VAE-MLP”模型在MRI数据集上取得了最先进的性能，交叉验证指标显示AUC为0.86 +/- 0.05，敏感性为0.79 +/- 0.06，特异性为0.85 +/- 0.05。", "conclusion": "该研究证明，使用变分自编码器作为特征编码器，可以实现对直肠癌MRI中淋巴结转移的准确且可解释的预测，并达到最先进的诊断性能。", "translation": "直肠癌的有效治疗依赖于准确的淋巴结转移（LNM）分期。然而，基于淋巴结大小、形状和纹理形态的放射学标准诊断准确性有限。在这项工作中，我们研究了应用变分自编码器（VAE）作为特征编码模型，以取代现有方法中使用的预训练大型卷积神经网络（CNN）。使用VAE的动机是，生成模型旨在重建图像，因此它直接编码视觉特征和数据中的有意义模式。这导致了一个解耦和结构化的潜在空间，比CNN更具可解释性。模型部署在一个包含168名未接受新辅助治疗患者的内部MRI数据集上。术后病理N分期被用作评估模型预测的真实标签。我们提出的模型“VAE-MLP”在MRI数据集上取得了最先进的性能，交叉验证指标显示AUC为0.86 +/- 0.05，敏感性为0.79 +/- 0.06，特异性为0.85 +/- 0.05。代码可在以下网址获取：https://github.com/benkeel/Lymph_Node_Classification_MIUA。", "summary": "本文提出了一种基于变分自编码器（VAE）的“VAE-MLP”模型，用于从直肠癌MRI图像中可解释地预测淋巴结转移。该模型旨在克服传统放射学诊断准确性有限的问题，并通过VAE的生成特性实现更具解释性的特征编码。在包含168名患者的内部MRI数据集上，VAE-MLP取得了0.86的AUC、0.79的敏感性和0.85的特异性，达到了最先进的性能。", "keywords": "直肠癌, 淋巴结转移, 变分自编码器, MRI, 可解释性AI", "comments": "这篇论文的创新点在于使用变分自编码器（VAE）作为特征编码器来预测直肠癌淋巴结转移，这不仅提高了诊断准确性，更重要的是，通过VAE的特性，使得模型具有更好的可解释性，解决了传统深度学习模型“黑箱”的问题。这对于临床决策具有重要意义，因为它能帮助医生理解预测结果的依据。"}}
{"id": "2507.11969", "title": "GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models", "authors": ["Zhaohong Huang", "Yuxin Zhang", "Jingjing Xie", "Fei Chao", "Rongrong Ji"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11969v1", "summary": "Recent advances in test-time adaptation (TTA) for Vision-Language Models\n(VLMs) have garnered increasing attention, particularly through the use of\nmultiple augmented views of a single image to boost zero-shot generalization.\nUnfortunately, existing methods fail to strike a satisfactory balance between\nperformance and efficiency, either due to excessive overhead of tuning text\nprompts or unstable benefits from handcrafted, training-free visual feature\nenhancement. In this paper, we present Global-Spatial Bias Learner (GS-Bias),\nan efficient and effective TTA paradigm that incorporates two learnable biases\nduring TTA, unfolded as the global bias and spatial bias. Particularly, the\nglobal bias captures the global semantic features of a test image by learning\nconsistency across augmented views, while spatial bias learns the semantic\ncoherence between regions in the image's spatial visual representation. It is\nworth highlighting that these two sets of biases are directly added to the\nlogits outputed by the pretrained VLMs, which circumvent the full\nbackpropagation through VLM that hinders the efficiency of existing TTA\nmethods. This endows GS-Bias with extremely high efficiency while achieving\nstate-of-the-art performance on 15 benchmark datasets. For example, it achieves\na 2.23% improvement over TPT in cross-dataset generalization and a 2.72%\nimprovement in domain generalization, while requiring only 6.5% of TPT's memory\nusage on ImageNet.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11969v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "GS-Bias：用于视觉-语言模型单图像测试时适应的全局-空间偏差学习器", "tldr": "GS-Bias是一种高效且有效的测试时适应（TTA）范式，通过学习全局和空间偏差直接添加到预训练视觉-语言模型的logits中，从而在保持最先进性能的同时显著提高效率。", "motivation": "现有的视觉-语言模型（VLM）测试时适应（TTA）方法在性能和效率之间未能取得令人满意的平衡，原因在于文本提示调整的开销过大，或者手工制作的、免训练的视觉特征增强带来的益处不稳定。", "method": "本文提出了一种名为全局-空间偏差学习器（GS-Bias）的高效且有效的TTA范式。它在TTA过程中引入了两种可学习偏差：全局偏差和空间偏差。全局偏差通过学习增强视图之间的一致性来捕获测试图像的全局语义特征，而空间偏差则学习图像空间视觉表示中区域间的语义连贯性。这些偏差直接添加到预训练VLM输出的logits中，避免了通过VLM进行完整的反向传播，从而提高了效率。", "result": "GS-Bias在15个基准数据集上实现了极高的效率和最先进的性能。例如，它在跨数据集泛化方面比TPT提高了2.23%，在域泛化方面提高了2.72%，同时在ImageNet上仅需要TPT 6.5%的内存使用量。", "conclusion": "GS-Bias通过引入可学习的全局和空间偏差并直接作用于预训练VLM的logits，成功解决了现有测试时适应方法在效率和性能平衡上的不足，实现了高效且高性能的单图像测试时适应。", "translation": "最近，视觉-语言模型（VLM）的测试时适应（TTA）取得了进展，特别通过使用单图像的多个增强视图来提升零样本泛化能力，引起了越来越多的关注。不幸的是，现有方法未能很好地平衡性能和效率，这要么是因为调整文本提示的开销过大，要么是手工制作的、免训练的视觉特征增强所带来的益处不稳定。在本文中，我们提出了全局-空间偏差学习器（GS-Bias），这是一种高效且有效的TTA范式，在TTA期间引入了两种可学习的偏差，分别表现为全局偏差和空间偏差。特别是，全局偏差通过学习增强视图之间的一致性来捕获测试图像的全局语义特征，而空间偏差则学习图像空间视觉表示中区域间的语义连贯性。值得强调的是，这两组偏差直接添加到预训练VLM输出的logits中，这避免了阻碍现有TTA方法效率的VLM完整反向传播。这使得GS-Bias在实现最先进性能的同时，具备极高的效率，并在15个基准数据集上得到了验证。例如，它在跨数据集泛化方面比TPT提高了2.23%，在域泛化方面提高了2.72%，同时在ImageNet上仅需要TPT 6.5%的内存使用量。", "summary": "本文提出了一种名为GS-Bias的创新测试时适应（TTA）范式，专为视觉-语言模型（VLM）设计。针对现有TTA方法在效率和性能之间平衡不佳的问题，GS-Bias引入了可学习的全局偏差和空间偏差。这些偏差直接添加到预训练VLM的logits输出中，有效避免了耗时的反向传播，从而显著提高了效率。实验结果表明，GS-Bias在15个基准数据集上实现了最先进的性能，并在泛化能力和内存效率方面均优于现有方法。", "keywords": "测试时适应, 视觉-语言模型, 全局-空间偏差, 效率, 泛化", "comments": "GS-Bias的创新之处在于其通过引入全局和空间偏差，并将其直接作用于预训练VLM的logits，从而巧妙地规避了全量反向传播的效率瓶颈。这种方法在不牺牲性能的前提下显著提高了测试时适应的效率，为VLM的实际应用提供了更可行的方案，特别是在资源受限的环境中。其在多个数据集上展现出的卓越泛化能力和内存效率是其重要性所在。"}}
{"id": "2507.12257", "title": "Robust Causal Discovery in Real-World Time Series with Power-Laws", "authors": ["Matteo Tusoni", "Giuseppe Masi", "Andrea Coletta", "Aldo Glielmo", "Viviana Arrigoni", "Novella Bartolini"], "categories": ["cs.LG", "physics.data-an", "stat.ML", "stat.OT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12257v1", "summary": "Exploring causal relationships in stochastic time series is a challenging yet\ncrucial task with a vast range of applications, including finance, economics,\nneuroscience, and climate science. Many algorithms for Causal Discovery (CD)\nhave been proposed, but they often exhibit a high sensitivity to noise,\nresulting in misleading causal inferences when applied to real data. In this\npaper, we observe that the frequency spectra of typical real-world time series\nfollow a power-law distribution, notably due to an inherent self-organizing\nbehavior. Leveraging this insight, we build a robust CD method based on the\nextraction of power -law spectral features that amplify genuine causal signals.\nOur method consistently outperforms state-of-the-art alternatives on both\nsynthetic benchmarks and real-world datasets with known causal structures,\ndemonstrating its robustness and practical relevance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12257v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "在具有幂律的真实世界时间序列中进行鲁棒因果发现", "tldr": "本文提出了一种基于幂律频谱特征提取的鲁棒因果发现方法，该方法在真实世界时间序列中表现优于现有技术。", "motivation": "在随机时间序列中探索因果关系是一项具有挑战性但至关重要的任务，在金融、经济学、神经科学和气候科学等领域有广泛应用。许多现有的因果发现算法对噪声高度敏感，导致在应用于真实数据时产生误导性因果推断。", "method": "本文观察到典型真实世界时间序列的频率谱遵循幂律分布，这主要归因于固有的自组织行为。利用这一见解，作者构建了一种基于提取幂律频谱特征的鲁棒因果发现方法，这些特征能够放大真实的因果信号。", "result": "该方法在合成基准和具有已知因果结构的真实世界数据集上均始终优于现有替代方案。", "conclusion": "本文提出的基于幂律频谱特征的因果发现方法在真实世界时间序列中表现出鲁棒性和实用性，能够有效放大真实的因果信号。", "translation": "在随机时间序列中探索因果关系是一项具有挑战性但至关重要的任务，在金融、经济学、神经科学和气候科学等领域有广泛应用。许多因果发现（CD）算法已被提出，但它们通常对噪声表现出高度敏感性，导致在应用于真实数据时产生误导性因果推断。在本文中，我们观察到典型真实世界时间序列的频率谱遵循幂律分布，这主要归因于固有的自组织行为。利用这一见解，我们构建了一种基于幂律频谱特征提取的鲁棒CD方法，该方法能够放大真实的因果信号。我们的方法在合成基准和具有已知因果结构的真实世界数据集上均始终优于现有替代方案，证明了其鲁棒性和实用相关性。", "summary": "本文提出了一种在具有幂律分布的真实世界时间序列中进行鲁棒因果发现的方法。针对现有因果发现算法对噪声敏感的问题，作者利用真实世界时间序列频率谱的幂律特性，开发了一种通过提取幂律频谱特征来增强因果信号的新方法。实验结果表明，该方法在合成数据和真实世界数据上均优于现有技术，证明了其在复杂、噪声环境中的有效性和鲁棒性。", "keywords": "因果发现, 幂律, 时间序列, 鲁棒性, 频谱特征", "comments": "本文的创新之处在于利用了真实世界时间序列中普遍存在的幂律频谱特征，将其作为因果发现的鲁棒信号放大器。这种方法有效地解决了传统因果发现算法对噪声敏感的问题，提升了在复杂真实数据中的应用潜力。其重要性体现在为金融、神经科学等领域提供了更可靠的因果推断工具。"}}
{"id": "2410.06405", "title": "Tackling the Abstraction and Reasoning Corpus with Vision Transformers: the Importance of 2D Representation, Positions, and Objects", "authors": ["Wenhao Li", "Yudong Xu", "Scott Sanner", "Elias Boutros Khalil"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.06405v2", "summary": "The Abstraction and Reasoning Corpus (ARC) is a popular benchmark focused on\nvisual reasoning in the evaluation of Artificial Intelligence systems. In its\noriginal framing, an ARC task requires solving a program synthesis problem over\nsmall 2D images using a few input-output training pairs. In this work, we adopt\nthe recently popular data-driven approach to the ARC and ask whether a Vision\nTransformer (ViT) can learn the implicit mapping, from input image to output\nimage, that underlies the task. We show that a ViT -- otherwise a\nstate-of-the-art model for images -- fails dramatically on most ARC tasks even\nwhen trained on one million examples per task. This points to an inherent\nrepresentational deficiency of the ViT architecture that makes it incapable of\nuncovering the simple structured mappings underlying the ARC tasks. Building on\nthese insights, we propose ViTARC, a ViT-style architecture that unlocks some\nof the visual reasoning capabilities required by the ARC. Specifically, we use\na pixel-level input representation, design a spatially-aware tokenization\nscheme, and introduce a novel object-based positional encoding that leverages\nautomatic segmentation, among other enhancements. Our task-specific ViTARC\nmodels achieve a test solve rate close to 100% on more than half of the 400\npublic ARC tasks strictly through supervised learning from input-output grids.\nThis calls attention to the importance of imbuing the powerful (Vision)\nTransformer with the correct inductive biases for abstract visual reasoning\nthat are critical even when the training data is plentiful and the mapping is\nnoise-free. Hence, ViTARC provides a strong foundation for future research in\nvisual reasoning using transformer-based architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.06405v2", "cate": "cs.CV", "date": "2024-10-08", "updated": "2025-07-15", "AI": {"title_translation": "使用视觉Transformer解决抽象推理语料库：2D表示、位置和对象的重要性", "tldr": "视觉Transformer在ARC任务上表现不佳，但通过引入2D表示、空间感知分词和基于对象的位置编码，提出的ViTARC模型显著提高了性能，强调了正确归纳偏差的重要性。", "motivation": "抽象推理语料库（ARC）是评估人工智能系统视觉推理能力的一个流行基准。研究旨在探究视觉Transformer（ViT）能否学习ARC任务中从输入图像到输出图像的隐式映射，并解决其在该类任务上的固有表示缺陷。", "method": "研究首先发现标准的视觉Transformer（ViT）在大多数ARC任务上表现不佳，即使在大量数据训练下。在此基础上，提出了一种ViT风格的架构ViTARC，通过使用像素级输入表示、设计空间感知分词方案以及引入利用自动分割的新颖的基于对象的位置编码等增强功能，来提升其视觉推理能力。ViTARC模型通过监督学习在输入-输出网格上进行训练。", "result": "标准的ViT在大多数ARC任务上表现“戏剧性失败”，即使在百万级示例训练下。而提出的ViTARC模型在超过一半的400个公共ARC任务上实现了接近100%的测试解决率。", "conclusion": "论文指出标准ViT架构存在固有的表示缺陷，使其无法揭示ARC任务下的简单结构化映射。研究强调了即使训练数据充足且映射无噪声，为强大的（视觉）Transformer注入正确的抽象视觉推理归纳偏差的重要性。ViTARC为未来使用基于Transformer架构的视觉推理研究提供了坚实的基础。", "translation": "抽象推理语料库（ARC）是一个流行的基准，专注于评估人工智能系统的视觉推理能力。在其最初的框架中，一个ARC任务需要通过少量输入-输出训练对来解决小2D图像上的程序合成问题。在这项工作中，我们采用了最近流行的数据驱动方法来处理ARC，并询问视觉Transformer（ViT）是否能够学习支撑任务的从输入图像到输出图像的隐式映射。我们发现，即使在每个任务一百万个示例上进行训练，ViT——一种在图像处理领域最先进的模型——在大多数ARC任务上都表现出戏剧性的失败。这表明ViT架构存在固有的表示缺陷，使其无法揭示ARC任务下简单的结构化映射。基于这些见解，我们提出了ViTARC，一种ViT风格的架构，它解锁了ARC所需的一些视觉推理能力。具体来说，我们使用了像素级输入表示，设计了空间感知分词方案，并引入了一种新颖的基于对象的位置编码，该编码利用了自动分割，以及其他增强功能。我们的任务特定ViTARC模型严格通过从输入-输出网格中进行监督学习，在超过一半的400个公共ARC任务上实现了接近100%的测试解决率。这呼吁人们关注为强大的（视觉）Transformer注入正确的抽象视觉推理归纳偏差的重要性，即使训练数据充足且映射无噪声，这些偏差也至关重要。因此，ViTARC为未来使用基于Transformer架构的视觉推理研究提供了坚实的基础。", "summary": "抽象推理语料库（ARC）是评估AI视觉推理的重要基准。本研究发现，尽管视觉Transformer（ViT）在图像处理领域表现出色，但其在ARC任务上表现不佳，即使拥有大量训练数据，原因在于其固有的表示缺陷无法捕捉任务的结构化映射。为解决此问题，论文提出了ViTARC，一种改进的ViT架构，它通过像素级输入、空间感知分词和基于对象的位置编码等创新，显著提升了模型性能。ViTARC在超过一半的ARC任务上实现了近100%的解决率，强调了为Transformer注入正确归纳偏差对于抽象视觉推理的关键性，并为该领域的未来研究奠定了基础。", "keywords": "视觉Transformer, 抽象推理语料库, 2D表示, 位置编码, 视觉推理", "comments": "这篇论文揭示了标准视觉Transformer在处理需要抽象和结构化推理的视觉任务时的局限性，即使在大量数据下也无法弥补。ViTARC通过引入针对2D结构、位置和对象的特定归纳偏差，有效地解决了这一问题，展示了为强大的基础模型设计任务特定架构改进的重要性。这对于理解和改进Transformer在更复杂推理任务上的应用具有重要意义，尤其是在需要超越纯数据拟合能力的场景中。"}}
{"id": "2507.11660", "title": "STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics", "authors": ["Joao F. Rocha", "Ke Xu", "Xingzhi Sun", "Ananya Krishna", "Dhananjay Bhaskar", "Blanche Mongeon", "Morgan Craig", "Mark Gerstein", "Smita Krishnaswamy"], "categories": ["cs.LG", "cs.MA", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11660v1", "summary": "The advent of single-cell technology has significantly improved our\nunderstanding of cellular states and subpopulations in various tissues under\nnormal and diseased conditions by employing data-driven approaches such as\nclustering and trajectory inference. However, these methods consider cells as\nindependent data points of population distributions. With spatial\ntranscriptomics, we can represent cellular organization, along with dynamic\ncell-cell interactions that lead to changes in cell state. Still, key\ncomputational advances are necessary to enable the data-driven learning of such\ncomplex interactive cellular dynamics. While agent-based modeling (ABM)\nprovides a powerful framework, traditional approaches rely on handcrafted rules\nderived from domain knowledge rather than data-driven approaches. To address\nthis, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED)\nintegrating ABM with deep learning to model intercellular communication, and\nits effect on the intracellular gene regulatory network. Using graph ODE\nnetworks (GDEs) with shared weights per cell type, our approach represents\ngenes as vertices and interactions as directed edges, dynamically learning\ntheir strengths through a designed attention mechanism. Trained to match\ncontinuous trajectories of simulated as well as inferred trajectories from\nspatial transcriptomics data, the model captures both intercellular and\nintracellular interactions, enabling a more adaptive and accurate\nrepresentation of cellular dynamics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11660v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "STAGED：一种用于学习细胞相互作用动力学的多智能体神经网络", "tldr": "STAGED是一个结合多智能体建模和深度学习的新型神经网络，用于数据驱动地学习复杂的细胞间和细胞内相互作用，克服了传统方法依赖手工规则的局限性。", "motivation": "现有的单细胞技术方法（如聚类和轨迹推断）将细胞视为独立的数据点，未能考虑细胞间的动态相互作用。虽然空间转录组学能表示细胞组织，但仍需要计算上的进步来学习复杂的交互式细胞动力学。传统的基于智能体的建模（ABM）依赖于手工规则而非数据驱动的方法。", "method": "本文引入了Spatio Temporal Agent-Based Graph Evolution Dynamics (STAGED)，它将基于智能体的建模（ABM）与深度学习相结合，以模拟细胞间通信及其对细胞内基因调控网络的影响。该方法使用具有每种细胞类型共享权重的图ODE网络（GDEs），将基因表示为顶点，相互作用表示为有向边，并通过设计的注意力机制动态学习它们的强度。模型通过匹配模拟轨迹和从空间转录组学数据推断的轨迹进行训练。", "result": "该模型能够捕获细胞间和细胞内相互作用，从而实现细胞动力学更具适应性和准确的表示。", "conclusion": "STAGED通过整合ABM和深度学习，提供了一个数据驱动的框架，用于学习复杂的细胞相互作用动力学，克服了传统ABM的局限性，并提供了对细胞状态变化更全面的理解。", "translation": "单细胞技术的出现，通过采用聚类和轨迹推断等数据驱动方法，显著提高了我们对正常和疾病条件下各种组织中细胞状态和亚群的理解。然而，这些方法将细胞视为群体分布的独立数据点。通过空间转录组学，我们可以表示细胞组织以及导致细胞状态变化的动态细胞间相互作用。尽管如此，仍需要关键的计算进展才能实现对这种复杂交互式细胞动力学的数据驱动学习。虽然基于智能体的建模（ABM）提供了一个强大的框架，但传统方法依赖于从领域知识而非数据驱动方法得出的手工规则。为了解决这个问题，我们引入了时空基于智能体的图演化动力学（STAGED），它将ABM与深度学习相结合，以模拟细胞间通信及其对细胞内基因调控网络的影响。我们的方法使用具有每种细胞类型共享权重的图ODE网络（GDEs），将基因表示为顶点，相互作用表示为有向边，并通过设计的注意力机制动态学习它们的强度。该模型经过训练，以匹配模拟轨迹以及从空间转录组学数据推断的轨迹，它能够捕获细胞间和细胞内相互作用，从而实现细胞动力学更具适应性和准确的表示。", "summary": "STAGED是一种新型多智能体神经网络，旨在通过结合基于智能体的建模（ABM）和深度学习来解决传统单细胞分析和ABM方法的局限性。它利用图ODE网络和注意力机制，数据驱动地学习复杂的细胞间通信和细胞内基因调控网络。该模型能够从模拟和空间转录组学数据中捕获动态细胞相互作用，从而提供对细胞动力学更准确和自适应的表示。", "keywords": "多智能体神经网络, 细胞相互作用, 空间转录组学, 深度学习, 基于智能体的建模", "comments": "STAGED的创新之处在于其将传统的基于智能体的建模（ABM）与深度学习相结合，实现了从数据中自动学习复杂的细胞相互作用规则，而不是依赖于耗时且可能不完全的手工规则。这对于理解细胞在正常和疾病条件下的动态行为至关重要，为生物学研究提供了强大的新工具。其利用图ODE网络和注意力机制来建模基因和相互作用的动态强度，是其方法学上的亮点。"}}
{"id": "2411.12898", "title": "Problem-dependent convergence bounds for randomized linear gradient compression", "authors": ["Thomas Flynn", "Patrick Johnstone", "Shinjae Yoo"], "categories": ["math.OC", "cs.LG"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.12898v3", "summary": "In distributed optimization, the communication of model updates can be a\nperformance bottleneck. Consequently, gradient compression has been proposed as\na means of increasing optimization throughput. In general, due to information\nloss, compression introduces a penalty on the number of iterations needed to\nreach a solution. In this work, we investigate how the iteration penalty\ndepends on the interaction between compression and problem structure, in the\ncontext of non-convex stochastic optimization. We focus on linear schemes,\nwhere compression and decompression can be modeled as multiplication with a\nrandom matrix. We consider several distributions of matrices, among them\nHaar-distributed orthogonal matrices and matrices with random Gaussian entries.\nWe find that the impact of compression on convergence can be quantified in\nterms of a smoothness matrix associated with the objective function, using a\nnorm defined by the compression scheme. The analysis reveals that in certain\ncases, compression performance is related to low-rank structure or other\nspectral properties of the problem and our bounds predict that the penalty\nintroduced by compression is significantly reduced compared to worst-case\nbounds that only consider the compression level, ignoring problem data. We\nverify the theoretical findings experimentally, including fine-tuning an image\nclassification model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.12898v3", "cate": "math.OC", "date": "2024-11-19", "updated": "2025-07-15", "AI": {"title_translation": "随机线性梯度压缩的问题依赖收敛界", "tldr": "本文研究了随机线性梯度压缩在非凸随机优化中如何影响收敛，发现压缩对收敛的影响取决于问题结构，并提出了比最坏情况更好的收敛界。", "motivation": "在分布式优化中，模型更新的通信是性能瓶颈。梯度压缩被提出以提高优化吞吐量，但通常会因信息丢失而增加达到解决方案所需的迭代次数。本文旨在研究这种迭代惩罚如何依赖于压缩和问题结构之间的相互作用。", "method": "在非凸随机优化背景下，研究了线性压缩方案，其中压缩和解压缩可以建模为与随机矩阵的乘法。考虑了几种矩阵分布，包括Haar分布正交矩阵和随机高斯条目矩阵。通过使用目标函数相关的平滑度矩阵和压缩方案定义的范数来量化压缩对收敛的影响。", "result": "发现压缩对收敛的影响可以通过与目标函数相关的平滑度矩阵来量化，使用由压缩方案定义的范数。分析表明，在某些情况下，压缩性能与问题的低秩结构或其他谱特性相关。提出的界限预测，与仅考虑压缩水平而忽略问题数据的最坏情况界限相比，压缩引入的惩罚显著降低。通过实验验证了理论发现，包括微调图像分类模型。", "conclusion": "压缩对收敛的影响可以根据问题结构（如平滑度矩阵、低秩特性）进行量化，从而可以推导出比通用最坏情况界限更紧密的收敛界限，表明在特定问题上压缩的效率更高。", "translation": "分布式优化中，模型更新的通信可能成为性能瓶颈。因此，梯度压缩被提出作为提高优化吞吐量的一种手段。通常，由于信息丢失，压缩会增加达到解决方案所需的迭代次数。在这项工作中，我们研究了在非凸随机优化的背景下，迭代惩罚如何依赖于压缩和问题结构之间的相互作用。我们专注于线性方案，其中压缩和解压缩可以建模为与随机矩阵的乘法。我们考虑了几种矩阵分布，其中包括Haar分布的正交矩阵和具有随机高斯条目的矩阵。我们发现，压缩对收敛的影响可以通过与目标函数相关的平滑度矩阵来量化，使用由压缩方案定义的范数。分析表明，在某些情况下，压缩性能与问题的低秩结构或其他谱特性相关，并且我们的界限预测，与仅考虑压缩水平而忽略问题数据的最坏情况界限相比，压缩引入的惩罚显著降低。我们通过实验验证了理论发现，包括微调图像分类模型。", "summary": "本文探讨了在分布式非凸随机优化中，随机线性梯度压缩对收敛的影响如何依赖于问题结构。研究发现，压缩对收敛的惩罚可以通过目标函数的平滑度矩阵及其定义的范数来量化。研究结果表明，在考虑问题特定结构（如低秩特性）时，压缩引入的迭代惩罚远低于通用的最坏情况界限。理论发现通过实验得到了验证。", "keywords": "梯度压缩, 分布式优化, 收敛界限, 问题结构, 随机矩阵", "comments": "这篇论文的创新点在于它超越了仅考虑压缩率的最坏情况分析，引入了问题结构（如平滑度矩阵和低秩特性）来更精确地量化梯度压缩对收敛的影响。这为在特定问题上设计和分析更高效的压缩方案提供了理论依据，对于提高分布式优化的实际性能具有重要意义。"}}
{"id": "2501.05590", "title": "Negative Ties Highlight Hidden Extremes in Social Media Polarization", "authors": ["Elena Candellone", "Shazia'Ayn Babul", "Özgür Togay", "Alexandre Bovet", "Javier Garcia-Bernardo"], "categories": ["physics.soc-ph", "cs.SI"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.05590v4", "summary": "Human interactions in the online world comprise a combination of positive and\nnegative exchanges. These diverse interactions can be captured using signed\nnetwork representations, where edges take positive or negative weights to\nindicate the sentiment of the interaction between individuals. Signed networks\noffer valuable insights into online political polarization by capturing\nantagonistic interactions and ideological divides on social media platforms.\nThis study analyzes polarization on Meneame, a Spanish social media platform\nthat facilitates engagement with news stories through comments and voting.\nUsing a dual-method approach, Signed Hamiltonian Eigenvector Embedding for\nProximity (SHEEP) for signed networks and Correspondence Analysis (CA) for\nunsigned networks, we investigate how including negative ties enhances the\nunderstanding of structural polarization levels across different conversation\ntopics on the platform. While the unsigned Meneame network effectively\ndelineates ideological communities, only by incorporating negative ties can we\nidentify ideologically extreme users who engage in antagonistic behaviors:\nwithout them, the most extreme users remain indistinguishable from their less\nconfrontational ideological peers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.05590v4", "cate": "physics.soc-ph", "date": "2025-01-09", "updated": "2025-07-16", "AI": {"title_translation": "负面关系揭示社交媒体两极分化中的隐藏极端", "tldr": "本研究表明，在社交媒体两极分化分析中，纳入负面关系（如敌对互动）对于识别意识形态极端用户至关重要，而仅凭非负面网络则无法区分这些极端用户。", "motivation": "在线世界中的人类互动包含正面和负面的交流，这些可以通过有符号网络表示来捕捉。有符号网络通过捕捉对抗性互动和意识形态分歧，为理解在线政治两极分化提供了宝贵的见解。本研究旨在探讨纳入负面关系如何增强对平台不同对话主题中结构性两极分化水平的理解。", "method": "本研究分析了西班牙社交媒体平台 Meneame 上的两极分化，该平台通过评论和投票促进新闻故事的参与。研究采用了双重方法：针对有符号网络使用近距离有符号哈密顿特征向量嵌入（SHEEP），针对无符号网络使用对应分析（CA）。", "result": "研究发现，虽然无符号的 Meneame 网络能有效地描绘意识形态社区，但只有通过纳入负面关系，才能识别出参与对抗行为的意识形态极端用户；如果没有负面关系，最极端的用户与那些不那么对抗的意识形态同伴将无法区分。", "conclusion": "纳入负面关系对于全面理解社交媒体上的两极分化至关重要，因为它能够揭示传统方法无法识别的隐藏极端用户。", "translation": "在线世界中的人类互动由正面和负面交流组成。这些多样化的互动可以使用有符号网络表示来捕捉，其中边带有正或负权重以表示个体之间互动的情绪。有符号网络通过捕捉社交媒体平台上的对抗性互动和意识形态分歧，为在线政治两极分化提供了宝贵的见解。本研究分析了西班牙社交媒体平台 Meneame 上的两极分化，该平台通过评论和投票促进新闻故事的参与。我们采用双重方法，即针对有符号网络使用近距离有符号哈密顿特征向量嵌入（SHEEP），针对无符号网络使用对应分析（CA），来调查纳入负面关系如何增强对平台不同对话主题中结构性两极分化水平的理解。虽然无符号的 Meneame 网络能有效地描绘意识形态社区，但只有通过纳入负面关系，我们才能识别出参与对抗行为的意识形态极端用户：如果没有它们，最极端的用户与那些不那么对抗的意识形态同伴将无法区分。", "summary": "本研究探讨了在社交媒体两极分化分析中，纳入负面关系的重要性。通过对西班牙社交媒体平台 Meneame 的案例研究，论文使用有符号网络（SHEEP）和无符号网络（CA）的双重方法。结果表明，虽然无符号网络可以识别意识形态社区，但只有考虑负面关系才能揭示并区分出那些参与对抗行为的极端意识形态用户，填补了现有分析方法的空白。", "keywords": "社交媒体两极分化, 有符号网络, 负面关系, 极端用户, Meneame", "comments": "这项研究的创新之处在于强调了负面关系在社交媒体两极分化分析中的关键作用。它揭示了仅依赖正面或中性互动可能无法捕捉到的隐藏极端，这对于理解和干预在线极端主义具有重要意义。该研究方法结合了有符号和无符号网络分析，提供了一个更全面的视角。"}}
{"id": "2507.11941", "title": "BlockBPE: Parallel BPE Tokenization", "authors": ["Amos You"], "categories": ["cs.CL", "cs.DC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models (ICML 2025)", "url": "http://arxiv.org/abs/2507.11941v1", "summary": "Tokenization is a critical preprocessing step in large language model\npipelines, yet widely-used implementations remain CPU-bound and suboptimal for\nbatch inference workflows on GPU. We present BlockBPE, a parallel GPU\nimplementation of byte-pair encoding (BPE) that achieves near linear-time\ncomplexity under realistic assumptions and is optimized for high-throughput,\nbatch inference. Unlike existing Rust-based tokenizers such as HuggingFace\nTokenizers or OpenAI's tiktoken-whose runtimes are dominated by Regex\npre-tokenization and exhibit $O(n \\log n)$ runtime-BlockBPE eliminates the\nRegex pre-tokenization which leads to small loss in generation quality, but\nenables highly parallelized token merges within thread blocks, reducing overall\ncomplexity to $O(nd)$ where $d \\ll n$. On high-batch inference workloads,\nBlockBPE achieves up to 2x higher throughput than tiktoken and 2.5x over\nHuggingFace Tokenizers.", "comment": "ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models\n  (ICML 2025)", "pdf_url": "http://arxiv.org/pdf/2507.11941v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "BlockBPE：并行BPE分词", "tldr": "BlockBPE是一种新的并行GPU BPE分词器，通过消除Regex预分词并优化GPU批处理推理，显著提高了LLM的吞吐量，性能优于现有分词器。", "motivation": "现有的分词器是CPU密集型的，并且对于GPU上的大批量推理工作流来说效率低下，成为大型语言模型管道的瓶颈。", "method": "提出了BlockBPE，一个并行的GPU实现的字节对编码（BPE）分词器。它通过消除Regex预分词并启用线程块内的高度并行化令牌合并来优化性能，从而将整体复杂性从$O(n \text{ log } n)$降低到$O(nd)$（其中$d \text{ \textless\textless } n$）。", "result": "在高批量推理工作负载下，BlockBPE的吞吐量比tiktoken高出2倍，比HuggingFace Tokenizers高出2.5倍。", "conclusion": "BlockBPE通过优化GPU上的并行处理，显著提高了大型语言模型推理的分词效率和吞吐量，尽管会带来微小的生成质量损失。", "translation": "分词是大型语言模型管道中一个关键的预处理步骤，然而广泛使用的实现仍然是CPU密集型的，并且对于GPU上的批处理推理工作流来说并不理想。我们提出了BlockBPE，一个字节对编码（BPE）的并行GPU实现，它在现实假设下实现了接近线性的时间复杂度，并针对高吞吐量、批处理推理进行了优化。与现有基于Rust的分词器（如HuggingFace Tokenizers或OpenAI的tiktoken）不同——它们的运行时主要由Regex预分词主导并表现出$O(n \text{ log } n)$的运行时——BlockBPE消除了Regex预分词，这导致生成质量有少量损失，但能够在线程块内进行高度并行的令牌合并，将整体复杂性降低到$O(nd)$，其中$d \text{ \textless\textless } n$。在高批量推理工作负载下，BlockBPE的吞吐量比tiktoken高出2倍，比HuggingFace Tokenizers高出2.5倍。", "summary": "BlockBPE是一种针对GPU批处理推理优化的并行BPE分词器，旨在解决现有分词器在大型语言模型中CPU密集且效率低下的问题。它通过消除Regex预分词并实现线程块内的高度并行化令牌合并，将时间复杂度从$O(n \text{ log } n)$降低到$O(nd)$。实验表明，BlockBPE在高批量推理工作负载下，吞吐量比tiktoken高出2倍，比HuggingFace Tokenizers高出2.5倍，尽管可能导致生成质量的轻微下降。", "keywords": "BPE分词, GPU并行, 大型语言模型, 吞吐量, 批处理推理", "comments": "BlockBPE的创新在于其GPU并行化设计，特别是消除了Regex预分词并实现了线程块内的并行合并，显著提高了分词效率，这对于大型语言模型的高吞吐量推理至关重要。其局限性在于可能导致生成质量的轻微损失，这需要在性能提升和质量之间进行权衡。"}}
{"id": "2403.01234", "title": "Active Deep Kernel Learning of Molecular Properties: Realizing Dynamic Structural Embeddings", "authors": ["Ayana Ghosh", "Maxim Ziatdinov", "Sergei V. Kalinin"], "categories": ["cs.LG", "physics.chem-ph", "physics.comp-ph", "physics.data-an"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.01234v2", "summary": "As vast databases of chemical identities become increasingly available, the\nchallenge shifts to how we effectively explore and leverage these resources to\nstudy molecular properties. This paper presents an active learning approach for\nmolecular discovery using Deep Kernel Learning (DKL), demonstrated on the QM9\ndataset. DKL links structural embeddings directly to properties, creating\norganized latent spaces that prioritize relevant property information. By\niteratively recalculating embedding vectors in alignment with target\nproperties, DKL uncovers concentrated maxima representing key molecular\nproperties and reveals unexplored regions with potential for innovation. This\napproach underscores DKL's potential in advancing molecular research and\ndiscovery.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.01234v2", "cate": "cs.LG", "date": "2024-03-02", "updated": "2025-07-16", "AI": {"title_translation": "分子性质的主动深度核学习：实现动态结构嵌入", "tldr": "本文提出了一种基于深度核学习（DKL）的主动学习方法，用于分子发现，通过动态结构嵌入来探索和利用分子性质。", "motivation": "随着大量化学身份数据库的可用性增加，挑战是如何有效地探索和利用这些资源来研究分子性质。", "method": "本文提出了一种使用深度核学习（DKL）的主动学习方法，用于分子发现，并在QM9数据集上进行了演示。DKL将结构嵌入直接与性质关联，创建有组织的潜在空间，并迭代地重新计算与目标性质对齐的嵌入向量。", "result": "通过迭代重新计算嵌入向量，DKL揭示了代表关键分子性质的集中最大值，并揭示了具有创新潜力的未探索区域。", "conclusion": "该方法强调了DKL在推进分子研究和发现方面的潜力。", "translation": "随着大量化学身份数据库的日益普及，挑战转向了如何有效探索和利用这些资源来研究分子性质。本文提出了一种使用深度核学习（DKL）进行分子发现的主动学习方法，并在QM9数据集上进行了演示。DKL将结构嵌入直接与性质关联，创建有组织的潜在空间，优先处理相关的性质信息。通过迭代地重新计算与目标性质对齐的嵌入向量，DKL揭示了代表关键分子性质的集中最大值，并揭示了具有创新潜力的未探索区域。这种方法强调了DKL在推进分子研究和发现方面的潜力。", "summary": "本文介绍了一种基于深度核学习（DKL）的主动学习方法，用于分子发现和分子性质研究。该方法通过将结构嵌入直接关联到分子性质，并在QM9数据集上进行验证，能够迭代优化嵌入向量，从而揭示关键分子性质的集中区域以及具有创新潜力的未探索分子空间，展示了DKL在分子研究中的巨大潜力。", "keywords": "主动学习, 深度核学习, 分子性质, 结构嵌入, 分子发现", "comments": "该论文创新性地将主动学习与深度核学习结合，实现了分子结构嵌入的动态调整，从而更有效地探索分子性质空间。这种方法对于加速新材料和药物的发现具有重要意义，尤其是在处理大规模化学数据库时，能够提高探索效率和准确性。"}}
{"id": "2507.12135", "title": "Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement", "authors": ["Junyu Lou", "Xiaorui Zhao", "Kexuan Shi", "Shuhang Gu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.12135v1", "summary": "Deep learning-based bilateral grid processing has emerged as a promising\nsolution for image enhancement, inherently encoding spatial and intensity\ninformation while enabling efficient full-resolution processing through slicing\noperations. However, existing approaches are limited to linear affine\ntransformations, hindering their ability to model complex color relationships.\nMeanwhile, while multi-layer perceptrons (MLPs) excel at non-linear mappings,\ntraditional MLP-based methods employ globally shared parameters, which is hard\nto deal with localized variations. To overcome these dual challenges, we\npropose a Bilateral Grid-based Pixel-Adaptive Multi-layer Perceptron (BPAM)\nframework. Our approach synergizes the spatial modeling of bilateral grids with\nthe non-linear capabilities of MLPs. Specifically, we generate bilateral grids\ncontaining MLP parameters, where each pixel dynamically retrieves its unique\ntransformation parameters and obtain a distinct MLP for color mapping based on\nspatial coordinates and intensity values. In addition, we propose a novel grid\ndecomposition strategy that categorizes MLP parameters into distinct types\nstored in separate subgrids. Multi-channel guidance maps are used to extract\ncategory-specific parameters from corresponding subgrids, ensuring effective\nutilization of color information during slicing while guiding precise parameter\ngeneration. Extensive experiments on public datasets demonstrate that our\nmethod outperforms state-of-the-art methods in performance while maintaining\nreal-time processing capabilities.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.12135v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "学习像素自适应多层感知机用于实时图像增强", "tldr": "本文提出BPAM框架，结合双边网格和像素自适应MLP，克服现有图像增强方法在复杂颜色关系建模和局部变化处理上的限制，实现实时高性能图像增强。", "motivation": "现有基于深度学习的双边网格处理方法仅限于线性仿射变换，难以建模复杂的颜色关系；而传统基于MLP的方法采用全局共享参数，难以处理局部变化。", "method": "本文提出一种基于双边网格的像素自适应多层感知机（BPAM）框架。该方法结合了双边网格的空间建模能力和MLP的非线性映射能力。具体来说，生成包含MLP参数的双边网格，每个像素根据空间坐标和强度值动态获取独特的MLP进行颜色映射。此外，提出了一种新颖的网格分解策略，将MLP参数分类存储在单独的子网格中，并使用多通道引导图从对应子网格中提取特定类别的参数，以确保有效利用颜色信息并引导精确的参数生成。", "result": "在公共数据集上的广泛实验表明，该方法在性能上优于现有最先进的方法，同时保持了实时处理能力。", "conclusion": "本文提出的BPAM框架有效解决了图像增强中复杂颜色关系建模和局部变化的挑战，实现了高性能且实时的图像增强效果。", "translation": "基于深度学习的双边网格处理已成为图像增强的一种有前景的解决方案，它固有地编码空间和强度信息，并通过切片操作实现高效的全分辨率处理。然而，现有方法仅限于线性仿射变换，阻碍了它们建模复杂颜色关系的能力。同时，虽然多层感知机（MLP）擅长非线性映射，但传统的基于MLP的方法采用全局共享参数，难以处理局部变化。为了克服这些双重挑战，我们提出了一种基于双边网格的像素自适应多层感知机（BPAM）框架。我们的方法将双边网格的空间建模与MLP的非线性能力相结合。具体来说，我们生成包含MLP参数的双边网格，其中每个像素根据空间坐标和强度值动态检索其独特的变换参数并获得一个独特的MLP用于颜色映射。此外，我们提出了一种新颖的网格分解策略，将MLP参数分类为存储在不同子网格中的不同类型。多通道引导图用于从相应的子网格中提取特定类别的参数，确保在切片过程中有效利用颜色信息，并指导精确的参数生成。在公共数据集上的广泛实验表明，我们的方法在性能上优于现有最先进的方法，同时保持了实时处理能力。", "summary": "针对现有图像增强方法在复杂颜色关系建模和局部变化处理上的不足，本文提出了一种基于双边网格的像素自适应多层感知机（BPAM）框架。该框架将双边网格的空间建模能力与MLP的非线性映射能力相结合，通过生成包含MLP参数的双边网格，使每个像素能动态获取独特的MLP进行颜色映射。此外，引入了新颖的网格分解策略和多通道引导图，以优化参数生成和利用。实验证明，BPAM在公共数据集上性能优于现有SOTA方法，并能保持实时处理。", "keywords": "图像增强, 双边网格, 多层感知机, 像素自适应, 实时处理", "comments": "该论文创新性地将双边网格与像素自适应多层感知机结合，并引入了独特的网格分解策略，有效解决了传统方法在复杂颜色关系建模和局部变化处理上的局限性，实现了高性能实时图像增强，具有重要的实际应用价值。"}}
{"id": "2507.11055", "title": "Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation", "authors": ["Shuchang Ye", "Usman Naseem", "Mingyuan Meng", "Jinman Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.11055v2", "summary": "Medical language-guided segmentation, integrating textual clinical reports as\nauxiliary guidance to enhance image segmentation, has demonstrated significant\nimprovements over unimodal approaches. However, its inherent reliance on paired\nimage-text input, which we refer to as ``textual reliance\", presents two\nfundamental limitations: 1) many medical segmentation datasets lack paired\nreports, leaving a substantial portion of image-only data underutilized for\ntraining; and 2) inference is limited to retrospective analysis of cases with\npaired reports, limiting its applicability in most clinical scenarios where\nsegmentation typically precedes reporting. To address these limitations, we\npropose ProLearn, the first Prototype-driven Learning framework for\nlanguage-guided segmentation that fundamentally alleviates textual reliance. At\nits core, we introduce a novel Prototype-driven Semantic Approximation (PSA)\nmodule to enable approximation of semantic guidance from textual input. PSA\ninitializes a discrete and compact prototype space by distilling\nsegmentation-relevant semantics from textual reports. Once initialized, it\nsupports a query-and-respond mechanism which approximates semantic guidance for\nimages without textual input, thereby alleviating textual reliance. Extensive\nexperiments on QaTa-COV19, MosMedData+ and Kvasir-SEG demonstrate that ProLearn\noutperforms state-of-the-art language-guided methods when limited text is\navailable.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.11055v2", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "通过原型驱动的语义近似缓解医学语言引导分割中的文本依赖", "tldr": "ProLearn框架通过原型驱动的语义近似模块（PSA）解决了医学语言引导分割中对文本输入的过度依赖，从而在文本有限的情况下优于现有方法。", "motivation": "医学语言引导分割虽然优于单模态方法，但其固有的“文本依赖”存在两个主要限制：1) 许多医学分割数据集缺乏配对报告，导致大量仅图像数据未被充分利用；2) 推理仅限于回顾性分析，限制了其在分割通常先于报告的临床场景中的适用性。", "method": "本文提出了ProLearn，第一个用于语言引导分割的原型驱动学习框架，旨在从根本上缓解文本依赖。其核心是引入了一种新颖的原型驱动语义近似（PSA）模块，该模块通过从文本报告中提取与分割相关的语义来初始化一个离散紧凑的原型空间。一旦初始化，PSA支持一种查询响应机制，为没有文本输入的图像近似生成语义指导。", "result": "在QaTa-COV19、MosMedData+和Kvasir-SEG数据集上的大量实验表明，在可用文本有限的情况下，ProLearn优于最先进的语言引导方法。", "conclusion": "ProLearn框架通过原型驱动的语义近似模块成功缓解了医学语言引导分割中的文本依赖问题，使其在数据和临床应用方面更具普适性，尤其是在文本数据有限的场景下表现出色。", "translation": "医学语言引导分割将文本临床报告作为辅助指导以增强图像分割，与单模态方法相比已显示出显著改进。然而，其固有的对配对图像-文本输入的依赖，我们称之为“文本依赖”，带来了两个基本限制：1) 许多医学分割数据集缺乏配对报告，导致大量仅图像数据未被充分利用进行训练；2) 推理仅限于对配对报告病例的回顾性分析，限制了其在大多数临床场景中的适用性，因为在这些场景中分割通常先于报告。为了解决这些限制，我们提出了ProLearn，这是第一个用于语言引导分割的原型驱动学习框架，它从根本上缓解了文本依赖。其核心是，我们引入了一种新颖的原型驱动语义近似（PSA）模块，以实现对文本输入语义指导的近似。PSA通过从文本报告中提取与分割相关的语义来初始化一个离散紧凑的原型空间。一旦初始化，它支持一种查询响应机制，为没有文本输入的图像近似生成语义指导，从而缓解文本依赖。在QaTa-COV19、MosMedData+和Kvasir-SEG上的大量实验表明，在文本有限的情况下，ProLearn优于最先进的语言引导方法。", "summary": "本文提出了ProLearn，一个原型驱动学习框架，旨在解决医学语言引导分割中对配对图像-文本输入的“文本依赖”问题。该框架引入了原型驱动语义近似（PSA）模块，通过从文本报告中提取语义来构建原型空间，从而为缺乏文本输入的图像提供语义指导。实验证明，ProLearn在文本数据有限的情况下，其性能优于现有的语言引导分割方法，提高了模型的普适性和临床适用性。", "keywords": "医学图像分割, 语言引导, 文本依赖, 原型驱动, 语义近似", "comments": "ProLearn的创新之处在于其原型驱动语义近似（PSA）模块，它通过学习和近似文本语义指导，有效解决了医学图像分割中文本报告稀缺和推理场景限制的关键问题。这一方法显著提高了语言引导分割模型的实用性和泛化能力，尤其是在数据受限的医疗领域具有重要意义。"}}
{"id": "2507.11621", "title": "HCOMC: A Hierarchical Cooperative On-Ramp Merging Control Framework in Mixed Traffic Environment on Two-Lane Highways", "authors": ["Tianyi Wang", "Yangyang Wang", "Jie Pan", "Junfeng Jiao", "Christian Claudel"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages, 2 figures, 3 tables, accepted for IEEE International Conference on Intelligent Transportation Systems (ITSC) 2025", "url": "http://arxiv.org/abs/2507.11621v1", "summary": "Highway on-ramp merging areas are common bottlenecks to traffic congestion\nand accidents. Currently, a cooperative control strategy based on connected and\nautomated vehicles (CAVs) is a fundamental solution to this problem. While CAVs\nare not fully widespread, it is necessary to propose a hierarchical cooperative\non-ramp merging control (HCOMC) framework for heterogeneous traffic flow on\ntwo-lane highways to address this gap. This paper extends longitudinal\ncar-following models based on the intelligent driver model and lateral\nlane-changing models using the quintic polynomial curve to account for\nhuman-driven vehicles (HDVs) and CAVs, comprehensively considering human\nfactors and cooperative adaptive cruise control. Besides, this paper proposes a\nHCOMC framework, consisting of a hierarchical cooperative planning model based\non the modified virtual vehicle model, a discretionary lane-changing model\nbased on game theory, and a multi-objective optimization model using the\nelitist non-dominated sorting genetic algorithm to ensure the safe, smooth, and\nefficient merging process. Then, the performance of our HCOMC is analyzed under\ndifferent traffic densities and CAV penetration rates through simulation. The\nfindings underscore our HCOMC's pronounced comprehensive advantages in\nenhancing the safety of group vehicles, stabilizing and expediting merging\nprocess, optimizing traffic efficiency, and economizing fuel consumption\ncompared with benchmarks.", "comment": "7 pages, 2 figures, 3 tables, accepted for IEEE International\n  Conference on Intelligent Transportation Systems (ITSC) 2025", "pdf_url": "http://arxiv.org/pdf/2507.11621v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "HCOMC：一种双车道高速公路混合交通环境下分层协作式匝道合流控制框架", "tldr": "该论文提出了一种名为HCOMC的分层协作式匝道合流控制框架，用于双车道高速公路的混合交通环境（人类驾驶车辆和自动驾驶车辆）。通过仿真分析，HCOMC在提高车辆安全性、稳定和加速合流过程、优化交通效率以及节省燃油消耗方面表现出显著的综合优势。", "motivation": "高速公路匝道合流区域是交通拥堵和事故的常见瓶颈。当前基于网联和自动驾驶车辆（CAVs）的协作控制策略是解决该问题的基本方案，但在CAVs尚未完全普及的情况下，有必要为双车道高速公路上的异构交通流提出一种分层协作式匝道合流控制（HCOMC）框架，以弥补这一空白。", "method": "本文扩展了基于智能驾驶模型的纵向跟驰模型和使用五次多项式曲线的横向换道模型，以同时考虑人类驾驶车辆（HDVs）和CAVs，并综合考虑了人为因素和协作式自适应巡航控制。此外，本文提出了一个HCOMC框架，该框架由基于修正虚拟车辆模型的分层协作规划模型、基于博弈论的自由换道模型以及使用精英非支配排序遗传算法的多目标优化模型组成，以确保合流过程的安全、平稳和高效。然后，通过仿真分析了HCOMC在不同交通密度和CAV渗透率下的性能。", "result": "研究结果表明，与基准方法相比，HCOMC在提高车队安全性、稳定和加速合流过程、优化交通效率以及节省燃油消耗方面具有显著的综合优势。", "conclusion": "本文提出的HCOMC框架有效解决了混合交通下匝道合流的挑战，在安全性、效率和燃油经济性方面表现出卓越的性能。", "translation": "高速公路匝道合流区域是交通拥堵和事故的常见瓶颈。目前，基于网联和自动驾驶车辆（CAVs）的协作控制策略是解决该问题的基本方案。在CAVs尚未完全普及的情况下，有必要为双车道高速公路上的异构交通流提出一种分层协作式匝道合流控制（HCOMC）框架，以弥补这一空白。本文扩展了基于智能驾驶模型的纵向跟驰模型和使用五次多项式曲线的横向换道模型，以同时考虑人类驾驶车辆（HDVs）和CAVs，并综合考虑了人为因素和协作式自适应巡航控制。此外，本文提出了一个HCOMC框架，该框架由基于修正虚拟车辆模型的分层协作规划模型、基于博弈论的自由换道模型以及使用精英非支配排序遗传算法的多目标优化模型组成，以确保合流过程的安全、平稳和高效。然后，通过仿真分析了HCOMC在不同交通密度和CAV渗透率下的性能。研究结果表明，与基准方法相比，HCOMC在提高车队安全性、稳定和加速合流过程、优化交通效率以及节省燃油消耗方面具有显著的综合优势。", "summary": "本论文提出了一种名为HCOMC的分层协作式控制框架，旨在解决双车道高速公路混合交通环境下（包含人类驾驶车辆和自动驾驶车辆）的匝道合流问题。该框架整合了扩展的车辆模型、基于修正虚拟车辆模型的分层协作规划模型、基于博弈论的自由换道模型以及使用精英非支配排序遗传算法的多目标优化模型。仿真结果表明，HCOMC在提升合流安全性、稳定性、交通效率和燃油经济性方面，相较于现有方法展现出显著优势。", "keywords": "HCOMC, 混合交通, 匝道合流, 协作控制, 交通效率", "comments": "该论文的创新之处在于为混合交通流中的匝道合流区域开发了一个分层协作控制框架，特别是在自动驾驶车辆尚未完全普及的过渡时期，这具有重要的现实意义。它综合运用了多种先进模型和优化算法，以全面提升交通流的安全性、效率和经济性。"}}
{"id": "2507.12265", "title": "FastReChain: Highly Responsive and Low-Overhead Centralized Route Scheduling in Clos Datacenter Networks", "authors": ["Zihan Zhu", "Dongchao Wu", "Zhanbang Zhang", "Jian Yang"], "categories": ["cs.NI", "cs.DS"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12265v1", "summary": "Ever since Clos topologies were used in datacenter networks (DCNs), a\npractical centralized scheduling algorithm that supports dynamic scheduling has\nbeen absent. The introduction of optical switches in DCNs as a future-proof\nsolution exacerbates this problem due to several properties of optical\nswitches, such as the fact that they are generally bufferless and therefore\nrely on centralized scheduling, and that they have long switching times and\ntherefore require the number of rearrangements to be minimized.\n  In this paper, we propose a centralized scheduling algorithm that achieves\ntheoretical maximum throughput even in one-rate bidirectional Clos networks,\nwhile producing schemes with near-minimal numbers of rearrangements. It is the\nonly algorithm that directly supports bidirectional Clos networks and has a\ntime efficiency high enough to support dynamic scheduling to date. For static\nminimal rewiring, its running time ranges from a fraction to a few hundredths\nof other algorithms, and the number of rearrangements has also been steadily\nimproved, allowing for more frequent adjustments and less impact on ongoing\ncommunications. In addition, the algorithm is very flexible and can support\nvarious functional requirements in real-world environments. We achieve this\nresult through the replacement chain concept and bitset optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12265v1", "cate": "cs.NI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "FastReChain：Clos数据中心网络中高响应、低开销的集中式路由调度", "tldr": "本文提出了FastReChain，一种用于Clos数据中心网络的集中式调度算法，特别适用于光交换机，即使在单速率双向Clos网络中也能实现理论最大吞吐量和接近最小的重排次数，同时具有高时间效率，支持动态调度和双向网络。", "motivation": "自Clos拓扑结构应用于数据中心网络（DCNs）以来，一直缺乏支持动态调度的实用集中式调度算法。光交换机的引入（无缓冲、切换时间长，需要最小化重排）进一步加剧了这一问题。", "method": "提出了一种集中式调度算法，通过“替换链概念”（replacement chain concept）和“位集优化”（bitset optimization）实现。", "result": "在单速率双向Clos网络中实现理论最大吞吐量，并产生接近最小重排次数的方案。是唯一直接支持双向Clos网络且时间效率高到足以支持动态调度的算法。对于静态最小重布线，其运行时间是其他算法的几分之一到百分之几，重排次数也得到稳定改进。", "conclusion": "所提出的FastReChain算法为Clos数据中心网络中的集中式路由调度提供了一个高效、灵活且实用的解决方案，解决了动态调度和光交换机带来的关键挑战。", "translation": "自Clos拓扑结构被应用于数据中心网络（DCNs）以来，一直缺乏一种支持动态调度的实用集中式调度算法。光交换机作为一种面向未来的解决方案引入DCNs，由于其无缓冲、切换时间长且因此需要最小化重排次数等特性，加剧了这一问题。\n在本文中，我们提出了一种集中式调度算法，即使在单速率双向Clos网络中也能实现理论最大吞吐量，同时产生接近最小重排次数的方案。它是迄今为止唯一直接支持双向Clos网络且时间效率高到足以支持动态调度的算法。对于静态最小重布线，其运行时间是其他算法的几分之一到百分之几，并且重排次数也得到了稳定改进，从而允许更频繁的调整并减少对正在进行的通信的影响。此外，该算法非常灵活，可以支持实际环境中的各种功能要求。我们通过替换链概念和位集优化实现了这一结果。", "summary": "本文介绍了FastReChain，一种用于Clos数据中心网络的新型集中式调度算法，专门设计用于解决动态调度和光交换机带来的挑战。它在双向Clos网络中实现了理论最大吞吐量和接近最小的重排次数。FastReChain展现出比现有方法显著更高的时间效率，通过“替换链概念”和“位集优化”实现了动态调度并支持各种功能需求。", "keywords": "Clos网络, 集中式调度, 数据中心网络, 光交换机, FastReChain", "comments": "该论文解决了数据中心网络管理中的一个关键空白，特别是在光交换机日益普及的背景下。其对高响应性、低开销和最小化重排的关注是创新的，直接解决了当前系统的实际限制。声称在实现理论最大吞吐量的同时具有高时间效率并支持双向网络，使其成为一项重要的贡献。"}}
{"id": "2507.11568", "title": "La Última Frontera de La Filosofía: Hacia una Síntesis de La Ética del Futuro a Largo Plazo, el Riesgo Existencial y la Ontología Posthumana", "authors": ["Santos E. Moreta Reyes"], "categories": ["physics.soc-ph", "cs.CY", "physics.hist-ph"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      14 paginas, in Spanish language. sin figuras. Articulo en español con resumen y titulo en ingles. Este ensayo interdisciplinario sintetiza el largoplacismo (longtermism), el riesgo existencial y la filosofía posthumanista para articular una agenda de investigación para una filosofía prospectiva. Dirigido tanto a audiencias académicas como al publico general", "url": "http://arxiv.org/abs/2507.11568v1", "summary": "Humanity's unprecedented technological capacity and concurrent existential\nrisks reveal a critical lacuna in the philosophical tradition: the absence of a\nsystematic framework for the long-term future. This article argues that\nformulating such a framework is the central ethical imperative of our era. To\ndefend this thesis, it synthesizes the normative ethics of Hans Jonas and Derek\nParfit with the analytical framework of Nick Bostrom's work on existential risk\nand longtermism. The analysis further addresses the ontological challenge posed\nby posthumanism to the human 'subject' and explores the functional role of a\nsecular cosmic purpose in motivating long-term action. The paper's main\ncontribution is the articulation of a synthetic research agenda for a\nprospective philosophy, one that integrates axiology, risk management, and\nontology to guide humanity through its perilous technological adolescence.", "comment": "14 paginas, in Spanish language. sin figuras. Articulo en espa\\~nol\n  con resumen y titulo en ingles. Este ensayo interdisciplinario sintetiza el\n  largoplacismo (longtermism), el riesgo existencial y la filosof\\'ia\n  posthumanista para articular una agenda de investigaci\\'on para una\n  filosof\\'ia prospectiva. Dirigido tanto a audiencias acad\\'emicas como al\n  publico general", "pdf_url": "http://arxiv.org/pdf/2507.11568v1", "cate": "physics.soc-ph", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "哲学的最后前沿：迈向长期未来伦理、生存风险与后人类本体论的综合", "tldr": "人类面临技术进步带来的生存风险，哲学缺乏长期未来框架。本文提出构建此框架是时代伦理要务，并综合汉斯·乔纳斯、德里克·帕菲特伦理学与尼克·博斯特罗姆的生存风险和长期主义，探讨后人类本体论挑战与世俗宇宙目的，旨在为人类的危险技术青春期提供综合性研究议程。", "motivation": "人类空前的技术能力和随之而来的生存风险，揭示了哲学传统中一个关键的缺失：缺乏一个针对长期未来的系统性框架。文章认为，制定这样一个框架是我们时代的核心伦理要务。", "method": "文章综合了汉斯·乔纳斯（Hans Jonas）和德里克·帕菲特（Derek Parfit）的规范伦理学，以及尼克·博斯特罗姆（Nick Bostrom）关于生存风险和长期主义的分析框架。此外，还探讨了后人类主义对人类“主体”造成的本体论挑战，并探索了世俗宇宙目的在激励长期行动中的功能作用。", "result": "论文的主要贡献是阐明了一个前瞻性哲学的综合研究议程，该议程整合了价值论、风险管理和本体论，以指导人类度过其危险的技术青春期。", "conclusion": "文章的结论是，为长期未来制定一个系统性框架是当今时代的核心伦理要务，并且需要一个整合价值论、风险管理和本体论的综合研究议程来指导人类。", "translation": "人类前所未有的技术能力以及随之而来的生存风险，揭示了哲学传统中的一个关键缺失：缺乏一个针对长期未来的系统性框架。本文认为，制定这样一个框架是我们时代的核心伦理要务。为了捍卫这一论点，文章综合了汉斯·乔纳斯（Hans Jonas）和德里克·帕菲特（Derek Parfit）的规范伦理学，以及尼克·博斯特罗姆（Nick Bostrom）关于生存风险和长期主义的分析框架。分析还进一步探讨了后人类主义对人类“主体”造成的本体论挑战，并探索了世俗宇宙目的在激励长期行动中的功能作用。论文的主要贡献是阐明了一个前瞻性哲学的综合研究议程，该议程整合了价值论、风险管理和本体论，以指导人类度过其危险的技术青春期。", "summary": "本文指出，鉴于人类当前的技术能力和伴随的生存风险，哲学传统中缺乏一个针对长期未来的系统性框架。作者认为，构建这一框架是当代的关键伦理任务。为此，论文综合了汉斯·乔纳斯和德里克·帕菲特的规范伦理学，以及尼克·博斯特罗姆关于生存风险和长期主义的理论。文章还探讨了后人类主义带来的本体论挑战，并分析了世俗宇宙目的对长期行动的激励作用。最终，本文提出了一个整合价值论、风险管理和本体论的综合性研究议程，旨在引导人类应对技术发展带来的危险。", "keywords": "长期未来伦理, 生存风险, 后人类本体论, 综合研究议程, 长期主义", "comments": "这篇论文的创新之处在于它试图弥合当前哲学与人类长期未来挑战之间的鸿沟，特别是将传统伦理学与生存风险及长期主义相结合。其重要性在于强调了为应对技术进步带来的潜在危险，构建一个跨学科的哲学框架的紧迫性。通过整合价值论、风险管理和本体论，该研究议程为哲学提供了一个实际且前瞻性的方向。"}}
{"id": "2407.20814", "title": "Embracing Fairness in Consumer Electricity Markets using an Automatic Market Maker", "authors": ["Shaun Sweeney", "Chris King", "Mark O'Malley", "Robert Shorten"], "categories": ["eess.SY", "cs.GT", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Invalid technical approach - this could mislead future researchers, will resubmit a new version when fixed", "url": "http://arxiv.org/abs/2407.20814v2", "summary": "As consumer flexibility becomes expected, it is important that the market\nmechanisms which attain that flexibility are perceived as fair. We set out\nfairness issues in energy markets today, and propose a market design to address\nthem. Consumption is categorised as either essential or flexible with different\nprices and reliability levels for each. Prices are generated by an Automatic\nMarket Maker (AMM) based on instantaneous scarcity and resource is allocated\nusing a novel Fair Play algorithm. We empirically show the performance of the\nsystem over 1 year for 101 UK households and benchmark its performance against\nmore classical approaches.", "comment": "Invalid technical approach - this could mislead future researchers,\n  will resubmit a new version when fixed", "pdf_url": "http://arxiv.org/pdf/2407.20814v2", "cate": "eess.SY", "date": "2024-07-30", "updated": "2025-07-16", "AI": {"title_translation": "在消费者电力市场中利用自动做市商实现公平", "tldr": "本文提出了一种新的电力市场设计，通过自动做市商和公平算法来解决消费者电力市场中的公平性问题，并在一年的实证研究中验证了其性能。", "motivation": "随着消费者灵活性的日益普及，确保获取这种灵活性的市场机制被认为是公平的至关重要。目前能源市场存在公平性问题，因此需要设计新的市场来解决这些问题。", "method": "将电力消费分为必需型和灵活型，并为每种类型设置不同的价格和可靠性水平。价格由基于瞬时稀缺性的自动做市商（AMM）生成，资源分配则采用一种新颖的“公平博弈”算法。", "result": "通过对101个英国家庭进行为期一年的实证研究，展示了该系统的性能，并将其与更经典的方法进行了比较。", "conclusion": "论文提出了一种新的市场设计，能够有效解决消费者电力市场中的公平性问题，并在实际应用中表现出良好的性能。", "translation": "随着消费者灵活性的日益普及，确保获取这种灵活性的市场机制被认为是公平的至关重要。我们阐述了当今能源市场中存在的公平性问题，并提出了一种市场设计来解决这些问题。消费被分为必需型和灵活型，每种类型都有不同的价格和可靠性水平。价格由基于瞬时稀缺性的自动做市商（AMM）生成，资源分配则采用一种新颖的“公平博弈”（Fair Play）算法。我们通过对101个英国家庭进行为期一年的实证研究，展示了该系统的性能，并将其与更经典的方法进行了比较。", "summary": "本文针对消费者电力市场中的公平性问题，提出了一种创新的市场设计。该设计将消费分为必需型和灵活型，并利用自动做市商（AMM）根据瞬时稀缺性生成价格，同时采用一种新颖的“公平博弈”算法进行资源分配。通过对英国家庭的实证研究，验证了该系统在提高市场公平性方面的有效性，并优于传统方法。", "keywords": "消费者电力市场, 公平性, 自动做市商, 能源分配, 公平博弈算法", "comments": "本文的创新点在于提出了结合自动做市商（AMM）和“公平博弈”算法的市场设计，旨在解决消费者电力市场中的公平性问题。这种方法通过细分消费类型和动态定价，为实现更公平的能源分配提供了新的思路。其重要性在于，在能源转型和消费者参与度提高的背景下，公平性是市场机制成功运行的关键。未来的研究可以进一步探讨其在大规模部署中的可扩展性和鲁棒性。"}}
{"id": "2507.11662", "title": "Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification", "authors": ["Moises Andrade", "Joonhyuk Cha", "Brandon Ho", "Vriksha Srihari", "Karmesh Yadav", "Zsolt Kira"], "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Our code and data are publicly available at this https URL", "url": "http://arxiv.org/abs/2507.11662v1", "summary": "Verifiers -- functions assigning rewards to agent behavior -- have been key\nfor AI progress in domains like math and board games. However, extending these\ngains to domains without clear-cut success criteria (e.g.,computer use) remains\na challenge: while humans can recognize suitable outcomes, translating this\nintuition into scalable rules is non-trivial. Multimodal Large Language\nModels(MLLMs) emerge as a promising solution, given their world knowledge,\nhuman-preference alignment, and reasoning skills. We evaluate MLLMs as\nverifiers of agent trajectories across web navigation, computer use, and\nrobotic manipulation, and identify a critical limitation: agreement bias, a\nstrong tendency for MLLMs to favor information in their context window, often\ngenerating chains of thought to rationalize flawed behavior. This bias is\npervasive across models, resilient to test-time scaling, and can impact several\nmethods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs\ndespite MLLMs showing strong, human-aligned priors on desired behavior. To\naddress this, we propose Self-Grounded Verification (SGV), a lightweight method\nthat enables more effective use of MLLMs' knowledge and reasoning by harnessing\ntheir own sampling mechanisms via unconditional and conditional generation. SGV\noperates in two steps: first, the MLLM is elicited to retrieve broad priors\nabout task completion, independent of the data under evaluation. Then,\nconditioned on self-generated priors, it reasons over and evaluates a candidate\ntrajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in\naccuracy and failure detection rates, and can perform real-time supervision of\nheterogeneous agents, boosting task completion of a GUI specialist in OSWorld,\na diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting\na new state of the art on the benchmark, surpassing the previous best by 48%.", "comment": "Our code and data are publicly available at\n  https://github.com/mshalimay/mllm-verifiers-abias-sgv", "pdf_url": "http://arxiv.org/pdf/2507.11662v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "让我们分两步思考：通过自我基础验证缓解多模态大语言模型中的一致性偏见", "tldr": "本文提出了一种名为自我基础验证（SGV）的两步法，以缓解多模态大语言模型（MLLMs）在作为验证器时普遍存在的一致性偏见，显著提高了其准确性和故障检测率，并在多个基准测试中达到了新的最先进水平。", "motivation": "在缺乏明确成功标准的领域（如计算机使用）中，将验证器的优势扩展到AI领域仍面临挑战。多模态大语言模型（MLLMs）虽然有潜力，但存在一个关键限制：一致性偏见，即MLLMs倾向于偏爱上下文窗口中的信息，并常为有缺陷的行为寻找理由。这种偏见普遍存在，且影响使用MLLMs作为评估器的方法。", "method": "本文提出了自我基础验证（SGV）方法来解决一致性偏见。SGV分两步操作：首先，MLLM被引导独立于评估数据，检索关于任务完成的广泛先验知识（无条件生成）。然后，在这些自我生成的先验知识的条件下，MLLM对候选轨迹进行推理和评估（条件生成）。", "result": "通过SGV增强后，MLLM验证器在准确性和故障检测率方面提高了多达20个百分点。SGV能够实时监督异构代理，提高了OSWorld中GUI专家的任务完成率、robomimic中扩散策略的任务完成率以及VisualWebArena中ReAct代理的任务完成率，在基准测试中创造了新的最先进水平，超越此前最佳成绩48%。", "conclusion": "自我基础验证（SGV）有效缓解了多模态大语言模型（MLLMs）作为验证器时的一致性偏见，使其能更有效地利用知识和推理能力，从而显著提升了性能，并在多项任务中取得了突破性进展。", "translation": "验证器——为代理行为分配奖励的函数——在数学和棋盘游戏等AI领域取得了关键进展。然而，将这些成果扩展到没有明确成功标准的领域（例如计算机使用）仍然是一个挑战：尽管人类可以识别合适的成果，但将这种直觉转化为可扩展的规则并非易事。鉴于其世界知识、人类偏好对齐和推理技能，多模态大语言模型（MLLMs）成为一种有前途的解决方案。我们评估了MLLMs作为网络导航、计算机使用和机器人操作中代理轨迹的验证器，并发现了一个关键限制：一致性偏见，即MLLMs强烈倾向于偏爱其上下文窗口中的信息，经常生成思维链来合理化有缺陷的行为。这种偏见普遍存在于各种模型中，对测试时规模化具有弹性，并可能影响使用MLLMs作为评估器的几种方法（例如数据过滤）。值得注意的是，尽管MLLMs在期望行为上表现出强大且与人类对齐的先验知识，但这种偏见仍然发生。为了解决这个问题，我们提出了自我基础验证（SGV），这是一种轻量级方法，通过利用MLLMs自身的采样机制（通过无条件和条件生成），使其能够更有效地利用其知识和推理能力。SGV分两步操作：首先，MLLM被引导独立于评估数据，检索关于任务完成的广泛先验知识。然后，在自我生成的先验知识的条件下，它对候选轨迹进行推理和评估。通过SGV增强后，MLLM验证器在准确性和故障检测率方面显示出高达20个百分点的提升，并且可以对异构代理进行实时监督，提高了OSWorld中GUI专家的任务完成率、robomimic中扩散策略的任务完成率以及VisualWebArena中ReAct代理的任务完成率——在基准测试中创造了新的最先进水平，超越此前最佳成绩48%。", "summary": "本文研究了多模态大语言模型（MLLMs）作为代理行为验证器的能力，并发现它们普遍存在一致性偏见，即倾向于偏爱上下文信息并合理化错误行为。为解决此问题，作者提出了自我基础验证（SGV）方法。SGV通过两步过程：首先让MLLM独立生成任务先验知识，然后基于这些先验知识评估候选轨迹。实验结果表明，SGV显著提高了MLLM验证器的准确性和故障检测率，并在多个复杂任务（如网页导航和机器人操作）中达到了新的最先进水平，证明了其在有效利用MLLM知识和推理能力方面的潜力。", "keywords": "多模态大语言模型, 一致性偏见, 自我基础验证, 验证器, 任务完成", "comments": "这项研究的创新之处在于识别并有效缓解了MLLMs在作为验证器时普遍存在的一致性偏见，这对于将MLLMs应用于需要可靠评估的复杂开放域任务至关重要。SGV提出的“两步思考”方法，即先生成独立先验再进行条件评估，是一种巧妙且轻量级的策略，能更充分地发挥MLLMs的内在知识和推理能力。其在多个异构代理任务中取得的显著性能提升，特别是48%的SOTA突破，凸显了该方法的实用性和重要性。"}}
{"id": "2507.12431", "title": "Design and Development of an Automated Contact Angle Tester (ACAT) for Surface Wettability Measurement", "authors": ["Connor Burgess", "Kyle Douin", "Amir Kordijazi"], "categories": ["cs.RO", "physics.ins-det"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      14 pages, 4 figures", "url": "http://arxiv.org/abs/2507.12431v1", "summary": "The Automated Contact Angle Tester (ACAT) is a fully integrated robotic work\ncell developed to automate the measurement of surface wettability on 3D-printed\nmaterials. Designed for precision, repeatability, and safety, ACAT addresses\nthe limitations of manual contact angle testing by combining programmable\nrobotics, precise liquid dispensing, and a modular software-hardware\narchitecture. The system is composed of three core subsystems: (1) an\nelectrical system including power, control, and safety circuits compliant with\nindustrial standards such as NEC 70, NFPA 79, and UL 508A; (2) a software\ncontrol system based on a Raspberry Pi and Python, featuring fault detection,\nGPIO logic, and operator interfaces; and (3) a mechanical system that includes\na 3-axis Cartesian robot, pneumatic actuation, and a precision liquid dispenser\nenclosed within a safety-certified frame. The ACAT enables high-throughput,\nautomated surface characterization and provides a robust platform for future\nintegration into smart manufacturing and materials discovery workflows. This\npaper details the design methodology, implementation strategies, and system\nintegration required to develop the ACAT platform.", "comment": "14 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.12431v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "用于表面润湿性测量的自动化接触角测试仪（ACAT）的设计与开发", "tldr": "ACAT是一种自动化机器人工作单元，用于测量3D打印材料的表面润湿性，旨在提高精度、重复性和安全性，解决手动测试的局限性。", "motivation": "手动接触角测试存在局限性，需要一种自动化、高精度、高重复性且安全的系统来测量3D打印材料的表面润湿性。", "method": "ACAT系统结合了可编程机器人、精确液体分配和模块化的软硬件架构。它由三个核心子系统组成：符合工业标准的电气系统（NEC 70, NFPA 79, UL 508A）、基于Raspberry Pi和Python的软件控制系统（具有故障检测、GPIO逻辑和操作员界面），以及包含3轴笛卡尔机器人、气动执行器和精密液体分配器的机械系统，并封闭在安全认证框架内。", "result": "ACAT实现了高通量、自动化的表面表征，并提供了一个强大的平台，可用于未来集成到智能制造和材料发现工作流程中。", "conclusion": "ACAT平台的设计、实施和系统集成细节被详细阐述，该系统成功地实现了自动化、高通量和可靠的表面润湿性测量，并为未来的智能制造和材料发现提供了基础。", "translation": "自动化接触角测试仪（ACAT）是一个完全集成的机器人工作单元，旨在自动化测量3D打印材料的表面润湿性。ACAT的设计注重精度、重复性和安全性，通过结合可编程机器人、精确液体分配和模块化的软硬件架构，解决了手动接触角测试的局限性。该系统由三个核心子系统组成：（1）符合NEC 70、NFPA 79和UL 508A等工业标准的电气系统，包括电源、控制和安全电路；（2）基于Raspberry Pi和Python的软件控制系统，具有故障检测、GPIO逻辑和操作员界面；以及（3）包含3轴笛卡尔机器人、气动执行器和精密液体分配器，并封闭在安全认证框架内的机械系统。ACAT实现了高通量、自动化的表面表征，并为未来集成到智能制造和材料发现工作流程中提供了一个强大的平台。本文详细介绍了开发ACAT平台所需的设计方法、实施策略和系统集成。", "summary": "本文介绍了自动化接触角测试仪（ACAT）的设计与开发，这是一种集成的机器人工作单元，旨在自动化测量3D打印材料的表面润湿性。ACAT通过结合可编程机器人、精确液体分配和模块化软硬件架构，解决了手动测试的限制，并提高了精度、重复性和安全性。系统包含符合工业标准的电气系统、基于树莓派和Python的软件控制系统，以及带有3轴机器人和精密分配器的机械系统。ACAT实现了高通量自动化表面表征，为智能制造和材料发现提供了坚实基础。", "keywords": "接触角测试, 表面润湿性, 自动化, 机器人, 3D打印材料", "comments": "ACAT的创新性在于其将多个工程领域（机器人、电子、软件、机械）集成到一个自动化系统中，以解决传统手动测试的痛点。其模块化设计和对工业标准的遵循确保了系统的鲁棒性和未来可扩展性，使其成为智能制造和材料发现领域的有价值工具。"}}
{"id": "2408.02426", "title": "Boosting Memory Efficiency in Transfer Learning for High-Resolution Medical Image Classification", "authors": ["Yijin Huang", "Pujin Cheng", "Roger Tam", "Xiaoying Tang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.02426v3", "summary": "The success of large-scale pre-trained models has established fine-tuning as\na standard method for achieving significant improvements in downstream tasks.\nHowever, fine-tuning the entire parameter set of a pre-trained model is costly.\nParameter-efficient transfer learning (PETL) has recently emerged as a\ncost-effective alternative for adapting pre-trained models to downstream tasks.\nDespite its advantages, the increasing model size and input resolution present\nchallenges for PETL, as the training memory consumption is not reduced as\neffectively as the parameter usage. In this paper, we introduce Fine-grained\nPrompt Tuning plus (FPT+), a PETL method designed for high-resolution medical\nimage classification, which significantly reduces the training memory\nconsumption compared to other PETL methods. FPT+ performs transfer learning by\ntraining a lightweight side network and accessing pre-trained knowledge from a\nlarge pre-trained model (LPM) through fine-grained prompts and fusion modules.\nSpecifically, we freeze the LPM of interest and construct a learnable\nlightweight side network. The frozen LPM processes high-resolution images to\nextract fine-grained features, while the side network employs corresponding\ndown-sampled low-resolution images to minimize the memory usage. To enable the\nside network to leverage pre-trained knowledge, we propose fine-grained prompts\nand fusion modules, which collaborate to summarize information through the\nLPM's intermediate activations. We evaluate FPT+ on eight medical image\ndatasets of varying sizes, modalities, and complexities. Experimental results\ndemonstrate that FPT+ outperforms other PETL methods, using only 1.03% of the\nlearnable parameters and 3.18% of the memory required for fine-tuning an entire\nViT-B model. Our code is available on https://github.com/YijinHuang/FPT.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.02426v3", "cate": "cs.CV", "date": "2024-08-05", "updated": "2025-07-16", "AI": {"title_translation": "提高高分辨率医学图像分类中迁移学习的内存效率", "tldr": "FPT+是一种参数高效的迁移学习方法，通过训练轻量级侧网络和使用细粒度提示与融合模块，显著降低了高分辨率医学图像分类的内存消耗，同时保持高性能。", "motivation": "现有的大规模预训练模型微调成本高昂，而参数高效迁移学习（PETL）虽然节省参数，但在处理高分辨率图像时内存消耗仍是挑战，未能有效降低。", "method": "本文提出FPT+，一种专为高分辨率医学图像分类设计的PETL方法。FPT+通过训练一个轻量级侧网络，并通过细粒度提示和融合模块从冻结的大型预训练模型（LPM）中获取知识。具体来说，冻结的LPM处理高分辨率图像以提取细粒度特征，而侧网络则使用降采样的低分辨率图像以最小化内存使用。细粒度提示和融合模块协同工作，汇总LPM中间激活的信息。", "result": "FPT+在八个医学图像数据集上进行了评估，结果表明它优于其他PETL方法，并且仅使用微调整个ViT-B模型所需可学习参数的1.03%和内存的3.18%。", "conclusion": "FPT+显著提高了高分辨率医学图像分类中迁移学习的内存效率，同时保持了卓越的性能。", "translation": "大规模预训练模型的成功使得微调成为在下游任务中取得显著改进的标准方法。然而，微调预训练模型的整个参数集成本高昂。参数高效迁移学习（PETL）最近作为一种经济高效的替代方案出现，用于将预训练模型适应到下游任务。尽管其具有优势，但不断增加的模型大小和输入分辨率给PETL带来了挑战，因为训练内存消耗并未像参数使用那样有效减少。在本文中，我们引入了细粒度提示微调增强版（FPT+），这是一种专为高分辨率医学图像分类设计的PETL方法，与其他PETL方法相比，它显著降低了训练内存消耗。FPT+通过训练一个轻量级侧网络，并通过细粒度提示和融合模块从大型预训练模型（LPM）中访问预训练知识来进行迁移学习。具体来说，我们冻结了目标LPM并构建了一个可学习的轻量级侧网络。冻结的LPM处理高分辨率图像以提取细粒度特征，而侧网络则使用相应的降采样低分辨率图像以最小化内存使用。为了使侧网络能够利用预训练知识，我们提出了细粒度提示和融合模块，它们协同工作，通过LPM的中间激活来汇总信息。我们在八个不同大小、模态和复杂度的医学图像数据集上评估了FPT+。实验结果表明，FPT+优于其他PETL方法，仅使用微调整个ViT-B模型所需可学习参数的1.03%和内存的3.18%。我们的代码可在https://github.com/YijinHuang/FPT上获取。", "summary": "本文提出了一种名为FPT+的参数高效迁移学习（PETL）方法，旨在解决高分辨率医学图像分类中PETL的内存消耗问题。FPT+通过训练一个轻量级侧网络并结合细粒度提示与融合模块，从冻结的大型预训练模型中高效地利用知识。实验证明，FPT+在减少内存和参数使用方面显著优于现有PETL方法，同时在多个医学图像数据集上保持了高性能。", "keywords": "迁移学习, 内存效率, 医学图像分类, 参数高效学习, 提示微调", "comments": "本文的创新点在于其FPT+方法有效地解决了高分辨率医学图像分类中PETL的内存效率问题，通过独特的轻量级侧网络与细粒度提示和融合模块的结合，实现了参数和内存的显著节省，这对于资源受限的医学影像分析领域具有重要意义。"}}
{"id": "2410.16069", "title": "Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context", "authors": ["Maggie Mi", "Aline Villavicencio", "Nafise Sadat Moosavi"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025", "url": "http://arxiv.org/abs/2410.16069v2", "summary": "Human processing of idioms relies on understanding the contextual sentences\nin which idioms occur, as well as language-intrinsic features such as frequency\nand speaker-intrinsic factors like familiarity. While LLMs have shown high\nperformance on idiomaticity detection tasks, this success may be attributed to\nreasoning shortcuts in existing datasets. To this end, we construct a novel,\ncontrolled contrastive dataset designed to test whether LLMs can effectively\nuse context to disambiguate idiomatic meaning. Additionally, we explore how\ncollocational frequency and sentence probability influence model performance.\nOur findings reveal that LLMs often fail to resolve idiomaticity when it is\nrequired to attend to the surrounding context, and that models perform better\non sentences that have higher likelihood. The collocational frequency of\nexpressions also impacts performance. We make our code and dataset publicly\navailable.", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2410.16069v2", "cate": "cs.CL", "date": "2024-10-21", "updated": "2025-07-15", "AI": {"title_translation": "在习语性上掷骰子：LLM如何未能掌握上下文", "tldr": "大型语言模型（LLMs）在理解依赖上下文的习语时表现不佳，其性能受句子可能性和搭配频率影响。", "motivation": "现有的大型语言模型在习语性检测任务上的高表现可能归因于数据集中存在的推理捷径，因此有必要测试LLMs是否能有效利用上下文来消歧习语含义。", "method": "构建了一个新颖的、受控的对比数据集，以测试LLMs使用上下文消歧习语含义的能力。此外，还探究了搭配频率和句子概率对模型性能的影响。", "result": "研究发现，当需要关注周围上下文时，LLMs通常无法解决习语性问题；模型在可能性更高的句子上表现更好；表达的搭配频率也影响性能。", "conclusion": "大型语言模型在处理依赖上下文的习语时存在不足，其性能受到句子可能性和搭配频率的影响。", "translation": "人类对习语的处理依赖于理解习语出现的上下文句子，以及语言内在特征（如频率）和说话者内在因素（如熟悉度）。虽然大型语言模型（LLMs）在习语性检测任务上表现出高水平，但这种成功可能归因于现有数据集中的推理捷径。为此，我们构建了一个新颖的、受控的对比数据集，旨在测试LLMs是否能有效利用上下文来消歧习语含义。此外，我们探讨了搭配频率和句子概率如何影响模型性能。我们的发现表明，当需要关注周围上下文时，LLMs通常无法解决习语性问题，并且模型在可能性更高的句子上表现更好。表达的搭配频率也影响性能。我们公开了代码和数据集。", "summary": "本研究构建了一个新颖的对比数据集，以评估大型语言模型（LLMs）在理解习语时利用上下文的能力。研究发现，LLMs在需要依赖上下文来消歧习语含义时表现不佳，但对高可能性句子表现更好，且搭配频率也会影响其性能。这表明LLMs在习语理解上可能存在深层缺陷，其现有成功可能源于数据集的捷径。", "keywords": "大型语言模型, 习语性, 上下文, 对比数据集, 搭配频率", "comments": "这篇论文通过构建一个受控的对比数据集，揭示了LLMs在习语理解中对上下文处理的局限性，挑战了LLMs在习语检测任务上的现有成功归因。其创新点在于通过严格的实验设计揭示了LLMs并非真正掌握了上下文，而是可能利用了数据集中的统计偏置。这项工作对于理解LLMs的真实能力和未来改进方向具有重要意义。"}}
{"id": "2410.01590", "title": "Active Learning of Deterministic Transducers with Outputs in Arbitrary Monoids", "authors": ["Quentin Aristote"], "categories": ["cs.FL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      28 pages, 3 figures; preprint submitted to Logical Methods in Computer Science; an extended abstract of this work was presented to the 32nd EACSL Annual Conference on Computer Science Logic 2024", "url": "http://arxiv.org/abs/2410.01590v3", "summary": "We study monoidal transducers, transition systems arising as deterministic\nautomata whose transitions also produce outputs in an arbitrary monoid, for\ninstance allowing outputs to commute or to cancel out. We use the categorical\nframework for minimization and learning of Colcombet, Petri\\c{s}an and Stabile\nto recover the notion of minimal transducer recognizing a language, and give\nnecessary and sufficient conditions on the output monoid for this minimal\ntransducer to exist and be unique (up to isomorphism). The categorical\nframework then provides an abstract algorithm for learning it using membership\nand equivalence queries, and we discuss practical aspects of this algorithm's\nimplementation.", "comment": "28 pages, 3 figures; preprint submitted to Logical Methods in\n  Computer Science; an extended abstract of this work was presented to the 32nd\n  EACSL Annual Conference on Computer Science Logic 2024", "pdf_url": "http://arxiv.org/pdf/2410.01590v3", "cate": "cs.FL", "date": "2024-10-02", "updated": "2025-07-16", "AI": {"title_translation": "具有任意幺半群输出的确定性传感器的主动学习", "tldr": "本文研究了幺半群传感器，利用一个范畴框架来恢复最小传感器的概念，给出了其存在和唯一性的条件，并提供了一种抽象的主动学习算法。", "motivation": "研究幺半群传感器，这是一种确定性自动机，其转换在任意幺半群中产生输出，例如允许输出交换或抵消。目标是理解和学习这些系统，并确定其最小化和学习的条件。", "method": "本文使用Colcombet、Petri\\c{s}an和Stabile的范畴框架进行最小化和学习。具体方法包括：恢复识别语言的最小传感器的概念；给出输出幺半群的必要和充分条件，以使此最小传感器存在且唯一；利用范畴框架提供一种使用成员查询和等价查询学习传感器的抽象算法；讨论该算法实现的实际方面。", "result": "本文成功恢复了识别语言的最小传感器的概念；确定了输出幺半群的必要和充分条件，以使最小传感器存在且唯一（同构意义下）；范畴框架提供了一种使用成员查询和等价查询学习最小传感器的抽象算法；并讨论了该算法实现的实际方面。", "conclusion": "通过利用一个范畴框架，本文深入研究了幺半群传感器，成功恢复了最小传感器的概念，确定了其存在和唯一性条件，并提出了一种抽象的主动学习算法，同时讨论了其实现细节，为该领域提供了重要的理论基础和算法指导。", "translation": "我们研究幺半群传感器，它们是确定性自动机，其转换也在任意幺半群中产生输出，例如允许输出交换或抵消。我们使用Colcombet、Petri\\c{s}an和Stabile的范畴框架进行最小化和学习，以恢复识别语言的最小传感器的概念，并给出了输出幺半群的必要和充分条件，以使该最小传感器存在且唯一（在同构意义下）。该范畴框架随后提供了一种使用成员查询和等价查询来学习它的抽象算法，并且我们讨论了该算法实现的实际方面。", "summary": "本文研究了幺半群传感器，这是一种确定性自动机，其转换在任意幺半群中产生输出。通过采用Colcombet、Petri\\c{s}an和Stabile的范畴框架，作者恢复了识别语言的最小传感器的概念，并确定了其存在和唯一性的必要和充分条件。此外，该范畴框架还提出了一种利用成员查询和等价查询的主动学习抽象算法，并探讨了该算法的实际实现问题。", "keywords": "幺半群传感器, 主动学习, 确定性自动机, 范畴框架, 最小化", "comments": "这项工作通过将范畴论引入幺半群传感器的最小化和学习，提供了一个理论上严谨且抽象的框架。确定最小传感器的存在和唯一性条件是重要的理论贡献，而提出抽象的学习算法并讨论其实际实现则展现了其潜在的应用价值，对相关领域的研究具有指导意义。"}}
{"id": "2502.15186", "title": "LUMINA-Net: Low-light Upgrade through Multi-stage Illumination and Noise Adaptation Network for Image Enhancement", "authors": ["Namrah Siddiqua", "Kim Suneung", "Seong-Whan Lee"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures. Accepted to the 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC), Vienna, Austria", "url": "http://arxiv.org/abs/2502.15186v2", "summary": "Low-light image enhancement (LLIE) is a crucial task in computer vision aimed\nat enhancing the visual fidelity of images captured under low-illumination\nconditions. Conventional methods frequently struggle with noise, overexposure,\nand color distortion, leading to significant image quality degradation. To\naddress these challenges, we propose LUMINA-Net, an unsupervised deep learning\nframework that learns adaptive priors from low-light image pairs by integrating\nmulti-stage illumination and reflectance modules. To assist the Retinex\ndecomposition, inappropriate features in the raw image can be removed using a\nsimple self-supervised mechanism. First, the illumination module intelligently\nadjusts brightness and contrast while preserving intricate textural details.\nSecond, the reflectance module incorporates a noise reduction mechanism that\nleverages spatial attention and channel-wise feature refinement to mitigate\nnoise contamination. Through extensive experiments on LOL and SICE datasets,\nevaluated using PSNR, SSIM, and LPIPS metrics, LUMINA-Net surpasses\nstate-of-the-art methods, demonstrating its efficacy in low-light image\nenhancement.", "comment": "6 pages, 4 figures. Accepted to the 2025 IEEE International\n  Conference on Systems, Man, and Cybernetics (SMC), Vienna, Austria", "pdf_url": "http://arxiv.org/pdf/2502.15186v2", "cate": "eess.IV", "date": "2025-02-21", "updated": "2025-07-16", "AI": {"title_translation": "LUMINA-Net：通过多阶段光照和噪声自适应网络进行图像增强的低光升级", "tldr": "LUMINA-Net是一个无监督的深度学习框架，通过多阶段光照和反射模块，有效解决了低光图像增强中噪声、过曝和色彩失真等问题，性能优于现有SOTA方法。", "motivation": "传统低光图像增强方法在处理噪声、过曝和色彩失真时效果不佳，导致图像质量显著下降，因此需要一种更有效的解决方案。", "method": "本文提出了LUMINA-Net，一个无监督的深度学习框架，旨在解决低光图像增强中的挑战。它通过整合多阶段光照和反射模块，从低光图像对中学习自适应先验。该方法利用简单的自监督机制去除原始图像中不合适的特征以辅助Retinex分解。具体地，光照模块智能地调整亮度对比度并保留复杂的纹理细节；反射模块则结合了降噪机制，利用空间注意力和通道特征细化来减轻噪声污染。", "result": "通过在LOL和SICE数据集上进行的广泛实验，并使用PSNR、SSIM和LPIPS指标进行评估，LUMINA-Net超越了现有最先进的方法，证明了其在低光图像增强方面的有效性。", "conclusion": "LUMINA-Net通过其创新的多阶段光照和噪声自适应网络，成功解决了低光图像增强中的关键挑战，并在多个评估指标上显著提升了图像质量，表现出卓越的性能。", "translation": "低光图像增强（LLIE）是计算机视觉中的一项关键任务，旨在提高在低光照条件下捕获图像的视觉保真度。传统方法经常受限于噪声、过曝和色彩失真，导致图像质量显著下降。为了应对这些挑战，我们提出了LUMINA-Net，一个无监督的深度学习框架，它通过整合多阶段光照和反射模块，从低光图像对中学习自适应先验。为了辅助Retinex分解，原始图像中不合适的特征可以通过简单的自监督机制去除。首先，光照模块智能地调整亮度和对比度，同时保留复杂的纹理细节。其次，反射模块结合了降噪机制，利用空间注意力和通道特征细化来减轻噪声污染。通过在LOL和SICE数据集上进行广泛实验，并使用PSNR、SSIM和LPIPS指标进行评估，LUMINA-Net超越了现有最先进的方法，证明了其在低光图像增强方面的有效性。", "summary": "本文提出了LUMINA-Net，一个用于低光图像增强的无监督深度学习框架，旨在解决传统方法中存在的噪声、过曝和色彩失真问题。该网络通过集成多阶段光照和反射模块，从低光图像对中学习自适应先验。其中，光照模块负责亮度对比度调整和细节保留，反射模块则利用空间注意力和通道特征细化实现降噪。实验结果表明，LUMINA-Net在多个数据集上均优于现有最先进方法，有效提升了低光图像的视觉质量。", "keywords": "低光图像增强, 无监督学习, 深度学习, Retinex分解, 噪声适应", "comments": "LUMINA-Net的创新点在于其无监督学习框架和多阶段模块设计，特别是结合了自监督机制来优化Retinex分解，以及利用空间注意力和通道特征细化进行降噪。这种组合有效地解决了低光图像增强中的多重挑战，使其在性能上超越了现有SOTA方法，对于实际应用具有重要意义。"}}
{"id": "2403.02004", "title": "Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities", "authors": ["Rocco Caprio", "Juan Kuntz", "Samuel Power", "Adam M. Johansen"], "categories": ["cs.LG", "math.FA", "math.OC", "stat.CO", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.02004v3", "summary": "We prove non-asymptotic error bounds for particle gradient descent (PGD,\nKuntz et al., 2023), a recently introduced algorithm for maximum likelihood\nestimation of large latent variable models obtained by discretizing a gradient\nflow of the free energy. We begin by showing that the flow converges\nexponentially fast to the free energy's minimizers for models satisfying a\ncondition that generalizes both the log-Sobolev and the Polyak--{\\L}ojasiewicz\ninequalities (LSI and P{\\L}I, respectively). We achieve this by extending a\nresult well-known in the optimal transport literature (that the LSI implies the\nTalagrand inequality) and its counterpart in the optimization literature (that\nthe P{\\L}I implies the so-called quadratic growth condition), and applying the\nextension to our new setting. We also generalize the Bakry--\\'Emery Theorem and\nshow that the LSI/P{\\L}I extension holds for models with strongly concave\nlog-likelihoods. For such models, we further control PGD's discretization error\nand obtain the non-asymptotic error bounds. While we are motivated by the study\nof PGD, we believe that the inequalities and results we extend may be of\nindependent interest.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.02004v3", "cate": "cs.LG", "date": "2024-03-04", "updated": "2025-07-16", "AI": {"title_translation": "粒子梯度下降的误差界，以及对数Sobolev和Talagrand不等式的扩展", "tldr": "本文通过扩展对数Sobolev和Talagrand不等式，为粒子梯度下降（PGD）算法的最大似然估计提供了非渐近误差界。", "motivation": "研究粒子梯度下降（PGD）算法在大型潜在变量模型最大似然估计中的性能，并为其提供非渐近误差界。此外，作者旨在扩展对数Sobolev和Polyak--{\\L}ojasiewicz不等式及其相关结果，这些扩展可能具有独立的理论价值。", "method": "1. 将自由能的梯度流离散化以得到PGD算法。2. 证明在满足推广对数Sobolev不等式（LSI）和Polyak--{\\L}ojasiewicz不等式（P{\\L}I）的条件下，梯度流能以指数速度收敛到自由能的最小值。3. 通过扩展LSI蕴含Talagrand不等式以及P{\\L}I蕴含二次增长条件的已知结果来实现。4. 推广Bakry--Émery定理。5. 对于具有强凹对数似然的模型，进一步控制PGD的离散化误差，从而获得非渐近误差界。", "result": "1. 证明了粒子梯度下降（PGD）的非渐近误差界。2. 证明了在推广LSI和P{\\L}I条件下，梯度流能以指数速度收敛到自由能的最小值。3. 成功扩展了LSI蕴含Talagrand不等式以及P{\\L}I蕴含二次增长条件的理论结果，并将其应用于新设定。4. 推广了Bakry--Émery定理。5. 证明了扩展的LSI/P{\\L}I条件适用于具有强凹对数似然的模型。", "conclusion": "本文为粒子梯度下降（PGD）算法在大型潜在变量模型中的最大似然估计提供了严格的非渐近误差界。通过对对数Sobolev和Talagrand不等式等基本理论的推广，不仅为PGD的收敛性分析奠定了基础，这些扩展的理论结果本身也具有重要的独立研究价值。", "translation": "我们证明了粒子梯度下降（PGD，Kuntz 等人，2023）的非渐近误差界，这是一种通过离散化自由能的梯度流而获得的大型潜在变量模型最大似然估计的最新算法。我们首先证明，对于满足推广对数Sobolev和Polyak--{\\L}ojasiewicz不等式（分别为LSI和P{\\L}I）的模型，梯度流能以指数速度收敛到自由能的最小值。我们通过扩展最优传输文献中众所周知的结果（LSI蕴含Talagrand不等式）及其在优化文献中的对应结果（P{\\L}I蕴含所谓的二次增长条件），并将该扩展应用于我们的新设定来实现这一点。我们还推广了Bakry--Émery定理，并证明LSI/P{\\L}I扩展适用于具有强凹对数似然的模型。对于此类模型，我们进一步控制了PGD的离散化误差并获得了非渐近误差界。虽然我们的动机是研究PGD，但我们相信我们扩展的不等式和结果可能具有独立的兴趣。", "summary": "本文为粒子梯度下降（PGD）算法在大型潜在变量模型最大似然估计中的应用提供了非渐近误差界。研究通过证明自由能梯度流的指数收敛性来实现，这依赖于一个推广了对数Sobolev（LSI）和Polyak--{\\L}ojasiewicz（P{\\L}I）不等式的新条件。作者扩展了LSI蕴含Talagrand不等式和P{\\L}I蕴含二次增长条件的已知结果，并推广了Bakry--Émery定理。这些理论工具被用于控制PGD的离散化误差，并最终为具有强凹对数似然的模型建立了误差界。文中指出，这些扩展的理论结果可能具有独立的学术价值。", "keywords": "粒子梯度下降, 误差界, 对数Sobolev不等式, Talagrand不等式, 最大似然估计", "comments": "本文在理论上做出了重要贡献，通过扩展对数Sobolev、Polyak--{\\L}ojasiewicz和Talagrand不等式以及Bakry--Émery定理，为粒子梯度下降（PGD）的误差分析提供了坚实的基础。其创新之处在于将最优传输和优化领域的经典理论成果进行融合与推广，以解决新算法的收敛性问题。这些理论扩展不仅对PGD算法的理解至关重要，也可能对其他相关的优化和机器学习算法分析产生深远影响。"}}
{"id": "2507.12107", "title": "Non-Adaptive Adversarial Face Generation", "authors": ["Sunpill Kim", "Seunghun Paik", "Chanwoo Hwang", "Minsu Kim", "Jae Hong Seo"], "categories": ["cs.CV", "cs.AI", "cs.CR", "I.2.6; I.5.4; D.4.6; K.6.5; I.4.8"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12107v1", "summary": "Adversarial attacks on face recognition systems (FRSs) pose serious security\nand privacy threats, especially when these systems are used for identity\nverification. In this paper, we propose a novel method for generating\nadversarial faces-synthetic facial images that are visually distinct yet\nrecognized as a target identity by the FRS. Unlike iterative optimization-based\napproaches (e.g., gradient descent or other iterative solvers), our method\nleverages the structural characteristics of the FRS feature space. We figure\nout that individuals sharing the same attribute (e.g., gender or race) form an\nattributed subsphere. By utilizing such subspheres, our method achieves both\nnon-adaptiveness and a remarkably small number of queries. This eliminates the\nneed for relying on transferability and open-source surrogate models, which\nhave been a typical strategy when repeated adaptive queries to commercial FRSs\nare impossible. Despite requiring only a single non-adaptive query consisting\nof 100 face images, our method achieves a high success rate of over 93% against\nAWS's CompareFaces API at its default threshold. Furthermore, unlike many\nexisting attacks that perturb a given image, our method can deliberately\nproduce adversarial faces that impersonate the target identity while exhibiting\nhigh-level attributes chosen by the adversary.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12107v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "非自适应对抗性人脸生成", "tldr": "本文提出了一种非自适应方法来生成对抗性人脸，能够在极少查询次数下以高成功率冒充目标身份，且无需依赖可迁移性。", "motivation": "对抗性攻击对人脸识别系统（FRSs）构成严重的安全和隐私威胁，尤其是在身份验证场景中。现有方法通常依赖迭代优化或可迁移性，这对于商业FRSs并不适用。", "method": "本文提出了一种新颖的方法，利用FRSs特征空间的结构特性，特别是发现共享相同属性的个体形成“属性子球体”。通过利用这些子球体，该方法实现了非自适应性和极少的查询次数，从而避免了对可迁移性和开源代理模型的依赖。它能生成视觉上独特但被FRSs识别为目标身份的对抗性人脸，并能包含攻击者选择的高级属性。", "result": "该方法在AWS的CompareFaces API默认阈值下，仅通过一次包含100张人脸图像的非自适应查询，就实现了超过93%的高成功率。此外，它能有意地生成伪装成目标身份并展现攻击者选择的高级属性的对抗性人脸。", "conclusion": "本文介绍了一种新颖的非自适应对抗性人脸生成方法，通过利用FRSs特征空间的结构特性，以极少的查询次数有效绕过商业FRSs，解决了现有方法的局限性，并允许对属性进行控制。", "translation": "对抗性攻击对人脸识别系统（FRSs）构成严重的安全和隐私威胁，特别是当这些系统用于身份验证时。在本文中，我们提出了一种生成对抗性人脸的新方法——合成的面部图像在视觉上是独特的，但却被FRSs识别为目标身份。与基于迭代优化（例如，梯度下降或其他迭代求解器）的方法不同，我们的方法利用了FRSs特征空间的结构特性。我们发现，共享相同属性（例如，性别或种族）的个体形成一个属性子球体。通过利用这些子球体，我们的方法实现了非自适应性和极少量的查询。这消除了对可迁移性和开源代理模型的依赖，而当对商业FRSs进行重复自适应查询不可能时，这些一直是典型的策略。尽管只需要一次由100张人脸图像组成的非自适应查询，我们的方法在AWS的CompareFaces API默认阈值下实现了超过93%的高成功率。此外，与许多现有攻击扰动给定图像不同，我们的方法可以有意地生成伪装成目标身份同时展现攻击者选择的高级属性的对抗性人脸。", "summary": "本文提出了一种新颖的非自适应对抗性人脸生成方法，旨在欺骗人脸识别系统（FRSs）。与传统的迭代方法不同，该方法利用FRSs特征空间的结构特性，特别是“属性子球体”的概念，以极少的查询次数实现高成功率。该方法无需依赖可迁移性或代理模型，在仅100次非自适应查询的情况下，对AWS的CompareFaces API实现了超过93%的成功率。此外，它还能生成具有攻击者选择的高级属性的对抗性人脸，使其成为一种强大而高效的攻击。", "keywords": "对抗性人脸生成, 人脸识别系统, 非自适应攻击, 特征空间, 属性子球体", "comments": "该论文通过摆脱传统的迭代优化和对可迁移性的依赖，提出了一种创新性的对抗性人脸生成方法。其关键创新在于利用FRSs特征空间的内在结构特性，特别是“属性子球体”的概念。这使得该方法能够进行高效的非自适应攻击，显著减少所需的查询次数，这对于攻击商业黑盒系统至关重要。能够控制生成对抗性人脸的高级属性是另一个显著贡献，为攻击的复杂性及其对身份验证安全性的潜在影响增添了新的维度。对真实世界API（如AWS CompareFaces）的高成功率突显了其实际意义。"}}
{"id": "2501.00691", "title": "Labels Generated by Large Language Models Help Measure People's Empathy in Vitro", "authors": ["Md Rakibul Hasan", "Yue Yao", "Md Zakir Hossain", "Aneesh Krishna", "Imre Rudas", "Shafin Rahman", "Tom Gedeon"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2501.00691v2", "summary": "Large language models (LLMs) have revolutionised many fields, with\nLLM-as-a-service (LLMSaaS) offering accessible, general-purpose solutions\nwithout costly task-specific training. In contrast to the widely studied prompt\nengineering for directly solving tasks (in vivo), this paper explores LLMs'\npotential for in-vitro applications: using LLM-generated labels to improve\nsupervised training of mainstream models. We examine two strategies - (1) noisy\nlabel correction and (2) training data augmentation - in empathy computing, an\nemerging task to predict psychology-based questionnaire outcomes from inputs\nlike textual narratives. Crowdsourced datasets in this domain often suffer from\nnoisy labels that misrepresent underlying empathy. We show that replacing or\nsupplementing these crowdsourced labels with LLM-generated labels, developed\nusing psychology-based scale-aware prompts, achieves statistically significant\naccuracy improvements. Notably, the RoBERTa pre-trained language model (PLM)\ntrained with noise-reduced labels yields a state-of-the-art Pearson correlation\ncoefficient of 0.648 on the public NewsEmp benchmarks. This paper further\nanalyses evaluation metric selection and demographic biases to help guide the\nfuture development of more equitable empathy computing models. Code and\nLLM-generated labels are available at\nhttps://github.com/hasan-rakibul/LLMPathy.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2501.00691v2", "cate": "cs.CL", "date": "2025-01-01", "updated": "2025-07-16", "AI": {"title_translation": "大型语言模型生成的标签有助于体外测量人们的同理心", "tldr": "本文探讨了利用大型语言模型（LLM）生成标签来改进同理心计算中主流模型的监督训练，通过噪声标签校正和数据增强两种策略，实现了显著的准确性提升，并达到了最先进的性能。", "motivation": "传统的众包数据集在同理心计算领域常存在噪声标签，导致无法准确反映真实的同理心。本文旨在探索大型语言模型在“体外”应用中的潜力，即利用其生成的标签来改进主流模型的监督训练，以解决这一问题。", "method": "作者在同理心计算任务中，探索了两种策略：1) 噪声标签校正；2) 训练数据增强。他们使用基于心理学量表感知的提示词生成LLM标签，并用这些标签替换或补充众包标签，进而训练主流模型（如RoBERTa）。", "result": "使用LLM生成的标签替换或补充众包标签，实现了统计学上显著的准确性提升。特别是，通过噪声减少标签训练的RoBERTa预训练语言模型在公共NewsEmp基准测试上达到了0.648的皮尔逊相关系数，为当前最先进水平。文章还分析了评估指标选择和人口统计学偏见。", "conclusion": "大型语言模型生成的标签能够有效提高同理心计算模型的性能，通过噪声标签校正和数据增强策略，可以显著提升模型准确性并达到SOTA水平。此外，研究还强调了未来同理心计算模型开发中评估指标和人口统计学偏见的重要性。", "translation": "大型语言模型（LLMs）已经彻底改变了许多领域，LLM即服务（LLMSaaS）提供了可访问的通用解决方案，无需昂贵的特定任务训练。与广泛研究的直接解决任务（体内）的提示工程不同，本文探索了LLM在体外应用的潜力：使用LLM生成的标签来改进主流模型的监督训练。我们在同理心计算中检验了两种策略——（1）噪声标签校正和（2）训练数据增强。同理心计算是一项新兴任务，旨在根据文本叙述等输入预测基于心理学问卷的结果。该领域的众包数据集通常存在噪声标签，这些标签错误地代表了潜在的同理心。我们表明，用基于心理学量表感知的提示词开发的LLM生成标签替换或补充这些众包标签，可以实现统计学上显著的准确性提升。值得注意的是，使用噪声减少标签训练的RoBERTa预训练语言模型（PLM）在公共NewsEmp基准测试上达到了0.648的最新皮尔逊相关系数。本文进一步分析了评估指标选择和人口统计学偏见，以帮助指导未来开发更公平的同理心计算模型。代码和LLM生成标签可在https://github.com/hasan-rakibul/LLMPathy获得。", "summary": "本文提出了一种利用大型语言模型（LLM）生成标签来改进同理心计算中主流模型监督训练的新方法。针对众包数据中常见的噪声标签问题，研究者探索了噪声标签校正和训练数据增强两种策略。实验结果表明，通过LLM生成的、基于心理学量表感知的标签替换或补充现有数据，能够显著提高模型的准确性，并使RoBERTa模型在NewsEmp基准测试上达到0.648的最先进皮尔逊相关系数。此外，论文还讨论了评估指标和人口统计学偏见对未来同理心计算模型开发的影响。", "keywords": "大型语言模型, 同理心计算, 噪声标签校正, 数据增强, 体外应用", "comments": "这项研究创新性地将大型语言模型应用于“体外”场景，即利用其生成高质量标签来辅助传统模型的训练，而非直接解决任务。这为LLM的应用开辟了新的范式，尤其是在数据标注成本高或标注质量难以保证的领域。其在同理心计算中的成功应用，证明了LLM在生成专业领域高质量标签方面的潜力，对于提升特定领域模型的性能具有重要意义。"}}
{"id": "2507.11623", "title": "A Roadmap for Climate-Relevant Robotics Research", "authors": ["Alan Papalia", "Charles Dawson", "Laurentiu L. Anton", "Norhan Magdy Bayomi", "Bianca Champenois", "Jung-Hoon Cho", "Levi Cai", "Joseph DelPreto", "Kristen Edwards", "Bilha-Catherine Githinji", "Cameron Hickert", "Vindula Jayawardana", "Matthew Kramer", "Shreyaa Raghavan", "David Russell", "Shide Salimi", "Jingnan Shi", "Soumya Sudhakar", "Yanwei Wang", "Shouyi Wang", "Luca Carlone", "Vijay Kumar", "Daniela Rus", "John E. Fernandez", "Cathy Wu", "George Kantor", "Derek Young", "Hanumant Singh"], "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11623v1", "summary": "Climate change is one of the defining challenges of the 21st century, and\nmany in the robotics community are looking for ways to contribute. This paper\npresents a roadmap for climate-relevant robotics research, identifying\nhigh-impact opportunities for collaboration between roboticists and experts\nacross climate domains such as energy, the built environment, transportation,\nindustry, land use, and Earth sciences. These applications include problems\nsuch as energy systems optimization, construction, precision agriculture,\nbuilding envelope retrofits, autonomous trucking, and large-scale environmental\nmonitoring. Critically, we include opportunities to apply not only physical\nrobots but also the broader robotics toolkit - including planning, perception,\ncontrol, and estimation algorithms - to climate-relevant problems. A central\ngoal of this roadmap is to inspire new research directions and collaboration by\nhighlighting specific, actionable problems at the intersection of robotics and\nclimate. This work represents a collaboration between robotics researchers and\ndomain experts in various climate disciplines, and it serves as an invitation\nto the robotics community to bring their expertise to bear on urgent climate\npriorities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11623v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "气候相关机器人研究路线图", "tldr": "该论文提出了一个气候相关机器人研究路线图，旨在通过突出高影响力的合作机会，鼓励机器人领域专家利用其专业知识应对气候变化挑战。", "motivation": "气候变化是21世纪的决定性挑战之一，机器人社区的许多人正在寻找贡献方法。本论文旨在为机器人专家和气候领域专家之间的合作提供指导，以应对气候相关问题。", "method": "本论文提出了一个气候相关机器人研究路线图，识别了机器人专家与能源、建筑环境、交通、工业、土地利用和地球科学等气候领域专家之间的高影响力合作机会。该路线图不仅包括物理机器人的应用，还包括更广泛的机器人工具包，如规划、感知、控制和估计算法，应用于气候相关问题。", "result": "该路线图识别了能源系统优化、建筑、精准农业、建筑围护结构改造、自动卡车运输和大规模环境监测等具体应用问题，并强调了机器人技术与气候交叉领域中具体的、可操作的问题，以激发新的研究方向和合作。", "conclusion": "本路线图旨在通过突出机器人与气候交叉领域中具体的、可操作的问题，激发新的研究方向和合作。它代表了机器人研究人员和各种气候学科领域专家之间的合作，并邀请机器人社区将其专业知识应用于紧迫的气候优先事项。", "translation": "气候变化是21世纪的决定性挑战之一，机器人社区的许多人正在寻找贡献方法。本论文提出了一个气候相关机器人研究路线图，识别了机器人专家与能源、建筑环境、交通、工业、土地利用和地球科学等气候领域专家之间的高影响力合作机会。这些应用包括能源系统优化、建筑、精准农业、建筑围护结构改造、自动卡车运输和大规模环境监测等问题。关键是，我们不仅包括应用物理机器人的机会，还包括更广泛的机器人工具包——包括规划、感知、控制和估计算法——应用于气候相关问题。本路线图的核心目标是，通过突出机器人与气候交叉领域中具体的、可操作的问题，激发新的研究方向和合作。这项工作代表了机器人研究人员和各种气候学科领域专家之间的合作，它旨在邀请机器人社区将其专业知识应用于紧迫的气候优先事项。", "summary": "本论文提出了一个气候相关机器人研究路线图，旨在应对21世纪的气候变化挑战。该路线图识别了机器人专家与能源、建筑环境、交通、工业、土地利用和地球科学等气候领域专家之间的高影响力合作机会。它强调了将物理机器人以及规划、感知、控制和估计等机器人算法应用于能源优化、精准农业和环境监测等气候相关问题的潜力。该工作旨在激发新的研究方向和合作，并邀请机器人社区将其专业知识应用于紧迫的气候优先事项。", "keywords": "机器人学, 气候变化, 路线图, 合作, 环境监测", "comments": "这篇论文的创新之处在于系统地梳理了机器人技术在应对气候变化方面的潜在应用和合作机会，为机器人领域提供了一个清晰的方向。其重要性在于将前沿的机器人技术与当前全球面临的最紧迫问题之一——气候变化——紧密结合，有望推动跨学科研究和解决方案的快速发展。该路线图不仅限于物理机器人，还包括了更广泛的机器人算法，拓宽了应用视野。"}}
{"id": "2507.12019", "title": "The Role of Rank in Mismatched Low-Rank Symmetric Matrix Estimation", "authors": ["Panpan Niu", "Yuhao Liu", "Teng Fu", "Jie Fan", "Chaowen Deng", "Zhongyi Huang"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12019v1", "summary": "We investigate the performance of a Bayesian statistician tasked with\nrecovering a rank-\\(k\\) signal matrix \\(\\bS \\bS^{\\top} \\in \\mathbb{R}^{n \\times\nn}\\), corrupted by element-wise additive Gaussian noise. This problem lies at\nthe core of numerous applications in machine learning, signal processing, and\nstatistics. We derive an analytic expression for the asymptotic mean-square\nerror (MSE) of the Bayesian estimator under mismatches in the assumed signal\nrank, signal power, and signal-to-noise ratio (SNR), considering both sphere\nand Gaussian signals. Additionally, we conduct a rigorous analysis of how rank\nmismatch influences the asymptotic MSE. Our primary technical tools include the\nspectrum of Gaussian orthogonal ensembles (GOE) with low-rank perturbations and\nasymptotic behavior of \\(k\\)-dimensional spherical integrals.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12019v1", "cate": "cs.IT", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "秩在失配低秩对称矩阵估计中的作用", "tldr": "本文研究了贝叶斯统计学家在存在秩、信号功率和信噪比失配情况下，恢复受高斯噪声破坏的低秩对称信号矩阵时的渐近均方误差。", "motivation": "该问题是机器学习、信号处理和统计学中众多应用的核心。", "method": "作者推导了贝叶斯估计器在假定信号秩、信号功率和信噪比失配情况下的渐近均方误差（MSE）的解析表达式，并对秩失配如何影响渐近MSE进行了严格分析。主要技术工具包括具有低秩扰动的高斯正交系综（GOE）的谱和k维球面积分的渐近行为。", "result": "推导出了贝叶斯估计器在假定信号秩、信号功率和信噪比失配情况下（考虑球面和高斯信号）的渐近均方误差（MSE）的解析表达式。进行了秩失配如何影响渐近MSE的严格分析。", "conclusion": "论文提供了在信号秩、功率和信噪比失配情况下，贝叶斯估计器性能的解析理解，特别是揭示了秩失配对渐近均方误差的影响。", "translation": "我们研究了贝叶斯统计学家在恢复一个秩为k的信号矩阵（该矩阵受到逐元素附加高斯噪声的破坏）时的性能。这个问题是机器学习、信号处理和统计学中众多应用的核心。我们推导了贝叶斯估计器在假定信号秩、信号功率和信噪比（SNR）失配情况下的渐近均方误差（MSE）的解析表达式，考虑了球面和高斯信号。此外，我们对秩失配如何影响渐近MSE进行了严格分析。我们主要的技术工具包括具有低秩扰动的高斯正交系综（GOE）的谱和k维球面积分的渐近行为。", "summary": "本文研究了在存在信号秩、功率和信噪比失配的情况下，贝叶斯估计器恢复受高斯噪声破坏的低秩对称信号矩阵的性能。作者推导了渐近均方误差（MSE）的解析表达式，并深入分析了秩失配对MSE的影响。研究利用了高斯正交系综的谱和球面积分的渐近行为作为主要技术工具。", "keywords": "低秩矩阵估计, 贝叶斯估计器, 均方误差, 秩失配, 高斯正交系综", "comments": "本文通过推导解析表达式并进行严格分析，深入探讨了在低秩对称矩阵估计中，信号参数失配（特别是秩失配）对贝叶斯估计器性能的影响。其创新性在于提供了对这种复杂问题在理论层面的精确量化和理解，为相关应用中的鲁棒性设计提供了重要的理论基础。"}}
{"id": "2507.06444", "title": "Eyes on the Road, Mind Beyond Vision: Context-Aware Multi-modal Enhanced Risk Anticipation", "authors": ["Jiaxun Zhang", "Haicheng Liao", "Yumu Xie", "Chengyue Wang", "Yanchen Guan", "Bin Rao", "Zhenning Li"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      Accepted by ACMMM2025", "url": "http://arxiv.org/abs/2507.06444v2", "summary": "Accurate accident anticipation remains challenging when driver cognition and\ndynamic road conditions are underrepresented in predictive models. In this\npaper, we propose CAMERA (Context-Aware Multi-modal Enhanced Risk\nAnticipation), a multi-modal framework integrating dashcam video, textual\nannotations, and driver attention maps for robust accident anticipation. Unlike\nexisting methods that rely on static or environment-centric thresholds, CAMERA\nemploys an adaptive mechanism guided by scene complexity and gaze entropy,\nreducing false alarms while maintaining high recall in dynamic, multi-agent\ntraffic scenarios. A hierarchical fusion pipeline with Bi-GRU (Bidirectional\nGRU) captures spatio-temporal dependencies, while a Geo-Context Vision-Language\nmodule translates 3D spatial relationships into interpretable, human-centric\nalerts. Evaluations on the DADA-2000 and benchmarks show that CAMERA achieves\nstate-of-the-art performance, improving accuracy and lead time. These results\ndemonstrate the effectiveness of modeling driver attention, contextual\ndescription, and adaptive risk thresholds to enable more reliable accident\nanticipation.", "comment": "Accepted by ACMMM2025", "pdf_url": "http://arxiv.org/pdf/2507.06444v2", "cate": "cs.CE", "date": "2025-07-08", "updated": "2025-07-16", "AI": {"title_translation": "眼观六路，心超视觉：情境感知多模态增强风险预测", "tldr": "CAMERA是一种情境感知多模态框架，通过整合行车记录仪视频、文本注释和驾驶员注意力图，利用自适应机制和分层融合，实现更准确、更可靠的事故预测，并在DADA-2000数据集上达到SOTA性能。", "motivation": "在预测模型中，驾驶员认知和动态道路状况的代表性不足，导致准确的事故预测仍然具有挑战性。", "method": "本文提出了CAMERA（情境感知多模态增强风险预测），这是一个集成了行车记录仪视频、文本注释和驾驶员注意力图的多模态框架。它采用由场景复杂性和凝视熵引导的自适应机制来降低误报，同时在动态、多智能体交通场景中保持高召回率。通过Bi-GRU（双向GRU）的分层融合管道捕获时空依赖性，而Geo-Context Vision-Language模块将3D空间关系转换为可解释的、以人为中心的警报。", "result": "在DADA-2000和基准测试中，CAMERA实现了最先进的性能，提高了准确性和提前期。", "conclusion": "这些结果表明，建模驾驶员注意力、情境描述和自适应风险阈值能够实现更可靠的事故预测。", "translation": "当驾驶员认知和动态道路条件在预测模型中代表性不足时，准确的事故预测仍然具有挑战性。在本文中，我们提出了CAMERA（情境感知多模态增强风险预测），这是一个集成了行车记录仪视频、文本注释和驾驶员注意力图的多模态框架，用于鲁棒的事故预测。与现有依赖静态或以环境为中心的阈值的方法不同，CAMERA采用由场景复杂性和凝视熵引导的自适应机制，在动态、多智能体交通场景中减少误报，同时保持高召回率。一个带有Bi-GRU（双向GRU）的分层融合管道捕获时空依赖性，而Geo-Context Vision-Language模块将3D空间关系转换为可解释的、以人为中心的警报。在DADA-2000和基准测试中的评估表明，CAMERA实现了最先进的性能，提高了准确性和提前期。这些结果证明了建模驾驶员注意力、情境描述和自适应风险阈值在实现更可靠的事故预测方面的有效性。", "summary": "本文提出了一种名为CAMERA（情境感知多模态增强风险预测）的框架，旨在解决现有事故预测模型中驾驶员认知和动态道路条件表示不足的问题。CAMERA整合了行车记录仪视频、文本注释和驾驶员注意力图，并引入了基于场景复杂性和凝视熵的自适应风险阈值机制，以减少误报并提高预测准确性。该框架采用Bi-GRU进行分层融合以捕捉时空依赖性，并通过Geo-Context Vision-Language模块提供以人为中心的警报。实验结果表明，CAMERA在DADA-2000数据集上实现了最先进的性能，显著提高了事故预测的准确性和提前期。", "keywords": "事故预测, 多模态融合, 驾驶员注意力, 自适应阈值, 情境感知", "comments": "该论文的创新点在于提出了一个多模态融合框架CAMERA，它不仅整合了多种数据源（视频、文本、注意力图），更引入了情境感知的自适应风险阈值，而非依赖固定的阈值，这对于动态交通场景下的事故预测至关重要。其Geo-Context Vision-Language模块将3D空间关系转化为人类可理解的警报，增强了系统的实用性。该方法在提高预测准确性和减少误报方面展现出显著潜力。"}}
{"id": "2507.11569", "title": "Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?", "authors": ["Hanxue Gu", "Yaqian Chen", "Nicholas Konz", "Qihang Li", "Maciej A. Mazurowski"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      3 figures, 9 pages", "url": "http://arxiv.org/abs/2507.11569v1", "summary": "Foundation models, pre-trained on large image datasets and capable of\ncapturing rich feature representations, have recently shown potential for\nzero-shot image registration. However, their performance has mostly been tested\nin the context of rigid or less complex structures, such as the brain or\nabdominal organs, and it remains unclear whether these models can handle more\nchallenging, deformable anatomy. Breast MRI registration is particularly\ndifficult due to significant anatomical variation between patients, deformation\ncaused by patient positioning, and the presence of thin and complex internal\nstructure of fibroglandular tissue, where accurate alignment is crucial.\nWhether foundation model-based registration algorithms can address this level\nof complexity remains an open question. In this study, we provide a\ncomprehensive evaluation of foundation model-based registration algorithms for\nbreast MRI. We assess five pre-trained encoders, including DINO-v2, SAM,\nMedSAM, SSLSAM, and MedCLIP, across four key breast registration tasks that\ncapture variations in different years and dates, sequences, modalities, and\npatient disease status (lesion versus no lesion). Our results show that\nfoundation model-based algorithms such as SAM outperform traditional\nregistration baselines for overall breast alignment, especially under large\ndomain shifts, but struggle with capturing fine details of fibroglandular\ntissue. Interestingly, additional pre-training or fine-tuning on medical or\nbreast-specific images in MedSAM and SSLSAM, does not improve registration\nperformance and may even decrease it in some cases. Further work is needed to\nunderstand how domain-specific training influences registration and to explore\ntargeted strategies that improve both global alignment and fine structure\naccuracy. We also publicly release our code at\n\\href{https://github.com/mazurowski-lab/Foundation-based-reg}{Github}.", "comment": "3 figures, 9 pages", "pdf_url": "http://arxiv.org/pdf/2507.11569v1", "cate": "eess.IV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "视觉基础模型是否已准备好用于开箱即用的医学图像配准？", "tldr": "本研究评估了视觉基础模型在乳腺MRI图像配准中的性能，发现它们在整体对齐方面优于传统方法，但在精细细节上表现不佳，且医学领域特异性预训练并未带来益处。", "motivation": "视觉基础模型在零样本图像配准方面显示出潜力，但其性能主要在刚性或较不复杂的结构（如大脑、腹部器官）上测试过。对于更具挑战性的可变形解剖结构（特别是乳腺MRI，因其显著的解剖变异、患者体位引起的形变以及纤维腺体组织的复杂内部结构），这些模型是否能处理仍不清楚，这促使了本研究的进行。", "method": "本研究对基于基础模型的乳腺MRI配准算法进行了全面评估。研究评估了五种预训练编码器（DINO-v2、SAM、MedSAM、SSLSAM和MedCLIP），在捕获不同年份和日期、序列、模态以及患者疾病状态（病变与无病变）变化的四项关键乳腺配准任务中进行测试。", "result": "结果显示，SAM等基于基础模型的算法在整体乳腺对齐方面优于传统配准基线，尤其是在大域偏移下。然而，它们在捕获纤维腺体组织的精细细节方面表现不佳。有趣的是，MedSAM和SSLSAM中在医学或乳腺特异性图像上的额外预训练或微调并未改善配准性能，甚至在某些情况下可能降低了性能。", "conclusion": "还需要进一步的工作来理解领域特定训练如何影响配准，并探索能够同时改善全局对齐和精细结构精度的目标策略。", "translation": "基础模型在大型图像数据集上进行预训练，能够捕获丰富的特征表示，最近在零样本图像配准方面显示出潜力。然而，它们的性能大多在刚性或较不复杂的结构（如大脑或腹部器官）背景下进行测试，目前尚不清楚这些模型是否能够处理更具挑战性的可变形解剖结构。乳腺MRI配准由于患者之间显著的解剖变异、患者体位引起的形变以及纤维腺体组织薄而复杂的内部结构（其中精确对齐至关重要）的存在而特别困难。基于基础模型的配准算法是否能够应对这种复杂程度仍然是一个悬而未决的问题。在本研究中，我们对基于基础模型的乳腺MRI配准算法进行了全面评估。我们评估了五种预训练编码器，包括DINO-v2、SAM、MedSAM、SSLSAM和MedCLIP，跨越捕获不同年份和日期、序列、模态以及患者疾病状态（病变与无病变）变化的四项关键乳腺配准任务。我们的结果显示，SAM等基于基础模型的算法在整体乳腺对齐方面优于传统配准基线，尤其是在大域偏移下，但在捕获纤维腺体组织的精细细节方面表现不佳。有趣的是，MedSAM和SSLSAM中在医学或乳腺特异性图像上的额外预训练或微调并未改善配准性能，甚至在某些情况下可能降低了性能。需要进一步的工作来理解领域特定训练如何影响配准，并探索能够同时改善全局对齐和精细结构精度的目标策略。我们还在GitHub上公开了我们的代码。", "summary": "本研究全面评估了视觉基础模型在乳腺MRI图像配准中的性能，旨在探究其在处理复杂可变形解剖结构时的能力。研究对比了DINO-v2、SAM、MedSAM、SSLSAM和MedCLIP五种预训练编码器在四项关键乳腺配准任务上的表现。结果表明，基础模型如SAM在整体乳腺对齐方面优于传统基线，尤其是在大域偏移下，但难以捕捉纤维腺体组织的精细细节。值得注意的是，医学或乳腺特异性图像上的额外预训练或微调并未提高配准性能，有时甚至会降低。研究强调需要进一步探索领域特定训练对配准的影响以及提升全局对齐和精细结构精度的策略。", "keywords": "视觉基础模型, 医学图像配准, 乳腺MRI, 深度学习, 图像对齐", "comments": "这项研究通过在具有挑战性的乳腺MRI配准任务中评估视觉基础模型，填补了现有研究的空白。其创新之处在于，它不仅验证了基础模型在整体对齐方面的潜力，还揭示了它们在处理精细解剖结构时的局限性。特别值得注意的是，研究发现专门针对医学图像的预训练或微调并未带来性能提升，甚至可能适得其反，这一发现对于未来基础模型在医学图像领域的应用和开发具有重要指导意义，提示开发者需重新审视当前常用的微调策略。"}}
{"id": "2507.09458", "title": "An Energy Efficient Design of Hybrid NOMA Based on Hybrid SIC with Power Adaptation", "authors": ["Ning Wang", "Chenyu Zhang", "Yanshi Sun", "Minghui Min", "Yuanwei Liu", "Shiyin Li"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      13pages, 8figures, 4tables. Submitted to IEEE TWC, manuscript ID is Paper-TW-Jul-25-1790", "url": "http://arxiv.org/abs/2507.09458v2", "summary": "Recently, hybrid non-orthogonal multiple access (H-NOMA) technology, which\neffectively utilizes both NOMA and orthogonal multiple access (OMA)\ntechnologies through flexible resource allocation in a single transmission, has\ndemonstrated immense potential for enhancing the performance of wireless\ncommunication systems. To further release the potential of HNOMA, this paper\nproposes a novel design of H-NOMA which jointly incorporates hybrid successive\ninterference cancellation (HSIC) and power adaptation (PA) in the NOMA\ntransmission phase. To reveal the potential of the proposed HSIC-PA aided\nH-NOMA scheme, closed-form expression for the probability of the event that\nH-NOMA can achieve a higher data rate than pure OMA by consuming less energy is\nrigorously derived. Furthermore, the asymptotic analysis demonstrates that the\nprobability of the proposed H-NOMA scheme approaches 1 in the high\nsignal-to-noise ratio (SNR) regime without any constraints on either users'\ntarget rates or transmit power ratios. This represents a significant\nimprovement over conventional H-NOMA schemes, which require specific\nrestrictive conditions to achieve probability 1 at high SNRs as shown in\nexisting work. The above observation indicates that with less energy\nconsumption, the proposed HSIC-PA aided H-NOMA can achieve a higher data rate\nthan pure OMA with probability 1 at high SNRs, and hence a higher energy\nefficiency. Finally, numerical results are provided to verify the accuracy of\nthe analysis and also demonstrate the superior performance of the proposed\nH-NOMA scheme.", "comment": "13pages, 8figures, 4tables. Submitted to IEEE TWC, manuscript ID is\n  Paper-TW-Jul-25-1790", "pdf_url": "http://arxiv.org/pdf/2507.09458v2", "cate": "eess.SP", "date": "2025-07-13", "updated": "2025-07-16", "AI": {"title_translation": "基于混合SIC和功率自适应的混合NOMA能量高效设计", "tldr": "本文提出了一种结合混合连续干扰消除（HSIC）和功率自适应（PA）的混合非正交多址（H-NOMA）新设计，在高信噪比下，该方案在能耗更低的情况下，以接近1的概率实现比纯OMA更高的数据速率，显著提高了能量效率。", "motivation": "混合非正交多址（H-NOMA）技术在提升无线通信系统性能方面显示出巨大潜力。为了进一步释放H-NOMA的潜力，本文旨在通过引入新的设计来提高其数据速率和能量效率。", "method": "本文提出了一种新颖的H-NOMA设计，该设计在NOMA传输阶段联合引入了混合连续干扰消除（HSIC）和功率自适应（PA）。论文严格推导了H-NOMA在消耗更少能量的情况下实现比纯正交多址（OMA）更高数据速率的事件概率的闭式表达式，并进行了渐近分析。", "result": "研究结果表明，所提出的HSIC-PA辅助H-NOMA方案在高信噪比（SNR）区域，无需对用户目标速率或发射功率比施加任何约束，其概率接近1。这比现有工作中需要特定限制条件才能在高信噪比下达到概率1的传统H-NOMA方案有显著改进。数值结果验证了分析的准确性，并展示了所提出H-NOMA方案的优越性能。", "conclusion": "所提出的HSIC-PA辅助H-NOMA方案能够在能耗更低的情况下，在高信噪比下以概率1实现比纯OMA更高的数据速率，从而获得更高的能量效率。", "translation": "最近，混合非正交多址（H-NOMA）技术通过在单次传输中灵活分配资源，有效利用了NOMA和正交多址（OMA）技术，展现出增强无线通信系统性能的巨大潜力。为了进一步释放H-NOMA的潜力，本文提出了一种新颖的H-NOMA设计，该设计在NOMA传输阶段联合引入了混合连续干扰消除（HSIC）和功率自适应（PA）。为了揭示所提出的HSIC-PA辅助H-NOMA方案的潜力，本文严格推导了H-NOMA在消耗更少能量的情况下可以实现比纯OMA更高数据速率的事件概率的闭式表达式。此外，渐近分析表明，在不限制用户目标速率或发射功率比的情况下，所提出的H-NOMA方案在高信噪比（SNR）区域的概率接近1。这比现有工作中需要特定限制条件才能在高信噪比下达到概率1的传统H-NOMA方案有显著改进。上述观察表明，在能耗更低的情况下，所提出的HSIC-PA辅助H-NOMA方案在高信噪比下可以以概率1实现比纯OMA更高的数据速率，从而获得更高的能量效率。最后，提供了数值结果以验证分析的准确性，并展示了所提出的H-NOMA方案的优越性能。", "summary": "本文提出了一种创新的混合非正交多址（H-NOMA）设计，该设计结合了混合连续干扰消除（HSIC）和功率自适应（PA），以提升无线通信系统的性能。研究推导了H-NOMA在低能耗下实现比纯正交多址（OMA）更高数据速率的概率闭式表达式，并进行渐近分析。结果显示，在高信噪比（SNR）区域，该方案能以接近1的概率实现更高的数据速率，且无需传统H-NOMA方案所需的严格约束，从而显著提高了能量效率。数值结果验证了理论分析的准确性和所提方案的优越性。", "keywords": "混合NOMA, 混合SIC, 功率自适应, 能量效率, 无线通信", "comments": "本文通过将混合连续干扰消除（HSIC）和功率自适应（PA）引入混合NOMA（H-NOMA）系统，提出了一种新颖且高效的设计。其创新点在于理论上证明了在高信噪比下，该方案能够在无需严格约束的情况下，以极高概率实现比传统OMA和H-NOMA更高的能量效率和数据速率。这对于未来无线通信系统的设计具有重要意义，尤其是在追求绿色通信和高频谱效率的背景下。"}}
{"id": "2506.21030", "title": "STEP Planner: Constructing cross-hierarchical subgoal tree as an embodied long-horizon task planner", "authors": ["Tianxing Zhou", "Zhirui Wang", "Haojia Ao", "Guangyan Chen", "Boyang Xing", "Jingwen Cheng", "Yi Yang", "Yufeng Yue"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.21030v2", "summary": "The ability to perform reliable long-horizon task planning is crucial for\ndeploying robots in real-world environments. However, directly employing Large\nLanguage Models (LLMs) as action sequence generators often results in low\nsuccess rates due to their limited reasoning ability for long-horizon embodied\ntasks. In the STEP framework, we construct a subgoal tree through a pair of\nclosed-loop models: a subgoal decomposition model and a leaf node termination\nmodel. Within this framework, we develop a hierarchical tree structure that\nspans from coarse to fine resolutions. The subgoal decomposition model\nleverages a foundation LLM to break down complex goals into manageable\nsubgoals, thereby spanning the subgoal tree. The leaf node termination model\nprovides real-time feedback based on environmental states, determining when to\nterminate the tree spanning and ensuring each leaf node can be directly\nconverted into a primitive action. Experiments conducted in both the\nVirtualHome WAH-NL benchmark and on real robots demonstrate that STEP achieves\nlong-horizon embodied task completion with success rates up to 34% (WAH-NL) and\n25% (real robot) outperforming SOTA methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.21030v2", "cate": "cs.RO", "date": "2025-06-26", "updated": "2025-07-16", "AI": {"title_translation": "STEP规划器：构建跨层级子目标树作为具身长周期任务规划器", "tldr": "STEP Planner通过构建跨层级子目标树，解决了LLM在长周期具身任务规划中成功率低的问题，并在虚拟和真实机器人环境中表现出色。", "motivation": "现有的LLM作为动作序列生成器在长周期具身任务中推理能力有限，导致成功率低，因此需要一种更可靠的长期任务规划方法。", "method": "STEP框架通过子目标分解模型和叶节点终止模型构建一个跨层级的子目标树。子目标分解模型利用基础LLM将复杂目标分解为可管理的子目标，从而扩展子目标树。叶节点终止模型根据环境状态提供实时反馈，确定何时终止树的扩展，并确保每个叶节点可直接转换为原始动作。", "result": "在VirtualHome WAH-NL基准测试和真实机器人上的实验表明，STEP在长周期具身任务完成方面取得了高达34%（WAH-NL）和25%（真实机器人）的成功率，优于最先进的方法。", "conclusion": "STEP Planner通过构建跨层级子目标树，有效提高了机器人在长周期具身任务中的规划可靠性和成功率。", "translation": "能够执行可靠的长周期任务规划对于在现实世界环境中部署机器人至关重要。然而，直接使用大型语言模型（LLM）作为动作序列生成器通常会导致成功率较低，因为它们对长周期具身任务的推理能力有限。在STEP框架中，我们通过一对闭环模型构建了一个子目标树：一个子目标分解模型和一个叶节点终止模型。在此框架内，我们开发了一个从粗到细粒度的分层树结构。子目标分解模型利用基础LLM将复杂目标分解为可管理的子目标，从而扩展子目标树。叶节点终止模型根据环境状态提供实时反馈，确定何时终止树的扩展，并确保每个叶节点都可以直接转换为原始动作。在VirtualHome WAH-NL基准测试和真实机器人上进行的实验表明，STEP在长周期具身任务完成方面取得了高达34%（WAH-NL）和25%（真实机器人）的成功率，优于最先进的方法。", "summary": "STEP Planner提出了一种新的具身长周期任务规划框架，通过构建跨层级子目标树来提高机器人任务规划的可靠性。该框架包含一个利用LLM进行子目标分解的模型和一个根据环境反馈终止树扩展的模型，确保子目标可转化为原始动作。实验证明，STEP在虚拟和真实机器人环境中均显著优于现有方法。", "keywords": "长周期任务规划, 具身机器人, 子目标树, 大语言模型, 层次化规划", "comments": "这篇论文的创新点在于提出了一个结合LLM分解能力和实时环境反馈的分层子目标树规划框架，有效解决了LLM在长周期具身任务规划中推理能力不足的问题。其闭环模型的思想保证了规划的实用性和高成功率，对于提高机器人自主性具有重要意义。"}}
{"id": "2410.09474", "title": "Distilling Invariant Representations with Dual Augmentation", "authors": ["Nikolaos Giakoumoglou", "Tania Stathaki"], "categories": ["cs.CV", "cs.AI", "cs.LG", "68T07", "I.4; I.2"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      After further review, we determined that the submission does not meet the quality standards we intended", "url": "http://arxiv.org/abs/2410.09474v4", "summary": "Knowledge distillation (KD) has been widely used to transfer knowledge from\nlarge, accurate models (teachers) to smaller, efficient ones (students). Recent\nmethods have explored enforcing consistency by incorporating causal\ninterpretations to distill invariant representations. In this work, we extend\nthis line of research by introducing a dual augmentation strategy to promote\ninvariant feature learning in both teacher and student models. Our approach\nleverages different augmentations applied to both models during distillation,\npushing the student to capture robust, transferable features. This dual\naugmentation strategy complements invariant causal distillation by ensuring\nthat the learned representations remain stable across a wider range of data\nvariations and transformations. Extensive experiments on CIFAR-100 demonstrate\nthe effectiveness of this approach, achieving competitive results in\nsame-architecture KD.", "comment": "After further review, we determined that the submission does not meet\n  the quality standards we intended", "pdf_url": "http://arxiv.org/pdf/2410.09474v4", "cate": "cs.CV", "date": "2024-10-12", "updated": "2025-07-16", "AI": {"title_translation": "双重增强蒸馏不变表示", "tldr": "本文提出了一种双重增强策略，用于在知识蒸馏中促进教师和学生模型学习不变特征，并在CIFAR-100上取得了有竞争力的结果。", "motivation": "现有的知识蒸馏方法通过因果解释来蒸馏不变表示，本文旨在通过引入双重增强策略来扩展这一研究方向，以促进教师和学生模型中的不变特征学习。", "method": "本文提出了一种双重增强策略，在蒸馏过程中对教师模型和学生模型应用不同的数据增强，以促使学生模型捕获鲁棒且可迁移的特征。该策略与不变因果蒸馏相结合，确保学习到的表示在更广泛的数据变化和转换中保持稳定。", "result": "在CIFAR-100上的大量实验证明了该方法的有效性，在同架构知识蒸馏中取得了有竞争力的结果。", "conclusion": "双重增强策略能够有效地促进知识蒸馏中不变特征的学习，并在实验中表现出良好的性能。", "translation": "知识蒸馏（KD）已被广泛用于将知识从大型、精确的模型（教师）转移到小型、高效的模型（学生）。最近的方法探索了通过结合因果解释来强制一致性，以蒸馏不变表示。在这项工作中，我们通过引入双重增强策略来扩展这一研究方向，以促进教师和学生模型中的不变特征学习。我们的方法利用在蒸馏过程中应用于两个模型的不同增强，促使学生捕获鲁棒、可迁移的特征。这种双重增强策略通过确保学习到的表示在更广泛的数据变化和转换中保持稳定，补充了不变因果蒸馏。在CIFAR-100上的大量实验证明了该方法的有效性，在同架构知识蒸馏中取得了有竞争力的结果。", "summary": "本文提出了一种新的双重增强策略，用于知识蒸馏（KD），旨在促进教师和学生模型学习不变特征。通过在蒸馏过程中对教师和学生模型应用不同的数据增强，该方法帮助学生模型捕获更鲁棒和可迁移的表示。实验结果表明，该方法在CIFAR-100数据集上的同架构KD任务中表现出色，验证了其有效性。", "keywords": "知识蒸馏, 不变表示, 双重增强, 特征学习, 数据增强", "comments": "本文的创新点在于引入了双重增强策略，该策略在知识蒸馏中同时应用于教师和学生模型，以促进不变特征的学习，这有效地补充了现有的不变因果蒸馏方法。这种方法提高了学生模型学习鲁棒和可迁移特征的能力，对于提升模型效率和泛化能力具有重要意义。"}}
{"id": "2507.12136", "title": "Room Impulse Response Generation Conditioned on Acoustic Parameters", "authors": ["Silvia Arellano", "Chunghsin Yeh", "Gautam Bhattacharya", "Daniel Arteaga"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      4+1 pages, 2 figures; accepted in IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA 2025)", "url": "http://arxiv.org/abs/2507.12136v1", "summary": "The generation of room impulse responses (RIRs) using deep neural networks\nhas attracted growing research interest due to its applications in virtual and\naugmented reality, audio postproduction, and related fields. Most existing\napproaches condition generative models on physical descriptions of a room, such\nas its size, shape, and surface materials. However, this reliance on geometric\ninformation limits their usability in scenarios where the room layout is\nunknown or when perceptual realism (how a space sounds to a listener) is more\nimportant than strict physical accuracy. In this study, we propose an\nalternative strategy: conditioning RIR generation directly on a set of RIR\nacoustic parameters. These parameters include various measures of reverberation\ntime and direct sound to reverberation ratio, both broadband and bandwise. By\nspecifying how the space should sound instead of how it should look, our method\nenables more flexible and perceptually driven RIR generation. We explore both\nautoregressive and non-autoregressive generative models operating in the\nDescript Audio Codec domain, using either discrete token sequences or\ncontinuous embeddings. Specifically, we have selected four models to evaluate:\nan autoregressive transformer, the MaskGIT model, a flow matching model, and a\nclassifier-based approach. Objective and subjective evaluations are performed\nto compare these methods with state-of-the-art alternatives. Results show that\nthe proposed models match or outperform state-of-the-art alternatives, with the\nMaskGIT model achieving the best performance.", "comment": "4+1 pages, 2 figures; accepted in IEEE Workshop on Applications of\n  Signal Processing to Audio and Acoustics (WASPAA 2025)", "pdf_url": "http://arxiv.org/pdf/2507.12136v1", "cate": "cs.SD", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于声学参数的房间脉冲响应生成", "tldr": "提出一种基于声学参数直接生成房间脉冲响应（RIR）的新方法，相比基于几何信息的方法更灵活、更注重感知真实性，且性能优于现有技术。", "motivation": "现有的房间脉冲响应（RIR）生成方法大多依赖于房间的物理描述（如尺寸、形状和表面材料），这限制了它们在房间布局未知或感知真实性比物理精度更重要的场景中的可用性。", "method": "本研究提出一种替代策略：直接基于一系列RIR声学参数（包括混响时间和直达声与混响比的宽带和分频带测量）来生成RIR。论文探索了在Descript音频编解码器域中运行的自回归和非自回归生成模型，使用离散令牌序列或连续嵌入。具体评估了四种模型：自回归Transformer、MaskGIT模型、流匹配模型和基于分类器的方法，并进行了客观和主观评估。", "result": "所提出的模型与最先进的替代方法相比，表现相当或更优，其中MaskGIT模型表现最佳。", "conclusion": "通过直接基于声学参数而非物理几何信息来生成房间脉冲响应，可以实现更灵活、更注重感知驱动的RIR生成，且所提出的模型能够匹配或超越现有先进技术。", "translation": "利用深度神经网络生成房间脉冲响应（RIR）因其在虚拟和增强现实、音频后期制作及相关领域的应用而引起了日益增长的研究兴趣。大多数现有方法以房间的物理描述（如其大小、形状和表面材料）为条件来训练生成模型。然而，这种对几何信息的依赖限制了它们在房间布局未知或当感知真实性（空间对听众的听感）比严格的物理精度更重要时的可用性。在本研究中，我们提出了一种替代策略：直接以一组RIR声学参数为条件来生成RIR。这些参数包括混响时间和直达声与混响比的各种测量值，包括宽带和分频带。通过指定空间应该如何发声而不是它应该看起来如何，我们的方法能够实现更灵活、更感知驱动的RIR生成。我们探索了在Descript音频编解码器域中运行的自回归和非自回归生成模型，使用离散令牌序列或连续嵌入。具体来说，我们选择了四种模型进行评估：自回归Transformer、MaskGIT模型、流匹配模型和基于分类器的方法。进行了客观和主观评估，以将这些方法与最先进的替代方案进行比较。结果表明，所提出的模型与最先进的替代方案表现相当或更优，其中MaskGIT模型取得了最佳性能。", "summary": "本论文提出了一种新颖的房间脉冲响应（RIR）生成方法，通过直接以声学参数（如混响时间、直达声与混响比）为条件来训练深度神经网络，而非传统的物理房间几何信息。这种方法解决了现有方法在房间布局未知或感知真实性优先时的局限性，提供了更灵活和感知驱动的RIR生成能力。研究评估了多种生成模型，包括自回归Transformer、MaskGIT、流匹配和基于分类器的方法，并经客观和主观评估证实，所提出的模型，特别是MaskGIT，其性能可与或超越现有最先进的技术。", "keywords": "房间脉冲响应, 声学参数, 深度神经网络, 生成模型, MaskGIT", "comments": "该论文通过将RIR生成条件从物理几何信息转向直接声学参数，提出了一个重要的创新范式。这种转变显著增强了生成RIR的灵活性和感知真实性，对于虚拟现实、增强现实和音频后期制作等领域具有重要价值，尤其是在无法获取精确几何信息或听觉体验更为关键的场景。论文对多种生成模型的探索以及MaskGIT模型所展现出的卓越性能，进一步验证了该新策略的实用性和巨大潜力。"}}
{"id": "2507.12307", "title": "The iterated Golub-Kahan-Tikhonov method", "authors": ["Davide Bianchi", "Marco Donatelli", "Davide Furchì", "Lothar Reichel"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12307v1", "summary": "The Golub-Kahan-Tikhonov method is a popular solution technique for large\nlinear discrete ill-posed problems. This method first applies partial\nGolub-Kahan bidiagonalization to reduce the size of the given problem and then\nuses Tikhonov regularization to compute a meaningful approximate solution of\nthe reduced problem. It is well known that iterated variants of this method\noften yield approximate solutions of higher quality than the standard\nnon-iterated method. Moreover, it produces more accurate computed solutions\nthan the Arnoldi method when the matrix that defines the linear discrete\nill-posed problem is far from symmetric.\n  This paper starts with an ill-posed operator equation in infinite-dimensional\nHilbert space, discretizes the equation, and then applies the iterated\nGolub-Kahan-Tikhonov method to the solution of the latter problem. An error\nanalysis that addresses all discretization and approximation errors is\nprovided. Additionally, a new approach for choosing the regularization\nparameter is described. This solution scheme produces more accurate approximate\nsolutions than the standard (non-iterated) Golub-Kahan-Tikhonov method and the\niterated Arnoldi-Tikhonov method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12307v1", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "迭代Golub-Kahan-Tikhonov方法", "tldr": "本文研究了迭代Golub-Kahan-Tikhonov方法，并对其在无限维希尔伯特空间中的应用进行了误差分析和正则化参数选择的改进，结果表明其比标准方法和迭代Arnoldi-Tikhonov方法更准确。", "motivation": "迭代表的Golub-Kahan-Tikhonov方法通常能提供比标准非迭代方法更高质量的近似解，并且在定义线性离散不适定问题的矩阵远非对称时，比Arnoldi方法能产生更精确的计算解。本文旨在将该方法应用于无限维希尔伯特空间中的不适定算子方程，并进行全面的误差分析和提出新的正则化参数选择方法。", "method": "本文首先处理无限维希尔伯特空间中的不适定算子方程，然后对其进行离散化，并应用迭代Golub-Kahan-Tikhonov方法求解离散化后的问题。论文提供了全面的误差分析，涵盖了所有离散化和近似误差，并描述了一种选择正则化参数的新方法。", "result": "所提出的求解方案比标准（非迭代）Golub-Kahan-Tikhonov方法和迭代Arnoldi-Tikhonov方法能产生更准确的近似解。", "conclusion": "迭代Golub-Kahan-Tikhonov方法，结合本文提出的误差分析和正则化参数选择方法，能够为不适定问题，包括源自无限维空间的问题，提供更准确的解。", "translation": "Golub-Kahan-Tikhonov方法是一种解决大型线性离散不适定问题的流行技术。该方法首先应用部分Golub-Kahan双对角化来减小给定问题的规模，然后使用Tikhonov正则化来计算约简问题的有意义的近似解。众所周知，该方法的迭代变体通常比标准非迭代方法产生更高质量的近似解。此外，当定义线性离散不适定问题的矩阵远非对称时，它比Arnoldi方法产生更精确的计算解。\n本文从无限维希尔伯特空间中的不适定算子方程开始，对该方程进行离散化，然后将迭代Golub-Kahan-Tikhonov方法应用于后者的求解。提供了涵盖所有离散化和近似误差的误差分析。此外，还描述了一种选择正则化参数的新方法。这种求解方案比标准（非迭代）Golub-Kahan-Tikhonov方法和迭代Arnoldi-Tikhonov方法能产生更准确的近似解。", "summary": "本文研究了迭代Golub-Kahan-Tikhonov（GKT）方法在解决大型线性离散不适定问题中的应用，特别是针对源于无限维算子方程的问题。研究首先对无限维方程进行离散化，然后应用迭代GKT方法。论文提供了全面的误差分析，涵盖了所有的离散化和近似误差，并提出了一种选择正则化参数的新方法。结果表明，这种新的求解方案比标准的非迭代GKT方法和迭代Arnoldi-Tikhonov方法能产生更准确的近似解。", "keywords": "Golub-Kahan-Tikhonov, 不适定问题, 迭代方法, 正则化, 误差分析", "comments": "本文的创新之处在于将迭代Golub-Kahan-Tikhonov方法扩展到无限维希尔伯特空间，并提供了全面的误差分析，同时提出了一种新的正则化参数选择方法，这些共同提升了问题求解的准确性。"}}
{"id": "2410.14987", "title": "SeaS: Few-shot Industrial Anomaly Image Generation with Separation and Sharing Fine-tuning", "authors": ["Zhewei Dai", "Shilei Zeng", "Haotian Liu", "Xurui Li", "Feng Xue", "Yu Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.14987v2", "summary": "We introduce SeaS, a unified industrial generative model for automatically\ncreating diverse anomalies, authentic normal products, and precise anomaly\nmasks. While extensive research exists, most efforts either focus on specific\ntasks, i.e., anomalies or normal products only, or require separate models for\neach anomaly type. Consequently, prior methods either offer limited generative\ncapability or depend on a vast array of anomaly-specific models. We demonstrate\nthat U-Net's differentiated learning ability captures the distinct visual\ntraits of slightly-varied normal products and diverse anomalies, enabling us to\nconstruct a unified model for all tasks. Specifically, we first introduce an\nUnbalanced Abnormal (UA) Text Prompt, comprising one normal token and multiple\nanomaly tokens. More importantly, our Decoupled Anomaly Alignment (DA) loss\ndecouples anomaly attributes and binds them to distinct anomaly tokens of UA,\nenabling SeaS to create unseen anomalies by recombining these attributes.\nFurthermore, our Normal-image Alignment (NA) loss aligns the normal token to\nnormal patterns, making generated normal products globally consistent and\nlocally varied. Finally, SeaS produces accurate anomaly masks by fusing\ndiscriminative U-Net features with high-resolution VAE features. SeaS sets a\nnew benchmark for industrial generation, significantly enhancing downstream\napplications, with average improvements of $+8.66\\%$ pixel-level AP for\nsynthesis-based AD approaches, $+1.10\\%$ image-level AP for unsupervised AD\nmethods, and $+12.79\\%$ IoU for supervised segmentation models. Code is\navailable at\n\\href{https://github.com/HUST-SLOW/SeaS}{https://github.com/HUST-SLOW/SeaS}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.14987v2", "cate": "cs.CV", "date": "2024-10-19", "updated": "2025-07-16", "AI": {"title_translation": "SeaS：基于分离和共享微调的少样本工业异常图像生成", "tldr": "SeaS是一个统一的工业生成模型，能够生成多样化的异常、真实的正常产品和精确的异常掩膜。它通过引入不平衡异常文本提示、解耦异常对齐损失和正常图像对齐损失，解决了现有方法生成能力有限或需要大量特定模型的问题，并显著提升了下游异常检测和分割任务的性能。", "motivation": "现有的工业生成模型要么只专注于特定任务（如仅生成异常或正常产品），要么需要为每种异常类型单独训练模型，导致生成能力有限或模型数量庞大，无法满足工业应用中对多样化异常和统一生成的需求。", "method": "论文提出了SeaS模型，利用U-Net的差异化学习能力构建了一个统一的工业生成模型。具体方法包括：1) 引入不平衡异常（UA）文本提示，包含一个正常token和多个异常token；2) 设计解耦异常对齐（DA）损失，将异常属性解耦并绑定到UA的不同异常token，从而实现通过重新组合属性生成未见异常；3) 引入正常图像对齐（NA）损失，使生成的正常产品全局一致且局部多样；4) 通过融合判别性U-Net特征与高分辨率VAE特征生成精确的异常掩膜。", "result": "SeaS为工业生成设定了新基准，显著增强了下游应用。具体提升包括：合成式异常检测方法的像素级AP平均提高+8.66%，无监督异常检测方法的图像级AP提高+1.10%，以及监督分割模型的IoU提高+12.79%。", "conclusion": "SeaS模型通过其统一的生成能力、创新的损失函数和特征融合策略，有效解决了工业异常图像生成中的挑战，并为下游异常检测和分割任务带来了显著的性能提升，证明了其在工业生成领域的巨大潜力。", "translation": "我们引入了SeaS，一个统一的工业生成模型，用于自动创建多样化的异常、真实的正常产品和精确的异常掩膜。尽管存在大量研究，但大多数努力要么专注于特定任务（即，仅异常或正常产品），要么需要为每种异常类型单独的模型。因此，现有方法要么提供有限的生成能力，要么依赖于大量的特定异常模型。我们证明了U-Net的差异化学习能力可以捕获微小变化的正常产品和多样化异常的独特视觉特征，使我们能够构建一个用于所有任务的统一模型。具体来说，我们首先引入了一个不平衡异常（UA）文本提示，包含一个正常token和多个异常token。更重要的是，我们的解耦异常对齐（DA）损失解耦了异常属性并将它们绑定到UA的不同异常token，使SeaS能够通过重新组合这些属性来创建未见过的异常。此外，我们的正常图像对齐（NA）损失将正常token与正常模式对齐，使生成的正常产品全局一致且局部多样。最后，SeaS通过融合判别性U-Net特征与高分辨率VAE特征生成精确的异常掩膜。SeaS为工业生成设定了新基准，显著增强了下游应用，合成式异常检测方法的像素级AP平均提高了+8.66%，无监督异常检测方法的图像级AP提高了+1.10%，监督分割模型的IoU提高了+12.79%。代码可在https://github.com/HUST-SLOW/SeaS获得。", "summary": "SeaS是一个创新的统一工业生成模型，旨在解决现有方法在生成多样化异常和正常产品方面的局限性。它利用U-Net的差异化学习能力，并引入了不平衡异常文本提示、解耦异常对齐损失和正常图像对齐损失，以实现对未见异常属性的灵活组合生成和高质量正常图像的生成。此外，SeaS通过特征融合生成精确的异常掩膜，并在多项下游任务中取得了显著的性能提升，为工业图像生成领域树立了新标杆。", "keywords": "工业异常生成, 少样本学习, 统一生成模型, 解耦对齐, 异常掩膜", "comments": "SeaS的创新点在于其统一的生成模型架构，能够同时生成异常、正常产品和精确的掩膜，这比现有多数专注于单一任务或需要大量特定模型的方案更高效。特别是，解耦异常对齐损失允许通过组合现有属性生成“未见”的异常，极大地增强了模型的泛化能力和实用性。这对于少样本学习场景尤其重要，因为它减少了对大量异常样本的依赖。其在多个下游任务中的显著性能提升也证明了其重要性。"}}
{"id": "2412.07682", "title": "TRIM: Token Reduction and Inference Modeling for Cost-Effective Language Generation", "authors": ["Alfredo Garrachón Ruiz", "Tomás de la Rosa", "Daniel Borrajo"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      13 pages, 12 tables, 7 figures", "url": "http://arxiv.org/abs/2412.07682v4", "summary": "The inference cost of Large Language Models (LLMs) is a significant challenge\ndue to their computational demands, specially on tasks requiring long outputs.\nHowever, natural language often contains redundancy, which presents an\nopportunity for optimization. We have observed that LLMs can generate distilled\nlanguage-concise outputs that retain essential meaning, when prompted\nappropriately. We propose TRIM, a pipeline for saving computational cost in\nwhich a shorter distilled output from the LLM is reconstructed into a full\nnarrative by a smaller model with lower inference costs. Our experiments show\npromising results, particularly in general knowledge domains with 20.58% saved\ntokens on average with tiny decrease in evaluation metrics, hinting that this\napproach can effectively balance efficiency and accuracy in language processing\ntasks.", "comment": "13 pages, 12 tables, 7 figures", "pdf_url": "http://arxiv.org/pdf/2412.07682v4", "cate": "cs.CL", "date": "2024-12-10", "updated": "2025-07-16", "AI": {"title_translation": "TRIM：面向成本效益型语言生成的Token缩减与推理建模", "tldr": "LLM推理成本高昂，本文提出TRIM框架，通过让LLM生成精简输出，再由小型模型重建为完整叙述，从而在保持准确性的同时显著降低计算成本，平均节省20.58%的token。", "motivation": "大型语言模型（LLM）的推理成本高昂，尤其是在需要长输出的任务中，这是一个巨大的挑战。同时，自然语言中存在冗余，这为优化提供了机会。", "method": "本文提出了TRIM（Token Reduction and Inference Modeling）管道，其核心思想是让大型语言模型（LLM）生成精简的、保留核心意义的简洁输出，然后由一个推理成本较低的小型模型将这些精简输出重建为完整的叙述。", "result": "实验结果显示出有前景的效果，特别是在通用知识领域。该方法平均节省了20.58%的token，同时评估指标仅有微小的下降。", "conclusion": "TRIM方法能够在语言处理任务中有效平衡效率和准确性，为降低LLM推理成本提供了一条有效途径。", "translation": "大型语言模型（LLM）的推理成本因其计算需求而成为一个重大挑战，尤其是在需要长输出的任务上。然而，自然语言通常包含冗余，这为优化提供了机会。我们观察到，当适当提示时，LLM可以生成精简的语言——保留核心意义的简洁输出。我们提出了TRIM，一个用于节省计算成本的管道，其中LLM生成的较短的精简输出由一个推理成本较低的小型模型重建为完整的叙述。我们的实验显示了有前景的结果，特别是在通用知识领域，平均节省了20.58%的token，同时评估指标略有下降，这表明该方法可以在语言处理任务中有效平衡效率和准确性。", "summary": "本文提出TRIM框架，旨在降低大型语言模型（LLM）的推理成本。该方法利用LLM生成精简的核心内容，然后由一个较小的模型将其扩展为完整叙述，从而利用自然语言的冗余性进行优化。实验结果表明，TRIM在通用知识领域实现了显著的token节省（平均20.58%），同时对性能影响甚微，展现了在效率和准确性之间取得平衡的潜力。", "keywords": "大型语言模型, 推理成本, token缩减, 语言生成, 效率优化", "comments": "TRIM通过结合大型模型生成核心内容和小型模型扩展的策略，提出了一种新颖的成本优化方案。这种分阶段处理方法在保持较高准确性的前提下显著降低了LLM的推理成本，尤其适用于对成本敏感且内容存在冗余的生成任务，具有重要的实践意义。"}}
{"id": "2507.12314", "title": "Thought Purity: Defense Paradigm For Chain-of-Thought Attack", "authors": ["Zihao Xue", "Zhen Bi", "Long Ma", "Zhenlin Hu", "Yan Wang", "Zhenfang Liu", "Qing Sheng", "Jie Xiao", "Jungang Lou"], "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12314v1", "summary": "While reinforcement learning-trained Large Reasoning Models (LRMs, e.g.,\nDeepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large\nLanguage Models (LLMs) domain, their susceptibility to security threats remains\na critical vulnerability. This weakness is particularly evident in\nChain-of-Thought (CoT) generation processes, where adversarial methods like\nbackdoor prompt attacks can systematically subvert the model's core reasoning\nmechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this\nvulnerability through exploiting prompt controllability, simultaneously\ndegrading both CoT safety and task performance with low-cost interventions. To\naddress this compounded security-performance vulnerability, we propose Thought\nPurity (TP): a defense paradigm that systematically strengthens resistance to\nmalicious content while preserving operational efficacy. Our solution achieves\nthis through three synergistic components: (1) a safety-optimized data\nprocessing pipeline (2) reinforcement learning-enhanced rule constraints (3)\nadaptive monitoring metrics. Our approach establishes the first comprehensive\ndefense mechanism against CoTA vulnerabilities in reinforcement\nlearning-aligned reasoning systems, significantly advancing the\nsecurity-functionality equilibrium for next-generation AI architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12314v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "思维纯度：链式思维攻击的防御范式", "tldr": "本文提出了“思维纯度”（Thought Purity, TP）防御范式，以应对大型推理模型（LRMs）在链式思维（CoT）生成过程中面临的链式思维攻击（CoTA）漏洞，旨在增强模型对恶意内容的抵抗力并保持操作效率。", "motivation": "尽管经过强化学习训练的大型推理模型（LRMs）展现出先进的推理能力，但它们在链式思维（CoT）生成过程中对安全威胁的敏感性是一个关键漏洞。新兴的链式思维攻击（CoTA）通过利用提示可控性，以低成本干预同时降低CoT安全性和任务性能，揭示了这一漏洞。本文旨在解决这种复合的安全-性能脆弱性。", "method": "本文提出了“思维纯度”（Thought Purity, TP）防御范式，通过三个协同组件来系统地增强模型对恶意内容的抵抗力，同时保持操作效率：1）安全优化的数据处理管道；2）强化学习增强的规则约束；3）自适应监控指标。", "result": "本方法建立了首个针对强化学习对齐推理系统中CoTA漏洞的综合防御机制，显著提升了下一代AI架构的安全-功能平衡。", "conclusion": "“思维纯度”防御范式有效地解决了大型推理模型在链式思维攻击下的安全性和性能退化问题，为强化学习对齐的推理系统提供了首个全面的防御机制，显著推动了AI架构在安全与功能之间的平衡。", "translation": "尽管经过强化学习训练的大型推理模型（LRMs，例如Deepseek-R1）在不断发展的大型语言模型（LLMs）领域中展现出先进的推理能力，但它们对安全威胁的敏感性仍然是一个关键漏洞。这种弱点在链式思维（CoT）生成过程中尤为明显，对抗性方法如后门提示攻击可以系统性地颠覆模型的核心推理机制。新兴的链式思维攻击（CoTA）通过利用提示可控性揭示了这一漏洞，同时以低成本干预降低了CoT安全性和任务性能。为了解决这种复合的安全-性能脆弱性，我们提出了“思维纯度”（Thought Purity, TP）：一种防御范式，它系统地增强了对恶意内容的抵抗力，同时保留了操作效率。我们的解决方案通过三个协同组件实现：1）安全优化的数据处理管道；2）强化学习增强的规则约束；3）自适应监控指标。我们的方法建立了首个针对强化学习对齐推理系统中CoTA漏洞的综合防御机制，显著提升了下一代AI架构的安全-功能平衡。", "summary": "本文针对强化学习训练的大型推理模型（LRMs）在链式思维（CoT）生成过程中面临的链式思维攻击（CoTA）漏洞，提出了一种名为“思维纯度”（Thought Purity, TP）的防御范式。CoTA通过利用提示可控性，以低成本干预同时降低CoT安全性和任务性能。TP通过包含安全优化的数据处理管道、强化学习增强的规则约束和自适应监控指标三个协同组件，系统地增强模型对恶意内容的抵抗力并保持操作效率。该方法是首个针对强化学习对齐推理系统中CoTA漏洞的综合防御机制，显著提升了AI架构的安全-功能平衡。", "keywords": "链式思维攻击, 大型推理模型, 思维纯度, 安全防御, 强化学习", "comments": "该论文提出了一个针对大型推理模型（LRMs）中链式思维攻击（CoTA）的重要防御范式，填补了当前研究在这一特定安全威胁领域的空白。其创新之处在于结合了数据处理、强化学习约束和自适应监控，提供了一个全面的解决方案，这对于确保未来AI系统的安全性和可靠性至关重要。"}}
{"id": "2507.11732", "title": "Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning", "authors": ["Shiyu Chen", "Cencheng Shen", "Youngser Park", "Carey E. Priebe"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11732v1", "summary": "Graph neural networks (GNNs) have emerged as a powerful framework for a wide\nrange of node-level graph learning tasks. However, their performance is often\nconstrained by reliance on random or minimally informed initial feature\nrepresentations, which can lead to slow convergence and suboptimal solutions.\nIn this paper, we leverage a statistically grounded method, one-hot graph\nencoder embedding (GEE), to generate high-quality initial node features that\nenhance the end-to-end training of GNNs. We refer to this integrated framework\nas the GEE-powered GNN (GG), and demonstrate its effectiveness through\nextensive simulations and real-world experiments across both unsupervised and\nsupervised settings. In node clustering, GG consistently achieves\nstate-of-the-art performance, ranking first across all evaluated real-world\ndatasets, while exhibiting faster convergence compared to the standard GNN. For\nnode classification, we further propose an enhanced variant, GG-C, which\nconcatenates the outputs of GG and GEE and outperforms competing baselines.\nThese results confirm the importance of principled, structure-aware feature\ninitialization in realizing the full potential of GNNs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11732v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "编码器嵌入增强的图神经网络，用于改进节点学习", "tldr": "本文提出GEE-powered GNN (GG) 框架，通过高质量初始节点特征解决GNN性能受限问题，在节点聚类和分类任务中取得SOTA表现并加速收敛。", "motivation": "图神经网络（GNNs）在节点级图学习任务中表现强大，但其性能常受限于随机或信息不足的初始特征表示，这会导致收敛缓慢和次优解。", "method": "本文利用统计学基础方法，即独热图编码器嵌入（one-hot graph encoder embedding, GEE），生成高质量的初始节点特征，以增强GNN的端到端训练。该集成框架被称为GEE-powered GNN (GG)。对于节点分类，进一步提出增强变体GG-C，它将GG和GEE的输出连接起来。", "result": "在节点聚类中，GG在所有评估的真实世界数据集中始终达到最先进的性能，排名第一，并且比标准GNN收敛更快。对于节点分类，GG-C优于竞争基线。", "conclusion": "这些结果证实了原则性、结构感知特征初始化在充分发挥GNN潜力方面的重要性。", "translation": "图神经网络（GNNs）已成为广泛节点级图学习任务的强大框架。然而，它们的性能往往受限于对随机或信息最少的初始特征表示的依赖，这可能导致收敛缓慢和次优解。在本文中，我们利用一种基于统计学的方法，即独热图编码器嵌入（GEE），生成高质量的初始节点特征，以增强GNN的端到端训练。我们将这种集成框架称为GEE-powered GNN (GG)，并通过广泛的模拟和真实世界实验在无监督和有监督设置下证明了其有效性。在节点聚类中，GG始终达到最先进的性能，在所有评估的真实世界数据集中排名第一，同时与标准GNN相比展现出更快的收敛速度。对于节点分类，我们进一步提出了一种增强变体GG-C，它将GG和GEE的输出连接起来，并优于竞争基线。这些结果证实了原则性、结构感知特征初始化在充分发挥GNN潜力方面的重要性。", "summary": "本文提出一种名为GEE-powered GNN (GG) 的新型图神经网络框架，旨在通过利用独热图编码器嵌入（GEE）生成高质量的初始节点特征，解决现有GNN因初始特征表示不足导致的性能瓶颈。GG框架通过增强端到端训练，在节点聚类任务中实现了最先进的性能和更快的收敛速度。此外，为节点分类任务设计的GG-C变体，通过结合GG和GEE的输出，也超越了现有基线。研究结果强调了结构感知特征初始化对于充分发挥GNN潜力的关键作用。", "keywords": "图神经网络, 节点学习, 特征初始化, 图编码器嵌入, 节点聚类", "comments": "该论文通过引入结构感知的特征初始化方法（GEE），有效解决了图神经网络（GNNs）在初始特征表示方面的局限性，从而提升了GNN的性能和收敛速度。其创新点在于将统计学基础的编码器嵌入与GNN相结合，形成了一个端到端优化的框架。这项工作对于推动GNN在节点级任务中的实际应用具有重要意义。"}}
{"id": "2507.11810", "title": "The Evolving Role of Large Language Models in Scientific Innovation: Evaluator, Collaborator, and Scientist", "authors": ["Haoxuan Zhang", "Ruochi Li", "Yang Zhang", "Ting Xiao", "Jiangping Chen", "Junhua Ding", "Haihua Chen"], "categories": ["cs.DL", "cs.AI"], "primary_category": "Subjects:       Digital Libraries (cs.DL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11810v1", "summary": "Scientific innovation is undergoing a paradigm shift driven by the rapid\nadvancement of Large Language Models (LLMs). As science faces mounting\nchallenges including information overload, disciplinary silos, and diminishing\nreturns on conventional research methods, LLMs are emerging as powerful agents\ncapable not only of enhancing scientific workflows but also of participating in\nand potentially leading the innovation process. Existing surveys mainly focus\non different perspectives, phrases, and tasks in scientific research and\ndiscovery, while they have limitations in understanding the transformative\npotential and role differentiation of LLM. This survey proposes a comprehensive\nframework to categorize the evolving roles of LLMs in scientific innovation\nacross three hierarchical levels: Evaluator, Collaborator, and Scientist. We\ndistinguish between LLMs' contributions to structured scientific research\nprocesses and open-ended scientific discovery, thereby offering a unified\ntaxonomy that clarifies capability boundaries, evaluation criteria, and\nhuman-AI interaction patterns at each level. Through an extensive analysis of\ncurrent methodologies, benchmarks, systems, and evaluation metrics, this survey\ndelivers an in-depth and systematic synthesis on LLM-driven scientific\ninnovation. We present LLMs not only as tools for automating existing\nprocesses, but also as catalysts capable of reshaping the epistemological\nfoundations of science itself. This survey offers conceptual clarity, practical\nguidance, and theoretical foundations for future research, while also\nhighlighting open challenges and ethical considerations in the pursuit of\nincreasingly autonomous AI-driven science. Resources related to this survey can\nbe accessed on GitHub at: https://github.com/haoxuan-unt2024/llm4innovation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11810v1", "cate": "cs.DL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "大型语言模型在科学创新中不断演变的角色：评估者、合作者和科学家", "tldr": "本综述提出了一个全面的框架，将大型语言模型在科学创新中的角色分为评估者、合作者和科学家三个层次，并分析了它们的能力边界、评估标准和人机交互模式，强调LLM不仅是工具，更是科学范式变革的催化剂。", "motivation": "科学创新面临信息过载、学科孤岛和传统研究方法回报递减等挑战。现有综述在理解大型语言模型（LLM）的变革潜力及其角色分化方面存在局限性。因此，需要一个全面的框架来理解LLM在科学创新中不断演变的角色。", "method": "本综述提出了一个全面的框架，将大型语言模型在科学创新中的角色分为评估者、合作者和科学家三个层次。通过对现有方法、基准、系统和评估指标的广泛分析，区分了LLM对结构化科学研究过程和开放式科学发现的贡献，并提供了一个统一的分类法，阐明了每个层次的能力边界、评估标准和人机交互模式。", "result": "本综述提供了一个关于LLM驱动的科学创新的深入且系统的综合分析。它将LLM呈现为自动化现有流程的工具，以及重塑科学认识论基础的催化剂。", "conclusion": "本综述为未来的研究提供了概念清晰度、实践指导和理论基础，同时强调了追求日益自主的AI驱动科学中的开放挑战和伦理考量。", "translation": "科学创新正在经历由大型语言模型（LLM）的快速发展所驱动的范式转变。随着科学面临信息过载、学科孤岛以及传统研究方法回报递减等日益严峻的挑战，LLM正成为强大的代理，不仅能够增强科学工作流程，还能参与并可能主导创新过程。现有综述主要关注科学研究和发现中的不同视角、短语和任务，但在理解LLM的变革潜力及其角色分化方面存在局限性。本综述提出了一个全面的框架，将LLM在科学创新中不断演变的角色分为三个层次：评估者、合作者和科学家。我们区分了LLM对结构化科学研究过程和开放式科学发现的贡献，从而提供了一个统一的分类法，阐明了每个层次的能力边界、评估标准和人机交互模式。通过对当前方法、基准、系统和评估指标的广泛分析，本综述对LLM驱动的科学创新进行了深入而系统的综合分析。我们将LLM不仅呈现为自动化现有流程的工具，而且是能够重塑科学本身认识论基础的催化剂。本综述为未来的研究提供了概念清晰度、实践指导和理论基础，同时强调了在追求日益自主的AI驱动科学中存在的开放挑战和伦理考量。本综述相关资源可在GitHub上访问：https://github.com/haoxuan-unt2024/llm4innovation。", "summary": "本综述探讨了大型语言模型（LLM）在科学创新中不断演变的角色，提出了一个将LLM角色分为评估者、合作者和科学家三个层次的全面框架。它旨在解决现有综述在理解LLM变革潜力方面的局限性，并通过分析LLM对结构化研究和开放式发现的贡献，阐明其能力边界、评估标准和人机交互模式。该论文强调LLM不仅是自动化工具，更是重塑科学认识论基础的催化剂，并为未来研究提供了指导，同时指出了相关挑战和伦理问题。", "keywords": "大型语言模型, 科学创新, 角色演变, 评估者, 合作者, 科学家", "comments": "这篇综述的重要性在于它系统地提出了LLM在科学创新中的多层次角色，超越了将其仅视为工具的传统视角，将其提升到协作甚至主导科学发现的层面。其提出的“评估者、合作者、科学家”框架为理解和未来发展AI驱动的科学提供了清晰的分类和理论基础，对于指导研究方向和解决人机协作中的挑战具有重要意义。"}}
{"id": "2507.12252", "title": "Improving Contextual ASR via Multi-grained Fusion with Large Language Models", "authors": ["Shilin Zhou", "Zhenghua Li"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12252v1", "summary": "While end-to-end Automatic Speech Recognition (ASR) models have shown\nimpressive performance in transcribing general speech, they often struggle to\naccurately recognize contextually relevant keywords, such as proper nouns or\nuser-specific entities.\n  Previous approaches have explored leveraging keyword dictionaries in the\ntextual modality to improve keyword recognition, either through token-level\nfusion that guides token-by-token generation or phrase-level fusion that\nenables direct copying of keyword phrases.\n  However, these methods operate at different granularities and have their own\nlimitations.\n  In this paper, we propose a novel multi-grained fusion approach that jointly\nleverages the strengths of both token-level and phrase-level fusion with Large\nLanguage Models (LLMs).\n  Our approach incorporates a late-fusion strategy that elegantly combines\nASR's acoustic information with LLM's rich contextual knowledge, balancing\nfine-grained token precision with holistic phrase-level understanding.\n  Experiments on Chinese and English datasets demonstrate that our approach\nachieves state-of-the-art performance on keyword-related metrics while\npreserving high accuracy on non-keyword text.\n  Ablation studies further confirm that the token-level and phrase-level\ncomponents both contribute significantly to the performance gains,\ncomplementing each other in our joint multi-grained framework.\n  The code and models will be publicly available at https://github.com/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12252v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "通过多粒度融合与大型语言模型改进上下文ASR", "tldr": "本文提出了一种多粒度融合方法，结合LLM的token级和短语级融合，显著提升了上下文ASR中关键词识别的准确性。", "motivation": "端到端ASR模型在识别上下文相关关键词（如专有名词或用户特定实体）时表现不佳。现有基于关键词词典的token级或短语级融合方法各有局限性，且操作粒度不同。", "method": "提出了一种新颖的多粒度融合方法，它共同利用了token级和短语级融合与大型语言模型（LLMs）的优势。该方法采用了一种晚期融合策略，将ASR的声学信息与LLM丰富的上下文知识相结合，平衡了细粒度的token精度与整体的短语级理解。", "result": "在中文和英文数据集上的实验表明，该方法在关键词相关指标上取得了最先进的性能，同时保持了非关键词文本的高准确性。消融研究进一步证实，token级和短语级组件都对性能提升有显著贡献，在联合多粒度框架中相互补充。", "conclusion": "本文提出的多粒度融合方法能有效结合token级和短语级融合的优势，通过与LLM结合，显著提升上下文ASR对关键词的识别能力，并达到最先进的性能。", "translation": "尽管端到端自动语音识别（ASR）模型在转录通用语音方面表现出色，但它们在准确识别上下文相关关键词（例如专有名词或用户特定实体）时常常遇到困难。\n先前的研究探索了利用文本模态中的关键词词典来改善关键词识别，无论是通过引导逐个token生成的token级融合，还是通过实现关键词短语直接复制的短语级融合。\n然而，这些方法在不同粒度上操作，并各有其局限性。\n在本文中，我们提出了一种新颖的多粒度融合方法，它共同利用了token级和短语级融合与大型语言模型（LLMs）的优势。\n我们的方法结合了一种晚期融合策略，优雅地将ASR的声学信息与LLM丰富的上下文知识相结合，平衡了细粒度的token精度与整体的短语级理解。\n中文和英文数据集上的实验表明，我们的方法在关键词相关指标上取得了最先进的性能，同时保持了非关键词文本的高准确性。\n消融研究进一步证实，token级和短语级组件都对性能提升有显著贡献，在我们的联合多粒度框架中相互补充。\n代码和模型将公开在 https://github.com/。", "summary": "本文提出了一种新颖的多粒度融合方法，将大型语言模型（LLMs）的token级和短语级融合策略相结合，以解决端到端ASR模型在识别上下文关键词方面的不足。该方法采用晚期融合策略，有效结合ASR的声学信息与LLM的上下文知识，实验证明在中文和英文数据集上，该方法在关键词识别方面达到了最先进的性能，同时保持了整体ASR的准确性。", "keywords": "上下文ASR, 多粒度融合, 大型语言模型, 关键词识别, 晚期融合", "comments": "这篇论文通过结合不同粒度的融合策略（token级和短语级）并整合大型语言模型，有效地解决了上下文ASR中关键词识别的挑战。其创新性在于提出的“多粒度晚期融合”框架，这为提升ASR在特定领域或复杂语境下的表现提供了新的思路。实验结果令人信服，表明该方法在保持通用准确性的同时显著提升了关键词识别能力，具有重要的实践意义。"}}
{"id": "2410.19704", "title": "Multi-view biomedical foundation models for molecule-target and property prediction", "authors": ["Parthasarathy Suryanarayanan", "Yunguang Qiu", "Shreyans Sethi", "Diwakar Mahajan", "Hongyang Li", "Yuxin Yang", "Elif Eyigoz", "Aldo Guzman Saenz", "Daniel E. Platt", "Timothy H. Rumbell", "Kenney Ng", "Sanjoy Dey", "Myson Burch", "Bum Chul Kwon", "Pablo Meyer", "Feixiong Cheng", "Jianying Hu", "Joseph A. Morrone"], "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Biomolecules (q-bio.BM)", "pdf_link": null, "comments": "Comments:      40 pages including supplement. 10 figures, 8 tables", "url": "http://arxiv.org/abs/2410.19704v4", "summary": "Quality molecular representations are key to foundation model development in\nbio-medical research. Previous efforts have typically focused on a single\nrepresentation or molecular view, which may have strengths or weaknesses on a\ngiven task. We develop Multi-view Molecular Embedding with Late Fusion\n(MMELON), an approach that integrates graph, image and text views in a\nfoundation model setting and may be readily extended to additional\nrepresentations. Single-view foundation models are each pre-trained on a\ndataset of up to 200M molecules. The multi-view model performs robustly,\nmatching the performance of the highest-ranked single-view. It is validated on\nover 120 tasks, including molecular solubility, ADME properties, and activity\nagainst G Protein-Coupled receptors (GPCRs). We identify 33 GPCRs that are\nrelated to Alzheimer's disease and employ the multi-view model to select strong\nbinders from a compound screen. Predictions are validated through\nstructure-based modeling and identification of key binding motifs.", "comment": "40 pages including supplement. 10 figures, 8 tables", "pdf_url": "http://arxiv.org/pdf/2410.19704v4", "cate": "q-bio.BM", "date": "2024-10-25", "updated": "2025-07-15", "AI": {"title_translation": "多视图生物医学基础模型用于分子-靶点和属性预测", "tldr": "MMELON是一个多视图分子嵌入模型，整合了图、图像和文本视图，在多种生物医学任务上表现鲁棒，并可用于识别与阿尔茨海默病相关的GPCRs的强结合剂。", "motivation": "高质量的分子表示是生物医学研究中基础模型开发的关键。以前的工作通常只关注单一表示或分子视图，这可能在特定任务上存在优缺点。", "method": "开发了多视图分子嵌入与晚期融合（MMELON）方法，该方法在基础模型设置中整合了图、图像和文本视图，并且可以很容易地扩展到其他表示。单一视图基础模型在多达2亿分子的数据集上进行了预训练。", "result": "多视图模型表现出鲁棒性，与排名最高的单一视图模型性能匹配。该模型在超过120项任务中得到了验证，包括分子溶解度、ADME特性以及针对G蛋白偶联受体（GPCRs）的活性。识别了33个与阿尔茨海默病相关的GPCRs，并使用多视图模型从化合物筛选中选择强结合剂。预测通过基于结构建模和关键结合基序的识别得到验证。", "conclusion": "多视图分子嵌入与晚期融合（MMELON）方法通过整合多种分子视图，在生物医学任务中实现了鲁棒且高性能的分子-靶点和属性预测，并成功应用于与阿尔茨海默病相关的GPCRs的强结合剂筛选。", "translation": "高质量的分子表示是生物医学研究中基础模型开发的关键。以前的工作通常只关注单一表示或分子视图，这可能在特定任务上存在优缺点。我们开发了多视图分子嵌入与晚期融合（MMELON），这是一种在基础模型设置中整合图、图像和文本视图的方法，并且可以很容易地扩展到其他表示。单一视图基础模型在多达2亿分子的数据集上进行了预训练。多视图模型表现出鲁棒性，与排名最高的单一视图模型性能匹配。它在超过120项任务中得到了验证，包括分子溶解度、ADME特性以及针对G蛋白偶联受体（GPCRs）的活性。我们识别了33个与阿尔茨海默病相关的GPCRs，并采用多视图模型从化合物筛选中选择强结合剂。预测通过基于结构建模和关键结合基序的识别得到验证。", "summary": "本文提出了多视图分子嵌入与晚期融合（MMELON）模型，旨在解决生物医学基础模型中单一分子表示的局限性。MMELON整合了图、图像和文本视图，并在多达2亿分子的数据集上进行预训练。该模型在超过120项任务中表现出与最佳单一视图模型相当的鲁棒性能，包括分子溶解度、ADME特性和GPCRs活性。研究还利用MMELON识别并验证了与阿尔茨海默病相关的GPCRs的强结合剂。", "keywords": "多视图, 生物医学基础模型, 分子表示, MMELON, 药物发现", "comments": "这项研究通过整合多种分子视图（图、图像、文本）来构建生物医学基础模型，具有显著的创新性。MMELON克服了单一视图模型的局限性，提高了预测的鲁棒性和性能。其在广泛任务上的验证以及在阿尔茨海默病相关GPCRs筛选中的应用，突显了该模型的实用性和潜在影响力。"}}
{"id": "2507.12338", "title": "A bound-preserving and conservative enriched Galerkin method for elliptic problems", "authors": ["Gabriel R. Barrenechea", "Philip L. Lederer", "Andreas Rupp"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12338v1", "summary": "We propose a locally conservative enriched Galerkin scheme that respects the\ndiscrete maximum principle of an elliptic problem. To this end, we use a\nsubstantial over-penalization of the discrete solution's jumps to obtain\noptimal convergence. To avoid the ill-conditioning issues that arise in\nover-penalized schemes, we introduce an involved splitting approach that\nseparates the system of equations for the discontinuous solution part from the\nsystem of equations for the continuous solution part, yielding well-behaved\nsubproblems. We prove the existence of discrete solutions and optimal error\nestimates, which are validated numerically.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12338v1", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "一种保界且守恒的椭圆问题富集Galerkin方法", "tldr": "提出了一种新的富集Galerkin方法，通过过惩罚和分离求解来解决椭圆问题的离散最大值原理和收敛性，并避免了病态问题。", "motivation": "为了提出一种能够遵守离散最大值原理、获得最优收敛且避免过惩罚方案中常见病态问题的富集Galerkin方法。", "method": "该方法是一种局部守恒的富集Galerkin方案，通过对离散解的跳跃进行大量过惩罚以获得最优收敛。为避免病态问题，引入了一种复杂的分解方法，将不连续解部分和连续解部分的方程系统分离，从而得到表现良好的子问题。", "result": "实现了最优收敛；分解方法产生了表现良好的子问题；证明了离散解的存在性；证明了最优误差估计；这些结果得到了数值验证。", "conclusion": "该富集Galerkin方法能够保持离散最大值原理，实现最优收敛，并通过创新的分解策略有效避免了病态问题，且经过了理论和数值验证。", "translation": "我们提出了一种局部守恒的富集Galerkin方案，该方案遵守椭圆问题的离散最大值原理。为此，我们对离散解的跳跃进行了大量的过惩罚以获得最优收敛。为了避免过惩罚方案中出现的病态问题，我们引入了一种复杂的分解方法，将不连续解部分的方程系统与连续解部分的方程系统分离，从而得到表现良好的子问题。我们证明了离散解的存在性和最优误差估计，这些都得到了数值验证。", "summary": "本文提出了一种用于椭圆问题的局部守恒富集Galerkin方法，该方法在保持离散最大值原理的同时，通过对离散解跳跃的显著过惩罚实现了最优收敛。为解决由此可能引发的病态问题，作者引入了一种创新的分解策略，将连续与不连续解部分分离，从而得到稳定的子问题。理论上，该方法证明了离散解的存在性及最优误差估计，并得到了数值验证。", "keywords": "富集Galerkin方法, 椭圆问题, 过惩罚, 分解方法, 离散最大值原理", "comments": "这篇论文的创新点在于其巧妙地结合了过惩罚策略以确保最优收敛，同时通过引入独特的系统分解方法，有效地规避了传统过惩罚方案中常见的病态问题，从而在保持数值稳定性的前提下，实现了对椭圆问题离散最大值原理的遵守。这种平衡收敛性、稳定性和物理原则的方法具有重要的理论和应用价值。"}}
{"id": "2507.11779", "title": "Large-scale distributed synchronization systems, using a cancel-on-completion redundancy mechanism", "authors": ["Alexander Stolyar"], "categories": ["math.PR", "cs.MA", "90B15, 60K25"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "Comments:      34 pages", "url": "http://arxiv.org/abs/2507.11779v1", "summary": "We consider a class of multi-agent distributed synchronization systems, which\nare modeled as $n$ particles moving on the real line. This class generalizes\nthe model of a multi-server queueing system, considered in [15], employing\nso-called cancel-on-completion (c.o.c.) redundancy mechanism, but is motivated\nby other applications as well. The model in [15] is a particle system,\nregulated at the left boundary point. The more general model of this paper is\nsuch that we allow regulation boundaries on either side, or both sides, or no\nregulation at all. We consider the mean-field asymptotic regime, when the\nnumber of particles $n$ and the job arrival rates go to infinity, while the job\narrival rates per particle remain constant. The results include: the\nexistence/uniqueness of fixed points of mean-field limits (ML), which describe\nthe limiting dynamics of the system; conditions for the steady-state asymptotic\nindependence (concentration, as $n \\to\\infty$, of the stationary distribution\non a single state, which is necessarily an ML fixed point); the limits, as $n\n\\to\\infty$, of the average velocity at which unregulated (free) particle system\nadvances. In particular, our results for the left-regulated system unify and\ngeneralize the corresponding results in [15]. Our technical development is such\nthat the systems with different types of regulation are analyzed within a\nunified framework. In particular, these systems are used as tools for analysis\nof each other.", "comment": "34 pages", "pdf_url": "http://arxiv.org/pdf/2507.11779v1", "cate": "math.PR", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "大规模分布式同步系统，采用取消即完成冗余机制", "tldr": "本文研究了一类广义的多代理分布式同步系统，将其建模为在实线上的粒子运动，并考虑了均场渐近机制。研究结果包括均场极限不动点的存在性/唯一性、稳态渐近独立性条件以及无调节粒子系统的平均速度极限，统一并推广了现有结果。", "motivation": "本文考虑一类多代理分布式同步系统，该系统推广了文献[15]中采用“取消即完成”(c.o.c.)冗余机制的多服务器排队系统模型，同时受其他应用的启发。文章旨在研究更通用的模型，允许在单侧、双侧或无调节边界的系统。", "method": "本文将系统建模为在实线上移动的$n$个粒子，并在粒子数量$n$和作业到达率趋于无穷大、但每粒子作业到达率保持不变的均场渐近机制下进行研究。通过统一的框架分析了具有不同类型调节的系统，并利用这些系统作为相互分析的工具。", "result": "结果包括：描述系统极限动力学的均场极限(ML)不动点的存在性/唯一性；稳态渐近独立性的条件（当$n \to\text{∞}$时，稳态分布集中于单一状态，该状态必然是ML不动点）；以及当$n \to\text{∞}$时，无调节（自由）粒子系统前进的平均速度的极限。特别是，对于左侧调节系统，本文的结果统一并推广了文献[15]中的相应结果。", "conclusion": "本文提出的更通用模型及其均场渐近机制下的分析，统一并推广了现有关于分布式同步系统的结果。通过在统一框架下分析不同类型的调节系统，本文为理解和设计大规模分布式同步系统提供了新的见解。", "translation": "我们考虑一类多代理分布式同步系统，将其建模为在实线上移动的$n$个粒子。此类系统推广了文献[15]中考虑的采用所谓“取消即完成”(c.o.c.)冗余机制的多服务器排队系统模型，但也受到其他应用的启发。文献[15]中的模型是一个在左边界点受调节的粒子系统。本文更一般的模型允许在单侧、双侧或完全没有调节边界。我们考虑均场渐近机制，即当粒子数量$n$和作业到达率趋于无穷大，而每粒子作业到达率保持不变时。研究结果包括：描述系统极限动力学的均场极限(ML)不动点的存在性/唯一性；稳态渐近独立性（当$n \to\text{∞}$时，稳态分布集中于单一状态，该状态必然是ML不动点）的条件；以及当$n \to\text{∞}$时，无调节（自由）粒子系统前进的平均速度的极限。特别是，我们关于左侧调节系统的结果统一并推广了文献[15]中的相应结果。我们的技术发展使得具有不同类型调节的系统可以在统一框架内进行分析。特别是，这些系统被用作相互分析的工具。", "summary": "本文研究了一类广义的多代理分布式同步系统，该系统将$n$个粒子在实线上的运动建模，并推广了采用“取消即完成”冗余机制的多服务器排队系统。与现有模型不同，本文允许系统具有单侧、双侧或无调节边界。在均场渐近机制下（粒子数和作业到达率趋于无穷大），论文探究了均场极限不动点的存在性与唯一性、稳态渐近独立性的条件，以及无调节粒子系统的平均速度极限。研究成果不仅统一并推广了前人的工作，还提供了一个分析不同类型调节系统的统一框架。", "keywords": "分布式同步系统, 取消即完成, 均场极限, 粒子系统, 冗余机制", "comments": "本文的创新之处在于提出了一个更通用的多代理分布式同步系统模型，并将其置于统一的均场渐近分析框架下，从而能够同时处理多种边界调节条件。这种统一性不仅简化了分析，也使得不同类型的系统可以相互作为分析工具。其对均场极限不动点、稳态独立性及平均速度极限的深入探讨，对于理解和设计大规模分布式系统具有重要理论价值和实际意义。"}}
{"id": "2507.12334", "title": "An Analysis of Text Functions in Information Visualization", "authors": ["Chase Stokes", "Anjana Arunkumar", "Marti A. Hearst", "Lace Padilla"], "categories": ["cs.HC", "H.5.0"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      11 pages, 3 figures, IEEE VIS Conference", "url": "http://arxiv.org/abs/2507.12334v1", "summary": "Text is an integral but understudied component of visualization design.\nAlthough recent studies have examined how text elements (e.g., titles and\nannotations) influence comprehension, preferences, and predictions, many\nquestions remain about textual design and use in practice. This paper\nintroduces a framework for understanding text functions in information\nvisualizations, building on and filling gaps in prior classifications and\ntaxonomies. Through an analysis of 120 real-world visualizations and 804 text\nelements, we identified ten distinct text functions, ranging from identifying\ndata mappings to presenting valenced subtext. We further identify patterns in\ntext usage and conduct a factor analysis, revealing four overarching\ntext-informed design strategies: Attribution and Variables, Annotation-Centric\nDesign, Visual Embellishments, and Narrative Framing. In addition to these\nfactors, we explore features of title rhetoric and text multifunctionality,\nwhile also uncovering previously unexamined text functions, such as text\nreplacing visual elements. Our findings highlight the flexibility of text,\ndemonstrating how different text elements in a given design can combine to\ncommunicate, synthesize, and frame visual information. This framework adds\nimportant nuance and detail to existing frameworks that analyze the diverse\nroles of text in visualization.", "comment": "11 pages, 3 figures, IEEE VIS Conference", "pdf_url": "http://arxiv.org/pdf/2507.12334v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "信息可视化中文本功能分析", "tldr": "本文提出了一个理解信息可视化中文本功能的新框架，通过分析大量真实世界的案例，识别了十种文本功能和四种设计策略，揭示了文本在可视化中的灵活性和多样性。", "motivation": "文本是可视化设计中不可或缺但研究不足的组成部分。尽管已有研究探讨了文本元素对理解、偏好和预测的影响，但关于文本设计和实际应用中的许多问题仍未解决。", "method": "本文引入了一个理解信息可视化中文本功能的新框架，并在现有分类和分类法的基础上进行了补充和完善。通过分析120个真实世界的可视化案例和804个文本元素，研究者识别了十种不同的文本功能。此外，研究还识别了文本使用模式并进行了因子分析，揭示了四种主要的文本驱动设计策略：归因与变量、以注释为中心的设计、视觉修饰和叙事框架。", "result": "研究识别了十种不同的文本功能，从识别数据映射到呈现有价子文本。因子分析揭示了四种主要的文本驱动设计策略：归因与变量、以注释为中心的设计、视觉修饰和叙事框架。此外，研究还探讨了标题修辞和文本多功能性，并发现了以前未被研究的文本功能，例如文本替代视觉元素。", "conclusion": "研究结果强调了文本的灵活性，展示了给定设计中不同的文本元素如何结合起来传达、综合和构建视觉信息。该框架为现有分析可视化中文本多样化作用的框架增加了重要的细微差别和细节。", "translation": "文本是可视化设计中不可或缺但研究不足的组成部分。尽管最近的研究已经检查了文本元素（例如，标题和注释）如何影响理解、偏好和预测，但关于文本设计和实际应用中的许多问题仍未解决。本文引入了一个理解信息可视化中文本功能的新框架，它建立在并填补了现有分类和分类法中的空白。通过对120个真实世界的可视化和804个文本元素的分析，我们识别了十种不同的文本功能，范围从识别数据映射到呈现有价子文本。我们进一步识别了文本使用模式并进行了因子分析，揭示了四种主要的文本驱动设计策略：归因与变量、以注释为中心的设计、视觉修饰和叙事框架。除了这些因素，我们还探讨了标题修辞和文本多功能性，同时揭示了以前未被研究的文本功能，例如文本替代视觉元素。我们的发现强调了文本的灵活性，展示了给定设计中不同的文本元素如何结合起来传达、综合和构建视觉信息。这个框架为现有分析可视化中文本多样化作用的框架增加了重要的细微差别和细节。", "summary": "本研究旨在弥补信息可视化中文本设计和应用研究的不足。通过对120个真实世界可视化案例和804个文本元素进行深入分析，本文提出了一个全新的文本功能框架，识别出十种文本功能和四种主要的文本驱动设计策略。研究结果揭示了文本在信息可视化中的高度灵活性和多样化作用，包括替代视觉元素的功能，为理解和优化可视化中的文本使用提供了新的视角和细节。", "keywords": "信息可视化, 文本功能, 设计策略, 文本分析, 可视化设计", "comments": "这项研究的创新之处在于其系统地构建了一个全新的文本功能框架，并通过大规模的实证分析识别了之前未被充分认识的文本作用，例如文本替代视觉元素。这对于可视化设计实践和理论研究都具有重要意义，有助于设计师更有效地利用文本来增强信息传达。"}}
{"id": "2507.11926", "title": "From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning", "authors": ["Max Hopkins", "Sihan Liu", "Christopher Ye", "Yuichi Yoshida"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      67 pages", "url": "http://arxiv.org/abs/2507.11926v1", "summary": "The epidemic failure of replicability across empirical science and machine\nlearning has recently motivated the formal study of replicable learning\nalgorithms [Impagliazzo et al. (2022)]. In batch settings where data comes from\na fixed i.i.d. source (e.g., hypothesis testing, supervised learning), the\ndesign of data-efficient replicable algorithms is now more or less understood.\nIn contrast, there remain significant gaps in our knowledge for control\nsettings like reinforcement learning where an agent must interact directly with\na shifting environment. Karbasi et. al show that with access to a generative\nmodel of an environment with $S$ states and $A$ actions (the RL 'batch\nsetting'), replicably learning a near-optimal policy costs only\n$\\tilde{O}(S^2A^2)$ samples. On the other hand, the best upper bound without a\ngenerative model jumps to $\\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)] due to the\nsubstantial difficulty of environment exploration. This gap raises a key\nquestion in the broader theory of replicability: Is replicable exploration\ninherently more expensive than batch learning? Is sample-efficient replicable\nRL even possible?\n  In this work, we (nearly) resolve this problem (for low-horizon tabular\nMDPs): exploration is not a significant barrier to replicable learning! Our\nmain result is a replicable RL algorithm on $\\tilde{O}(S^2A)$ samples, bridging\nthe gap between the generative and episodic settings. We complement this with a\nmatching $\\tilde{\\Omega}(S^2A)$ lower bound in the generative setting (under\nthe common parallel sampling assumption) and an unconditional lower bound in\nthe episodic setting of $\\tilde{\\Omega}(S^2)$ showcasing the near-optimality of\nour algorithm with respect to the state space $S$.", "comment": "67 pages", "pdf_url": "http://arxiv.org/pdf/2507.11926v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "从生成式到回合式：样本高效的可复制强化学习", "tldr": "本文提出了一种样本高效的可复制强化学习算法，将生成式设置与回合式设置之间的样本复杂度差距从$\tilde{O}(S^7 A^7)$缩小到$\tilde{O}(S^2A)$，并证明探索不再是可复制学习的显著障碍。", "motivation": "可复制性在经验科学和机器学习中普遍存在失败，这促使人们对可复制学习算法进行正式研究。在强化学习等控制设置中，可复制学习的知识存在显著空白，特别是在没有生成模型的情况下，样本复杂度非常高，这引发了关于可复制探索是否本质上比批量学习更昂贵以及样本高效的可复制强化学习是否可能的问题。", "method": "本文提出了一种新的可复制强化学习算法，该算法在低视野表格MDPs上运行，实现了$\tilde{O}(S^2A)$的样本复杂度。此外，还提供了生成式设置下的匹配$\tilde{\tilde{Omega}}(S^2A)$下界（在常见的并行采样假设下）以及回合式设置下的无条件$\tilde{\tilde{Omega}}(S^2)$下界。", "result": "主要结果是提出了一种可复制的强化学习算法，其样本复杂度为$\tilde{O}(S^2A)$，显著缩小了生成式设置（$\tilde{O}(S^2A^2)$）和回合式设置（之前为$\tilde{O}(S^7 A^7)$）之间的差距。同时，提供了匹配的$\tilde{\tilde{Omega}}(S^2A)$生成式下界和$\tilde{\tilde{Omega}}(S^2)$回合式下界，证明了算法在状态空间$S$方面的接近最优性。", "conclusion": "探索并不是可复制学习的显著障碍。本文的算法有效地弥合了生成式强化学习和回合式强化学习在样本效率上的差距，实现了接近最优的性能。", "translation": "经验科学和机器学习领域可复制性普遍失效，这促使人们最近对可复制学习算法进行了正式研究 [Impagliazzo et al. (2022)]。在数据来自固定独立同分布源的批量设置中（例如，假设检验、监督学习），数据高效可复制算法的设计现在或多或少已被理解。相反，在强化学习等代理必须直接与变化环境交互的控制设置中，我们的知识仍存在显著空白。Karbasi 等人表明，在可访问具有 $S$ 个状态和 $A$ 个动作的环境生成模型（强化学习“批量设置”）的情况下，可复制地学习近似最优策略仅需 $\tilde{O}(S^2A^2)$ 个样本。另一方面，在没有生成模型的情况下，最佳上限跃升至 $\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)]，这是由于环境探索的巨大困难。这一差距引出了可复制性更广泛理论中的一个关键问题：可复制探索是否本质上比批量学习更昂贵？样本高效的可复制强化学习是否可能？\n\n在本工作中，我们（几乎）解决了这个问题（对于低视野表格MDPs）：探索并不是可复制学习的显著障碍！我们的主要成果是一种可复制的强化学习算法，其样本复杂度为 $\tilde{O}(S^2A)$，弥合了生成式设置和回合式设置之间的差距。我们通过在生成式设置中（在常见的并行采样假设下）提供匹配的 $\tilde{\tilde{Omega}}(S^2A)$ 下界以及在回合式设置中提供 $\tilde{\tilde{Omega}}(S^2)$ 的无条件下界来补充这一点，展示了我们的算法相对于状态空间 $S$ 的接近最优性。", "summary": "本文解决了强化学习中可复制性面临的样本效率挑战。针对之前在没有生成模型的情况下样本复杂度过高的问题，作者提出了一种新的可复制强化学习算法。该算法在低视野表格MDPs上实现了$\tilde{O}(S^2A)$的样本复杂度，显著缩小了生成式与回合式设置之间的差距。研究还提供了匹配的理论下界，证明了所提算法在样本效率上的接近最优性，并得出结论：探索不再是可复制学习的显著障碍。", "keywords": "可复制强化学习, 样本效率, 生成式模型, 回合式学习, 复杂度下界", "comments": "本文在解决强化学习领域可复制性这一重要问题上取得了显著进展。其创新点在于提出了一种样本高效的算法，有效地弥合了有生成模型和无生成模型之间在可复制RL样本复杂度上的巨大差距。通过将样本复杂度从$\tilde{O}(S^7 A^7)$降低到$\tilde{O}(S^2A)$，并提供紧密的下界，该工作不仅提供了实用的算法，也加深了对可复制探索本质的理论理解，证明了探索并非可复制学习的主要障碍，具有重要的理论和实践意义。"}}
{"id": "2507.12262", "title": "A Framework for Nonstationary Gaussian Processes with Neural Network Parameters", "authors": ["Zachary James", "Joseph Guinness"], "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12262v1", "summary": "Gaussian processes have become a popular tool for nonparametric regression\nbecause of their flexibility and uncertainty quantification. However, they\noften use stationary kernels, which limit the expressiveness of the model and\nmay be unsuitable for many datasets. We propose a framework that uses\nnonstationary kernels whose parameters vary across the feature space, modeling\nthese parameters as the output of a neural network that takes the features as\ninput. The neural network and Gaussian process are trained jointly using the\nchain rule to calculate derivatives. Our method clearly describes the behavior\nof the nonstationary parameters and is compatible with approximation methods\nfor scaling to large datasets. It is flexible and easily adapts to different\nnonstationary kernels without needing to redesign the optimization procedure.\nOur methods are implemented with the GPyTorch library and can be readily\nmodified. We test a nonstationary variance and noise variant of our method on\nseveral machine learning datasets and find that it achieves better accuracy and\nlog-score than both a stationary model and a hierarchical model approximated\nwith variational inference. Similar results are observed for a model with only\nnonstationary variance. We also demonstrate our approach's ability to recover\nthe nonstationary parameters of a spatial dataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12262v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于神经网络参数的非平稳高斯过程框架", "tldr": "提出了一种基于神经网络参数的非平稳高斯过程框架，提高了模型性能和灵活性。", "motivation": "传统的（高斯过程）模型通常使用平稳核，这限制了模型的表达能力，并且可能不适用于许多数据集。", "method": "提出了一种使用非平稳核的框架，其中核参数在特征空间中变化，并将其建模为以特征为输入的神经网络的输出。神经网络和高斯过程通过链式法则计算导数进行联合训练。", "result": "在多个机器学习数据集上测试了非平稳方差和噪声变体，发现它比平稳模型和通过变分推断近似的分层模型都取得了更好的准确性和对数分数。仅具有非平稳方差的模型也观察到类似结果。此外，该方法能够恢复空间数据集的非平稳参数。", "conclusion": "该框架描述了非平稳参数的行为，与近似方法兼容以扩展到大型数据集，并且灵活且易于适应不同的非平稳核，无需重新设计优化过程，并取得了优越的性能。", "translation": "高斯过程因其灵活性和不确定性量化能力，已成为非参数回归的流行工具。然而，它们通常使用平稳核，这限制了模型的表达能力，并且可能不适用于许多数据集。我们提出了一个框架，该框架使用非平稳核，其参数在特征空间中变化，并将这些参数建模为以特征作为输入的神经网络的输出。神经网络和高斯过程通过链式法则计算导数进行联合训练。我们的方法清晰地描述了非平稳参数的行为，并与近似方法兼容，可扩展到大型数据集。它灵活且易于适应不同的非平稳核，无需重新设计优化过程。我们的方法使用GPyTorch库实现，并且可以轻松修改。我们在几个机器学习数据集上测试了我们方法的非平稳方差和噪声变体，发现它比平稳模型和通过变分推断近似的分层模型都取得了更好的准确性和对数分数。仅具有非平稳方差的模型也观察到类似结果。我们还展示了我们的方法恢复空间数据集非平稳参数的能力。", "summary": "本文提出了一种用于非平稳高斯过程的框架，旨在解决传统平稳核的局限性。其核心思想是利用神经网络对特征空间中变化的核参数进行建模，并与高斯过程联合训练。这种方法增强了模型的表达能力和灵活性。在多个机器学习数据集上的实验结果表明，所提出的方法在准确性和对数分数方面优于平稳模型和分层模型，并且能够有效恢复空间数据中的非平稳参数。", "keywords": "高斯过程, 非平稳核, 神经网络, 机器学习, GPyTorch", "comments": "本文的创新点在于有效地将神经网络与高斯过程结合，以建模非平稳核参数，这显著提高了高斯过程在复杂数据集上的灵活性和表达能力。联合训练机制以及与近似方法的兼容性也是其主要优势。"}}
{"id": "2404.17789", "title": "BiLO: Bilevel Local Operator Learning for PDE Inverse Problems. Part I: PDE-Constrained Optimization", "authors": ["Ray Zirui Zhang", "Christopher E. Miles", "Xiaohui Xie", "John S. Lowengrub"], "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "65M32", "I.2.6; G.1.8"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.17789v5", "summary": "We propose a new neural network based method for solving inverse problems for\npartial differential equations (PDEs) by formulating the PDE inverse problem as\na bilevel optimization problem. At the upper level, we minimize the data loss\nwith respect to the PDE parameters. At the lower level, we train a neural\nnetwork to locally approximate the PDE solution operator in the neighborhood of\na given set of PDE parameters, which enables an accurate approximation of the\ndescent direction for the upper level optimization problem. The lower level\nloss function includes the L2 norms of both the residual and its derivative\nwith respect to the PDE parameters. We apply gradient descent simultaneously on\nboth the upper and lower level optimization problems, leading to an effective\nand fast algorithm. The method, which we refer to as BiLO (Bilevel Local\nOperator learning), is also able to efficiently infer unknown functions in the\nPDEs through the introduction of an auxiliary variable. We provide a\ntheoretical analysis that justifies our approach. Through extensive experiments\nover multiple PDE systems, we demonstrate that our method enforces strong PDE\nconstraints, is robust to sparse and noisy data, and eliminates the need to\nbalance the residual and the data loss, which is inherent to the soft PDE\nconstraints in many existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.17789v5", "cate": "cs.LG", "date": "2024-04-27", "updated": "2025-07-16", "AI": {"title_translation": "BiLO：偏微分方程逆问题的双层局部算子学习。第一部分：偏微分方程约束优化", "tldr": "该论文提出了一种名为BiLO的神经网络方法，通过双层优化来解决偏微分方程（PDE）逆问题，该方法快速、鲁棒，并能强制执行强PDE约束。", "motivation": "旨在通过将偏微分方程逆问题表述为双层优化问题，提出一种新的基于神经网络的方法来解决偏微分方程逆问题，以克服现有方法中软PDE约束固有的残差和数据损失平衡问题。", "method": "该方法将偏微分方程逆问题表述为双层优化问题。上层优化问题最小化相对于偏微分方程参数的数据损失。下层训练一个神经网络，以在给定偏微分方程参数的邻域内局部近似偏微分方程解算子，从而为上层优化问题提供准确的下降方向。下层损失函数包括残差及其对偏微分方程参数导数的L2范数。通过同时对上层和下层优化问题应用梯度下降，实现了高效快速的算法。该方法还通过引入辅助变量有效推断偏微分方程中的未知函数。", "result": "该方法（BiLO）能够强制执行强偏微分方程约束，对稀疏和噪声数据具有鲁棒性，并消除了许多现有方法中软偏微分方程约束固有的残差和数据损失平衡的需求。", "conclusion": "通过广泛的实验，该方法在多个偏微分方程系统中表现出有效性和快速性，并能强制执行强偏微分方程约束，对稀疏和噪声数据具有鲁棒性。", "translation": "我们提出了一种新的基于神经网络的方法，通过将偏微分方程（PDE）逆问题表述为双层优化问题来解决它。在上层，我们最小化相对于偏微分方程参数的数据损失。在下层，我们训练一个神经网络，以在给定偏微分方程参数的邻域内局部近似偏微分方程解算子，这使得上层优化问题的下降方向能够得到准确近似。下层损失函数包括残差及其对偏微分方程参数导数的L2范数。我们同时对上层和下层优化问题应用梯度下降，从而形成一种有效且快速的算法。我们称之为BiLO（双层局部算子学习）的方法，还能够通过引入辅助变量有效地推断偏微分方程中的未知函数。我们提供了理论分析来证明我们方法的合理性。通过对多个偏微分方程系统进行的广泛实验，我们证明了我们的方法强制执行了强偏微分方程约束，对稀疏和噪声数据具有鲁棒性，并消除了平衡残差和数据损失的需要，这在许多现有方法中软偏微分方程约束是固有的。", "summary": "本文提出了一种新的基于神经网络的BiLO方法，用于解决偏微分方程（PDE）逆问题，将其表述为双层优化问题。上层优化旨在最小化数据损失，而下层则训练一个神经网络来局部近似PDE解算子，以提供精确的下降方向。该方法通过同时对两层应用梯度下降，实现了高效快速的算法，能够强制执行强PDE约束，对稀疏和噪声数据具有鲁棒性，并消除了平衡残差和数据损失的需要。", "keywords": "双层优化, 偏微分方程逆问题, 算子学习, 神经网络, 偏微分方程约束优化", "comments": "该论文的创新之处在于将偏微分方程逆问题构建为双层优化框架，并利用局部算子学习来获得准确的下降方向，有效地解决了偏微分方程约束优化中的一个关键挑战。其强制执行强偏微分方程约束的能力是一个显著的优势。"}}
{"id": "2501.12189", "title": "MirrorCBO: A consensus-based optimization method in the spirit of mirror descent", "authors": ["Leon Bungert", "Franca Hoffmann", "Dohyeon Kim", "Tim Roith"], "categories": ["math.OC", "cs.LG", "35B40, 35Q84, 35Q89, 35Q90, 65K10, 90C26, 90C56"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      66 pages, 18 figures, 19 tables", "url": "http://arxiv.org/abs/2501.12189v2", "summary": "In this work we propose MirrorCBO, a consensus-based optimization (CBO)\nmethod which generalizes standard CBO in the same way that mirror descent\ngeneralizes gradient descent. For this we apply the CBO methodology to a swarm\nof dual particles and retain the primal particle positions by applying the\ninverse of the mirror map, which we parametrize as the subdifferential of a\nstrongly convex function $\\phi$. In this way, we combine the advantages of a\nderivative-free non-convex optimization algorithm with those of mirror descent.\nAs a special case, the method extends CBO to optimization problems with convex\nconstraints. Assuming bounds on the Bregman distance associated to $\\phi$, we\nprovide asymptotic convergence results for MirrorCBO with explicit exponential\nrate. Another key contribution is an exploratory numerical study of this new\nalgorithm across different application settings, focusing on (i)\nsparsity-inducing optimization, and (ii) constrained optimization,\ndemonstrating the competitive performance of MirrorCBO. We observe empirically\nthat the method can also be used for optimization on (non-convex) submanifolds\nof Euclidean space, can be adapted to mirrored versions of other recent CBO\nvariants, and that it inherits from mirror descent the capability to select\ndesirable minimizers, like sparse ones. We also include an overview of recent\nCBO approaches for constrained optimization and compare their performance to\nMirrorCBO.", "comment": "66 pages, 18 figures, 19 tables", "pdf_url": "http://arxiv.org/pdf/2501.12189v2", "cate": "math.OC", "date": "2025-01-21", "updated": "2025-07-16", "AI": {"title_translation": "MirrorCBO：一种借鉴镜像下降思想的基于共识的优化方法", "tldr": "MirrorCBO是一种新的基于共识的优化（CBO）方法，它将镜像下降的原理融入其中，从而扩展了CBO以处理约束和非凸问题，并提供了收敛性保证和良好的经验表现，尤其适用于寻找稀疏解。", "motivation": "本研究旨在提出MirrorCBO，一种基于共识的优化（CBO）方法，它以镜像下降推广梯度下降的方式来推广标准CBO。其动机在于结合无导数非凸优化算法与镜像下降的优点，并将CBO扩展到具有凸约束的优化问题。", "method": "MirrorCBO通过将CBO方法应用于一群对偶粒子来实现，并通过应用镜像映射的逆（参数化为强凸函数$\\phi$的次微分）来保留原始粒子位置。该方法结合了无导数非凸优化算法和镜像下降的优点，并作为特例将CBO扩展到凸约束优化问题。此外，该方法可以适应其他近期CBO变体的镜像版本。", "result": "在假设与$\\phi$相关的Bregman距离有界的情况下，MirrorCBO被证明具有明确指数速率的渐近收敛性。探索性数值研究表明，MirrorCBO在稀疏诱导优化和约束优化等不同应用设置中表现出竞争力。经验观察表明，该方法还可用于欧几里得空间（非凸）子流形上的优化，并且继承了镜像下降选择期望极小值（如稀疏解）的能力。研究还对近期用于约束优化的CBO方法进行了概述并将其性能与MirrorCBO进行了比较。", "conclusion": "MirrorCBO是一种结合了镜像下降思想的基于共识的优化方法，它有效推广了标准CBO，能够处理具有凸约束的优化问题，并在理论上提供了渐近收敛性保证。通过数值实验，该方法在稀疏诱导和约束优化等应用中展现出强大的竞争力，并且能够选择期望的稀疏解，为无导数非凸优化提供了新的有效工具。", "translation": "在这项工作中，我们提出了MirrorCBO，一种基于共识的优化（CBO）方法，它以镜像下降推广梯度下降的方式来推广标准CBO。为此，我们将CBO方法应用于一群对偶粒子，并通过应用镜像映射的逆来保留原始粒子位置，我们将该映射参数化为强凸函数$\\phi$的次微分。通过这种方式，我们结合了无导数非凸优化算法与镜像下降的优点。作为特例，该方法将CBO扩展到具有凸约束的优化问题。假设与$\\phi$相关的Bregman距离有界，我们提供了MirrorCBO的渐近收敛结果，并具有明确的指数速率。另一个关键贡献是对这种新算法在不同应用设置中进行的探索性数值研究，重点关注（i）稀疏诱导优化和（ii）约束优化，证明了MirrorCBO的竞争性能。我们根据经验观察到，该方法还可以用于欧几里得空间（非凸）子流形上的优化，可以适应其他近期CBO变体的镜像版本，并且它继承了镜像下降选择期望极小值（如稀疏解）的能力。我们还包括了近期用于约束优化的CBO方法的概述，并将其性能与MirrorCBO进行了比较。", "summary": "MirrorCBO是一种新颖的基于共识的优化（CBO）方法，它通过将CBO方法应用于对偶粒子群并利用镜像映射的逆（通过强凸函数$\\phi$的次微分参数化）来获取原始粒子位置，从而推广了标准CBO。该方法结合了无导数非凸优化算法和镜像下降的优点，并能将CBO扩展到凸约束优化问题。在布雷格曼距离有界假设下，MirrorCBO被证明具有明确指数收敛率的渐近收敛性。数值研究表明，MirrorCBO在稀疏诱导优化和约束优化等不同应用场景中表现出竞争力，并且经验性地证明其可用于欧几里得空间非凸子流形上的优化，可适应其他CBO变体，并继承了镜像下降选择稀疏解的能力。", "keywords": "基于共识的优化, 镜像下降, 非凸优化, 约束优化, 稀疏性", "comments": "MirrorCBO的创新之处在于将镜像下降的思想引入到基于共识的优化框架中，这不仅使得CBO能够处理带有凸约束的问题，还继承了镜像下降选择特定类型解（如稀疏解）的能力。这种结合为无导数非凸优化提供了一个新的强大工具，尤其是在处理高维和复杂约束问题时具有潜在优势。理论上的收敛性证明和广泛的数值实验都增强了该方法的可靠性和实用性。"}}
{"id": "2507.11716", "title": "CoNav Chair: Development and Evaluation of a Shared Control based Wheelchair for the Built Environment", "authors": ["Yifan Xu", "Qianwei Wang", "Jordan Lillie", "Vineet Kamat", "Carol Menassa", "Clive D'Souza"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      13 pages, 10 figures", "url": "http://arxiv.org/abs/2507.11716v1", "summary": "As the global population of people with disabilities (PWD) continues to grow,\nso will the need for mobility solutions that promote independent living and\nsocial integration. Wheelchairs are vital for the mobility of PWD in both\nindoor and outdoor environments. The current SOTA in powered wheelchairs is\nbased on either manually controlled or fully autonomous modes of operation,\noffering limited flexibility and often proving difficult to navigate in\nspatially constrained environments. Moreover, research on robotic wheelchairs\nhas focused predominantly on complete autonomy or improved manual control;\napproaches that can compromise efficiency and user trust. To overcome these\nchallenges, this paper introduces the CoNav Chair, a smart wheelchair based on\nthe Robot Operating System (ROS) and featuring shared control navigation and\nobstacle avoidance capabilities that are intended to enhance navigational\nefficiency, safety, and ease of use for the user. The paper outlines the CoNav\nChair's design and presents a preliminary usability evaluation comparing three\ndistinct navigation modes, namely, manual, shared, and fully autonomous,\nconducted with 21 healthy, unimpaired participants traversing an indoor\nbuilding environment. Study findings indicated that the shared control\nnavigation framework had significantly fewer collisions and performed\ncomparably, if not superior to the autonomous and manual modes, on task\ncompletion time, trajectory length, and smoothness; and was perceived as being\nsafer and more efficient based on user reported subjective assessments of\nusability. Overall, the CoNav system demonstrated acceptable safety and\nperformance, laying the foundation for subsequent usability testing with end\nusers, namely, PWDs who rely on a powered wheelchair for mobility.", "comment": "13 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.11716v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "CoNav 轮椅：基于共享控制的轮椅在建成环境中的开发与评估", "tldr": "CoNav Chair 是一种基于ROS的智能轮椅，采用共享控制导航和避障功能，旨在提高导航效率、安全性和易用性。初步评估显示，共享控制模式在碰撞次数、任务完成时间、轨迹长度和平滑度方面优于或与手动和完全自主模式相当，并被认为更安全高效。", "motivation": "随着残疾人人口的增长，对促进独立生活和社交融合的移动解决方案的需求也在增加。现有电动轮椅（手动或完全自主）在空间受限环境中导航困难，且灵活性有限，可能影响效率和用户信任。为克服这些挑战，本研究旨在开发一种新型智能轮椅。", "method": "本文介绍了CoNav Chair，一种基于机器人操作系统（ROS）的智能轮椅，具有共享控制导航和避障功能。研究设计并对CoNav Chair进行了初步可用性评估，比较了手动、共享和完全自主三种导航模式。实验在室内建筑环境中进行，有21名健康、无障碍的参与者参与。", "result": "研究结果表明，共享控制导航框架的碰撞次数显著减少，在任务完成时间、轨迹长度和平滑度方面与自主和手动模式相当甚至更优。根据用户主观评估，共享控制模式被认为更安全、更高效。", "conclusion": "CoNav 系统总体上展示了可接受的安全性和性能，为未来与最终用户（即依赖电动轮椅出行的残疾人）进行可用性测试奠定了基础。", "translation": "随着全球残疾人（PWD）人口的持续增长，对促进独立生活和社会融合的出行解决方案的需求也将随之增加。轮椅对于残疾人在室内和室外环境中的出行至关重要。当前电动轮椅的SOTA（最先进技术）基于手动控制或完全自主操作模式，提供有限的灵活性，并且在空间受限的环境中往往难以导航。此外，机器人轮椅的研究主要集中在完全自主或改进手动控制；这些方法可能会损害效率和用户信任。为了克服这些挑战，本文介绍了CoNav Chair，这是一种基于机器人操作系统（ROS）的智能轮椅，具有共享控制导航和避障功能，旨在提高用户的导航效率、安全性以及易用性。本文概述了CoNav Chair的设计，并提出了初步的可用性评估，比较了三种不同的导航模式，即手动、共享和完全自主模式，实验在室内建筑环境中进行，有21名健康、无障碍的参与者参与。研究结果表明，共享控制导航框架的碰撞次数显著减少，在任务完成时间、轨迹长度和平滑度方面与自主和手动模式相比具有可比性，甚至更优；并且根据用户报告的可用性主观评估，被认为更安全、更高效。总的来说，CoNav 系统展示了可接受的安全性和性能，为后续与最终用户（即依赖电动轮椅出行的残疾人）进行可用性测试奠定了基础。", "summary": "本文介绍了CoNav Chair，一种基于ROS的智能轮椅，其核心在于共享控制导航和避障功能，旨在解决传统电动轮椅在复杂环境中导航困难及效率、信任度受损的问题。通过对21名健康参与者的初步可用性评估，比较了手动、共享和完全自主三种模式，结果显示共享控制模式在减少碰撞、优化任务完成时间、轨迹长度和流畅度方面表现出色，并被用户认为更安全高效。CoNav系统展现了良好的安全性和性能，为后续与残疾用户的测试奠定了基础。", "keywords": "智能轮椅, 共享控制, 导航, 避障, 可用性评估", "comments": "CoNav Chair的创新点在于其共享控制模式，它在完全自主和纯手动控制之间找到了一个平衡点，既能提供辅助导航和避障，又能保留用户的控制感，这对于提升用户信任和实际操作效率至关重要。该研究的初步评估结果令人鼓舞，表明共享控制在性能和用户感知方面具有显著优势。然而，目前的测试对象是健康参与者，未来的研究需要与真正的残疾用户进行更深入的可用性测试，以验证其在实际应用中的有效性和用户体验。"}}
{"id": "2507.11980", "title": "EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models", "authors": ["Jiajian Xie", "Shengyu Zhang", "Zhou Zhao", "Fan Wu", "Fei Wu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      21 pages, 8 figures", "url": "http://arxiv.org/abs/2507.11980v1", "summary": "Diffusion Models have shown remarkable proficiency in image and video\nsynthesis. As model size and latency increase limit user experience, hybrid\nedge-cloud collaborative framework was recently proposed to realize fast\ninference and high-quality generation, where the cloud model initiates\nhigh-quality semantic planning and the edge model expedites later-stage\nrefinement. However, excessive cloud denoising prolongs inference time, while\ninsufficient steps cause semantic ambiguity, leading to inconsistency in edge\nmodel output. To address these challenges, we propose EC-Diff that accelerates\ncloud inference through gradient-based noise estimation while identifying the\noptimal point for cloud-edge handoff to maintain generation quality.\nSpecifically, we design a K-step noise approximation strategy to reduce cloud\ninference frequency by using noise gradients between steps and applying cloud\ninference periodically to adjust errors. Then we design a two-stage greedy\nsearch algorithm to efficiently find the optimal parameters for noise\napproximation and edge model switching. Extensive experiments demonstrate that\nour method significantly enhances generation quality compared to edge\ninference, while achieving up to an average $2\\times$ speedup in inference\ncompared to cloud inference. Video samples and source code are available at\nhttps://ec-diff.github.io/.", "comment": "21 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.11980v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "EC-Diff: 扩散模型的快速高质量边缘-云协同推理", "tldr": "EC-Diff提出了一种边缘-云协同推理框架，通过梯度噪声估计加速云端推理并优化云边切换点，以在扩散模型中实现高质量生成和更快的推理速度。", "motivation": "扩散模型在图像和视频合成中表现出色，但模型尺寸和延迟限制了用户体验。现有的混合边缘-云协同框架存在问题：过度的云端去噪会延长推理时间，而不足的步骤会导致语义模糊和边缘模型输出不一致。", "method": "我们提出了EC-Diff，通过基于梯度的噪声估计加速云端推理，并识别最佳的云边切换点以保持生成质量。具体而言，我们设计了一个K步噪声近似策略，利用步骤间的噪声梯度减少云端推理频率，并定期进行云端推理以调整误差。然后，我们设计了一个两阶段贪婪搜索算法，以高效找到噪声近似和边缘模型切换的最佳参数。", "result": "与边缘推理相比，我们的方法显著提升了生成质量；与云端推理相比，推理速度平均提高了2倍。", "conclusion": "EC-Diff通过创新的噪声估计和云边切换策略，成功解决了扩散模型在边缘-云协同推理中的速度与质量平衡问题，实现了高效且高质量的生成。", "translation": "扩散模型在图像和视频合成方面表现出卓越的性能。然而，模型尺寸和延迟的增加限制了用户体验。最近提出了混合边缘-云协同框架，以实现快速推理和高质量生成，其中云模型启动高质量的语义规划，边缘模型加速后期细化。然而，过度的云端去噪会延长推理时间，而不足的步骤会导致语义模糊，从而导致边缘模型输出的不一致性。为了解决这些挑战，我们提出了EC-Diff，它通过基于梯度的噪声估计加速云端推理，同时识别最佳的云边切换点以保持生成质量。具体而言，我们设计了一个K步噪声近似策略，通过使用步骤间的噪声梯度来减少云端推理频率，并定期应用云端推理来调整误差。然后，我们设计了一个两阶段贪婪搜索算法，以高效找到噪声近似和边缘模型切换的最佳参数。大量实验表明，与边缘推理相比，我们的方法显著提高了生成质量，同时与云端推理相比，推理速度平均提高了2倍。视频样本和源代码可在https://ec-diff.github.io/获得。", "summary": "EC-Diff是一种针对扩散模型的边缘-云协同推理框架，旨在解决现有方法中推理速度与生成质量的权衡问题。它通过引入基于梯度的K步噪声近似策略来减少云端推理频率，并设计了一个两阶段贪婪搜索算法以确定最佳的云边切换点。实验结果显示，EC-Diff在保持高质量生成的同时，实现了比纯云端推理快2倍的推理速度，并优于纯边缘推理的生成质量。", "keywords": "扩散模型, 边缘-云协同, 推理加速, 噪声估计, 生成质量", "comments": "EC-Diff的创新点在于其结合了梯度信息进行噪声估计和动态调整云边切换点，有效平衡了计算效率和生成质量。这种方法对于部署大型扩散模型到资源受限的边缘设备具有重要意义，展现了其在实际应用中的潜力。"}}
{"id": "2402.05102", "title": "You Can REST Now: Automated REST API Documentation and Testing via LLM-Assisted Request Mutations", "authors": ["Alix Decrop", "Xavier Devroey", "Mike Papadakis", "Pierre-Yves Schobbens", "Gilles Perrouin"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.05102v2", "summary": "REST APIs are prevalent among web service implementations, easing\ninteroperability through the HTTP protocol. API testers and users exploit the\nwidely adopted OpenAPI Specification (OAS), a machine-readable standard to\ndocument REST APIs. However, documenting APIs is a time-consuming and\nerror-prone task, and existing documentation is not always complete, publicly\naccessible, or up-to-date. This situation limits the efficiency of testing\ntools and hinders human comprehension. Large Language Models (LLMs) offer the\npotential to automatically infer API documentation, using their colossal\ntraining data. In this paper, we present RESTSpecIT, the first automated\napproach that infers documentation and performs black-box testing of REST APIs\nby leveraging LLMs. Our approach requires minimal user input compared to\nstate-of-the-art tools; Given an API name and an LLM access key, RESTSpecIT\ngenerates API request seeds and mutates them with data returned by the LLM. The\ntool then analyzes API responses for documentation inference and testing\npurposes. RESTSpecIT utilizes an in-context prompt masking strategy, requiring\nno prior model fine-tuning. We evaluate the quality of our tool with three\nstate-of-the-art LLMs: DeepSeek V3, GPT-4.1, and GPT-3.5. Our evaluation\ndemonstrates that RESTSpecIT can (1) infer documentation with 88.62% of routes\nand 89.25% of query parameters found on average, (2) discover undocumented API\ndata, (3) operate efficiently (in terms of model costs, requests sent,\nruntime), and (4) assist REST API testing by uncovering server errors and\ngenerating valid OpenAPI Specification inputs for testing tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.05102v2", "cate": "cs.SE", "date": "2024-02-07", "updated": "2025-07-15", "AI": {"title_translation": "你现在可以休息了：通过LLM辅助请求变异实现自动化REST API文档和测试", "tldr": "通过LLM辅助请求变异，实现REST API的自动化文档生成和黑盒测试，所需用户输入极少。", "motivation": "REST API文档化耗时且易出错，导致文档不完整或过时，这限制了测试工具的效率并阻碍了人类理解。大型语言模型（LLM）具有自动推断API文档的潜力。", "method": "本文提出了RESTSpecIT，一种利用LLM自动推断REST API文档并执行黑盒测试的方法。它只需API名称和LLM访问密钥，即可生成并变异API请求种子，然后分析API响应以进行文档推断和测试。该工具采用上下文提示掩码策略，无需模型微调。通过DeepSeek V3、GPT-4.1和GPT-3.5三种LLM进行了评估。", "result": "RESTSpecIT能够（1）推断文档，平均找到88.62%的路由和89.25%的查询参数，（2）发现未文档化的API数据，（3）高效运行（在模型成本、发送请求、运行时方面），以及（4）通过发现服务器错误和为测试工具生成有效的OpenAPI规范输入来辅助REST API测试。", "conclusion": "RESTSpecIT有效实现了REST API文档推断和黑盒测试的自动化，提高了效率和覆盖范围，且用户输入极少，无需微调LLM。", "translation": "REST API 在 Web 服务实现中非常普遍，通过 HTTP 协议简化了互操作性。API 测试人员和用户利用广泛采用的 OpenAPI 规范 (OAS)，这是一种用于文档化 REST API 的机器可读标准。然而，文档化 API 是一项耗时且容易出错的任务，并且现有文档并非总是完整、公开可访问或最新的。这种情况限制了测试工具的效率并阻碍了人类理解。大型语言模型 (LLM) 提供了自动推断 API 文档的潜力，利用其庞大的训练数据。在本文中，我们提出了 RESTSpecIT，这是第一个通过利用 LLM 推断文档并执行 REST API 黑盒测试的自动化方法。与现有最先进的工具相比，我们的方法需要最少的用户输入；给定一个 API 名称和 LLM 访问密钥，RESTSpecIT 生成 API 请求种子并通过 LLM 返回的数据对其进行变异。然后，该工具分析 API 响应以进行文档推断和测试。RESTSpecIT 利用上下文提示掩码策略，无需预先进行模型微调。我们使用三种最先进的 LLM 评估了我们工具的质量：DeepSeek V3、GPT-4.1 和 GPT-3.5。我们的评估表明，RESTSpecIT 可以 (1) 推断文档，平均找到 88.62% 的路由和 89.25% 的查询参数，(2) 发现未文档化的 API 数据，(3) 高效运行（在模型成本、发送请求、运行时方面），以及 (4) 通过发现服务器错误和为测试工具生成有效的 OpenAPI 规范输入来辅助 REST API 测试。", "summary": "本文介绍了RESTSpecIT，一种利用大型语言模型（LLM）自动推断REST API文档并执行黑盒测试的方法。针对手动API文档化耗时且易出错的挑战，RESTSpecIT只需极少用户输入（API名称和LLM密钥），即可生成并变异API请求，然后分析响应以进行文档推断和测试。该方法采用上下文提示掩码策略，无需微调模型。评估结果表明，RESTSpecIT能有效推断文档、发现未文档数据、高效运行，并通过识别错误和生成有效的OpenAPI规范输入来辅助测试。", "keywords": "REST API, LLM, 自动化文档, 黑盒测试, OpenAPI 规范", "comments": "该论文将LLM应用于软件开发中的实际问题——自动化REST API文档和测试，具有创新性。其方法仅需极少用户输入且无需模型微调，使其具有高度适应性和成本效益。它能够推断文档并发现未文档化的API数据，结合其高效性，凸显了其在显著改善开发者体验和API质量方面的潜力。"}}
{"id": "2507.12137", "title": "AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving", "authors": ["Jiawei Xu", "Kai Deng", "Zexin Fan", "Shenlong Wang", "Jin Xie", "Jian Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.12137v1", "summary": "Modeling and rendering dynamic urban driving scenes is crucial for\nself-driving simulation. Current high-quality methods typically rely on costly\nmanual object tracklet annotations, while self-supervised approaches fail to\ncapture dynamic object motions accurately and decompose scenes properly,\nresulting in rendering artifacts. We introduce AD-GS, a novel self-supervised\nframework for high-quality free-viewpoint rendering of driving scenes from a\nsingle log. At its core is a novel learnable motion model that integrates\nlocality-aware B-spline curves with global-aware trigonometric functions,\nenabling flexible yet precise dynamic object modeling. Rather than requiring\ncomprehensive semantic labeling, AD-GS automatically segments scenes into\nobjects and background with the simplified pseudo 2D segmentation, representing\nobjects using dynamic Gaussians and bidirectional temporal visibility masks.\nFurther, our model incorporates visibility reasoning and physically rigid\nregularization to enhance robustness. Extensive evaluations demonstrate that\nour annotation-free model significantly outperforms current state-of-the-art\nannotation-free methods and is competitive with annotation-dependent\napproaches.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.12137v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "AD-GS：面向自动驾驶的物体感知B样条高斯泼溅自监督学习", "tldr": "AD-GS是一种新型自监督框架，利用B样条高斯泼溅技术，无需手动标注即可高质量渲染动态驾驶场景，并有效处理动态物体。", "motivation": "当前高质量的动态城市驾驶场景建模和渲染方法依赖昂贵的手动物体轨迹标注，而现有的自监督方法无法准确捕捉动态物体运动并正确分解场景，导致渲染伪影。", "method": "提出AD-GS，一个自监督框架，用于从单一日志中进行高质量的驾驶场景自由视角渲染。其核心是一个可学习的运动模型，结合了局部感知B样条曲线和全局感知三角函数，实现了灵活而精确的动态物体建模。AD-GS通过简化的伪2D分割自动将场景分割为物体和背景，并使用动态高斯和双向时间可见性掩码表示物体。此外，模型还结合了可见性推理和物理刚性正则化以增强鲁棒性。", "result": "AD-GS这一无需标注的模型显著优于当前最先进的无需标注方法，并且与依赖标注的方法具有竞争力。", "conclusion": "AD-GS成功地解决了动态驾驶场景自监督渲染中的挑战，实现了高质量的渲染效果，且无需昂贵的手动标注，使其成为自动驾驶模拟的关键技术。", "translation": "建模和渲染动态城市驾驶场景对于自动驾驶模拟至关重要。当前高质量的方法通常依赖于昂贵的手动物体轨迹标注，而自监督方法未能准确捕捉动态物体运动并正确分解场景，导致渲染伪影。我们引入了AD-GS，一个新颖的自监督框架，用于从单一日志中进行驾驶场景的高质量自由视角渲染。其核心是一个新颖的可学习运动模型，它将局部感知B样条曲线与全局感知三角函数相结合，从而实现灵活而精确的动态物体建模。AD-GS无需全面的语义标注，通过简化的伪2D分割自动将场景分割为物体和背景，并使用动态高斯和双向时间可见性掩码表示物体。此外，我们的模型结合了可见性推理和物理刚性正则化以增强鲁棒性。广泛的评估表明，我们的无需标注模型显著优于当前最先进的无需标注方法，并且与依赖标注的方法具有竞争力。", "summary": "AD-GS是一个新颖的自监督框架，专为动态城市驾驶场景的高质量自由视角渲染设计。它通过一个结合B样条曲线和三角函数的可学习运动模型，以及自动化的物体-背景分割（使用动态高斯和时间可见性掩码），解决了现有方法对昂贵标注的依赖和自监督方法在动态物体处理上的不足。实验证明，AD-GS在无需标注的情况下，性能超越了现有同类方法，并能与依赖标注的方法相媲美。", "keywords": "自动驾驶, 自监督学习, 高斯泼溅, 动态场景渲染, B样条", "comments": "该论文提出了一个创新的自监督方法AD-GS，解决了动态驾驶场景渲染中对昂贵手动标注的依赖问题。其核心创新在于结合了B样条和三角函数的可学习运动模型，以及无需语义标注的自动场景分割机制，这对于自动驾驶模拟领域具有重要意义。模型的鲁棒性通过可见性推理和物理刚性正则化得到增强，使其在无需标注的情况下达到与有标注方法相当的性能，展示了其巨大的潜力。"}}
{"id": "2411.00355", "title": "TextDestroyer: A Training- and Annotation-Free Diffusion Method for Destroying Anomal Text from Images", "authors": ["Mengcheng Li", "Fei Chao"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.00355v3", "summary": "In this paper, we propose TextDestroyer, the first training- and\nannotation-free method for scene text destruction using a pre-trained diffusion\nmodel. Existing scene text removal models require complex annotation and\nretraining, and may leave faint yet recognizable text information, compromising\nprivacy protection and content concealment. TextDestroyer addresses these\nissues by employing a three-stage hierarchical process to obtain accurate text\nmasks. Our method scrambles text areas in the latent start code using a\nGaussian distribution before reconstruction. During the diffusion denoising\nprocess, self-attention key and value are referenced from the original latent\nto restore the compromised background. Latent codes saved at each inversion\nstep are used for replacement during reconstruction, ensuring perfect\nbackground restoration. The advantages of TextDestroyer include: (1) it\neliminates labor-intensive data annotation and resource-intensive training; (2)\nit achieves more thorough text destruction, preventing recognizable traces; and\n(3) it demonstrates better generalization capabilities, performing well on both\nreal-world scenes and generated images.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.00355v3", "cate": "cs.CV", "date": "2024-11-01", "updated": "2025-07-16", "AI": {"title_translation": "TextDestroyer：一种无需训练和标注的图像异常文本销毁扩散方法", "tldr": "TextDestroyer是一种首个无需训练和标注的扩散方法，用于彻底销毁图像中的场景文本，解决了现有方法的标注和残留问题。", "motivation": "现有的场景文本移除模型需要复杂的标注和再训练，并且可能会留下模糊但可识别的文本信息，从而损害隐私保护和内容隐藏。", "method": "TextDestroyer采用三阶段分层过程来获取准确的文本掩码。它在重建之前使用高斯分布扰乱潜在起始代码中的文本区域。在扩散去噪过程中，自注意力键和值会参考原始潜在空间以恢复受损的背景。在每个反演步骤中保存的潜在代码用于重建过程中的替换，以确保完美的背景恢复。", "result": "TextDestroyer的优势包括：1) 消除了劳动密集型数据标注和资源密集型训练；2) 实现了更彻底的文本销毁，防止留下可识别的痕迹；3) 表现出更好的泛化能力，在真实场景和生成图像上均表现良好。", "conclusion": "本文提出的TextDestroyer是一种无需训练和标注的扩散方法，能够彻底销毁图像中的场景文本，有效解决了现有方法的局限性，并展现出卓越的泛化能力。", "translation": "在本文中，我们提出了TextDestroyer，这是第一个使用预训练扩散模型进行场景文本销毁的无需训练和标注的方法。现有的场景文本移除模型需要复杂的标注和再训练，并且可能会留下模糊但可识别的文本信息，从而损害隐私保护和内容隐藏。TextDestroyer通过采用三阶段分层过程来获取准确的文本掩码，从而解决了这些问题。我们的方法在重建之前使用高斯分布扰乱潜在起始代码中的文本区域。在扩散去噪过程中，自注意力键和值会参考原始潜在空间以恢复受损的背景。在每个反演步骤中保存的潜在代码用于重建过程中的替换，以确保完美的背景恢复。TextDestroyer的优势包括：(1) 它消除了劳动密集型数据标注和资源密集型训练；(2) 它实现了更彻底的文本销毁，防止留下可识别的痕迹；(3) 它表现出更好的泛化能力，在真实场景和生成图像上均表现良好。", "summary": "TextDestroyer是首个无需训练和标注的场景文本销毁方法，利用预训练扩散模型克服了现有方法对复杂标注和再训练的需求，并解决了文本残留问题。该方法采用三阶段分层过程获取精确文本掩码，通过高斯分布扰乱文本区域的潜在代码，并在扩散去噪中利用自注意力恢复背景，最终通过潜在代码替换确保完美背景重建。TextDestroyer的优势在于无需大量数据标注和训练资源，能更彻底地销毁文本，并具有出色的泛化能力。", "keywords": "TextDestroyer, 扩散模型, 文本销毁, 无需标注, 场景文本移除", "comments": "TextDestroyer的创新之处在于它是第一个实现无需训练和标注的场景文本销毁方法，极大地降低了成本和复杂性。其利用预训练扩散模型和独特的三阶段处理流程，确保了文本的彻底销毁和背景的完美恢复，同时展现出卓越的泛化能力，使其在实际应用中具有重要价值。"}}
{"id": "2502.10341", "title": "Organize the Web: Constructing Domains Enhances Pre-Training Data Curation", "authors": ["Alexander Wettig", "Kyle Lo", "Sewon Min", "Hannaneh Hajishirzi", "Danqi Chen", "Luca Soldaini"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at ICML 2025. Project page: this https URL", "url": "http://arxiv.org/abs/2502.10341v3", "summary": "Modern language models are trained on large, unstructured datasets consisting\nof trillions of tokens and obtained by crawling the web. The unstructured\nnature makes it difficult to reason about their contents and develop systematic\napproaches to data curation. In this paper, we unpack monolithic web corpora by\ndeveloping taxonomies of their contents and organizing them into domains. We\nintroduce WebOrganizer, a framework for organizing web pages in terms of both\ntheir topic and format. Using these two complementary notions of domains, we\nautomatically annotate pre-training data by distilling annotations from a large\nlanguage model into efficient classifiers. This allows us to study how data\nfrom different domains should be mixed to improve models on downstream tasks,\nand we show that we can combine insights about effective topics and formats to\nfurther boost performance. We demonstrate that our domain mixing also improves\nexisting methods that select data based on quality. Furthermore, we study and\ncompare how quality-based methods will implicitly change the domain mixture.\nOverall, our work demonstrates that constructing and mixing domains provides a\nvaluable complement to quality-based data curation methods, opening new avenues\nfor effective and insightful pre-training data curation.", "comment": "Accepted at ICML 2025. Project page: https://weborganizer.allen.ai", "pdf_url": "http://arxiv.org/pdf/2502.10341v3", "cate": "cs.CL", "date": "2025-02-14", "updated": "2025-07-16", "AI": {"title_translation": "组织网络：构建领域增强预训练数据整理", "tldr": "本文引入WebOrganizer框架，通过主题和格式组织网络数据，并利用领域混合策略优化预训练数据，提高下游任务性能，补充了现有基于质量的数据整理方法。", "motivation": "现代语言模型依赖大规模非结构化网络数据集，难以对其内容进行推理和系统性数据整理。因此，需要一种方法来解构和组织这些单体网络语料库。", "method": "引入WebOrganizer框架，通过主题和格式两种互补概念组织网页。利用大型语言模型蒸馏注释到高效分类器，自动标注预训练数据。研究不同领域数据混合对下游任务性能的影响，并结合主题和格式洞察进一步提升性能。还研究了基于质量的数据选择方法如何隐式改变领域混合。", "result": "领域混合能够提升模型在下游任务上的性能。结合有效主题和格式的洞察可以进一步提升性能。领域混合还能改进现有基于质量的数据选择方法。研究并比较了基于质量的方法如何隐式改变领域混合。", "conclusion": "构建和混合领域为基于质量的数据整理方法提供了有价值的补充，为有效和有洞察力的预训练数据整理开辟了新途径。", "translation": "现代语言模型是在由数万亿个标记组成的大型非结构化数据集上训练的，这些数据集通过爬取网络获得。非结构化的性质使得难以对其内容进行推理并开发系统的数据整理方法。在本文中，我们通过开发其内容的分类法并将其组织成领域来解构单一的网络语料库。我们引入了WebOrganizer，一个根据网页的主题和格式组织网页的框架。利用这两种互补的领域概念，我们通过将大型语言模型的注释蒸馏到高效的分类器中，自动标注预训练数据。这使我们能够研究来自不同领域的数据应如何混合以改进下游任务上的模型，并且我们表明我们可以结合关于有效主题和格式的见解以进一步提升性能。我们证明了我们的领域混合也改进了现有基于质量选择数据的方法。此外，我们研究并比较了基于质量的方法将如何隐式改变领域混合。总的来说，我们的工作表明，构建和混合领域为基于质量的数据整理方法提供了有价值的补充，为有效和有洞察力的预训练数据整理开辟了新途径。", "summary": "本文针对现代语言模型预训练数据非结构化的问题，提出了WebOrganizer框架。该框架通过主题和格式两种维度组织网络语料，并利用LLM蒸馏技术自动标注数据。研究发现，通过领域混合策略可以有效提升模型在下游任务上的性能，并能补充和改进现有的基于质量的数据整理方法。这项工作为预训练数据的有效整理提供了新思路。", "keywords": "预训练数据整理, 领域混合, WebOrganizer, 大型语言模型, 数据策展", "comments": "这篇论文通过引入“领域”概念，为大规模非结构化网络数据提供了一种新的组织和整理方法，这对于提升大型语言模型的预训练效率和下游任务性能具有重要意义。其创新之处在于结合了主题和格式维度，并利用LLM进行自动标注，有效地将无序数据转化为结构化信息。该方法补充了传统的基于质量的数据筛选，为未来更精细化的数据整理开辟了新的研究方向。"}}
{"id": "2507.11595", "title": "A Study on the Application of Artificial Intelligence in Ecological Design", "authors": ["Hengyue Zhao"], "categories": ["cs.AI", "cs.CY", "I.4.8; I.2.6"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11595v1", "summary": "This paper asks whether our relationship with nature can move from human\ndominance to genuine interdependence, and whether artificial intelligence (AI)\ncan mediate that shift. We examine a new ecological-design paradigm in which AI\ninteracts with non-human life forms. Through case studies we show how artists\nand designers apply AI for data analysis, image recognition, and ecological\nrestoration, producing results that differ from conventional media. We argue\nthat AI not only expands creative methods but also reframes the theory and\npractice of ecological design. Building on the author's prototype for\nAI-assisted water remediation, the study proposes design pathways that couple\nreinforcement learning with plant-based phytoremediation. The findings\nhighlight AI's potential to link scientific insight, artistic practice, and\nenvironmental stewardship, offering a roadmap for future research on\nsustainable, technology-enabled ecosystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11595v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "人工智能在生态设计中应用的研究", "tldr": "本文探讨了人工智能如何促进人与自然从主导关系转向相互依存，并提出AI在生态设计中的新范式，通过案例研究和原型展示其潜力。", "motivation": "探讨人与自然的关系能否从人类主导转变为真正的相互依存，以及人工智能能否促成这一转变。", "method": "通过案例研究，展示艺术家和设计师如何将AI应用于数据分析、图像识别和生态修复。基于作者的AI辅助水体修复原型，提出了结合强化学习和植物修复的设计路径。", "result": "AI的应用产生了不同于传统媒体的结果，不仅扩展了创意方法，还重塑了生态设计的理论和实践。研究结果强调了AI连接科学洞察、艺术实践和环境管理方面的潜力。", "conclusion": "AI能够促进人与自然的相互依存关系，并为可持续、技术赋能的生态系统研究提供了路线图。", "translation": "本文探讨了我们与自然的关系能否从人类主导转向真正的相互依存，以及人工智能（AI）能否促成这一转变。我们研究了一种新的生态设计范式，其中AI与非人类生命形式互动。通过案例研究，我们展示了艺术家和设计师如何将AI应用于数据分析、图像识别和生态修复，产生了与传统媒体不同的结果。我们认为，AI不仅扩展了创意方法，还重塑了生态设计的理论和实践。基于作者的AI辅助水体修复原型，本研究提出了将强化学习与植物修复相结合的设计路径。研究结果强调了AI连接科学洞察、艺术实践和环境管理方面的潜力，为未来可持续、技术赋能的生态系统研究提供了路线图。", "summary": "本文探讨了人工智能在生态设计中的应用，旨在促进人与自然从主导走向相互依存。研究通过案例分析展示了AI在数据分析、图像识别和生态修复中的独特作用，并提出了结合AI强化学习与植物修复的原型。研究强调了AI在融合科学、艺术与环境管理方面的巨大潜力，为未来可持续生态系统的发展提供了新的方向。", "keywords": "人工智能, 生态设计, 相互依存, 生态修复, 强化学习", "comments": "本文创新性地探讨了AI在生态设计中的应用，超越了传统的技术工具范畴，将其视为重塑人与自然关系、实现真正相互依存的媒介。其通过案例研究和原型设计，具体展示了AI在生态修复和创意扩展方面的潜力，为跨学科研究提供了有益的视角。文章的局限性可能在于其更多地关注了概念和潜力，而对实际实施中的技术挑战和伦理考量探讨不足。"}}
{"id": "2507.11642", "title": "Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment", "authors": ["Abhishek Jaiswal", "Nisheeth Srivastava"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11642v1", "summary": "Posture-based mental state inference has significant potential in diagnosing\nfatigue, preventing injury, and enhancing performance across various domains.\nSuch tools must be research-validated with large datasets before being\ntranslated into practice. Unfortunately, such vision diagnosis faces serious\nchallenges due to the sensitivity of human subject data. To address this, we\nidentify sports settings as a viable alternative for accumulating data from\nhuman subjects experiencing diverse emotional states. We test our hypothesis in\nthe game of cricket and present a posture-based solution to identify human\nintent from activity videos. Our method achieves over 75\\% F1 score and over\n80\\% AUC-ROC in discriminating aggressive and defensive shot intent through\nmotion analysis. These findings indicate that posture leaks out strong signals\nfor intent inference, even with inherent noise in the data pipeline.\nFurthermore, we utilize existing data statistics as weak supervision to\nvalidate our findings, offering a potential solution for overcoming data\nlabelling limitations. This research contributes to generalizable techniques\nfor sports analytics and also opens possibilities for applying human behavior\nanalysis across various fields.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11642v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "姿态驱动的动作意图推断，用于评估比赛风格和疲劳", "tldr": "该研究通过分析姿态从活动视频中推断人类意图，特别是在板球运动中区分攻击性和防守性击球意图，并利用弱监督克服数据标注限制。", "motivation": "基于姿态的精神状态推断在诊断疲劳、预防损伤和提高表现方面潜力巨大，但需要大量数据集进行研究验证，而人类受试者数据的敏感性带来了严峻挑战。为了解决这一问题，研究者将体育环境确定为积累人类受试者数据的一个可行替代方案。", "method": "研究在板球比赛中验证了假设，并提出了一种基于姿态的解决方案，通过运动分析从活动视频中识别击球手是攻击性还是防守性意图。此外，研究利用现有数据统计作为弱监督来验证其发现，以克服数据标注限制。", "result": "该方法在区分攻击性和防守性击球意图方面，F1分数超过75%，AUC-ROC分数超过80%。这些发现表明，即使数据管道中存在固有噪声，姿态也能泄露出强烈的意图推断信号。", "conclusion": "姿态为意图推断提供了强烈的信号。这项研究为体育分析的通用技术做出了贡献，并为将人类行为分析应用于各个领域开辟了可能性。利用现有数据统计作为弱监督是克服数据标注限制的潜在解决方案。", "translation": "基于姿态的精神状态推断在诊断疲劳、预防损伤和提高各个领域的表现方面具有巨大潜力。此类工具在投入实践之前必须通过大型数据集进行研究验证。不幸的是，由于人类受试者数据的敏感性，这种视觉诊断面临严峻挑战。为了解决这个问题，我们确定体育环境是积累来自经历不同情绪状态的人类受试者数据的可行替代方案。我们在板球比赛中测试了我们的假设，并提出了一种基于姿态的解决方案，用于从活动视频中识别人类意图。我们的方法通过运动分析在区分攻击性和防守性击球意图方面实现了超过75%的F1分数和超过80%的AUC-ROC分数。这些发现表明，即使数据管道中存在固有噪声，姿态也能泄露出强烈的意图推断信号。此外，我们利用现有数据统计作为弱监督来验证我们的发现，为克服数据标注限制提供了一个潜在的解决方案。这项研究为体育分析的通用技术做出了贡献，也为将人类行为分析应用于各个领域开辟了可能性。", "summary": "本研究提出了一种姿态驱动的动作意图推断方法，旨在解决基于姿态的精神状态推断在数据收集和标注方面的挑战。通过选择体育环境（以板球为例）作为数据积累的替代方案，并利用运动分析，该方法在区分攻击性和防守性击球意图上取得了超过75%的F1分数和超过80%的AUC-ROC分数。研究结果表明姿态能够提供强烈的意图信号，并且结合弱监督能有效克服数据标注限制，为体育分析及更广泛的人类行为分析提供了通用技术和新的可能性。", "keywords": "姿态分析, 意图推断, 体育分析, 疲劳评估, 板球", "comments": "该论文的创新点在于将体育环境作为获取敏感人类行为数据（如姿态）的有效途径，并成功应用于意图推断。其提出的弱监督方法为解决大型数据集标注难题提供了实用方案，具有重要的应用价值和推广潜力，不仅限于体育领域，还可扩展到其他需要行为分析的场景。"}}
{"id": "2507.03220", "title": "Symbiosis: Multi-Adapter Inference and Fine-Tuning", "authors": ["Saransh Gupta", "Umesh Deshpande", "Travis Janssen", "Swami Sundararaman"], "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03220v2", "summary": "Parameter-efficient fine-tuning (PEFT) allows model builders to capture the\ntask specific parameters into adapters, which are a fraction of the size of the\noriginal base model. Popularity of PEFT technique for fine-tuning has led to\ncreation of a large number of adapters for popular Large Language Models\n(LLMs). However, existing frameworks fall short in supporting inference or\nfine-tuning with multiple adapters in the following ways. 1) For fine-tuning,\neach job needs to deploy its dedicated base model instance, which results in\nexcessive GPU memory consumption and poor GPU utilization. 2) While popular\ninference platforms can serve multiple PEFT adapters, they do not allow\nindependent resource management or mixing of different PEFT methods. 3) They\ncannot share resources (such as base model instance) between inference and\nfine-tuning jobs. 4) They do not provide privacy to users who may not wish to\nexpose their fine-tuned parameters to service providers. In Symbiosis, we\naddress the above problems by enabling as-a-service deployment of base model.\nThe base model layers can be shared across multiple inference or fine-tuning\nprocesses. Our split-execution technique decouples the execution of\nclient-specific adapters and layers from the frozen base model layers offering\nthem flexibility to manage their resources, to select their fine-tuning method,\nto achieve their performance goals. Our approach is transparent to models and\nworks out-of-the-box for most models in the transformers library. Our\nevaluation on Llama2-13B shows the compared to baseline, Symbiosis can\nfine-tune 4X more adapters on the same set of GPUs in the same amount of time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03220v2", "cate": "cs.DC", "date": "2025-07-03", "updated": "2025-07-16", "AI": {"title_translation": "共生：多适配器推理与微调", "tldr": "Symbiosis通过解耦基础模型和适配器执行，实现了多适配器推理和微调的服务化部署，显著提高了GPU利用率和可扩展性。", "motivation": "现有的参数高效微调（PEFT）框架在支持多适配器推理或微调方面存在不足，包括：每个微调任务需独立部署基础模型导致GPU内存消耗高、利用率低；推理平台不支持独立资源管理或混合不同PEFT方法；推理和微调作业无法共享资源；以及用户隐私可能暴露。这导致了资源浪费和使用限制。", "method": "Symbiosis通过启用基础模型的“即服务”部署来解决上述问题。它允许基础模型层在多个推理和微调过程中共享。其核心是“分离执行”技术，将客户端特定的适配器和层与冻结的基础模型层解耦，从而提供资源管理、微调方法选择和性能目标实现的灵活性。该方法对模型透明，并与transformers库中的大多数模型开箱即用。", "result": "在Llama2-13B上的评估显示，与基线相比，Symbiosis在相同的GPU集合和时间内可以微调多达4倍的适配器。", "conclusion": "Symbiosis提供了一种创新的解决方案，通过实现基础模型的服务化部署和分离执行技术，显著提高了多适配器推理和微调的效率、资源利用率和隐私保护，解决了现有PEFT框架的痛点。", "translation": "参数高效微调（PEFT）允许模型构建者将任务特定参数捕获到适配器中，这些适配器的大小仅为原始基础模型的一小部分。PEFT技术在微调方面的普及导致为流行的大型语言模型（LLMs）创建了大量适配器。然而，现有框架在支持多适配器推理或微调方面存在以下不足：1）对于微调，每个作业需要部署其专用的基础模型实例，导致GPU内存消耗过大和GPU利用率低下。2）虽然流行的推理平台可以服务多个PEFT适配器，但它们不允许独立资源管理或混合不同的PEFT方法。3）它们无法在推理和微调作业之间共享资源（例如基础模型实例）。4）它们不为不希望向服务提供商暴露其微调参数的用户提供隐私。在Symbiosis中，我们通过启用基础模型的“即服务”部署来解决上述问题。基础模型层可以在多个推理或微调过程中共享。我们的分离执行技术将客户端特定的适配器和层的执行与冻结的基础模型层解耦，为它们提供了管理资源、选择微调方法、实现性能目标的灵活性。我们的方法对模型透明，并且对transformers库中的大多数模型开箱即用。我们对Llama2-13B的评估表明，与基线相比，Symbiosis可以在相同的GPU集合和相同的时间内微调多达4倍的适配器。", "summary": "本论文提出了Symbiosis，一个旨在解决现有参数高效微调（PEFT）框架在多适配器推理和微调方面不足的系统。现有框架存在GPU资源浪费、缺乏灵活资源管理和隐私保护等问题。Symbiosis通过实现基础模型的服务化部署和引入分离执行技术，允许基础模型层在多个推理和微调任务之间共享，并解耦客户端适配器与基础模型的执行。这使得用户可以灵活管理资源、选择微调方法并达到性能目标。实验结果表明，Symbiosis在Llama2-13B上能够以4倍的效率进行适配器微调，显著提升了资源利用率和可扩展性。", "keywords": "参数高效微调, 多适配器, 大语言模型, 资源共享, 分离执行", "comments": "Symbiosis的创新点在于其“即服务”的基础模型部署和“分离执行”技术，这有效地解决了大规模部署和管理PEFT适配器时的资源效率和隐私问题。通过将基础模型与适配器执行解耦，它提供了一个高度可扩展和灵活的框架，对于LLM在实际应用中的广泛采用具有重要意义。该方法对模型透明，进一步降低了集成难度。"}}
{"id": "2411.04202", "title": "Observability and Generalized Sensor Placement for Nonlinear Quality Models in Drinking Water Networks", "authors": ["Mohamad H. Kazma", "Salma M. Elsherif", "Ahmad F. Taha"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.04202v4", "summary": "This paper studies the problem of optimal placement of water quality (WQ)\nsensors in water distribution networks (WDNs), with a focus on chlorine\ntransport, decay, and reaction models. Such models are traditionally used as\nsuitable proxies for WQ. The literature on this topic is inveterate, but has a\nkey limitation: it utilizes simplified single-species decay and reaction models\nthat do not capture WQ transients for nonlinear, multi-species interactions.\nThis results in sensor placements (SP) that do not account for nonlinear WQ\ndynamics. Furthermore, as WQ simulations are parameterized by hydraulic\nprofiles and demand patterns, the placement of sensors are often\nhydraulics-dependent. This study produces a greedy algorithm that addresses the\ntwo aforementioned limitations. The algorithm is grounded in nonlinear dynamic\nsystems and observability theory, and yields SPs that are submodular and robust\nto hydraulic changes. Case studies on benchmark water networks are provided.\nThe key findings provide practical recommendations for WDN operators.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.04202v4", "cate": "eess.SY", "date": "2024-11-06", "updated": "2025-07-15", "AI": {"title_translation": "饮用水网络中非线性水质模型的观测性与广义传感器布设", "tldr": "本研究提出了一种基于非线性动态系统和可观测性理论的贪婪算法，用于优化饮用水网络中的水质传感器布设，以解决现有方法在处理非线性多物种相互作用和水力变化鲁棒性方面的局限性。", "motivation": "现有文献在饮用水网络水质传感器布设方面存在局限性：一是使用简化的单物种衰变和反应模型，无法捕捉非线性、多物种相互作用的水质瞬变，导致传感器布设无法考虑非线性水质动态；二是传感器布设常常依赖于水力剖面和需求模式，缺乏对水力变化的鲁棒性。本研究旨在解决这些问题。", "method": "本研究提出了一种基于非线性动态系统和可观测性理论的贪婪算法，用于水质传感器布设。该算法能够生成次模化（submodular）且对水力变化具有鲁棒性的传感器布设方案。", "result": "该研究提供了一种新的贪婪算法，能够解决现有水质传感器布设方法的局限性。通过在基准水网络上的案例研究，该算法为饮用水网络运营商提供了实用的建议。", "conclusion": "本研究成功开发了一种新的贪婪算法，用于优化饮用水网络中的水质传感器布设，克服了现有方法在非线性动态和水力鲁棒性方面的不足，并为实际操作提供了有价值的建议。", "translation": "本文研究了饮用水分配网络（WDNs）中水质（WQ）传感器的优化布设问题，重点关注氯的传输、衰减和反应模型。这类模型传统上被用作水质的合适替代物。关于这个主题的文献由来已久，但存在一个关键局限性：它们利用简化的单物种衰减和反应模型，无法捕捉非线性、多物种相互作用的水质瞬变。这导致传感器布设（SP）没有考虑非线性水质动态。此外，由于水质模拟通过水力剖面和需求模式进行参数化，传感器的布设通常依赖于水力条件。本研究提出了一种贪婪算法，解决了上述两个局限性。该算法以非线性动态系统和可观测性理论为基础，产生的传感器布设方案是次模化且对水力变化具有鲁棒性。论文提供了在基准水网络上的案例研究。关键发现为WDN运营商提供了实用建议。", "summary": "本研究针对饮用水网络中水质传感器的优化布设问题，提出了一种基于非线性动态系统和可观测性理论的贪婪算法。该算法旨在解决现有方法在处理非线性多物种水质动态和水力变化鲁棒性方面的不足。通过在基准水网络上的案例研究，验证了该算法的有效性，并为水网络运营商提供了实用的传感器布设建议。", "keywords": "水质传感器布设, 饮用水网络, 非线性系统, 可观测性, 贪婪算法", "comments": "该论文的创新之处在于将非线性动态系统和可观测性理论应用于水质传感器布设问题，克服了传统方法在处理复杂水质动态和水力变化鲁棒性方面的局限性。其提出的贪婪算法能够生成次模化且鲁棒的传感器布设方案，对于提高饮用水网络的监测效率和安全性具有重要意义。该研究为实际应用提供了有价值的指导。"}}
{"id": "2411.00265", "title": "Quantifying calibration error in modern neural networks through evidence based theory", "authors": ["Koffi Ismael Ouattara"], "categories": ["cs.LG", "cs.AI", "math.LO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at FUSION 2025 Conference", "url": "http://arxiv.org/abs/2411.00265v2", "summary": "Trustworthiness in neural networks is crucial for their deployment in\ncritical applications, where reliability, confidence, and uncertainty play\npivotal roles in decision-making. Traditional performance metrics such as\naccuracy and precision fail to capture these aspects, particularly in cases\nwhere models exhibit overconfidence. To address these limitations, this paper\nintroduces a novel framework for quantifying the trustworthiness of neural\nnetworks by incorporating subjective logic into the evaluation of Expected\nCalibration Error (ECE). This method provides a comprehensive measure of trust,\ndisbelief, and uncertainty by clustering predicted probabilities and fusing\nopinions using appropriate fusion operators. We demonstrate the effectiveness\nof this approach through experiments on MNIST and CIFAR-10 datasets, where\npost-calibration results indicate improved trustworthiness. The proposed\nframework offers a more interpretable and nuanced assessment of AI models, with\npotential applications in sensitive domains such as healthcare and autonomous\nsystems.", "comment": "Accepted at FUSION 2025 Conference", "pdf_url": "http://arxiv.org/pdf/2411.00265v2", "cate": "cs.LG", "date": "2024-10-31", "updated": "2025-07-16", "AI": {"title_translation": "通过证据理论量化现代神经网络中的校准误差", "tldr": "本文提出了一种结合主观逻辑的新框架，用于量化神经网络的信任度，通过评估预期校准误差（ECE）并聚类预测概率来提高模型在关键应用中的可靠性。", "motivation": "传统性能指标（如准确性和精确度）无法捕捉神经网络的可靠性、置信度和不确定性，尤其是在模型过度自信的情况下，这限制了它们在关键应用中的部署。", "method": "本文引入了一个新颖的框架，通过将主观逻辑纳入预期校准误差（ECE）的评估中，来量化神经网络的信任度。该方法通过聚类预测概率并使用适当的融合算子融合意见，提供信任、不信任和不确定性的综合度量。", "result": "在MNIST和CIFAR-10数据集上的实验表明，后校准结果显示信任度有所提高。", "conclusion": "所提出的框架为AI模型提供了一种更具可解释性和细致的评估方法，在医疗保健和自主系统等敏感领域具有潜在应用。", "translation": "神经网络的可靠性对于它们在关键应用中的部署至关重要，在这些应用中，可靠性、置信度和不确定性在决策中起着关键作用。传统的性能指标，如准确性和精确度，未能捕捉到这些方面，尤其是在模型表现出过度自信的情况下。为了解决这些限制，本文引入了一个新颖的框架，通过将主观逻辑纳入预期校准误差（ECE）的评估中，来量化神经网络的信任度。该方法通过聚类预测概率并使用适当的融合算子融合意见，提供信任、不信任和不确定性的综合度量。我们通过在MNIST和CIFAR-10数据集上进行的实验证明了这种方法的有效性，其中后校准结果表明信任度有所提高。所提出的框架为AI模型提供了一种更具可解释性和细致的评估方法，在医疗保健和自主系统等敏感领域具有潜在应用。", "summary": "本研究针对传统性能指标无法捕捉神经网络信任度的问题，提出了一种新的框架。该框架将主观逻辑融入预期校准误差（ECE）评估中，通过聚类预测概率和融合意见，全面衡量模型的信任、不信任和不确定性。实验结果表明，该方法能有效提高模型校准后的信任度，为AI模型在关键领域（如医疗保健和自动驾驶）的应用提供了更可靠和可解释的评估工具。", "keywords": "神经网络, 校准误差, 主观逻辑, 信任度, ECE", "comments": "该论文通过引入主观逻辑来量化神经网络的信任度，提供了一种新颖的校准误差评估方法。其创新之处在于将信任、不信任和不确定性纳入度量，这对于提升模型在敏感和关键应用中的可靠性至关重要。该方法在可解释性方面有所提升，但其在更复杂和大规模数据集上的泛化能力及计算效率可能需要进一步研究。"}}
{"id": "2507.12406", "title": "Refinement of the theory and convergence of the Sinc convolution", "authors": ["Tomoaki Okayama"], "categories": ["math.NA", "cs.NA", "65D15, 65D30"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12406v1", "summary": "The Sinc convolution is an approximate formula for indefinite convolutions\nproposed by F. Stenger. The formula was derived based on the Sinc indefinite\nintegration formula combined with the single-exponential transformation.\nAlthough its efficiency has been confirmed in variety of areas, there remain\nsome open problems in its theory. The first contribution of this study is to\nresolve those problems by refinement of the theory of the Sinc convolution.\nThis contribution includes a partial resolution of Stenger's conjecture. The\nsecond contribution of this study is to improve the convergence rate by\nreplacement of the single-exponential transformation with the\ndouble-exponential transformation. In both theoretical and numerical ways, this\nstudy also shows that the convergence rate of the new formula is improved\ncompared to Stenger's formula.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12406v1", "cate": "math.NA", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Sinc卷积理论与收敛性的改进", "tldr": "本文通过改进Sinc卷积的理论并用双指数变换替代单指数变换，解决了现有问题并提高了收敛速度。", "motivation": "Sinc卷积虽然在许多领域被证实有效，但其理论中仍存在一些悬而未决的问题，包括Stenger的猜想，因此需要对理论进行改进和收敛性提升。", "method": "本研究首先通过改进Sinc卷积的理论来解决现有问题，包括部分解决Stenger的猜想。其次，通过用双指数变换替代单指数变换来提高收敛速度。研究通过理论和数值方法展示了新公式的改进。", "result": "解决了Sinc卷积理论中的开放问题，部分解决了Stenger的猜想。通过采用双指数变换，成功提高了Sinc卷积的收敛速度，并且新公式的收敛速度优于Stenger的公式。", "conclusion": "通过对Sinc卷积理论的改进和采用双指数变换，本研究提出的新公式在理论和数值上都显示出更高的收敛速度。", "translation": "Sinc卷积是F. Stenger提出的一种用于不定卷积的近似公式。该公式是基于Sinc不定积分公式结合单指数变换推导出来的。尽管其效率已在多个领域得到证实，但其理论中仍存在一些悬而未决的问题。本研究的首个贡献是通过改进Sinc卷积的理论来解决这些问题。这一贡献包括部分解决了Stenger的猜想。本研究的第二个贡献是通过用双指数变换替代单指数变换来提高收敛速度。通过理论和数值两种方式，本研究还表明新公式的收敛速度相较于Stenger的公式有所提高。", "summary": "本文旨在改进F. Stenger提出的Sinc卷积公式的理论和收敛性。研究首先通过完善理论解决了Sinc卷积中存在的开放问题，并部分解决了Stenger的猜想。其次，通过将原公式中的单指数变换替换为双指数变换，显著提高了公式的收敛速度。理论和数值分析均证实了新公式相较于Stenger原公式的收敛性提升。", "keywords": "Sinc卷积, 收敛性, 双指数变换, Stenger猜想, 数值积分", "comments": "这篇论文通过解决Sinc卷积的理论开放问题并引入双指数变换来提高收敛性，对数值积分和卷积计算领域做出了重要贡献。其创新性在于对现有理论的深度修正以及对变换方法的优化，这对于需要高精度计算的应用具有重要意义。"}}
{"id": "2507.12408", "title": "Bounding the asymptotic quantum value of all multipartite compiled non-local games", "authors": ["Matilde Baroni", "Dominik Leichtle", "Siniša Janković", "Ivan Šupić"], "categories": ["quant-ph", "cs.CR"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      74 pages, 14 figures", "url": "http://arxiv.org/abs/2507.12408v1", "summary": "Non-local games are a powerful tool to distinguish between correlations\npossible in classical and quantum worlds. Kalai et al. (STOC'23) proposed a\ncompiler that converts multipartite non-local games into interactive protocols\nwith a single prover, relying on cryptographic tools to remove the assumption\nof physical separation of the players. While quantum completeness and classical\nsoundness of the construction have been established for all multipartite games,\nquantum soundness is known only in the special case of bipartite games.\n  In this paper, we prove that the Kalai et al.'s compiler indeed achieves\nquantum soundness for all multipartite compiled non-local games, by showing\nthat any correlations that can be generated in the asymptotic case correspond\nto quantum commuting strategies.\n  Our proof uses techniques from the theory of operator algebras, and relies on\na characterisation of sequential operationally no-signalling strategies as\nquantum commuting operator strategies in the multipartite case, thereby\ngeneralising several previous results. On the way, we construct universal\nC*-algebras of sequential PVMs and prove a new chain rule for Radon-Nikodym\nderivatives of completely positive maps on C*-algebras which may be of\nindependent interest.", "comment": "74 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.12408v1", "cate": "quant-ph", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "限制所有多方编译非局域博弈的渐近量子值", "tldr": "本文证明了Kalai等人提出的编译器对所有多方编译非局域博弈都实现了量子可靠性，通过展示渐近情况下的相关性对应于量子交换策略。", "motivation": "Kalai等人提出的编译器可以将多方非局域博弈转换为单证明者交互协议，并已证明其量子完备性和经典可靠性适用于所有多方博弈，但其量子可靠性此前仅在双分量博弈的特殊情况下得到证实。本文旨在证明该编译器对所有多方编译非局域博弈都具有量子可靠性。", "method": "本文利用算子代数理论的技术，并依赖于将多方情况下的顺序操作无信号策略表征为量子交换算子策略，从而推广了之前的一些结果。此外，还构建了顺序PVM的通用C*-代数，并证明了C*-代数上完全正映射的Radon-Nikodym导数的新链式法则。", "result": "证明了Kalai等人提出的编译器对所有多方编译非局域博弈确实实现了量子可靠性。具体而言，展示了渐近情况中可以生成的所有相关性都对应于量子交换策略。", "conclusion": "本文成功证明了Kalai等人提出的多方非局域博弈编译器的量子可靠性，填补了此前仅在双分量博弈中已知此特性的空白，并推广了相关理论，对量子信息和算子代数领域具有重要意义。", "translation": "非局域博弈是区分经典世界和量子世界中可能存在的关联的强大工具。Kalai等人（STOC'23）提出了一种编译器，它将多方非局域博弈转换为具有单一证明者的交互协议，并依赖于密码学工具来消除参与者物理分离的假设。虽然该结构的量子完备性和经典可靠性已经为所有多方博弈建立，但量子可靠性仅在双分量博弈的特殊情况下已知。\n在本文中，我们证明了Kalai等人的编译器确实对所有多方编译非局域博弈都实现了量子可靠性，通过展示在渐近情况下可以生成的所有关联都对应于量子交换策略。\n我们的证明使用了算子代数理论的技术，并依赖于将顺序操作无信号策略表征为多方情况下的量子交换算子策略，从而推广了之前的一些结果。在此过程中，我们构建了顺序PVM的通用C*-代数，并证明了C*-代数上完全正映射的Radon-Nikodym导数的新链式法则，这可能具有独立的兴趣。", "summary": "本文解决了Kalai等人提出的多方非局域博弈编译器在所有多方博弈中的量子可靠性问题。此前，该编译器的量子可靠性仅在双分量博弈中得到证明。通过运用算子代数理论并表征渐近情况下的关联为量子交换策略，本文成功证明了该编译器对于所有多方编译非局域博弈都具有量子可靠性。研究还构建了通用C*-代数并提出了新的链式法则，对相关理论领域有所贡献。", "keywords": "非局域博弈, 量子可靠性, 算子代数, 多方博弈, 量子交换策略", "comments": "本文的重要创新在于解决了多方非局域博弈编译器量子可靠性的一个关键开放问题，从而使该编译器在更广泛的应用中变得更加鲁棒。其证明方法依赖于高级的算子代数技术，并推广了现有结果，显示了理论深度。此外，衍生的C*-代数和链式法则也具有独立的数学价值。"}}
{"id": "2507.12443", "title": "LLM-Based Config Synthesis requires Disambiguation", "authors": ["Rajdeep Mondal", "Nikolaj Bjorner", "Todd Millstein", "Alan Tang", "George Varghese"], "categories": ["cs.NI", "cs.AI", "cs.HC", "cs.PL"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12443v1", "summary": "Beyond hallucinations, another problem in program synthesis using LLMs is\nambiguity in user intent. We illustrate the ambiguity problem in a networking\ncontext for LLM-based incremental configuration synthesis of route-maps and\nACLs. These structures frequently overlap in header space, making the relative\npriority of actions impossible for the LLM to infer without user interaction.\nMeasurements in a large cloud identify complex ACLs with 100's of overlaps,\nshowing ambiguity is a real problem. We propose a prototype system, Clarify,\nwhich uses an LLM augmented with a new module called a Disambiguator that helps\nelicit user intent. On a small synthetic workload, Clarify incrementally\nsynthesizes routing policies after disambiguation and then verifies them. Our\ntreatment of ambiguities is useful more generally when the intent of updates\ncan be correctly synthesized by LLMs, but their integration is ambiguous and\ncan lead to different global behaviors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12443v1", "cate": "cs.NI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于LLM的配置合成需要消歧", "tldr": "基于LLM的程序合成中，用户意图的歧义是一个重要问题，尤其是在网络配置中规则重叠的情况下。本文提出了一个名为Clarify的原型系统，它通过一个消歧模块来帮助LLM澄清用户意图，从而解决这一问题。", "motivation": "除了幻觉问题，在使用LLM进行程序合成时，用户意图的模糊性是另一个问题。在网络环境中，LLM基于的路由映射和ACL的增量配置合成中，这种模糊性尤为突出，因为这些结构在头部空间经常重叠，使得LLM在没有用户交互的情况下无法推断操作的相对优先级。在大规模云环境中的测量表明，复杂的ACL存在数百个重叠，证实了歧义是一个真实存在的问题。", "method": "本文提出了一个名为Clarify的原型系统，该系统通过一个新的“消歧器”（Disambiguator）模块来增强LLM，该模块有助于引出用户意图。Clarify在一个小型合成工作负载上，在消歧后增量合成路由策略并进行验证。", "result": "在大规模云环境中的测量发现，复杂的ACL存在数百个重叠，表明歧义是一个真实存在的问题。Clarify系统在一个小型合成工作负载上，成功地在消歧后增量合成了路由策略并进行了验证。", "conclusion": "当LLM能够正确合成更新的意图，但它们的集成是模糊的并可能导致不同的全局行为时，本文对歧义的处理方法更普遍地有用。", "translation": "除了幻觉问题，使用大型语言模型（LLM）进行程序合成的另一个问题是用户意图的模糊性。我们以网络环境为例，说明了LLM基于路由映射和ACL的增量配置合成中的模糊性问题。这些结构在头部空间经常重叠，使得LLM在没有用户交互的情况下无法推断操作的相对优先级。对大型云环境的测量识别出数百个重叠的复杂ACL，表明模糊性是一个真实存在的问题。我们提出了一个名为Clarify的原型系统，该系统使用一个LLM，并增加了一个名为“消歧器”的新模块，以帮助引出用户意图。在一个小型合成工作负载上，Clarify在消歧后增量合成路由策略并进行验证。当LLM能够正确合成更新的意图，但它们的集成是模糊的并可能导致不同的全局行为时，我们对歧义的处理方法更普遍地有用。", "summary": "本文探讨了基于LLM的程序合成中用户意图模糊性的问题，尤其是在网络配置（如路由映射和ACL）中，由于规则重叠导致LLM难以推断优先级。研究指出，这种模糊性是一个在大型云环境中普遍存在的实际问题。为解决此问题，论文提出了一个名为Clarify的原型系统，该系统通过一个“消歧器”模块增强LLM，以有效引导用户澄清意图，并在小型合成工作负载上成功地增量合成并验证了路由策略。", "keywords": "LLM, 程序合成, 歧义, 网络配置, 消歧", "comments": "该论文解决了LLM在程序合成中一个关键但常被忽视的问题——用户意图的歧义性，这与幻觉问题不同。提出的Clarify系统及其Disambiguator模块为提升LLM在复杂、上下文敏感任务（如网络配置）中的实用性提供了一个创新性方法。"}}
{"id": "2507.11966", "title": "Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation", "authors": ["Ziyu Ge", "Gabriel Chua", "Leanne Tan", "Roy Ka-Wei Lee"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11966v1", "summary": "As online communication increasingly incorporates under-represented languages\nand colloquial dialects, standard translation systems often fail to preserve\nlocal slang, code-mixing, and culturally embedded markers of harmful speech.\nTranslating toxic content between low-resource language pairs poses additional\nchallenges due to scarce parallel data and safety filters that sanitize\noffensive expressions. In this work, we propose a reproducible, two-stage\nframework for toxicity-preserving translation, demonstrated on a code-mixed\nSinglish safety corpus. First, we perform human-verified few-shot prompt\nengineering: we iteratively curate and rank annotator-selected Singlish-target\nexamples to capture nuanced slang, tone, and toxicity. Second, we optimize\nmodel-prompt pairs by benchmarking several large language models using semantic\nsimilarity via direct and back-translation. Quantitative human evaluation\nconfirms the effectiveness and efficiency of our pipeline. Beyond improving\ntranslation quality, our framework contributes to the safety of multicultural\nLLMs by supporting culturally sensitive moderation and benchmarking in\nlow-resource contexts. By positioning Singlish as a testbed for inclusive NLP,\nwe underscore the importance of preserving sociolinguistic nuance in real-world\napplications such as content moderation and regional platform governance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11966v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "低资源新加坡式英语翻译中的毒性感知小样本提示", "tldr": "本文提出了一个两阶段框架，通过毒性感知的小样本提示来解决低资源新加坡式英语（Singlish）的毒性内容翻译问题，以保留文化细微差别和毒性。", "motivation": "标准翻译系统在处理欠代表语言和口语方言时，难以保留本地俚语、语码混用和文化嵌入的有害言论标记。在低资源语言对之间翻译毒性内容面临数据稀缺和安全过滤器清除冒犯性表达的额外挑战。", "method": "提出一个可复现的两阶段毒性保留翻译框架。第一阶段：进行人工验证的小样本提示工程，迭代策划和排序人工选择的新加坡式英语目标示例，以捕捉细微的俚语、语调和毒性。第二阶段：通过直接和回译的语义相似性，基准测试多个大型语言模型，优化模型-提示对。", "result": "定量的人工评估证实了该管道的有效性和效率。该框架不仅提高了翻译质量，还通过支持低资源语境下的文化敏感内容审核和基准测试，有助于多文化大型语言模型的安全性。", "conclusion": "该框架通过提高翻译质量和支持多文化大型语言模型的安全性，为包容性自然语言处理做出了贡献，并强调了在内容审核和区域平台治理等实际应用中保留社会语言学细微差别的重要性。", "translation": "随着在线交流越来越多地融入欠代表语言和口语方言，标准翻译系统往往无法保留本地俚语、语码混用和文化嵌入的有害言论标记。由于平行数据稀缺以及安全过滤器会清除冒犯性表达，在低资源语言对之间翻译有毒内容带来了额外的挑战。在这项工作中，我们提出了一个可复现的两阶段毒性保留翻译框架，并在一个语码混用的新加坡式英语安全语料库上进行了演示。首先，我们进行人工验证的小样本提示工程：我们迭代地策划和排序人工选择的新加坡式英语目标示例，以捕捉细微的俚语、语调和毒性。其次，我们通过直接和回译的语义相似性，基准测试了几个大型语言模型，以优化模型-提示对。定量的人工评估证实了我们管道的有效性和效率。除了提高翻译质量外，我们的框架通过支持低资源语境下的文化敏感内容审核和基准测试，有助于多文化大型语言模型的安全性。通过将新加坡式英语定位为包容性自然语言处理的试验台，我们强调了在内容审核和区域平台治理等实际应用中保留社会语言学细微差别的重要性。", "summary": "本文提出一个两阶段框架，用于在低资源环境下进行毒性保留的新加坡式英语（Singlish）翻译。该框架首先通过人工验证的小样本提示工程捕捉Singlish的语言和毒性细微差别，然后通过语义相似性优化模型-提示对。实验结果表明，该方法有效且高效，不仅提升了翻译质量，还有助于多文化大型语言模型在内容审核中的安全性。", "keywords": "低资源语言, 新加坡式英语, 毒性翻译, 小样本提示, 自然语言处理", "comments": "该论文的创新点在于提出了一个专门针对低资源语言（如Singlish）毒性内容翻译的两阶段框架，并通过小样本提示工程来解决文化敏感性和毒性保留的挑战。这对于处理在线交流中日益增多的欠代表语言和方言具有重要意义，尤其是在内容审核和多文化LLM安全方面。"}}
{"id": "2505.13017", "title": "Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning", "authors": ["Dang Thoai Phan", "Tuan Anh Huynh", "Van Tuan Pham", "Cao Minh Tran", "Van Thuan Mai", "Ngoc Quy Tran"], "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.13017v4", "summary": "The Continuous Wavelet Transform (CWT) is an effective tool for feature\nextraction in acoustic recognition using Convolutional Neural Networks (CNNs),\nparticularly when applied to non-stationary audio. However, its high\ncomputational cost poses a significant challenge, often leading researchers to\nprefer alternative methods such as the Short-Time Fourier Transform (STFT). To\naddress this issue, this paper proposes a method to reduce the computational\ncomplexity of CWT by optimizing the length of the wavelet kernel and the hop\nsize of the output scalogram. Experimental results demonstrate that the\nproposed approach significantly reduces computational cost while maintaining\nthe robust performance of the trained model in acoustic recognition tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.13017v4", "cate": "eess.AS", "date": "2025-05-19", "updated": "2025-07-16", "AI": {"title_translation": "深度学习中声学识别计算复杂性降低的最优尺度图", "tldr": "本文提出了一种优化连续小波变换（CWT）参数的方法，以降低其计算成本，同时在声学识别中保持性能。", "motivation": "连续小波变换（CWT）在声学识别中与卷积神经网络（CNN）结合使用时，尤其是在处理非平稳音频时，是一种有效的特征提取工具。然而，其高计算成本是一个重大挑战，导致研究人员倾向于使用短时傅里叶变换（STFT）等替代方法。", "method": "本文提出了一种通过优化小波核长度和输出尺度图的跳跃步长来降低CWT计算复杂性的方法。", "result": "实验结果表明，所提出的方法显著降低了计算成本，同时在声学识别任务中保持了训练模型的鲁棒性能。", "conclusion": "通过优化CWT的参数，可以有效降低其计算复杂度，使其在声学识别任务中更具实用性，而不会牺牲性能。", "translation": "连续小波变换（CWT）是一种有效的特征提取工具，与卷积神经网络（CNN）结合应用于声学识别，特别是在处理非平稳音频时。然而，其高计算成本构成了重大挑战，常常导致研究人员更倾向于选择短时傅里叶变换（STFT）等替代方法。为了解决这个问题，本文提出了一种通过优化小波核长度和输出尺度图的跳跃步长来降低CWT计算复杂性的方法。实验结果表明，所提出的方法显著降低了计算成本，同时在声学识别任务中保持了训练模型的鲁棒性能。", "summary": "本文提出了一种优化连续小波变换（CWT）参数以降低其计算复杂性的方法，旨在解决CWT在声学识别中高成本的问题。通过优化小波核长度和尺度图的跳跃步长，该方法成功地在显著降低计算成本的同时，保持了深度学习模型在声学识别任务中的鲁棒性能。", "keywords": "连续小波变换,计算复杂性,声学识别,深度学习,尺度图", "comments": "这篇论文通过优化连续小波变换（CWT）的关键参数，有效地解决了CWT在深度学习声学识别中计算成本过高的问题。其创新点在于从参数层面进行优化，使得CWT这种在处理非平稳信号方面具有优势的工具能够更实用化。这项工作对于推动CWT在实际声学应用中的普及具有重要意义，因为它克服了阻碍其广泛应用的主要障碍。"}}
{"id": "2407.00765", "title": "Structured and Balanced Multi-Component and Multi-Layer Neural Networks", "authors": ["Shijun Zhang", "Hongkai Zhao", "Yimin Zhong", "Haomin Zhou"], "categories": ["cs.LG", "cs.NA", "cs.NE", "math.NA", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Our codes and implementation details are available at this https URL", "url": "http://arxiv.org/abs/2407.00765v3", "summary": "In this work, we propose a balanced multi-component and multi-layer neural\nnetwork (MMNN) structure to accurately and efficiently approximate functions\nwith complex features, in terms of both degrees of freedom and computational\ncost. The main idea is inspired by a multi-component approach, in which each\ncomponent can be effectively approximated by a single-layer network, combined\nwith a multi-layer decomposition strategy to capture the complexity of the\ntarget function. Although MMNNs can be viewed as a simple modification of fully\nconnected neural networks (FCNNs) or multi-layer perceptrons (MLPs) by\nintroducing balanced multi-component structures, they achieve a significant\nreduction in training parameters, a much more efficient training process, and\nimproved accuracy compared to FCNNs or MLPs. Extensive numerical experiments\ndemonstrate the effectiveness of MMNNs in approximating highly oscillatory\nfunctions and their ability to automatically adapt to localized features.", "comment": "Our codes and implementation details are available at\n  https://github.com/ShijunZhangMath/MMNN", "pdf_url": "http://arxiv.org/pdf/2407.00765v3", "cate": "cs.LG", "date": "2024-06-30", "updated": "2025-07-16", "AI": {"title_translation": "结构化和平衡的多组件多层神经网络", "tldr": "本文提出了一种平衡的多组件多层神经网络（MMNN），通过引入平衡的多组件结构和多层分解策略，能够更高效、更准确地逼近复杂函数，显著优于传统FCNNs或MLPs。", "motivation": "为了在自由度和计算成本方面准确高效地逼近具有复杂特征的函数。", "method": "提出了一种平衡的多组件多层神经网络（MMNN）结构。其核心思想是受多组件方法启发，将每个组件由单层网络有效逼近，并结合多层分解策略来捕获目标函数的复杂性。", "result": "与全连接神经网络（FCNNs）或多层感知器（MLPs）相比，MMNNs显著减少了训练参数，实现了更高效的训练过程并提高了准确性。大量的数值实验证明MMNNs在逼近高振荡函数方面表现出有效性，并能自动适应局部特征。", "conclusion": "MMNNs提供了一种更高效、更准确的复杂函数逼近方法，在参数效率、训练速度和准确性方面优于传统神经网络。", "translation": "在这项工作中，我们提出了一种平衡的多组件多层神经网络（MMNN）结构，以在自由度和计算成本方面准确高效地逼近具有复杂特征的函数。其主要思想受多组件方法启发，其中每个组件可以由单层网络有效逼近，并结合多层分解策略来捕获目标函数的复杂性。尽管MMNNs可以被视为通过引入平衡的多组件结构对全连接神经网络（FCNNs）或多层感知器（MLPs）的简单修改，但与FCNNs或MLPs相比，它们实现了训练参数的显著减少，更高效的训练过程以及更高的准确性。大量的数值实验证明了MMNNs在逼近高振荡函数方面的有效性，以及它们自动适应局部特征的能力。", "summary": "本文提出了一种平衡的多组件多层神经网络（MMNN），旨在准确高效地逼近复杂函数。该网络受多组件方法启发，通过将每个组件由单层网络逼近并结合多层分解策略来处理函数复杂性。与传统FCNNs或MLPs相比，MMNN显著减少了训练参数，加速了训练过程，并提高了准确性。实验表明其在逼近高振荡函数和适应局部特征方面表现出色。", "keywords": "多组件神经网络, 多层神经网络, 函数逼近, 计算效率, 高振荡函数", "comments": "该论文的创新在于提出了平衡的多组件多层神经网络（MMNN）结构。这种结构巧妙地结合了多组件方法和多层分解策略，在保持或提高函数逼近准确性的同时，显著降低了模型参数量并提升了训练效率。尤其在处理高振荡函数和局部特征方面表现出的自适应能力，使其在数值分析和科学计算领域具有重要的应用潜力。"}}
{"id": "2502.05676", "title": "Generalized Venn and Venn-Abers Calibration with Applications in Conformal Prediction", "authors": ["Lars van der Laan", "Ahmed Alaa"], "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.05676v3", "summary": "Ensuring model calibration is critical for reliable prediction, yet popular\ndistribution-free methods such as histogram binning and isotonic regression\noffer only asymptotic guarantees. We introduce a unified framework for Venn and\nVenn-Abers calibration that extends Vovk's approach beyond binary\nclassification to a broad class of prediction problems defined by generic loss\nfunctions. Our method transforms any perfectly in-sample calibrated predictor\ninto a set-valued predictor that, in finite samples, outputs at least one\nmarginally calibrated point prediction. These set predictions shrink\nasymptotically and converge to a single conditionally calibrated prediction,\ncapturing epistemic uncertainty. We further propose Venn multicalibration, a\nnew approach for achieving finite-sample calibration across subpopulations. For\nquantile loss, our framework recovers group-conditional and multicalibrated\nconformal prediction as special cases and yields novel prediction intervals\nwith quantile-conditional coverage.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.05676v3", "cate": "stat.ML", "date": "2025-02-08", "updated": "2025-07-15", "AI": {"title_translation": "广义维恩和维恩-阿伯斯校准及其在共形预测中的应用", "tldr": "本文提出了一个统一的维恩和维恩-阿伯斯校准框架，将Vovk的方法扩展到更广泛的预测问题，并在有限样本下提供校准保证，捕获认知不确定性，且在分位数损失下可恢复共形预测。", "motivation": "确保模型校准对于可靠预测至关重要，但现有的流行无分布方法（如直方图分箱和等渗回归）仅提供渐近保证，缺乏有限样本下的保证。", "method": "本文引入了一个统一的维恩和维恩-阿伯斯校准框架，将Vovk的方法从二元分类扩展到由通用损失函数定义的一大类预测问题。该方法将任何在样本内完美校准的预测器转换为一个集值预测器，该预测器在有限样本下至少输出一个边际校准点预测。此外，还提出了维恩多重校准，一种在子群体间实现有限样本校准的新方法。", "result": "该方法在有限样本下输出至少一个边际校准点预测。这些集预测渐近收缩并收敛到单个条件校准预测，捕获了认知不确定性。对于分位数损失，该框架可恢复组条件和多重校准共形预测作为特例，并产生具有分位数条件覆盖的新型预测区间。", "conclusion": "本文提出的广义维恩和维恩-阿伯斯校准框架为广泛的预测问题提供了有限样本下的校准保证，并通过集值预测捕获认知不确定性，同时在特定损失函数下与共形预测建立了联系，提升了预测的可靠性。", "translation": "确保模型校准对于可靠预测至关重要，但流行的无分布方法（如直方图分箱和等渗回归）仅提供渐近保证。我们引入了一个统一的维恩和维恩-阿伯斯校准框架，将Vovk的方法从二元分类扩展到由通用损失函数定义的一大类预测问题。我们的方法将任何在样本内完美校准的预测器转换为一个集值预测器，该预测器在有限样本下至少输出一个边际校准点预测。这些集预测渐近收缩并收敛到单个条件校准预测，捕获认知不确定性。我们进一步提出了维恩多重校准，一种在子群体间实现有限样本校准的新方法。对于分位数损失，我们的框架可恢复组条件和多重校准共形预测作为特例，并产生具有分位数条件覆盖的新型预测区间。", "summary": "该论文提出了一个广义的维恩和维恩-阿伯斯校准统一框架，扩展了Vovk的方法以处理更广泛的预测问题和通用损失函数。该方法将内部校准的预测器转换为集值预测，在有限样本下提供边际校准，并渐近收敛到条件校准预测以量化认知不确定性。此外，还引入了维恩多重校准以实现子群体的有限样本校准。该框架在分位数损失下可作为共形预测的特例，并生成具有分位数条件覆盖的新预测区间。", "keywords": "模型校准, 维恩校准, 共形预测, 有限样本, 认知不确定性", "comments": "本文的主要创新在于提出了一个统一的框架，将维恩和维恩-阿伯斯校准从二元分类扩展到更广泛的预测问题，并解决了现有方法仅提供渐近保证的局限性，提供了有限样本下的校准保证。其引入的集值预测器和维恩多重校准概念对于提高模型预测的可靠性和公平性具有重要意义。"}}
{"id": "2507.11979", "title": "Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness", "authors": ["Yuki Sakamoto", "Takahisa Uchida", "Hiroshi Ishiguro"], "categories": ["cs.CL", "cs.MA"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11979v1", "summary": "Large language models (LLMs) have emerged as powerful tools for simulating\ncomplex social phenomena using human-like agents with specific traits. In human\nsocieties, value similarity is important for building trust and close\nrelationships; however, it remains unexplored whether this principle holds true\nin artificial societies comprising LLM agents. Therefore, this study\ninvestigates the influence of value similarity on relationship-building among\nLLM agents through two experiments. First, in a preliminary experiment, we\nevaluated the controllability of values in LLMs to identify the most effective\nmodel and prompt design for controlling the values. Subsequently, in the main\nexperiment, we generated pairs of LLM agents imbued with specific values and\nanalyzed their mutual evaluations of trust and interpersonal closeness\nfollowing a dialogue. The experiments were conducted in English and Japanese to\ninvestigate language dependence. The results confirmed that pairs of agents\nwith higher value similarity exhibited greater mutual trust and interpersonal\ncloseness. Our findings demonstrate that the LLM agent simulation serves as a\nvalid testbed for social science theories, contributes to elucidating the\nmechanisms by which values influence relationship building, and provides a\nfoundation for inspiring new theories and insights into the social sciences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11979v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于价值的大型语言模型智能体模拟用于信任和人际亲密度的相互评估", "tldr": "本研究通过大型语言模型（LLM）智能体模拟，发现智能体之间更高的价值观相似性会导致更高的相互信任和人际亲密度，证明LLM智能体模拟是社会科学理论的有效试验台。", "motivation": "大型语言模型（LLM）已成为模拟复杂社会现象的强大工具，但价值观相似性在LLM智能体组成的人工社会中是否也适用于建立信任和亲密关系仍未被探索。因此，本研究旨在调查价值观相似性对LLM智能体之间关系建立的影响。", "method": "本研究通过两项实验进行。首先，在初步实验中评估了LLM中价值观的可控性，以确定最有效的模型和提示设计来控制价值观。随后，在主要实验中，生成了具有特定价值观的LLM智能体对，并分析了它们在对话后对信任和人际亲密度的相互评估。实验以英语和日语进行，以探究语言依赖性。", "result": "结果证实，价值观相似度较高的智能体对表现出更高的相互信任和人际亲密度。", "conclusion": "本研究结果表明，LLM智能体模拟可作为社会科学理论的有效试验台，有助于阐明价值观影响关系建立的机制，并为启发社会科学新理论和见解奠定基础。", "translation": "大型语言模型（LLM）已成为强大的工具，可用于模拟具有特定特质的类人智能体，从而模拟复杂的社会现象。在人类社会中，价值观相似性对于建立信任和亲密关系至关重要；然而，这一原则是否适用于由LLM智能体组成的人工社会仍未被探索。因此，本研究通过两项实验调查了价值观相似性对LLM智能体之间关系建立的影响。首先，在初步实验中，我们评估了LLM中价值观的可控性，以确定控制价值观最有效的模型和提示设计。随后，在主要实验中，我们生成了具有特定价值观的LLM智能体对，并分析了它们在对话后对信任和人际亲密度的相互评估。实验以英语和日语进行，以探究语言依赖性。结果证实，价值观相似度较高的智能体对表现出更高的相互信任和人际亲密度。我们的研究结果表明，LLM智能体模拟可作为社会科学理论的有效试验台，有助于阐明价值观影响关系建立的机制，并为启发社会科学新理论和见解奠定基础。", "summary": "本研究探讨了价值观相似性在大型语言模型（LLM）智能体之间建立信任和亲密关系中的作用。通过两项实验，首先评估了LLM中价值观的可控性，然后生成了具有特定价值观的智能体对，并分析了它们在对话后对信任和人际亲密度的相互评估。实验以英语和日语进行。结果表明，价值观相似度越高的智能体对，其相互信任和人际亲密度也越高。这表明LLM智能体模拟可以作为验证社会科学理论的有效工具，并有助于理解价值观如何影响关系建立。", "keywords": "大型语言模型, 智能体模拟, 价值观相似性, 信任, 人际亲密度", "comments": "这项研究的创新之处在于利用LLM智能体模拟来验证社会科学理论，特别是关于价值观相似性与关系建立之间的关系。它提供了一个新的、可控的实验平台来研究复杂的社会现象，为社会科学研究开辟了新途径。其重要性在于证明了LLM在模拟人类社会行为方面的潜力，并为未来探索人工智能与人类社会互动提供了基础。"}}
{"id": "2507.12073", "title": "On the error correction of iterative bounded distance decoding of generalized LDPC codes", "authors": ["David Burshtein"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Under review in IEEE, Submitted: December 2024, Revised: July 2025", "url": "http://arxiv.org/abs/2507.12073v1", "summary": "Consider an ensemble of regular generalized LDPC (GLDPC) codes and assume\nthat the same component code is associated with each parity check node. To\ndecode a GLDPC code from the ensemble, we use the bit flipping bounded distance\ndecoding algorithm, which is an extension of the bit flipping algorithm for\nLDPC codes. Previous work has shown conditions, under which, for a typical code\nin the ensemble with blocklength sufficiently large, a positive constant\nfraction of worst case errors can be corrected. In this work we first show that\nthese requirements can be relaxed for ensembles with small left degrees. While\nprevious work on GLDPC codes has considered expander graph arguments, our\nanalysis formulates a necessary condition that the Tanner graph needs to\nsatisfy for a failure event and then shows that the probability of this event\nvanishes for a sufficiently large blocklength. We then extend the analysis to\nrandom error correction and derive a lower bound on the fraction of random\nerrors that can be corrected asymptotically. We discuss the extension of our\nresults to non-binary GLDPC codes and present numerical examples.", "comment": "Under review in IEEE, Submitted: December 2024, Revised: July 2025", "pdf_url": "http://arxiv.org/pdf/2507.12073v1", "cate": "cs.IT", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "广义LDPC码迭代有限距离译码的纠错性能研究", "tldr": "本文研究了广义LDPC (GLDPC) 码迭代有限距离译码的纠错能力，放宽了纠错条件，将分析扩展到随机错误，并提供了数值示例。", "motivation": "之前的研究表明，对于足够大的块长，典型GLDPC码可以在最坏情况下纠正一部分错误。本文旨在放宽小左度码集合的这些要求，并将分析扩展到随机错误纠正。", "method": "本文采用比特翻转有限距离译码算法。与之前基于扩展图的分析不同，本文的分析为故障事件的Tanner图制定了一个必要条件，并证明了该事件的概率在块长足够大时会消失。随后，将分析扩展到随机错误纠正。", "result": "1. 放宽了小左度码集合的纠错要求。2. 制定了Tanner图上故障事件的必要条件，并证明了在足够大的块长下，该事件的概率会消失。3. 推导了渐近可纠正随机错误比例的下界。4. 讨论了结果向非二进制GLDPC码的扩展，并提供了数值示例。", "conclusion": "本文成功地放宽了小左度GLDPC码的纠错条件，将分析扩展到随机错误，并提供了一种新的分析框架来理解其性能。", "translation": "考虑一个正则广义LDPC (GLDPC) 码集合，并假设每个奇偶校验节点都关联相同的分量码。为了解码集合中的GLDPC码，我们使用比特翻转有限距离译码算法，它是LDPC码比特翻转算法的扩展。之前的工作表明，在特定条件下，对于一个集合中块长足够大的典型码，可以纠正正数常数比例的最坏情况错误。在这项工作中，我们首先表明，对于小左度集合，这些要求可以放宽。虽然之前关于GLDPC码的工作考虑了扩展图论证，但我们的分析为Tanner图需要满足的故障事件制定了一个必要条件，然后表明该事件的概率对于足够大的块长会消失。然后，我们将分析扩展到随机错误纠正，并推导了渐近可纠正随机错误比例的下界。我们讨论了我们的结果向非二进制GLDPC码的扩展，并提供了数值示例。", "summary": "本文研究了广义LDPC (GLDPC) 码的迭代有限距离译码的纠错性能。它放宽了先前关于最坏情况错误纠正的条件，特别是对于小左度码集合。该研究通过制定Tanner图上解码失败的必要条件并证明其在块长足够大时概率消失，从而超越了传统的扩展图论证。此外，工作还将分析扩展到随机错误纠正，推导了可纠正错误比例的下界，并讨论了其在非二进制GLDPC码中的应用，辅以数值示例。", "keywords": "GLDPC码, 迭代译码, 有限距离译码, 纠错, Tanner图", "comments": "本文的创新之处在于放宽了GLDPC码的纠错条件，并引入了一种新的分析方法，该方法侧重于Tanner图上的故障条件而非扩展图论证，从而提供了对其纠错能力的更深入理解。"}}
{"id": "2505.08140", "title": "Lost in Transmission: When and Why LLMs Fail to Reason Globally", "authors": ["Tobias Schnabel", "Kiran Tomlinson", "Adith Swaminathan", "Jennifer Neville"], "categories": ["cs.AI", "cs.FL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      28 pages", "url": "http://arxiv.org/abs/2505.08140v3", "summary": "Despite their many successes, transformer-based large language models (LLMs)\ncontinue to struggle with tasks that require complex reasoning over large parts\nof their input. We argue that these failures arise due to capacity limits on\nthe accurate flow of information within LLMs. To formalize this issue, we\nintroduce the bounded attention prefix oracle (BAPO) model, a new computational\nframework that models bandwidth constraints on attention heads, the mechanism\nfor internal communication in LLMs. We show that several important reasoning\nproblems like graph reachability require high communication bandwidth for BAPOs\nto solve; we call these problems BAPO-hard. Our experiments corroborate our\ntheoretical predictions: GPT-4o, Claude, and Gemini succeed on BAPO-easy tasks\nand fail even on relatively small BAPO-hard tasks. BAPOs also reveal another\nbenefit of chain of thought (CoT): we prove that breaking down a task using CoT\ncan turn any BAPO-hard problem into a BAPO-easy one. Our results offer\nprincipled explanations for key LLM failures and suggest directions for\narchitectures and inference methods that mitigate bandwidth limits.", "comment": "28 pages", "pdf_url": "http://arxiv.org/pdf/2505.08140v3", "cate": "cs.AI", "date": "2025-05-13", "updated": "2025-07-15", "AI": {"title_translation": "传输中迷失：大型语言模型何时以及为何无法进行全局推理", "tldr": "大型语言模型（LLMs）在复杂推理任务中表现不佳，原因在于其内部信息流动的容量限制。本文引入了BAPO模型来形式化这一问题，实验证明主流LLMs在BAPO-hard任务上会失败，但思维链（CoT）可以将其转化为BAPO-easy问题，为LLM的失败提供了理论解释并指明了改进方向。", "motivation": "尽管大型语言模型（LLMs）取得了许多成功，但它们在需要对输入大部分内容进行复杂推理的任务上仍然表现不佳。本文认为这些失败是由于LLMs内部信息准确流动的容量限制所致。", "method": "本文引入了有界注意力前缀预言机（BAPO）模型，这是一个新的计算框架，用于模拟注意力头（LLMs内部通信机制）的带宽限制。研究表明，图可达性等重要的推理问题需要BAPO模型的高通信带宽才能解决，并将这些问题定义为BAPO-hard问题。", "result": "实验证实了理论预测：GPT-4o、Claude和Gemini在BAPO-easy任务上表现成功，但在相对较小的BAPO-hard任务上失败。BAPO模型还揭示了思维链（CoT）的另一个好处：通过CoT分解任务可以将任何BAPO-hard问题转化为BAPO-easy问题。", "conclusion": "本研究为关键的LLM失败提供了有原则的解释，并为缓解带宽限制的架构和推理方法指明了方向。", "translation": "尽管大型语言模型（LLMs）取得了许多成功，但它们在需要对输入大部分内容进行复杂推理的任务上仍然表现不佳。我们认为这些失败是由于LLMs内部信息准确流动的容量限制所致。为了将这个问题形式化，我们引入了有界注意力前缀预言机（BAPO）模型，这是一个新的计算框架，用于模拟注意力头（LLMs内部通信机制）的带宽限制。我们表明，图可达性等几个重要的推理问题需要BAPO模型的高通信带宽才能解决；我们将这些问题称为BAPO-hard问题。我们的实验证实了我们的理论预测：GPT-4o、Claude和Gemini在BAPO-easy任务上表现成功，但在相对较小的BAPO-hard任务上失败。BAPO模型还揭示了思维链（CoT）的另一个好处：我们证明通过CoT分解任务可以将任何BAPO-hard问题转化为BAPO-easy问题。我们的结果为关键的LLM失败提供了有原则的解释，并为缓解带宽限制的架构和推理方法指明了方向。", "summary": "本文探讨了大型语言模型（LLMs）在处理需要全局推理的复杂任务时遇到的困难，并将其归因于LLMs内部信息流动的容量限制。为形式化这一问题，研究引入了有界注意力前缀预言机（BAPO）模型，该模型模拟了注意力头的带宽约束，并定义了需要高通信带宽的“BAPO-hard”问题。实验结果验证了主流LLMs在BAPO-hard任务上的失败，同时发现思维链（CoT）能够将BAPO-hard问题转化为BAPO-easy问题。这项研究为LLM的推理失败提供了理论解释，并为未来的模型架构和推理方法提供了改进方向。", "keywords": "大型语言模型, 复杂推理, 信息流, 注意力机制, 思维链", "comments": "这篇论文通过引入BAPO模型，为LLMs在复杂推理任务中的失败提供了一个新颖且有原则的解释，强调了内部信息传输带宽的重要性。它不仅理论化了问题，还通过实验验证了其假设，并提出了思维链（CoT）作为一种缓解策略，对LLM的未来发展具有指导意义。"}}
{"id": "2503.05063", "title": "Lightweight Hypercomplex MRI Reconstruction: A Generalized Kronecker-Parameterized Approach", "authors": ["Haosen Zhang", "Jiahao Huang", "Yinzhe Wu", "Congren Dai", "Fanwen Wang", "Zhenxuan Zhang", "Guang Yang"], "categories": ["eess.IV", "cs.CV", "I.2.6; I.4.5"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      11 pages, 3 figures. Submitted for publication", "url": "http://arxiv.org/abs/2503.05063v3", "summary": "Magnetic Resonance Imaging (MRI) is crucial for clinical diagnostics but is\nhindered by prolonged scan times. Current deep learning models enhance MRI\nreconstruction but are often memory-intensive and unsuitable for\nresource-limited systems. This paper introduces a lightweight MRI\nreconstruction model leveraging Kronecker-Parameterized Hypercomplex Neural\nNetworks to achieve high performance with reduced parameters. By integrating\nKronecker-based modules, including Kronecker MLP, Kronecker Window Attention,\nand Kronecker Convolution, the proposed model efficiently extracts spatial\nfeatures while preserving representational power. We introduce Kronecker U-Net\nand Kronecker SwinMR, which maintain high reconstruction quality with\napproximately 50% fewer parameters compared to existing models. Experimental\nevaluation on the FastMRI dataset demonstrates competitive PSNR, SSIM, and\nLPIPS metrics, even at high acceleration factors (8x and 16x), with no\nsignificant performance drop. Additionally, Kronecker variants exhibit superior\ngeneralization and reduced overfitting on limited datasets, facilitating\nefficient MRI reconstruction on hardware-constrained systems. This approach\nsets a new benchmark for parameter-efficient medical imaging models.", "comment": "11 pages, 3 figures. Submitted for publication", "pdf_url": "http://arxiv.org/pdf/2503.05063v3", "cate": "eess.IV", "date": "2025-03-07", "updated": "2025-07-15", "AI": {"title_translation": "轻量级超复数MRI重建：一种广义克罗内克参数化方法", "tldr": "提出一种基于克罗内克参数化超复数神经网络的轻量级MRI重建模型，参数量减半，性能保持竞争力，适用于资源受限系统。", "motivation": "MRI扫描时间长，现有深度学习模型内存密集，不适用于资源受限系统。", "method": "引入克罗内克参数化超复数神经网络，通过集成克罗内克MLP、克罗内克窗口注意力、克罗内克卷积等模块，构建了克罗内克U-Net和克罗内克SwinMR，以减少参数量并保持表示能力。", "result": "在FastMRI数据集上，参数量减少约50%，PSNR、SSIM和LPIPS指标具有竞争力，在高加速因子（8x和16x）下性能无显著下降。克罗内克变体在有限数据集上表现出优越的泛化能力和更低的过拟合。", "conclusion": "该方法为参数高效的医学图像模型树立了新基准，实现了在硬件受限系统上高效的MRI重建。", "translation": "磁共振成像（MRI）对临床诊断至关重要，但其扫描时间长是一个阻碍。当前的深度学习模型虽然增强了MRI重建，但通常内存密集且不适用于资源受限的系统。本文介绍了一种轻量级MRI重建模型，该模型利用克罗内克参数化超复数神经网络，以更少的参数实现高性能。通过集成基于克罗内克的模块，包括克罗内克MLP、克罗内克窗口注意力和克罗内克卷积，所提出的模型在保留表示能力的同时有效地提取空间特征。我们引入了克罗内克U-Net和克罗内克SwinMR，它们与现有模型相比，在参数减少约50%的情况下仍保持了高重建质量。在FastMRI数据集上的实验评估表明，即使在高加速因子（8倍和16倍）下，其PSNR、SSIM和LPIPS指标也具有竞争力，且性能没有显著下降。此外，克罗内克变体在有限数据集上表现出优越的泛化能力和更低的过拟合，从而有助于在硬件受限的系统上实现高效的MRI重建。这种方法为参数高效的医学成像模型树立了新基准。", "summary": "该论文提出一种轻量级MRI重建模型，利用克罗内克参数化超复数神经网络，通过引入克罗内克模块（如克罗内克U-Net和克罗内克SwinMR），将模型参数量减少约50%，同时在FastMRI数据集上保持了与现有模型相当的重建质量，并展现出更好的泛化能力，适用于资源受限的硬件系统。", "keywords": "MRI重建, 克罗内克参数化, 超复数神经网络, 轻量级, 深度学习", "comments": "该研究通过引入克罗内克参数化方法，有效解决了深度学习MRI重建模型参数量大、不适用于资源受限设备的问题。其创新点在于将克罗内克分解与超复数神经网络结合，实现了显著的参数效率提升，同时保持了高性能，这对于临床应用中设备的普及和实时性具有重要意义。"}}
{"id": "2411.10745", "title": "Bridging the Skeleton-Text Modality Gap: Diffusion-Powered Modality Alignment for Zero-shot Skeleton-based Action Recognition", "authors": ["Jeonghyeok Do", "Munchurl Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 (camera-ready version). Please visit our project page at this https URL", "url": "http://arxiv.org/abs/2411.10745v4", "summary": "In zero-shot skeleton-based action recognition (ZSAR), aligning skeleton\nfeatures with the text features of action labels is essential for accurately\npredicting unseen actions. ZSAR faces a fundamental challenge in bridging the\nmodality gap between the two-kind features, which severely limits\ngeneralization to unseen actions. Previous methods focus on direct alignment\nbetween skeleton and text latent spaces, but the modality gaps between these\nspaces hinder robust generalization learning. Motivated by the success of\ndiffusion models in multi-modal alignment (e.g., text-to-image, text-to-video),\nwe firstly present a diffusion-based skeleton-text alignment framework for\nZSAR. Our approach, Triplet Diffusion for Skeleton-Text Matching (TDSM),\nfocuses on cross-alignment power of diffusion models rather than their\ngenerative capability. Specifically, TDSM aligns skeleton features with text\nprompts by incorporating text features into the reverse diffusion process,\nwhere skeleton features are denoised under text guidance, forming a unified\nskeleton-text latent space for robust matching. To enhance discriminative\npower, we introduce a triplet diffusion (TD) loss that encourages our TDSM to\ncorrect skeleton-text matches while pushing them apart for different action\nclasses. Our TDSM significantly outperforms very recent state-of-the-art\nmethods with significantly large margins of 2.36%-point to 13.05%-point,\ndemonstrating superior accuracy and scalability in zero-shot settings through\neffective skeleton-text matching.", "comment": "ICCV 2025 (camera-ready version). Please visit our project page at\n  https://kaist-viclab.github.io/TDSM_site/", "pdf_url": "http://arxiv.org/pdf/2411.10745v4", "cate": "cs.CV", "date": "2024-11-16", "updated": "2025-07-16", "AI": {"title_translation": "弥合骨架-文本模态鸿沟：扩散驱动的模态对齐用于零样本骨架动作识别", "tldr": "提出TDSM，一种基于扩散模型的骨架-文本对齐框架，通过文本引导的逆向扩散和三重扩散损失，显著提升零样本骨架动作识别的性能。", "motivation": "零样本骨架动作识别（ZSAR）中，骨架特征与动作标签的文本特征对齐至关重要，但两者之间的模态鸿沟严重限制了对未见动作的泛化能力。现有方法直接对齐骨架和文本潜在空间，但模态鸿沟阻碍了鲁棒的泛化学习。", "method": "提出了“骨架-文本匹配三重扩散”（TDSM）框架，首次将扩散模型应用于ZSAR的骨架-文本对齐。TDSM利用扩散模型的交叉对齐能力而非生成能力，通过在逆向扩散过程中融入文本特征，在文本引导下对骨架特征进行去噪，形成一个统一的骨架-文本潜在空间以实现鲁棒匹配。此外，引入三重扩散（TD）损失，鼓励TDSM正确匹配骨架-文本对，同时区分不同动作类别。", "result": "TDSM显著优于最新的最先进方法，性能提升2.36%至13.05%，在零样本设置下通过有效的骨架-文本匹配展现出卓越的准确性和可扩展性。", "conclusion": "Not mentioned in abstract", "translation": "在零样本骨架动作识别（ZSAR）中，将骨架特征与动作标签的文本特征对齐对于准确预测未见动作至关重要。ZSAR面临着弥合这两种特征之间模态鸿沟的根本挑战，这严重限制了对未见动作的泛化能力。以前的方法侧重于骨架和文本潜在空间之间的直接对齐，但这些空间之间的模态鸿沟阻碍了鲁棒的泛化学习。受扩散模型在多模态对齐（例如，文本到图像、文本到视频）方面成功的启发，我们首次提出了一种基于扩散的骨架-文本对齐框架用于ZSAR。我们的方法，即骨架-文本匹配三重扩散（TDSM），侧重于扩散模型的交叉对齐能力而非其生成能力。具体来说，TDSM通过将文本特征融入逆向扩散过程来对齐骨架特征与文本提示，其中骨架特征在文本引导下去噪，形成一个统一的骨架-文本潜在空间以实现鲁棒匹配。为了增强判别能力，我们引入了三重扩散（TD）损失，鼓励TDSM进行正确的骨架-文本匹配，同时将它们推开以区分不同的动作类别。我们的TDSM显著优于最新的最先进方法，性能提升2.36%到13.05%，通过有效的骨架-文本匹配，在零样本设置中展示了卓越的准确性和可扩展性。", "summary": "本文针对零样本骨架动作识别（ZSAR）中骨架与文本模态鸿沟问题，首次提出基于扩散模型的骨架-文本对齐框架TDSM。TDSM利用扩散模型的交叉对齐能力，在文本引导下通过逆向扩散过程将骨架特征与文本提示对齐，形成统一的潜在空间。引入三重扩散损失以增强判别力。实验证明TDSM在ZSAR任务上显著优于现有SOTA方法，提升高达13.05%的性能。", "keywords": "零样本骨架动作识别, 扩散模型, 模态对齐, 三重扩散, 骨架-文本匹配", "comments": "本文创新性地将扩散模型应用于模态对齐而非生成任务，有效解决了零样本骨架动作识别中的骨架-文本模态鸿沟问题。其提出的TDSM框架通过文本引导的去噪过程和三重扩散损失，实现了鲁棒且判别力强的特征匹配，显著提升了该任务的性能和泛化能力，为多模态对齐提供了新的思路。"}}
{"id": "2502.11078", "title": "DEEPER Insight into Your User: Directed Persona Refinement for Dynamic Persona Modeling", "authors": ["Aili Chen", "Chengyu Du", "Jiangjie Chen", "Jinghan Xu", "Yikai Zhang", "Siyu Yuan", "Zulong Chen", "Liangyue Li", "Yanghua Xiao"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.11078v2", "summary": "To advance personalized applications such as recommendation systems and user\nbehavior prediction, recent research increasingly adopts large language models\n(LLMs) for human -readable persona modeling. In dynamic real -world scenarios,\neffective persona modeling necessitates leveraging streaming behavior data to\ncontinually optimize user personas. However, existing methods -whether\nregenerating personas or incrementally extending them with new behaviors -often\nfail to achieve sustained improvements in persona quality or future behavior\nprediction accuracy. To address this, we propose DEEPER, a novel approach for\ndynamic persona modeling that enables continual persona optimization.\nSpecifically, we enhance the model's direction -search capability through an\niterative reinforcement learning framework, allowing it to automatically\nidentify effective update directions and optimize personas using discrepancies\nbetween user behaviors and model predictions. Extensive experiments on dynamic\npersona modeling involving 4800 users across 10 domains highlight the superior\npersona optimization capabilities of DEEPER, delivering an impressive 32.2%\naverage reduction in user behavior prediction error over four update rounds\n-outperforming the best baseline by a remarkable 22.92%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.11078v2", "cate": "cs.CL", "date": "2025-02-16", "updated": "2025-07-16", "AI": {"title_translation": "DEEPER：深入了解您的用户：动态用户画像建模的定向画像优化", "tldr": "本文提出了DEEPER，一种利用强化学习动态优化用户画像的新方法，显著提高了用户行为预测的准确性。", "motivation": "现有动态用户画像建模方法在利用流式行为数据时，未能持续提升画像质量或未来行为预测准确性。", "method": "本文提出了DEEPER，一种新颖的动态用户画像建模方法，通过迭代强化学习框架增强模型的方向搜索能力，使其能够根据用户行为和模型预测之间的差异自动识别有效的更新方向并优化用户画像。", "result": "DEEPER在涉及10个领域4800名用户的动态用户画像建模实验中，展现出卓越的画像优化能力，在四轮更新中平均将用户行为预测误差降低了32.2%，比最佳基线高出22.92%。", "conclusion": "DEEPER通过持续优化用户画像，有效解决了现有动态用户画像建模方法的局限性，显著提高了预测准确性。", "translation": "为了推进推荐系统和用户行为预测等个性化应用，最近的研究越来越多地采用大型语言模型（LLM）进行人类可读的用户画像建模。在动态的现实世界场景中，有效的用户画像建模需要利用流式行为数据来持续优化用户画像。然而，现有方法——无论是重新生成画像还是通过新行为增量扩展画像——往往未能实现画像质量或未来行为预测准确性的持续改进。为了解决这个问题，我们提出了DEEPER，一种用于动态用户画像建模的新颖方法，它能够实现持续的用户画像优化。具体来说，我们通过迭代强化学习框架增强了模型的方向搜索能力，使其能够利用用户行为和模型预测之间的差异自动识别有效的更新方向并优化用户画像。在涉及10个领域4800名用户的动态用户画像建模的广泛实验突出显示了DEEPER卓越的用户画像优化能力，在四轮更新中平均将用户行为预测误差令人印象深刻地降低了32.2%——比最佳基线高出22.92%。", "summary": "本文介绍了DEEPER，一种新颖的动态用户画像建模方法，旨在利用流式数据持续优化用户画像。它采用迭代强化学习框架来增强方向搜索能力，根据用户行为与模型预测之间的差异自动识别最佳更新方向。在涉及4800名用户、跨越10个领域的实验中，DEEPER展示了卓越的性能，平均将用户行为预测误差降低了32.2%，并优于最佳基线22.92%。", "keywords": "动态用户画像建模, 强化学习, 用户行为预测, 画像优化, 大型语言模型", "comments": "DEEPER的创新之处在于其应用迭代强化学习框架来动态优化用户画像，这是一种新颖的解决流式数据持续画像优化挑战的方法。该方法显著提高了预测准确性，突出了其在个性化应用中的潜力。"}}
{"id": "2507.11770", "title": "Generating Actionable Robot Knowledge Bases by Combining 3D Scene Graphs with Robot Ontologies", "authors": ["Giang Nguyen", "Mihai Pomarlan", "Sascha Jongebloed", "Nils Leusmann", "Minh Nhat Vu", "Michael Beetz"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 7 figures, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2025)", "url": "http://arxiv.org/abs/2507.11770v1", "summary": "In robotics, the effective integration of environmental data into actionable\nknowledge remains a significant challenge due to the variety and\nincompatibility of data formats commonly used in scene descriptions, such as\nMJCF, URDF, and SDF. This paper presents a novel approach that addresses these\nchallenges by developing a unified scene graph model that standardizes these\nvaried formats into the Universal Scene Description (USD) format. This\nstandardization facilitates the integration of these scene graphs with robot\nontologies through semantic reporting, enabling the translation of complex\nenvironmental data into actionable knowledge essential for cognitive robotic\ncontrol. We evaluated our approach by converting procedural 3D environments\ninto USD format, which is then annotated semantically and translated into a\nknowledge graph to effectively answer competency questions, demonstrating its\nutility for real-time robotic decision-making. Additionally, we developed a\nweb-based visualization tool to support the semantic mapping process, providing\nusers with an intuitive interface to manage the 3D environment.", "comment": "8 pages, 7 figures, IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS2025)", "pdf_url": "http://arxiv.org/pdf/2507.11770v1", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "结合3D场景图与机器人本体生成可操作的机器人知识库", "tldr": "本文提出一种新方法，通过将多样化的3D场景数据格式标准化为USD，并与机器人本体集成，从而生成可操作的知识库，以支持机器人实时决策和认知控制。", "motivation": "在机器人领域，由于场景描述中常用的数据格式（如MJCF、URDF和SDF）的多样性和不兼容性，将环境数据有效整合为可操作知识仍然是一个重大挑战。", "method": "本文提出一种新颖的方法，通过开发统一的场景图模型，将各种3D场景数据格式标准化为通用场景描述（USD）格式。这种标准化通过语义报告促进了场景图与机器人本体的集成，从而将复杂的环境数据转化为认知机器人控制所需的关键可操作知识。", "result": "该方法通过将程序化3D环境转换为USD格式，并进行语义标注和翻译成知识图谱，成功回答了能力问题，证明了其在实时机器人决策中的实用性。此外，还开发了一个支持语义映射过程的基于网络的可是化工具，为用户提供了直观的界面来管理3D环境。", "conclusion": "本文提出的方法通过标准化3D场景数据并与机器人本体集成，能够有效生成可操作的机器人知识库，从而支持认知机器人控制和实时决策。", "translation": "在机器人领域，由于场景描述中常用的数据格式（如MJCF、URDF和SDF）的多样性和不兼容性，将环境数据有效整合为可操作知识仍然是一个重大挑战。本文提出了一种新颖的方法来解决这些挑战，即开发一个统一的场景图模型，将这些不同的格式标准化为通用场景描述（USD）格式。这种标准化通过语义报告促进了这些场景图与机器人本体的集成，从而将复杂的环境数据转化为认知机器人控制所必需的可操作知识。我们通过将程序化3D环境转换为USD格式来评估我们的方法，然后对其进行语义标注并翻译成知识图谱，以有效回答能力问题，从而展示了其在实时机器人决策中的实用性。此外，我们还开发了一个基于网络的可是化工具来支持语义映射过程，为用户提供了一个直观的界面来管理3D环境。", "summary": "本文提出一种新颖的方法，旨在解决机器人领域中环境数据整合为可操作知识的挑战。该方法通过将多样化的3D场景数据格式（如MJCF、URDF、SDF）统一标准化为通用场景描述（USD）格式，并结合机器人本体，生成可操作的知识库。实验证明，该方法能有效将3D环境数据转化为知识图谱并回答能力问题，支持实时机器人决策。研究还开发了一个可视化工具辅助语义映射。", "keywords": "机器人知识库, 3D场景图, 机器人本体, USD, 实时决策", "comments": "这篇论文通过提出一个统一的3D场景图模型和标准化数据格式（USD），有效地解决了机器人领域中环境数据异构性导致的知识整合难题。其创新点在于将场景数据与机器人本体深度融合，生成可操作的知识，这对于提升认知机器人的决策能力具有重要意义。可视化工具的开发也增强了其实用性。"}}
{"id": "2507.12440", "title": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos", "authors": ["Ruihan Yang", "Qinxi Yu", "Yecheng Wu", "Rui Yan", "Borui Li", "An-Chieh Cheng", "Xueyan Zou", "Yunhao Fang", "Hongxu Yin", "Sifei Liu", "Song Han", "Yao Lu", "Xiaolong Wang"], "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      More videos can be found on our website: this https URL", "url": "http://arxiv.org/abs/2507.12440v1", "summary": "Real robot data collection for imitation learning has led to significant\nadvancements in robotic manipulation. However, the requirement for robot\nhardware in the process fundamentally constrains the scale of the data. In this\npaper, we explore training Vision-Language-Action (VLA) models using egocentric\nhuman videos. The benefit of using human videos is not only for their scale but\nmore importantly for the richness of scenes and tasks. With a VLA trained on\nhuman video that predicts human wrist and hand actions, we can perform Inverse\nKinematics and retargeting to convert the human actions to robot actions. We\nfine-tune the model using a few robot manipulation demonstrations to obtain the\nrobot policy, namely EgoVLA. We propose a simulation benchmark called Isaac\nHumanoid Manipulation Benchmark, where we design diverse bimanual manipulation\ntasks with demonstrations. We fine-tune and evaluate EgoVLA with Isaac Humanoid\nManipulation Benchmark and show significant improvements over baselines and\nablate the importance of human data. Videos can be found on our website:\nhttps://rchalyang.github.io/EgoVLA", "comment": "More videos can be found on our website:\n  https://rchalyang.github.io/EgoVLA", "pdf_url": "http://arxiv.org/pdf/2507.12440v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "EgoVLA：从自我中心视角人类视频中学习视觉-语言-动作模型", "tldr": "EgoVLA通过大规模自我中心视角人类视频训练VLA模型，并通过少量机器人演示进行微调，显著提升了机器人操作学习效果，并提出了新的基准。", "motivation": "现有的机器人模仿学习数据收集受限于机器人硬件规模，且数据场景和任务多样性不足，限制了VLA模型的发展。", "method": "该研究探索使用自我中心视角人类视频训练视觉-语言-动作（VLA）模型。首先，训练VLA模型预测人类手腕和手部动作，然后通过逆运动学和重定向将其转换为机器人动作。最后，使用少量机器人操作演示对模型进行微调，得到机器人策略EgoVLA。此外，提出了Isaac Humanoid Manipulation Benchmark模拟基准用于评估。", "result": "EgoVLA在Isaac Humanoid Manipulation Benchmark上比基线方法取得了显著改进，并验证了人类数据的重要性。", "conclusion": "通过利用大规模自我中心视角人类视频训练VLA模型并结合少量机器人演示进行微调，可以有效克服机器人数据收集的限制，显著提升机器人操作学习的性能。", "translation": "机器人模仿学习的真实数据收集已在机器人操作方面取得了显著进展。然而，该过程中对机器人硬件的要求从根本上限制了数据的规模。在本文中，我们探索使用自我中心视角人类视频训练视觉-语言-动作（VLA）模型。使用人类视频的好处不仅在于其规模，更重要的是场景和任务的丰富性。通过在人类视频上训练的VLA模型预测人类手腕和手部动作，我们可以执行逆运动学和重定向，将人类动作转换为机器人动作。我们使用少量机器人操作演示对模型进行微调，以获得机器人策略，即EgoVLA。我们提出了一个名为Isaac Humanoid Manipulation Benchmark的模拟基准，其中我们设计了多样化的双手操作任务并提供了演示。我们使用Isaac Humanoid Manipulation Benchmark对EgoVLA进行微调和评估，结果显示其比基线方法有显著改进，并消除了人类数据重要性的疑虑。视频可在我们的网站上找到：https://rchalyang.github.io/EgoVLA", "summary": "本文提出EgoVLA，一种利用大规模自我中心视角人类视频训练的视觉-语言-动作（VLA）模型，旨在克服机器人模仿学习中数据收集受限的问题。该方法首先通过人类视频学习人类手部动作，再通过逆运动学转换为机器人动作，并结合少量机器人演示进行微调。研究引入了Isaac Humanoid Manipulation Benchmark进行评估，结果表明EgoVLA显著优于现有基线，并强调了人类数据在提升机器人操作学习中的关键作用。", "keywords": "机器人模仿学习, 视觉-语言-动作模型, 自我中心视角视频, 人类数据, 数据集规模", "comments": "这篇论文通过利用大规模易于获取的自我中心视角人类视频来训练机器人操作模型，创新性地解决了机器人数据收集成本高昂和规模受限的问题。其通过人类动作到机器人动作的转换机制，以及结合少量真实机器人数据微调的策略，提供了一个实用的、可扩展的模仿学习范式。提出的新基准也有助于未来研究的评估和比较。"}}
{"id": "2507.09822", "title": "Active Probing with Multimodal Predictions for Motion Planning", "authors": ["Darshan Gadginmath", "Farhad Nawaz", "Minjun Sung", "Faizan M Tariq", "Sangjae Bae", "David Isele", "Fabio Pasqualetti", "Jovin D'sa"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      To appear at IROS '25. 8 pages. 3 tables. 6 figures", "url": "http://arxiv.org/abs/2507.09822v2", "summary": "Navigation in dynamic environments requires autonomous systems to reason\nabout uncertainties in the behavior of other agents. In this paper, we\nintroduce a unified framework that combines trajectory planning with multimodal\npredictions and active probing to enhance decision-making under uncertainty. We\ndevelop a novel risk metric that seamlessly integrates multimodal prediction\nuncertainties through mixture models. When these uncertainties follow a\nGaussian mixture distribution, we prove that our risk metric admits a\nclosed-form solution, and is always finite, thus ensuring analytical\ntractability. To reduce prediction ambiguity, we incorporate an active probing\nmechanism that strategically selects actions to improve its estimates of\nbehavioral parameters of other agents, while simultaneously handling multimodal\nuncertainties. We extensively evaluate our framework in autonomous navigation\nscenarios using the MetaDrive simulation environment. Results demonstrate that\nour active probing approach successfully navigates complex traffic scenarios\nwith uncertain predictions. Additionally, our framework shows robust\nperformance across diverse traffic agent behavior models, indicating its broad\napplicability to real-world autonomous navigation challenges. Code and videos\nare available at\nhttps://darshangm.github.io/papers/active-probing-multimodal-predictions/.", "comment": "To appear at IROS '25. 8 pages. 3 tables. 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.09822v2", "cate": "cs.RO", "date": "2025-07-13", "updated": "2025-07-15", "AI": {"title_translation": "运动规划中的多模态预测主动探测", "tldr": "提出一个结合多模态预测和主动探测的统一框架，用于动态环境下不确定性决策，通过新风险度量和主动探测机制提高自动驾驶在复杂交通场景中的导航能力。", "motivation": "自动系统在动态环境中导航时，需要处理其他智能体行为的不确定性。", "method": "引入一个统一框架，结合轨迹规划、多模态预测和主动探测来增强不确定性下的决策。开发了一种新颖的风险度量，通过混合模型无缝集成多模态预测不确定性，并在高斯混合分布下证明其存在闭式解且始终有限。引入主动探测机制，策略性地选择动作以改进对其他智能体行为参数的估计，同时处理多模态不确定性。", "result": "在MetaDrive仿真环境中，主动探测方法成功地在具有不确定预测的复杂交通场景中导航。该框架在不同交通智能体行为模型中表现出鲁棒性能。", "conclusion": "该框架通过结合多模态预测和主动探测，有效提升了自动系统在动态、不确定环境中的导航能力和决策质量，并显示出广泛的实际应用潜力。", "translation": "在动态环境中导航需要自主系统推理其他智能体行为中的不确定性。在本文中，我们引入了一个统一框架，该框架结合了轨迹规划、多模态预测和主动探测，以增强不确定性下的决策。我们开发了一种新颖的风险度量，通过混合模型无缝地整合多模态预测不确定性。当这些不确定性遵循高斯混合分布时，我们证明我们的风险度量具有闭式解，并且始终是有限的，从而确保了分析的可处理性。为了减少预测模糊性，我们引入了一个主动探测机制，该机制策略性地选择动作以改进对其他智能体行为参数的估计，同时处理多模态不确定性。我们使用MetaDrive仿真环境在自主导航场景中广泛评估了我们的框架。结果表明，我们的主动探测方法成功地在具有不确定预测的复杂交通场景中导航。此外，我们的框架在各种交通智能体行为模型中显示出鲁棒性能，表明其对现实世界自主导航挑战的广泛适用性。代码和视频可在https://darshangm.github.io/papers/active-probing-multimodal-predictions/获得。", "summary": "本文提出了一个用于动态环境运动规划的统一框架，该框架将轨迹规划、多模态预测和主动探测相结合，以提升不确定性下的决策能力。作者开发了一种新颖的风险度量，能够整合多模态预测不确定性，并在特定条件下保证分析可处理性。此外，引入的主动探测机制通过策略性选择动作来减少预测模糊性，并优化对其他智能体行为参数的估计。实验结果表明，该框架在复杂交通场景中表现出成功的导航能力和对多样化行为模型的鲁棒性，具有广泛的实际应用潜力。", "keywords": "运动规划, 多模态预测, 主动探测, 不确定性决策, 风险度量", "comments": "该论文的创新点在于提出了一个统一的框架，将多模态预测的不确定性处理与主动探测机制相结合，以优化自动系统在动态环境中的决策。其提出的风险度量在高斯混合分布下的闭式解提高了理论上的可处理性，而主动探测机制则有效地解决了预测模糊性问题。这对于提升自动驾驶等领域在复杂、不确定环境下的安全性和效率具有重要意义。"}}
{"id": "2507.12175", "title": "RUMAA: Repeat-Aware Unified Music Audio Analysis for Score-Performance Alignment, Transcription, and Mistake Detection", "authors": ["Sungkyun Chang", "Simon Dixon", "Emmanouil Benetos"], "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted to WASPAA 2025", "url": "http://arxiv.org/abs/2507.12175v1", "summary": "This study introduces RUMAA, a transformer-based framework for music\nperformance analysis that unifies score-to-performance alignment,\nscore-informed transcription, and mistake detection in a near end-to-end\nmanner. Unlike prior methods addressing these tasks separately, RUMAA\nintegrates them using pre-trained score and audio encoders and a novel\ntri-stream decoder capturing task interdependencies through proxy tasks. It\naligns human-readable MusicXML scores with repeat symbols to full-length\nperformance audio, overcoming traditional MIDI-based methods that rely on\nmanually unfolded score-MIDI data with pre-specified repeat structures. RUMAA\nmatches state-of-the-art alignment methods on non-repeated scores and\noutperforms them on scores with repeats in a public piano music dataset, while\nalso delivering promising transcription and mistake detection results.", "comment": "Accepted to WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.12175v1", "cate": "cs.SD", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "RUMAA：重复感知统一音乐音频分析，用于乐谱-演奏对齐、转录和错误检测", "tldr": "RUMAA是一个基于Transformer的框架，统一了乐谱-演奏对齐、转录和错误检测等音乐性能分析任务，尤其擅长处理乐谱中的重复部分。", "motivation": "现有方法将乐谱-演奏对齐、乐谱信息转录和错误检测等任务分开处理。传统的基于MIDI的对齐方法依赖于手动展开的、具有预设重复结构的乐谱-MIDI数据，本研究旨在克服这些局限。", "method": "RUMAA是一个基于Transformer的框架。它使用预训练的乐谱和音频编码器以及一个新颖的三流解码器来整合各项任务，该解码器通过代理任务捕捉任务间的相互依赖性。它能将带有重复符号的MusicXML乐谱与完整长度的演奏音频对齐。", "result": "RUMAA在非重复乐谱上与最先进的对齐方法效果相当，并在公共钢琴音乐数据集中，在带有重复的乐谱上表现优于它们。它还在转录和错误检测方面取得了有前景的结果。", "conclusion": "RUMAA成功地统一了音乐性能分析任务，有效处理了乐谱中的重复部分，并在对齐、转录和错误检测方面取得了有竞争力或更优的性能。", "translation": "本研究引入了RUMAA，一个基于Transformer的音乐演奏分析框架，它以近乎端到端的方式统一了乐谱-演奏对齐、乐谱信息转录和错误检测。与以往单独处理这些任务的方法不同，RUMAA通过预训练的乐谱和音频编码器以及一个新颖的三流解码器整合了它们，通过代理任务捕捉任务间的相互依赖性。它将带有重复符号的可读MusicXML乐谱与完整长度的演奏音频对齐，克服了传统基于MIDI的方法依赖于手动展开的、具有预设重复结构的乐谱-MIDI数据的缺点。RUMAA在非重复乐谱上与最先进的对齐方法相当，并在公共钢琴音乐数据集中，在带有重复的乐谱上表现优于它们，同时还在转录和错误检测方面取得了有前景的结果。", "summary": "RUMAA是一个基于Transformer的音乐分析框架，它将乐谱-演奏对齐、乐谱信息转录和错误检测这三项任务整合起来，并能有效处理乐谱中的重复部分。通过预训练的编码器和新型三流解码器，RUMAA在处理重复乐谱时超越了现有最先进的对齐方法，并在其他任务中也表现出色。", "keywords": "音乐性能分析, 乐谱-演奏对齐, 转录, 错误检测, Transformer", "comments": "RUMAA的创新之处在于其统一的框架和对乐谱重复结构的处理能力，这克服了传统方法的局限性，提高了音乐性能分析的效率和准确性。"}}
{"id": "2411.02572", "title": "ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy", "authors": ["Kian Kenyon-Dean", "Zitong Jerry Wang", "John Urbanik", "Konstantin Donhauser", "Jason Hartford", "Saber Saberian", "Nil Sahin", "Ihab Bendidi", "Safiye Celik", "Marta Fay", "Juan Sebastian Rodriguez Vera", "Imran S Haque", "Oren Kraus"], "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07", "I.2; I.4"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025 main-track paper (42nd International Conference on Machine Learning). Formerly appeared as best paper runner-up at NeurIPS 2024 Foundation Models for Science Workshop (38th Conference on Neural Information Processing Systems). 18 pages, 7 figures", "url": "http://arxiv.org/abs/2411.02572v2", "summary": "Large-scale cell microscopy screens are used in drug discovery and molecular\nbiology research to study the effects of millions of chemical and genetic\nperturbations on cells. To use these images in downstream analysis, we need\nmodels that can map each image into a feature space that represents diverse\nbiological phenotypes consistently, in the sense that perturbations with\nsimilar biological effects have similar representations. In this work, we\npresent the largest foundation model for cell microscopy data to date, a new\n1.9 billion-parameter ViT-G/8 MAE trained on over 8 billion microscopy image\ncrops. Compared to a previous published ViT-L/8 MAE, our new model achieves a\n60% improvement in linear separability of genetic perturbations and obtains the\nbest overall performance on whole-genome biological relationship recall and\nreplicate consistency benchmarks. Beyond scaling, we developed two key methods\nthat improve performance: (1) training on a curated and diverse dataset; and,\n(2) using biologically motivated linear probing tasks to search across each\ntransformer block for the best candidate representation of whole-genome\nscreens. We find that many self-supervised vision transformers, pretrained on\neither natural or microscopy images, yield significantly more biologically\nmeaningful representations of microscopy images in their intermediate blocks\nthan in their typically used final blocks. More broadly, our approach and\nresults provide insights toward a general strategy for successfully building\nfoundation models for large-scale biological data.", "comment": "ICML 2025 main-track paper (42nd International Conference on Machine\n  Learning). Formerly appeared as best paper runner-up at NeurIPS 2024\n  Foundation Models for Science Workshop (38th Conference on Neural Information\n  Processing Systems). 18 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2411.02572v2", "cate": "cs.LG", "date": "2024-11-04", "updated": "2025-07-16", "AI": {"title_translation": "ViTally Consistent：细胞显微镜生物表征学习的规模化", "tldr": "本文提出了迄今为止最大的细胞显微镜基础模型ViT-G/8 MAE，通过规模化训练和优化方法，显著提升了生物表征学习性能，并发现自监督视觉Transformer的中间块在生物学意义上更有效。", "motivation": "在大规模细胞显微镜筛选中，需要模型能将图像一致地映射到特征空间，以表示多样的生物表型，使得具有相似生物效应的扰动拥有相似的表示，从而用于下游分析。", "method": "1. 提出了一个19亿参数的ViT-G/8 MAE基础模型，在超过80亿张显微镜图像裁剪上进行训练。2. 在经过筛选和多样化的数据集上进行训练。3. 使用生物学驱动的线性探测任务来搜索每个Transformer块中全基因组筛选的最佳候选表示。", "result": "1. 与先前的ViT-L/8 MAE相比，在遗传扰动的线性可分性方面实现了60%的改进。2. 在全基因组生物关系召回和重复一致性基准测试中获得了最佳整体性能。3. 发现许多自监督视觉Transformer（无论是在自然图像还是显微镜图像上预训练）的中间块产生的显微镜图像生物学意义上的表示显著优于其通常使用的最终块。", "conclusion": "本研究的方法和结果为成功构建大规模生物数据的基础模型提供了一种通用策略的见解。", "translation": "大规模细胞显微镜筛选被用于药物发现和分子生物学研究，以研究数百万种化学和遗传扰动对细胞的影响。为了在下游分析中使用这些图像，我们需要能够将每个图像映射到特征空间的模型，该特征空间能够一致地表示多样化的生物表型，即具有相似生物效应的扰动具有相似的表示。在这项工作中，我们提出了迄今为止最大的细胞显微镜数据基础模型，一个在超过80亿张显微镜图像裁剪上训练的新的19亿参数ViT-G/8 MAE。与之前发布的ViT-L/8 MAE相比，我们的新模型在遗传扰动的线性可分性方面实现了60%的改进，并在全基因组生物关系召回和重复一致性基准测试中获得了最佳整体性能。除了规模化，我们还开发了两种提高性能的关键方法：（1）在经过筛选和多样化的数据集上进行训练；（2）使用生物学驱动的线性探测任务，在每个Transformer块中搜索全基因组筛选的最佳候选表示。我们发现，许多自监督视觉Transformer，无论是预训练在自然图像还是显微镜图像上，其中间块产生的显微镜图像生物学意义上的表示显著优于其通常使用的最终块。更广泛地说，我们的方法和结果为成功构建大规模生物数据基础模型提供了一种通用策略的见解。", "summary": "本文提出了迄今为止最大的细胞显微镜基础模型ViT-G/8 MAE，该模型拥有19亿参数，并在超过80亿张图像裁剪上训练。该模型在遗传扰动线性可分性上相比现有模型提升60%，并在全基因组生物关系召回和重复一致性上表现最佳。研究通过在精心策划的多样化数据集上训练并利用生物学驱动的线性探测来优化性能，并发现自监督视觉Transformer的中间块比最终块更能产生有生物学意义的图像表示。这些发现为构建大规模生物数据基础模型提供了通用策略。", "keywords": "细胞显微镜, 基础模型, 表征学习, ViT-G/8 MAE, 生物表型", "comments": "该论文的创新之处在于其提出了迄今为止最大的细胞显微镜基础模型，并在规模化训练和方法优化方面取得了显著进展。尤其重要的是，研究发现自监督视觉Transformer的中间块比最终块能产生更具生物学意义的表示，这一洞见对于未来生物图像特征提取和模型设计具有重要指导意义。其提出的通用策略对于大规模生物数据基础模型的构建具有广泛的应用前景。摘要中未提及具体的局限性。"}}
{"id": "2507.12040", "title": "An augmented Lagrangian method for strongly regular minimizers in a class of convex composite optimization problems", "authors": ["Chengjing Wang", "Peipei Tang"], "categories": ["math.OC", "cs.NA", "math.NA", "49J52, 49J53, 90C31, 90C22"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      31 pages", "url": "http://arxiv.org/abs/2507.12040v1", "summary": "In this paper, we study a class of convex composite optimization problems. We\nbegin by characterizing the equivalence between the primal/dual strong\nsecond-order sufficient condition and the dual/primal nondegeneracy condition.\nBuilding on this foundation, we derive a specific set of equivalent conditions\nfor the perturbation analysis of the problem. Furthermore, we employ the\naugmented Lagrangian method (ALM) to solve the problem and provide theoretical\nguarantees for its performance. Specifically, we establish the equivalence\nbetween the primal/dual second-order sufficient condition and the dual/primal\nstrict Robinson constraint qualification, as well as the equivalence between\nthe dual nondegeneracy condition and the nonsingularity of Clarke's generalized\nJacobian for the ALM subproblem. These theoretical results form a solid\nfoundation for designing efficient algorithms. Finally, we apply the ALM to the\nvon Neumann entropy optimization problem and present numerical experiments to\ndemonstrate the algorithm's effectiveness.", "comment": "31 pages", "pdf_url": "http://arxiv.org/pdf/2507.12040v1", "cate": "math.OC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "针对一类凸复合优化问题中强正则极小点的增广拉格朗日方法", "tldr": "本文研究凸复合优化问题，通过表征条件等价性并应用增广拉格朗日方法（ALM）求解，为设计高效算法奠定基础，并通过数值实验验证了ALM的有效性。", "motivation": "本文旨在深入研究一类凸复合优化问题，特别是通过理论分析和应用增广拉格朗日方法（ALM）来解决这些问题，并为设计高效、性能有保证的算法提供坚实的基础。", "method": "本文首先刻画了原始/对偶强二阶充分条件与对偶/原始非退化条件之间的等价性，并推导了用于问题扰动分析的等价条件集。随后，采用增广拉格朗日方法（ALM）来求解问题，并为其性能提供了理论保证，包括建立相关条件（如二阶充分条件、严格Robinson约束条件和Clarke广义Jacobian的非奇异性）之间的等价性。", "result": "结果表明，原始/对偶强二阶充分条件与对偶/原始非退化条件是等价的。此外，原始/对偶二阶充分条件与对偶/原始严格Robinson约束条件等价，对偶非退化条件与ALM子问题中Clarke广义Jacobian的非奇异性等价。数值实验证明了ALM在von Neumann熵优化问题上的有效性。", "conclusion": "本文的理论结果为设计高效的算法奠定了坚实的基础。通过将增广拉格朗日方法应用于von Neumann熵优化问题并进行数值实验，验证了该算法的有效性和实用性。", "translation": "本文研究了一类凸复合优化问题。我们首先刻画了原始/对偶强二阶充分条件与对偶/原始非退化条件之间的等价性。在此基础上，我们推导了一组用于问题扰动分析的特定等价条件。此外，我们采用增广拉格朗日方法（ALM）来解决该问题，并为其性能提供了理论保证。具体而言，我们建立了原始/对偶二阶充分条件与对偶/原始严格Robinson约束条件之间的等价性，以及对偶非退化条件与ALM子问题中Clarke广义Jacobian的非奇异性之间的等价性。这些理论结果为设计高效算法奠定了坚实的基础。最后，我们将ALM应用于von Neumann熵优化问题，并进行了数值实验以证明算法的有效性。", "summary": "本文专注于一类凸复合优化问题。研究首先建立了原始/对偶强二阶充分条件与对偶/原始非退化条件之间的等价关系，并推导了扰动分析的等价条件。核心方法是增广拉格朗日方法（ALM），其性能得到了理论保证，包括条件等价性（如原始/对偶二阶充分条件与严格Robinson约束条件，以及对偶非退化条件与Clarke广义Jacobian的非奇异性）。这些理论成果为高效算法设计提供了基础。最后，通过在von Neumann熵优化问题上的数值实验验证了ALM的有效性。", "keywords": "凸复合优化, 增广拉格朗日方法, 二阶条件, 非退化条件, von Neumann熵优化", "comments": "本文在凸复合优化问题中，通过建立关键条件（如二阶充分条件、非退化条件、严格Robinson约束条件）之间的等价性，为理论分析和算法设计提供了坚实基础。特别是将增广拉格朗日方法应用于此类问题，并从理论上保证其性能，具有重要意义。数值实验进一步验证了其在具体问题中的实用性。其创新点在于深入探讨了条件之间的内在联系，并将其应用于优化算法的设计与分析。"}}
{"id": "2507.11633", "title": "General Modular Harness for LLM Agents in Multi-Turn Gaming Environments", "authors": ["Yuxuan Zhang", "Haoyang Yu", "Lanxiang Hu", "Haojian Jin", "Hao Zhang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      8 pages, ICML MAS workshop", "url": "http://arxiv.org/abs/2507.11633v1", "summary": "We introduce a modular harness design for LLM agents that composes of\nperception, memory, and reasoning components, enabling a single LLM or VLM\nbackbone to tackle a wide spectrum of multi turn gaming environments without\ndomain-specific engineering. Using classic and modern game suites as\nlow-barrier, high-diversity testbeds, our framework provides a unified workflow\nfor analyzing how each module affects performance across dynamic interactive\nsettings. Extensive experiments demonstrate that the harness lifts gameplay\nperformance consistently over un-harnessed baselines and reveals distinct\ncontribution patterns, for example, memory dominates in long-horizon puzzles\nwhile perception is critical in vision noisy arcades. These findings highlight\nthe effectiveness of our modular harness design in advancing general-purpose\nagent, given the familiarity and ubiquity of games in everyday human\nexperience.", "comment": "8 pages, ICML MAS workshop", "pdf_url": "http://arxiv.org/pdf/2507.11633v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "面向多轮游戏环境中LLM智能体的通用模块化工具", "tldr": "提出一种模块化工具（感知、记忆、推理）用于LLM智能体在多轮游戏环境中表现，优于基线并揭示模块贡献模式。", "motivation": "为了使LLM智能体能应对广泛的多轮游戏环境，而无需进行领域特定的工程，本研究旨在提供一种通用的模块化解决方案。", "method": "引入了一种由感知、记忆和推理组件组成的模块化工具设计。使用经典和现代游戏套件作为低门槛、高多样性的测试平台，提供统一的工作流程来分析每个模块如何影响动态交互设置中的性能。", "result": "实验表明，该工具持续提升了游戏性能，优于未使用的基线。同时揭示了不同模块的独特贡献模式，例如，记忆在长周期谜题中占主导地位，而感知在视觉噪声街机游戏中至关重要。", "conclusion": "鉴于游戏在日常人类经验中的熟悉性和普遍性，所提出的模块化工具设计在推进通用代理方面是有效的。", "translation": "我们引入了一种用于LLM智能体的模块化工具设计，它由感知、记忆和推理组件组成，使单个LLM或VLM骨干能够应对各种多轮游戏环境，而无需进行领域特定的工程。利用经典和现代游戏套件作为低门槛、高多样性的测试平台，我们的框架提供了一个统一的工作流程，用于分析每个模块如何在动态交互设置中影响性能。大量的实验表明，该工具持续提升了游戏性能，优于未经工具的基线，并揭示了独特的贡献模式，例如，在长周期谜题中记忆起主导作用，而在视觉嘈杂的街机游戏中感知至关重要。这些发现突显了我们模块化工具设计在推进通用代理方面的有效性，考虑到游戏在日常人类经验中的熟悉性和普遍性。", "summary": "该论文提出了一种通用的模块化工具，用于LLM智能体在多轮游戏环境中进行感知、记忆和推理。通过在多样化的游戏套件上进行实验，证明该工具显著提升了游戏性能，并揭示了不同模块在特定游戏类型中的关键作用，从而推动了通用智能体的发展。", "keywords": "LLM智能体, 模块化工具, 多轮游戏, 感知, 记忆", "comments": "这项工作创新性地提出了一个通用的模块化框架，将感知、记忆和推理能力集成到LLM智能体中，使其能够适应广泛的多轮游戏环境，而无需领域特定调整。其重要性在于为构建更通用、更鲁棒的LLM代理提供了新的范式，并通过实证分析揭示了不同模块在复杂交互环境中的独特贡献。"}}
{"id": "2507.11588", "title": "SToFM: a Multi-scale Foundation Model for Spatial Transcriptomics", "authors": ["Suyuan Zhao", "Yizhen Luo", "Ganbo Yang", "Yan Zhong", "Hao Zhou", "Zaiqing Nie"], "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Genomics (q-bio.GN)", "pdf_link": null, "comments": "Comments:      Accpeted by ICML 2024", "url": "http://arxiv.org/abs/2507.11588v1", "summary": "Spatial Transcriptomics (ST) technologies provide biologists with rich\ninsights into single-cell biology by preserving spatial context of cells.\nBuilding foundational models for ST can significantly enhance the analysis of\nvast and complex data sources, unlocking new perspectives on the intricacies of\nbiological tissues. However, modeling ST data is inherently challenging due to\nthe need to extract multi-scale information from tissue slices containing vast\nnumbers of cells. This process requires integrating macro-scale tissue\nmorphology, micro-scale cellular microenvironment, and gene-scale gene\nexpression profile. To address this challenge, we propose SToFM, a multi-scale\nSpatial Transcriptomics Foundation Model. SToFM first performs multi-scale\ninformation extraction on each ST slice, to construct a set of ST sub-slices\nthat aggregate macro-, micro- and gene-scale information. Then an SE(2)\nTransformer is used to obtain high-quality cell representations from the\nsub-slices. Additionally, we construct \\textbf{SToCorpus-88M}, the largest\nhigh-resolution spatial transcriptomics corpus for pretraining. SToFM achieves\noutstanding performance on a variety of downstream tasks, such as tissue region\nsemantic segmentation and cell type annotation, demonstrating its comprehensive\nunderstanding of ST data", "comment": "Accpeted by ICML 2024", "pdf_url": "http://arxiv.org/pdf/2507.11588v1", "cate": "q-bio.GN", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "SToFM：一种用于空间转录组学的多尺度基础模型", "tldr": "SToFM是一个多尺度空间转录组学基础模型，通过提取多尺度信息并结合SE(2) Transformer，在SToCorpus-88M数据集上预训练，在多种下游任务中表现出色。", "motivation": "空间转录组学（ST）数据分析面临从包含大量细胞的组织切片中提取多尺度信息的挑战，需要整合宏观组织形态、微观细胞微环境和基因表达谱。为了解决这一挑战并构建能增强ST数据分析的基础模型，本文提出了SToFM。", "method": "SToFM首先对每个ST切片进行多尺度信息提取，构建聚合宏观、微观和基因尺度信息的ST子切片。然后使用SE(2) Transformer从子切片中获取高质量的细胞表示。此外，研究构建了最大的高分辨率空间转录组学语料库SToCorpus-88M用于预训练。", "result": "SToFM在多种下游任务（如组织区域语义分割和细胞类型注释）上取得了出色的性能。", "conclusion": "SToFM通过其多尺度信息提取和SE(2) Transformer架构，结合大规模预训练语料库，能够全面理解空间转录组学数据，并在下游任务中展现出卓越的性能。", "translation": "空间转录组学（ST）技术通过保留细胞的空间背景，为生物学家提供了对单细胞生物学的丰富见解。为ST构建基础模型可以显著增强对庞大而复杂数据源的分析，从而开启对生物组织复杂性的新视角。然而，由于需要从包含大量细胞的组织切片中提取多尺度信息，ST数据建模本身就具有挑战性。此过程需要整合宏观尺度的组织形态、微观尺度的细胞微环境以及基因尺度的基因表达谱。为了应对这一挑战，我们提出了SToFM，一个多尺度空间转录组学基础模型。SToFM首先对每个ST切片进行多尺度信息提取，以构建一组聚合了宏观、微观和基因尺度信息的ST子切片。然后使用SE(2) Transformer从子切片中获取高质量的细胞表示。此外，我们构建了**SToCorpus-88M**，这是用于预训练的最大的高分辨率空间转录组学语料库。SToFM在各种下游任务中取得了出色的性能，例如组织区域语义分割和细胞类型注释，这表明它对ST数据具有全面的理解。", "summary": "SToFM是一种多尺度空间转录组学基础模型，旨在解决ST数据建模中提取多尺度信息的挑战。它通过多尺度信息提取和SE(2) Transformer构建高质量细胞表示，并利用大规模预训练语料库SToCorpus-88M。该模型在组织区域语义分割和细胞类型注释等下游任务中表现出卓越性能，证明了其对ST数据的全面理解能力。", "keywords": "空间转录组学, 基础模型, 多尺度信息, SE(2) Transformer, SToCorpus-88M", "comments": "SToFM的创新点在于其多尺度信息提取方法和SE(2) Transformer的应用，以及构建了迄今为止最大的高分辨率空间转录组学语料库SToCorpus-88M用于预训练。这使得该模型能够有效处理ST数据的复杂性，并有望成为该领域的重要基础模型，推动ST数据分析的发展。"}}
{"id": "2507.11936", "title": "A Survey of Deep Learning for Geometry Problem Solving", "authors": ["Jianzhe Ma", "Wenxuan Wang", "Qin Jin"], "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2507.11936v1", "summary": "Geometry problem solving is a key area of mathematical reasoning, which is\nwidely involved in many important fields such as education, mathematical\nability assessment of artificial intelligence, and multimodal ability\nassessment. In recent years, the rapid development of deep learning technology,\nespecially the rise of multimodal large language models, has triggered a\nwidespread research boom. This paper provides a survey of the applications of\ndeep learning in geometry problem solving, including (i) a comprehensive\nsummary of the relevant tasks in geometry problem solving; (ii) a thorough\nreview of related deep learning methods; (iii) a detailed analysis of\nevaluation metrics and methods; and (iv) a critical discussion of the current\nchallenges and future directions that can be explored. Our goal is to provide a\ncomprehensive and practical reference of deep learning for geometry problem\nsolving to promote further developments in this field. We create a continuously\nupdated list of papers on GitHub: https://github.com/majianz/dl4gps.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.11936v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "深度学习在几何问题求解中的综述", "tldr": "这篇综述论文全面回顾了深度学习在几何问题求解中的应用，包括任务、方法、评估指标和未来方向，旨在为该领域提供参考。", "motivation": "几何问题求解是数学推理的关键领域，广泛应用于教育、人工智能数学能力评估和多模态能力评估。近年来，深度学习技术特别是多模态大语言模型的快速发展，引发了广泛的研究热潮。因此，需要一篇综述来总结和促进该领域的发展。", "method": "本文对深度学习在几何问题求解中的应用进行了综述，具体包括：(i) 全面总结几何问题求解中的相关任务；(ii) 彻底回顾相关的深度学习方法；(iii) 详细分析评估指标和方法；(iv) 批判性讨论当前挑战和未来方向。", "result": "该综述提供了一个全面且实用的深度学习在几何问题求解方面的参考，并创建了一个持续更新的GitHub论文列表。", "conclusion": "本文旨在提供一个全面且实用的深度学习在几何问题求解方面的参考，以促进该领域的进一步发展。", "translation": "几何问题求解是数学推理的关键领域，广泛应用于教育、人工智能数学能力评估和多模态能力评估等许多重要领域。近年来，深度学习技术的快速发展，特别是多模态大语言模型的兴起，引发了广泛的研究热潮。本文对深度学习在几何问题求解中的应用进行了综述，包括：(i) 对几何问题求解中相关任务的全面总结；(ii) 对相关深度学习方法的彻底回顾；(iii) 对评估指标和方法的详细分析；以及 (iv) 对当前挑战和未来方向的批判性讨论。我们的目标是为深度学习在几何问题求解领域提供一个全面而实用的参考，以促进该领域的进一步发展。我们创建了一个持续更新的GitHub论文列表：https://github.com/majianz/dl4gps。", "summary": "该论文是对深度学习在几何问题求解领域应用的全面综述。它系统地总结了相关任务、回顾了深度学习方法、分析了评估指标，并讨论了现有挑战和未来研究方向。该综述旨在为研究人员提供一个实用的参考，以推动几何问题求解领域的发展，并提供了一个持续更新的论文列表。", "keywords": "深度学习, 几何问题求解, 综述, 数学推理, 多模态大语言模型", "comments": "这是一篇及时且重要的综述论文，因为它涵盖了一个日益受到关注的交叉领域——深度学习与几何问题求解。其结构清晰，涵盖了任务、方法、评估和未来方向，为研究人员提供了宝贵的路线图。提供一个持续更新的GitHub论文列表是一个非常实用的创新点。"}}
{"id": "2507.12261", "title": "Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes", "authors": ["Johann Frei", "Nils Feldhus", "Lisa Raithel", "Roland Roller", "Alexander Meyer", "Frank Kramer"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Submitted to EMNLP 2025 System Demonstrations | Code: this https URL | Video: this https URL | Demo: this https URL | HuggingFace Spaces: this https URL", "url": "http://arxiv.org/abs/2507.12261v1", "summary": "For clinical data integration and healthcare services, the HL7 FHIR standard\nhas established itself as a desirable format for interoperability between\ncomplex health data. Previous attempts at automating the translation from\nfree-form clinical notes into structured FHIR resources rely on modular,\nrule-based systems or LLMs with instruction tuning and constrained decoding.\nSince they frequently suffer from limited generalizability and structural\ninconformity, we propose an end-to-end framework powered by LLM agents, code\nexecution, and healthcare terminology database tools to address these issues.\nOur solution, called Infherno, is designed to adhere to the FHIR document\nschema and competes well with a human baseline in predicting FHIR resources\nfrom unstructured text. The implementation features a front end for custom and\nsynthetic data and both local and proprietary models, supporting clinical data\nintegration processes and interoperability across institutions.", "comment": "Submitted to EMNLP 2025 System Demonstrations | Code:\n  https://github.com/j-frei/Infherno | Video:\n  https://www.youtube.com/watch?v=kyj5C2ivbMw | Demo:\n  https://infherno.misit-augsburg.de | HuggingFace Spaces:\n  https://huggingface.co/spaces/nfel/infherno", "pdf_url": "http://arxiv.org/pdf/2507.12261v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Infherno：基于代理的从自由格式临床笔记到FHIR资源端到端合成", "tldr": "Infherno是一个LLM代理驱动的端到端框架，能将自由格式临床笔记转换为结构化的FHIR资源，表现优于人类基线，解决了现有方法的局限性。", "motivation": "现有的从自由格式临床笔记自动转换为结构化FHIR资源的方法（如模块化、基于规则的系统或经过指令调整和受限解码的LLM）常受限于泛化能力和结构不一致性，无法满足临床数据集成和医疗保健服务对FHIR标准互操作性的需求。", "method": "提出一个名为Infherno的端到端框架，该框架由LLM代理、代码执行和医疗术语数据库工具驱动，旨在遵循FHIR文档模式，实现从非结构化文本到结构化FHIR资源的转换。", "result": "Infherno在从非结构化文本预测FHIR资源方面与人类基线相比表现良好。其实现具有用于自定义和合成数据的前端，并支持本地和专有模型，有助于支持临床数据集成和机构间的互操作性。", "conclusion": "Infherno提供了一个有效且可推广的解决方案，用于将自由格式临床笔记转换为符合FHIR标准的结构化数据，从而促进临床数据集成和机构间的互操作性，解决了现有方法的局限性。", "translation": "对于临床数据集成和医疗保健服务，HL7 FHIR标准已成为复杂健康数据之间互操作性的理想格式。之前将自由格式临床笔记自动转换为结构化FHIR资源的尝试依赖于模块化、基于规则的系统或经过指令调优和受限解码的大型语言模型（LLM）。由于它们经常面临泛化能力有限和结构不一致的问题，我们提出了一个由LLM代理、代码执行和医疗保健术语数据库工具驱动的端到端框架来解决这些问题。我们的解决方案名为Infherno，旨在遵循FHIR文档模式，并且在从非结构化文本预测FHIR资源方面与人类基线竞争良好。该实现具有用于自定义和合成数据的前端，并支持本地和专有模型，从而支持临床数据集成过程和机构间的互操作性。", "summary": "Infherno是一个创新的端到端框架，利用LLM代理、代码执行和医疗术语数据库，旨在将自由格式临床笔记高效准确地转换为符合HL7 FHIR标准的结构化资源。它解决了现有方法在泛化性和结构一致性方面的局限，并在性能上与人类基线相当，显著提升了医疗数据集成和互操作性。", "keywords": "FHIR, 临床笔记, LLM代理, 数据合成, 医疗互操作性", "comments": "该论文提出了一种新颖的基于LLM代理的端到端方法，用于将非结构化临床笔记转换为FHIR资源，解决了传统方法泛化性差和结构不一致的问题。其创新点在于结合了LLM代理、代码执行和术语数据库，实现了高度自动化和准确性，并能与人类基线竞争，对于促进医疗数据标准化和互操作性具有重要意义。"}}
{"id": "2407.09357", "title": "Any-Property-Conditional Molecule Generation with Self-Criticism using Spanning Trees", "authors": ["Alexia Jolicoeur-Martineau", "Aristide Baratin", "Kisoo Kwon", "Boris Knyazev", "Yan Zhang"], "categories": ["cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Code: this https URL", "url": "http://arxiv.org/abs/2407.09357v3", "summary": "Generating novel molecules is challenging, with most representations leading\nto generative models producing many invalid molecules. Spanning Tree-based\nGraph Generation (STGG) is a promising approach to ensure the generation of\nvalid molecules, outperforming state-of-the-art SMILES and graph diffusion\nmodels for unconditional generation. In the real world, we want to be able to\ngenerate molecules conditional on one or multiple desired properties rather\nthan unconditionally. Thus, in this work, we extend STGG to\nmulti-property-conditional generation. Our approach, STGG+, incorporates a\nmodern Transformer architecture, random masking of properties during training\n(enabling conditioning on any subset of properties and classifier-free\nguidance), an auxiliary property-prediction loss (allowing the model to\nself-criticize molecules and select the best ones), and other improvements. We\nshow that STGG+ achieves state-of-the-art performance on in-distribution and\nout-of-distribution conditional generation, and reward maximization.", "comment": "Code: https://github.com/SamsungSAILMontreal/AnyMolGenCritic", "pdf_url": "http://arxiv.org/pdf/2407.09357v3", "cate": "cs.LG", "date": "2024-07-12", "updated": "2025-07-15", "AI": {"title_translation": "使用生成树和自我批评的任意属性条件分子生成", "tldr": "STGG+通过结合Transformer架构、随机属性掩蔽和辅助属性预测损失，将基于生成树的图生成(STGG)扩展到多属性条件分子生成，并在条件生成和奖励最大化方面取得了最先进的性能。", "motivation": "现有的分子生成方法通常会产生许多无效分子，而基于生成树的图生成(STGG)能有效确保生成有效分子。然而，实际应用中需要根据一个或多个期望属性进行条件生成，而非无条件生成，因此需要将STGG扩展到多属性条件生成。", "method": "本文将STGG扩展为STGG+，用于多属性条件生成。STGG+整合了现代Transformer架构、训练期间的属性随机掩蔽（实现任意属性子集条件生成和无分类器指导），以及辅助属性预测损失（允许模型自我批评并选择最佳分子），并进行了其他改进。", "result": "STGG+在分布内和分布外条件生成以及奖励最大化方面均取得了最先进的性能。", "conclusion": "STGG+通过引入多项创新，成功地将STGG扩展到多属性条件分子生成，并在性能上超越了现有技术，为有效且可控的分子设计提供了新方法。", "translation": "生成新型分子具有挑战性，大多数表示方法会导致生成模型产生许多无效分子。基于生成树的图生成 (STGG) 是一种有前途的方法，可确保生成有效分子，在无条件生成方面优于最先进的 SMILES 和图扩散模型。在现实世界中，我们希望能够根据一个或多个所需属性而非无条件地生成分子。因此，在这项工作中，我们将 STGG 扩展到多属性条件生成。我们的方法 STGG+，结合了现代 Transformer 架构、训练期间的属性随机掩蔽（支持在任意属性子集上进行条件生成和无分类器指导）、辅助属性预测损失（允许模型自我批评分子并选择最佳分子）以及其他改进。我们表明 STGG+ 在分布内和分布外条件生成以及奖励最大化方面均取得了最先进的性能。", "summary": "本研究提出了一种名为STGG+的新型分子生成模型，它将现有的基于生成树的图生成（STGG）方法扩展到支持任意属性条件下的分子生成。STGG+融合了Transformer架构、随机属性掩蔽技术（实现灵活的条件生成和无分类器指导）以及辅助属性预测损失（用于模型自我评估和优化）。实验结果表明，STGG+在条件分子生成和奖励最大化任务上均达到了最先进的性能，解决了现有方法生成无效分子的问题，并实现了更实际的、有属性约束的分子设计。", "keywords": "分子生成, 条件生成, 生成树, 自我批评, Transformer", "comments": "STGG+的创新之处在于将STGG与Transformer、随机属性掩蔽和自我批评机制相结合，实现了灵活且高效的多属性条件分子生成。其引入的辅助属性预测损失，使模型能够进行“自我批评”，从而选择更优的分子，这在提高生成质量方面具有重要意义。该方法为药物发现和材料科学等领域提供了强大的工具，有望加速新型分子的设计与合成。"}}
{"id": "2506.04602", "title": "MVP-Shapley: Feature-based Modeling for Evaluating the Most Valuable Player in Basketball", "authors": ["Haifeng Sun", "Yu Xiong", "Runze Wu", "Kai Wang", "Lan Zhang", "Changjie Fan", "Shaojie Tang", "Xiang-Yang Li"], "categories": ["cs.GT", "cs.LG"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.04602v2", "summary": "The burgeoning growth of the esports and multiplayer online gaming community\nhas highlighted the critical importance of evaluating the Most Valuable Player\n(MVP). The establishment of an explainable and practical MVP evaluation method\nis very challenging. In our study, we specifically focus on play-by-play data,\nwhich records related events during the game, such as assists and points. We\naim to address the challenges by introducing a new MVP evaluation framework,\ndenoted as \\oursys, which leverages Shapley values. This approach encompasses\nfeature processing, win-loss model training, Shapley value allocation, and MVP\nranking determination based on players' contributions. Additionally, we\noptimize our algorithm to align with expert voting results from the perspective\nof causality. Finally, we substantiated the efficacy of our method through\nvalidation using the NBA dataset and the Dunk City Dynasty dataset and\nimplemented online deployment in the industry.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.04602v2", "cate": "cs.GT", "date": "2025-06-05", "updated": "2025-07-16", "AI": {"title_translation": "MVP-Shapley：基于特征建模的篮球最有价值球员评估", "tldr": "本文提出了一个名为MVP-Shapley的框架，利用Shapley值和因果关系，基于比赛数据评估篮球MVP，并在NBA和《灌篮城市王朝》数据集上进行了验证和在线部署。", "motivation": "电竞和多人在线游戏社区的蓬勃发展凸显了评估最有价值球员（MVP）的关键重要性。建立一个可解释且实用的MVP评估方法非常具有挑战性。", "method": "引入了一个名为MVP-Shapley的新MVP评估框架，该框架利用Shapley值。该方法包括特征处理、输赢模型训练、Shapley值分配以及基于球员贡献的MVP排名确定。此外，从因果关系的角度优化算法以与专家投票结果保持一致。", "result": "通过使用NBA数据集和《灌篮城市王朝》数据集的验证，证实了我们方法的有效性，并在行业中实现了在线部署。", "conclusion": "本文提出的MVP-Shapley框架能够有效地评估篮球MVP，并且其结果与专家投票一致，并已成功应用于实际产业。", "translation": "电竞和多人在线游戏社区的蓬勃发展凸显了评估最有价值球员（MVP）的关键重要性。建立一个可解释且实用的MVP评估方法非常具有挑战性。在我们的研究中，我们特别关注逐场比赛数据，该数据记录了比赛中的相关事件，例如助攻和得分。我们旨在通过引入一个名为\\oursys的新MVP评估框架来应对这些挑战，该框架利用Shapley值。这种方法包括特征处理、输赢模型训练、Shapley值分配以及基于球员贡献的MVP排名确定。此外，我们从因果关系的角度优化了我们的算法，使其与专家投票结果保持一致。最后，我们通过使用NBA数据集和《灌篮城市王朝》数据集的验证证实了我们方法的有效性，并在行业中实现了在线部署。", "summary": "本文提出了一个名为MVP-Shapley的篮球MVP评估框架，旨在解决现有方法的挑战。该框架利用Shapley值，通过对逐场比赛数据进行特征处理、训练输赢模型、分配Shapley值来确定球员贡献和MVP排名。研究还从因果关系角度优化算法以匹配专家投票。该方法已在NBA和《灌篮城市王朝》数据集上验证其有效性，并已在工业界实现在线部署。", "keywords": "MVP评估, Shapley值, 篮球, 特征建模, 因果关系", "comments": "该论文的创新点在于将Shapley值引入到篮球MVP评估中，提供了一个可解释且基于特征贡献的评估方法。结合因果关系优化算法以贴近专家投票结果，增强了方法的实用性和可信度。其在实际数据集上的验证和工业界部署表明了其应用价值。"}}
{"id": "2507.12439", "title": "A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning", "authors": ["Daniel Commey", "Rebecca A. Sarpong", "Griffith S. Klogo", "Winful Bagyl-Bac", "Garth V. Crosby"], "categories": ["cs.LG", "cs.CR", "cs.GT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12439v1", "summary": "Federated learning (FL) enables collaborative model training across\ndecentralized clients while preserving data privacy. However, its\nopen-participation nature exposes it to data-poisoning attacks, in which\nmalicious actors submit corrupted model updates to degrade the global model.\nExisting defenses are often reactive, relying on statistical aggregation rules\nthat can be computationally expensive and that typically assume an honest\nmajority. This paper introduces a proactive, economic defense: a lightweight\nBayesian incentive mechanism that makes malicious behavior economically\nirrational. Each training round is modeled as a Bayesian game of incomplete\ninformation in which the server, acting as the principal, uses a small, private\nvalidation dataset to verify update quality before issuing payments. The design\nsatisfies Individual Rationality (IR) for benevolent clients, ensuring their\nparticipation is profitable, and Incentive Compatibility (IC), making poisoning\nan economically dominated strategy. Extensive experiments on non-IID partitions\nof MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping\nadversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3\npercentage points lower than in a scenario with 30% label-flipping adversaries.\nThis outcome is 51.7 percentage points better than standard FedAvg, which\ncollapses under the same 50% attack. The mechanism is computationally light,\nbudget-bounded, and readily integrates into existing FL frameworks, offering a\npractical route to economically robust and sustainable FL ecosystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12439v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "针对抗毒联邦学习的贝叶斯激励机制", "tldr": "本文提出了一种轻量级的贝叶斯激励机制，通过经济手段主动防御联邦学习中的数据投毒攻击，使其对恶意客户端而言经济上不合理，并在实验中表现出显著的鲁棒性。", "motivation": "联邦学习虽然保护数据隐私，但其开放参与性使其易受数据投毒攻击，导致全局模型退化。现有防御机制通常是被动的、计算成本高昂的，且假设存在诚实多数。因此需要一种主动的、经济有效的防御机制。", "method": "本文提出了一种轻量级的贝叶斯激励机制。将每个训练轮次建模为不完全信息的贝叶斯博弈，服务器作为委托人，使用小型私有验证数据集来验证更新质量，然后进行支付。该设计满足了良性客户端的个体理性（IR），确保其参与有利可图，并满足激励兼容性（IC），使投毒成为经济上劣势的策略。", "result": "在MNIST和FashionMNIST的非IID分区上进行了广泛实验。在MNIST上，面对50%标签翻转攻击者，该机制仍保持96.7%的准确率，仅比30%标签翻转攻击者场景低0.3个百分点。这比标准FedAvg在相同50%攻击下性能崩溃的情况好51.7个百分点。该机制计算量轻、预算有界，且易于集成到现有FL框架中。", "conclusion": "该贝叶斯激励机制为联邦学习提供了一种经济上鲁棒且可持续的实用途径，有效防御了数据投毒攻击，并优于现有方法。", "translation": "联邦学习（FL）实现了跨去中心化客户端的协作模型训练，同时保护数据隐私。然而，其开放参与的性质使其容易受到数据投毒攻击，恶意行为者提交损坏的模型更新以降低全局模型的性能。现有的防御措施通常是被动的，依赖于统计聚合规则，这些规则计算成本高昂，并且通常假设存在诚实多数。本文引入了一种主动的经济防御：一种轻量级的贝叶斯激励机制，使恶意行为在经济上不合理。每个训练轮次都被建模为不完全信息贝叶斯博弈，其中服务器作为委托人，使用一小部分私有验证数据集来验证更新质量，然后支付报酬。该设计满足良性客户端的个体理性（IR），确保其参与有利可图，并满足激励兼容性（IC），使投毒成为经济上劣势的策略。在MNIST和FashionMNIST的非IID分区上进行的广泛实验证明了其鲁棒性：在MNIST上，面对50%标签翻转攻击者，该机制保持96.7%的准确率，仅比30%标签翻转攻击者场景低0.3个百分点。这一结果比在相同50%攻击下崩溃的标准FedAvg好51.7个百分点。该机制计算量轻、预算有界，并且易于集成到现有FL框架中，为构建经济上鲁棒和可持续的联邦学习生态系统提供了一条实用途径。", "summary": "本文提出了一种创新的贝叶斯激励机制，旨在通过经济手段主动防御联邦学习中的数据投毒攻击。该机制将训练轮次建模为贝叶斯博弈，通过服务器验证更新质量并支付报酬，确保良性客户端的收益，并使恶意投毒行为在经济上不可取。实验证明，该机制在严重攻击下仍能保持高准确率，显著优于传统方法，且计算高效、易于集成，为构建健壮的联邦学习系统提供了实用方案。", "keywords": "联邦学习, 数据投毒, 贝叶斯激励机制, 博弈论, 经济防御", "comments": "该论文的创新点在于将经济学原理引入联邦学习的安全防御中，通过激励机制从根本上改变恶意行为者的决策，使其投毒行为在经济上不合理，这是一种主动且新颖的防御范式。相对于传统的统计聚合防御，这种基于博弈论的方法更具前瞻性，且在极端攻击条件下表现出卓越的鲁棒性。其轻量级和易于集成的特性也增加了其实用价值。"}}
{"id": "2507.11739", "title": "Sparse Identification of Nonlinear Dynamics with Conformal Prediction", "authors": ["Urban Fasel"], "categories": ["cs.LG", "cs.CE", "math.DS"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11739v1", "summary": "The Sparse Identification of Nonlinear Dynamics (SINDy) is a method for\ndiscovering nonlinear dynamical system models from data. Quantifying\nuncertainty in SINDy models is essential for assessing their reliability,\nparticularly in safety-critical applications. While various uncertainty\nquantification methods exist for SINDy, including Bayesian and ensemble\napproaches, this work explores the integration of Conformal Prediction, a\nframework that can provide valid prediction intervals with coverage guarantees\nbased on minimal assumptions like data exchangeability. We introduce three\napplications of conformal prediction with Ensemble-SINDy (E-SINDy): (1)\nquantifying uncertainty in time series prediction, (2) model selection based on\nlibrary feature importance, and (3) quantifying the uncertainty of identified\nmodel coefficients using feature conformal prediction. We demonstrate the three\napplications on stochastic predator-prey dynamics and several chaotic dynamical\nsystems. We show that conformal prediction methods integrated with E-SINDy can\nreliably achieve desired target coverage for time series forecasting,\neffectively quantify feature importance, and produce more robust uncertainty\nintervals for model coefficients, even under non-Gaussian noise, compared to\nstandard E-SINDy coefficient estimates.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11739v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "基于共形预测的非线性动力学稀疏识别", "tldr": "本研究将共形预测与Ensemble-SINDy (E-SINDy)结合，用于量化非线性动力学模型的不确定性，并在时间序列预测、模型选择和系数不确定性量化方面取得了更可靠的结果。", "motivation": "量化SINDy模型的不确定性对于评估其可靠性至关重要，尤其是在安全关键应用中。尽管SINDy存在多种不确定性量化方法，但本工作旨在探索共形预测框架的集成，该框架能提供具有覆盖保证的有效预测区间。", "method": "本研究探索了将共形预测与Ensemble-SINDy (E-SINDy)结合。具体介绍了共形预测在E-SINDy中的三个应用：(1) 量化时间序列预测中的不确定性；(2) 基于库特征重要性进行模型选择；(3) 使用特征共形预测量化已识别模型系数的不确定性。这些应用在随机捕食者-猎物动力学和几个混沌动力学系统上进行了演示。", "result": "研究表明，与标准E-SINDy系数估计相比，集成共形预测方法的E-SINDy能够可靠地实现时间序列预测所需的预期覆盖率，有效量化特征重要性，并为模型系数生成更鲁棒的不确定性区间，即使在非高斯噪声下也能表现良好。", "conclusion": "共形预测方法与Ensemble-SINDy的结合可以显著提高非线性动力学模型不确定性量化的可靠性和鲁棒性，尤其是在时间序列预测、特征重要性评估和模型系数不确定性方面。", "translation": "稀疏识别非线性动力学（SINDy）是一种从数据中发现非线性动力学系统模型的方法。量化SINDy模型的不确定性对于评估其可靠性至关重要，尤其是在安全关键应用中。尽管SINDy存在各种不确定性量化方法，包括贝叶斯和集成方法，但本工作探索了共形预测的集成，这是一个可以提供具有覆盖保证的有效预测区间的框架，其基于数据可交换性等最小假设。我们介绍了共形预测与Ensemble-SINDy（E-SINDy）的三个应用：（1）量化时间序列预测中的不确定性，（2）基于库特征重要性进行模型选择，以及（3）使用特征共形预测量化已识别模型系数的不确定性。我们在随机捕食者-猎物动力学和几个混沌动力学系统上演示了这三个应用。我们表明，与标准E-SINDy系数估计相比，与E-SINDy集成的共形预测方法可以可靠地实现时间序列预测所需的预期覆盖率，有效量化特征重要性，并为模型系数产生更鲁棒的不确定性区间，即使在非高斯噪声下也是如此。", "summary": "本研究提出将共形预测（Conformal Prediction）框架集成到稀疏识别非线性动力学（SINDy）方法中，特别是与Ensemble-SINDy（E-SINDy）结合，以有效量化非线性动力学模型的不确定性。研究详细探讨了共形预测在时间序列预测不确定性量化、基于特征重要性的模型选择以及模型系数不确定性量化方面的应用。通过在随机捕食者-猎物和混沌动力学系统上的实验，结果表明，与标准E-SINDy相比，该方法能可靠地实现预测覆盖率、有效量化特征重要性，并在非高斯噪声下为模型系数提供更鲁棒的不确定性区间。", "keywords": "稀疏识别非线性动力学, 共形预测, 不确定性量化, Ensemble-SINDy, 时间序列预测", "comments": "该论文的创新点在于将共形预测这一提供有效预测区间的通用框架引入到SINDy模型的不确定性量化中，解决了传统方法在某些假设下的局限性。其重要性体现在提高了SINDy模型在安全关键应用中的可靠性，尤其是在处理非高斯噪声数据时，为模型系数提供了更稳健的不确定性估计。"}}
{"id": "2507.11928", "title": "Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning", "authors": ["Abhishek Sriram", "Neal Tuffy"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper is a pre-print version and has been submitted to the IEEE International Conference on Future Machine Learning and Data Science (FMLDS 2025)", "url": "http://arxiv.org/abs/2507.11928v1", "summary": "This paper presents a machine learning-accelerated optimization framework for\nRF power amplifier design that reduces simulation requirements by 65% while\nmaintaining $\\pm0.3$ to $\\pm0.4$ dBm accuracy. The proposed method combines\nMaxMin Latin Hypercube Sampling with CatBoost gradient boosting to\nintelligently explore multidimensional parameter spaces. Instead of\nexhaustively simulating all parameter combinations to achieve target P2dB\ncompression specifications, our approach strategically selects approximately\n35% of critical simulation points. The framework processes ADS netlists,\nexecutes harmonic balance simulations on the reduced dataset, and trains a\nCatBoost model to predict P2dB performance across the entire design space.\nValidation across 15 PA operating modes yields an average $R^2$ of 0.901, with\nthe system ranking parameter combinations by their likelihood of meeting target\nspecifications. The integrated solution delivers 58.24% to 77.78% reduction in\nsimulation time through automated GUI-based workflows, enabling rapid design\niterations without compromising accuracy standards required for production RF\ncircuits.", "comment": "This paper is a pre-print version and has been submitted to the IEEE\n  International Conference on Future Machine Learning and Data Science (FMLDS\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.11928v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "智能采样和基于机器学习的参数调优加速射频功率放大器设计", "tldr": "提出一种ML加速的射频功放设计优化框架，可大幅减少仿真需求并保持高精度，显著缩短设计时间。", "motivation": "射频功率放大器设计需要大量的仿真，现有方法效率不高，需要一种更快速、更高效的设计迭代方法。", "method": "结合MaxMin拉丁超立方采样和CatBoost梯度提升算法，智能探索多维参数空间，选择约35%的关键仿真点。框架处理ADS网表，在缩减数据集上执行谐波平衡仿真，并训练CatBoost模型预测P2dB性能。", "result": "仿真需求减少65%，精度保持在±0.3至±0.4 dBm。在15种PA操作模式下，平均R^2为0.901。仿真时间减少58.24%至77.78%。", "conclusion": "该集成解决方案通过自动化GUI工作流，在不牺牲生产射频电路所需精度标准的前提下，实现了快速设计迭代，显著减少了仿真时间。", "translation": "本文提出了一种机器学习加速的射频功率放大器设计优化框架，该框架将仿真需求减少了65%，同时保持了±0.3至±0.4 dBm的精度。所提出的方法结合了MaxMin拉丁超立方采样和CatBoost梯度提升算法，以智能地探索多维参数空间。我们的方法不是穷举模拟所有参数组合以达到目标P2dB压缩规范，而是策略性地选择大约35%的关键仿真点。该框架处理ADS网表，在缩减的数据集上执行谐波平衡仿真，并训练CatBoost模型来预测整个设计空间中的P2dB性能。在15种PA操作模式下的验证显示，平均R^2为0.901，系统根据参数组合满足目标规范的可能性进行排名。该集成解决方案通过自动化基于GUI的工作流程，将仿真时间减少了58.24%至77.78%，从而实现了快速设计迭代，而不会影响生产射频电路所需的精度标准。", "summary": "本文提出一个基于机器学习的射频功率放大器设计优化框架。该框架结合MaxMin拉丁超立方采样和CatBoost，通过智能选择关键仿真点，将仿真需求减少65%，同时保持高精度。实验结果表明，该方法在不牺牲精度的前提下，显著缩短了设计时间（58.24%至77.78%），实现了快速设计迭代。", "keywords": "射频功率放大器设计, 机器学习, 智能采样, CatBoost, 仿真加速", "comments": "该论文的创新点在于将智能采样与机器学习（CatBoost）相结合，用于射频功率放大器设计，显著提高了设计效率。其重要性体现在大幅减少了耗时的仿真需求和设计周期，对于加速RF电路的开发具有实际应用价值。"}}
{"id": "2507.12297", "title": "RegCL: Continual Adaptation of Segment Anything Model via Model Merging", "authors": ["Yuan-Chen Shu", "Zhiwei Lin", "Yongtao Wang"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12297v1", "summary": "To address the performance limitations of the Segment Anything Model (SAM) in\nspecific domains, existing works primarily adopt adapter-based one-step\nadaptation paradigms. However, some of these methods are specific developed for\nspecific domains. If used on other domains may lead to performance degradation.\nThis issue of catastrophic forgetting severely limits the model's scalability.\nTo address this issue, this paper proposes RegCL, a novel non-replay continual\nlearning (CL) framework designed for efficient multi-domain knowledge\nintegration through model merging. Specifically, RegCL incorporates the model\nmerging algorithm into the continual learning paradigm by merging the\nparameters of SAM's adaptation modules (e.g., LoRA modules) trained on\ndifferent domains. The merging process is guided by weight optimization, which\nminimizes prediction discrepancies between the merged model and each of the\ndomain-specific models. RegCL effectively consolidates multi-domain knowledge\nwhile maintaining parameter efficiency, i.e., the model size remains constant\nregardless of the number of tasks, and no historical data storage is required.\nExperimental results demonstrate that RegCL achieves favorable continual\nlearning performance across multiple downstream datasets, validating its\neffectiveness in dynamic scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12297v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "RegCL：通过模型合并持续适应Segment Anything模型", "tldr": "RegCL提出了一种新颖的非回放持续学习框架，通过合并不同领域训练的适应模块参数来解决SAM在多领域适应中的灾难性遗忘问题，实现了参数高效的多领域知识整合。", "motivation": "现有Segment Anything Model (SAM) 的域适应方法存在性能局限性，特别是适配器基线方法可能导致在其他域上性能下降，即灾难性遗忘，这严重限制了模型的扩展性。", "method": "本文提出了RegCL，一个新颖的非回放持续学习(CL)框架，通过模型合并实现高效的多领域知识集成。具体来说，RegCL将模型合并算法整合到持续学习范式中，合并在不同领域训练的SAM适应模块（如LoRA模块）的参数。合并过程通过权重优化引导，旨在最小化合并模型与每个特定领域模型之间的预测差异。", "result": "实验结果表明，RegCL在多个下游数据集上取得了良好的持续学习性能。", "conclusion": "RegCL通过模型合并有效地整合了多领域知识，同时保持了参数效率（模型大小不变，无需存储历史数据），并在动态场景中展现了其有效性。", "translation": "为了解决Segment Anything Model (SAM) 在特定领域中的性能局限性，现有工作主要采用基于适配器的一步式适应范式。然而，其中一些方法是为特定领域开发的，如果用于其他领域可能会导致性能下降。这种灾难性遗忘问题严重限制了模型的扩展性。为了解决这个问题，本文提出了RegCL，一个新颖的非回放持续学习（CL）框架，旨在通过模型合并实现高效的多领域知识集成。具体来说，RegCL将模型合并算法整合到持续学习范式中，通过合并在不同领域训练的SAM适应模块（例如LoRA模块）的参数。合并过程通过权重优化引导，以最小化合并模型与每个特定领域模型之间的预测差异。RegCL有效地整合了多领域知识，同时保持了参数效率，即无论任务数量多少，模型大小都保持不变，并且无需存储历史数据。实验结果表明，RegCL在多个下游数据集上取得了良好的持续学习性能，验证了其在动态场景中的有效性。", "summary": "本文提出了RegCL，一个针对Segment Anything Model (SAM) 的新型非回放持续学习框架，旨在解决现有域适应方法中存在的灾难性遗忘问题。RegCL通过合并在不同领域训练的SAM适应模块（如LoRA模块）的参数，并利用权重优化来最小化预测差异，从而有效地整合多领域知识。该方法实现了参数效率，无需存储历史数据，并在多个数据集上取得了良好的持续学习表现，验证了其在动态场景中的有效性。", "keywords": "持续学习, 模型合并, Segment Anything Model, 灾难性遗忘, 参数效率", "comments": "RegCL的创新之处在于将模型合并技术应用于持续学习范式中，以解决SAM在多领域适应中的灾难性遗忘问题。其优势在于无需回放历史数据，且能保持模型参数效率，这对于资源受限或隐私敏感的应用场景非常重要。该方法为基础模型在动态环境下的持续适应提供了一种新的思路。"}}
{"id": "2411.17240", "title": "Boost 3D Reconstruction using Diffusion-based Monocular Camera Calibration", "authors": ["Junyuan Deng", "Wei Yin", "Xiaoyang Guo", "Qian Zhang", "Xiaotao Hu", "Weiqiang Ren", "Xiaoxiao-Long", "Ping Tan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.17240v2", "summary": "In this paper, we present DM-Calib, a diffusion-based approach for estimating\npinhole camera intrinsic parameters from a single input image. Monocular camera\ncalibration is essential for many 3D vision tasks. However, most existing\nmethods depend on handcrafted assumptions or are constrained by limited\ntraining data, resulting in poor generalization across diverse real-world\nimages. Recent advancements in stable diffusion models, trained on massive\ndata, have shown the ability to generate high-quality images with varied\ncharacteristics. Emerging evidence indicates that these models implicitly\ncapture the relationship between camera focal length and image content.\nBuilding on this insight, we explore how to leverage the powerful priors of\ndiffusion models for monocular pinhole camera calibration. Specifically, we\nintroduce a new image-based representation, termed Camera Image, which\nlosslessly encodes the numerical camera intrinsics and integrates seamlessly\nwith the diffusion framework. Using this representation, we reformulate the\nproblem of estimating camera intrinsics as the generation of a dense Camera\nImage conditioned on an input image. By fine-tuning a stable diffusion model to\ngenerate a Camera Image from a single RGB input, we can extract camera\nintrinsics via a RANSAC operation. We further demonstrate that our monocular\ncalibration method enhances performance across various 3D tasks, including\nzero-shot metric depth estimation, 3D metrology, pose estimation and\nsparse-view reconstruction. Extensive experiments on multiple public datasets\nshow that our approach significantly outperforms baselines and provides broad\nbenefits to 3D vision tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.17240v2", "cate": "cs.CV", "date": "2024-11-26", "updated": "2025-07-16", "AI": {"title_translation": "使用扩散模型进行单目相机校准以提升三维重建", "tldr": "DM-Calib是一种基于扩散模型的方法，用于从单张图像估计针孔相机内参，显著提升了三维重建等任务的性能。", "motivation": "现有的单目相机校准方法依赖手工假设或受限于有限的训练数据，导致在多样化的真实世界图像中泛化能力差。", "method": "本文提出了DM-Calib，一种扩散模型方法，用于从单张输入图像估计针孔相机内参。该方法引入了一种新的图像表示，称为“相机图像”（Camera Image），它无损编码相机内参并与扩散框架无缝集成。通过将相机内参估计问题重新表述为以输入图像为条件的密集相机图像生成，并微调一个稳定的扩散模型来从单张RGB输入生成相机图像，最后通过RANSAC操作提取相机内参。", "result": "我们的单目校准方法在零样本度量深度估计、三维测量、姿态估计和稀疏视图重建等各种三维任务中都增强了性能。在多个公共数据集上的广泛实验表明，我们的方法显著优于基线方法，并为三维视觉任务带来了广泛的好处。", "conclusion": "DM-Calib利用扩散模型的强大先验知识，解决了单目相机校准的泛化性问题，并通过生成相机图像的方式有效估计了相机内参，从而提升了多种三维视觉任务的性能。", "translation": "在本文中，我们提出了DM-Calib，一种基于扩散模型的方法，用于从单张输入图像估计针孔相机内参。单目相机校准对于许多三维视觉任务至关重要。然而，大多数现有方法依赖于手工假设或受限于有限的训练数据，导致在多样化的真实世界图像中泛化能力差。最近在稳定扩散模型方面的进展，这些模型在海量数据上进行训练，已经显示出生成具有不同特征的高质量图像的能力。新兴证据表明，这些模型隐式地捕捉了相机焦距与图像内容之间的关系。基于这一洞察，我们探索如何利用扩散模型的强大先验知识进行单目针孔相机校准。具体来说，我们引入了一种新的基于图像的表示，称为相机图像（Camera Image），它无损地编码了数值相机内参，并与扩散框架无缝集成。使用这种表示，我们将估计相机内参的问题重新表述为以输入图像为条件的密集相机图像生成。通过微调一个稳定的扩散模型以从单个RGB输入生成相机图像，我们可以通过RANSAC操作提取相机内参。我们进一步证明，我们的单目校准方法增强了各种三维任务的性能，包括零样本度量深度估计、三维测量、姿态估计和稀疏视图重建。在多个公共数据集上的广泛实验表明，我们的方法显著优于基线方法，并为三维视觉任务带来了广泛的好处。", "summary": "DM-Calib是一种基于扩散模型的单目相机校准方法，旨在从单张图像精确估计针孔相机内参。该方法通过引入“相机图像”这一新的图像表示形式，将相机内参估计转化为条件图像生成问题，并利用微调的稳定扩散模型生成相机图像，再通过RANSAC提取内参。实验证明，DM-Calib在各种三维任务中（如深度估计、三维测量、姿态估计和稀疏视图重建）表现出色，显著优于现有基线方法，提升了三维视觉的泛化能力和性能。", "keywords": "单目相机校准, 扩散模型, 三维重建, 相机内参, DM-Calib", "comments": "本文的创新点在于巧妙地利用了大规模预训练扩散模型的强大先验知识来解决单目相机校准的泛化性问题。通过将相机内参编码为“相机图像”并将其作为扩散模型的生成目标，这种方法避免了传统方法对特定场景或大量标注数据的依赖，展现了扩散模型在高级视觉任务中的巨大潜力。其重要性在于提升了单目三维重建的精度和鲁棒性，为实际应用提供了更可靠的相机校准方案。"}}
{"id": "2503.08506", "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "authors": ["Xian Gao", "Jiacheng Ruan", "Zongyun Zhang", "Jingsheng Gao", "Ting Liu", "Yuzhuo Fu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2503.08506v3", "summary": "Academic paper review is a critical yet time-consuming task within the\nresearch community. With the increasing volume of academic publications,\nautomating the review process has become a significant challenge. The primary\nissue lies in generating comprehensive, accurate, and reasoning-consistent\nreview comments that align with human reviewers' judgments. In this paper, we\naddress this challenge by proposing ReviewAgents, a framework that leverages\nlarge language models (LLMs) to generate academic paper reviews. We first\nintroduce a novel dataset, Review-CoT, consisting of 142k review comments,\ndesigned for training LLM agents. This dataset emulates the structured\nreasoning process of human reviewers-summarizing the paper, referencing\nrelevant works, identifying strengths and weaknesses, and generating a review\nconclusion. Building upon this, we train LLM reviewer agents capable of\nstructured reasoning using a relevant-paper-aware training method. Furthermore,\nwe construct ReviewAgents, a multi-role, multi-LLM agent review framework, to\nenhance the review comment generation process. Additionally, we propose\nReviewBench, a benchmark for evaluating the review comments generated by LLMs.\nOur experimental results on ReviewBench demonstrate that while existing LLMs\nexhibit a certain degree of potential for automating the review process, there\nremains a gap when compared to human-generated reviews. Moreover, our\nReviewAgents framework further narrows this gap, outperforming advanced LLMs in\ngenerating review comments.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2503.08506v3", "cate": "cs.CL", "date": "2025-03-11", "updated": "2025-07-16", "AI": {"title_translation": "ReviewAgents：弥合人类与AI生成的论文评审之间的差距", "tldr": "ReviewAgents框架利用大型语言模型（LLMs）生成学术论文评审，并通过新数据集和训练方法缩小了与人类评审之间的差距。", "motivation": "学术论文评审耗时且出版物数量不断增加，自动化评审成为挑战。主要问题在于生成全面、准确且推理一致的评审意见，使其与人类评审员的判断保持一致。", "method": "本文提出了ReviewAgents框架，利用LLMs生成学术论文评审。首先，引入了一个新颖的Review-CoT数据集（包含14.2万条评审意见），用于训练LLM代理，该数据集模仿了人类评审员的结构化推理过程。在此基础上，使用相关论文感知训练方法训练了能够进行结构化推理的LLM评审代理。此外，构建了一个多角色、多LLM代理的评审框架ReviewAgents来增强评审意见生成过程。还提出了一个用于评估LLM生成评审意见的基准ReviewBench。", "result": "在ReviewBench上的实验结果表明，虽然现有LLMs在自动化评审方面具有一定潜力，但与人类生成的评审仍存在差距。ReviewAgents框架进一步缩小了这一差距，在生成评审意见方面优于先进的LLMs。", "conclusion": "ReviewAgents框架通过模仿人类评审的结构化推理过程和多代理协作，有效提升了LLM生成论文评审的质量，缩小了与人类评审之间的差距，为自动化论文评审提供了有效方案。", "translation": "学术论文评审是研究社区中一项关键但耗时的任务。随着学术出版物数量的增加，自动化评审过程已成为一个重大挑战。主要问题在于生成全面、准确且推理一致的评审意见，使其与人类评审员的判断保持一致。在本文中，我们通过提出ReviewAgents来解决这一挑战，这是一个利用大型语言模型（LLMs）生成学术论文评审的框架。我们首先引入了一个新颖的数据集Review-CoT，包含14.2万条评审意见，旨在训练LLM代理。该数据集模仿了人类评审员的结构化推理过程——总结论文、引用相关工作、识别优点和缺点，并生成评审结论。在此基础上，我们使用相关论文感知训练方法训练了能够进行结构化推理的LLM评审代理。此外，我们构建了一个多角色、多LLM代理的评审框架ReviewAgents，以增强评审意见生成过程。此外，我们提出了ReviewBench，一个用于评估LLM生成评审意见的基准。我们在ReviewBench上的实验结果表明，虽然现有LLMs在自动化评审过程方面表现出一定的潜力，但与人类生成的评审相比仍存在差距。此外，我们的ReviewAgents框架进一步缩小了这一差距，在生成评审意见方面优于先进的LLMs。", "summary": "本文提出了ReviewAgents框架，旨在利用大型语言模型（LLMs）解决学术论文自动化评审中生成高质量评审意见的挑战。通过构建模仿人类评审结构化推理的新数据集Review-CoT，并采用相关论文感知训练方法，训练出能够进行结构化推理的LLM评审代理。ReviewAgents是一个多角色、多LLM代理的评审框架，能够有效提升评审意见的生成质量。实验结果表明，尽管LLMs在自动化评审方面有潜力，ReviewAgents能进一步缩小与人类评审之间的差距，性能优于现有先进LLMs。", "keywords": "论文评审, 大型语言模型, 自动化, ReviewAgents, 数据集", "comments": "ReviewAgents通过引入结构化推理数据集和多代理框架，为LLM在复杂任务（如学术评审）中的应用提供了创新思路。其通过模仿人类思维过程来提升AI生成内容质量的方法值得关注。该研究不仅提出了解决方案，还提供了评估基准ReviewBench，对未来该领域的研究具有重要意义。"}}
{"id": "2507.12174", "title": "Fast and Scalable Game-Theoretic Trajectory Planning with Intentional Uncertainties", "authors": ["Zhenmin Huang", "Yusen Xie", "Benshan Ma", "Shaojie Shen", "Jun Ma"], "categories": ["cs.RO", "cs.MA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12174v1", "summary": "Trajectory planning involving multi-agent interactions has been a\nlong-standing challenge in the field of robotics, primarily burdened by the\ninherent yet intricate interactions among agents. While game-theoretic methods\nare widely acknowledged for their effectiveness in managing multi-agent\ninteractions, significant impediments persist when it comes to accommodating\nthe intentional uncertainties of agents. In the context of intentional\nuncertainties, the heavy computational burdens associated with existing\ngame-theoretic methods are induced, leading to inefficiencies and poor\nscalability. In this paper, we propose a novel game-theoretic interactive\ntrajectory planning method to effectively address the intentional uncertainties\nof agents, and it demonstrates both high efficiency and enhanced scalability.\nAs the underpinning basis, we model the interactions between agents under\nintentional uncertainties as a general Bayesian game, and we show that its\nagent-form equivalence can be represented as a potential game under certain\nminor assumptions. The existence and attainability of the optimal interactive\ntrajectories are illustrated, as the corresponding Bayesian Nash equilibrium\ncan be attained by optimizing a unified optimization problem. Additionally, we\npresent a distributed algorithm based on the dual consensus alternating\ndirection method of multipliers (ADMM) tailored to the parallel solving of the\nproblem, thereby significantly improving the scalability. The attendant\noutcomes from simulations and experiments demonstrate that the proposed method\nis effective across a range of scenarios characterized by general forms of\nintentional uncertainties. Its scalability surpasses that of existing\ncentralized and decentralized baselines, allowing for real-time interactive\ntrajectory planning in uncertain game settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12174v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "具有意图不确定性的快速可扩展博弈论轨迹规划", "tldr": "本文提出了一种新颖的博弈论交互式轨迹规划方法，以有效处理代理的意图不确定性，并通过将其建模为贝叶斯博弈并使用基于ADMM的分布式算法，实现了高效率和增强的可扩展性，超越了现有基线。", "motivation": "多智能体交互的轨迹规划是一个长期存在的挑战，现有博弈论方法在处理智能体意图不确定性时面临巨大的计算负担，导致效率低下和可扩展性差的问题。", "method": "本文提出了一种新颖的博弈论交互式轨迹规划方法。核心思想是将意图不确定性下的智能体交互建模为通用贝叶斯博弈，并证明其智能体形式等价物在特定假设下可表示为势博弈。通过优化一个统一的优化问题来达到贝叶斯纳什均衡，从而证明了最优交互轨迹的存在性和可实现性。此外，提出了一种基于双共识交替方向乘子法（ADMM）的分布式算法，用于问题的并行求解，显著提高了可扩展性。", "result": "仿真和实验结果表明，所提出的方法在各种具有通用意图不确定性的场景中都有效。其可扩展性优于现有的集中式和分布式基线方法，能够实现不确定博弈设置下的实时交互式轨迹规划。", "conclusion": "本文提出的博弈论交互式轨迹规划方法，通过将意图不确定性建模为贝叶斯博弈并采用分布式ADMM算法，有效解决了多智能体轨迹规划中意图不确定性带来的计算负担和可扩展性问题，实现了高效和实时的规划能力。", "translation": "涉及多智能体交互的轨迹规划一直是机器人领域的一个长期挑战，主要受限于智能体之间固有的复杂交互。虽然博弈论方法被广泛认为是管理多智能体交互的有效方法，但在适应智能体意图不确定性方面仍然存在重大障碍。在意图不确定性的背景下，现有博弈论方法会产生沉重的计算负担，导致效率低下和可扩展性差。在本文中，我们提出了一种新颖的博弈论交互式轨迹规划方法，以有效解决智能体的意图不确定性，并且它展示了高效率和增强的可扩展性。作为基础，我们将意图不确定性下智能体之间的交互建模为通用贝叶斯博弈，并表明在某些次要假设下，其智能体形式等价物可以表示为势博弈。通过优化一个统一的优化问题可以达到相应的贝叶斯纳什均衡，从而说明了最优交互轨迹的存在性和可实现性。此外，我们提出了一种基于双共识交替方向乘子法（ADMM）的分布式算法，专门用于问题的并行求解，从而显著提高了可扩展性。仿真和实验的伴随结果表明，所提出的方法在各种以通用意图不确定性为特征的场景中都有效。其可扩展性超越了现有的集中式和分散式基线，允许在不确定博弈设置中进行实时交互式轨迹规划。", "summary": "本文针对多智能体轨迹规划中意图不确定性导致的计算负担和可扩展性差的问题，提出了一种新颖的博弈论交互式轨迹规划方法。该方法将意图不确定性下的智能体交互建模为贝叶斯博弈，并证明其可等价为势博弈，通过统一优化问题求解贝叶斯纳什均衡。为提高可扩展性，还引入了基于ADMM的分布式算法进行并行求解。实验结果表明，该方法在处理意图不确定性方面高效且可扩展性强，能够实现实时轨迹规划，优于现有基线。", "keywords": "博弈论, 轨迹规划, 意图不确定性, 贝叶斯博弈, ADMM, 可扩展性", "comments": "本文创新性地将多智能体轨迹规划中的意图不确定性问题转化为贝叶斯博弈，并利用势博弈理论和分布式ADMM算法解决了传统方法面临的计算负担和可扩展性问题。其通过分布式求解实现实时规划的能力是重要的突破，对于实际机器人应用具有重要意义。"}}
{"id": "2507.12337", "title": "MExplore: an entity-based visual analytics approach for medical expertise acquisition", "authors": ["Xiao Pang", "Yan Huang", "Chang Liu", "JiYuan Liu", "MingYou Liu"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12337v1", "summary": "Acquiring medical expertise is a critical component of medical education and\nprofessional development. While existing studies focus primarily on\nconstructing medical knowledge bases or developing learning tools based on the\nstructured, private healthcare data, they often lack methods for extracting\nexpertise from unstructured medical texts. These texts constitute a significant\nportion of medical literature and offer greater flexibility and detail compared\nto structured data formats. Furthermore, many studies fail to provide explicit\nanalytical and learning pathways in this context.\n  This paper introduces MExplore, an interactive visual analytics system\ndesigned to support the acquisition of medical expertise. To address the\nchallenges of the inconsistencies and confidentiality concerns inherent in\nunstructured medical texts, we propose a workflow that employs a fine-tuned\nBERT-based model to extract medical entities (MEs) from them. We then present a\nnovel multilevel visual analysis framework that integrates multiple coordinated\nvisualizations, enabling a progressive and interactive exploration of medical\nknowledge.\n  To assess the effectiveness of MExplore, we conducted three case studies, a\nuser study, and interviews with domain experts. The results indicate that the\nsystem significantly enhances the medical expertise acquisition process,\nproviding an effective interactive approach for acquiring and retaining\nknowledge from medical texts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12337v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MExplore：一种基于实体的医学专业知识获取可视化分析方法", "tldr": "MExplore是一个交互式可视化分析系统，通过提取医学实体并提供多级可视化分析框架，帮助用户从非结构化医学文本中获取医学专业知识。", "motivation": "现有研究主要关注结构化医疗数据，缺乏从非结构化医学文本中提取专业知识的方法，且未能提供明确的分析和学习路径。非结构化文本占医学文献的很大一部分，具有更大的灵活性和细节。", "method": "MExplore系统采用一个微调的BERT模型从非结构化医学文本中提取医学实体，并提出一个新颖的多级可视化分析框架，该框架集成了多个协调的可视化，以实现医学知识的渐进式和交互式探索。", "result": "通过三项案例研究、一项用户研究和对领域专家的访谈表明，MExplore系统显著增强了医学专业知识获取过程，为从医学文本中获取和保留知识提供了一种有效的交互式方法。", "conclusion": "MExplore提供了一种有效的交互式可视化分析方法，用于从非结构化医学文本中获取和保留医学专业知识，解决了现有方法的局限性。", "translation": "医学专业知识的获取是医学教育和专业发展的关键组成部分。现有研究主要侧重于构建医学知识库或开发基于结构化、私人医疗数据的学习工具，但它们通常缺乏从非结构化医学文本中提取专业知识的方法。这些文本构成了医学文献的重要部分，与结构化数据格式相比，提供了更大的灵活性和细节。此外，许多研究未能在此背景下提供明确的分析和学习路径。\n本文介绍了 MExplore，一个旨在支持医学专业知识获取的交互式可视化分析系统。为了解决非结构化医学文本中固有的不一致性和保密性问题，我们提出了一种工作流程，该流程采用经过微调的基于 BERT 的模型从中提取医学实体（ME）。然后，我们提出了一个新颖的多级可视化分析框架，该框架集成了多个协调的可视化，实现了医学知识的渐进式和交互式探索。\n为了评估 MExplore 的有效性，我们进行了三项案例研究、一项用户研究以及对领域专家的访谈。结果表明，该系统显著增强了医学专业知识获取过程，为从医学文本中获取和保留知识提供了一种有效的交互式方法。", "summary": "MExplore是一个交互式可视化分析系统，旨在帮助用户从非结构化医学文本中获取专业知识。它通过微调的BERT模型提取医学实体，并结合多级可视化分析框架进行知识探索。通过案例研究、用户研究和专家访谈验证，MExplore显著提高了医学专业知识获取的效率和效果。", "keywords": "医学专业知识获取, 可视化分析, 非结构化文本, BERT, 医学实体", "comments": "MExplore的创新之处在于其针对非结构化医学文本的专业知识提取方法，结合了先进的BERT模型和多级可视化分析，填补了现有研究在处理此类数据上的空白，为医学教育和专业发展提供了新颖且实用的工具。"}}
{"id": "2507.11985", "title": "Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints", "authors": ["Jiahao Xia", "Yike Wu", "Wenjian Huang", "Jianguo Zhang", "Jian Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.11985v1", "summary": "Part-level features are crucial for image understanding, but few studies\nfocus on them because of the lack of fine-grained labels. Although unsupervised\npart discovery can eliminate the reliance on labels, most of them cannot\nmaintain robustness across various categories and scenarios, which restricts\ntheir application range. To overcome this limitation, we present a more\neffective paradigm for unsupervised part discovery, named Masked Part\nAutoencoder (MPAE). It first learns part descriptors as well as a feature map\nfrom the inputs and produces patch features from a masked version of the\noriginal images. Then, the masked regions are filled with the learned part\ndescriptors based on the similarity between the local features and descriptors.\nBy restoring these masked patches using the part descriptors, they become\nbetter aligned with their part shapes, guided by appearance features from\nunmasked patches. Finally, MPAE robustly discovers meaningful parts that\nclosely match the actual object shapes, even in complex scenarios. Moreover,\nseveral looser yet more effective constraints are proposed to enable MPAE to\nidentify the presence of parts across various scenarios and categories in an\nunsupervised manner. This provides the foundation for addressing challenges\nposed by occlusion and for exploring part similarity across multiple\ncategories. Extensive experiments demonstrate that our method robustly\ndiscovers meaningful parts across various categories and scenarios. The code is\navailable at the project https://github.com/Jiahao-UTS/MPAE.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.11985v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于描述符掩蔽图像恢复和优化约束的无监督部件发现", "tldr": "本文提出了一种名为MPAE的无监督部件发现新范式，通过基于描述符的掩蔽图像恢复和优化约束，在不同类别和场景下鲁棒地发现有意义的部件。", "motivation": "由于缺乏细粒度标签，部分级特征的研究较少。现有无监督部件发现方法在不同类别和场景下鲁棒性不足，限制了其应用范围。本文旨在克服这一局限性。", "method": "本文提出了一种掩蔽部件自编码器（MPAE）。它首先从输入中学习部件描述符和特征图，并从原始图像的掩蔽版本中生成补丁特征。然后，根据局部特征和描述符之间的相似性，用学习到的部件描述符填充掩蔽区域。通过使用部件描述符恢复这些掩蔽补丁，使其更好地与部件形状对齐，并由未掩蔽补丁的外观特征引导。此外，提出了几个更宽松但更有效的约束，使MPAE能够以无监督方式识别不同场景和类别中部件的存在。", "result": "实验表明，MPAE即使在复杂场景下也能鲁棒地发现与实际物体形状紧密匹配的有意义部件。该方法在各种类别和场景下都能鲁棒地发现有意义的部件。", "conclusion": "MPAE为解决遮挡带来的挑战以及探索多类别之间的部件相似性奠定了基础。它能够鲁棒地发现有意义的部件，并适用于各种场景和类别。", "translation": "部分级特征对于图像理解至关重要，但由于缺乏细粒度标签，很少有研究关注它们。尽管无监督部件发现可以消除对标签的依赖，但大多数方法无法在各种类别和场景中保持鲁棒性，这限制了它们的应用范围。为了克服这一限制，我们提出了一种更有效的无监督部件发现范式，命名为掩蔽部件自编码器（MPAE）。它首先从输入中学习部件描述符以及特征图，并从原始图像的掩蔽版本中生成补丁特征。然后，根据局部特征和描述符之间的相似性，用学习到的部件描述符填充掩蔽区域。通过使用部件描述符恢复这些掩蔽补丁，使其更好地与部件形状对齐，并由未掩蔽补丁的外观特征引导。最后，MPAE即使在复杂场景下也能鲁棒地发现与实际物体形状紧密匹配的有意义部件。此外，提出了几个更宽松但更有效的约束，使MPAE能够以无监督方式识别不同场景和类别中部件的存在。这为解决遮挡带来的挑战以及探索多类别之间的部件相似性奠定了基础。大量的实验表明，我们的方法在各种类别和场景下都能鲁棒地发现有意义的部件。代码可在项目https://github.com/Jiahao-UTS/MPAE获取。", "summary": "本文提出了一种名为掩蔽部件自编码器（MPAE）的无监督部件发现新范式。针对现有方法在不同类别和场景下鲁棒性不足的问题，MPAE通过学习部件描述符并基于描述符进行掩蔽图像恢复来发现部件。它通过填充掩蔽区域并使其与部件形状对齐，同时引入优化约束来增强其鲁棒性。实验证明，MPAE能够鲁棒地发现有意义的部件，即使在复杂场景和跨不同类别也能有效工作，为处理遮挡和探索部件相似性提供了基础。", "keywords": "无监督部件发现, 掩蔽图像恢复, 部件描述符, 自编码器, 鲁棒性", "comments": "MPAE的创新之处在于其将描述符学习与掩蔽图像恢复相结合的无监督范式，并引入了优化约束以显著提高部件发现的鲁棒性。这对于在缺乏细粒度标签的情况下进行图像理解具有重要意义，尤其是在复杂场景和多类别应用中展现了优越性，是无监督学习在细粒度分析方面的重要进展。"}}
{"id": "2507.12138", "title": "Neural Human Pose Prior", "authors": ["Michal Heker", "Sefy Kararlitsky", "David Tolpin"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2507.12138v1", "summary": "We introduce a principled, data-driven approach for modeling a neural prior\nover human body poses using normalizing flows. Unlike heuristic or\nlow-expressivity alternatives, our method leverages RealNVP to learn a flexible\ndensity over poses represented in the 6D rotation format. We address the\nchallenge of modeling distributions on the manifold of valid 6D rotations by\ninverting the Gram-Schmidt process during training, enabling stable learning\nwhile preserving downstream compatibility with rotation-based frameworks. Our\narchitecture and training pipeline are framework-agnostic and easily\nreproducible. We demonstrate the effectiveness of the learned prior through\nboth qualitative and quantitative evaluations, and we analyze its impact via\nablation studies. This work provides a sound probabilistic foundation for\nintegrating pose priors into human motion capture and reconstruction pipelines.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.12138v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "神经人体姿态先验", "tldr": "提出了一种使用归一化流学习人体姿态的神经先验模型。", "motivation": "现有的姿态先验方法存在启发式或表达能力不足的问题，需要一个原则性的、数据驱动的方法来建模人体姿态的灵活密度分布。", "method": "该方法引入了一种数据驱动的归一化流模型，利用RealNVP学习6D旋转格式的人体姿态的灵活密度。为解决在有效6D旋转流形上建模分布的挑战，该方法在训练期间逆转了Gram-Schmidt过程，从而实现了稳定学习并保持了与基于旋转的框架的兼容性。其架构和训练流程是框架无关且易于复现的。", "result": "通过定性和定量评估，证明了所学习先验的有效性，并通过消融研究分析了其影响。", "conclusion": "这项工作为将姿态先验整合到人体运动捕捉和重建流程中提供了坚实的概率基础。", "translation": "我们引入了一种原则性的、数据驱动的方法，用于使用归一化流对人体姿态的神经先验进行建模。与启发式或表达能力不足的替代方案不同，我们的方法利用RealNVP学习6D旋转格式表示的姿态的灵活密度。我们通过在训练期间逆转Gram-Schmidt过程来解决在有效6D旋转流形上建模分布的挑战，从而实现稳定学习，同时保持与基于旋转的框架的下游兼容性。我们的架构和训练流程是框架无关且易于复现的。我们通过定性和定量评估证明了学习到的先验的有效性，并通过消融研究分析了其影响。这项工作为将姿态先验整合到人体运动捕捉和重建流程中提供了坚实的概率基础。", "summary": "该论文提出了一种基于归一化流（特别是RealNVP）的神经人体姿态先验模型。该模型能够学习6D旋转格式姿态的灵活密度分布，并通过逆转Gram-Schmidt过程解决了流形分布建模的挑战，实现了稳定训练和框架兼容性。实验结果表明了其有效性，并为人体运动捕捉和重建提供了新的概率基础。", "keywords": "神经姿态先验, 归一化流, 6D旋转, 人体姿态估计, 运动捕捉", "comments": "该论文的创新点在于将归一化流应用于人体姿态先验建模，特别是解决了6D旋转流形上的分布建模难题，为运动捕捉和重建领域提供了一个数据驱动且具有坚实概率基础的新方法，有望提高姿态估计的准确性和鲁棒性。"}}
{"id": "2501.13959", "title": "Learning an Effective Premise Retrieval Model for Efficient Mathematical Formalization", "authors": ["Yicheng Tao", "Haotian Liu", "Shanwen Wang", "Hongteng Xu"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.13959v3", "summary": "Formalized mathematics has recently garnered significant attention for its\nability to assist mathematicians across various fields. Premise retrieval, as a\ncommon step in mathematical formalization, has been a challenge, particularly\nfor inexperienced users. Existing retrieval methods that facilitate natural\nlanguage queries require a certain level of mathematical expertise from users,\nwhile approaches based on formal languages (e.g., Lean) typically struggle with\nthe scarcity of training data, hindering the training of effective and\ngeneralizable retrieval models. In this work, we introduce a novel method that\nleverages data extracted from Mathlib to train a lightweight and effective\npremise retrieval model. In particular, the proposed model embeds queries\n(i.e., proof state provided by Lean) and premises in a latent space, featuring\na tokenizer specifically trained on formal corpora. The model is learned in a\ncontrastive learning framework, in which a fine-grained similarity calculation\nmethod and a re-ranking module are applied to enhance the retrieval\nperformance. Experimental results demonstrate that our model outperforms\nexisting baselines, achieving higher accuracy while maintaining a lower\ncomputational load. We have released an open-source search engine based on our\nretrieval model at https://premise-search.com/. The source code and the trained\nmodel can be found at https://github.com/ruc-ai4math/Premise-Retrieval.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.13959v3", "cate": "cs.CL", "date": "2025-01-21", "updated": "2025-07-16", "AI": {"title_translation": "学习一种有效的数学形式化前提检索模型", "tldr": "本文提出了一种利用Mathlib数据训练的轻量级且高效的前提检索模型，通过对比学习和特定的分词器，在数学形式化中实现了更好的检索性能和更低的计算成本。", "motivation": "形式化数学在协助数学家方面受到关注，但前提检索对于经验不足的用户来说是一个挑战。现有方法要么需要用户具备数学专业知识，要么受限于训练数据稀缺，难以训练出有效且通用的检索模型。", "method": "本文提出了一种新方法，利用从Mathlib中提取的数据来训练一个轻量级且有效的前提检索模型。该模型将查询（Lean提供的证明状态）和前提嵌入到潜在空间中，并配备了一个专门在形式语料库上训练的分词器。模型采用对比学习框架进行训练，并应用了细粒度相似度计算方法和重排序模块来增强检索性能。", "result": "实验结果表明，我们的模型优于现有基线，在保持较低计算负载的同时实现了更高的准确性。", "conclusion": "本文成功开发并发布了一个高效且准确的前提检索模型，解决了数学形式化中前提检索的挑战，并已开源其搜索引擎、源代码和训练模型。", "translation": "形式化数学最近因其在各个领域协助数学家的能力而受到广泛关注。前提检索作为数学形式化中的一个常见步骤，一直是一个挑战，特别是对于经验不足的用户。现有促进自然语言查询的检索方法需要用户具备一定程度的数学专业知识，而基于形式语言（例如Lean）的方法通常面临训练数据稀缺的问题，阻碍了有效且可泛化的检索模型的训练。在这项工作中，我们引入了一种新颖的方法，该方法利用从Mathlib中提取的数据来训练一个轻量级且有效的前提检索模型。特别是，所提出的模型将查询（即Lean提供的证明状态）和前提嵌入到一个潜在空间中，其特点是专门在形式语料库上训练的分词器。该模型在对比学习框架中进行学习，其中应用了细粒度相似度计算方法和重排序模块以增强检索性能。实验结果表明，我们的模型优于现有基线，在保持较低计算负载的同时实现了更高的准确性。我们已经发布了一个基于我们检索模型的开源搜索引擎，网址为https://premise-search.com/。源代码和训练模型可在https://github.com/ruc-ai4math/Premise-Retrieval找到。", "summary": "本文针对数学形式化中前提检索的挑战，提出了一种新颖的、轻量级且高效的模型。该模型利用Mathlib数据，通过对比学习框架训练，将查询和前提嵌入潜在空间，并采用专门训练的分词器、细粒度相似度计算和重排序模块。实验证明，该模型在准确性上超越现有基线，同时计算负载更低，并已开源其搜索引擎和代码。", "keywords": "前提检索, 数学形式化, 对比学习, Mathlib, Lean", "comments": "该论文的创新点在于利用Mathlib中的形式化数据来训练一个轻量级且高效的前提检索模型，解决了现有方法在数据稀缺和用户专业知识要求上的痛点。其结合对比学习、专门分词器和重排序模块的设计，有效地提升了检索性能。模型的开源发布也极大地促进了形式化数学领域的研究和应用。"}}
{"id": "2507.12411", "title": "Linearization-Based Feedback Stabilization of McKean-Vlasov PDEs", "authors": ["Dante Kalise", "Lucas M. Moschen", "Grigorios A. Pavliotis"], "categories": ["math.OC", "cs.NA", "math-ph", "math.MP", "math.NA", "49M41, 35Q84, 65M70", "G.1.6; G.1.8"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      24 pages, 8 figures", "url": "http://arxiv.org/abs/2507.12411v1", "summary": "We study the feedback stabilization of the McKean-Vlasov PDE on the torus.\nOur goal is to steer the dynamics toward a prescribed stationary distribution\nor accelerate convergence to it using a time-dependent control potential. We\nreformulate the controlled PDE in a weighted-projected space and apply the\nground-state transform to obtain a Schrodinger-type operator. The resulting\noperator framework enables spectral analysis, verification of the\ninfinite-dimensional Hautus test, and the construction of Riccati-based\nfeedback laws. We rigorously prove local exponential stabilization via maximal\nregularity arguments and nonlinear estimates. Numerical experiments on\nwell-studied models (the noisy Kuramoto model for synchronization, the O(2)\nspin model in a magnetic field, and the Gaussian/von Mises attractive\ninteraction potential) showcase the effectiveness of our control strategy,\ndemonstrating convergence speed-ups and stabilization of otherwise unstable\nequilibria.", "comment": "24 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.12411v1", "cate": "math.OC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于线性化的McKean-Vlasov偏微分方程反馈镇定", "tldr": "本文研究了McKean-Vlasov偏微分方程的反馈镇定问题，通过将PDE重构为薛定谔型算子并结合Riccati反馈律，实现了对系统动力学向预设平稳分布的引导或加速收敛，并通过数值实验验证了其有效性。", "motivation": "目标是引导McKean-Vlasov PDE的动力学走向预设的平稳分布，或使用时变控制势加速其收敛。", "method": "将受控PDE在加权投影空间中重构，并应用基态变换得到薛定谔型算子。该算子框架支持谱分析、无限维Hautus检验的验证以及基于Riccati的反馈律构建。通过最大正则性论证和非线性估计严格证明了局部指数镇定。", "result": "严格证明了局部指数镇定。在噪声Kuramoto模型、O(2)自旋模型和高斯/von Mises吸引相互作用势模型上的数值实验表明，该控制策略有效，能够加速收敛并稳定原本不稳定的平衡点。", "conclusion": "本文成功提出了基于线性化的反馈控制策略，实现了McKean-Vlasov PDE的局部指数镇定，并通过数值实验验证了其在加速收敛和稳定不稳定平衡点方面的有效性。", "translation": "我们研究了环面上的McKean-Vlasov偏微分方程的反馈镇定问题。我们的目标是使用时变控制势将动力学引导至预设的平稳分布或加速其收敛。我们将受控偏微分方程在加权投影空间中重新表述，并应用基态变换以获得薛定谔型算子。由此产生的算子框架使得谱分析、无限维Hautus检验的验证以及基于Riccati的反馈律的构建成为可能。我们通过最大正则性论证和非线性估计严格证明了局部指数镇定。在充分研究的模型（用于同步的噪声Kuramoto模型、磁场中的O(2)自旋模型以及高斯/von Mises吸引相互作用势）上的数值实验展示了我们控制策略的有效性，证明了收敛速度的加快和原本不稳定平衡点的镇定。", "summary": "本文探讨了环面上McKean-Vlasov偏微分方程的反馈镇定问题，旨在通过时变控制势引导系统动力学至预设平稳分布或加速收敛。研究者将受控PDE重构为薛定谔型算子，并在此算子框架下进行谱分析、Hautus检验和构建Riccati反馈律。理论上，通过最大正则性论证和非线性估计，证明了局部指数镇定。数值实验在多个经典模型上验证了该控制策略的有效性，包括加速收敛和稳定不稳定平衡点。", "keywords": "McKean-Vlasov PDE, 反馈镇定, 薛定谔算子, Riccati反馈律", "comments": "本文创新性地将McKean-Vlasov PDE的反馈控制问题转化为薛定谔型算子框架，并利用其进行谱分析和Riccati反馈律设计，为这类复杂系统提供了一种严谨且有效的镇定方法。其理论证明的严谨性和数值实验的广泛验证增强了研究的可靠性。"}}
{"id": "2507.11840", "title": "The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey", "authors": ["Gaofeng Li", "Ruize Wang", "Peisen Xu", "Qi Ye", "Jiming Chen"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11840v1", "summary": "Achieving human-like dexterous robotic manipulation remains a central goal\nand a pivotal challenge in robotics. The development of Artificial Intelligence\n(AI) has allowed rapid progress in robotic manipulation. This survey summarizes\nthe evolution of robotic manipulation from mechanical programming to embodied\nintelligence, alongside the transition from simple grippers to multi-fingered\ndexterous hands, outlining key characteristics and main challenges. Focusing on\nthe current stage of embodied dexterous manipulation, we highlight recent\nadvances in two critical areas: dexterous manipulation data collection (via\nsimulation, human demonstrations, and teleoperation) and skill-learning\nframeworks (imitation and reinforcement learning). Then, based on the overview\nof the existing data collection paradigm and learning framework, three key\nchallenges restricting the development of dexterous robotic manipulation are\nsummarized and discussed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11840v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "灵巧具身机器人操作的发展与挑战：一项综述", "tldr": "本综述回顾了灵巧具身机器人操作的演变、当前进展（数据收集、技能学习）以及面临的挑战。", "motivation": "实现类人灵巧机器人操作是机器人领域的核心目标和关键挑战。人工智能的发展使得机器人操作取得了快速进展，因此有必要对该领域的发展和挑战进行总结。", "method": "本论文是一篇综述，总结了机器人操作从机械编程到具身智能的演变，以及从简单夹持器到多指灵巧手的过渡。它概述了主要特点和挑战，并重点介绍了当前具身灵巧操作阶段在数据收集（通过模拟、人类演示和远程操作）和技能学习框架（模仿学习和强化学习）方面的最新进展。最后，基于对现有数据收集范式和学习框架的概述，总结并讨论了限制灵巧机器人操作发展的三个关键挑战。", "result": "该综述概述了机器人操作从机械编程到具身智能的演变，以及从简单夹持器到多指灵巧手的过渡。它重点介绍了灵巧操作数据收集和技能学习框架方面的最新进展，并总结了限制灵巧机器人操作发展的三个关键挑战。", "conclusion": "本文基于对现有数据收集范式和学习框架的概述，总结并讨论了限制灵巧机器人操作发展的三个关键挑战。", "translation": "实现类人灵巧机器人操作仍然是机器人领域的核心目标和关键挑战。人工智能（AI）的发展使得机器人操作取得了快速进展。本综述总结了机器人操作从机械编程到具身智能的演变，以及从简单夹持器到多指灵巧手的过渡，概述了主要特点和主要挑战。针对当前具身灵巧操作阶段，我们重点介绍了两个关键领域的最新进展：灵巧操作数据收集（通过模拟、人类演示和远程操作）和技能学习框架（模仿学习和强化学习）。然后，基于对现有数据收集范式和学习框架的概述，总结并讨论了限制灵巧机器人操作发展的三个关键挑战。", "summary": "本综述探讨了机器人操作从机械编程到具身智能的演变，以及从简单夹持器向灵巧手的转变。它重点介绍了具身灵巧操作在数据收集（模拟、人类演示、远程操作）和技能学习（模仿学习、强化学习）方面的最新进展。最后，文章识别并讨论了阻碍该领域进一步发展的三个主要挑战。", "keywords": "灵巧操作, 具身智能, 机器人操作, 数据收集, 技能学习", "comments": "这是一篇及时且全面的综述，整合了机器人关键领域的发展和挑战。其结构化方法涵盖了演变、当前技术和未来挑战，使其成为研究人员宝贵的资源。考虑到人工智能驱动的进展，对数据收集和技能学习的关注尤其具有现实意义。"}}
{"id": "2410.00603", "title": "An Empirical Study of Large Language Models for Type and Call Graph Analysis in Python and JavaScript", "authors": ["Ashwin Prasad Shivarpatna Venkatesh", "Rose Sunil", "Samkutty Sabu", "Amir M. Mir", "Sofia Reis", "Eric Bodden"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted to be published in the EMSE journal", "url": "http://arxiv.org/abs/2410.00603v2", "summary": "Large Language Models (LLMs) are increasingly being explored for their\npotential in software engineering, particularly in static analysis tasks. In\nthis study, we investigate the potential of current LLMs to enhance call-graph\nanalysis and type inference for Python and JavaScript programs. We empirically\nevaluated 24 LLMs, including OpenAI's GPT series and open-source models like\nLLaMA and Mistral, using existing and newly developed benchmarks. Specifically,\nwe enhanced TypeEvalPy, a micro-benchmarking framework for type inference in\nPython, with auto-generation capabilities, expanding its scope from 860 to\n77,268 type annotations for Python. Additionally, we introduced SWARM-CG and\nSWARM-JS, comprehensive benchmarking suites for evaluating call-graph\nconstruction tools across multiple programming languages.\n  Our findings reveal a contrasting performance of LLMs in static analysis\ntasks. For call-graph generation, traditional static analysis tools such as\nPyCG for Python and Jelly for JavaScript consistently outperform LLMs. While\nadvanced models like mistral-large-it-2407-123b and gpt-4o show promise, they\nstill struggle with completeness and soundness in call-graph analysis across\nboth languages. In contrast, LLMs demonstrate a clear advantage in type\ninference for Python, surpassing traditional tools like HeaderGen and hybrid\napproaches such as HiTyper. These results suggest that, while LLMs hold promise\nin type inference, their limitations in call-graph analysis highlight the need\nfor further research. Our study provides a foundation for integrating LLMs into\nstatic analysis workflows, offering insights into their strengths and current\nlimitations.", "comment": "Accepted to be published in the EMSE journal", "pdf_url": "http://arxiv.org/pdf/2410.00603v2", "cate": "cs.SE", "date": "2024-10-01", "updated": "2025-07-16", "AI": {"title_translation": "大型语言模型在Python和JavaScript类型和调用图分析中的实证研究", "tldr": "本研究实证评估了大型语言模型在Python和JavaScript程序类型推断和调用图分析中的潜力。结果显示LLM在类型推断方面表现优异，但在调用图分析方面仍不如传统工具，需要进一步研究。", "motivation": "探讨大型语言模型（LLMs）在软件工程领域，特别是在静态分析任务中增强调用图分析和类型推断的潜力。", "method": "研究评估了24个LLM（包括OpenAI的GPT系列和开源模型如LLaMA、Mistral），使用了现有和新开发的基准测试。具体地，增强了Python类型推断的微基准测试框架TypeEvalPy，并引入了SWARM-CG和SWARM-JS作为多语言调用图构建工具的综合基准测试套件。", "result": "LLM在静态分析任务中表现出对比性：对于调用图生成，传统静态分析工具（如Python的PyCG和JavaScript的Jelly）持续优于LLM，即使是先进的LLM模型也存在完整性和健全性问题。然而，LLM在Python的类型推断方面展现出明显优势，超越了传统工具（如HeaderGen）和混合方法（如HiTyper）。", "conclusion": "LLM在类型推断方面具有潜力，但在调用图分析方面存在局限性，这表明需要进一步研究。本研究为将LLM集成到静态分析工作流程中提供了基础，并揭示了它们的优势和当前局限性。", "translation": "大型语言模型（LLMs）在软件工程领域，特别是在静态分析任务中的潜力正日益受到探索。在本研究中，我们调查了当前LLMs在增强Python和JavaScript程序调用图分析和类型推断方面的潜力。我们实证评估了24个LLM，包括OpenAI的GPT系列以及LLaMA和Mistral等开源模型，使用了现有和新开发的基准测试。具体而言，我们增强了TypeEvalPy，一个用于Python类型推断的微基准测试框架，使其具备自动生成能力，将其范围从860个类型注解扩展到77,268个。此外，我们引入了SWARM-CG和SWARM-JS，这是用于评估多种编程语言中调用图构建工具的综合基准测试套件。\n我们的研究结果揭示了LLMs在静态分析任务中截然不同的表现。对于调用图生成，传统的静态分析工具，例如Python的PyCG和JavaScript的Jelly，始终优于LLMs。尽管像mistral-large-it-2407-123b和gpt-4o这样的高级模型显示出前景，但它们在两种语言的调用图分析中仍然在完整性和健全性方面存在问题。相比之下，LLMs在Python的类型推断方面表现出明显优势，超越了HeaderGen等传统工具以及HiTyper等混合方法。这些结果表明，虽然LLMs在类型推断方面具有潜力，但它们在调用图分析中的局限性突显了进一步研究的必要性。我们的研究为将LLMs集成到静态分析工作流程中奠定了基础，提供了关于其优势和当前局限性的见解。", "summary": "本研究实证评估了24种大型语言模型（LLMs）在Python和JavaScript程序的类型推断和调用图分析中的应用潜力。通过扩展现有基准并引入新的测试套件（SWARM-CG和SWARM-JS），研究发现LLMs在Python类型推断方面表现出色，超越了传统工具。然而，在调用图生成方面，LLMs仍不如传统静态分析工具，且存在完整性和健全性问题。研究强调了LLMs在静态分析中的优势和局限性，并为未来集成LLMs到静态分析工作流程提供了基础。", "keywords": "大型语言模型, 静态分析, 类型推断, 调用图, Python, JavaScript", "comments": "本研究通过对大量LLM进行实证评估，为LLM在静态分析领域的应用提供了宝贵的见解。其创新点在于开发了新的基准测试，并揭示了LLM在不同静态分析任务（类型推断 vs. 调用图分析）上的差异化表现。这对于指导未来LLM在软件工程领域的研发具有重要意义，尤其指出了LLM在调用图分析方面的局限性是未来研究的重点。"}}
{"id": "2507.06608", "title": "Proactive Intra-GPU Disaggregation of Prefill and Decode in LLM Serving", "authors": ["Xiaoxiang Shi", "Colin Cai", "Junjia Du"], "categories": ["cs.DC", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06608v4", "summary": "Monolithic serving with chunked prefill improves GPU utilization by batching\nprefill and decode together, but suffers from fine-grained phase interference.\nEngine-level prefill-decode (PD) disaggregation avoids interference but incurs\nhigher hardware and coordination overhead. Prior intra-GPU disaggregation\napproaches multiplex prefill and decode within a single GPU, using SLO-based\ntuning guided by heuristics from offline profiling or reactive feedback loops.\nHowever, these methods respond reactively to performance issues rather than\nanticipating them, limiting adaptability under dynamic workloads.\n  We ask: can we achieve proactive intra-GPU disaggregation that adapts\neffectively to dynamic workloads? The key challenge lies in managing the\nconflicting resource demands of prefill and decode under varying conditions. We\nfirst show that GPU resources exhibit diminishing returns -- beyond a\nsaturation point, more allocation yields minimal latency benefit. Second, we\nobserve that memory bandwidth contention becomes a critical bottleneck. These\ninsights motivate a design that dynamically partitions GPU resources across\nprefill and decode phases, while jointly considering compute capacity, memory\nfootprint, and bandwidth contention.\n  Evaluated on diverse LLMs and workloads, our system Nexus achieves up to 2.2x\nhigher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM; outperforms\nSGLang by up to 2x; and matches or exceeds disaggregated vLLM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06608v4", "cate": "cs.DC", "date": "2025-07-09", "updated": "2025-07-16", "AI": {"title_translation": "LLM服务中预填充和解码的GPU内主动解耦", "tldr": "现有的LLM服务方法存在干扰或开销问题。本文提出了Nexus，一个主动的GPU内解耦系统，动态分配GPU资源，显著提高了吞吐量并降低了延迟。", "motivation": "现有的整体式服务在预填充和解码阶段存在细粒度干扰；引擎级解耦会带来更高的硬件和协调开销。之前的GPU内解耦方法是反应性的，无法有效适应动态工作负载，主要挑战在于管理动态条件下预填充和解码的冲突资源需求。", "method": "本文提出了一个名为Nexus的主动GPU内解耦系统。该系统基于两个关键发现：GPU资源存在边际收益递减效应（超过饱和点后，更多分配带来的延迟收益最小），以及内存带宽竞争是一个关键瓶颈。Nexus的设计动态地在预填充和解码阶段之间划分GPU资源，同时考虑计算能力、内存占用和带宽竞争。", "result": "Nexus系统在不同LLM和工作负载下，相比vLLM实现了高达2.2倍的吞吐量提升，20倍的TTFT（首次令牌时间）降低，以及2.5倍的TBT（令牌间时间）降低；比SGLang性能高出2倍；并与解耦的vLLM性能持平或超越。", "conclusion": "本文提出的Nexus系统通过主动的GPU内解耦方法，有效解决了动态工作负载下LLM服务的性能挑战，显著提高了吞吐量并降低了延迟，表现优于现有先进系统。", "translation": "整体式服务通过分块预填充提高了GPU利用率，将预填充和解码批处理在一起，但存在细粒度阶段干扰。引擎级预填充-解码（PD）解耦避免了干扰，但带来了更高的硬件和协调开销。先前的GPU内解耦方法在单个GPU内复用预填充和解码，使用基于SLO的调优，其指导来自离线分析的启发式方法或反应性反馈循环。然而，这些方法对性能问题是反应性的，而不是预先预测，限制了在动态工作负载下的适应性。\n我们提出问题：能否实现主动的GPU内解耦，有效适应动态工作负载？关键挑战在于管理预填充和解码在不同条件下的冲突资源需求。我们首先表明GPU资源表现出边际收益递减——超过饱和点后，更多的分配带来的延迟收益最小。其次，我们观察到内存带宽竞争成为一个关键瓶颈。这些见解促使我们设计一个动态地在预填充和解码阶段之间划分GPU资源的系统，同时考虑计算能力、内存占用和带宽竞争。\n在不同的LLM和工作负载上进行评估，我们的系统Nexus实现了比vLLM高达2.2倍的吞吐量提升，20倍的TTFT（首次令牌时间）降低，以及2.5倍的TBT（令牌间时间）降低；比SGLang性能高出高达2倍；并与解耦的vLLM性能持平或超越。", "summary": "本文针对LLM服务中现有整体式和解耦方法存在的阶段干扰、开销高或反应性适应性差的问题，提出了Nexus系统。Nexus是一种主动的GPU内解耦方法，通过识别GPU资源边际收益递减和内存带宽竞争为关键瓶颈，动态地在预填充和解码阶段间划分GPU资源。实验结果表明，Nexus在多种LLM和工作负载下，相比现有先进系统显著提升了吞吐量并降低了延迟。", "keywords": "LLM服务, GPU解耦, 预填充, 解码, 资源管理", "comments": "本文的创新点在于提出了LLM服务中预填充和解码的“主动”GPU内解耦方法，而非传统的反应性方法。其核心洞察力在于发现了GPU资源的边际收益递减效应和内存带宽竞争的关键性，这为高效的资源动态划分提供了理论基础。这项工作对于在动态工作负载下优化LLM服务性能具有重要意义，解决了现有方案的适应性限制。"}}
{"id": "2411.13140", "title": "Robust Convergency Indicator using MIMO-PI Controller in the presence of disturbances", "authors": ["Zimao Sheng", "Hongan Yang", "Jiakang Wang", "Tong Zhang"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      15 pages, 10 figures", "url": "http://arxiv.org/abs/2411.13140v2", "summary": "The PID controller remains the most widely adopted control architecture, with\ngroundbreaking success across extensive implications. However, optimal\nparameter tuning for PID controller remains a critical challenge. Existing\ntheories predominantly focus on linear time-invariant systems and Single-Input\nSingle-Output (SISO) scenarios, leaving a research gap in addressing complex\nPID control problems for Multi-Input Multi-Output (MIMO) nonlinear systems with\ndisturbances. This study enhances controller robustness by leveraging insights\ninto the velocity form of nonlinear systems. It establishes a quantitative\nmetric to evaluate the robustness of MIMO-PI controller, clarifies key theories\non how robustness influences exponential error stabilization. Guided by these\ntheories, an optimal robust MIMO-PI controller is developed without\noversimplifying assumptions. Experimental results demonstrate that the\ncontroller achieves effective exponential stabilization and exhibits\nexceptional robustness under the guidance of the proposed robust indicator.\nNotably, the robust convergence indicator can also effectively assess\ncomprehensive performance.", "comment": "15 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2411.13140v2", "cate": "eess.SY", "date": "2024-11-20", "updated": "2025-07-16", "AI": {"title_translation": "存在扰动情况下基于MIMO-PI控制器的鲁棒收敛性指标", "tldr": "本研究针对存在扰动的MIMO非线性系统，提出了一种鲁棒收敛性指标，并开发了MIMO-PI控制器，实验证明其在指数稳定性和鲁棒性方面表现出色，且该指标能有效评估综合性能。", "motivation": "现有的PID控制器优化参数调整理论主要集中在线性时不变SISO系统，而针对存在扰动的MIMO非线性系统中的复杂PID控制问题存在研究空白和挑战。", "method": "本研究利用非线性系统的速度形式增强控制器鲁棒性，建立了一个量化指标来评估MIMO-PI控制器的鲁棒性，并阐明了鲁棒性如何影响指数误差稳定性的关键理论，在此指导下开发了一个最优鲁棒MIMO-PI控制器。", "result": "实验结果表明，该控制器在所提出的鲁棒指标指导下实现了有效的指数稳定性，并表现出卓越的鲁棒性。此外，鲁棒收敛性指标也能有效评估综合性能。", "conclusion": "本研究提出的鲁棒收敛性指标能够有效指导MIMO-PI控制器在存在扰动的MIMO非线性系统中实现有效的指数稳定性和卓越的鲁棒性，并且该指标还能全面评估系统性能。", "translation": "PID控制器仍然是应用最广泛的控制架构，并在广泛的应用中取得了突破性的成功。然而，PID控制器的最佳参数调整仍然是一个关键挑战。现有理论主要集中在线性时不变系统和单输入单输出（SISO）场景，这在解决存在扰动多输入多输出（MIMO）非线性系统的复杂PID控制问题方面留下了研究空白。本研究通过利用对非线性系统速度形式的理解来增强控制器鲁棒性。它建立了一个量化指标来评估MIMO-PI控制器的鲁棒性，阐明了鲁棒性如何影响指数误差稳定性的关键理论。在这些理论的指导下，开发了一个最优鲁棒MIMO-PI控制器，而没有过度简化的假设。实验结果表明，在所提出的鲁棒指标指导下，该控制器实现了有效的指数稳定，并表现出卓越的鲁棒性。值得注意的是，鲁棒收敛性指标也能有效评估综合性能。", "summary": "本研究旨在解决存在扰动的MIMO非线性系统中PID控制器参数优化和鲁棒性不足的问题。通过利用非线性系统速度形式的见解，研究建立了一个量化鲁棒性指标，并开发了一个最优鲁棒MIMO-PI控制器。实验证明，该控制器在实现指数稳定性和增强鲁棒性方面表现出色，且所提出的鲁棒收敛性指标能有效评估系统综合性能。", "keywords": "MIMO-PI控制器, 鲁棒性, 收敛性指标, 非线性系统, 扰动", "comments": "该论文创新性地提出了一个鲁棒收敛性指标，用于量化和评估MIMO-PI控制器的鲁棒性，并在此指导下开发了最优控制器。这对于解决复杂MIMO非线性系统在存在扰动下的控制难题具有重要意义，弥补了现有PID理论在SISO和线性系统上的局限性，提升了控制器在实际应用中的性能和可靠性。"}}
{"id": "2409.00979", "title": "Regret Analysis for Randomized Gaussian Process Upper Confidence Bound", "authors": ["Shion Takeno", "Yu Inatsu", "Masayuki Karasuyama"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      37 pages, 4 figures. Accepted to Journal of Artificial Intelligence Research as an extended paper from arXiv:2302.01511", "url": "http://arxiv.org/abs/2409.00979v3", "summary": "Gaussian process upper confidence bound (GP-UCB) is a theoretically\nestablished algorithm for Bayesian optimization (BO), where we assume the\nobjective function $f$ follows a GP. One notable drawback of GP-UCB is that the\ntheoretical confidence parameter $\\beta$ increases along with the iterations\nand is too large. To alleviate this drawback, this paper analyzes the\nrandomized variant of GP-UCB called improved randomized GP-UCB (IRGP-UCB),\nwhich uses the confidence parameter generated from the shifted exponential\ndistribution. We analyze the expected regret and conditional expected regret,\nwhere the expectation and the probability are taken respectively with $f$ and\nnoise and with the randomness of the BO algorithm. In both regret analyses,\nIRGP-UCB achieves a sub-linear regret upper bound without increasing the\nconfidence parameter if the input domain is finite. Furthermore, we show that\nrandomization plays a key role in avoiding an increase in confidence parameter\nby showing that GP-UCB using a constant confidence parameter can incur linearly\ngrowing expected cumulative regret. Finally, we show numerical experiments\nusing synthetic and benchmark functions and real-world emulators.", "comment": "37 pages, 4 figures. Accepted to Journal of Artificial Intelligence\n  Research as an extended paper from arXiv:2302.01511", "pdf_url": "http://arxiv.org/pdf/2409.00979v3", "cate": "cs.LG", "date": "2024-09-02", "updated": "2025-07-16", "AI": {"title_translation": "随机高斯过程上置信界遗憾分析", "tldr": "本文分析了改进的随机高斯过程上置信界（IRGP-UCB）算法，该算法通过使用来自移位指数分布的置信参数，在不增加置信参数的情况下实现了次线性遗憾上界，解决了传统GP-UCB中置信参数过大的问题。", "motivation": "高斯过程上置信界（GP-UCB）是贝叶斯优化（BO）中一个理论上成熟的算法，但其理论置信参数$\beta$随迭代次数增加而过大。本文旨在缓解这一缺点。", "method": "本文分析了GP-UCB的随机变体，称为改进的随机GP-UCB（IRGP-UCB），它使用从移位指数分布生成的置信参数。研究了期望遗憾和条件期望遗憾，并通过数值实验验证了其性能。", "result": "在两种遗憾分析中，如果输入域是有限的，IRGP-UCB在不增加置信参数的情况下实现了次线性遗憾上界。此外，研究表明随机化在避免置信参数增加方面起着关键作用，因为使用常数置信参数的GP-UCB可能会导致线性增长的期望累积遗憾。", "conclusion": "IRGP-UCB通过引入随机置信参数，有效地解决了传统GP-UCB中置信参数随迭代次数增加而过大的问题，并在有限输入域下实现了更好的遗憾界。", "translation": "高斯过程上置信界（GP-UCB）是贝叶斯优化（BO）中一个理论上成熟的算法，其中我们假设目标函数$f$遵循GP。GP-UCB的一个显著缺点是理论置信参数$\beta$随着迭代次数的增加而增大并且过大。为了缓解这个缺点，本文分析了GP-UCB的随机变体，称为改进的随机GP-UCB（IRGP-UCB），它使用从移位指数分布生成的置信参数。我们分析了期望遗憾和条件期望遗憾，其中期望和概率分别针对$f$和噪声以及BO算法的随机性进行计算。在这两种遗憾分析中，如果输入域是有限的，IRGP-UCB在不增加置信参数的情况下实现了次线性遗憾上界。此外，我们通过证明使用常数置信参数的GP-UCB可能导致线性增长的期望累积遗憾，表明随机化在避免置信参数增加方面起着关键作用。最后，我们展示了使用合成函数、基准函数和真实世界模拟器的数值实验。", "summary": "本文针对贝叶斯优化中GP-UCB算法的置信参数随迭代次数增加而过大的问题，提出并分析了改进的随机GP-UCB（IRGP-UCB）算法。IRGP-UCB通过引入来自移位指数分布的随机置信参数，在有限输入域下实现了次线性遗憾上界，且无需增加置信参数。研究强调了随机化在避免置信参数增长中的关键作用，并通过数值实验验证了算法的有效性。", "keywords": "贝叶斯优化, 高斯过程上置信界, 遗憾分析, 随机化, 次线性遗憾", "comments": "本文的创新点在于引入了随机化方法来解决GP-UCB算法中置信参数随迭代次数线性增长的问题，并从理论上证明了其次线性遗憾界。这对于提高贝叶斯优化算法的效率和实用性具有重要意义。"}}
{"id": "2506.13575", "title": "Machine Learning-Driven Compensation for Non-Ideal Channels in AWG-Based FBG Interrogator", "authors": ["Ivan A. Kazakov", "Iana V. Kulichenko", "Egor E. Kovalev", "Angelina A. Treskova", "Daria D. Barma", "Kirill M. Malakhov", "Ivan V. Oseledets", "Arkady V. Shipulin"], "categories": ["physics.optics", "cs.LG"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      The manuscript has been accepted and is now available in early access in IEEE Sensors Letters. This revision includes the addition of a co-author, and updates the style of Figure 4 and the formatting of Table 1", "url": "http://arxiv.org/abs/2506.13575v2", "summary": "We present an experimental study of a fiber Bragg grating (FBG) interrogator\nbased on a silicon oxynitride (SiON) photonic integrated arrayed waveguide\ngrating (AWG). While AWG-based interrogators are compact and scalable, their\npractical performance is limited by non-ideal spectral responses. To address\nthis, two calibration strategies within a 2.4 nm spectral region were compared:\n(1) a segmented analytical model based on a sigmoid fitting function, and (2) a\nmachine learning (ML)-based regression model. The analytical method achieves a\nroot mean square error (RMSE) of 7.11 pm within the calibrated range, while the\nML approach based on exponential regression achieves 3.17 pm. Moreover, the ML\nmodel demonstrates generalization across an extended 2.9 nm wavelength span,\nmaintaining sub-5 pm accuracy without re-fitting. Residual and error\ndistribution analyses further illustrate the trade-offs between the two\napproaches. ML-based calibration provides a robust, data-driven alternative to\nanalytical methods, delivering enhanced accuracy for non-ideal channel\nresponses, reduced manual calibration effort, and improved scalability across\ndiverse FBG sensor configurations.", "comment": "The manuscript has been accepted and is now available in early access\n  in IEEE Sensors Letters. This revision includes the addition of a co-author,\n  and updates the style of Figure 4 and the formatting of Table 1", "pdf_url": "http://arxiv.org/pdf/2506.13575v2", "cate": "physics.optics", "date": "2025-06-16", "updated": "2025-07-15", "AI": {"title_translation": "机器学习驱动的基于AWG的FBG解调仪中非理想信道的补偿", "tldr": "本研究比较了两种校准策略（分析模型和机器学习模型）来补偿基于AWG的FBG解调仪中的非理想信道响应，结果显示机器学习方法在准确性和泛化能力上均优于分析方法。", "motivation": "基于AWG的FBG解调仪虽然紧凑且可扩展，但其实际性能受到非理想光谱响应的限制。为了解决这个问题，需要有效的校准策略。", "method": "研究比较了两种在2.4 nm光谱范围内的校准策略：1. 基于Sigmoid拟合函数的分段分析模型；2. 基于指数回归的机器学习(ML)回归模型。通过残差和误差分布分析进一步评估了两种方法的权衡。", "result": "分析方法在校准范围内的均方根误差(RMSE)为7.11 pm。基于指数回归的ML方法达到了3.17 pm的RMSE。ML模型在2.9 nm的扩展波长范围内无需重新拟合即可保持亚5 pm的精度，表现出良好的泛化能力。", "conclusion": "基于机器学习的校准为分析方法提供了一种鲁棒的、数据驱动的替代方案，可为非理想信道响应提供更高的精度，减少手动校准工作，并提高在不同FBG传感器配置中的可扩展性。", "translation": "我们提出了一项基于硅氧氮化物（SiON）光子集成阵列波导光栅（AWG）的光纤布拉格光栅（FBG）解调仪的实验研究。虽然基于AWG的解调仪紧凑且可扩展，但其实际性能受到非理想光谱响应的限制。为了解决这个问题，我们比较了2.4纳米光谱区域内的两种校准策略：（1）基于Sigmoid拟合函数的分段分析模型，和（2）基于机器学习（ML）的回归模型。分析方法在校准范围内的均方根误差（RMSE）为7.11皮米，而基于指数回归的ML方法达到了3.17皮米。此外，ML模型在扩展的2.9纳米波长范围内无需重新拟合即可展示出泛化能力，保持亚5皮米的精度。残差和误差分布分析进一步说明了两种方法之间的权衡。基于ML的校准为分析方法提供了一种鲁棒的、数据驱动的替代方案，可为非理想信道响应提供更高的精度，减少手动校准工作，并提高在不同FBG传感器配置中的可扩展性。", "summary": "本研究针对基于AWG的光纤布拉格光栅解调仪中非理想信道响应问题，比较了分析模型和机器学习模型两种校准策略。实验结果表明，机器学习方法在校准精度上显著优于传统分析方法（RMSE分别为3.17 pm和7.11 pm），并且展现出更强的波长泛化能力。这表明机器学习校准是一种更精确、更省力且更具扩展性的解决方案。", "keywords": "FBG interrogator, AWG, Machine Learning, Calibration", "comments": "本文展示了机器学习在光学测量设备校准中的巨大潜力。通过引入数据驱动的ML方法，显著提高了FBG解调仪的精度和泛化能力，并减少了传统手动校准的复杂性。这对于推动紧凑型、高性能光纤传感系统的实际应用具有重要意义。"}}
{"id": "2507.11733", "title": "ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making", "authors": ["Srikanth Vemula"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11733v1", "summary": "This Study introduces Clarity and Reasoning Interface for Artificial\nIntelligence(ClarifAI), a novel approach designed to augment the transparency\nand interpretability of artificial intelligence (AI) in the realm of improved\ndecision making. Leveraging the Case-Based Reasoning (CBR) methodology and\nintegrating an ontology-driven approach, ClarifAI aims to meet the intricate\nexplanatory demands of various stakeholders involved in AI-powered\napplications. The paper elaborates on ClarifAI's theoretical foundations,\ncombining CBR and ontologies to furnish exhaustive explanation mechanisms. It\nfurther elaborates on the design principles and architectural blueprint,\nhighlighting ClarifAI's potential to enhance AI interpretability across\ndifferent sectors and its applicability in high-stake environments. This\nresearch delineates the significant role of ClariAI in advancing the\ninterpretability of AI systems, paving the way for its deployment in critical\ndecision-making processes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11733v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "ClarifAI：通过基于案例的推理和本体驱动方法增强AI可解释性和透明度以改进决策", "tldr": "提出ClarifAI，一种结合案例推理和本体论的新方法，旨在提高AI的可解释性和透明度，以支持关键决策。", "motivation": "旨在增强AI的透明度和可解释性，以改进决策制定，并满足AI应用中各利益相关者的复杂解释需求。", "method": "采用基于案例的推理（CBR）方法并整合本体驱动的方法来提供详尽的解释机制。", "result": "ClarifAI有潜力增强AI在不同领域的可解释性，并适用于高风险环境，为AI系统在关键决策过程中的部署铺平道路。", "conclusion": "ClarifAI在提高AI系统的可解释性方面发挥着重要作用，为AI在关键决策过程中的部署奠定了基础。", "translation": "本研究介绍了人工智能清晰度和推理接口（ClarifAI），这是一种旨在增强人工智能（AI）在改进决策制定领域透明度和可解释性的新颖方法。ClarifAI利用基于案例的推理（CBR）方法并整合本体驱动方法，旨在满足AI驱动应用中各利益相关者的复杂解释需求。本文详细阐述了ClarifAI的理论基础，结合CBR和本体论以提供详尽的解释机制。它进一步阐述了设计原则和架构蓝图，突出了ClarifAI在不同领域增强AI可解释性的潜力及其在高风险环境中的适用性。这项研究描绘了ClarifAI在推进AI系统可解释性方面的显著作用，为AI在关键决策过程中的部署铺平了道路。", "summary": "ClarifAI是一种新颖的方法，结合基于案例的推理（CBR）和本体驱动方法，旨在提高AI的透明度和可解释性，以支持改进的决策制定。该研究阐述了ClarifAI的理论基础、设计原则和架构，强调了其在不同领域增强AI可解释性以及在高风险环境中的应用潜力，为AI系统在关键决策过程中的部署奠定了基础。", "keywords": "AI可解释性, 透明度, 基于案例的推理, 本体驱动, 决策制定", "comments": "该论文创新性地结合了基于案例的推理（CBR）和本体论，以解决AI可解释性和透明度这一关键问题。其重要性在于为AI在关键决策环境中的应用提供了更可靠、可信赖的基础，有助于满足不同利益相关者的解释需求。"}}
{"id": "2507.11653", "title": "VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization", "authors": ["Hannah Shafferman", "Annika Thomas", "Jouko Kinnari", "Michael Ricard", "Jose Nino", "Jonathan How"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures. This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.11653v1", "summary": "Global localization is critical for autonomous navigation, particularly in\nscenarios where an agent must localize within a map generated in a different\nsession or by another agent, as agents often have no prior knowledge about the\ncorrelation between reference frames. However, this task remains challenging in\nunstructured environments due to appearance changes induced by viewpoint\nvariation, seasonal changes, spatial aliasing, and occlusions -- known failure\nmodes for traditional place recognition methods. To address these challenges,\nwe propose VISTA (View-Invariant Segmentation-Based Tracking for Frame\nAlignment), a novel open-set, monocular global localization framework that\ncombines: 1) a front-end, object-based, segmentation and tracking pipeline,\nfollowed by 2) a submap correspondence search, which exploits geometric\nconsistencies between environment maps to align vehicle reference frames. VISTA\nenables consistent localization across diverse camera viewpoints and seasonal\nchanges, without requiring any domain-specific training or finetuning. We\nevaluate VISTA on seasonal and oblique-angle aerial datasets, achieving up to a\n69% improvement in recall over baseline methods. Furthermore, we maintain a\ncompact object-based map that is only 0.6% the size of the most\nmemory-conservative baseline, making our approach capable of real-time\nimplementation on resource-constrained platforms.", "comment": "9 pages, 6 figures. This work has been submitted to the IEEE for\n  possible publication", "pdf_url": "http://arxiv.org/pdf/2507.11653v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "VISTA：基于单目分割的地图构建，实现外观和视角不变的全局定位", "tldr": "VISTA提出一种基于单目分割的全局定位框架，解决了外观和视角变化下的定位挑战，显著提升了召回率并减小了地图大小。", "motivation": "全局定位对于自主导航至关重要，但在非结构化环境中，由于视角变化、季节变化、空间混叠和遮挡引起的外观变化，传统地点识别方法面临挑战。", "method": "VISTA是一个开放集、单目全局定位框架，结合了：1) 前端、基于对象的分割和跟踪管道；2) 子图对应搜索，利用环境地图之间的几何一致性来对齐车辆参考系。该方法无需任何特定领域训练或微调。", "result": "在季节性和倾斜角度航空数据集上，VISTA的召回率比基线方法提高了69%；维护了一个紧凑的、仅为最节省内存基线0.6%大小的基于对象的地图。", "conclusion": "VISTA能够在多样化的摄像机视角和季节变化下实现一致的定位，且无需特定领域训练或微调，其紧凑的地图使其能够在资源受限的平台上实时实现。", "translation": "全局定位对于自主导航至关重要，尤其是在智能体必须在不同会话或由其他智能体生成的地图中进行定位的场景中，因为智能体通常对参考系之间的关联没有先验知识。然而，由于视角变化、季节变化、空间混叠和遮挡引起的外观变化，这项任务在非结构化环境中仍然具有挑战性——这些都是传统地点识别方法的已知失效模式。为了应对这些挑战，我们提出了VISTA（View-Invariant Segmentation-Based Tracking for Frame Alignment），这是一种新颖的开放集、单目全局定位框架，它结合了：1）一个前端、基于对象的分割和跟踪管道，随后是2）一个子图对应搜索，该搜索利用环境地图之间的几何一致性来对齐车辆参考系。VISTA无需任何特定领域训练或微调，即可在多样化的摄像机视角和季节变化下实现一致的定位。我们在季节性和倾斜角度航空数据集上评估了VISTA，召回率比基线方法提高了69%。此外，我们维护了一个紧凑的、基于对象的地图，其大小仅为最节省内存基线的0.6%，这使得我们的方法能够在资源受限的平台上实时实现。", "summary": "VISTA是一个创新的单目全局定位框架，旨在解决自主导航中因外观和视角变化导致的定位挑战。它通过结合基于对象的分割跟踪和子图对应搜索来对齐参考系，无需特定训练即可在不同视角和季节下实现稳定定位。实验结果显示，VISTA在召回率上比现有方法提高了69%，并显著减小了地图大小，使其适用于资源受限平台的实时应用。", "keywords": "全局定位, 单目分割, 外观不变性, 视角不变性, 地图构建", "comments": "VISTA的创新之处在于其无需领域特定训练和微调的特性，以及结合单目分割和几何一致性进行全局定位的方法。其在召回率和地图紧凑性上的显著提升，对于资源受限的自主导航系统具有重要意义。"}}
{"id": "2507.12103", "title": "DeepShade: Enable Shade Simulation by Text-conditioned Image Generation", "authors": ["Longchao Da", "Xiangrui Liu", "Mithun Shivakoti", "Thirulogasankar Pranav Kutralingam", "Yezhou Yang", "Hua Wei"], "categories": ["cs.CV", "cs.CY", "68T45, 68U10, 62H35", "I.2.10; I.4.8; I.5.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7pages, 4 figures. Accepted to IJCAI 2025", "url": "http://arxiv.org/abs/2507.12103v1", "summary": "Heatwaves pose a significant threat to public health, especially as global\nwarming intensifies. However, current routing systems (e.g., online maps) fail\nto incorporate shade information due to the difficulty of estimating shades\ndirectly from noisy satellite imagery and the limited availability of training\ndata for generative models. In this paper, we address these challenges through\ntwo main contributions. First, we build an extensive dataset covering diverse\nlongitude-latitude regions, varying levels of building density, and different\nurban layouts. Leveraging Blender-based 3D simulations alongside building\noutlines, we capture building shadows under various solar zenith angles\nthroughout the year and at different times of day. These simulated shadows are\naligned with satellite images, providing a rich resource for learning shade\npatterns. Second, we propose the DeepShade, a diffusion-based model designed to\nlearn and synthesize shade variations over time. It emphasizes the nuance of\nedge features by jointly considering RGB with the Canny edge layer, and\nincorporates contrastive learning to capture the temporal change rules of\nshade. Then, by conditioning on textual descriptions of known conditions (e.g.,\ntime of day, solar angles), our framework provides improved performance in\ngenerating shade images. We demonstrate the utility of our approach by using\nour shade predictions to calculate shade ratios for real-world route planning\nin Tempe, Arizona. We believe this work will benefit society by providing a\nreference for urban planning in extreme heat weather and its potential\npractical applications in the environment.", "comment": "7pages, 4 figures. Accepted to IJCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.12103v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "DeepShade：通过文本条件图像生成实现阴影模拟", "tldr": "DeepShade通过构建大规模阴影数据集和提出扩散模型，实现了基于文本条件的阴影图像生成，以解决现有地图系统缺乏阴影信息的问题，助力城市规划和路线规划。", "motivation": "全球变暖加剧了热浪对公共健康的威胁。当前的路线规划系统（如在线地图）未能整合阴影信息，原因是难以直接从噪声卫星图像中估计阴影，且生成模型的训练数据有限。", "method": "本文提出两项主要贡献：首先，构建了一个包含不同经纬度区域、建筑密度和城市布局的综合数据集，利用Blender进行3D模拟，捕捉全年不同时间和太阳天顶角下的建筑阴影，并与卫星图像对齐。其次，提出了DeepShade模型，一个基于扩散的模型，通过结合RGB与Canny边缘层强调边缘特征，并融入对比学习捕捉阴影的时间变化规律。该模型通过文本描述（如一天中的时间、太阳角度）进行条件化，生成阴影图像。", "result": "该方法在生成阴影图像方面表现出改进的性能。通过使用阴影预测，成功计算了亚利桑那州坦佩市实际路线规划中的阴影比例。", "conclusion": "这项工作通过为极端炎热天气下的城市规划提供参考，并具有潜在的环境实际应用价值，将造福社会。", "translation": "热浪对公共健康构成重大威胁，尤其是在全球变暖加剧的情况下。然而，当前的路线规划系统（例如在线地图）未能整合阴影信息，原因是难以直接从噪声卫星图像中估计阴影，且生成模型的训练数据有限。在本文中，我们通过两项主要贡献解决了这些挑战。首先，我们构建了一个涵盖不同经纬度区域、不同建筑密度和不同城市布局的广泛数据集。我们利用基于Blender的3D模拟以及建筑轮廓，捕捉全年不同时间和不同太阳天顶角下的建筑阴影。这些模拟的阴影与卫星图像对齐，为学习阴影模式提供了丰富的资源。其次，我们提出了DeepShade，一个基于扩散的模型，旨在学习和合成随时间变化的阴影。它通过联合考虑RGB与Canny边缘层来强调边缘特征的细微之处，并结合对比学习来捕捉阴影的时间变化规律。然后，通过以已知条件（例如一天中的时间、太阳角度）的文本描述为条件，我们的框架在生成阴影图像方面提供了改进的性能。我们通过使用我们的阴影预测来计算亚利桑那州坦佩市真实路线规划中的阴影比例，展示了我们方法的实用性。我们相信这项工作通过为极端炎热天气下的城市规划提供参考及其在环境中的潜在实际应用，将造福社会。", "summary": "本文提出DeepShade框架，旨在解决现有路线规划系统缺乏阴影信息的问题，以应对热浪威胁。作者首先构建了一个大规模、多样的阴影数据集，利用Blender模拟不同时间、角度下的建筑阴影并与卫星图像对齐。接着，开发了基于扩散的DeepShade模型，该模型结合了RGB与Canny边缘信息，并采用对比学习来捕捉阴影的时间动态。通过文本条件化，DeepShade能有效生成阴影图像，并已成功应用于实际路线规划中的阴影比例计算，为城市规划提供了有益工具。", "keywords": "阴影模拟, 图像生成, 扩散模型, 城市规划, 数据集", "comments": "DeepShade的创新之处在于结合了大规模模拟数据集的构建与先进的扩散模型，并通过文本条件化实现了灵活的阴影生成。其重要性在于解决了热浪下城市规划和导航的关键痛点，有望提升公共健康和城市宜居性。通过将3D模拟与卫星图像相结合，为数据受限的生成任务提供了新的思路。潜在的局限性可能在于模拟的精确度与真实世界复杂性的匹配程度，以及模型在极端未见条件下的泛化能力。"}}
{"id": "2506.01588", "title": "Learning Perceptually Relevant Temporal Envelope Morphing", "authors": ["Satvik Dixit", "Sungjoon Park", "Chris Donahue", "Laurie M. Heller"], "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted at WASPAA 2025", "url": "http://arxiv.org/abs/2506.01588v2", "summary": "Temporal envelope morphing, the process of interpolating between the\namplitude dynamics of two audio signals, is an emerging problem in generative\naudio systems that lacks sufficient perceptual grounding. Morphing of temporal\nenvelopes in a perceptually intuitive manner should enable new methods for\nsound blending in creative media and for probing perceptual organization in\npsychoacoustics. However, existing audio morphing techniques often fail to\nproduce intermediate temporal envelopes when input sounds have distinct\ntemporal structures; many morphers effectively overlay both temporal\nstructures, leading to perceptually unnatural results. In this paper, we\nintroduce a novel workflow for learning envelope morphing with perceptual\nguidance: we first derive perceptually grounded morphing principles through\nhuman listening studies, then synthesize large-scale datasets encoding these\nprinciples, and finally train machine learning models to create perceptually\nintermediate morphs. Specifically, we present: (1) perceptual principles that\nguide envelope morphing, derived from our listening studies, (2) a supervised\nframework to learn these principles, (3) an autoencoder that learns to compress\ntemporal envelope structures into latent representations, and (4) benchmarks\nfor evaluating audio envelope morphs, using both synthetic and naturalistic\ndata, and show that our approach outperforms existing methods in producing\ntemporally intermediate morphs. All code, models, and datasets will be made\npublicly available upon publication.", "comment": "Accepted at WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2506.01588v2", "cate": "cs.SD", "date": "2025-06-02", "updated": "2025-07-16", "AI": {"title_translation": "学习感知相关的时域包络线变形", "tldr": "本文提出了一种新颖的、由感知引导的机器学习工作流程，用于时域包络线变形。该方法通过人类听觉研究推导感知原则，合成大规模数据集，并训练机器学习模型来生成感知上自然的中间变形，优于现有方法。", "motivation": "现有时域包络线变形技术在输入声音具有不同时域结构时，往往无法产生感知上自然的中间时域包络线，许多方法只是简单叠加结构，导致不自然的结果。生成式音频系统中，此问题缺乏足够的感知基础。", "method": "本文提出了一种新颖的学习包络线变形的工作流程：1) 通过人类听觉研究推导感知基础的变形原则；2) 合成编码这些原则的大规模数据集；3) 训练机器学习模型（包括一个监督框架和一个学习将时域包络线结构压缩到潜在表示中的自编码器）来创建感知上中间的变形；4) 使用合成和自然数据，建立了评估音频包络线变形的基准。", "result": "所提出的方法在生成时域中间变形方面优于现有方法。", "conclusion": "本文成功引入了一种新颖的、感知引导的时域包络线变形工作流程，解决了现有方法的不足，从而实现了更自然、感知上更直观的声音混合。", "translation": "时域包络线变形，即在两个音频信号的振幅动态之间进行插值的过程，是生成式音频系统中一个新兴的问题，但其缺乏足够的感知基础。以感知直观的方式进行时域包络线变形，应能为创意媒体中的声音混合以及心理声学中探究感知组织提供新方法。然而，现有音频变形技术在输入声音具有不同时域结构时，往往无法产生中间时域包络线；许多变形器实际上会叠加两种时域结构，导致感知上不自然的结果。在本文中，我们介绍了一种学习具有感知指导的包络线变形的新颖工作流程：我们首先通过人类听觉研究得出感知基础的变形原则，然后合成编码这些原则的大规模数据集，最后训练机器学习模型来创建感知上中间的变形。具体来说，我们提出了：(1) 源自我们听觉研究的指导包络线变形的感知原则，(2) 一个学习这些原则的监督框架，(3) 一个学习将时域包络线结构压缩到潜在表示中的自编码器，以及 (4) 用于评估音频包络线变形的基准，使用合成和自然数据，并表明我们的方法在生成时域中间变形方面优于现有方法。所有代码、模型和数据集将在发布后公开提供。", "summary": "本文旨在解决生成式音频系统中时域包络线变形缺乏感知基础的问题，现有方法在处理不同时域结构的声音时常产生不自然的结果。作者提出了一种新颖的工作流程：首先通过人类听觉研究确立感知原则，然后基于这些原则合成大规模数据集，并训练包括监督框架和自编码器在内的机器学习模型来生成感知上自然的中间变形。研究表明，该方法在生成时域中间变形方面优于现有技术，为声音混合和心理声学研究提供了更直观的方法。", "keywords": "时域包络线变形, 感知指导, 机器学习, 音频合成, 心理声学", "comments": "本文通过将人类感知研究直接整合到机器学习流程中，为音频变形领域带来了显著创新。这种以感知驱动的方法解决了先前技术的一个关键限制，从而产生了更自然、更直观的结果。基准的建立和资源的公开可用性也是对该领域的宝贵贡献。"}}
{"id": "2501.03629", "title": "CFFormer: Cross CNN-Transformer Channel Attention and Spatial Feature Fusion for Improved Segmentation of Heterogeneous Medical Images", "authors": ["Jiaxuan Li", "Qing Xu", "Xiangjian He", "Ziyu Liu", "Daokun Zhang", "Ruili Wang", "Rong Qu", "Guoping Qiu"], "categories": ["cs.CV", "I.2; I.4; I.5"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.03629v2", "summary": "Medical image segmentation plays an important role in computer-aided\ndiagnosis. Existing methods mainly utilize spatial attention to highlight the\nregion of interest. However, due to limitations of medical imaging devices,\nmedical images exhibit significant heterogeneity, posing challenges for\nsegmentation. Ultrasound images, for instance, often suffer from speckle noise,\nlow resolution, and poor contrast between target tissues and background, which\nmay lead to inaccurate boundary delineation. To address these challenges caused\nby heterogeneous image quality, we propose a hybrid CNN-Transformer\nmodel,called CFFormer, which leverages effective channel feature extraction to\nenhance the model' s ability to accurately identify tissue regions by capturing\nrich contextual information. The proposed architecture contains two key\ncomponents: the Cross Feature Channel Attention (CFCA) module and the X-Spatial\nFeature Fusion (XFF) module. The model incorporates dual encoders, with the CNN\nencoder focusing on capturing local features and the Transformer encoder\nmodeling global features. The CFCA module filters and facilitates interactions\nbetween the channel features from the two encoders, while the XFF module\neffectively reduces the significant semantic information differences in spatial\nfeatures, enabling a smooth and cohesive spatial feature fusion. We evaluate\nour model across eight datasets covering five modalities to test its\ngeneralization capability. Experimental results demonstrate that our model\noutperforms current state-of-the-art methods and maintains accurate tissue\nregion segmentation across heterogeneous medical image datasets. The code is\navailable at https://github.com/JiaxuanFelix/CFFormer.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.03629v2", "cate": "cs.CV", "date": "2025-01-07", "updated": "2025-07-16", "AI": {"title_translation": "CFFormer：交叉CNN-Transformer通道注意力与空间特征融合，用于改进异构医学图像分割", "tldr": "CFFormer是一个混合CNN-Transformer模型，通过交叉通道注意力与空间特征融合，改善了异构医学图像的分割效果，超越了SOTA方法。", "motivation": "医学图像分割在计算机辅助诊断中扮演重要角色。现有方法主要利用空间注意力，但由于医疗成像设备的限制，医学图像表现出显著的异构性（例如超声图像中的斑点噪声、低分辨率和对比度差），导致分割边界不准确。", "method": "提出了一种混合CNN-Transformer模型，名为CFFormer。它利用有效的通道特征提取来增强模型准确识别组织区域的能力。该架构包含两个关键组件：交叉特征通道注意力（CFCA）模块和X-空间特征融合（XFF）模块。模型结合了双编码器，其中CNN编码器侧重于捕获局部特征，Transformer编码器建模全局特征。CFCA模块过滤并促进来自两个编码器的通道特征之间的交互，而XFF模块有效减少空间特征中显著的语义信息差异，实现平滑和内聚的空间特征融合。", "result": "在涵盖五种模态的八个数据集上进行了评估。实验结果表明，我们的模型优于当前最先进的方法，并在异构医学图像数据集上保持了准确的组织区域分割。", "conclusion": "CFFormer模型有效解决了异构医学图像质量带来的挑战，并在不同模态的医学图像数据集上实现了优越且鲁棒的组织区域分割性能。", "translation": "医学图像分割在计算机辅助诊断中扮演重要角色。现有方法主要利用空间注意力来突出感兴趣区域。然而，由于医疗成像设备的限制，医学图像表现出显著的异构性，给分割带来了挑战。例如，超声图像通常存在斑点噪声、低分辨率以及目标组织与背景之间对比度差的问题，这可能导致边界描绘不准确。为了解决异构图像质量带来的这些挑战，我们提出了一种混合CNN-Transformer模型，名为CFFormer，它利用有效的通道特征提取来增强模型通过捕获丰富的上下文信息来准确识别组织区域的能力。所提出的架构包含两个关键组件：交叉特征通道注意力（CFCA）模块和X-空间特征融合（XFF）模块。模型结合了双编码器，其中CNN编码器侧重于捕获局部特征，Transformer编码器建模全局特征。CFCA模块过滤并促进来自两个编码器的通道特征之间的交互，而XFF模块有效减少空间特征中显著的语义信息差异，实现平滑和内聚的空间特征融合。我们在涵盖五种模态的八个数据集上评估了我们的模型，以测试其泛化能力。实验结果表明，我们的模型优于当前最先进的方法，并在异构医学图像数据集上保持了准确的组织区域分割。代码可在https://github.com/JiaxuanFelix/CFFormer获取。", "summary": "CFFormer是一种新颖的混合CNN-Transformer模型，旨在改进异构医学图像的分割。它通过整合交叉特征通道注意力（CFCA）和X-空间特征融合（XFF）模块来解决噪声和低对比度等挑战。CFFormer利用双编码器（CNN用于局部特征，Transformer用于全局特征），增强了上下文信息的捕获，并促进了鲁棒的特征交互和融合。在涵盖五种模态的八个数据集上的评估表明，CFFormer超越了最先进的方法，实现了准确且泛化能力强的组织分割。", "keywords": "医学图像分割, CNN-Transformer, 通道注意力, 空间特征融合, 异构图像", "comments": "该论文提出了一种创新的混合CNN-Transformer架构CFFormer，有效解决了医学图像分割中异构性的关键挑战。结合新颖的交叉通道注意力和空间融合模块的双编码器方法，代表了在不同图像质量下鲁棒特征学习和集成方面的重大进展。其在多种模态上展示出的优越性能和泛化能力，凸显了其在实际临床应用中的潜力。"}}
{"id": "2503.22913", "title": "Resona: Improving Context Copying in Linear Recurrence Models with Retrieval", "authors": ["Xinyu Wang", "Linrui Ma", "Jerry Huang", "Peng Lu", "Prasanna Parthasarathi", "Xiao-Wen Chang", "Boxing Chen", "Yufei Cui"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Comments: Accepted at COLM 2025 (Conference on Learning with Machines)", "url": "http://arxiv.org/abs/2503.22913v2", "summary": "Recent shifts in the space of large language model (LLM) research have shown\nan increasing focus on novel architectures to compete with prototypical\nTransformer-based models that have long dominated this space. Linear recurrent\nmodels have proven to be a viable competitor due to their computational\nefficiency. However, such models still demonstrate a sizable gap compared to\nTransformers in terms of in-context learning among other tasks that require\nrecalling information from a context. In this work, we introduce Resona, a\nsimple and scalable framework for augmenting linear recurrent models with\nretrieval. Resona augments models with the ability to integrate retrieved\ninformation from the provided input context, enabling tailored behavior to\ndiverse task requirements. Experiments on a variety of linear recurrent models\ndemonstrate that Resona-augmented models observe significant performance gains\non a variety of synthetic as well as real-world natural language tasks,\nhighlighting its ability to act as a general purpose method to improve the\nin-context learning and language modeling abilities of linear recurrent LLMs.", "comment": "Comments: Accepted at COLM 2025 (Conference on Learning with\n  Machines)", "pdf_url": "http://arxiv.org/pdf/2503.22913v2", "cate": "cs.CL", "date": "2025-03-28", "updated": "2025-07-16", "AI": {"title_translation": "Resona：通过检索改进线性循环模型中的上下文复制", "tldr": "线性循环模型虽然高效，但在上下文学习方面不如Transformer模型。本文引入了Resona，通过检索增强线性循环模型，以改善其上下文复制能力。", "motivation": "大型语言模型领域中，线性循环模型因其计算效率成为Transformer的有力竞争者。然而，它们在上下文学习和从上下文中回忆信息方面与Transformer模型存在显著差距。", "method": "本文引入了Resona，一个简单且可扩展的框架，通过检索能力来增强线性循环模型。Resona使模型能够整合来自输入上下文的检索信息，以适应不同的任务需求。", "result": "在多种线性循环模型上进行的实验表明，Resona增强的模型在各种合成任务以及真实世界的自然语言任务上都取得了显著的性能提升。", "conclusion": "Resona作为一种通用方法，能够有效提高线性循环大型语言模型的上下文学习和语言建模能力。", "translation": "大型语言模型（LLM）研究领域的最新转变表明，人们越来越关注新颖的架构，以与长期主导该领域的原型Transformer模型竞争。线性循环模型因其计算效率而被证明是一个可行的竞争者。然而，与Transformer模型相比，此类模型在上下文学习以及其他需要从上下文中回忆信息的任务方面仍然存在相当大的差距。在这项工作中，我们引入了Resona，一个简单且可扩展的框架，用于通过检索增强线性循环模型。Resona使模型能够集成来自所提供输入上下文的检索信息，从而能够根据不同的任务要求进行定制行为。对各种线性循环模型的实验表明，Resona增强模型在各种合成任务以及真实世界的自然语言任务上都取得了显著的性能提升，突显了其作为一种通用方法来改进线性循环LLM的上下文学习和语言建模能力的作用。", "summary": "本研究介绍了Resona，一个用于增强线性循环语言模型（LLM）的框架，旨在解决其在上下文学习和信息回忆方面相对于Transformer模型的不足。尽管线性循环模型具有计算效率，但在需要从上下文中复制或回忆信息的任务上表现出明显差距。Resona通过引入检索机制来弥补这一差距，使模型能够集成来自输入上下文的检索信息。实验证明，Resona显著提升了多种线性循环模型在合成和真实世界自然语言任务上的性能，表明它是一种通用的方法，可以提高线性循环LLM的上下文学习和语言建模能力。", "keywords": "线性循环模型, 上下文复制, 检索, 大型语言模型, 上下文学习", "comments": "Resona通过引入检索机制，有效地弥补了线性循环模型在上下文学习方面的短板，同时保持了其计算效率的优势。这对于推动更高效、更强大的LLM架构具有重要意义，尤其是在资源受限的环境中。"}}
{"id": "2412.05737", "title": "Balancing Confidentiality and Transparency for Blockchain-based Process-Aware Information Systems", "authors": ["Alessandro Marcelletti", "Edoardo Marangone", "Michele Kryston", "Claudio Di Ciccio"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.05737v3", "summary": "Blockchain enables novel, trustworthy Process-Aware Information Systems\n(PAISs) by enforcing the security, robustness, and traceability of operations.\nIn particular, transparency ensures that all information exchanges are openly\naccessible, fostering trust within the system. Although this is a desirable\nproperty to enable notarization and auditing activities, it also represents a\nlimitation for such cases where confidentiality is a requirement since\ninteractions involve sensitive data. Current solutions rely on obfuscation\ntechniques or private infrastructures, hindering the enforcement capabilities\nof smart contracts and the public verifiability of transactions. Against this\nbackground, we propose CONFETTY, an architecture for blockchain-based PAISs to\npreserve confidentiality and transparency. Smart contracts enact, enforce and\nstore public interactions, while attribute-based encryption techniques are\nadopted to specify access grants to confidential information. We assess the\nsecurity of our solution through a systematic threat model analysis and\nevaluate its practical feasibility by gauging the performance of our\nimplemented prototype in different scenarios from the literature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.05737v3", "cate": "cs.CR", "date": "2024-12-07", "updated": "2025-07-16", "AI": {"title_translation": "区块链BPM系统中的保密性与透明性平衡", "tldr": "提出CONFETTY架构，平衡区块链流程信息系统中的数据保密性和透明性，解决现有方案的局限性。", "motivation": "区块链流程感知信息系统（PAISs）的透明性虽然有利于公证和审计，但在涉及敏感数据时，保密性成为必需。现有解决方案依赖混淆技术或私有基础设施，这限制了智能合约的执行能力和交易的公共可验证性。", "method": "本文提出CONFETTY架构，用于基于区块链的流程感知信息系统。该架构通过智能合约来执行、强制和存储公共交互，同时采用基于属性的加密技术来指定对机密信息的访问权限。", "result": "通过系统的威胁模型分析评估了解决方案的安全性，并通过衡量实现原型在不同场景下的性能，评估了其实用可行性。", "conclusion": "CONFETTY成功地在区块链流程感知信息系统（PAISs）中平衡了保密性和透明性，解决了现有方案的局限性，并提供了一个安全且可行的解决方案。", "translation": "区块链通过强制执行操作的安全性、鲁棒性和可追溯性，使得新型、可信的流程感知信息系统（PAISs）成为可能。特别是，透明性确保所有信息交换都是公开可访问的，从而增强了系统内的信任。尽管这是实现公证和审计活动的一个理想特性，但对于需要保密性的情况（因为交互涉及敏感数据）来说，它也代表了一种局限性。当前的解决方案依赖于混淆技术或私有基础设施，这阻碍了智能合约的执行能力和交易的公共可验证性。在此背景下，我们提出了CONFETTY，一种用于基于区块链的PAIS的架构，以维护保密性和透明性。智能合约执行、强制并存储公共交互，同时采用基于属性的加密技术来指定对机密信息的访问权限。我们通过系统威胁模型分析评估了我们解决方案的安全性，并通过衡量我们实现的原型在文献中不同场景下的性能来评估其实用可行性。", "summary": "本文提出CONFETTY架构，旨在解决区块链流程感知信息系统（PAISs）中保密性与透明性之间的矛盾。针对现有区块链透明性在处理敏感数据时的局限性以及现有解决方案的不足，CONFETTY通过智能合约处理公共交互，并利用属性基加密技术管理机密数据访问，从而在公共可验证性与数据隐私之间取得平衡。该方案通过威胁模型分析评估了安全性，并通过原型性能测试验证了实用性。", "keywords": "区块链, 流程感知信息系统, 保密性, 透明性, 属性基加密", "comments": "本文创新性地提出了一种在区块链PAISs中平衡保密性和透明性的架构CONFETTY，通过结合智能合约和属性基加密，解决了现有方案中公共可验证性和数据隐私之间的冲突。这对于需要处理敏感数据的区块链应用具有重要意义，尤其是在企业级或法规遵从性要求较高的场景中。"}}
{"id": "2507.12445", "title": "CRAFT: Latency and Cost-Aware Genetic-Based Framework for Node Placement in Edge-Fog Environments", "authors": ["Soheil Mahdizadeh", "Amir Mahdi Rasouli", "Mohammad Pourashory", "Sadra Galavani", "Mohsen Ansari"], "categories": ["cs.NI", "cs.AR", "cs.DC"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12445v1", "summary": "Reducing latency in the Internet of Things (IoT) is a critical concern. While\ncloud computing facilitates communication, it falls short of meeting real-time\nrequirements reliably. Edge and fog computing have emerged as viable solutions\nby positioning computing nodes closer to end users, offering lower latency and\nincreased processing power. An edge-fog framework comprises various components,\nincluding edge and fog nodes, whose strategic placement is crucial as it\ndirectly impacts latency and system cost. This paper presents an effective and\ntunable node placement strategy based on a genetic algorithm to address the\noptimization problem of deploying edge and fog nodes. The main objective is to\nminimize latency and cost through optimal node placement. Simulation results\ndemonstrate that the proposed framework achieves up to 2.77% latency and 31.15%\ncost reduction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12445v1", "cate": "cs.NI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "CRAFT：边缘-雾计算环境中基于遗传算法的延迟和成本感知节点部署框架", "tldr": "CRAFT是一个基于遗传算法的框架，用于优化边缘-雾计算环境中的节点部署，以降低物联网应用的延迟和成本。", "motivation": "物联网（IoT）中降低延迟是一个关键问题。云计算难以满足实时需求，而边缘和雾计算通过将计算节点部署到更靠近用户的位置来提供更低的延迟和更高的处理能力。边缘和雾节点的位置部署至关重要，因为它直接影响延迟和系统成本。", "method": "本文提出了一种基于遗传算法的有效且可调的节点部署策略，以解决边缘和雾节点部署的优化问题。主要目标是通过最优节点部署来最小化延迟和成本。", "result": "仿真结果表明，所提出的框架实现了高达2.77%的延迟降低和31.15%的成本降低。", "conclusion": "所提出的基于遗传算法的CRAFT框架能够有效地优化边缘-雾计算环境中的节点部署，显著降低物联网应用的延迟和成本。", "translation": "降低物联网（IoT）中的延迟是一个关键问题。虽然云计算促进了通信，但它未能可靠地满足实时要求。边缘和雾计算通过将计算节点放置在更靠近最终用户的位置，提供了更低的延迟和更高的处理能力，从而成为可行的解决方案。边缘-雾框架包含各种组件，包括边缘和雾节点，其战略性部署至关重要，因为它直接影响延迟和系统成本。本文提出了一种基于遗传算法的有效且可调的节点部署策略，以解决部署边缘和雾节点的优化问题。主要目标是通过最优节点部署来最小化延迟和成本。仿真结果表明，所提出的框架实现了高达2.77%的延迟和31.15%的成本降低。", "summary": "本文提出了CRAFT，一个基于遗传算法的框架，用于解决边缘-雾计算环境中的节点部署优化问题。该框架旨在通过战略性节点部署来最小化物联网应用的延迟和系统成本。仿真结果表明，CRAFT能够显著降低延迟（高达2.77%）和成本（高达31.15%）。", "keywords": "边缘-雾计算, 节点部署, 遗传算法, 延迟优化, 成本降低", "comments": "该论文的创新点在于将遗传算法应用于复杂的边缘-雾节点部署优化问题，这对于提升物联网应用的实时性能和降低运营成本具有重要意义。该方法提供了一个可调的策略，有望在实际部署中带来显著的效益。"}}
{"id": "2507.11726", "title": "A Deep Reinforcement Learning Method for Multi-objective Transmission Switching", "authors": ["Ding Lin", "Jianhui Wang", "Tianqiao Zhao", "Meng Yue"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      5 pages", "url": "http://arxiv.org/abs/2507.11726v1", "summary": "Transmission switching is a well-established approach primarily applied to\nminimize operational costs through strategic network reconfiguration. However,\nexclusive focus on cost reduction can compromise system reliability. While\nmulti-objective transmission switching can balance cost savings with\nreliability improvements, feasible solutions become exceedingly difficult to\nobtain as system scale grows, due to the inherent nonlinearity and high\ncomputational demands involved. This paper proposes a deep reinforcement\nlearning (DRL) method for multi-objective transmission switching. The method\nincorporates a dueling-based actor-critic framework to evaluate the relative\nimpact of each line switching decision within the action space, which improves\ndecision quality and enhances both system reliability and cost efficiency.\nNumerical studies on the IEEE 118-bus system verify the effectiveness and\nefficiency of the proposed approach compared to two benchmark DRL algorithms.", "comment": "5 pages", "pdf_url": "http://arxiv.org/pdf/2507.11726v1", "cate": "eess.SY", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "多目标输电开关的深度强化学习方法", "tldr": "本文提出了一种基于深度强化学习（DRL）的多目标输电开关方法，通过决斗式Actor-Critic框架在平衡成本和可靠性的同时，提高决策质量。在IEEE 118-bus系统上的数值研究验证了其有效性和效率。", "motivation": "传统的输电开关主要关注降低运营成本，但这会牺牲系统可靠性。虽然多目标输电开关可以兼顾成本和可靠性，但由于固有的非线性和高计算需求，在大规模系统中难以获得可行解。", "method": "本文提出了一种用于多目标输电开关的深度强化学习（DRL）方法。该方法融合了基于决斗的Actor-Critic框架，以评估动作空间中每个线路开关决策的相对影响。", "result": "在IEEE 118-bus系统上的数值研究验证了所提出的方法与两种基准DRL算法相比具有有效性和效率，提高了决策质量并增强了系统可靠性和成本效率。", "conclusion": "所提出的深度强化学习方法能够有效提高多目标输电开关的决策质量，并同时提升系统可靠性和成本效率。", "translation": "输电开关是一种行之有效的方法，主要通过战略性网络重构来最小化运营成本。然而，仅仅关注成本降低可能会损害系统可靠性。虽然多目标输电开关可以在节约成本和提高可靠性之间取得平衡，但由于固有的非线性和高计算需求，随着系统规模的增长，获得可行的解决方案变得异常困难。本文提出了一种用于多目标输电开关的深度强化学习（DRL）方法。该方法结合了一个基于决斗的Actor-Critic框架，以评估动作空间中每个线路开关决策的相对影响，从而提高决策质量并提高系统可靠性和成本效率。在IEEE 118-bus系统上的数值研究验证了所提出方法与两种基准DRL算法相比的有效性和效率。", "summary": "本文提出了一种基于深度强化学习（DRL）的多目标输电开关方法，旨在解决传统方法中成本与可靠性之间的权衡难题，以及大规模系统下解决方案获取困难的问题。该方法采用基于决斗的Actor-Critic框架，优化线路开关决策以同时提高系统可靠性和成本效率。在IEEE 118-bus系统上的数值研究验证了该方法相较于基准DRL算法的有效性和高效性。", "keywords": "深度强化学习, 多目标优化, 输电开关, 电力系统可靠性, Actor-Critic", "comments": "该论文通过将深度强化学习应用于多目标输电开关，解决了电力系统中成本优化与可靠性保障之间的关键矛盾，具有重要的实践意义。其创新点在于采用了基于决斗的Actor-Critic框架来优化决策质量，有效平衡了多个目标。在标准IEEE总线系统上的验证进一步表明了其潜在的应用价值。"}}
{"id": "2506.08677", "title": "MAMBO: High-Resolution Generative Approach for Mammography Images", "authors": ["Milica Škipina", "Nikola Jovišić", "Nicola Dall'Asen", "Vanja Švenda", "Anil Osman Tur", "Slobodan Ilić", "Elisa Ricci", "Dubravko Ćulibrk"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      21 pages, 14 figures, 7 tables This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2506.08677v2", "summary": "Mammography is the gold standard for the detection and diagnosis of breast\ncancer. This procedure can be significantly enhanced with Artificial\nIntelligence (AI)-based software, which assists radiologists in identifying\nabnormalities. However, training AI systems requires large and diverse\ndatasets, which are often difficult to obtain due to privacy and ethical\nconstraints. To address this issue, the paper introduces MAMmography ensemBle\nmOdel (MAMBO), a novel patch-based diffusion approach designed to generate\nfull-resolution mammograms. Diffusion models have shown breakthrough results in\nrealistic image generation, yet few studies have focused on mammograms, and\nnone have successfully generated high-resolution outputs required to capture\nfine-grained features of small lesions. To achieve this, MAMBO integrates\nseparate diffusion models to capture both local and global (image-level)\ncontexts. The contextual information is then fed into the final model,\nsignificantly aiding the noise removal process. This design enables MAMBO to\ngenerate highly realistic mammograms of up to 3840x3840 pixels. Importantly,\nthis approach can be used to enhance the training of classification models and\nextended to anomaly segmentation. Experiments, both numerical and radiologist\nvalidation, assess MAMBO's capabilities in image generation, super-resolution,\nand anomaly segmentation, highlighting its potential to enhance mammography\nanalysis for more accurate diagnoses and earlier lesion detection. The source\ncode used in this study is publicly available at:\nhttps://github.com/iai-rs/mambo.", "comment": "21 pages, 14 figures, 7 tables This work has been submitted to the\n  IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2506.08677v2", "cate": "eess.IV", "date": "2025-06-10", "updated": "2025-07-16", "AI": {"title_translation": "MAMBO：乳腺X线图像的高分辨率生成方法", "tldr": "MAMBO是一种新颖的基于补丁的扩散模型，能够生成高分辨率乳腺X线图像，以解决AI训练数据稀缺的问题，并有望提升乳腺癌诊断准确性。", "motivation": "由于隐私和伦理限制，用于训练AI系统识别乳腺X线图像异常的大型多样化数据集难以获取。现有的扩散模型在乳腺X线图像生成方面研究较少，且未能成功生成捕获细微病灶特征所需的高分辨率图像。", "method": "本文引入了MAMBO（MAMmography ensemBle mOdel），一种新颖的基于补丁的扩散方法，用于生成全分辨率乳腺X线图像。MAMBO通过整合独立的扩散模型来捕获局部和全局（图像级别）上下文信息，并将这些上下文信息输入到最终模型中，从而显著帮助去噪过程，生成高达3840x3840像素的逼真乳腺X线图像。", "result": "MAMBO能够生成高达3840x3840像素的高分辨率逼真乳腺X线图像。该方法可用于增强分类模型的训练，并可扩展到异常分割。通过数值实验和放射科医生验证，MAMBO在图像生成、超分辨率和异常分割方面展现了其能力。", "conclusion": "MAMBO通过生成高分辨率的乳腺X线图像，有望增强乳腺X线分析，实现更准确的诊断和更早期的病灶检测，从而克服了AI训练数据稀缺的挑战。", "translation": "乳腺X线照相术是检测和诊断乳腺癌的黄金标准。人工智能（AI）软件可以显著增强这一程序，协助放射科医生识别异常。然而，训练AI系统需要大量多样化的数据集，由于隐私和伦理限制，这些数据集通常难以获取。为了解决这个问题，本文介绍了一种名为MAMmography ensemBle mOdel (MAMBO) 的新型基于补丁的扩散方法，旨在生成全分辨率乳腺X线图像。扩散模型在逼真图像生成方面取得了突破性成果，但很少有研究关注乳腺X线图像，也没有成功生成捕获小病灶细微特征所需的高分辨率输出。为实现这一点，MAMBO整合了独立的扩散模型，以捕获局部和全局（图像级别）上下文。然后将上下文信息输入到最终模型中，显著帮助去噪过程。这种设计使MAMBO能够生成高达3840x3840像素的高度逼真的乳腺X线图像。重要的是，这种方法可用于增强分类模型的训练，并可扩展到异常分割。通过数值和放射科医生验证的实验评估了MAMBO在图像生成、超分辨率和异常分割方面的能力，突出了其增强乳腺X线分析以实现更准确诊断和更早期病灶检测的潜力。本研究中使用的源代码可在以下网址公开获取：https://github.com/iai-rs/mambo。", "summary": "MAMBO是一种高分辨率的生成方法，旨在解决乳腺X线图像AI训练数据稀缺的问题。该模型采用新颖的基于补丁的扩散方法，通过整合局部和全局上下文信息，能够生成高达3840x3840像素的逼真乳腺X线图像。MAMBO在图像生成、超分辨率和异常分割方面表现出色，有望提升乳腺癌诊断的准确性和早期病灶检测能力。", "keywords": "乳腺X线图像, 扩散模型, 高分辨率, 图像生成, 人工智能辅助诊断", "comments": "MAMBO的创新之处在于其结合了基于补丁和全局上下文的扩散模型，成功实现了高分辨率医学图像（乳腺X线图像）的生成，克服了现有扩散模型在该领域的分辨率限制。这对于解决医学AI领域数据隐私和伦理导致的训练数据稀缺问题具有重要意义，其生成的数据可用于增强诊断模型的训练，具有巨大的应用潜力。"}}
{"id": "2501.16605", "title": "The Impact of Modern AI in Metadata Management", "authors": ["Wenli Yang", "Rui Fu", "Muhammad Bilal Amin", "Byeong Kang"], "categories": ["cs.DB", "cs.AI"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.16605v2", "summary": "Metadata management plays a critical role in data governance, resource\ndiscovery, and decision-making in the data-driven era. While traditional\nmetadata approaches have primarily focused on organization, classification, and\nresource reuse, the integration of modern artificial intelligence (AI)\ntechnologies has significantly transformed these processes. This paper\ninvestigates both traditional and AI-driven metadata approaches by examining\nopen-source solutions, commercial tools, and research initiatives. A\ncomparative analysis of traditional and AI-driven metadata management methods\nis provided, highlighting existing challenges and their impact on\nnext-generation datasets. The paper also presents an innovative AI-assisted\nmetadata management framework designed to address these challenges. This\nframework leverages more advanced modern AI technologies to automate metadata\ngeneration, enhance governance, and improve the accessibility and usability of\nmodern datasets. Finally, the paper outlines future directions for research and\ndevelopment, proposing opportunities to further advance metadata management in\nthe context of AI-driven innovation and complex datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.16605v2", "cate": "cs.DB", "date": "2025-01-28", "updated": "2025-07-16", "AI": {"title_translation": "现代AI在元数据管理中的影响", "tldr": "本文探讨了现代AI如何变革元数据管理，比较了传统与AI驱动方法，并提出了一个创新的AI辅助元数据管理框架，以应对挑战并提升数据治理。", "motivation": "传统元数据管理方法已无法满足数据驱动时代的需求，现代AI技术的整合显著改变了这些过程，但仍存在挑战。本研究旨在探讨AI对元数据管理的影响，并提出解决方案以应对现有挑战，提升下一代数据集的治理和可用性。", "method": "本文通过考察开源解决方案、商业工具和研究项目，调查了传统和AI驱动的元数据方法。提供了传统与AI驱动元数据管理方法的比较分析，并提出了一个创新的AI辅助元数据管理框架，该框架利用先进的AI技术实现元数据自动化生成、增强治理并提高数据集的可访问性和可用性。", "result": "本文揭示了传统和AI驱动元数据管理方法中的现有挑战及其对下一代数据集的影响。提出了一个创新的AI辅助元数据管理框架，该框架能够自动化元数据生成，增强数据治理，并提高现代数据集的可访问性和可用性。", "conclusion": "文章概述了未来元数据管理在AI驱动创新和复杂数据集背景下的研究和发展方向，提出了进一步推进元数据管理的机会。", "translation": "在数据驱动的时代，元数据管理在数据治理、资源发现和决策制定中发挥着关键作用。传统元数据方法主要侧重于组织、分类和资源重用，而现代人工智能（AI）技术的整合已显著改变了这些过程。本文通过考察开源解决方案、商业工具和研究项目，调查了传统和AI驱动的元数据方法。文章对传统和AI驱动的元数据管理方法进行了比较分析，强调了现有挑战及其对下一代数据集的影响。本文还提出了一个创新的AI辅助元数据管理框架，旨在应对这些挑战。该框架利用更先进的现代AI技术自动化元数据生成、增强治理，并提高现代数据集的可访问性和可用性。最后，文章概述了未来研究和发展方向，提出了在AI驱动创新和复杂数据集背景下进一步推进元数据管理的机会。", "summary": "本文探讨了现代AI对元数据管理的关键影响，比较了传统与AI驱动的方法。文章指出，尽管AI带来了显著变革，但仍面临挑战。为此，本文提出了一个创新的AI辅助元数据管理框架，旨在通过自动化生成、强化治理和提升可用性来应对这些挑战。最后，论文展望了AI驱动下元数据管理的未来发展方向。", "keywords": "元数据管理, 人工智能, 数据治理, AI辅助框架, 数据集", "comments": "本文创新性地提出了一个AI辅助元数据管理框架，旨在解决当前元数据管理面临的挑战。其重要性在于强调了现代AI在自动化、治理和提升数据可用性方面的潜力，为未来复杂数据集的元数据管理提供了新的思路和方向。"}}
{"id": "2306.04473", "title": "Fast adaptive high-order integral equation methods for electromagnetic scattering from smooth perfect electric conductors", "authors": ["Felipe Vico", "Leslie Greengard", "Michael O'Neil", "Manas Rachh"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.04473v2", "summary": "Many integral equation-based methods are available for problems of\ntime-harmonic electromagnetic scattering from perfect electric conductors.\nAmong the many challenges that arise in such calculations are the avoidance of\nspurious resonances, robustness of the method to scatterers of non-trivial\ntopology or multiscale features, stability under mesh refinement, ease of\nimplementation with high-order basis functions, and behavior in the static\nlimit. Since three-dimensional scattering is a challenging, large-scale\nproblem, many of these issues have been historically difficult to investigate.\nIt is only with the advent of fast algorithms for matrix-vector multiplies\ncoupled with modern iterative methods that a careful study of these issues can\nbe carried out effectively. Our focus here is on comparing the behavior of\nseveral integral equation formulations with regard to the issues noted above,\nnamely: the well-known, standard electric, magnetic, and combined field\nintegral equations with standard RWG basis functions, and the more modern\nnon-resonant charge-current and decoupled potential integral equation.\nNumerical results are provided to demonstrate the behavior of each of these\nschemes. Furthermore, we provide some analytical properties and comparisons\nwith the electric charge-current integral equation and the augmented\nregularized combined source integral equation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.04473v2", "cate": "math.NA", "date": "2023-06-07", "updated": "2025-07-16", "AI": {"title_translation": "快速自适应高阶积分方程方法用于光滑理想导体的电磁散射", "tldr": "本文比较了几种积分方程公式在解决电磁散射问题中的行为，包括标准和现代方法，并提供了数值和分析结果。", "motivation": "电磁散射计算中存在诸多挑战，如虚假谐振、拓扑鲁棒性、网格细化稳定性、高阶基函数实现难度和静态极限行为等。由于三维散射是大规模问题，这些问题在历史上难以有效研究。", "method": "本文通过比较多种积分方程公式（包括标准电场、磁场、组合场积分方程与RWG基函数，以及现代非谐振电荷-电流和解耦势积分方程）的行为来解决上述问题。研究借助快速算法和现代迭代方法进行。", "result": "提供了数值结果以展示每种方案的行为。此外，还提供了电荷-电流积分方程和增广正则化组合源积分方程的一些分析特性和比较。", "conclusion": "本文通过数值和分析方法，详细比较了不同积分方程公式在解决电磁散射问题中的表现，为理解和选择适合的积分方程方法提供了依据。", "translation": "针对理想导体的时谐电磁散射问题，有许多基于积分方程的方法可用。此类计算中出现的诸多挑战包括：避免虚假谐振、方法对非平凡拓扑或多尺度散射体的鲁棒性、网格细化下的稳定性、高阶基函数实现的便捷性以及静态极限行为。由于三维散射是一个具有挑战性的大规模问题，其中许多问题在历史上难以研究。只有随着矩阵-向量乘法的快速算法与现代迭代方法的出现，才能有效地对这些问题进行仔细研究。本文的重点是比较几种积分方程公式在上述问题方面的行为，即：众所周知的标准电场、磁场和组合场积分方程与标准RWG基函数，以及更现代的非谐振电荷-电流和解耦势积分方程。提供了数值结果以展示每种方案的行为。此外，我们还提供了一些分析特性，并与电荷-电流积分方程和增广正则化组合源积分方程进行了比较。", "summary": "本文研究了用于理想导体电磁散射问题的多种积分方程方法，旨在解决虚假谐振、鲁棒性、稳定性等挑战。通过比较标准电场、磁场、组合场积分方程以及非谐振电荷-电流和解耦势积分方程的行为，并利用快速算法和迭代方法，论文提供了数值结果和分析特性，以评估这些方法的性能。", "keywords": "电磁散射, 积分方程, 快速算法, 高阶方法, 理想导体", "comments": "这篇论文的重要性在于它系统地比较了多种积分方程方法在处理电磁散射问题时的关键特性，特别是在大规模三维问题背景下。它关注了方法在实际应用中可能遇到的挑战，如稳定性、鲁棒性和高阶实现，这对于实际工程应用具有指导意义。通过结合快速算法和现代迭代方法，该研究能够深入探讨这些复杂问题，并为读者选择合适的数值方法提供了宝贵的见解。"}}
{"id": "2401.11212", "title": "Programming Distributed Collective Processes in the eXchange Calculus", "authors": ["Giorgio Audrito", "Roberto Casadei", "Ferruccio Damiani", "Gianluca Torta", "Mirko Viroli"], "categories": ["cs.DC", "cs.AI", "cs.MA", "cs.PL", "D.1.3; F.1.1; F.4.3; I.2.11; J.7"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      41 pages, 17 figures", "url": "http://arxiv.org/abs/2401.11212v5", "summary": "Recent trends like the Internet of Things (IoT) suggest a vision of dense and\nmulti-scale deployments of computing devices in nearly all kinds of\nenvironments. A prominent engineering challenge revolves around programming the\ncollective adaptive behaviour of such computational ecosystems. This requires\nabstractions able to capture concepts like ensembles (dynamic groups of\ncooperating devices) and collective tasks (joint activities carried out by\nensembles). In this work, we consider collections of devices interacting with\nneighbours and that execute in nearly-synchronised sense-compute-interact\nrounds, where the computation is given by a single program mapping sensing\nvalues and incoming messages to output and outcoming messages. To support\nprogramming whole computational collectives, we propose the abstraction of a\ndistributed collective process, which can be used to define at once the\nensemble formation logic and its collective task. We formalise the abstraction\nin the eXchange Calculus (XC), a core functional language based on neighbouring\nvalues (maps from neighbours to values) where state and interaction is handled\nthrough a single primitive, exchange, and provide a corresponding\nimplementation in the FCPP language. Then, we exercise distributed collective\nprocesses using two case studies: multi-hop message propagation and distributed\nmonitoring of spatial properties. Finally, we discuss the features of the\nabstraction and its suitability for different kinds of distributed computing\napplications.", "comment": "41 pages, 17 figures", "pdf_url": "http://arxiv.org/pdf/2401.11212v5", "cate": "cs.DC", "date": "2024-01-20", "updated": "2025-07-16", "AI": {"title_translation": "在eXchange演算中编程分布式集体过程", "tldr": "本文提出了一种分布式集体过程的抽象，用于解决物联网等密集部署中计算设备集体自适应行为的编程挑战，并在eXchange演算中进行了形式化和FCPP语言的实现，通过案例研究展示了其适用性。", "motivation": "物联网等新兴趋势预示着计算设备在各种环境中密集且多尺度部署的愿景。一个突出的工程挑战是如何编程这些计算生态系统的集体自适应行为，这需要能够捕获集合（合作设备的动态群组）和集体任务（集合执行的联合活动）等概念的抽象。", "method": "本文提出了一种分布式集体过程的抽象，可用于同时定义集合形成逻辑及其集体任务。该抽象在eXchange演算（XC）中进行形式化，XC是一种基于邻居值（从邻居到值的映射）的核心函数式语言，其中状态和交互通过单一原语“exchange”处理。同时，在FCPP语言中提供了相应的实现。", "result": "通过两个案例研究（多跳消息传播和空间属性的分布式监测）对分布式集体过程进行了实践。", "conclusion": "文中讨论了所提出抽象的特性及其对不同类型分布式计算应用的适用性。", "translation": "物联网（IoT）等最新趋势预示着计算设备在几乎所有环境中密集且多尺度部署的愿景。一个突出的工程挑战围绕着如何编程此类计算生态系统的集体自适应行为。这需要能够捕获集合（合作设备的动态群组）和集体任务（集合执行的联合活动）等概念的抽象。在这项工作中，我们考虑了与邻居交互并以近乎同步的感知-计算-交互循环执行的设备集合，其中计算由一个将感知值和传入消息映射到输出和传出消息的单一程序给出。为了支持整个计算集合的编程，我们提出了分布式集体过程的抽象，它可用于一次性定义集合形成逻辑及其集体任务。我们在eXchange演算（XC）中形式化了该抽象，XC是一种基于邻居值（从邻居到值的映射）的核心函数式语言，其中状态和交互通过单一原语“exchange”处理，并提供了FCPP语言中的相应实现。然后，我们通过两个案例研究：多跳消息传播和空间属性的分布式监测，实践了分布式集体过程。最后，我们讨论了该抽象的特性及其对不同类型分布式计算应用的适用性。", "summary": "本文针对物联网等密集部署中计算设备的集体自适应行为编程挑战，提出了一种名为“分布式集体过程”的抽象。该抽象旨在同时定义设备集合的形成逻辑及其集体任务。研究人员在eXchange演算（XC）中对该抽象进行了形式化，并使用FCPP语言提供了实现。通过多跳消息传播和空间属性分布式监测两个案例研究，验证了该抽象的有效性，并讨论了其在各种分布式计算应用中的适用性。", "keywords": "物联网, 分布式系统, 集体过程, eXchange演算, 抽象", "comments": "本文提出了一种新颖的分布式集体过程抽象，以应对物联网等新兴领域中大规模、多尺度设备部署的复杂编程挑战。其创新之处在于将集合形成逻辑和集体任务统一在一个抽象中，并通过eXchange演算这一函数式语言进行严格形式化，为编程分布式自适应系统提供了坚实的基础。通过案例研究展示了其潜力，但抽象的实际工程复杂性和性能开销可能需要进一步深入评估。"}}
{"id": "2507.12155", "title": "Lowering Error Floors for Hard Decision Decoding of OFEC Code", "authors": ["Jasper Lagendijk", "Yunus Can Gültekin", "Alexios Balatsoukas-Stimming", "Gabriele Liga", "Alex Alvarado"], "categories": ["cs.IT", "math.IT", "94-06"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      4 pages, 4 figures; accepted to SC4 of ECOC 2025", "url": "http://arxiv.org/abs/2507.12155v1", "summary": "Stall patterns are known to cause an error floor in hard decision decoding of\nthe OFEC code. We propose a novel stall pattern removal algorithm that lowers\nthe error floor of state-of-the-art algorithms by an order of magnitude", "comment": "4 pages, 4 figures; accepted to SC4 of ECOC 2025", "pdf_url": "http://arxiv.org/pdf/2507.12155v1", "cate": "cs.IT", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "降低OFEC码硬判决译码的错误平台", "tldr": "提出了一种新的停滞模式消除算法，可显著降低OFEC码硬判决译码的错误平台。", "motivation": "停滞模式会导致OFEC码硬判决译码中出现错误平台。", "method": "提出了一种新颖的停滞模式消除算法。", "result": "该算法将现有最先进算法的错误平台降低了一个数量级。", "conclusion": "该新算法能有效降低OFEC码硬判决译码的错误平台，显著优于现有技术。", "translation": "已知停滞模式会导致OFEC码硬判决译码中出现错误平台。我们提出了一种新颖的停滞模式消除算法，该算法将现有最先进算法的错误平台降低了一个数量级。", "summary": "该论文提出了一种新颖的停滞模式消除算法，旨在解决OFEC码硬判决译码中由停滞模式导致的错误平台问题。实验结果表明，该算法能将现有最先进算法的错误平台降低一个数量级，显著提升了OFEC码的译码性能。", "keywords": "OFEC码, 硬判决译码, 错误平台, 停滞模式, 错误消除", "comments": "该论文的创新点在于提出了一种有效消除停滞模式的新算法，成功解决了OFEC码硬判决译码中的错误平台问题。其重要性在于显著提升了OFEC码的译码性能，对通信和数据存储等领域具有潜在的应用价值。论文明确指出了其方法在降低错误平台方面的量化优势，但未提及算法的复杂度或具体实现细节。"}}
{"id": "2507.11069", "title": "TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update", "authors": ["Jeongyun Kim", "Seunghoon Jeong", "Giseop Kim", "Myung-Hwan Jeon", "Eunji Jun", "Ayoung Kim"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11069v2", "summary": "Understanding the 3D geometry of transparent objects from RGB images is\nchallenging due to their inherent physical properties, such as reflection and\nrefraction. To address these difficulties, especially in scenarios with sparse\nviews and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian\nSplatting-based depth reconstruction method for transparent objects. Our key\ninsight lies in separating transparent objects from the background, enabling\nfocused optimization of Gaussians corresponding to the object. We mitigate\nartifacts with an object-aware loss that places Gaussians in obscured regions,\nensuring coverage of invisible surfaces while reducing overfitting.\nFurthermore, we incorporate a physics-based simulation that refines the\nreconstruction in just a few seconds, effectively handling object removal and\nchain-reaction movement of remaining objects without the need for rescanning.\nTRAN-D is evaluated on both synthetic and real-world sequences, and it\nconsistently demonstrated robust improvements over existing GS-based\nstate-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean\nabsolute error by over 39% for the synthetic TRansPose sequences. Furthermore,\ndespite being updated using only one image, TRAN-D reaches a {\\delta} < 2.5 cm\naccuracy of 48.46%, over 1.5 times that of baselines, which uses six images.\nCode and more results are available at https://jeongyun0609.github.io/TRAN-D/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11069v2", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "TRAN-D：基于2D高斯泼溅的稀疏视角透明物体深度重建，通过物理模拟实现场景更新", "tldr": "TRAN-D是一种基于2D高斯泼溅的新型方法，用于在稀疏视角和动态环境中重建透明物体的深度，通过分离物体、引入物体感知损失和物理模拟，显著提高了重建精度和场景更新能力。", "motivation": "由于透明物体固有的物理特性（如反射和折射），从RGB图像理解其3D几何结构具有挑战性，尤其是在稀疏视角和动态环境中。", "method": "本文引入了TRAN-D，一种基于2D高斯泼溅的透明物体深度重建方法。其核心思想是将透明物体与背景分离，从而对与物体对应的高斯进行聚焦优化。通过引入物体感知损失来减轻伪影，确保覆盖不可见表面并减少过拟合。此外，该方法还结合了基于物理的模拟，可在几秒钟内完善重建，有效处理物体移除和剩余物体的链式反应移动，无需重新扫描。", "result": "TRAN-D在合成和真实世界序列上均表现出比现有基于GS的最新方法更强大的改进。与基线相比，TRAN-D在合成TRansPose序列上的平均绝对误差降低了39%以上。此外，尽管仅使用一张图像进行更新，TRAN-D仍能达到48.46%的准确度（误差小于2.5厘米），是使用六张图像的基线的1.5倍以上。", "conclusion": "TRAN-D在稀疏视角和动态环境下，通过结合2D高斯泼溅、物体分离、物体感知损失和物理模拟，显著提高了透明物体深度重建的精度，并有效支持场景的快速更新。", "translation": "从RGB图像理解透明物体的3D几何结构由于其固有的物理特性（如反射和折射）而具有挑战性。为了解决这些困难，特别是在稀疏视角和动态环境的场景中，我们引入了TRAN-D，一种基于2D高斯泼溅的新型透明物体深度重建方法。我们的关键见解在于将透明物体与背景分离，从而能够对与物体对应的高斯进行聚焦优化。我们通过引入物体感知损失来减轻伪影，该损失将高斯放置在被遮挡区域，确保覆盖不可见表面同时减少过拟合。此外，我们还结合了基于物理的模拟，可在几秒钟内完善重建，有效处理物体移除和剩余物体的链式反应移动，无需重新扫描。TRAN-D在合成和真实世界序列上均进行了评估，并且始终表现出比现有基于GS的最新方法更强大的改进。与基线相比，TRAN-D在合成TRansPose序列上的平均绝对误差降低了39%以上。此外，尽管仅使用一张图像进行更新，TRAN-D仍能达到48.46%的准确度（误差小于2.5厘米），是使用六张图像的基线的1.5倍以上。代码和更多结果可在https://jeongyun0609.github.io/TRAN-D/获取。", "summary": "TRAN-D是一种针对稀疏视角和动态环境下透明物体深度重建的新方法，它利用2D高斯泼溅技术，并通过将透明物体与背景分离、引入物体感知损失来优化高斯分布，从而解决透明物体固有的反射和折射难题。该方法还集成了一个物理模拟模块，能够快速更新场景，处理物体移除和连锁反应，无需重新扫描。实验结果表明，TRAN-D在精度上显著优于现有SOTA方法，在合成数据集上MAE降低超过39%，并且在仅使用一张图像更新的情况下，其准确度是使用六张图像的基线的1.5倍以上。", "keywords": "透明物体, 深度重建, 高斯泼溅, 物理模拟, 稀疏视角", "comments": "TRAN-D的创新点在于其针对透明物体深度重建的独特策略，特别是在稀疏视角和动态环境下的应用。通过将透明物体与背景分离，并引入物体感知损失，它有效地解决了高斯泼溅在处理透明物体时可能出现的伪影和过拟合问题。更重要的是，引入物理模拟来快速更新场景，无需重新扫描，这对于实时或近实时应用具有重要意义，极大地提升了实用性。"}}
{"id": "2507.12217", "title": "Towards few-shot isolated word reading assessment", "authors": ["Reuben Smit", "Retief Louw", "Herman Kamper"], "categories": ["cs.CL", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to SLaTE 2025", "url": "http://arxiv.org/abs/2507.12217v1", "summary": "We explore an ASR-free method for isolated word reading assessment in\nlow-resource settings. Our few-shot approach compares input child speech to a\nsmall set of adult-provided reference templates. Inputs and templates are\nencoded using intermediate layers from large self-supervised learned (SSL)\nmodels. Using an Afrikaans child speech benchmark, we investigate design\noptions such as discretising SSL features and barycentre averaging of the\ntemplates. Idealised experiments show reasonable performance for adults, but a\nsubstantial drop for child speech input, even with child templates. Despite the\nsuccess of employing SSL representations in low-resource speech tasks, our work\nhighlights the limitations of SSL representations for processing child data\nwhen used in a few-shot classification system.", "comment": "Accepted to SLaTE 2025", "pdf_url": "http://arxiv.org/pdf/2507.12217v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "迈向少样本孤立词阅读评估", "tldr": "本文探索了一种在低资源环境下进行孤立词阅读评估的无ASR少样本方法，该方法利用自监督学习（SSL）模型，但发现其在处理儿童语音时存在局限性。", "motivation": "在低资源环境下探索一种无需自动语音识别（ASR）的孤立词阅读评估方法。", "method": "采用无ASR的少样本方法，将输入的儿童语音与少量成人提供的参考模板进行比较。输入和模板使用大型自监督学习（SSL）模型的中间层进行编码。研究了SSL特征离散化和模板重心平均等设计选项，并使用南非荷兰语儿童语音基准进行评估。", "result": "理想化实验表明，该方法对成人语音表现出合理的性能，但对于儿童语音输入，即使使用儿童模板，性能也大幅下降。", "conclusion": "尽管自监督学习（SSL）表示在低资源语音任务中取得了成功，但本研究强调了在少样本分类系统中使用SSL表示处理儿童数据时的局限性。", "translation": "我们探索了一种在低资源环境下进行孤立词阅读评估的无ASR方法。我们的少样本方法将输入的儿童语音与少量成人提供的参考模板进行比较。输入和模板使用大型自监督学习（SSL）模型的中间层进行编码。我们使用一个南非荷兰语儿童语音基准，研究了设计选项，例如SSL特征的离散化和模板的重心平均。理想化实验表明，对成人表现出合理的性能，但对于儿童语音输入，即使使用儿童模板，性能也大幅下降。尽管在低资源语音任务中采用SSL表示取得了成功，但我们的工作强调了在少样本分类系统中使用SSL表示处理儿童数据时的局限性。", "summary": "本文提出了一种在低资源环境下进行孤立词阅读评估的无ASR少样本方法。该方法利用大型自监督学习（SSL）模型的中间层来编码儿童语音输入和成人提供的参考模板。尽管对成人语音表现出合理性能，但实验结果显示，该方法在处理儿童语音时性能显著下降，凸显了当前SSL表示在少样本分类系统中处理儿童数据时的局限性。", "keywords": "少样本学习, 孤立词阅读评估, 低资源语音, 自监督学习, 儿童语音", "comments": "该论文解决了低资源环境下，特别是针对儿童的阅读评估这一重要问题。其创新点在于探索了使用自监督学习（SSL）特征的无ASR少样本方法。关键贡献在于明确指出了SSL表示在应用于儿童语音时，在此类少样本情境下的特定局限性，这对未来儿童语音处理研究至关重要。"}}
{"id": "2410.08355", "title": "Metalic: Meta-Learning In-Context with Protein Language Models", "authors": ["Jacob Beck", "Shikha Surana", "Manus McAuliffe", "Oliver Bent", "Thomas D. Barrett", "Juan Jose Garau Luis", "Paul Duckworth"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published at The Thirteenth International Conference on Learning Representations (ICLR 2025). Code is provided at this https URL . Also relevant to searches for \"metallic\", \"meta-learning in-context\", \"LLM\", and \"protein language model\"", "url": "http://arxiv.org/abs/2410.08355v3", "summary": "Predicting the biophysical and functional properties of proteins is essential\nfor in silico protein design. Machine learning has emerged as a promising\ntechnique for such prediction tasks. However, the relative scarcity of in vitro\nannotations means that these models often have little, or no, specific data on\nthe desired fitness prediction task. As a result of limited data, protein\nlanguage models (PLMs) are typically trained on general protein sequence\nmodeling tasks, and then fine-tuned, or applied zero-shot, to protein fitness\nprediction. When no task data is available, the models make strong assumptions\nabout the correlation between the protein sequence likelihood and fitness\nscores. In contrast, we propose meta-learning over a distribution of standard\nfitness prediction tasks, and demonstrate positive transfer to unseen fitness\nprediction tasks. Our method, called Metalic (Meta-Learning In-Context), uses\nin-context learning and fine-tuning, when data is available, to adapt to new\ntasks. Crucially, fine-tuning enables considerable generalization, even though\nit is not accounted for during meta-training. Our fine-tuned models achieve\nstrong results with 18 times fewer parameters than state-of-the-art models.\nMoreover, our method sets a new state-of-the-art in low-data settings on\nProteinGym, an established fitness-prediction benchmark. Due to data scarcity,\nwe believe meta-learning will play a pivotal role in advancing protein\nengineering.", "comment": "Published at The Thirteenth International Conference on Learning\n  Representations (ICLR 2025). Code is provided at\n  https://github.com/instadeepai/metalic. Also relevant to searches for\n  \"metallic\", \"meta-learning in-context\", \"LLM\", and \"protein language model\"", "pdf_url": "http://arxiv.org/pdf/2410.08355v3", "cate": "cs.LG", "date": "2024-10-10", "updated": "2025-07-15", "AI": {"title_translation": "Metalic：使用蛋白质语言模型进行情境元学习", "tldr": "提出Metalic，一种元学习方法，通过情境学习和微调来预测蛋白质特性，即使数据稀缺也能在低数据设置下取得SOTA结果，参数量更少。", "motivation": "蛋白质特性预测对蛋白质设计至关重要，但体外注释数据稀缺，导致现有机器学习模型（包括蛋白质语言模型PLMs）在特定预测任务上数据不足，需要进行微调或零样本应用，并且在无任务数据时会做出强假设。", "method": "提出Metalic（情境元学习），该方法通过对标准适应度预测任务的分布进行元学习，并在有数据时利用情境学习和微调来适应新任务。即使在元训练期间未考虑微调，微调也能实现显著泛化。", "result": "我们的微调模型以比最先进模型少18倍的参数获得了优异结果。此外，我们的方法在ProteinGym（一个成熟的适应度预测基准）的低数据设置中创造了新的最先进水平。", "conclusion": "由于数据稀缺，元学习将在推动蛋白质工程方面发挥关键作用。", "translation": "预测蛋白质的生物物理和功能特性对于计算机蛋白质设计至关重要。机器学习已成为此类预测任务的一种有前途的技术。然而，体外注释的相对稀缺意味着这些模型通常在所需的适应度预测任务上拥有很少或根本没有特定数据。由于数据有限，蛋白质语言模型（PLM）通常在通用蛋白质序列建模任务上进行训练，然后进行微调或零样本应用于蛋白质适应度预测。当没有任务数据可用时，模型会对蛋白质序列可能性和适应度分数之间的相关性做出强假设。相比之下，我们提出对标准适应度预测任务的分布进行元学习，并证明了对未见过的适应度预测任务的正向迁移。我们的方法，称为Metalic（情境元学习），在有数据可用时使用情境学习和微调来适应新任务。至关重要的是，微调实现了相当大的泛化，即使在元训练期间没有考虑到这一点。我们的微调模型以比最先进模型少18倍的参数获得了优异结果。此外，我们的方法在ProteinGym（一个成熟的适应度预测基准）的低数据设置中创造了新的最先进水平。由于数据稀缺，我们相信元学习将在推动蛋白质工程方面发挥关键作用。", "summary": "这篇论文提出了一种名为Metalic的元学习方法，旨在解决蛋白质生物物理和功能特性预测中数据稀缺的问题。Metalic通过对一系列蛋白质适应度预测任务进行元学习，并结合情境学习和微调来适应新任务。该方法在低数据环境下表现出色，不仅以更少的参数量（比SOTA模型少18倍）达到强劲性能，还在ProteinGym基准上刷新了低数据设置下的最佳记录，表明元学习对于蛋白质工程的未来发展至关重要。", "keywords": "元学习, 蛋白质语言模型, 蛋白质工程, 低数据设置, 情境学习", "comments": "这篇论文的创新点在于将元学习应用于蛋白质特性预测领域，有效解决了该领域数据稀缺的挑战。通过结合情境学习和微调，该方法不仅提高了模型在低数据设置下的泛化能力，还在保持高性能的同时显著减少了模型参数量，这对于实际应用具有重要意义。在蛋白质工程领域，数据获取成本高昂，Metalic的提出为更高效、更经济的蛋白质设计提供了新的途径。"}}
{"id": "2507.06607", "title": "Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation", "authors": ["Liliang Ren", "Congcong Chen", "Haoran Xu", "Young Jin Kim", "Adam Atkinson", "Zheng Zhan", "Jiankai Sun", "Baolin Peng", "Liyuan Liu", "Shuohang Wang", "Hao Cheng", "Jianfeng Gao", "Weizhu Chen", "Yelong Shen"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06607v2", "summary": "Recent advances in language modeling have demonstrated the effectiveness of\nState Space Models (SSMs) for efficient sequence modeling. While hybrid\narchitectures such as Samba and the decoder-decoder architecture, YOCO, have\nshown promising performance gains over Transformers, prior works have not\ninvestigated the efficiency potential of representation sharing between SSM\nlayers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet\neffective mechanism for efficient memory sharing across layers. We apply it to\ncreate SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in\nthe cross-decoder to share memory readout states from a Samba-based\nself-decoder. SambaY significantly enhances decoding efficiency, preserves\nlinear pre-filling time complexity, and boosts long-context performance, all\nwhile eliminating the need for explicit positional encoding. Through extensive\nscaling experiments, we demonstrate that our model exhibits a significantly\nlower irreducible loss compared to a strong YOCO baseline, indicating superior\nperformance scalability under large-scale compute regimes. Our largest model\nenhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves\nsignificantly better performance than Phi4-mini-Reasoning on reasoning tasks\nsuch as Math500, AIME24/25, and GPQA Diamond without any reinforcement\nlearning, while delivering up to 10x higher decoding throughput on 2K-length\nprompts with 32K generation length under the vLLM inference framework. We\nrelease our training codebase on open-source data at\nhttps://github.com/microsoft/ArchScale.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06607v2", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-16", "AI": {"title_translation": "用于长生成高效推理的解码器-混合-解码器架构", "tldr": "本文提出了一种名为SambaY的解码器-混合-解码器架构，通过引入门控记忆单元（GMU）实现层间记忆共享，显著提高了长文本生成的解码效率和性能，尤其在推理任务上表现出色。", "motivation": "尽管混合架构在序列建模中表现出潜力，但现有工作尚未探索SSM层间表示共享的效率潜力。", "method": "本文引入了门控记忆单元（GMU），这是一种用于高效层间记忆共享的机制。将GMU应用于创建SambaY，这是一种解码器-混合-解码器架构，它在交叉解码器中整合GMU，以共享基于Samba的自解码器的记忆读取状态。该模型还结合了差分注意力（Differential Attention）。", "result": "SambaY显著提高了解码效率，保持了线性预填充时间复杂度，并提升了长上下文性能，同时无需显式位置编码。与强大的YOCO基线相比，模型表现出显著更低的不可约损失，表明在大型计算方案下具有卓越的性能可扩展性。最大的模型Phi4-mini-Flash-Reasoning在推理任务（如Math500、AIME24/25和GPQA Diamond）上表现显著优于Phi4-mini-Reasoning，且在2K长度提示和32K生成长度下，解码吞吐量提高了10倍。", "conclusion": "通过引入GMU并构建SambaY架构，本研究成功实现了SSM层间的高效记忆共享，从而显著提升了长生成场景下的解码效率和推理性能，并展示了其在大规模计算下的优越可扩展性。", "translation": "近年来，语言建模的进展已证明状态空间模型（SSM）在高效序列建模方面的有效性。尽管Samba和解码器-解码器架构YOCO等混合架构已显示出优于Transformer的良好性能增益，但现有工作尚未研究SSM层之间表示共享的效率潜力。在本文中，我们引入了门控记忆单元（GMU），这是一种简单而有效的层间高效记忆共享机制。我们将其应用于创建SambaY，这是一种解码器-混合-解码器架构，它在交叉解码器中整合GMU，以共享基于Samba的自解码器的记忆读取状态。SambaY显著提高了解码效率，保持了线性预填充时间复杂度，并提升了长上下文性能，所有这些都无需显式位置编码。通过广泛的扩展实验，我们证明了我们的模型与强大的YOCO基线相比，表现出显著更低的不可约损失，表明在大型计算方案下具有卓越的性能可扩展性。我们最大的模型，增强了差分注意力（Differential Attention）的Phi4-mini-Flash-Reasoning，在推理任务（如Math500、AIME24/25和GPQA Diamond）上表现显著优于Phi4-mini-Reasoning，且无需任何强化学习，同时在vLLM推理框架下，对于2K长度提示和32K生成长度，解码吞吐量提高了高达10倍。我们在https://github.com/microsoft/ArchScale上发布了开源数据的训练代码库。", "summary": "本文提出了一种名为SambaY的解码器-混合-解码器架构，旨在通过引入门控记忆单元（GMU）来解决状态空间模型（SSM）层间表示共享的效率问题。GMU实现了层间记忆的高效共享，SambaY将GMU整合到交叉解码器中，以共享Samba自解码器的记忆读取状态。实验结果表明，SambaY显著提高了长文本生成的解码效率、保持了线性预填充时间复杂度并提升了长上下文性能，同时无需位置编码。与现有基线相比，它在推理任务上展现出更低的损失和优越的性能可扩展性，并在长生成场景下实现了高达10倍的解码吞吐量提升。", "keywords": "解码器-混合-解码器, 状态空间模型, 记忆共享, 长生成, 推理效率", "comments": "本文的创新点在于提出了门控记忆单元（GMU）以实现SSM层间的高效记忆共享，并将其应用于构建SambaY架构。这种方法有效地解决了长生成任务中的效率瓶颈，尤其在推理任务中表现出色，且无需显式位置编码，这简化了模型设计。显著的解码吞吐量提升和性能可扩展性表明其在大型语言模型推理部署中的重要潜力。"}}
{"id": "2507.11852", "title": "Towards Autonomous Riding: A Review of Perception, Planning, and Control in Intelligent Two-Wheelers", "authors": ["Mohammed Hassanin", "Mohammad Abu Alsheikh", "Carlos C. N. Kuhn", "Damith Herath", "Dinh Thai Hoang", "Ibrahim Radwan"], "categories": ["cs.RO", "cs.CV", "93C85", "F.2.2; I.2.7"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2507.11852v1", "summary": "The rapid adoption of micromobility solutions, particularly two-wheeled\nvehicles like e-scooters and e-bikes, has created an urgent need for reliable\nautonomous riding (AR) technologies. While autonomous driving (AD) systems have\nmatured significantly, AR presents unique challenges due to the inherent\ninstability of two-wheeled platforms, limited size, limited power, and\nunpredictable environments, which pose very serious concerns about road users'\nsafety. This review provides a comprehensive analysis of AR systems by\nsystematically examining their core components, perception, planning, and\ncontrol, through the lens of AD technologies. We identify critical gaps in\ncurrent AR research, including a lack of comprehensive perception systems for\nvarious AR tasks, limited industry and government support for such\ndevelopments, and insufficient attention from the research community. The\nreview analyses the gaps of AR from the perspective of AD to highlight\npromising research directions, such as multimodal sensor techniques for\nlightweight platforms and edge deep learning architectures. By synthesising\ninsights from AD research with the specific requirements of AR, this review\naims to accelerate the development of safe, efficient, and scalable autonomous\nriding systems for future urban mobility.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2507.11852v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "迈向自动驾驶：智能两轮车感知、规划与控制综述", "tldr": "该综述分析了两轮车自动驾驶（AR）系统的感知、规划和控制核心组件，并与自动驾驶（AD）技术进行对比，指出了当前AR研究的不足之处，并提出了未来的研究方向，旨在加速安全、高效AR系统的发展。", "motivation": "随着微出行解决方案（特别是两轮电动车）的迅速普及，对可靠的自动驾驶（AR）技术产生了迫切需求。尽管自动驾驶（AD）系统已日趋成熟，但两轮车的固有不稳定性、尺寸限制、功率限制和不可预测的环境为AR带来了独特的挑战，对道路使用者的安全构成严重威胁。", "method": "本综述通过自动驾驶（AD）技术的视角，系统地审视了两轮车自动驾驶（AR）系统的核心组成部分——感知、规划和控制，从而对AR系统进行了全面分析。", "result": "本综述识别了当前AR研究中的关键空白，包括：缺乏针对各种AR任务的综合感知系统；行业和政府对此类发展的支持有限；以及研究界对此关注不足。本综述从AD的角度分析了AR的不足，以突出有前景的研究方向，例如轻量级平台的多模态传感器技术和边缘深度学习架构。", "conclusion": "本综述旨在通过综合自动驾驶（AD）研究的见解与自动驾驶（AR）的特定要求，加速未来城市出行中安全、高效、可扩展的自动驾驶系统的发展。", "translation": "微出行解决方案，特别是电动滑板车和电动自行车等两轮车的迅速普及，对可靠的自动驾驶（AR）技术产生了迫切需求。尽管自动驾驶（AD）系统已日趋成熟，但两轮车的固有不稳定性、尺寸限制、功率限制和不可预测的环境为AR带来了独特的挑战，对道路使用者的安全构成非常严重的问题。本综述通过自动驾驶（AD）技术的视角，系统地审视了AR系统的核心组成部分——感知、规划和控制，从而对AR系统进行了全面分析。我们识别了当前AR研究中的关键空白，包括：缺乏针对各种AR任务的综合感知系统；行业和政府对此类发展的支持有限；以及研究界对此关注不足。本综述从AD的角度分析了AR的不足，以突出有前景的研究方向，例如轻量级平台的多模态传感器技术和边缘深度学习架构。通过综合AD研究的见解与AR的特定要求，本综述旨在加速未来城市出行中安全、高效、可扩展的自动驾驶系统的发展。", "summary": "本综述旨在解决两轮车自动驾驶（AR）技术在微出行领域日益增长的需求，尽管自动驾驶（AD）系统已成熟，但AR面临着两轮车固有的不稳定性和资源限制等独特挑战。该研究全面分析了AR系统的感知、规划和控制核心组件，并将其与AD技术进行对比。综述识别了当前AR研究中的关键空白，包括感知系统不完善、行业支持不足以及研究关注度不够。它还从AD的角度探讨了AR的不足，并提出了多模态传感器和边缘深度学习等有前景的研究方向。最终目标是结合AD的经验和AR的特定需求，加速安全、高效、可扩展的自动驾驶系统在未来城市出行中的发展。", "keywords": "自动驾驶, 两轮车, 感知, 规划, 控制, 综述", "comments": "这篇综述的重要性在于它系统地填补了自动驾驶（AD）和两轮车自动驾驶（AR）研究之间的空白。它不仅清晰地指出了当前AR研究的局限性，例如感知系统和行业支持的不足，还通过借鉴AD的成熟经验，为AR的未来发展提供了具体且有前景的方向，例如多模态传感器和边缘深度学习。这对于推动两轮车自动驾驶技术的发展，提升城市微出行的安全性和效率具有重要意义。"}}
{"id": "2304.12063", "title": "Risk in Stochastic and Robust Model Predictive Path-Following Control for Vehicular Motion Planning", "authors": ["Leon Tolksdorf", "Arturo Tejada", "Nathan van de Wouw", "Christian Birkner"], "categories": ["math.OC", "cs.RO"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      Accepted for the 2023 Intelligent Vehicles Symposium, 8 pages", "url": "http://arxiv.org/abs/2304.12063v1", "summary": "In automated driving, risk describes potential harm to passengers of an\nautonomous vehicle (AV) and other road users. Recent studies suggest that\nhuman-like driving behavior emerges from embedding risk in AV motion planning\nalgorithms. Additionally, providing evidence that risk is minimized during the\nAV operation is essential to vehicle safety certification. However, there has\nyet to be a consensus on how to define and operationalize risk in motion\nplanning or how to bound or minimize it during operation. In this paper, we\ndefine a stochastic risk measure and introduce it as a constraint into both\nrobust and stochastic nonlinear model predictive path-following controllers\n(RMPC and SMPC respectively). We compare the vehicle's behavior arising from\nemploying SMPC and RMPC with respect to safety and path-following performance.\nFurther, the implementation of an automated driving example is provided,\nshowcasing the effects of different risk tolerances and uncertainty growths in\npredictions of other road users for both cases. We find that the RMPC is\nsignificantly more conservative than the SMPC, while also displaying greater\nfollowing errors towards references. Further, the RMPCs behavior cannot be\nconsidered as human-like. Moreover, unlike SMPC, the RMPC cannot account for\ndifferent risk tolerances. The RMPC generates undesired driving behavior for\neven moderate uncertainties, which are handled better by the SMPC.", "comment": "Accepted for the 2023 Intelligent Vehicles Symposium, 8 pages", "pdf_url": "http://arxiv.org/pdf/2304.12063v1", "cate": "math.OC", "date": "2023-04-24", "updated": "2023-04-24", "AI": {"title_translation": "车辆运动规划中随机和鲁棒模型预测路径跟踪控制的风险", "tldr": "本文定义了一种随机风险度量，并将其引入随机和鲁棒模型预测路径跟踪控制器。研究发现鲁棒MPC比随机MPC更保守，路径跟踪误差更大，且无法实现类人行为或适应不同风险容忍度。", "motivation": "在自动驾驶中，风险描述了对自动驾驶车辆（AV）乘客和其他道路使用者的潜在伤害。近期研究表明类人驾驶行为源于将风险嵌入运动规划算法中。此外，证明自动驾驶车辆操作期间风险最小化对于车辆安全认证至关重要。然而，目前对于如何在运动规划中定义和操作化风险，以及如何限制或最小化风险尚未达成共识。", "method": "本文定义了一种随机风险度量，并将其作为约束引入到鲁棒和随机非线性模型预测路径跟踪控制器（分别为RMPC和SMPC）中。通过比较SMPC和RMPC在安全性和路径跟踪性能方面的车辆行为，并提供了自动驾驶示例的实现，展示了不同风险容忍度和对其他道路使用者预测不确定性增长对两种情况的影响。", "result": "研究发现RMPC比SMPC显著更保守，同时对参考的跟踪误差更大。RMPC的行为不能被认为是类人行为。此外，与SMPC不同，RMPC无法考虑不同的风险容忍度。即使面对中等不确定性，RMPC也会产生不期望的驾驶行为，而SMPC能更好地处理这些情况。", "conclusion": "随机模型预测路径跟踪控制器（SMPC）在处理不确定性和适应不同风险容忍度方面优于鲁棒模型预测路径跟踪控制器（RMPC），并且SMPC能够更好地实现类人驾驶行为。RMPC过于保守且不灵活，不适合自动驾驶中的风险管理。", "translation": "在自动驾驶中，风险描述了对自动驾驶车辆（AV）乘客和其他道路使用者的潜在伤害。最近的研究表明，类人驾驶行为源于将风险嵌入到自动驾驶车辆的运动规划算法中。此外，提供自动驾驶车辆操作期间风险最小化的证据对于车辆安全认证至关重要。然而，关于如何在运动规划中定义和操作化风险，以及如何在操作过程中限制或最小化风险，尚未达成共识。在本文中，我们定义了一种随机风险度量，并将其作为约束引入到鲁棒和随机非线性模型预测路径跟踪控制器（分别为RMPC和SMPC）中。我们比较了SMPC和RMPC在安全性和路径跟踪性能方面的车辆行为。此外，还提供了自动驾驶示例的实现，展示了不同风险容忍度和对其他道路使用者预测不确定性增长对两种情况的影响。我们发现RMPC比SMPC显著更保守，同时对参考的跟踪误差更大。此外，RMPC的行为不能被认为是类人行为。而且，与SMPC不同，RMPC无法考虑不同的风险容忍度。即使面对中等不确定性，RMPC也会产生不期望的驾驶行为，而SMPC能更好地处理这些情况。", "summary": "本文针对自动驾驶中风险定义和管理缺乏共识的问题，提出了一种新的随机风险度量，并将其整合到随机和鲁棒模型预测路径跟踪控制器（SMPC和RMPC）中。通过比较发现，SMPC在处理不确定性、实现类人驾驶行为以及适应不同风险容忍度方面明显优于RMPC，后者表现出过度保守且跟踪误差大的问题。", "keywords": "风险度量, 模型预测控制, 路径跟踪, 自动驾驶, 车辆运动规划", "comments": "本文创新性地将随机风险度量引入模型预测控制，并明确对比了随机与鲁棒方法在自动驾驶风险管理中的优劣。其重要性在于为自动驾驶车辆的安全认证和类人行为建模提供了新的视角和实证支持，指出了鲁棒控制在处理复杂不确定性和风险容忍度方面的局限性。"}}
{"id": "2507.11681", "title": "Finite Pinwheel Scheduling: the k-Visits Problem", "authors": ["Sotiris Kanellopoulos", "Christos Pergaminelis", "Maria Kokkou", "Euripides Markou", "Aris Pagourtzis"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11681v1", "summary": "Pinwheel Scheduling is a fundamental scheduling problem, in which each task\n$i$ is associated with a positive integer $d_i$, and the objective is to\nschedule one task per time slot, ensuring each task perpetually appears at\nleast once in every $d_i$ time slots. Although conjectured to be\nPSPACE-complete, it remains open whether Pinwheel Scheduling is NP-hard (unless\na compact input encoding is used) or even contained in NP.\n  We introduce k-Visits, a finite version of Pinwheel Scheduling, where given n\ndeadlines, the goal is to schedule each task exactly k times. While we observe\nthat the 1-Visit problem is trivial, we prove that 2-Visits is strongly\nNP-complete through a surprising reduction from Numerical 3-Dimensional\nMatching (N3DM). As intermediate steps in the reduction, we define NP-complete\nvariants of N3DM which may be of independent interest. We further extend our\nstrong NP-hardness result to a generalization of k-Visits $k\\geq 2$ in which\nthe deadline of each task may vary throughout the schedule, as well as to a\nsimilar generalization of Pinwheel Scheduling, thus making progress towards\nsettling the complexity of Pinwheel Scheduling.\n  Additionally, we prove that 2-Visits can be solved in linear time if all\ndeadlines are distinct, rendering it one of the rare natural problems which\nexhibit the interesting dichotomy of being in P if their input is a set and\nNP-complete if the input is a multiset. We achieve this through a Turing\nreduction from 2-Visits to a variation of N3DM, which we call Position\nMatching. Based on this reduction, we also show an FPT algorithm for 2-Visits\nparameterized by a value related to how close the input deadlines are to each\nother, as well as a linear-time algorithm for instances with up to two distinct\ndeadlines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11681v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "有限风车调度：k-访问问题", "tldr": "本文引入了风车调度的有限版本k-访问问题，证明了2-访问问题是强NP完全的，但在所有截止日期都不同时可以在线性时间内解决，并提出了相关算法，为解决风车调度的复杂性问题取得了进展。", "motivation": "风车调度是一个基本的调度问题，其NP难性（除非使用紧凑输入编码）和是否包含在NP中仍然是未解决的问题。本文旨在通过引入其有限版本k-访问问题来推进风车调度复杂性的研究。", "method": "本文引入了风车调度的有限版本k-访问问题，其中目标是精确调度每个任务k次。通过从数值三维匹配（N3DM）进行归约，证明了2-访问问题是强NP完全的。此外，通过图灵归约将2-访问问题转化为位置匹配（N3DM的变体），证明了在所有截止日期都不同时，2-访问问题可以在线性时间内解决。还提出了一个FPT算法和针对具有最多两个不同截止日期的实例的线性时间算法。", "result": "1. 1-访问问题是微不足道的。\n2. 2-访问问题是强NP完全的，通过从数值三维匹配（N3DM）进行归约证明。\n3. 这种强NP硬度结果扩展到k-访问（k≥2）的泛化版本，其中每个任务的截止日期可能在整个调度过程中变化，以及风车调度的类似泛化。\n4. 如果所有截止日期都不同，2-访问问题可以在线性时间内解决。\n5. 提出了一个2-访问问题的FPT算法，其参数与输入截止日期彼此接近程度相关。\n6. 提出了一个针对具有最多两个不同截止日期的实例的线性时间算法。", "conclusion": "本文通过引入有限风车调度（k-访问问题）并深入分析其复杂性，特别是证明了2-访问问题的强NP完全性以及在特定条件下的线性时间可解性，为解决风车调度的复杂性问题取得了显著进展。研究揭示了输入是集合（所有截止日期不同）时问题在P中，而输入是多重集时问题是NP完全的这种有趣的二分法。", "translation": "风车调度是一个基本的调度问题，其中每个任务$i$都与一个正整数$d_i$相关联，目标是每时间段调度一个任务，确保每个任务在每$d_i$个时间段内至少永久出现一次。尽管被推测为PSPACE完全，但风车调度是否是NP难（除非使用紧凑输入编码）或甚至包含在NP中仍然是未解决的问题。\n我们引入了k-访问，风车调度的有限版本，其中给定n个截止日期，目标是精确调度每个任务k次。虽然我们观察到1-访问问题是微不足道的，但我们通过从数值三维匹配（N3DM）进行令人惊讶的归约，证明了2-访问问题是强NP完全的。作为归约的中间步骤，我们定义了可能具有独立兴趣的N3DM的NP完全变体。我们将我们的强NP硬度结果进一步扩展到k-访问$k\text{≥}2$的泛化版本，其中每个任务的截止日期可能在整个调度过程中变化，以及风车调度的类似泛化，从而在解决风车调度的复杂性方面取得了进展。\n此外，我们证明了如果所有截止日期都不同，2-访问问题可以在线性时间内解决，使其成为少数展现出有趣二分法（如果输入是集合则在P中，如果输入是多重集则NP完全）的自然问题之一。我们通过从2-访问到N3DM的变体（我们称之为位置匹配）的图灵归约实现了这一点。基于此归约，我们还展示了2-访问的FPT算法，其参数与输入截止日期彼此接近的程度相关，以及针对具有最多两个不同截止日期的实例的线性时间算法。", "summary": "本文引入了风车调度的有限版本——k-访问问题，旨在解决风车调度复杂性分析中的未决问题。研究发现1-访问问题是平凡的，但通过巧妙地归约到数值三维匹配（N3DM），证明了2-访问问题是强NP完全的。这一NP难性结果进一步推广到k-访问（k≥2）及风车调度的某些泛化形式。值得注意的是，如果所有截止日期都互不相同，2-访问问题可以在线性时间内解决，这揭示了该问题在输入为集合和多重集时表现出的P与NP完全之间的有趣二分法。此外，文章还提出了一个参数化算法（FPT）和一个针对特定简单情况（最多两个不同截止日期）的线性时间算法。", "keywords": "风车调度, k-访问问题, NP完全性, 调度算法, 计算复杂性", "comments": "这篇论文通过引入风车调度的有限版本k-访问问题，为解决长期悬而未决的风车调度复杂性问题迈出了重要一步。其创新之处在于通过从N3DM的巧妙归约证明了2-访问问题的强NP完全性，同时又揭示了在特定条件下（所有截止日期不同）问题可以在线性时间内解决的有趣二分法，这在理论计算机科学中是相当罕见且重要的发现。这种对问题边界条件的细致分析，不仅加深了对调度问题复杂性的理解，也为未来算法设计提供了宝贵的洞察。通过定义N3DM的NP完全变体，也可能激发了其他领域的研究兴趣。"}}
{"id": "2507.11939", "title": "POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering", "authors": ["Yichen Xu", "Liangyu Chen", "Liang Zhang", "Wenxuan Wang", "Qin Jin"], "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Work in Progress", "url": "http://arxiv.org/abs/2507.11939v1", "summary": "Charts are a universally adopted medium for interpreting and communicating\ndata. However, existing chart understanding benchmarks are predominantly\nEnglish-centric, limiting their accessibility and applicability to global\naudiences. In this paper, we present PolyChartQA, the first large-scale\nmultilingual chart question answering benchmark covering 22,606 charts and\n26,151 question-answering pairs across 10 diverse languages. PolyChartQA is\nbuilt using a decoupled pipeline that separates chart data from rendering code,\nallowing multilingual charts to be flexibly generated by simply translating the\ndata and reusing the code. We leverage state-of-the-art LLM-based translation\nand enforce rigorous quality control in the pipeline to ensure the linguistic\nand semantic consistency of the generated multilingual charts. PolyChartQA\nfacilitates systematic evaluation of multilingual chart understanding.\nExperiments on both open- and closed-source large vision-language models reveal\na significant performance gap between English and other languages, especially\nlow-resource ones with non-Latin scripts. This benchmark lays a foundation for\nadvancing globally inclusive vision-language models.", "comment": "Work in Progress", "pdf_url": "http://arxiv.org/pdf/2507.11939v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "POLYCHARTQA：基准测试多语言图表问答中的大型视觉-语言模型", "tldr": "现有图表理解基准以英语为主，限制了全球适用性。本文提出了PolyChartQA，首个大规模多语言图表问答基准，涵盖10种语言，揭示了大型视觉-语言模型在非英语，尤其是低资源语言上的显著性能差距。", "motivation": "现有图表理解基准主要以英语为中心，限制了其对全球用户的可访问性和适用性。", "method": "本文提出了PolyChartQA，一个大规模多语言图表问答基准，包含22,606张图表和26,151个问答对，涵盖10种不同的语言。该基准通过解耦管道构建，将图表数据与渲染代码分离，从而能够通过简单地翻译数据和重用代码来灵活生成多语言图表。研究人员利用最先进的基于LLM的翻译技术，并在管道中实施严格的质量控制，以确保生成的多语言图表的语言和语义一致性。", "result": "对开源和闭源大型视觉-语言模型进行的实验表明，英语与其他语言之间存在显著的性能差距，特别是在非拉丁文字的低资源语言上。", "conclusion": "PolyChartQA基准为推进全球包容性的视觉-语言模型奠定了基础。", "translation": "图表是解释和交流数据的普遍采用媒介。然而，现有的图表理解基准主要以英语为中心，限制了它们对全球受众的可访问性和适用性。在本文中，我们提出了PolyChartQA，这是第一个大规模多语言图表问答基准，涵盖22,606张图表和26,151个问答对，涉及10种不同的语言。PolyChartQA是使用解耦管道构建的，该管道将图表数据与渲染代码分离，通过简单地翻译数据和重用代码，可以灵活地生成多语言图表。我们利用最先进的基于LLM的翻译，并在管道中实施严格的质量控制，以确保生成的多语言图表的语言和语义一致性。PolyChartQA有助于对多语言图表理解进行系统评估。对开源和闭源大型视觉-语言模型的实验揭示了英语和其他语言之间存在显著的性能差距，特别是对于非拉丁文字的低资源语言。该基准为推进全球包容性的视觉-语言模型奠定了基础。", "summary": "本文介绍了PolyChartQA，一个大规模多语言图表问答基准，旨在解决现有图表理解基准的英语中心化问题。该基准包含22,606张图表和26,151个问答对，覆盖10种语言，通过解耦数据与代码的管道以及LLM翻译和质量控制构建。实验表明，大型视觉-语言模型在处理非英语，特别是低资源语言的图表问答时，性能远低于英语。PolyChartQA为开发更具全球包容性的视觉-语言模型提供了基础。", "keywords": "多语言图表问答, 视觉-语言模型, 基准测试, PolyChartQA, 跨语言理解", "comments": "PolyChartQA的创新之处在于其首次构建了大规模多语言图表问答基准，解决了现有基准的语言局限性。其解耦数据与代码的生成管道以及对LLM翻译和质量控制的运用，保证了基准的灵活性和高质量。该工作的重要性在于揭示了当前大型视觉-语言模型在多语言图表理解方面的显著差距，特别是对低资源语言的挑战，为未来研究指明了方向，有助于推动全球范围内AI的包容性发展。"}}
{"id": "2501.15151", "title": "SpikeDet: Better Firing Patterns for Accurate and Energy-Efficient Object Detection with Spiking Neuron Networks", "authors": ["Yimeng Fan", "Changsong Liu", "Mingyang Li", "Dongze Liu", "Yanyan Liu", "Wei Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.15151v3", "summary": "Spiking Neural Networks (SNNs) are the third generation of neural networks.\nThey have gained widespread attention in object detection due to their low\npower consumption and biological interpretability. However, existing SNN-based\nobject detection methods suffer from local firing saturation, where neurons in\ninformation-concentrated regions fire continuously throughout all time steps.\nThis abnormal neuron firing pattern reduces the feature discrimination\ncapability and detection accuracy, while also increasing the firing rates that\nprevent SNNs from achieving their potential energy efficiency. To address this\nproblem, we propose SpikeDet, a novel spiking object detector that optimizes\nfiring patterns for accurate and energy-efficient detection. Specifically, we\ndesign a spiking backbone network, MDSNet, which effectively adjusts the\nmembrane synaptic input distribution at each layer, achieving better neuron\nfiring patterns during spiking feature extraction. Additionally, to better\nutilize and preserve these high-quality backbone features, we introduce the\nSpiking Multi-direction Fusion Module (SMFM), which realizes multi-direction\nfusion of spiking features, enhancing the multi-scale detection capability of\nthe model. Experimental results demonstrate that SpikeDet achieves superior\nperformance. On the COCO 2017 dataset, it achieves 51.4% AP, outperforming\nprevious SNN-based methods by 2.5% AP while requiring only half the power\nconsumption. On object detection sub-tasks, including the GEN1 event-based\ndataset and the URPC 2019 underwater dataset, SpikeDet also achieves the best\nperformance. Notably, on GEN1, our method achieves 47.6% AP, outperforming\nprevious SNN-based methods by 7.2% AP with better energy efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.15151v3", "cate": "cs.CV", "date": "2025-01-25", "updated": "2025-07-16", "AI": {"title_translation": "SpikeDet：利用脉冲神经网络实现更优的脉冲模式以实现准确和节能的目标检测", "tldr": "SpikeDet是一种新型脉冲目标检测器，通过优化脉冲模式解决了现有脉冲神经网络在目标检测中存在的局部脉冲饱和问题，显著提高了检测精度并降低了能耗。", "motivation": "现有基于脉冲神经网络（SNNs）的目标检测方法存在局部脉冲饱和问题，即信息集中区域的神经元在所有时间步长内持续放电，这降低了特征判别能力和检测精度，并增加了放电率，阻碍了SNNs实现其潜在的能效。", "method": "我们提出了SpikeDet，一个新颖的脉冲目标检测器，它优化了脉冲模式以实现准确和节能的检测。具体来说，我们设计了一个脉冲骨干网络MDSNet，它有效地调整了每一层的膜突触输入分布，在脉冲特征提取过程中实现了更好的神经元脉冲模式。此外，为了更好地利用和保留这些高质量的骨干特征，我们引入了脉冲多方向融合模块（SMFM），实现了脉冲特征的多方向融合，增强了模型的多尺度检测能力。", "result": "在COCO 2017数据集上，SpikeDet实现了51.4%的AP，比以前基于SNN的方法高出2.5%的AP，同时功耗仅为一半。在目标检测子任务（包括GEN1事件数据集和URPC 2019水下数据集）上，SpikeDet也取得了最佳性能。值得注意的是，在GEN1上，我们的方法实现了47.6%的AP，比以前基于SNN的方法高出7.2%的AP，并具有更好的能效。", "conclusion": "SpikeDet通过优化脉冲模式，显著提高了脉冲神经网络在目标检测任务上的准确性和能效，解决了现有方法的局限性，并在多个数据集上取得了领先的性能。", "translation": "脉冲神经网络（SNNs）是第三代神经网络。\n它们因其低功耗和生物可解释性而在目标检测领域受到广泛关注。然而，现有基于SNN的目标检测方法存在局部脉冲饱和问题，即信息集中区域的神经元在所有时间步长内持续放电。这种异常的神经元放电模式降低了特征判别能力和检测精度，同时还增加了放电率，阻碍了SNNs实现其潜在的能效。为了解决这个问题，我们提出了SpikeDet，一个新颖的脉冲目标检测器，它优化了脉冲模式以实现准确和节能的检测。具体来说，我们设计了一个脉冲骨干网络MDSNet，它有效地调整了每一层的膜突触输入分布，在脉冲特征提取过程中实现了更好的神经元脉冲模式。此外，为了更好地利用和保留这些高质量的骨干特征，我们引入了脉冲多方向融合模块（SMFM），实现了脉冲特征的多方向融合，增强了模型的多尺度检测能力。实验结果表明SpikeDet实现了卓越的性能。在COCO 2017数据集上，它实现了51.4%的AP，比以前基于SNN的方法高出2.5%的AP，同时功耗仅为一半。在目标检测子任务，包括GEN1事件数据集和URPC 2019水下数据集上，SpikeDet也取得了最佳性能。值得注意的是，在GEN1上，我们的方法实现了47.6%的AP，比以前基于SNN的方法高出7.2%的AP，并具有更好的能效。", "summary": "本研究提出了一种名为SpikeDet的新型脉冲目标检测器，旨在解决现有脉冲神经网络（SNNs）在目标检测中存在的局部脉冲饱和问题，该问题导致精度下降和能耗增加。SpikeDet通过引入MDSNet骨干网络优化神经元脉冲模式，并利用SMFM增强多尺度特征融合。实验结果表明，SpikeDet在COCO 2017、GEN1和URPC 2019等数据集上均取得了SNNs领域领先的检测精度，同时大幅降低了能耗，证明了其在准确性和能效方面的优越性。", "keywords": "脉冲神经网络, 目标检测, 脉冲模式, 能效, SpikeDet", "comments": "SpikeDet的创新点在于其通过优化神经元脉冲模式来解决SNNs局部脉冲饱和的核心问题，这直接提升了特征判别能力并降低了能耗。MDSNet和SMFM的设计体现了对SNNs特性深刻理解，特别是MDSNet对膜突触输入分布的调整，是实现“更好的脉冲模式”的关键。该工作不仅在性能上取得了显著提升，尤其是在能效方面，还为SNNs在实际应用中的推广提供了重要支持，具有较高的研究价值和实际意义。"}}
{"id": "2505.10389", "title": "Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples", "authors": ["Benjamin White", "Anastasia Shimorina"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.10389v2", "summary": "This paper explores the design of an aspect-based sentiment analysis system\nusing large language models (LLMs) for real-world use. We focus on quadruple\nopinion extraction -- identifying aspect categories, sentiment polarity,\ntargets, and opinion expressions from text data across different domains and\nlanguages. We investigate whether a single fine-tuned model can effectively\nhandle multiple domain-specific taxonomies simultaneously. We demonstrate that\na combined multi-domain model achieves performance comparable to specialized\nsingle-domain models while reducing operational complexity. We also share\nlessons learned for handling non-extractive predictions and evaluating various\nfailure modes when developing LLM-based systems for structured prediction\ntasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.10389v2", "cate": "cs.CL", "date": "2025-05-15", "updated": "2025-07-15", "AI": {"title_translation": "工业领域多领域多语言情感分析：预测基于方面的情感四元组", "tldr": "本文探索使用大型语言模型（LLMs）设计一个用于实际应用的多领域多语言方面情感分析系统，该系统能够有效提取情感四元组，并证明一个单一的微调模型可以有效处理多个领域特定分类法，同时性能与专业单领域模型相当。", "motivation": "该研究旨在设计一个基于大型语言模型（LLMs）的方面情感分析系统，以应对工业领域中多领域、多语言文本数据的情感四元组（方面类别、情感极性、目标、情感表达）提取挑战，并探讨一个单一的微调模型是否能有效处理多个领域特定分类法。", "method": "本文采用大型语言模型（LLMs）设计了一个方面情感分析系统，专注于情感四元组提取。研究方法包括调查一个单一的微调模型是否能同时处理多个领域特定分类法，并演示了一个组合的多领域模型。", "result": "研究表明，一个组合的多领域模型在性能上与专业的单领域模型相当，同时降低了操作复杂性。此外，论文还分享了处理非抽取式预测和评估各种故障模式的经验。", "conclusion": "本文证明了单一微调模型在多领域多语言方面情感分析中的有效性，其性能与专业单领域模型相当，并能降低操作复杂性。研究还分享了开发基于LLM的结构化预测系统时处理非抽取式预测和评估故障模式的经验教训。", "translation": "本文探讨了使用大型语言模型（LLMs）设计一个用于实际使用的基于方面的情感分析系统。我们专注于四元组意见提取——从跨不同领域和语言的文本数据中识别方面类别、情感极性、目标和意见表达。我们研究了单个微调模型是否能有效同时处理多个领域特定分类法。我们证明了一个组合的多领域模型实现了与专业单领域模型相当的性能，同时降低了操作复杂性。我们还分享了在开发基于LLM的结构化预测任务系统时，处理非抽取式预测和评估各种故障模式的经验教训。", "summary": "本文探讨了在工业背景下使用大型语言模型（LLMs）进行多领域多语言方面情感分析。研究重点在于从文本中提取方面类别、情感极性、目标和意见表达四元组。论文证明，一个单一的微调模型能够有效地处理多个领域特定分类法，并且其性能与多个专业的单领域模型相当，同时显著降低了操作复杂性。此外，作者还分享了在开发基于LLM的结构化预测系统时，处理非抽取式预测和故障模式评估的实践经验。", "keywords": "情感分析, 大型语言模型, 多领域, 多语言, 方面情感分析", "comments": "该论文的创新点在于其提出并验证了单一微调LLM模型在多领域多语言方面情感分析任务中的有效性，这对于实际工业应用而言，在降低操作复杂性方面具有重要意义。它不仅解决了跨领域和语言的挑战，还提供了在实际部署LLM系统时处理非抽取式预测和评估失败模式的实用经验，这些经验对于推动LLM在结构化预测任务中的应用具有指导价值。"}}
{"id": "2507.11737", "title": "Auto-Formulating Dynamic Programming Problems with Large Language Models", "authors": ["Chenyu Zhou", "Jingyuan Yang", "Linwei Xin", "Yitian Chen", "Ziyan He", "Dongdong Ge"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11737v1", "summary": "Dynamic programming (DP) is a fundamental method in operations research, but\nformulating DP models has traditionally required expert knowledge of both the\nproblem context and DP techniques. Large Language Models (LLMs) offer the\npotential to automate this process. However, DP problems pose unique challenges\ndue to their inherently stochastic transitions and the limited availability of\ntraining data. These factors make it difficult to directly apply existing\nLLM-based models or frameworks developed for other optimization problems, such\nas linear or integer programming. We introduce DP-Bench, the first benchmark\ncovering a wide range of textbook-level DP problems to enable systematic\nevaluation. We present Dynamic Programming Language Model (DPLM), a\n7B-parameter specialized model that achieves performance comparable to\nstate-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on\nhard problems. Central to DPLM's effectiveness is DualReflect, our novel\nsynthetic data generation pipeline, designed to scale up training data from a\nlimited set of initial examples. DualReflect combines forward generation for\ndiversity and backward generation for reliability. Our results reveal a key\ninsight: backward generation is favored in low-data regimes for its strong\ncorrectness guarantees, while forward generation, though lacking such\nguarantees, becomes increasingly valuable at scale for introducing diverse\nformulations. This trade-off highlights the complementary strengths of both\napproaches and the importance of combining them.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11737v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "使用大型语言模型自动构建动态规划问题", "tldr": "本文介绍了DPLM，一个7B参数的专用模型，能自动构建动态规划问题，并提出了DualReflect数据生成管道以解决数据稀缺问题，性能媲美甚至超越现有顶级LLM。", "motivation": "动态规划模型构建需要专业知识，且现有LLM难以直接应用于DP问题，因为DP固有的随机性转换和训练数据有限。", "method": "引入了首个DP问题基准测试DP-Bench；提出了7B参数的专用模型DPLM；设计了新颖的合成数据生成管道DualReflect，结合了前向（多样性）和后向（可靠性）生成。", "result": "DPLM在DP问题上的表现与SOTA LLM（如OpenAI的o1和DeepSeek-R1）相当，并在难题上超越它们。研究发现，在数据量少时后向生成更可靠，而前向生成在数据量大时能提供更多样化的公式。", "conclusion": "后向生成在数据量少时因其高正确性保证而受青睐，而前向生成在规模化时对引入多样化公式变得越来越有价值，这两种方法具有互补优势，结合使用至关重要。", "translation": "动态规划（DP）是运筹学中的一种基本方法，但传统上，构建DP模型需要问题背景和DP技术的专业知识。大型语言模型（LLMs）提供了自动化这一过程的潜力。然而，由于其固有的随机转换和训练数据有限，DP问题带来了独特的挑战。这些因素使得现有为其他优化问题（如线性或整数规划）开发的基于LLM的模型或框架难以直接应用。我们引入了DP-Bench，这是第一个涵盖广泛教科书级DP问题的基准测试，以实现系统评估。我们提出了动态规划语言模型（DPLM），这是一个70亿参数的专用模型，其性能可与OpenAI的o1和DeepSeek-R1等最先进的LLM相媲美，并在难题上超越它们。DPLM有效性的核心是DualReflect，我们新颖的合成数据生成管道，旨在从有限的初始示例集中扩展训练数据。DualReflect结合了前向生成的多样性与后向生成的可靠性。我们的结果揭示了一个关键见解：在低数据量情况下，后向生成因其强大的正确性保证而受到青睐，而前向生成虽然缺乏此类保证，但在规模化时对于引入多样化公式变得越来越有价值。这种权衡突出了两种方法的互补优势以及结合它们的重要性。", "summary": "本文旨在利用大型语言模型（LLMs）自动化动态规划（DP）问题的构建，以应对传统方法对专家知识的依赖以及LLMs在DP领域面临的数据稀缺和随机性挑战。为此，研究团队开发了DP-Bench基准测试和70亿参数的专用模型DPLM，其性能与现有顶级LLMs相当甚至更优。此外，还提出了DualReflect合成数据生成管道，通过结合前向生成（多样性）和后向生成（可靠性）来有效扩充训练数据，并揭示了两种生成策略在不同数据量下的互补优势。", "keywords": "动态规划, 大型语言模型, 数据生成, DPLM, DualReflect", "comments": "这篇论文的创新点在于提出了专门针对动态规划问题的LLM模型DPLM和高效的数据生成管道DualReflect，有效解决了DP问题在LLM应用中的数据稀缺和复杂性挑战。DP-Bench的引入也为后续研究提供了标准化的评估平台。DualReflect关于前向和后向生成在不同数据量下互补作用的发现具有重要的理论和实践意义，为未来LLM在专业领域的数据增强提供了新思路。"}}
{"id": "2507.11597", "title": "AI, Humans, and Data Science: Optimizing Roles Across Workflows and the Workforce", "authors": ["Richard Timpone", "Yongwei Yang"], "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Paper prepared for the 2025 European Survey Research Association Conference; 30 pages, 5 tables and 4 figures", "url": "http://arxiv.org/abs/2507.11597v1", "summary": "AI is transforming research. It is being leveraged to construct surveys,\nsynthesize data, conduct analysis, and write summaries of the results. While\nthe promise is to create efficiencies and increase quality, the reality is not\nalways as clear cut. Leveraging our framework of Truth, Beauty, and Justice\n(TBJ) which we use to evaluate AI, machine learning and computational models\nfor effective and ethical use (Taber and Timpone 1997; Timpone and Yang 2024),\nwe consider the potential and limitation of analytic, generative, and agentic\nAI to augment data scientists or take on tasks traditionally done by human\nanalysts and researchers. While AI can be leveraged to assist analysts in their\ntasks, we raise some warnings about push-button automation. Just as earlier\neras of survey analysis created some issues when the increased ease of using\nstatistical software allowed researchers to conduct analyses they did not fully\nunderstand, the new AI tools may create similar but larger risks. We emphasize\na human-machine collaboration perspective (Daugherty and Wilson 2018)\nthroughout the data science workflow and particularly call out the vital role\nthat data scientists play under VUCA decision areas. We conclude by encouraging\nthe advance of AI tools to complement data scientists but advocate for\ncontinued training and understanding of methods to ensure the substantive value\nof research is fully achieved by applying, interpreting, and acting upon\nresults most effectively and ethically.", "comment": "Paper prepared for the 2025 European Survey Research Association\n  Conference; 30 pages, 5 tables and 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.11597v1", "cate": "cs.CY", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "人工智能、人类与数据科学：优化工作流程和劳动力中的角色", "tldr": "本文探讨了人工智能在数据科学中的潜力和局限性，强调了人机协作的重要性，并警告了过度自动化带来的风险，呼吁持续的培训和方法理解以确保研究的实质价值。", "motivation": "人工智能正在改变研究，但其应用并非总是清晰明了。本文旨在评估分析型、生成型和代理型人工智能在增强数据科学家能力或取代人类分析师任务方面的潜力与局限性，并提出警告以确保有效和道德的使用。", "method": "本文利用“真理、美德和正义”（TBJ）框架来评估人工智能、机器学习和计算模型，以探讨分析型、生成型和代理型人工智能的潜力与局限性，并强调人机协作视角。", "result": "人工智能可以辅助分析师，但“一键式”自动化存在风险。文章强调在数据科学工作流程中人机协作的重要性，尤其是在VUCA（易变性、不确定性、复杂性、模糊性）决策领域中数据科学家的关键作用。", "conclusion": "鼓励人工智能工具作为数据科学家的补充，但主张持续的培训和对方法的理解，以确保通过最有效和道德地应用、解释和利用结果来充分实现研究的实质价值。", "translation": "人工智能正在改变研究。它被用于构建调查、综合数据、进行分析和撰写结果摘要。虽然其承诺是提高效率和质量，但现实并非总是如此清晰。我们利用评估人工智能、机器学习和计算模型以实现有效和道德使用的“真理、美德和正义”（TBJ）框架（Taber和Timpone 1997；Timpone和Yang 2024），来审视分析型、生成型和代理型人工智能在增强数据科学家能力或承担传统上由人类分析师和研究人员完成的任务方面的潜力和局限性。虽然人工智能可以帮助分析师完成任务，但我们对“一键式”自动化提出了一些警告。正如早期调查分析时代，统计软件使用便利性的提高曾导致研究人员进行他们不完全理解的分析，从而产生了一些问题；新的AI工具可能会带来类似但更大的风险。我们强调在整个数据科学工作流程中采取人机协作的视角（Daugherty和Wilson 2018），并特别指出在VUCA决策领域中数据科学家的关键作用。最后，我们鼓励人工智能工具作为数据科学家的补充，但倡导持续的培训和对方法的理解，以确保通过最有效和道德地应用、解释和利用结果来充分实现研究的实质价值。", "summary": "本文探讨了人工智能在数据科学研究中的应用，指出其在提高效率和质量方面的潜力，但也警示了过度自动化带来的风险。作者们利用其TBJ框架评估了不同类型AI对数据科学家的影响，强调了在数据科学工作流程中人机协作的关键作用，并呼吁在推动AI工具发展的同时，数据科学家应持续学习和理解方法，以确保研究的实质价值和道德应用。", "keywords": "人工智能, 数据科学, 人机协作, 自动化, 伦理", "comments": "本文深刻探讨了人工智能在数据科学领域日益增长的作用，并提出了一个重要的平衡点。其创新之处在于利用“真理、美德和正义”（TBJ）框架来评估AI的伦理和有效性，这为AI应用提供了一个重要的道德指南。论文强调人机协作而非完全自动化，这一点在当前AI快速发展的背景下尤为重要，因为它警示了“一键式”自动化可能带来的风险，并强调了人类专业知识在解释和应用研究结果中的不可替代性。这对于确保研究的严谨性和伦理性具有重要意义。"}}
{"id": "2507.11997", "title": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection", "authors": ["Tairan Huang", "Yili Wang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11997v1", "summary": "Graph fraud detection has garnered significant attention as Graph Neural\nNetworks (GNNs) have proven effective in modeling complex relationships within\nmultimodal data. However, existing graph fraud detection methods typically use\npreprocessed node embeddings and predefined graph structures to reveal\nfraudsters, which ignore the rich semantic cues contained in raw textual\ninformation. Although Large Language Models (LLMs) exhibit powerful\ncapabilities in processing textual information, it remains a significant\nchallenge to perform multimodal fusion of processed textual embeddings with\ngraph structures. In this paper, we propose a \\textbf{M}ulti-level \\textbf{L}LM\n\\textbf{E}nhanced Graph Fraud \\textbf{D}etection framework called MLED. In\nMLED, we utilize LLMs to extract external knowledge from textual information to\nenhance graph fraud detection methods. To integrate LLMs with graph structure\ninformation and enhance the ability to distinguish fraudsters, we design a\nmulti-level LLM enhanced framework including type-level enhancer and\nrelation-level enhancer. One is to enhance the difference between the\nfraudsters and the benign entities, the other is to enhance the importance of\nthe fraudsters in different relations. The experiments on four real-world\ndatasets show that MLED achieves state-of-the-art performance in graph fraud\ndetection as a generalized framework that can be applied to existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11997v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "LLM能找到欺诈者吗？多级LLM增强图欺诈检测", "tldr": "提出MLED框架，利用LLM增强图欺诈检测，在真实数据集上表现SOTA。", "motivation": "现有图欺诈检测方法通常使用预处理的节点嵌入和预定义的图结构，忽略了原始文本信息中包含的丰富语义线索。此外，将处理过的文本嵌入与图结构进行多模态融合仍然是一个重大挑战。", "method": "本文提出了一个名为MLED的多级LLM增强图欺诈检测框架。MLED利用LLMs从文本信息中提取外部知识，并通过设计多级LLM增强器（包括类型级增强器和关系级增强器）将LLMs与图结构信息集成。类型级增强器旨在增强欺诈者与良性实体之间的差异，关系级增强器旨在增强欺诈者在不同关系中的重要性。", "result": "在四个真实世界数据集上的实验表明，MLED作为一种可应用于现有方法的通用框架，在图欺诈检测方面取得了最先进的性能。", "conclusion": "本文提出的MLED框架通过有效集成大型语言模型与图结构，并利用多级增强机制来整合文本语义信息，显著提高了图欺诈检测的性能。", "translation": "图欺诈检测作为图神经网络（GNNs）在建模多模态数据中的复杂关系方面被证明是有效的，受到了广泛关注。然而，现有的图欺诈检测方法通常使用预处理的节点嵌入和预定义的图结构来揭示欺诈者，这忽略了原始文本信息中包含的丰富语义线索。尽管大型语言模型（LLMs）在处理文本信息方面表现出强大的能力，但将处理过的文本嵌入与图结构进行多模态融合仍然是一个重大挑战。在本文中，我们提出了一个名为MLED的“多级LLM增强图欺诈检测”框架。在MLED中，我们利用LLMs从文本信息中提取外部知识，以增强图欺诈检测方法。为了将LLMs与图结构信息相结合并增强区分欺诈者的能力，我们设计了一个多级LLM增强框架，包括类型级增强器和关系级增强器。其中一个旨在增强欺诈者与良性实体之间的差异，另一个旨在增强欺诈者在不同关系中的重要性。在四个真实世界数据集上的实验表明，MLED作为一种可应用于现有方法的通用框架，在图欺诈检测方面取得了最先进的性能。", "summary": "本文提出了一种新颖的名为MLED的多级LLM增强图欺诈检测框架。该框架旨在解决现有图欺诈检测方法忽略文本语义信息以及多模态融合的挑战。MLED利用大型语言模型（LLMs）从文本数据中提取外部知识，并通过类型级和关系级增强器将其与图结构信息有效整合。在四个真实世界数据集上的实验证明，MLED实现了最先进的性能，并具有良好的通用性。", "keywords": "图欺诈检测, 大型语言模型, 图神经网络, 多模态融合, MLED", "comments": "本文的创新之处在于其有效地将大型语言模型（LLMs）与图神经网络（GNNs）相结合，用于欺诈检测。通过设计多级增强机制，该方法解决了将丰富的文本语义信息纳入图结构的关键问题，弥补了传统图方法在这方面的不足，并提供了一个通用的框架。"}}
{"id": "2507.12269", "title": "Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants", "authors": ["Sybelle Goedicke-Fritz", "Michelle Bous", "Annika Engel", "Matthias Flotho", "Pascal Hirsch", "Hannah Wittig", "Dino Milanovic", "Dominik Mohr", "Mathias Kaspar", "Sogand Nemat", "Dorothea Kerner", "Arno Bücker", "Andreas Keller", "Sascha Meyer", "Michael Zemlin", "Philipp Flotho"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      S.G.-F., M.B., and A.E. contributed equally to this work and share first authorship. M.Z. and P.F. contributed equally to this work and share senior authorship", "url": "http://arxiv.org/abs/2507.12269v1", "summary": "Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of\nextremely low birth weight infants. Defined by oxygen dependence at 36 weeks\npostmenstrual age, it causes lifelong respiratory complications. However,\npreventive interventions carry severe risks, including neurodevelopmental\nimpairment, ventilator-induced lung injury, and systemic complications.\nTherefore, early BPD prognosis and prediction of BPD outcome is crucial to\navoid unnecessary toxicity in low risk infants. Admission radiographs of\nextremely preterm infants are routinely acquired within 24h of life and could\nserve as a non-invasive prognostic tool. In this work, we developed and\ninvestigated a deep learning approach using chest X-rays from 163 extremely\nlow-birth-weight infants ($\\leq$32 weeks gestation, 401-999g) obtained within\n24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult\nchest radiographs, employing progressive layer freezing with discriminative\nlearning rates to prevent overfitting and evaluated a CutMix augmentation and\nlinear probing. For moderate/severe BPD outcome prediction, our best performing\nmodel with progressive freezing, linear probing and CutMix achieved an AUROC of\n0.78 $\\pm$ 0.10, balanced accuracy of 0.69 $\\pm$ 0.10, and an F1-score of 0.67\n$\\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet\ninitialization (p = 0.031) which confirms domain-specific pretraining to be\nimportant for BPD outcome prediction. Routine IRDS grades showed limited\nprognostic value (AUROC 0.57 $\\pm$ 0.11), confirming the need of learned\nmarkers. Our approach demonstrates that domain-specific pretraining enables\naccurate BPD prediction from routine day-1 radiographs. Through progressive\nfreezing and linear probing, the method remains computationally feasible for\nsite-level implementation and future federated learning deployments.", "comment": "S.G.-F., M.B., and A.E. contributed equally to this work and share\n  first authorship. M.Z. and P.F. contributed equally to this work and share\n  senior authorship", "pdf_url": "http://arxiv.org/pdf/2507.12269v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "站点级微调与渐进层冻结：从极早产儿出生第一天的胸部X光片中稳健预测支气管肺发育不良", "tldr": "使用深度学习结合渐进层冻结，通过出生第一天的胸部X光片预测极早产儿的支气管肺发育不良。", "motivation": "支气管肺发育不良(BPD)是一种慢性肺病，影响35%的极低出生体重婴儿，导致终身呼吸并发症。预防性干预措施伴随严重风险，因此早期预测BPD结果对于避免对低风险婴儿进行不必要的治疗至关重要。", "method": "研究使用163名极低出生体重婴儿（≤32周胎龄，401-999克）出生24小时内获得的胸部X光片。对在成人胸部X光片上预训练的ResNet-50模型进行微调，采用渐进层冻结和判别性学习率以防止过拟合，并评估了CutMix数据增强和线性探测。", "result": "对于中度/重度BPD预测，最佳模型（渐进层冻结、线性探测和CutMix）的AUROC为0.78 ± 0.10，平衡准确率为0.69 ± 0.10，F1-score为0.67 ± 0.11。领域内预训练显著优于ImageNet初始化（p = 0.031）。常规IRDS分级预后价值有限（AUROC 0.57 ± 0.11）。", "conclusion": "领域特定预训练能够从常规出生第一天X光片中准确预测BPD。该方法通过渐进层冻结和线性探测，在计算上对于站点级实施和未来的联邦学习部署是可行的。", "translation": "支气管肺发育不良（BPD）是一种慢性肺病，影响35%的极低出生体重婴儿。它定义为在矫正胎龄36周时需要吸氧，会导致终身呼吸并发症。然而，预防性干预措施伴随严重风险，包括神经发育障碍、呼吸机引起的肺损伤和全身并发症。因此，早期BPD预后和预测BPD结果对于避免低风险婴儿不必要的毒性至关重要。极早产儿入院时在出生24小时内常规获取X光片，可作为一种非侵入性预后工具。在这项工作中，我们开发并研究了一种深度学习方法，该方法使用163名极低出生体重婴儿（胎龄≤32周，体重401-999克）在出生24小时内获得的胸部X光片。我们对专门在成人胸部X光片上预训练的ResNet-50模型进行了微调，采用渐进层冻结和判别性学习率以防止过拟合，并评估了CutMix数据增强和线性探测。对于中度/重度BPD结果预测，我们采用渐进层冻结、线性探测和CutMix的最佳模型实现了0.78 ± 0.10的AUROC，0.69 ± 0.10的平衡准确率和0.67 ± 0.11的F1-score。领域内预训练显著优于ImageNet初始化（p = 0.031），这证实了领域特定预训练对于BPD结果预测的重要性。常规IRDS分级显示出有限的预后价值（AUROC 0.57 ± 0.11），证实了需要学习标记物。我们的方法表明，领域特定预训练能够从常规出生第一天X光片中准确预测BPD。通过渐进层冻结和线性探测，该方法在计算上对于站点级实施和未来的联邦学习部署是可行的。", "summary": "本文开发并评估了一种基于深度学习的方法，利用出生第一天的胸部X光片预测极早产儿的支气管肺发育不良（BPD）。该方法通过对在成人胸部X光片上预训练的ResNet-50模型进行渐进层冻结微调，并结合CutMix数据增强和线性探测，实现了对中度/重度BPD的准确预测（AUROC 0.78）。研究强调了领域特定预训练的重要性，并证明该方法在计算上可行，适用于站点级和联邦学习部署。", "keywords": "支气管肺发育不良, 深度学习, 胸部X光片, 渐进层冻结, 极早产儿", "comments": "这项工作创新性地将深度学习应用于极早产儿出生第一天的胸部X光片，以早期预测支气管肺发育不良，这对于避免不必要的干预和改善患儿预后具有重要意义。渐进层冻结和领域特定预训练的策略有效提升了模型的性能和鲁棒性，使其在实际应用中具有可行性。"}}
{"id": "2502.01912", "title": "PATCH: a deep learning method to assess heterogeneity of artistic practice in historical paintings", "authors": ["Andrew Van Horn", "Lauryn Smith", "Mahamad Mahmoud", "Michael McMaster", "Clara Pinchbeck", "Ina Martin", "Andrew Lininger", "Anthony Ingrisano", "Adam Lowe", "Carlos Bayod", "Elizabeth Bolman", "Kenneth Singer", "Michael Hinczewski"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      main text: 15 pages, 5 figures; SI: 10 pages, 4 figures; v2: minor typo corrections, higher resolution figures; v3: additional comparisons with alternative methods", "url": "http://arxiv.org/abs/2502.01912v3", "summary": "The history of art has seen significant shifts in the manner in which\nartworks are created, making understanding of creative processes a central\nquestion in technical art history. In the Renaissance and Early Modern period,\npaintings were largely produced by master painters directing workshops of\napprentices who often contributed to projects. The masters varied significantly\nin artistic and managerial styles, meaning different combinations of artists\nand implements might be seen both between masters and within workshops or even\nindividual canvases. Information on how different workshops were managed and\nthe processes by which artworks were created remains elusive. Machine learning\nmethods have potential to unearth new information about artists' creative\nprocesses by extending the analysis of brushwork to a microscopic scale.\nAnalysis of workshop paintings, however, presents a challenge in that\ndocumentation of the artists and materials involved is sparse, meaning external\nexamples are not available to train networks to recognize their contributions.\nHere we present a novel machine learning approach we call pairwise assignment\ntraining for classifying heterogeneity (PATCH) that is capable of identifying\nindividual artistic practice regimes with no external training data, or \"ground\ntruth.\" The method achieves unsupervised results by supervised means, and\noutperforms both simple statistical procedures and unsupervised machine\nlearning methods. We apply this method to two historical paintings by the\nSpanish Renaissance master, El Greco: The Baptism of Christ and Christ on the\nCross with Landscape, and our findings regarding the former potentially\nchallenge previous work that has assigned the painting to workshop members.\nFurther, the results of our analyses create a measure of heterogeneity of\nartistic practice that can be used to characterize artworks across time and\nspace.", "comment": "main text: 15 pages, 5 figures; SI: 10 pages, 4 figures; v2: minor\n  typo corrections, higher resolution figures; v3: additional comparisons with\n  alternative methods", "pdf_url": "http://arxiv.org/pdf/2502.01912v3", "cate": "cs.CV", "date": "2025-02-04", "updated": "2025-07-16", "AI": {"title_translation": "PATCH：一种评估历史画作中艺术实践异质性的深度学习方法", "tldr": "PATCH是一种新型深度学习方法，无需外部训练数据即可识别历史画作中的艺术实践异质性，并已成功应用于埃尔·格列柯的作品，挑战了现有归属。", "motivation": "理解艺术创作过程是技术艺术史的核心问题。文艺复兴和早期现代时期的画作常由大师与学徒合作完成，但关于不同工作室如何管理以及艺术品创作过程的信息稀缺且难以获取，同时缺乏足够的外部训练数据来识别不同艺术家的贡献。", "method": "提出了一种名为PATCH（pairwise assignment training for classifying heterogeneity）的新型机器学习方法。该方法能够在没有外部训练数据或“真实标签”的情况下识别个体艺术实践模式，通过监督学习的方式实现无监督结果，并且优于简单的统计程序和现有的无监督机器学习方法。", "result": "该方法被应用于西班牙文艺复兴大师埃尔·格列柯的两幅历史画作：《基督受洗》和《带风景的基督受难》，其中关于《基督受洗》的发现可能挑战了先前将其归因于工作室成员的观点。", "conclusion": "PATCH方法的分析结果能够创建一种艺术实践异质性的衡量标准，可用于跨时间和空间地表征艺术品。", "translation": "艺术史见证了艺术品创作方式的重大转变，使理解创作过程成为技术艺术史的核心问题。在文艺复兴和早期现代时期，画作主要由大师画家指导学徒工坊创作，学徒们也常参与项目。大师们的艺术和管理风格差异显著，这意味着在不同大师之间、甚至在同一工坊内或单幅画布上，都可能看到艺术家和工具的不同组合。关于不同工坊如何管理以及艺术品创作过程的信息仍然难以捉摸。机器学习方法有潜力通过将笔触分析扩展到微观尺度，从而揭示关于艺术家创作过程的新信息。然而，工坊画作的分析面临挑战，因为涉及的艺术家和材料的文献稀少，这意味着没有外部范例来训练网络识别他们的贡献。本文提出了一种名为“成对赋值训练分类异质性”（PATCH）的新型机器学习方法，该方法能够在没有外部训练数据或“真实标签”的情况下识别个体艺术实践模式。该方法通过监督方式实现无监督结果，并且优于简单的统计程序和无监督机器学习方法。我们将此方法应用于西班牙文艺复兴大师埃尔·格列柯的两幅历史画作：《基督受洗》和《带风景的基督受难》，我们关于前者的发现可能挑战了先前将该画作归因于工坊成员的观点。此外，我们的分析结果创建了一种艺术实践异质性的衡量标准，可用于跨时间和空间地表征艺术品。", "summary": "本文提出了一种名为PATCH的深度学习方法，旨在解决历史画作中艺术实践异质性难以量化的问题。针对缺乏外部训练数据的挑战，PATCH采用一种独特的无监督学习方式。该方法能够识别单个艺术家的实践模式，并在应用于埃尔·格列柯的两幅作品时，成功挑战了关于《基督受洗》的现有归属。研究结果为量化艺术实践的异质性提供了一个新工具，有助于深入理解历史艺术创作。", "keywords": "艺术实践异质性, 深度学习, 历史绘画, 无监督学习, 工坊画作", "comments": "这篇论文的创新点在于提出了一个无需外部“真实标签”数据就能识别艺术实践异质性的深度学习方法（PATCH），这对于缺乏详细文献记载的历史艺术品分析尤为重要。其“通过监督方式实现无监督结果”的设计理念值得关注。成功应用于埃尔·格列柯的作品并挑战现有归属，展示了该方法的实际应用价值和潜力。该方法为技术艺术史研究提供了一个强大的新工具，有助于更深入地理解历史艺术品的创作过程和合作模式。"}}
{"id": "2403.08269", "title": "A posteriori error estimates for the Generalized Burgers-Huxley equation with weakly singular kernels", "authors": ["Sumit Mahajan", "Arbaz Khan"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.08269v2", "summary": "This paper explores the residual based a posteriori error estimations for the\ngeneralized Burgers-Huxley equation (GBHE) featuring weakly singular kernels.\nInitially, we present a reliable and efficient error estimator for both the\nstationary GBHE and the semi-discrete GBHE with memory, utilizing the\ndiscontinuous Galerkin finite element method (DGFEM) in spatial dimensions.\nAdditionally, employing backward Euler and Crank Nicolson discretization in the\ntemporal domain and DGFEM in spatial dimensions, we introduce an estimator for\nthe fully discrete GBHE, taking into account the influence of past history. The\npaper also establishes optimal $L^2$ error estimates for both the stationary\nGBHE and GBHE. Ultimately, we validate the effectiveness of the proposed error\nestimator through numerical results, demonstrating its efficacy in an adaptive\nrefinement strategy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.08269v2", "cate": "math.NA", "date": "2024-03-13", "updated": "2025-07-16", "AI": {"title_translation": "广义Burgers-Huxley方程弱奇异核的后验误差估计", "tldr": "本文研究了广义Burgers-Huxley方程（GBHE）弱奇异核的残差后验误差估计，并提出了高效的估计器，验证了其在自适应细化策略中的有效性。", "motivation": "本文旨在探索具有弱奇异核的广义Burgers-Huxley方程（GBHE）的基于残差的后验误差估计。", "method": "本研究利用空间维度的间断Galerkin有限元方法（DGFEM）为稳态GBHE和带记忆的半离散GBHE提供了误差估计器。此外，通过在时间域采用后向Euler和Crank Nicolson离散化，并在空间维度采用DGFEM，引入了一个考虑过去历史影响的全离散GBHE估计器。", "result": "研究提出了稳态GBHE和带记忆半离散GBHE的可靠且高效的误差估计器。同时，引入了全离散GBHE的估计器，并建立了稳态GBHE和GBHE的最优$L^2$误差估计。数值结果验证了所提出误差估计器的有效性，并展示了其在自适应细化策略中的功效。", "conclusion": "所提出的误差估计器是有效的，并且能够成功应用于自适应细化策略中。", "translation": "本文探讨了具有弱奇异核的广义Burgers-Huxley方程（GBHE）的基于残差的后验误差估计。最初，我们利用空间维度的间断Galerkin有限元方法（DGFEM），为稳态GBHE和带记忆的半离散GBHE提供了一个可靠且高效的误差估计器。此外，通过在时间域采用后向Euler和Crank Nicolson离散化，并在空间维度采用DGFEM，我们引入了一个考虑过去历史影响的全离散GBHE估计器。本文还为稳态GBHE和GBHE建立了最优的$L^2$误差估计。最终，我们通过数值结果验证了所提出误差估计器的有效性，证明了其在自适应细化策略中的功效。", "summary": "本文研究了广义Burgers-Huxley方程（GBHE）弱奇异核的残差后验误差估计。研究者利用间断Galerkin有限元方法（DGFEM）在空间维度，并结合后向Euler和Crank Nicolson时间离散化，提出了稳态、半离散和全离散GBHE的可靠高效误差估计器。文中还建立了最优$L^2$误差估计。数值结果验证了这些估计器的有效性及其在自适应细化策略中的应用潜力。", "keywords": "广义Burgers-Huxley方程, 后验误差估计, 弱奇异核, 间断Galerkin有限元方法, 自适应细化策略", "comments": "该论文提出了一种针对广义Burgers-Huxley方程（GBHE）的后验误差估计方法，特别关注了弱奇异核的情况。其创新点在于结合了DGFEM和时间离散化，为不同形式的GBHE提供了统一且有效的误差估计框架，并验证了其在自适应细化策略中的实用性，这对于提高数值模拟的精度和效率具有重要意义。"}}
{"id": "2503.23175", "title": "Large Language Models are Unreliable for Cyber Threat Intelligence", "authors": ["Emanuele Mezzi", "Fabio Massacci", "Katja Tuma"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.23175v2", "summary": "Several recent works have argued that Large Language Models (LLMs) can be\nused to tame the data deluge in the cybersecurity field, by improving the\nautomation of Cyber Threat Intelligence (CTI) tasks. This work presents an\nevaluation methodology that other than allowing to test LLMs on CTI tasks when\nusing zero-shot learning, few-shot learning and fine-tuning, also allows to\nquantify their consistency and their confidence level. We run experiments with\nthree state-of-the-art LLMs and a dataset of 350 threat intelligence reports\nand present new evidence of potential security risks in relying on LLMs for\nCTI. We show how LLMs cannot guarantee sufficient performance on real-size\nreports while also being inconsistent and overconfident. Few-shot learning and\nfine-tuning only partially improve the results, thus posing doubts about the\npossibility of using LLMs for CTI scenarios, where labelled datasets are\nlacking and where confidence is a fundamental factor.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.23175v2", "cate": "cs.CR", "date": "2025-03-29", "updated": "2025-07-16", "AI": {"title_translation": "大型语言模型在网络威胁情报方面不可靠", "tldr": "本研究评估了大型语言模型（LLMs）在网络威胁情报（CTI）任务中的表现，发现它们在处理实际报告时性能不足、不一致且过于自信，即使通过少量样本学习和微调也只能部分改善结果，因此不建议依赖LLMs进行CTI工作。", "motivation": "最近一些研究认为大型语言模型（LLMs）可以通过提高网络威胁情报（CTI）任务的自动化水平来应对网络安全领域的数据洪流，本研究旨在评估LLMs在CTI任务中的实际可靠性。", "method": "本研究提出了一种评估方法，用于在零样本学习、少量样本学习和微调的情况下测试LLMs在CTI任务中的表现，并量化其一致性和置信水平。实验使用了三个最先进的LLMs和包含350份威胁情报报告的数据集。", "result": "实验结果表明，依赖LLMs进行CTI存在潜在的安全风险。LLMs无法保证在实际大小报告上的足够性能，同时表现出不一致和过度自信。少量样本学习和微调只能部分改善结果。", "conclusion": "鉴于标记数据集的缺乏和置信度作为基本因素的重要性，本研究对在网络威胁情报场景中使用大型语言模型的可能性提出了质疑。", "translation": "最近的一些工作认为，大型语言模型（LLMs）可以通过提高网络威胁情报（CTI）任务的自动化水平，来应对网络安全领域的数据洪流。本研究提出了一种评估方法，除了允许在零样本学习、少量样本学习和微调时测试LLMs在CTI任务中的表现外，还允许量化它们的一致性和置信水平。我们使用三个最先进的LLMs和包含350份威胁情报报告的数据集进行了实验，并提出了依赖LLMs进行CTI可能存在的潜在安全风险的新证据。我们展示了LLMs在处理实际大小的报告时无法保证足够的性能，同时表现出不一致和过度自信。少量样本学习和微调只能部分改善结果，因此对在缺乏标记数据集且置信度是基本因素的CTI场景中使用LLMs的可能性提出了质疑。", "summary": "本研究评估了大型语言模型（LLMs）在网络威胁情报（CTI）任务中的可靠性，挑战了LLMs能有效处理网络安全数据洪流的观点。通过零样本、少量样本学习和微调方法，并使用350份威胁情报报告数据集对三个先进LLMs进行实验，结果显示LLMs在处理实际报告时性能不足、不一致且过于自信。即使经过少量样本学习和微调，性能也仅部分改善，这引发了对LLMs在缺乏标记数据且置信度至关重要的CTI场景中应用可行性的质疑。", "keywords": "大型语言模型, 网络威胁情报, 可靠性, 评估, 置信度", "comments": "这篇论文通过实证研究，对大型语言模型在网络威胁情报领域的适用性提出了重要的质疑。它不仅提供了一种严谨的评估方法，还揭示了LLMs在真实场景中存在的性能不足、不一致性和过度自信等关键局限性，这对于当前过度乐观地看待LLMs能力的趋势具有警示意义。研究强调了在缺乏高质量标记数据和高置信度要求的安全领域中，LLMs的局限性，对未来的研究和应用具有指导价值。"}}
{"id": "2507.11757", "title": "A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction", "authors": ["Yuehua Song", "Yong Gao"], "categories": ["cs.LG", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11757v1", "summary": "Accurately predicting drug-target interactions (DTIs) is pivotal for\nadvancing drug discovery and target validation techniques. While machine\nlearning approaches including those that are based on Graph Neural Networks\n(GNN) have achieved notable success in DTI prediction, many of them have\ndifficulties in effectively integrating the diverse features of drugs, targets\nand their interactions. To address this limitation, we introduce a novel\nframework to take advantage of the power of both transductive learning and\ninductive learning so that features at molecular level and drug-target\ninteraction network level can be exploited. Within this framework is a\nGNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and\ntarget molecular structures as meta-nodes in a drug-target interaction graph,\nenabling a detailed exploration of their intricate relationships. To evaluate\nthe proposed model, we have compiled a special benchmark comprising drug\nSMILES, protein sequences, and their interaction data, which is interesting in\nits own right. Our experimental results demonstrate that the GiG model\nsignificantly outperforms existing approaches across all evaluation metrics,\nhighlighting the benefits of integrating different learning paradigms and\ninteraction data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11757v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "用于药物-靶点相互作用预测的图内图学习框架", "tldr": "提出了一种名为Graph-in-Graph (GiG)的新型GNN框架，通过在药物-靶点相互作用图中将药物和靶点分子结构图表示为元节点，有效整合了药物、靶点及其相互作用的多种特征，显著提高了药物-靶点相互作用预测的准确性。", "motivation": "准确预测药物-靶点相互作用（DTIs）对于药物发现和靶点验证至关重要。尽管现有的机器学习方法（包括基于图神经网络的方法）在DTI预测方面取得了成功，但它们在有效整合药物、靶点及其相互作用的多种特征方面存在困难。", "method": "本研究引入了一个新的学习框架，结合了转导学习和归纳学习的优势，以利用分子级别和药物-靶点相互作用网络级别的特征。该框架中包含一个基于GNN的模型，称为Graph-in-Graph (GiG)，它将药物和靶点分子结构图表示为药物-靶点相互作用图中的元节点，从而能够详细探索它们之间复杂的关。此外，作者还编译了一个包含药物SMILES、蛋白质序列及其相互作用数据的特殊基准数据集用于模型评估。", "result": "实验结果表明，GiG模型在所有评估指标上都显著优于现有方法。", "conclusion": "GiG模型通过整合不同的学习范式和相互作用数据，在药物-靶点相互作用预测方面展现出显著优势和更高的性能。", "translation": "准确预测药物-靶点相互作用（DTIs）对于推进药物发现和靶点验证技术至关重要。尽管包括基于图神经网络（GNN）在内的机器学习方法在DTI预测方面取得了显著成功，但其中许多方法难以有效整合药物、靶点及其相互作用的多种特征。为了解决这一局限性，我们引入了一种新颖的框架，以利用转导学习和归纳学习的强大能力，从而可以利用分子层面和药物-靶点相互作用网络层面的特征。该框架内是一个基于GNN的模型，称为图内图（GiG），它将药物和靶点分子结构的图表示为药物-靶点相互作用图中的元节点，从而能够详细探索它们之间复杂的关。为了评估所提出的模型，我们编译了一个特殊的基准数据集，包括药物SMILES、蛋白质序列及其相互作用数据，这本身也很有意义。我们的实验结果表明，GiG模型在所有评估指标上都显著优于现有方法，突出了整合不同学习范式和相互作用数据的好处。", "summary": "本研究提出了一个名为Graph-in-Graph (GiG) 的新型图神经网络框架，用于药物-靶点相互作用（DTI）预测。该框架通过将药物和靶点分子结构图作为药物-靶点相互作用图中的元节点，有效整合了分子级别和网络级别的特征，解决了现有方法在整合多源特征方面的局限性。实验结果表明，GiG模型在DTI预测性能上显著优于现有方法，证明了其在药物发现领域的潜力。", "keywords": "药物-靶点相互作用预测, 图神经网络, 图内图, 药物发现, 特征整合", "comments": "该论文的创新点在于提出了“图内图”的概念，巧妙地将药物和靶点的内部分子结构图作为元节点嵌入到药物-靶点相互作用图中，从而能够同时捕获局部（分子结构）和全局（相互作用网络）信息。这种多尺度特征整合的方法有效地解决了现有DTI预测模型在处理异构数据时的挑战，对药物发现领域具有重要意义。"}}
{"id": "2507.11986", "title": "Style Composition within Distinct LoRA modules for Traditional Art", "authors": ["Jaehyun Lee", "Wonhark Park", "Wonsik Shin", "Hyunho Lee", "Hyoung Min Na", "Nojun Kwak"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11986v1", "summary": "Diffusion-based text-to-image models have achieved remarkable results in\nsynthesizing diverse images from text prompts and can capture specific artistic\nstyles via style personalization. However, their entangled latent space and\nlack of smooth interpolation make it difficult to apply distinct painting\ntechniques in a controlled, regional manner, often causing one style to\ndominate. To overcome this, we propose a zero-shot diffusion pipeline that\nnaturally blends multiple styles by performing style composition on the\ndenoised latents predicted during the flow-matching denoising process of\nseparately trained, style-specialized models. We leverage the fact that\nlower-noise latents carry stronger stylistic information and fuse them across\nheterogeneous diffusion pipelines using spatial masks, enabling precise,\nregion-specific style control. This mechanism preserves the fidelity of each\nindividual style while allowing user-guided mixing. Furthermore, to ensure\nstructural coherence across different models, we incorporate depth-map\nconditioning via ControlNet into the diffusion framework. Qualitative and\nquantitative experiments demonstrate that our method successfully achieves\nregion-specific style mixing according to the given masks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11986v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "传统艺术中不同LoRA模块的风格组合", "tldr": "本文提出了一种零样本扩散管道，通过在去噪潜在空间中融合不同风格专用模型的去噪潜在信息，并利用空间掩码进行区域性风格控制，从而实现多种艺术风格的自然混合。", "motivation": "现有的基于扩散的文本到图像模型在合成图像方面表现出色，但其纠缠的潜在空间和缺乏平滑插值使得难以在受控的区域性方式中应用不同的绘画技术，常常导致一种风格占据主导地位。", "method": "我们提出了一种零样本扩散管道，通过在单独训练的风格专用模型的流匹配去噪过程中，对预测的去噪潜在信息进行风格组合，从而自然地混合多种风格。该方法利用低噪声潜在信息携带更强风格信息的特点，并使用空间掩码在异构扩散管道中融合它们，实现精确的区域特定风格控制。此外，为了确保不同模型之间的结构连贯性，我们将通过ControlNet进行的深度图条件化纳入扩散框架。", "result": "定性和定量实验表明，我们提出的方法成功地根据给定掩码实现了区域性风格混合。", "conclusion": "本文提出的零样本扩散管道能够有效实现传统艺术中区域特定的风格混合，同时保持每种独立风格的保真度并确保结构连贯性。", "translation": "基于扩散的文本到图像模型在从文本提示合成多样化图像方面取得了显著成果，并且可以通过风格个性化来捕捉特定的艺术风格。然而，它们纠缠的潜在空间和缺乏平滑插值使得难以在受控的区域性方式中应用不同的绘画技术，常常导致一种风格占据主导地位。为了克服这个问题，我们提出了一种零样本扩散管道，通过在单独训练的风格专用模型的流匹配去噪过程中，对预测的去噪潜在信息进行风格组合，从而自然地混合多种风格。我们利用低噪声潜在信息携带更强风格信息的特点，并使用空间掩码在异构扩散管道中融合它们，从而实现精确的区域特定风格控制。这种机制在允许用户引导混合的同时，保留了每种独立风格的保真度。此外，为了确保不同模型之间的结构连贯性，我们将通过ControlNet进行的深度图条件化纳入扩散框架。定性和定量实验表明，我们提出的方法成功地根据给定掩码实现了区域性风格混合。", "summary": "本文提出了一种新颖的零样本扩散管道，用于解决现有扩散模型在区域性应用多种艺术风格时的局限性。该方法通过在不同风格专用模型的去噪潜在空间中进行风格组合，并利用空间掩码实现精确的区域风格控制。此外，为了保持结构一致性，模型还结合了ControlNet的深度图条件化。实验证明，该方法能有效实现区域特定的风格混合。", "keywords": "扩散模型, 风格组合, 区域风格控制, 传统艺术, ControlNet", "comments": "该论文提出了一种创新的方法来解决扩散模型在多风格融合方面的挑战，特别是通过利用潜在空间中的风格信息强度和空间掩码实现区域控制，这对于传统艺术的风格合成具有重要意义。结合ControlNet确保结构连贯性也增强了方法的实用性。"}}
{"id": "2507.12305", "title": "PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning", "authors": ["M. Anwar Ma'sum", "Mahardhika Pratama", "Savitha Ramasamy", "Lin Liu", "Habibullah Habibullah", "Ryszard Kowalczyk"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.12305v1", "summary": "The data privacy constraint in online continual learning (OCL), where the\ndata can be seen only once, complicates the catastrophic forgetting problem in\nstreaming data. A common approach applied by the current SOTAs in OCL is with\nthe use of memory saving exemplars or features from previous classes to be\nreplayed in the current task. On the other hand, the prompt-based approach\nperforms excellently in continual learning but with the cost of a growing\nnumber of trainable parameters. The first approach may not be applicable in\npractice due to data openness policy, while the second approach has the issue\nof throughput associated with the streaming data. In this study, we propose a\nnovel prompt-based method for online continual learning that includes 4 main\ncomponents: (1) single light-weight prompt generator as a general knowledge,\n(2) trainable scaler-and-shifter as specific knowledge, (3) pre-trained model\n(PTM) generalization preserving, and (4) hard-soft updates mechanism. Our\nproposed method achieves significantly higher performance than the current\nSOTAs in CIFAR100, ImageNet-R, ImageNet-A, and CUB dataset. Our complexity\nanalysis shows that our method requires a relatively smaller number of\nparameters and achieves moderate training time, inference time, and throughput.\nFor further study, the source code of our method is available at\nhttps://github.com/anwarmaxsum/PROL.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.12305v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "PROL：通过即时在线学习在流数据中实现无排练持续学习", "tldr": "本文提出了一种名为PROL的新型即时在线持续学习方法，解决了现有方法在数据隐私和参数增长方面的局限性，并在多个数据集上取得了显著优于SOTA的性能，同时保持较低的参数量和适中的训练/推理时间。", "motivation": "在线持续学习（OCL）中的数据隐私限制使得流数据中的灾难性遗忘问题变得复杂。现有OCL的SOTA方法常使用记忆样本或特征进行重放，但这可能因数据开放政策而不可行。基于提示的方法虽然在持续学习中表现出色，但代价是可训练参数数量不断增加，导致流数据处理的吞吐量问题。", "method": "本文提出了一种名为PROL的新型基于提示的在线持续学习方法，包含四个主要组件：1) 作为通用知识的单一轻量级提示生成器；2) 作为特定知识的可训练缩放器和移位器；3) 预训练模型（PTM）泛化保持；4) 硬-软更新机制。", "result": "PROL在CIFAR100、ImageNet-R、ImageNet-A和CUB数据集上取得了显著高于当前SOTA的性能。复杂度分析表明，该方法所需的参数数量相对较少，并实现了适中的训练时间、推理时间和吞吐量。", "conclusion": "PROL通过其创新的组件设计，有效解决了在线持续学习中灾难性遗忘和现有方法局限性（如数据重放限制和参数膨胀）的问题，并在多个基准数据集上展现出优越的性能和效率。", "translation": "在线持续学习（OCL）中的数据隐私限制（数据只能被查看一次）使得流数据中的灾难性遗忘问题变得复杂。当前OCL领域最先进（SOTA）方法通常采用的方法是使用来自先前类别的记忆样本或特征在当前任务中进行重放。另一方面，基于提示的方法在持续学习中表现出色，但代价是可训练参数的数量不断增加。第一种方法由于数据开放政策可能在实践中不适用，而第二种方法存在与流数据相关的吞吐量问题。在本研究中，我们提出了一种新颖的、基于提示的在线持续学习方法，该方法包含4个主要组件：(1) 单一轻量级提示生成器作为通用知识，(2) 可训练的缩放器和移位器作为特定知识，(3) 预训练模型（PTM）泛化保持，以及 (4) 硬-软更新机制。我们提出的方法在CIFAR100、ImageNet-R、ImageNet-A和CUB数据集上取得了显著高于当前SOTA的性能。我们的复杂度分析表明，我们的方法需要相对较少的参数，并实现了适中的训练时间、推理时间和吞吐量。为了进一步研究，我们方法的源代码可在https://github.com/anwarmaxsum/PROL 获取。", "summary": "本文针对在线持续学习（OCL）中数据隐私和现有方法局限性（如重放机制和参数膨胀）问题，提出了一种名为PROL的新型基于提示的方法。PROL通过集成轻量级提示生成器、可训练缩放器和移位器、PTM泛化保持以及硬-软更新机制，实现了无排练的持续学习。实验证明，PROL在多个基准数据集上显著超越了现有SOTA方法，同时保持了较低的参数量和高效的训练与推理时间。", "keywords": "在线持续学习, 即时学习, 无排练, 灾难性遗忘, 流数据", "comments": "本文提出了一种创新的无排练在线持续学习方法PROL，通过结合轻量级提示和精巧的更新机制，有效解决了传统重放机制的数据隐私问题和基于提示方法参数膨胀的问题。其在多个数据集上的优越性能和效率分析，表明了该方法在实际应用中的潜力。"}}
{"id": "2411.02813", "title": "Sparse Orthogonal Parameters Tuning for Continual Learning", "authors": ["Hai-Jian Ke", "Kun-Peng Ning", "Yu-Yang Liu", "Jia-Yu Yao", "Yong-Hong Tian", "Li Yuan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.02813v2", "summary": "Continual learning methods based on pre-trained models (PTM) have recently\ngained attention which adapt to successive downstream tasks without\ncatastrophic forgetting. These methods typically refrain from updating the\npre-trained parameters and instead employ additional adapters, prompts, and\nclassifiers. In this paper, we from a novel perspective investigate the benefit\nof sparse orthogonal parameters for continual learning. We found that merging\nsparse orthogonality of models learned from multiple streaming tasks has great\npotential in addressing catastrophic forgetting. Leveraging this insight, we\npropose a novel yet effective method called SoTU (Sparse Orthogonal Parameters\nTUning). We hypothesize that the effectiveness of SoTU lies in the\ntransformation of knowledge learned from multiple domains into the fusion of\northogonal delta parameters. Experimental evaluations on diverse CL benchmarks\ndemonstrate the effectiveness of the proposed approach. Notably, SoTU achieves\noptimal feature representation for streaming data without necessitating complex\nclassifier designs, making it a Plug-and-Play solution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.02813v2", "cate": "cs.LG", "date": "2024-11-05", "updated": "2025-07-16", "AI": {"title_translation": "持续学习中的稀疏正交参数调优", "tldr": "本文提出SoTU方法，通过稀疏正交参数调优解决持续学习中的灾难性遗忘问题，实现高效的特征表示，且无需复杂分类器设计。", "motivation": "现有的基于预训练模型的持续学习方法通常采用额外的适配器、提示和分类器来适应新任务。本文从一个新颖的视角，探讨了稀疏正交参数对持续学习中解决灾难性遗忘的益处。", "method": "本文提出了一种名为SoTU（Sparse Orthogonal Parameters TUning）的新方法。该方法通过融合从多个流式任务中学到的模型的稀疏正交性，将多领域知识转化为正交增量参数的融合，以解决灾难性遗忘问题。", "result": "在多种持续学习基准上的实验评估证明了所提出方法的有效性。SoTU在无需复杂分类器设计的情况下，为流式数据实现了最佳特征表示，使其成为一个即插即用的解决方案。", "conclusion": "本文证明了将从多个流式任务中学到的模型的稀疏正交性融合，在解决持续学习中的灾难性遗忘方面具有巨大潜力，并提出了有效的SoTU方法，其即插即用的特性使其具有广泛应用前景。", "translation": "基于预训练模型（PTM）的持续学习方法最近受到关注，它们在不发生灾难性遗忘的情况下适应后续下游任务。这些方法通常避免更新预训练参数，而是采用额外的适配器、提示和分类器。在本文中，我们从一个新颖的视角研究了稀疏正交参数对持续学习的益处。我们发现，将从多个流式任务学习到的模型的稀疏正交性进行融合，在解决灾难性遗忘方面具有巨大潜力。利用这一见解，我们提出了一种新颖而有效的方法，名为SoTU（稀疏正交参数调优）。我们假设SoTU的有效性在于将从多个领域学到的知识转化为正交增量参数的融合。在各种持续学习基准上的实验评估证明了所提出方法的有效性。值得注意的是，SoTU在无需复杂分类器设计的情况下，为流式数据实现了最佳特征表示，使其成为一个即插即用的解决方案。", "summary": "本文提出了一种名为SoTU（稀疏正交参数调优）的新型持续学习方法，旨在解决基于预训练模型的持续学习中的灾难性遗忘问题。该方法的核心思想是利用从多个流式任务中学到的模型的稀疏正交性进行融合，将多领域知识转化为正交增量参数的融合。实验结果表明，SoTU在多个持续学习基准上表现出有效性，并且能够在不依赖复杂分类器设计的情况下，为流式数据提供最佳特征表示，体现了其即插即用的优势。", "keywords": "持续学习, 稀疏正交参数, 灾难性遗忘, 预训练模型, SoTU", "comments": "该论文提出了一种新颖的视角，即利用稀疏正交参数来解决持续学习中的灾难性遗忘问题，这与现有主流的适配器/提示方法有所不同。其创新之处在于利用模型间参数的正交性融合知识，并实现了即插即用的特性，简化了持续学习的部署，具有重要的实践意义。未来可以进一步探讨其在更大数据集和复杂任务上的泛化能力。"}}
{"id": "2507.08218", "title": "Simple Mechanistic Explanations for Out-Of-Context Reasoning", "authors": ["Atticus Wang", "Joshua Engels", "Oliver Clive-Griffin", "Senthooran Rajamanoharan", "Neel Nanda"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ICML 2025 Workshop R2-FM", "url": "http://arxiv.org/abs/2507.08218v2", "summary": "Out-of-context reasoning (OOCR) is a phenomenon in which fine-tuned LLMs\nexhibit surprisingly deep out-of-distribution generalization. Rather than\nlearning shallow heuristics, they implicitly internalize and act on the\nconsequences of observations scattered throughout the fine-tuning data. In this\nwork, we investigate this phenomenon mechanistically and find that many\ninstances of OOCR in the literature have a simple explanation: the LoRA\nfine-tuning essentially adds a constant steering vector, steering the model\ntowards a general concept. This improves performance on the fine-tuning task\nand in many other concept-related domains, causing the surprising\ngeneralization. Moreover, we can directly train steering vectors for these\ntasks from scratch, which also induces OOCR. We find that our results hold even\nfor a task that seems like it must involve conditional behavior (model\nbackdoors); it turns out that unconditionally adding a steering vector is\nsufficient. Overall, our work presents one explanation of what gets learned\nduring fine-tuning for OOCR tasks, contributing to the key question of why LLMs\ncan reason out of context, an advanced capability that is highly relevant to\ntheir safe and reliable deployment.", "comment": "ICML 2025 Workshop R2-FM", "pdf_url": "http://arxiv.org/pdf/2507.08218v2", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-16", "AI": {"title_translation": "离上下文推理的简单机制解释", "tldr": "研究发现，LLM的离上下文推理（OOCR）现象可以通过LoRA微调添加的恒定引导向量来简单解释，该向量将模型引导至一个通用概念，从而实现出乎意料的泛化。", "motivation": "了解大型语言模型（LLMs）在微调后表现出的离上下文推理（OOCR）现象，即它们如何通过内化分散在微调数据中的观察结果来展现出乎意料的域外泛化能力，而不是学习浅层启发式。这对于LLM的安全可靠部署至关重要。", "method": "本文通过机械论方法研究OOCR现象。他们分析了LoRA微调对模型行为的影响，并发现它本质上是添加了一个恒定的引导向量。此外，他们还尝试从头开始直接训练这些引导向量，以观察其是否也能诱导OOCR。", "result": "研究发现，文献中许多OOCR实例的简单解释是：LoRA微调本质上添加了一个恒定的引导向量，将模型引导至一个通用概念，从而在微调任务和许多其他概念相关领域提高了性能，导致了令人惊讶的泛化。此外，他们可以直接从头开始训练这些任务的引导向量，这同样能诱导OOCR。结果甚至适用于看似必须涉及条件行为的任务（模型后门），发现无条件地添加引导向量就足够了。", "conclusion": "本文提出了对OOCR任务微调过程中所学内容的解释，为“为什么LLMs能够进行离上下文推理”这一关键问题提供了贡献，这是LLM高级能力中与安全可靠部署高度相关的一项。", "translation": "离上下文推理（OOCR）是一种现象，其中经过微调的大型语言模型（LLMs）表现出令人惊讶的深层分布外泛化能力。它们不是学习浅层启发式，而是隐含地内化并根据分散在微调数据中的观察结果的后果行事。在这项工作中，我们以机械论的方式研究了这种现象，发现文献中许多OOCR实例都有一个简单的解释：LoRA微调本质上添加了一个恒定的引导向量，将模型引导至一个通用概念。这提高了微调任务和许多其他与概念相关的领域的性能，从而导致了令人惊讶的泛化。此外，我们可以从头开始直接训练这些任务的引导向量，这同样也能诱导OOCR。我们发现，即使对于一个似乎必须涉及条件行为的任务（模型后门），我们的结果也成立；事实证明，无条件地添加引导向量就足够了。总的来说，我们的工作解释了OOCR任务微调期间所学到的一些内容，为“为什么LLMs能够进行离上下文推理”这一关键问题做出了贡献，这是一项与LLM安全可靠部署高度相关的高级能力。", "summary": "本文对大型语言模型（LLMs）的离上下文推理（OOCR）现象进行了机械论研究。研究发现，LoRA微调通过添加一个恒定的引导向量，将模型导向一个通用概念，从而解释了OOCR的泛化能力。即使直接训练此类引导向量也能诱导OOCR，且该机制对条件行为任务也适用。这为理解LLMs的OOCR能力提供了简单解释，有助于其安全部署。", "keywords": "离上下文推理, 大型语言模型, LoRA微调, 引导向量, 泛化", "comments": "这项工作提出了一个关于LLM离上下文推理（OOCR）现象的简洁且具有洞察力的机械论解释。其创新之处在于将LoRA微调与一个“恒定引导向量”的概念联系起来，这简化了对复杂泛化行为的理解。通过证明即使是看似需要条件行为的任务也能通过无条件引导向量解决，该研究挑战了现有的一些假设。这对于理解LLM的内部工作机制及其可靠性具有重要意义，尤其是在其安全部署方面。"}}
{"id": "2411.11192", "title": "Robot Metabolism: Towards machines that can grow by consuming other machines", "authors": ["Philippe Martin Wyder", "Riyaan Bakhda", "Meiqi Zhao", "Quinn A. Booth", "Matthew E. Modi", "Andrew Song", "Simon Kang", "Jiahao Wu", "Priya Patel", "Robert T. Kasumi", "David Yi", "Nihar Niraj Garg", "Pranav Jhunjhunwala", "Siddharth Bhutoria", "Evan H. Tong", "Yuhang Hu", "Judah Goldfeder", "Omer Mustel", "Donghan Kim", "Hod Lipson"], "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY", "70-01, 68-02", "I.6; H.4; H.m; I.m; B.m"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Manuscript combined with Supplementary Materials File for arXiv submission", "url": "http://arxiv.org/abs/2411.11192v2", "summary": "Biological lifeforms can heal, grow, adapt, and reproduce -- abilities\nessential for sustained survival and development. In contrast, robots today are\nprimarily monolithic machines with limited ability to self-repair, physically\ndevelop, or incorporate material from their environments. While robot minds\nrapidly evolve new behaviors through AI, their bodies remain closed systems,\nunable to systematically integrate material to grow or heal. We argue that\nopen-ended physical adaptation is only possible when robots are designed using\na small repertoire of simple modules. This allows machines to mechanically\nadapt by consuming parts from other machines or their surroundings and shed\nbroken components. We demonstrate this principle on a truss modular robot\nplatform. We show how robots can grow bigger, faster, and more capable by\nconsuming materials from their environment and other robots. We suggest that\nmachine metabolic processes like those demonstrated here will be an essential\npart of any sustained future robot ecology.", "comment": "Manuscript combined with Supplementary Materials File for arXiv\n  submission", "pdf_url": "http://arxiv.org/pdf/2411.11192v2", "cate": "cs.RO", "date": "2024-11-17", "updated": "2025-07-16", "AI": {"title_translation": "机器人新陈代谢：迈向能通过消耗其他机器而生长的机器", "tldr": "提出一种机器人新陈代谢的概念，使机器人能通过消耗环境中的材料或其它机器的部件来生长、修复和适应，从而克服当前机器人身体的局限性。", "motivation": "现有机器人是整体式机器，自我修复、物理发展或整合环境材料的能力有限，而生物生命形式具备这些能力。机器人身体作为封闭系统，无法像其AI大脑那样开放式适应和发展。", "method": "提出设计机器人时使用少量简单的模块，使其能够通过消耗其他机器或环境中的部件进行机械适应并丢弃损坏的组件。在桁架模块化机器人平台上进行了演示。", "result": "演示了机器人如何通过消耗环境和其它机器的材料变得更大、更快、能力更强。", "conclusion": "建议机器代谢过程（如本文所示）将是未来持续机器人生态系统的重要组成部分。", "translation": "生物生命形式能够愈合、生长、适应和繁殖——这些能力对于持续生存和发展至关重要。相比之下，当今的机器人主要是整体式机器，自我修复、物理发展或整合环境材料的能力有限。虽然机器人大脑通过人工智能迅速发展出新的行为，但它们的身体仍然是封闭系统，无法系统地整合材料以生长或愈合。我们认为，只有当机器人使用少量简单的模块进行设计时，才能实现开放式的物理适应。这使得机器能够通过消耗其他机器或其周围的部件来进行机械适应，并丢弃损坏的组件。我们在一个桁架模块化机器人平台上展示了这一原理。我们展示了机器人如何通过消耗环境和其它机器的材料变得更大、更快、能力更强。我们认为，像本文中展示的机器代谢过程将是未来任何持续机器人生态系统的重要组成部分。", "summary": "本文提出了“机器人新陈代谢”的概念，旨在解决当前机器人身体作为封闭系统无法自我修复、生长和适应环境材料的问题。研究者认为，通过使用简单的模块化设计，机器人可以像生物一样消耗环境中的材料或其它机器的部件进行物理适应，从而实现生长、增强能力和修复。在桁架模块化机器人平台上的演示验证了这一原理，并指出这种机器代谢过程对未来的机器人生态系统至关重要。", "keywords": "机器人新陈代谢, 模块化机器人, 自适应机器人, 机器人生长, 机器人生态系统", "comments": "这篇论文的创新点在于将生物学的“新陈代谢”概念引入到机器人设计中，突破了传统机器人作为封闭系统的限制。其重要性在于为机器人实现开放式物理适应、自我修复和持续发展提供了新的视角和可行路径，对于构建未来更具韧性和自适应能力的机器人系统具有深远意义。"}}
{"id": "2507.12377", "title": "Deconstructing Implicit Beliefs in Visual Data Journalism: Unstable Meanings Behind Data as Truth & Design for Insight", "authors": ["Ke Er Amy Zhang", "Jodie Jenkinson", "Laura Garrison"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      11 pages, 5 figures, accepted to IEEE VIS 2025 Conference", "url": "http://arxiv.org/abs/2507.12377v1", "summary": "We conduct a deconstructive reading of a qualitative interview study with 17\nvisual data journalists from newsrooms across the globe. We borrow a\ndeconstruction approach from literary critique to explore the instability of\nmeaning in language and reveal implicit beliefs in words and ideas. Through our\nanalysis we surface two sets of opposing implicit beliefs in visual data\njournalism: objectivity/subjectivity and humanism/mechanism. We contextualize\nthese beliefs through a genealogical analysis, which brings deconstruction\ntheory into practice by providing a historic backdrop for these opposing\nperspectives. Our analysis shows that these beliefs held within visual data\njournalism are not self-enclosed but rather a product of external societal\nforces and paradigm shifts over time. Through this work, we demonstrate how\nthinking with critical theories such as deconstruction and genealogy can\nreframe \"success\" in visual data storytelling and diversify visualization\nresearch outcomes. These efforts push the ways in which we as researchers\nproduce domain knowledge to examine the sociotechnical issues of today's values\ntowards datafication and data visualization.", "comment": "11 pages, 5 figures, accepted to IEEE VIS 2025 Conference", "pdf_url": "http://arxiv.org/pdf/2507.12377v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "解构视觉数据新闻中的隐含信念：数据即真相背后不稳定的意义与洞察力设计", "tldr": "本文解构了视觉数据新闻中的隐含信念，揭示了由社会力量塑造的对立观点（客观性/主观性、人文主义/机械主义），并主张利用批判性理论重新定义成功并使研究多样化。", "motivation": "通过解构一项定性访谈研究，探索语言意义的不稳定性，揭示视觉数据新闻中的隐含信念。同时，旨在展示批判性理论如何能够重新定义“成功”并使可视化研究成果多样化。", "method": "对一项涉及17位视觉数据记者的定性访谈研究进行了“解构性解读”。借鉴文学批评中的解构方法，并运用谱系分析来情境化所发现的信念。", "result": "揭示了视觉数据新闻中两组对立的隐含信念：客观性/主观性和人文主义/机械主义。分析表明这些信念并非自我封闭，而是外部社会力量和随时间推移的范式转变的产物。", "conclusion": "批判性理论（如解构和谱系学）能够重新定义视觉数据叙事中的“成功”，并使可视化研究成果多样化，促使研究人员审视与数据化和数据可视化相关的社会技术问题。", "translation": "我们对一项针对全球17位视觉数据记者进行的定性访谈研究进行了解构性解读。我们借鉴文学批评中的解构方法，探索语言意义的不稳定性，揭示词语和思想中隐含的信念。通过我们的分析，我们揭示了视觉数据新闻中两组对立的隐含信念：客观性/主观性和人文主义/机械主义。我们通过谱系分析来情境化这些信念，这通过为这些对立的观点提供历史背景，将解构理论付诸实践。我们的分析表明，视觉数据新闻中持有的这些信念并非自我封闭，而是外部社会力量和随时间推移的范式转变的产物。通过这项工作，我们展示了批判性理论（如解构和谱系学）如何能够重新定义视觉数据叙事中的“成功”，并使可视化研究成果多样化。这些努力推动了我们作为研究人员生产领域知识的方式，以审视当今对数据化和数据可视化的价值观所产生的社会技术问题。", "summary": "本文对一项针对17位视觉数据记者的定性研究进行了批判性的解构和谱系分析。研究揭示了视觉数据新闻中两对隐含的对立信念——客观性/主观性和人文主义/机械主义，并阐明了这些信念源于外部社会影响。该工作主张运用批判性理论重新思考数据叙事中的成功，并拓宽可视化研究范围，鼓励审视与数据相关的社会技术问题。", "keywords": "视觉数据新闻, 解构, 隐含信念, 谱系学, 社会技术问题", "comments": "本文创新性地将文学解构和谱系分析应用于视觉数据新闻领域，提供了一个批判性视角来理解超越表层实践的潜在信念。它强调了批判性理论在重新评估数据叙事中“成功”的重要性，并推动更细致、更具社会意识的数据可视化研究。其对社会技术问题以及社会力量对数据实践影响的关注尤其富有洞察力。"}}
{"id": "2506.23210", "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model", "authors": ["Taehwan Yoon", "Bongjun Choi"], "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages,14 equation, 4 figure, 1table", "url": "http://arxiv.org/abs/2506.23210v2", "summary": "Federated learning(FL) is used for distributed scenarios to train artificial\nintelligence(AI) models while ensuring users' privacy. In federated learning\nscenario, the server generally never knows about users' data. This type of\nconcept makes the AI training process efficient in terms of data privacy.\nHowever, regarding model performance, federated AI models may not sufficiently\nsatisfy AI users' expectations. Furthermore, AI users have a wide range of\ndifferent needs. It is not easy to satisfy the whole users needs. These types\nof issues can be addressed through AI model optimization, fine-tuning, or\npersonalization to achieve optimal model performance. To address model\noptimization challenges, we propose reference model-based federated learning\nfor optimal fine-tuning, which overcomes catastrophic forgetting in each round.\nThis method is derived from Bayesian parameter-efficient transfer learning,\nwhich includes an optimal proximal term and utilizes a reference model that\nincorporates previous model parameters. As a result, this method achieves both\nhigh model performance and clients' low computing cost.", "comment": "6 pages,14 equation, 4 figure, 1table", "pdf_url": "http://arxiv.org/pdf/2506.23210v2", "cate": "cs.LG", "date": "2025-06-29", "updated": "2025-07-16", "AI": {"title_translation": "FedRef：基于参考模型的通信高效贝叶斯微调", "tldr": "本文提出FedRef，一种基于参考模型的联邦学习微调方法，通过贝叶斯参数高效迁移学习克服灾难性遗忘，实现高性能和低计算成本。", "motivation": "联邦学习在保护用户隐私的同时训练AI模型，但存在模型性能可能不满足用户期望以及难以满足多样化用户需求的问题。", "method": "提出FedRef，一种基于参考模型的联邦学习微调方法，该方法源于贝叶斯参数高效迁移学习，包含一个最优的近端项，并利用一个包含先前模型参数的参考模型。", "result": "实现了高模型性能和客户端低计算成本。", "conclusion": "FedRef通过引入参考模型和贝叶斯参数高效迁移学习，有效解决了联邦学习中模型性能不足和灾难性遗忘的问题，同时优化了通信效率和客户端计算成本。", "translation": "联邦学习（FL）用于分布式场景，在确保用户隐私的同时训练人工智能（AI）模型。在联邦学习场景中，服务器通常永远不知道用户的数据。这种概念使得AI训练过程在数据隐私方面是高效的。然而，在模型性能方面，联邦AI模型可能无法充分满足AI用户的期望。此外，AI用户具有广泛的不同需求。满足所有用户的需求并不容易。这些类型的问题可以通过AI模型优化、微调或个性化来解决，以实现最佳模型性能。为了解决模型优化挑战，我们提出了基于参考模型的联邦学习，用于最优微调，该方法克服了每一轮中的灾难性遗忘。这种方法源自贝叶斯参数高效迁移学习，其中包括一个最优的近端项，并利用了一个包含先前模型参数的参考模型。因此，该方法实现了高模型性能和客户端的低计算成本。", "summary": "本文提出FedRef，一种用于联邦学习的通信高效贝叶斯微调方法。针对联邦学习中模型性能可能不足以满足用户期望及多样化需求的问题，FedRef基于贝叶斯参数高效迁移学习，引入最优近端项和参考模型（包含先前模型参数），以克服微调过程中的灾难性遗忘。实验结果表明，该方法在提高模型性能的同时，显著降低了客户端的计算成本。", "keywords": "联邦学习, 贝叶斯微调, 参考模型, 通信效率, 灾难性遗忘", "comments": "这篇论文通过引入“参考模型”和结合“贝叶斯参数高效迁移学习”来解决联邦学习中的模型性能和灾难性遗忘问题，具有创新性。它关注了联邦学习在实际应用中面临的关键挑战，即如何在保护隐私的同时提升模型实用性和个性化能力。通过优化通信效率和客户端计算成本，该方法有望在资源受限的分布式环境中发挥重要作用。"}}
{"id": "2507.12157", "title": "Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation", "authors": ["Edwin Arkel Rios", "Fernando Mikael", "Oswin Gosal", "Femiloye Oyerinde", "Hao-Chun Liang", "Bo-Cheng Lai", "Min-Chun Hu"], "categories": ["cs.CV", "I.2; I.4"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Main: 10 pages, 2 figures, 4 tables", "url": "http://arxiv.org/abs/2507.12157v1", "summary": "Fine-grained image recognition (FGIR) aims to distinguish visually similar\nsub-categories within a broader class, such as identifying bird species. While\nmost existing FGIR methods rely on backbones pretrained on large-scale datasets\nlike ImageNet, this dependence limits adaptability to resource-constrained\nenvironments and hinders the development of task-specific architectures\ntailored to the unique challenges of FGIR.\n  In this work, we challenge the conventional reliance on pretrained models by\ndemonstrating that high-performance FGIR systems can be trained entirely from\nscratch. We introduce a novel training framework, TGDA, that integrates\ndata-aware augmentation with weak supervision via a fine-grained-aware teacher\nmodel, implemented through knowledge distillation. This framework unlocks the\ndesign of task-specific and hardware-aware architectures, including LRNets for\nlow-resolution FGIR and ViTFS, a family of Vision Transformers optimized for\nefficient inference.\n  Extensive experiments across three FGIR benchmarks over diverse settings\ninvolving low-resolution and high-resolution inputs show that our method\nconsistently matches or surpasses state-of-the-art pretrained counterparts. In\nparticular, in the low-resolution setting, LRNets trained with TGDA improve\naccuracy by up to 23\\% over prior methods while requiring up to 20.6x less\nparameters, lower FLOPs, and significantly less training data. Similarly,\nViTFS-T can match the performance of a ViT B-16 pretrained on ImageNet-21k\nwhile using 15.3x fewer trainable parameters and requiring orders of magnitudes\nless data. These results highlight TGDA's potential as an adaptable alternative\nto pretraining, paving the way for more efficient fine-grained vision systems.", "comment": "Main: 10 pages, 2 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.12157v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "从零开始的细粒度图像识别：教师引导的数据增强", "tldr": "本文提出了一种名为TGDA的新训练框架，通过教师引导的数据增强，实现了从零开始训练高性能细粒度图像识别（FGIR）系统，超越或匹配了现有预训练模型，并显著降低了资源需求。", "motivation": "大多数现有的细粒度图像识别（FGIR）方法依赖于在大规模数据集上预训练的骨干网络，这种依赖性限制了在资源受限环境中的适应性，并阻碍了针对FGIR独特挑战的任务特定架构的开发。", "method": "本文引入了一种名为TGDA的新型训练框架，该框架通过细粒度感知教师模型（通过知识蒸馏实现）将数据感知增强与弱监督相结合。该框架解锁了任务特定和硬件感知架构的设计，包括用于低分辨率FGIR的LRNets和为高效推理优化的Vision Transformers系列ViTFS。", "result": "在低分辨率设置下，使用TGDA训练的LRNets比现有方法提高了高达23%的准确率，同时所需参数减少了20.6倍，FLOPs更低，训练数据显著减少。ViTFS-T在性能上可以与ImageNet-21k上预训练的ViT B-16相媲美，同时使用少15.3倍的可训练参数，并需要少几个数量级的数据。", "conclusion": "TGDA作为预训练的一种适应性替代方案，为更高效的细粒度视觉系统铺平了道路。", "translation": "细粒度图像识别（FGIR）旨在区分更广泛类别中视觉上相似的子类别，例如识别鸟类。虽然大多数现有FGIR方法依赖于在ImageNet等大规模数据集上预训练的骨干网络，但这种依赖性限制了在资源受限环境中的适应性，并阻碍了针对FGIR独特挑战的任务特定架构的开发。\n在这项工作中，我们通过证明可以完全从零开始训练高性能FGIR系统，挑战了对预训练模型的传统依赖。我们引入了一种新颖的训练框架TGDA，它通过细粒度感知教师模型（通过知识蒸馏实现）将数据感知增强与弱监督相结合。该框架解锁了任务特定和硬件感知架构的设计，包括用于低分辨率FGIR的LRNets和为高效推理优化的Vision Transformers系列ViTFS。\n在涉及低分辨率和高分辨率输入的不同设置下，对三个FGIR基准进行了广泛实验，结果表明我们的方法始终匹配或超越了最先进的预训练对应方法。特别是，在低分辨率设置中，使用TGDA训练的LRNets比现有方法提高了高达23%的准确率，同时所需参数减少了20.6倍，FLOPs更低，训练数据显著减少。同样，ViTFS-T可以在性能上与ImageNet-21k上预训练的ViT B-16相媲美，同时使用少15.3倍的可训练参数，并需要少几个数量级的数据。这些结果突出了TGDA作为预训练的一种适应性替代方案的潜力，为更高效的细粒度视觉系统铺平了道路。", "summary": "本文针对细粒度图像识别（FGIR）中对预训练模型的过度依赖问题，提出了一种名为TGDA的新型训练框架，旨在实现从零开始训练高性能FGIR系统。TGDA通过结合数据感知增强和基于知识蒸馏的教师模型弱监督，克服了资源限制并支持任务特定架构设计。实验证明，TGDA在多个FGIR基准测试中表现出色，尤其在低分辨率场景下，其训练的LRNets和ViTFS模型在大幅减少参数、FLOPs和数据需求的同时，性能可匹敌甚至超越现有预训练的最先进方法，为构建高效且适应性强的细粒度视觉系统提供了新途径。", "keywords": "细粒度图像识别, 数据增强, 知识蒸馏, 从零开始训练, 资源效率", "comments": "本文的创新之处在于挑战了细粒度图像识别领域对大规模预训练模型的传统依赖，提出了一种从零开始训练的高效替代方案。TGDA框架通过教师引导的数据增强和知识蒸馏，实现了在资源受限环境下部署高性能FGIR系统的可能性，并促进了任务特定轻量级架构（如LRNets和ViTFS）的设计。这对于推动FGIR在边缘设备和数据稀缺场景中的应用具有重要意义。"}}
{"id": "2507.11049", "title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection", "authors": ["Dahyun Lee", "Jonghyeon Choi", "Jiyoung Han", "Kunwoo Park"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint. 24 pages", "url": "http://arxiv.org/abs/2507.11049v2", "summary": "As online news consumption grows, personalized recommendation systems have\nbecome integral to digital journalism. However, these systems risk reinforcing\nfilter bubbles and political polarization by failing to incorporate diverse\nperspectives. Stance detection -- identifying a text's position on a target --\ncan help mitigate this by enabling viewpoint-aware recommendations and\ndata-driven analyses of media bias. Yet, existing stance detection research\nremains largely limited to short texts and high-resource languages. To address\nthese gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for\narticle-level stance detection, comprising 2,000 news articles with\narticle-level and 19,650 segment-level stance annotations across 47 societal\nissues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided\n\\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that\nemploys a language model agent to predict the stances of key structural\nsegments (e.g., leads, quotes), which are then aggregated to infer the overall\narticle stance. Experiments show that \\textsc{JoA-ICL} outperforms existing\nstance detection methods, highlighting the benefits of segment-level agency in\ncapturing the overall position of long-form news articles. Two case studies\nfurther demonstrate its broader utility in promoting viewpoint diversity in\nnews recommendations and uncovering patterns of media bias.", "comment": "Preprint. 24 pages", "pdf_url": "http://arxiv.org/pdf/2507.11049v2", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "新闻学指导的代理式上下文学习用于新闻立场检测", "tldr": "该研究引入了首个韩语文章级立场检测数据集\\textsc{K-News-Stance}，并提出了\\textsc{JoA-ICL}框架，通过代理式上下文学习预测新闻文章关键段落的立场，然后聚合以推断整体文章立场。实验表明\\textsc{JoA-ICL}优于现有方法，有助于促进新闻推荐中的观点多样性并揭示媒体偏见。", "motivation": "随着在线新闻消费的增长，个性化推荐系统面临强化过滤气泡和政治两极分化的风险，因为它们未能整合多样化的视角。立场检测可以帮助缓解这一问题，但现有研究主要局限于短文本和高资源语言。", "method": "研究引入了\\textsc{K-News-Stance}，这是首个用于文章级立场检测的韩语数据集，包含2,000篇新闻文章，具有文章级和19,650个段落级立场标注，涵盖47个社会议题。同时提出了\\textsc{JoA-ICL}（新闻学指导的代理式上下文学习）框架，该框架利用语言模型代理预测关键结构段落（如导语、引语）的立场，然后聚合这些立场以推断整体文章立场。", "result": "实验表明，\\textsc{JoA-ICL}优于现有立场检测方法，突出了段落级代理在捕捉长篇新闻文章整体立场方面的优势。两项案例研究进一步证明了其在促进新闻推荐中的观点多样性以及揭示媒体偏见模式方面的更广泛效用。", "conclusion": "该研究通过引入首个韩语文章级立场检测数据集\\textsc{K-News-Stance}和创新的\\textsc{JoA-ICL}框架，有效解决了现有立场检测在长文本和低资源语言方面的局限性，为观点感知型推荐系统和媒体偏见分析提供了有力的工具。", "translation": "随着在线新闻消费的增长，个性化推荐系统已成为数字新闻不可或缺的一部分。然而，这些系统未能整合多样化的视角，存在强化过滤气泡和政治两极分化的风险。立场检测——识别文本对目标的立场——可以通过实现观点感知型推荐和媒体偏见的数据驱动分析来帮助缓解这一问题。然而，现有立场检测研究仍主要局限于短文本和高资源语言。为了解决这些空白，我们引入了\\textsc{K-News-Stance}，这是首个用于文章级立场检测的韩语数据集，包含2,000篇新闻文章，具有文章级和19,650个段落级立场标注，涵盖47个社会议题。我们还提出了\\textsc{JoA-ICL}，一个新闻学指导的代理式上下文学习框架，该框架利用语言模型代理预测关键结构段落（例如导语、引语）的立场，然后聚合这些立场以推断整体文章立场。实验表明，\\textsc{JoA-ICL}优于现有立场检测方法，突出了段落级代理在捕捉长篇新闻文章整体立场方面的优势。两项案例研究进一步证明了其在促进新闻推荐中的观点多样性以及揭示媒体偏见模式方面的更广泛效用。", "summary": "本研究旨在解决现有新闻立场检测在长文本和低资源语言上的局限性，并缓解在线新闻消费带来的过滤气泡和政治两极分化问题。为此，研究首次构建了韩语文章级立场检测数据集\\textsc{K-News-Stance}，包含大量新闻文章及其文章级和段落级立场标注。在此基础上，提出了一种新颖的\\textsc{JoA-ICL}框架，该框架利用语言模型代理对新闻文章的关键结构段落进行立场预测，并通过聚合这些段落立场来推断文章整体立场。实验结果表明，\\textsc{JoA-ICL}在立场检测任务中表现优异，超越了现有方法，尤其在处理长篇新闻文章时展现出段落级代理的有效性。此外，案例研究进一步验证了该框架在促进新闻推荐多样性和揭示媒体偏见方面的实际应用价值。", "keywords": "立场检测, 上下文学习, 新闻, 代理, 媒体偏见", "comments": "该论文的创新点在于构建了首个韩语文章级立场检测数据集，并提出了一种新颖的代理式上下文学习框架（\\textsc{JoA-ICL}），通过分析文章关键段落来推断整体立场。其重要性在于解决了现有立场检测研究在长文本和低资源语言上的局限性，并为缓解在线新闻的过滤气泡和媒体偏见提供了有效工具。文章中未明确提及局限性。"}}
{"id": "2501.19034", "title": "XRF V2: A Dataset for Action Summarization with Wi-Fi Signals, and IMUs in Phones, Watches, Earbuds, and Glasses", "authors": ["Bo Lan", "Pei Li", "Jiaxi Yin", "Yunpeng Song", "Ge Wang", "Han Ding", "Jinsong Han", "Fei Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted by ACM IMWUT/UBICOMP 2025", "url": "http://arxiv.org/abs/2501.19034v2", "summary": "Human Action Recognition (HAR) plays a crucial role in applications such as\nhealth monitoring, smart home automation, and human-computer interaction. While\nHAR has been extensively studied, action summarization using Wi-Fi and IMU\nsignals in smart-home environments , which involves identifying and summarizing\ncontinuous actions, remains an emerging task. This paper introduces the novel\nXRF V2 dataset, designed for indoor daily activity Temporal Action Localization\n(TAL) and action summarization. XRF V2 integrates multimodal data from Wi-Fi\nsignals, IMU sensors (smartphones, smartwatches, headphones, and smart\nglasses), and synchronized video recordings, offering a diverse collection of\nindoor activities from 16 volunteers across three distinct environments. To\ntackle TAL and action summarization, we propose the XRFMamba neural network,\nwhich excels at capturing long-term dependencies in untrimmed sensory sequences\nand achieves the best performance with an average mAP of 78.74, outperforming\nthe recent WiFiTAD by 5.49 points in mAP@avg while using 35% fewer parameters.\nIn action summarization, we introduce a new metric, Response Meaning\nConsistency (RMC), to evaluate action summarization performance. And it\nachieves an average Response Meaning Consistency (mRMC) of 0.802. We envision\nXRF V2 as a valuable resource for advancing research in human action\nlocalization, action forecasting, pose estimation, multimodal foundation models\npre-training, synthetic data generation, and more. The data and code are\navailable at https://github.com/aiotgroup/XRFV2.", "comment": "accepted by ACM IMWUT/UBICOMP 2025", "pdf_url": "http://arxiv.org/pdf/2501.19034v2", "cate": "cs.CV", "date": "2025-01-31", "updated": "2025-07-16", "AI": {"title_translation": "XRF V2：一个用于使用手机、手表、耳塞和眼镜中的Wi-Fi信号和IMU进行动作摘要的数据集", "tldr": "XRF V2是一个新数据集，用于使用Wi-Fi和IMU信号进行动作摘要和时间动作定位，并提出了XRFMamba网络，在相关任务上表现优异。", "motivation": "尽管人类行为识别（HAR）已被广泛研究，但在智能家居环境中使用Wi-Fi和IMU信号进行动作摘要（涉及识别和总结连续动作）仍然是一项新兴任务。", "method": "本文引入了新颖的XRF V2数据集，用于室内日常活动的时间动作定位（TAL）和动作摘要。XRF V2整合了来自Wi-Fi信号、IMU传感器（智能手机、智能手表、耳机和智能眼镜）以及同步视频记录的多模态数据。为解决TAL和动作摘要问题，本文提出了XRFMamba神经网络，该网络擅长捕获未裁剪传感器序列中的长期依赖性。此外，还引入了一种新的度量标准——响应意义一致性（RMC）来评估动作摘要性能。", "result": "XRFMamba神经网络在动作摘要任务中表现出色，平均mAP达到78.74，比最近的WiFiTAD高出5.49个mAP@avg点，同时参数减少了35%。在动作摘要中，它实现了0.802的平均响应意义一致性（mRMC）。", "conclusion": "XRF V2被视为一个宝贵的资源，将推动人类动作定位、动作预测、姿态估计、多模态基础模型预训练、合成数据生成等领域的研究进展。", "translation": "人类行为识别（HAR）在健康监测、智能家居自动化和人机交互等应用中扮演着关键角色。尽管HAR已被广泛研究，但在智能家居环境中使用Wi-Fi和IMU信号进行动作摘要，其中涉及识别和总结连续动作，仍然是一项新兴任务。本文引入了新颖的XRF V2数据集，专为室内日常活动的时间动作定位（TAL）和动作摘要而设计。XRF V2整合了来自Wi-Fi信号、IMU传感器（智能手机、智能手表、耳机和智能眼镜）以及同步视频记录的多模态数据，提供了来自16名志愿者在三个不同环境中收集的各种室内活动。为解决TAL和动作摘要问题，我们提出了XRFMamba神经网络，该网络擅长捕获未裁剪传感器序列中的长期依赖性，并以78.74的平均mAP取得了最佳性能，在mAP@avg方面比最近的WiFiTAD高出5.49个点，同时使用的参数减少了35%。在动作摘要中，我们引入了一种新的度量标准——响应意义一致性（RMC），以评估动作摘要性能。它实现了0.802的平均响应意义一致性（mRMC）。我们设想XRF V2将成为推动人类动作定位、动作预测、姿态估计、多模态基础模型预训练、合成数据生成等领域研究的宝贵资源。数据和代码可在https://github.com/aiotgroup/XRFV2获取。", "summary": "本文介绍了XRF V2数据集，这是一个用于室内日常活动时间动作定位（TAL）和动作摘要的新型多模态数据集，整合了Wi-Fi信号、IMU传感器（来自手机、手表、耳塞、眼镜）和视频记录。为处理这些任务，论文提出了XRFMamba神经网络，该网络在TAL任务上表现优异，并引入了新的动作摘要评估指标RMC。XRF V2数据集和相关方法旨在推动人类动作分析领域的研究。", "keywords": "动作摘要, Wi-Fi信号, IMU传感器, XRF V2, 时间动作定位", "comments": "该论文的创新之处在于构建了一个独特的多模态数据集XRF V2，其结合了Wi-Fi信号、IMU传感器和视频数据，以解决新兴的基于传感器信号的动作摘要问题。提出的XRFMamba神经网络在处理长序列数据和实现高性能方面表现出色，并且在参数效率上优于现有模型。引入新的评估指标RMC也对动作摘要领域做出了贡献。XRF V2数据集的发布对于推动未来在动作定位、预测和多模态学习等领域的研究具有重要意义。"}}
{"id": "2507.11880", "title": "A Fast Method for Planning All Optimal Homotopic Configurations for Tethered Robots and Its Extended Applications", "authors": ["Jinyuan Liu", "Minglei Fu", "Ling Shi", "Chenguang Yang", "Wenan Zhang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      37 pages, 33 figures", "url": "http://arxiv.org/abs/2507.11880v1", "summary": "Tethered robots play a pivotal role in specialized environments such as\ndisaster response and underground exploration, where their stable power supply\nand reliable communication offer unparalleled advantages. However, their motion\nplanning is severely constrained by tether length limitations and entanglement\nrisks, posing significant challenges to achieving optimal path planning. To\naddress these challenges, this study introduces CDT-TCS (Convex Dissection\nTopology-based Tethered Configuration Search), a novel algorithm that leverages\nCDT Encoding as a homotopy invariant to represent topological states of paths.\nBy integrating algebraic topology with geometric optimization, CDT-TCS\nefficiently computes the complete set of optimal feasible configurations for\ntethered robots at all positions in 2D environments through a single\ncomputation. Building on this foundation, we further propose three\napplication-specific algorithms: i) CDT-TPP for optimal tethered path planning,\nii) CDT-TMV for multi-goal visiting with tether constraints, iii) CDT-UTPP for\ndistance-optimal path planning of untethered robots. All theoretical results\nand propositions underlying these algorithms are rigorously proven and\nthoroughly discussed in this paper. Extensive simulations demonstrate that the\nproposed algorithms significantly outperform state-of-the-art methods in their\nrespective problem domains. Furthermore, real-world experiments on robotic\nplatforms validate the practicality and engineering value of the proposed\nframework.", "comment": "37 pages, 33 figures", "pdf_url": "http://arxiv.org/pdf/2507.11880v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "系留机器人所有最优同伦配置的快速规划方法及其扩展应用", "tldr": "本文提出了一种名为CDT-TCS的新算法，能快速计算系留机器人在2D环境中所有最优同伦配置。该算法还扩展到系留路径规划、多目标访问和非系留机器人路径规划，并在仿真和实际实验中证明其性能优于现有方法，具有实用价值。", "motivation": "系留机器人在灾难响应和地下探索等特殊环境中具有优势，但其运动规划受限于系绳长度和缠结风险，难以实现最优路径规划。", "method": "本研究引入了CDT-TCS（基于凸分解拓扑的系留配置搜索）算法，该算法利用CDT编码作为同伦不变量来表示路径的拓扑状态。CDT-TCS通过结合代数拓扑与几何优化，能够一次性高效计算出2D环境中系留机器人在所有位置的完整最优可行配置集。在此基础上，进一步提出了三个应用特定算法：i) CDT-TPP用于最优系留路径规划，ii) CDT-TMV用于带系绳约束的多目标访问，iii) CDT-UTPP用于非系留机器人的距离最优路径规划。所有理论结果都经过了严格证明。", "result": "大量的仿真表明，所提出的算法在各自的问题领域中显著优于现有最先进方法。此外，在机器人平台上的实际实验验证了所提出框架的实用性和工程价值。", "conclusion": "该研究提出的CDT-TCS及其扩展算法为系留机器人（以及非系留机器人）的运动规划提供了高效且实用的解决方案，有效克服了系绳约束和缠结风险，并在仿真和实际应用中都展现出优越性能，具有重要的工程价值。", "translation": "系留机器人在灾难响应和地下探索等专业环境中发挥着关键作用，其稳定的电源供应和可靠的通信提供了无与伦比的优势。然而，它们的运动规划受到系绳长度限制和缠结风险的严重约束，对实现最优路径规划构成了重大挑战。为了应对这些挑战，本研究引入了CDT-TCS（基于凸分解拓扑的系留配置搜索）这一新颖算法，该算法利用CDT编码作为同伦不变量来表示路径的拓扑状态。通过将代数拓扑与几何优化相结合，CDT-TCS能够通过一次计算高效地计算出2D环境中系留机器人在所有位置的完整最优可行配置集。在此基础上，我们进一步提出了三种应用特定算法：i) CDT-TPP用于最优系留路径规划，ii) CDT-TMV用于带系绳约束的多目标访问，iii) CDT-UTPP用于非系留机器人的距离最优路径规划。这些算法背后的所有理论结果和命题都在本文中得到了严格的证明和充分的讨论。大量的仿真表明，所提出的算法在各自的问题领域中显著优于最先进的方法。此外，在机器人平台上的实际实验验证了所提出框架的实用性和工程价值。", "summary": "本文提出了一种名为CDT-TCS的快速算法，旨在解决系留机器人在复杂2D环境中的运动规划挑战，特别是系绳长度限制和缠结风险。该算法创新性地结合代数拓扑与几何优化，利用CDT编码作为同伦不变量，能够高效地一次性计算所有最优同伦配置。基于此核心算法，研究进一步开发了CDT-TPP、CDT-TMV和CDT-UTPP，分别应用于系留路径规划、带系绳约束的多目标访问以及非系留机器人距离最优路径规划。仿真和实际实验结果均有力证明了所提算法在性能上的显著优势和在工程实践中的实用价值。", "keywords": "系留机器人, 运动规划, 同伦配置, CDT-TCS, 路径规划", "comments": "这项研究通过引入CDT-TCS算法，为系留机器人的运动规划提供了一个创新的解决方案，特别是在处理系绳约束和缠结风险方面。其核心创新在于利用CDT编码作为同伦不变量，并结合代数拓扑与几何优化，实现了一次性计算所有最优可行配置。论文不仅提出了核心算法，还将其扩展到多个实际应用场景，包括非系留机器人，显示了其通用性和重要性。仿真和实际实验的验证进一步增强了其工程价值。"}}
{"id": "2504.00513", "title": "Leveraging LLMs for User Stories in AI Systems: UStAI Dataset", "authors": ["Asma Yamani", "Malak Baslyman", "Moataz Ahmed"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.00513v3", "summary": "AI systems are gaining widespread adoption across various sectors and\ndomains. Creating high-quality AI system requirements is crucial for aligning\nthe AI system with business goals and consumer values and for social\nresponsibility. However, with the uncertain nature of AI systems and the heavy\nreliance on sensitive data, more research is needed to address the elicitation\nand analysis of AI systems requirements. With the proprietary nature of many AI\nsystems, there is a lack of open-source requirements artifacts and technical\nrequirements documents for AI systems, limiting broader research and\ninvestigation. With Large Language Models (LLMs) emerging as a promising\nalternative to human-generated text, this paper investigates the potential use\nof LLMs to generate user stories for AI systems based on abstracts from\nscholarly papers. We conducted an empirical evaluation using three LLMs and\ngenerated $1260$ user stories from $42$ abstracts from $26$ domains. We assess\ntheir quality using the Quality User Story (QUS) framework. Moreover, we\nidentify relevant non-functional requirements (NFRs) and ethical principles.\nOur analysis demonstrates that the investigated LLMs can generate user stories\ninspired by the needs of various stakeholders, offering a promising approach\nfor generating user stories for research purposes and for aiding in the early\nrequirements elicitation phase of AI systems. We have compiled and curated a\ncollection of stories generated by various LLMs into a dataset (UStAI), which\nis now publicly available for use.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.00513v3", "cate": "cs.SE", "date": "2025-04-01", "updated": "2025-07-16", "AI": {"title_translation": "利用大型语言模型为AI系统生成用户故事：UStAI数据集", "tldr": "本研究探讨了利用大型语言模型（LLMs）根据学术论文摘要生成AI系统用户故事的潜力，并创建了一个包含1260个用户故事的公共数据集（UStAI），评估结果显示LLMs生成的用户故事质量良好，可用于AI系统早期需求启发。", "motivation": "AI系统在各领域广泛应用，但高质量需求获取对于系统与业务目标、消费者价值观对齐以及社会责任至关重要。然而，AI系统的不确定性和对敏感数据的依赖使得其需求启发和分析面临挑战。此外，由于许多AI系统的专有性质，缺乏开源的需求工件和技术文档，限制了更广泛的研究。鉴于大型语言模型（LLMs）在文本生成方面的潜力，本研究旨在探索利用LLMs解决AI系统用户故事生成中的这些问题。", "method": "本研究调查了利用大型语言模型（LLMs）根据学术论文摘要生成AI系统用户故事的潜力。研究人员使用三种LLMs，从26个领域的42篇摘要中生成了1260个用户故事。他们使用质量用户故事（QUS）框架评估了这些用户故事的质量。此外，他们还识别了相关的非功能性需求（NFRs）和伦理原则。所有生成的故事被编译并整理成一个名为UStAI的公共数据集。", "result": "分析表明，所研究的LLMs能够生成受各种利益相关者需求启发的用户故事。LLMs在为研究目的生成用户故事以及辅助AI系统早期需求启发阶段方面提供了一种有前景的方法。研究团队已将各种LLMs生成的故事编译并整理成一个名为UStAI的公共数据集，其中包含1260个用户故事。", "conclusion": "本研究表明，大型语言模型（LLMs）能够有效生成高质量的AI系统用户故事，这为AI系统早期需求启发和研究提供了新的途径，并且通过公开UStAI数据集，促进了该领域的进一步研究。", "translation": "AI系统在各个领域和行业中得到广泛应用。创建高质量的AI系统需求对于使AI系统与业务目标和消费者价值观保持一致，以及承担社会责任至关重要。然而，鉴于AI系统的不确定性以及对敏感数据的严重依赖，需要更多的研究来解决AI系统需求的启发和分析问题。由于许多AI系统的专有性质，缺乏开源的需求工件和AI系统的技术需求文档，这限制了更广泛的研究和调查。随着大型语言模型（LLMs）成为人类生成文本的一种有前景的替代方案，本文研究了利用LLMs根据学术论文摘要生成AI系统用户故事的潜在用途。我们对三种LLMs进行了实证评估，并从26个领域的42篇摘要中生成了1260个用户故事。我们使用质量用户故事（QUS）框架评估了它们的质量。此外，我们还识别了相关的非功能性需求（NFRs）和伦理原则。我们的分析表明，所研究的LLMs能够生成受各种利益相关者需求启发的用户故事，为研究目的生成用户故事以及辅助AI系统早期需求启发阶段提供了一种有前景的方法。我们已经将各种LLMs生成的故事编译并整理成一个数据集（UStAI），该数据集现已公开发布。", "summary": "本研究探讨了利用大型语言模型（LLMs）从学术论文摘要中生成AI系统用户故事的潜力。鉴于AI系统需求获取的挑战和开源数据缺乏，研究团队使用三种LLMs生成了1260个用户故事，并基于QUS框架评估其质量，同时识别了非功能性需求和伦理原则。结果表明LLMs能够生成高质量的用户故事，为AI系统早期需求启发和研究提供了可行方案。为此，研究团队构建并公开了UStAI数据集。", "keywords": "大型语言模型, 用户故事, AI系统, 需求工程, UStAI数据集", "comments": "这项研究具有重要的创新性和实用性。它利用了LLMs在文本生成方面的强大能力，解决了AI系统需求启发中长期存在的挑战，特别是对于缺乏开放需求工件的问题。UStAI数据集的公开将极大地促进该领域的研究，为AI系统开发中的需求工程提供了一个宝贵的资源。该方法有望提高需求获取的效率和质量，并可能降低开发成本。"}}
{"id": "2505.09598", "title": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference", "authors": ["Nidhal Jegham", "Marwan Abdelatti", "Lassad Elmoubarki", "Abdeltawab Hendawi"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.09598v3", "summary": "This paper introduces a novel infrastructure-aware benchmarking framework for\nquantifying the environmental footprint of LLM inference across 30\nstate-of-the-art models as deployed in commercial data centers. Our framework\ncombines public API performance data with region-specific environmental\nmultipliers and statistical inference of hardware configurations. We\nadditionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank\nmodels by performance relative to environmental cost. Our results show that o3\nand DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33\nWh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and\nthat Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short\nGPT-4o query consumes 0.42 Wh, scaling this to 700 million queries/day results\nin substantial annual environmental impacts. These include electricity use\ncomparable to 35,000 U.S. homes, freshwater evaporation matching the annual\ndrinking needs of 1.2 million people, and carbon emissions requiring a\nChicago-sized forest to offset. These findings illustrate a growing paradox:\nAlthough AI is becoming cheaper and faster, its global adoption drives\ndisproportionate resource consumption. Our study provides a standardized,\nempirically grounded methodology for benchmarking the sustainability of LLM\ndeployments, laying a foundation for future environmental accountability in AI\ndevelopment and sustainability standards.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.09598v3", "cate": "cs.CY", "date": "2025-05-14", "updated": "2025-07-15", "AI": {"title_translation": "人工智能有多“饿”？基准测试大型语言模型推理的能源、水和碳足迹", "tldr": "本研究引入了一个新的基准测试框架，量化了30个大型语言模型在商业数据中心推理时的环境足迹，发现一些模型能耗巨大，并强调了AI快速发展带来的资源消耗矛盾。", "motivation": "尽管人工智能变得越来越便宜和快速，但其全球普及导致了不成比例的资源消耗。本研究旨在量化大型语言模型（LLM）推理的环境足迹，以解决这一日益增长的矛盾，并为AI开发中的环境责任和可持续性标准奠定基础。", "method": "本研究引入了一个新颖的、基础设施感知的基准测试框架，用于量化大型语言模型在商业数据中心推理时的环境足迹。该框架结合了公共API性能数据、区域特定的环境乘数和硬件配置的统计推断。此外，研究还利用交叉效率数据包络分析（DEA）根据性能相对于环境成本对模型进行排名。", "result": "研究结果显示，o3和DeepSeek-R1是能耗最高的模型，每次长提示消耗超过33瓦时，是GPT-4.1 nano的70多倍。Claude-3.7 Sonnet在生态效率方面排名最高。一个短的GPT-4o查询消耗0.42瓦时，但每天7亿次查询将导致巨大的年度环境影响，包括相当于35,000个美国家庭的用电量、满足120万人年度饮水需求的淡水蒸发量，以及需要芝加哥大小森林来抵消的碳排放。", "conclusion": "本研究揭示了AI日益增长的资源消耗与其成本效益之间的矛盾，并提供了一个标准化、基于经验的方法来衡量LLM部署的可持续性。这为未来AI开发中的环境责任和可持续性标准奠定了基础。", "translation": "本文介绍了一个新颖的基础设施感知基准测试框架，用于量化30个最先进模型在商业数据中心部署时的大型语言模型推理的环境足迹。我们的框架结合了公共API性能数据、区域特定的环境乘数和硬件配置的统计推断。我们还利用交叉效率数据包络分析（DEA）根据性能相对于环境成本对模型进行排名。我们的结果显示，o3和DeepSeek-R1是能耗最高的模型，每次长提示消耗超过33瓦时，是GPT-4.1 nano的70多倍，而Claude-3.7 Sonnet在生态效率方面排名最高。虽然单个短的GPT-4o查询消耗0.42瓦时，但将其扩展到每天7亿次查询将导致巨大的年度环境影响。这些影响包括相当于35,000个美国家庭的用电量、满足120万人年度饮水需求的淡水蒸发量，以及需要芝加哥大小森林来抵消的碳排放。这些发现说明了一个日益增长的矛盾：尽管人工智能变得越来越便宜和快速，但其全球普及导致了不成比例的资源消耗。我们的研究提供了一个标准化、基于经验的方法来衡量LLM部署的可持续性，为未来AI开发中的环境责任和可持续性标准奠定了基础。", "summary": "本研究提出了一个基础设施感知的基准测试框架，以量化大型语言模型在商业数据中心运行时的能源、水和碳足迹。通过分析30个主流LLM，并结合API数据、环境乘数和DEA，研究发现不同模型间能耗差异巨大，如o3和DeepSeek-R1的能耗是GPT-4.1 nano的70多倍。研究强调，尽管AI成本下降，但其大规模应用导致了巨大的资源消耗，并提供了一个评估LLM可持续性的标准化方法，旨在推动AI领域的环境责任。", "keywords": "大型语言模型, 环境足迹, 能耗, 水消耗, 碳排放", "comments": "该论文通过引入一个新颖的、基础设施感知的基准测试框架，首次系统地量化了大型语言模型推理在商业数据中心的环境足迹，具有重要的开创性。其创新点在于结合了多源数据和DEA分析，提供了量化的环境影响数据，并揭示了AI发展中日益突出的资源消耗矛盾。这项研究对于提高AI领域的可持续发展意识和推动行业制定环境标准具有重要意义，有助于未来的AI部署更加负责任。"}}
{"id": "2503.17483", "title": "Sharp Hybrid Zonotopes: Set Operations and the Reformulation-linearization Technique", "authors": ["Jonah J. Glunt", "Joshua A. Robbins", "Jacob A. Siefert", "Daniel Silvestre", "Herschel C. Pangborn"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.17483v2", "summary": "Mixed integer set representations, and specifically hybrid zonotopes, have\nenabled new techniques for reachability and verification of nonlinear and\nhybrid systems. Mixed-integer sets which have the property that their convex\nrelaxation is equal to their convex hull are said to be sharp. This property\nallows the convex hull to be computed with minimal overhead, and is known to be\nimportant for improving the convergence rates of mixed-integer optimization\nalgorithms that rely on convex relaxations. This paper examines methods for\nformulating sharp hybrid zonotopes and provides sharpness-preserving methods\nfor performing several key set operations. The paper then shows how the\nreformulation-linearization technique can be applied to create a sharp\nrealization of a hybrid zonotope that is initially not sharp. A numerical\nexample applies this technique to find the convex hull of a level set of a\nfeedforward ReLU neural network.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.17483v2", "cate": "eess.SY", "date": "2025-03-21", "updated": "2025-07-16", "AI": {"title_translation": "尖锐混合Zonotopes：集合操作与重构-线性化技术", "tldr": "本文研究了如何构建和保持尖锐混合zonotopes，并展示了如何利用重构-线性化技术使非尖锐的zonotopes变得尖锐，这对于提高混合整数优化算法的收敛速度至关重要。", "motivation": "混合整数集表示（特别是混合zonotopes）为非线性系统和混合系统的可达性及验证提供了新方法。具有“尖锐”特性的混合整数集（其凸松弛等于凸包）可以以最小的开销计算凸包，并能显著提高依赖凸松弛的混合整数优化算法的收敛速度。", "method": "本文研究了构建尖锐混合zonotopes的方法，提供了保持尖锐性的关键集合操作方法，并展示了如何应用重构-线性化技术来创建最初不尖锐的混合zonotope的尖锐实现。", "result": "该研究提供了一种应用重构-线性化技术来创建尖锐混合zonotope的方法，并通过数值例子将其应用于寻找前馈ReLU神经网络的水平集的凸包。", "conclusion": "该研究提出了构建和保持尖锐混合zonotopes的方法，并通过重构-线性化技术解决了非尖锐zonotopes的尖锐化问题，这对于提高相关优化算法的收敛速度和非线性系统分析具有重要意义。", "translation": "混合整数集表示，特别是混合zonotopes，为非线性系统和混合系统的可达性和验证提供了新技术。具有凸松弛等于其凸包性质的混合整数集被称为尖锐集。这种性质允许以最小的开销计算凸包，并且已知对于提高依赖凸松弛的混合整数优化算法的收敛速度至关重要。本文研究了形成尖锐混合zonotopes的方法，并提供了保持尖锐性的几种关键集合操作方法。然后，本文展示了如何应用重构-线性化技术来创建最初不尖锐的混合zonotope的尖锐实现。一个数值例子将该技术应用于寻找前馈ReLU神经网络的水平集的凸包。", "summary": "本文探讨了尖锐混合zonotopes的构建、操作及其在优化中的应用。研究提出了保持尖锐性的集合操作方法，并引入重构-线性化技术以将非尖锐混合zonotopes转化为尖锐形式，从而有效计算其凸包，提升混合整数优化算法的收敛效率。通过一个数值例子展示了该技术在寻找前馈ReLU神经网络水平集凸包上的应用。", "keywords": "混合Zonotopes, 尖锐性, 集合操作, 重构-线性化技术, 凸包", "comments": "本文的创新点在于提出了利用重构-线性化技术将非尖锐混合zonotopes转化为尖锐形式的方法，这对于依赖凸松弛的混合整数优化算法具有重要的理论和实际意义。其重要性体现在能够提高这些算法的收敛速度，并为复杂系统的可达性分析提供了更高效的工具。"}}
{"id": "2507.11582", "title": "Subjective Evaluation Profile Analysis of Science Fiction Short Stories and its Critical-Theoretical Significance", "authors": ["Kazuyoshi Otsuka"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      38 pages. Manuscript submitted for review to the Journal of Computational Literary Studies (JCLS)", "url": "http://arxiv.org/abs/2507.11582v1", "summary": "This study positions large language models (LLMs) as \"subjective literary\ncritics\" to explore aesthetic preferences and evaluation patterns in literary\nassessment. Ten Japanese science fiction short stories were translated into\nEnglish and evaluated by six state-of-the-art LLMs across seven independent\nsessions. Principal component analysis and clustering techniques revealed\nsignificant variations in evaluation consistency ({\\alpha} ranging from 1.00 to\n0.35) and five distinct evaluation patterns. Additionally, evaluation variance\nacross stories differed by up to 4.5-fold, with TF-IDF analysis confirming\ndistinctive evaluation vocabularies for each model. Our seven-session\nwithin-day protocol using an original Science Fiction corpus strategically\nminimizes external biases, allowing us to observe implicit value systems shaped\nby RLHF and their influence on literary judgment. These findings suggest that\nLLMs may possess individual evaluation characteristics similar to human\ncritical schools, rather than functioning as neutral benchmarkers.", "comment": "38 pages. Manuscript submitted for review to the Journal of\n  Computational Literary Studies (JCLS)", "pdf_url": "http://arxiv.org/pdf/2507.11582v1", "cate": "cs.CL", "date": "2025-06-07", "updated": "2025-06-07", "AI": {"title_translation": "科幻短篇小说主观评价剖析及其批判理论意义", "tldr": "本研究将大型语言模型（LLM）定位为“主观文学评论家”，发现其在文学评估中展现出类似人类评论流派的个体评价特征，而非中立的基准工具。", "motivation": "本研究旨在将大型语言模型（LLM）定位为“主观文学评论家”，以探索其在文学评估中的审美偏好和评价模式。", "method": "研究将十篇日本科幻短篇小说翻译成英文，并由六个最先进的LLM在七个独立的会话中进行评估。通过主成分分析和聚类技术揭示评价一致性和模式，并使用TF-IDF分析确认独特的评价词汇。研究采用七次会话日内协议及原创科幻语料库，以最大程度地减少外部偏差。", "result": "研究发现评价一致性存在显著差异（α范围从1.00到0.35），并揭示了五种不同的评价模式。此外，不同故事间的评价方差差异高达4.5倍，且每个模型都拥有独特的评价词汇。", "conclusion": "研究结果表明，大型语言模型可能拥有类似于人类评论流派的个体评价特征，而非充当中立的基准测试工具。", "translation": "本研究将大型语言模型（LLM）定位为“主观文学评论家”，以探索文学评估中的审美偏好和评价模式。十篇日本科幻短篇小说被翻译成英文，并由六个最先进的LLM在七个独立的会话中进行评估。主成分分析和聚类技术揭示了评价一致性的显著差异（α范围从1.00到0.35）和五种不同的评价模式。此外，不同故事间的评价方差差异高达4.5倍，TF-IDF分析证实了每个模型独特的评价词汇。我们采用原始科幻语料库的七次会话日内协议，策略性地最大程度地减少了外部偏差，使我们能够观察由RLHF塑造的隐含价值体系及其对文学判断的影响。这些发现表明，LLM可能拥有类似于人类评论流派的个体评价特征，而不是充当中立的基准测试工具。", "summary": "本研究将大型语言模型（LLM）视为“主观文学评论家”，旨在分析其在文学评估中的审美偏好和评价模式。通过让六个先进的LLM评估十篇翻译成英文的日本科幻短篇小说，研究发现LLM的评价一致性存在显著差异，并呈现出五种独特的评价模式。此外，不同故事间的评价方差和模型的评价词汇也各不相同。这些结果表明，LLM可能具有类似于人类评论流派的个体评价特征，而非中立的基准评估工具，其隐含的价值体系受强化学习人类反馈（RLHF）影响。", "keywords": "大型语言模型, 文学评论, 主观评价, 科幻小说, 评价模式", "comments": "这项研究具有创新性，因为它将LLM视为具有主观性的文学评论家，而非简单的工具，这挑战了LLM作为中立评估者的传统观念。它揭示了LLM在文学判断中可能存在的“个性”和潜在偏见，对于理解LLM在复杂、主观任务中的行为具有重要意义。"}}
{"id": "2507.11787", "title": "Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity", "authors": ["Chandrashekar Muniyappa", "Eunjin Kim"], "categories": ["cs.AI", "68-68W50"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      CSAIDE '25: Proceedings of the 2025 4th International Conference on Cyber Security, Artificial Intelligence and the Digital Economy", "url": "http://arxiv.org/abs/2507.11787v1", "summary": "Swarm Intelligence (SI) is gaining a lot of popularity in artificial\nintelligence, where the natural behavior of animals and insects is observed and\ntranslated into computer algorithms called swarm computing to solve real-world\nproblems. Due to their effectiveness, they are applied in solving various\ncomputer optimization problems. This survey will review all the latest\ndevelopments in Searching for documents based on semantic similarity using\nSwarm Intelligence algorithms and recommend future research directions.", "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "pdf_url": "http://arxiv.org/pdf/2507.11787v1", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "基于语义相似度的群智能文档搜索方法综述", "tldr": "本文综述了利用群智能算法进行基于语义相似度的文档搜索的最新进展，并提出了未来的研究方向。", "motivation": "群智能（SI）在人工智能领域日益普及，因其有效性被应用于解决各种计算机优化问题。本综述旨在回顾利用群智能算法进行基于语义相似度的文档搜索的最新发展。", "method": "本文采用综述（Survey）的方法，回顾了利用群智能算法进行基于语义相似度的文档搜索的所有最新进展。", "result": "本综述将回顾在利用群智能算法进行基于语义相似度的文档搜索方面的最新发展。具体研究结果未在摘要中提及。", "conclusion": "本综述将推荐未来在该领域的研究方向。", "translation": "群智能（SI）在人工智能领域越来越受欢迎，它观察动物和昆虫的自然行为并将其转化为称为群计算的计算机算法，以解决现实世界的问题。由于其有效性，它们被应用于解决各种计算机优化问题。本综述将回顾利用群智能算法进行基于语义相似度的文档搜索的所有最新进展，并推荐未来的研究方向。", "summary": "本综述探讨了群智能（SI）在基于语义相似度的文档搜索中的应用。SI作为一种模仿自然行为的算法，在解决计算机优化问题方面表现出高效性。文章旨在回顾该领域的所有最新发展，并为未来的研究提供指导。", "keywords": "群智能, 语义相似度, 文档搜索, 综述", "comments": "本综述对于理解群智能在文档语义搜索领域的应用现状及其未来发展方向具有重要意义，为研究人员提供了全面的概览和潜在的研究线索。"}}
{"id": "2503.04695", "title": "A linearly-implicit energy-momentum preserving scheme for geometrically nonlinear mechanics based on non-canonical Hamiltonian formulations", "authors": ["Andrea Brugnoli", "Denis Matignon", "Joseph Morlier"], "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      34 pages, 22 figures", "url": "http://arxiv.org/abs/2503.04695v3", "summary": "This work presents a novel formulation and numerical strategy for the\nsimulation of geometrically nonlinear structures. First, a non-canonical\nHamiltonian (Poisson) formulation is introduced by including the dynamics of\nthe stress tensor. This framework is developed for von-K\\'arm\\'an\nnonlinearities in beams and plates, as well as geometrically nonlinear\nelasticity with Saint-Venant material behavior. In the case of plates, both\nnegligible and non-negligible membrane inertia are considered. For the former\ncase the two-dimensional elasticity complex is leveraged to express the\ndynamics in terms of the Airy stress function. The finite element\ndiscretization employs a mixed approach, combining a conforming approximation\nfor displacement and velocity fields with a discontinuous stress tensor\nrepresentation. A staggered, linear implicit time integration scheme is\nproposed, establishing connections with existing explicit-implicit\nenergy-preserving methods. The stress degrees of freedom are statically\ncondensed, reducing the computational complexity to solving a system with a\npositive definite matrix. The integration strategy preserves energy and angular\nmomentum exactly. The methodology is validated through numerical experiments on\nthe Duffing oscillator, a von-K\\'arm\\'an beam, and a column undergoing finite\ndeformations. Comparisons with fully implicit energy-preserving method and the\nleapfrog scheme demonstrate that the proposed approach achieves superior\naccuracy while maintaining energy stability. Additionally, it enables larger\ntime steps compared to explicit schemes and exhibits computational efficiency\ncomparable to the leapfrog method.", "comment": "34 pages, 22 figures", "pdf_url": "http://arxiv.org/pdf/2503.04695v3", "cate": "math.NA", "date": "2025-03-06", "updated": "2025-07-16", "AI": {"title_translation": "基于非规范哈密顿公式的几何非线性力学中线性隐式能量-动量守恒格式", "tldr": "本文提出了一种新的线性隐式能量-动量守恒方案，用于模拟几何非线性结构，通过引入包含应力张量动力学的非规范哈密顿公式，并在数值实验中显示出更高的精度和计算效率。", "motivation": "现有方法可能在几何非线性结构模拟中存在局限性，需要一种新的数值策略来精确且高效地模拟这类系统，同时保持能量和动量守恒。", "method": "1. 引入了包含应力张量动力学的非规范哈密顿(泊松)公式，适用于von-Kármán非线性梁板和圣维南材料的几何非线性弹性。2. 有限元离散采用混合方法，结合了位移和速度场的协调近似与不连续应力张量表示。3. 提出了一种交错的、线性隐式时间积分方案，与现有显式-隐式能量守恒方法建立联系。4. 应力自由度被静态凝聚，计算复杂度降低到求解一个正定矩阵系统。5. 积分策略精确地保持能量和角动量。", "result": "1. 该方法在Duffing振子、von-Kármán梁和有限变形柱的数值实验中得到验证。2. 与全隐式能量守恒方法和蛙跳格式相比，该方法在保持能量稳定性的同时，实现了更高的精度。3. 相比显式方案，允许更大的时间步长。4. 计算效率与蛙跳法相当。", "conclusion": "本文提出的线性隐式能量-动量守恒方案为几何非线性结构的模拟提供了一种准确、高效且稳定的方法，在保持能量和角动量精确守恒的同时，提高了计算效率和精度。", "translation": "这项工作提出了一种用于几何非线性结构模拟的新颖公式和数值策略。首先，通过引入应力张量动力学，提出了一种非规范哈密顿（泊松）公式。该框架是为梁和板中的von-Kármán非线性以及圣维南材料行为的几何非线性弹性而开发的。在板的情况下，考虑了可忽略和不可忽略的膜惯性。对于前者，利用二维弹性复数来表达以艾里应力函数表示的动力学。有限元离散采用混合方法，将位移和速度场的协调近似与不连续应力张量表示相结合。提出了一种交错的、线性隐式时间积分方案，与现有显式-隐式能量守恒方法建立了联系。应力自由度被静态凝聚，将计算复杂度降低到求解一个正定矩阵系统。该积分策略精确地保持能量和角动量。该方法通过在Duffing振子、von-Kármán梁和经历有限变形的柱上的数值实验进行了验证。与全隐式能量守恒方法和蛙跳格式的比较表明，所提出的方法在保持能量稳定性的同时，实现了更高的精度。此外，与显式方案相比，它允许更大的时间步长，并表现出与蛙跳法相当的计算效率。", "summary": "本文提出了一种用于模拟几何非线性结构的新型线性隐式数值策略。该方法基于引入应力张量动力学的非规范哈密顿公式，并采用混合有限元离散。其核心是一个交错的线性隐式时间积分方案，能够精确保持能量和角动量。通过静态凝聚应力自由度，降低了计算复杂度。数值实验验证了该方法在精度、能量稳定性、时间步长以及计算效率方面的优越性。", "keywords": "几何非线性力学, 哈密顿公式, 能量-动量守恒, 线性隐式, 有限元", "comments": "该论文的创新点在于将应力张量动力学纳入非规范哈密顿公式，并结合线性隐式时间积分，实现了能量和动量的精确守恒。其重要性在于为几何非线性力学提供了更高效、更精确且稳定的数值模拟工具，特别是在处理大变形问题时具有优势。通过静态凝聚应力自由度，显著提高了计算效率，使其在实际应用中更具吸引力。"}}
{"id": "2507.11730", "title": "Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis", "authors": ["Maciej Szankin", "Vidhyananth Venkatasamy", "Lihang Ying"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11730v1", "summary": "Outdoor advertisements remain a critical medium for modern marketing, yet\naccurately verifying billboard text visibility under real-world conditions is\nstill challenging. Traditional Optical Character Recognition (OCR) pipelines\nexcel at cropped text recognition but often struggle with complex outdoor\nscenes, varying fonts, and weather-induced visual noise. Recently, multimodal\nVision-Language Models (VLMs) have emerged as promising alternatives, offering\nend-to-end scene understanding with no explicit detection step. This work\nsystematically benchmarks representative VLMs - including Qwen 2.5 VL 3B,\nInternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline\n(PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with\nsynthetic weather distortions to simulate realistic degradation. Our results\nreveal that while selected VLMs excel at holistic scene reasoning, lightweight\nCNN pipelines still achieve competitive accuracy for cropped text at a fraction\nof the computational cost-an important consideration for edge deployment. To\nfoster future research, we release our weather-augmented benchmark and\nevaluation code publicly.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11730v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "辨识标志：边缘部署型OCR模型在广告牌可见性分析中的调查", "tldr": "本文调查了边缘部署型OCR模型（包括VLM和CNN）在户外广告牌文本识别中的表现，发现VLM在场景理解上表现出色，而轻量级CNN在计算成本上具有优势。", "motivation": "户外广告牌文本可见性验证面临挑战，传统OCR难以处理复杂户外场景、多变字体和天气噪声。需要评估新型模型（如VLMs）在真实世界条件下的潜力。", "method": "系统地基准测试了代表性的多模态视觉语言模型（Qwen 2.5 VL 3B, InternVL3, SmolVLM2）和一个紧凑的基于CNN的OCR基线（PaddleOCRv4）。使用了两个公共数据集（ICDAR 2015和SVT），并通过合成天气失真进行增强，以模拟现实退化。", "result": "选定的VLMs在整体场景推理方面表现出色，而轻量级CNN管道在裁剪文本识别方面仍能以较低的计算成本实现具有竞争力的准确性，这对于边缘部署很重要。研究发布了天气增强基准和评估代码。", "conclusion": "VLMs在户外广告牌场景理解方面具有潜力，但对于边缘部署的裁剪文本识别，轻量级CNN模型仍是具有成本效益的有效选择。", "translation": "户外广告仍然是现代营销的关键媒介，然而，在真实世界条件下准确验证广告牌文本可见性仍然具有挑战性。传统的OCR（光学字符识别）管道擅长裁剪文本识别，但常常难以应对复杂的户外场景、多变字体和天气引起的视觉噪声。最近，多模态视觉语言模型（VLMs）作为有前景的替代方案出现，提供了端到端的场景理解，无需明确的检测步骤。这项工作系统地基准测试了代表性的VLM——包括Qwen 2.5 VL 3B、InternVL3和SmolVLM2——以及一个紧凑的基于CNN的OCR基线（PaddleOCRv4），在两个公共数据集（ICDAR 2015和SVT）上进行，并增加了合成天气失真以模拟真实的退化。我们的结果表明，虽然选定的VLM在整体场景推理方面表现出色，但轻量级CNN管道在裁剪文本方面仍能以较低的计算成本实现具有竞争力的准确性——这是边缘部署的重要考量。为了促进未来的研究，我们公开了我们的天气增强基准和评估代码。", "summary": "本文调查了用于户外广告牌可见性分析的边缘部署型OCR模型，特别关注了多模态视觉语言模型（VLM）与传统CNN模型的性能对比。研究发现，尽管VLM在整体场景理解方面表现突出，但轻量级CNN模型在裁剪文本识别上仍能以更低的计算成本达到具有竞争力的准确性，这对于资源受限的边缘设备部署至关重要。为推动未来研究，作者公开了增强数据集和评估代码。", "keywords": "边缘部署, OCR, 视觉语言模型, 广告牌可见性, 计算机视觉", "comments": "这项工作的重要性在于它直接解决了户外广告牌文本可见性验证的实际难题，并通过系统基准测试，为边缘部署场景下的OCR模型选择提供了有价值的见解。特别地，它比较了新兴的VLM与成熟的CNN模型，指出了VLM在场景理解上的优势以及CNN在计算效率上的实用性，这对于资源受限的边缘设备部署具有指导意义。公开数据集和代码也有助于推动该领域的研究进展。"}}
{"id": "2507.11749", "title": "Reconfigurable Battery Systems for Enhanced Fast Charging in Electric Vehicles", "authors": ["Jonathan Olivares", "Tyler Depe", "Rakeshkumar Mahto"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11749v1", "summary": "The adoption of electric vehicles (EVs) is rapidly growing as a key solution\nto reducing greenhouse gas emissions. However, prolonged charging times remain\na significant barrier to widespread EV usage, especially for individuals\nwithout access to fast charging infrastructure. This paper explores the\npotential of reconfigurable battery systems to reduce EV charging times without\ncompromising battery life. We propose innovative battery pack configurations\nthat dynamically adjust the arrangement of cells to optimize charging\nperformance. Simulations were conducted using MATLAB and Simulink to compare\nthe efficiency of various battery configurations, focusing on charging times,\nstate of charge (SOC), voltage, and current under different conditions. The\nresults demonstrate that connecting more batteries in series through\nreconfigurability in battery packs can significantly reduce charging times\nwhile maintaining operational safety. This study offers insights into how\nreconfigurable battery designs can provide a practical solution for faster,\nmore efficient home-based EV charging, making EV ownership more accessible and\nsustainable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11749v1", "cate": "eess.SY", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "电动汽车可重构电池系统以增强快速充电", "tldr": "可重构电池系统可显著缩短电动汽车充电时间。", "motivation": "电动汽车的充电时间过长是其普及的主要障碍，尤其对于缺乏快速充电基础设施的用户。", "method": "提出创新的电池组配置，通过MATLAB和Simulink仿真动态调整电池单元排列，比较不同配置下充电时间、荷电状态（SOC）、电压和电流的效率。", "result": "结果表明，通过可重构性将更多电池串联可以显著缩短充电时间，同时保持操作安全。", "conclusion": "可重构电池设计为更快、更高效的家庭电动汽车充电提供了实用解决方案，使电动汽车更易于拥有和可持续。", "translation": "电动汽车（EV）的普及正在迅速增长，成为减少温室气体排放的关键解决方案。然而，充电时间过长仍然是电动汽车广泛使用的重大障碍，特别是对于无法使用快速充电基础设施的个人而言。本文探讨了可重构电池系统在不影响电池寿命的情况下缩短电动汽车充电时间的潜力。我们提出了创新的电池组配置，可以动态调整电池单元的排列以优化充电性能。使用MATLAB和Simulink进行了仿真，比较了不同条件下各种电池配置的效率，重点关注充电时间、荷电状态（SOC）、电压和电流。结果表明，通过电池组中的可重构性将更多电池串联可以显著缩短充电时间，同时保持操作安全。这项研究提供了关于可重构电池设计如何为更快、更高效的家庭电动汽车充电提供实用解决方案的见解，从而使电动汽车的拥有更加便捷和可持续。", "summary": "本文研究了可重构电池系统如何缩短电动汽车充电时间而不影响电池寿命。通过提出创新的电池组配置并使用MATLAB和Simulink进行仿真，研究发现将更多电池串联可以显著减少充电时间。该研究表明，可重构电池设计是实现更快、更高效家庭充电的实用方案，有助于电动汽车的普及。", "keywords": "可重构电池系统, 快速充电, 电动汽车, 电池管理, 仿真", "comments": "本文提出了一个创新的方法来解决电动汽车充电时间过长的问题，通过动态调整电池配置来优化充电效率，这对于提升用户体验和推动电动汽车普及具有重要意义。其创新点在于电池的“可重构性”，为家庭充电提供了新的思路。"}}
{"id": "2506.22790", "title": "ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge", "authors": ["Yixu Chen", "Bowen Chen", "Hai Wei", "Alan C. Bovik", "Baojun Li", "Wei Sun", "Linhan Cao", "Kang Fu", "Dandan Zhu", "Jun Jia", "Menghan Hu", "Xiongkuo Min", "Guangtao Zhai", "Dounia Hammou", "Fei Yin", "Rafal Mantiuk", "Amritha Premkumar", "Prajit T Rajendran", "Vignesh V Menon"], "categories": ["eess.IV", "cs.CV", "cs.MM"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      ICME 2025 Grand Challenges", "url": "http://arxiv.org/abs/2506.22790v2", "summary": "This paper reports IEEE International Conference on Multimedia \\& Expo (ICME)\n2025 Grand Challenge on Generalizable HDR and SDR Video Quality Measurement.\nWith the rapid development of video technology, especially High Dynamic Range\n(HDR) and Standard Dynamic Range (SDR) contents, the need for robust and\ngeneralizable Video Quality Assessment (VQA) methods has become increasingly\ndemanded. Existing VQA models often struggle to deliver consistent performance\nacross varying dynamic ranges, distortion types, and diverse content. This\nchallenge was established to benchmark and promote VQA approaches capable of\njointly handling HDR and SDR content. In the final evaluation phase, five teams\nsubmitted seven models along with technical reports to the Full Reference (FR)\nand No Reference (NR) tracks. Among them, four methods outperformed VMAF\nbaseline, while the top-performing model achieved state-of-the-art performance,\nsetting a new benchmark for generalizable video quality assessment.", "comment": "ICME 2025 Grand Challenges", "pdf_url": "http://arxiv.org/pdf/2506.22790v2", "cate": "eess.IV", "date": "2025-06-28", "updated": "2025-07-15", "AI": {"title_translation": "ICME 2025 可泛化HDR和SDR视频质量测量挑战赛", "tldr": "ICME 2025举办了一项大挑战，旨在推动和基准测试能够同时处理HDR和SDR内容的通用视频质量评估方法，其中一些提交的模型超越了VMAF基线，最佳模型达到了SOTA性能。", "motivation": "随着视频技术（特别是HDR和SDR内容）的快速发展，对鲁棒和可泛化的视频质量评估（VQA）方法的需求日益增长。现有VQA模型在不同动态范围、失真类型和多样内容上表现不一致。", "method": "该挑战旨在基准测试和推广能够联合处理HDR和SDR内容的VQA方法。在最终评估阶段，五个团队提交了七个模型及技术报告，参与全参考（FR）和无参考（NR）赛道。", "result": "四种方法超越了VMAF基线，表现最佳的模型达到了最先进的性能，为可泛化视频质量评估设定了新的基准。", "conclusion": "该挑战成功地推动了可泛化HDR和SDR视频质量评估领域的研究，并识别出超越现有基线甚至达到SOTA性能的新方法。", "translation": "这篇论文报道了IEEE多媒体与博览会（ICME）2025年关于可泛化HDR和SDR视频质量测量的挑战赛。随着视频技术，特别是高动态范围（HDR）和标准动态范围（SDR）内容的快速发展，对鲁棒和可泛化的视频质量评估（VQA）方法的需求日益增加。现有VQA模型往往难以在不同的动态范围、失真类型和多样内容上提供一致的性能。设立这项挑战是为了对能够联合处理HDR和SDR内容的VQA方法进行基准测试和推广。在最终评估阶段，五个团队提交了七个模型以及技术报告，参与全参考（FR）和无参考（NR）赛道。其中，四种方法超越了VMAF基线，而表现最佳的模型实现了最先进的性能，为可泛化视频质量评估设定了新的基准。", "summary": "本文介绍了ICME 2025年关于可泛化HDR和SDR视频质量测量的大挑战。鉴于现有VQA模型在处理不同动态范围内容时的局限性，该挑战旨在推动和基准测试能同时处理HDR和SDR内容的VQA方法。挑战赛吸引了五个团队提交七个模型，最终有四种方法超越了VMAF基线，其中表现最佳的模型达到了最先进水平，为该领域树立了新标杆。", "keywords": "视频质量评估, HDR, SDR, 大挑战, 泛化性", "comments": "这项挑战赛对于推动HDR和SDR视频质量评估领域的发展至关重要，因为它直接解决了现有模型在跨动态范围内容表现不一致的问题。通过设定明确的基准和鼓励新的SOTA方法，它将加速该领域的研究和实际应用。"}}
{"id": "2502.05111", "title": "Flexible and Efficient Grammar-Constrained Decoding", "authors": ["Kanghee Park", "Timothy Zhou", "Loris D'Antoni"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.05111v2", "summary": "Large Language Models (LLMs) are often asked to generate structured outputs\nthat obey precise syntactic rules, such as code snippets or formatted data.\nGrammar-constrained decoding (GCD) can guarantee that LLM outputs matches such\nrules by masking out tokens that will provably lead to outputs that do not\nbelong to a specified context-free grammar (CFG). To guarantee soundness, GCD\nalgorithms have to compute how a given LLM subword tokenizer can align with the\ntokens used\n  by a given context-free grammar and compute token masks based on this\ninformation. Doing so efficiently is challenging and existing GCD algorithms\nrequire tens of minutes to preprocess common grammars. We present a new GCD\nalgorithm together with an implementation that offers 17.71x faster offline\npreprocessing than existing approaches while preserving state-of-the-art\nefficiency in online mask computation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.05111v2", "cate": "cs.CL", "date": "2025-02-07", "updated": "2025-07-15", "AI": {"title_translation": "灵活高效的语法约束解码", "tldr": "提出了一种新的语法约束解码（GCD）算法，显著加快了离线预处理速度，同时保持了在线掩码计算的效率。", "motivation": "大型语言模型（LLMs）经常需要生成遵循精确语法规则的结构化输出，如代码片段或格式化数据。语法约束解码（GCD）可以保证输出符合这些规则，但现有算法在预处理常见语法时效率低下，需要数十分钟。", "method": "本文提出了一种新的GCD算法及其实现，该算法通过计算LLM子词分词器如何与上下文无关文法中的标记对齐，并基于此信息计算标记掩码，以保证其健全性。", "result": "与现有方法相比，该新算法的离线预处理速度提高了17.71倍，同时在在线掩码计算方面保持了最先进的效率。", "conclusion": "本文提出的新GCD算法显著提升了语法约束解码的离线预处理效率，使其在生成结构化输出时更加实用和高效。", "translation": "大型语言模型（LLMs）通常被要求生成遵循精确句法规则的结构化输出，例如代码片段或格式化数据。语法约束解码（GCD）可以通过屏蔽那些明显会导致不属于指定上下文无关文法（CFG）的输出的标记来保证LLM输出符合此类规则。为了保证健全性，GCD算法必须计算给定的LLM子词分词器如何与给定上下文无关文法使用的标记对齐，并根据此信息计算标记掩码。高效地完成这项工作具有挑战性，现有GCD算法需要数十分钟来预处理常见的语法。我们提出了一种新的GCD算法及其实现，与现有方法相比，它提供了17.71倍的离线预处理速度，同时在在线掩码计算方面保持了最先进的效率。", "summary": "本文针对大型语言模型（LLMs）生成结构化输出时语法约束解码（GCD）预处理效率低下的问题，提出了一种新的GCD算法。该算法在保证输出语法正确性的前提下，将离线预处理速度提高了17.71倍，同时保持了在线掩码计算的效率，显著提升了GCD的实用性。", "keywords": "语法约束解码, 大型语言模型, 结构化输出, 预处理效率, 上下文无关文法", "comments": "本文的创新之处在于其提出的新GCD算法显著提升了离线预处理效率，解决了现有方法耗时过长的问题。这对于需要大量结构化输出的LLM应用具有重要意义，使其在实际部署中更加高效和可行。该研究关注了LLM在特定应用场景下的性能瓶颈，并提出了有效的解决方案。"}}
{"id": "2507.09828", "title": "Regret Analysis of Posterior Sampling-Based Expected Improvement for Bayesian Optimization", "authors": ["Shion Takeno", "Yu Inatsu", "Masayuki Karasuyama", "Ichiro Takeuchi"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      35pages, 5 figures, fix trivial errors", "url": "http://arxiv.org/abs/2507.09828v2", "summary": "Bayesian optimization is a powerful tool for optimizing an\nexpensive-to-evaluate black-box function. In particular, the effectiveness of\nexpected improvement (EI) has been demonstrated in a wide range of\napplications. However, theoretical analyses of EI are limited compared with\nother theoretically established algorithms. This paper analyzes a randomized\nvariant of EI, which evaluates the EI from the maximum of the posterior sample\npath. We show that this posterior sampling-based random EI achieves the\nsublinear Bayesian cumulative regret bounds under the assumption that the\nblack-box function follows a Gaussian process. Finally, we demonstrate the\neffectiveness of the proposed method through numerical experiments.", "comment": "35pages, 5 figures, fix trivial errors", "pdf_url": "http://arxiv.org/pdf/2507.09828v2", "cate": "stat.ML", "date": "2025-07-13", "updated": "2025-07-16", "AI": {"title_translation": "后验采样期望改进贝叶斯优化的遗憾分析", "tldr": "本文分析了一种基于后验采样的随机期望改进（EI）变体，并证明其在黑盒函数为高斯过程时能实现次线性贝叶斯累积遗憾界限。", "motivation": "期望改进（EI）在贝叶斯优化中应用广泛，但其理论分析相对有限。", "method": "本文分析了一种随机化的EI变体，该变体从后验样本路径的最大值评估EI。", "result": "证明了这种基于后验采样的随机EI在黑盒函数遵循高斯过程的假设下，实现了次线性贝叶斯累积遗憾界限。数值实验也验证了所提方法的有效性。", "conclusion": "基于后验采样的随机EI是一种有效的贝叶斯优化策略，并在理论上证明了其具有良好的遗憾性能。", "translation": "贝叶斯优化是优化昂贵评估的黑盒函数的强大工具。特别是，期望改进（EI）的有效性已在广泛应用中得到证实。然而，与其它理论上已确立的算法相比，EI的理论分析是有限的。本文分析了EI的一种随机变体，该变体从后验样本路径的最大值评估EI。我们证明了这种基于后验采样的随机EI在黑盒函数遵循高斯过程的假设下，实现了次线性贝叶斯累积遗憾界限。最后，我们通过数值实验证明了所提出方法的有效性。", "summary": "本文针对贝叶斯优化中期望改进（EI）理论分析不足的问题，提出并分析了一种基于后验采样的随机EI变体。研究证明，在黑盒函数遵循高斯过程的条件下，该方法能够实现次线性的贝叶斯累积遗憾界限，并且通过数值实验验证了其有效性。", "keywords": "贝叶斯优化, 期望改进, 后验采样, 遗憾分析, 高斯过程", "comments": "这篇论文通过引入和分析一种基于后验采样的随机EI变体，填补了EI理论分析方面的空白，为EI在贝叶斯优化中的应用提供了更坚实的理论基础。其创新点在于将后验采样与EI结合，并从遗憾分析的角度进行理论证明。"}}
{"id": "2507.11547", "title": "Recurrent U-Net-Based Graph Neural Network (RUGNN) for Accurate Deformation Predictions in Sheet Material Forming", "authors": ["Yingxue Zhao", "Qianyi Chen", "Haoran Li", "Haosu Zhou", "Hamid Reza Attar", "Tobias Pfaff", "Tailin Wu", "Nan Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11547v1", "summary": "In recent years, various artificial intelligence-based surrogate models have\nbeen proposed to provide rapid manufacturability predictions of material\nforming processes. However, traditional AI-based surrogate models, typically\nbuilt with scalar or image-based neural networks, are limited in their ability\nto capture complex 3D spatial relationships and to operate in a\npermutation-invariant manner. To overcome these issues, emerging graph-based\nsurrogate models are developed using graph neural networks. This study\ndeveloped a new graph neural network surrogate model named Recurrent U\nNet-based Graph Neural Network (RUGNN). The RUGNN model can achieve accurate\npredictions of sheet material deformation fields across multiple forming\ntimesteps. The RUGNN model incorporates Gated Recurrent Units (GRUs) to model\ntemporal dynamics and a U-Net inspired graph-based downsample/upsample\nmechanism to handle spatial long-range dependencies. A novel 'node-to-surface'\ncontact representation method was proposed, offering significant improvements\nin computational efficiency for large-scale contact interactions. The RUGNN\nmodel was validated using a cold forming case study and a more complex hot\nforming case study using aluminium alloys. Results demonstrate that the RUGNN\nmodel provides accurate deformation predictions closely matching ground truth\nFE simulations and outperforming several baseline GNN architectures. Model\ntuning was also performed to identify suitable hyperparameters, training\nstrategies, and input feature representations. These results demonstrate that\nRUGNN is a reliable approach to support sheet material forming design by\nenabling accurate manufacturability predictions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11547v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10", "AI": {"title_translation": "循环U-Net图神经网络(RUGNN)用于板材成形中的精确变形预测", "tldr": "RUGNN是一种新的图神经网络模型，结合了GRU和U-Net机制，用于精确预测板材成形过程中的变形，并在计算效率和准确性方面优于现有模型。", "motivation": "传统基于AI的替代模型（通常是标量或基于图像的神经网络）在捕获复杂3D空间关系和以置换不变方式操作方面存在局限性。", "method": "本研究开发了一种名为循环U-Net图神经网络（RUGNN）的新型图神经网络替代模型。RUGNN模型结合了门控循环单元（GRU）来建模时间动态，并采用了受U-Net启发的基于图的下采样/上采样机制来处理空间长程依赖。此外，还提出了一种新颖的“节点到表面”接触表示方法，显著提高了大规模接触交互的计算效率。", "result": "RUGNN模型通过冷成形和更复杂的铝合金热成形案例研究进行了验证。结果表明，RUGNN模型提供了与真实有限元（FE）模拟高度匹配的精确变形预测，并且优于几种基线GNN架构。还进行了模型调优以识别合适的超参数、训练策略和输入特征表示。", "conclusion": "RUGNN是一种可靠的方法，通过实现精确的可制造性预测来支持板材成形设计。", "translation": "近年来，各种基于人工智能的替代模型被提出，以提供材料成形过程的快速可制造性预测。然而，传统的基于人工智能的替代模型，通常使用标量或基于图像的神经网络构建，在捕获复杂3D空间关系和以置换不变方式操作方面的能力有限。为了克服这些问题，新兴的基于图的替代模型正在使用图神经网络进行开发。本研究开发了一种名为循环U-Net图神经网络（RUGNN）的新型图神经网络替代模型。RUGNN模型可以实现跨多个成形时间步的板材变形场的精确预测。RUGNN模型结合了门控循环单元（GRU）来建模时间动态，并采用受U-Net启发的基于图的下采样/上采样机制来处理空间长程依赖。提出了一种新颖的“节点到表面”接触表示方法，显著提高了大规模接触交互的计算效率。RUGNN模型通过一个冷成形案例研究和一个更复杂的铝合金热成形案例研究进行了验证。结果表明，RUGNN模型提供了与真实有限元模拟高度匹配的精确变形预测，并且优于几种基线GNN架构。还进行了模型调优以识别合适的超参数、训练策略和输入特征表示。这些结果表明，RUGNN是一种可靠的方法，通过实现精确的可制造性预测来支持板材成形设计。", "summary": "本文提出了一种名为循环U-Net图神经网络（RUGNN）的新型图神经网络替代模型，旨在克服传统AI模型在捕获复杂3D空间关系和置换不变性方面的局限性。RUGNN模型结合了门控循环单元（GRU）以建模时间动态，并采用了受U-Net启发的图基下采样/上采样机制来处理空间长程依赖。此外，还引入了一种新颖的“节点到表面”接触表示方法，显著提升了大规模接触交互的计算效率。通过冷成形和热成形案例研究验证，RUGNN在板材变形预测方面表现出高精度，与有限元模拟结果高度吻合，并优于现有GNN架构，证明了其在板材成形设计中支持可制造性预测的可靠性。", "keywords": "图神经网络, 变形预测, 板材成形, 循环神经网络, U-Net", "comments": "RUGNN模型通过结合GRU处理时间动态和U-Net式下采样/上采样机制处理空间依赖，有效解决了传统AI模型在复杂3D空间关系和置换不变性方面的局限性。特别是，“节点到表面”接触表示方法的提出，显著提升了大规模接触交互的计算效率，是其重要的创新点。该研究为板材成形过程中的快速、精确变形预测提供了一种可靠且高效的工具。"}}
{"id": "2507.12028", "title": "MOFCO: Mobility- and Migration-Aware Task Offloading in Three-Layer Fog Computing Environments", "authors": ["Soheil Mahdizadeh", "Elyas Oustad", "Mohsen Ansari"], "categories": ["cs.AR", "cs.DC", "cs.NI"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12028v1", "summary": "Task offloading in three-layer fog computing environments presents a critical\nchallenge due to user equipment (UE) mobility, which frequently triggers costly\nservice migrations and degrades overall system performance. This paper\naddresses this problem by proposing MOFCO, a novel Mobility- and\nMigration-aware Task Offloading algorithm for Fog Computing environments. The\nproposed method formulates task offloading and resource allocation as a\nMixed-Integer Nonlinear Programming (MINLP) problem and employs a\nheuristic-aided evolutionary game theory approach to solve it efficiently. To\nevaluate MOFCO, we simulate mobile users using SUMO, providing realistic\nmobility patterns. Experimental results show that MOFCO reduces system cost,\ndefined as a combination of latency and energy consumption, by an average of\n19% and up to 43% in certain scenarios compared to state-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12028v1", "cate": "cs.AR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MOFCO：三层雾计算环境中移动性和迁移感知的任务卸载", "tldr": "MOFCO是一种新的算法，用于解决三层雾计算环境中由于用户移动性导致的任务卸载和服务迁移成本高和性能下降问题。它通过混合整数非线性规划和启发式演化博弈论方法，显著降低了系统成本（延迟和能耗）。", "motivation": "由于用户设备（UE）的移动性，三层雾计算环境中的任务卸载面临严峻挑战，这经常导致高昂的服务迁移成本并降低整体系统性能。", "method": "该论文提出了MOFCO算法。它将任务卸载和资源分配建模为混合整数非线性规划（MINLP）问题，并采用启发式辅助演化博弈论方法高效求解。为了评估MOFCO，研究人员使用SUMO模拟了移动用户，以提供真实的移动模式。", "result": "实验结果表明，与现有最先进的方法相比，MOFCO将系统成本（定义为延迟和能耗的组合）平均降低了19%，在某些场景下甚至高达43%。", "conclusion": "MOFCO算法通过有效解决移动性和迁移带来的挑战，显著降低了三层雾计算环境中的任务卸载系统成本，提升了性能。", "translation": "三层雾计算环境中的任务卸载由于用户设备（UE）的移动性而面临严峻挑战，这经常触发高昂的服务迁移成本并降低整体系统性能。本文通过提出MOFCO，一种新颖的针对雾计算环境的移动性和迁移感知任务卸载算法，来解决这个问题。所提出的方法将任务卸载和资源分配制定为混合整数非线性规划（MINLP）问题，并采用启发式辅助演化博弈论方法来高效解决它。为了评估MOFCO，我们使用SUMO模拟了移动用户，提供了真实的移动模式。实验结果表明，与现有最先进的方法相比，MOFCO将系统成本（定义为延迟和能耗的组合）平均降低了19%，在某些场景下甚至高达43%。", "summary": "MOFCO是一种创新的任务卸载算法，专为解决三层雾计算环境中由用户移动性引起的服务迁移和性能下降问题而设计。它通过将任务卸载和资源分配建模为MINLP问题，并结合启发式辅助演化博弈论进行高效求解。仿真结果表明，MOFCO在降低系统成本（延迟和能耗）方面表现出色，相较于现有技术，平均降低19%，最高可达43%。", "keywords": "任务卸载, 雾计算, 移动性感知, 服务迁移, 演化博弈论", "comments": "该论文的创新点在于提出了MOFCO算法，它能够感知用户移动性和服务迁移，并将其纳入任务卸载的优化中。通过结合MINLP和演化博弈论，提供了一种高效的求解方法。其重要性在于有效解决了雾计算中实际存在的移动性挑战，并显著提升了系统性能，具有较强的实际应用潜力。"}}
{"id": "2507.11498", "title": "Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming", "authors": ["Asad Ali Shahid", "Francesco Braghin", "Loris Roveda"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11498v2", "summary": "Humanoid robots have seen remarkable advances in dexterity, balance, and\nlocomotion, yet their role in expressive domains such as music performance\nremains largely unexplored. Musical tasks, like drumming, present unique\nchallenges, including split-second timing, rapid contacts, and multi-limb\ncoordination over performances lasting minutes. In this paper, we introduce\nRobot Drummer, a humanoid capable of expressive, high-precision drumming across\na diverse repertoire of songs. We formulate humanoid drumming as sequential\nfulfillment of timed contacts and transform drum scores into a Rhythmic Contact\nChain. To handle the long-horizon nature of musical performance, we decompose\neach piece into fixed-length segments and train a single policy across all\nsegments in parallel using reinforcement learning. Through extensive\nexperiments on over thirty popular rock, metal, and jazz tracks, our results\ndemonstrate that Robot Drummer consistently achieves high F1 scores. The\nlearned behaviors exhibit emergent human-like drumming strategies, such as\ncross-arm strikes, and adaptive stick assignments, demonstrating the potential\nof reinforcement learning to bring humanoid robots into the domain of creative\nmusical performance. Project page: robotdrummer.github.io", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11498v2", "cate": "cs.RO", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "机器人鼓手：学习类人机器人打鼓的节奏技能", "tldr": "本文介绍了“机器人鼓手”，一个能够进行高精度、富有表现力的类人机器人鼓手，通过强化学习在多样化的歌曲中展现出类人打鼓策略。", "motivation": "尽管类人机器人在灵巧性、平衡性和运动方面取得了显著进步，但它们在音乐表演等表达性领域的应用仍未得到充分探索。打鼓等音乐任务带来了独特的挑战，包括瞬间时机、快速接触以及持续数分钟的多肢协调。", "method": "引入了“机器人鼓手”，将类人机器人打鼓表述为定时接触的顺序完成，并将鼓谱转换为“节奏接触链”。为了处理音乐表演的长期性，将每首曲子分解为固定长度的片段，并使用强化学习并行训练所有片段的单一策略。", "result": "在三十多首流行摇滚、金属和爵士乐曲目上的广泛实验表明，“机器人鼓手”始终 achieves 高 F1 分数。学习到的行为表现出 emergent 类人打鼓策略，例如交叉手臂击打和自适应鼓棒分配。", "conclusion": "强化学习有潜力将类人机器人带入创意音乐表演领域。", "translation": "类人机器人在灵巧性、平衡性和运动方面取得了显著进步，但它们在音乐表演等表达性领域的应用仍未得到充分探索。打鼓等音乐任务带来了独特的挑战，包括瞬间时机、快速接触以及持续数分钟的多肢协调。在本文中，我们介绍了“机器人鼓手”，一个能够对各种歌曲进行富有表现力、高精度打鼓的类人机器人。我们将类人机器人打鼓表述为定时接触的顺序完成，并将鼓谱转换为“节奏接触链”。为了处理音乐表演的长期性，我们将每首曲子分解为固定长度的片段，并使用强化学习并行训练所有片段的单一策略。通过对三十多首流行摇滚、金属和爵士乐曲目的广泛实验，我们的结果表明“机器人鼓手”始终 achieves 高 F1 分数。学习到的行为表现出 emergent 类人打鼓策略，例如交叉手臂击打和自适应鼓棒分配，这展示了强化学习将类人机器人带入创意音乐表演领域的潜力。项目页面：robotdrummer.github.io", "summary": "本文介绍了“机器人鼓手”，一个能够进行富有表现力、高精度打鼓的类人机器人。研究人员将打鼓任务转化为节奏接触链，并利用强化学习并行训练固定长度的音乐片段。在对大量歌曲的实验中，“机器人鼓手”展现出高F1分数和类人打鼓策略，证明了强化学习在使类人机器人从事创意音乐表演方面的潜力。", "keywords": "机器人鼓手, 类人机器人, 强化学习, 音乐表演, 节奏技能", "comments": "这项工作创新性地将强化学习应用于类人机器人的复杂音乐表演领域，特别是打鼓。其通过将鼓谱转化为“节奏接触链”并并行训练固定长度片段的方法，有效解决了音乐表演的长期性挑战。机器人展现出的类人打鼓策略，如交叉手臂击打，表明了其学习能力的强大和行为的自然性，为未来类人机器人在艺术和表演领域的应用开辟了新途径。"}}
{"id": "2505.07615", "title": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models", "authors": ["Riccardo Passoni", "Francesca Ronchini", "Luca Comanducci", "Romain Serizel", "Fabio Antonacci"], "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted at WASPAA 2025", "url": "http://arxiv.org/abs/2505.07615v2", "summary": "Text-to-audio models have recently emerged as a powerful technology for\ngenerating sound from textual descriptions. However, their high computational\ndemands raise concerns about energy consumption and environmental impact. In\nthis paper, we conduct an analysis of the energy usage of 7 state-of-the-art\ntext-to-audio diffusion-based generative models, evaluating to what extent\nvariations in generation parameters affect energy consumption at inference\ntime. We also aim to identify an optimal balance between audio quality and\nenergy consumption by considering Pareto-optimal solutions across all selected\nmodels. Our findings provide insights into the trade-offs between performance\nand environmental impact, contributing to the development of more efficient\ngenerative audio models.", "comment": "Accepted at WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2505.07615v2", "cate": "eess.AS", "date": "2025-05-12", "updated": "2025-07-16", "AI": {"title_translation": "扩散的责任：分析生成式文本到音频扩散模型的能耗", "tldr": "本文分析了7种最先进的文本到音频扩散模型的能耗，评估了生成参数对推理时能耗的影响，并旨在找到音频质量与能耗之间的最佳平衡，以促进更高效的生成式音频模型开发。", "motivation": "文本到音频模型虽然强大，但其高计算需求引发了对能耗和环境影响的担忧。本研究旨在解决这些担忧，并为开发更高效的生成式音频模型做出贡献。", "method": "本研究分析了7种最先进的基于扩散的生成式文本到音频模型的能耗。研究评估了生成参数的变化在推理时对能耗的影响程度，并通过考虑所有选定模型的帕累托最优解，识别了音频质量和能耗之间的最佳平衡。", "result": "研究结果提供了关于性能和环境影响之间权衡的见解。", "conclusion": "本研究通过提供性能与环境影响权衡的见解，有助于开发更高效的生成式音频模型。", "translation": "文本到音频模型最近已成为一种从文本描述生成声音的强大技术。然而，它们的高计算需求引发了对能耗和环境影响的担忧。在本文中，我们对7种最先进的基于扩散的生成式文本到音频模型的能耗进行了分析，评估了生成参数的变化在推理时对能耗的影响程度。我们还旨在通过考虑所有选定模型的帕累托最优解，找到音频质量和能耗之间的最佳平衡。我们的发现为性能和环境影响之间的权衡提供了见解，有助于开发更高效的生成式音频模型。", "summary": "本论文研究了7种最先进的文本到音频扩散模型的能耗，这些模型因其高计算需求而引发环境担忧。研究分析了生成参数如何影响推理时的能耗，并寻求帕累托最优解以平衡音频质量与能源效率。该研究为性能与环境影响之间的权衡提供了见解，旨在推动开发更节能的生成式音频模型。", "keywords": "能耗, 文本到音频, 扩散模型, 环境影响, 生成式AI", "comments": "这篇论文探讨了一个日益重要且关键的问题：人工智能模型，特别是生成式文本到音频扩散模型的环境影响。其关注推理时的能耗以及质量与能源效率之间的权衡等实际方面，对于可持续AI发展具有重要价值。使用帕累托最优解表明其在寻找实际折衷方案上的严谨方法。"}}
{"id": "2411.05813", "title": "AI for Explosive Ordnance Detection in Clearance Operations: The State of Research", "authors": ["Björn Kischelewski", "Gregory Cathcart", "David Wahl", "Benjamin Guedj"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The research paper was accepted for publication in The Journal of Conventional Weapons Destruction", "url": "http://arxiv.org/abs/2411.05813v2", "summary": "The detection and clearance of explosive ordnance (EO) continues to be a\npredominantly manual and high-risk process that can benefit from advances in\ntechnology to improve its efficiency and effectiveness. Research on artificial\nintelligence (AI) for EO detection in clearance operations has grown\nsignificantly in recent years. However, this research spans a wide range of\nfields, making it difficult to gain a comprehensive understanding of current\ntrends and developments. Therefore, this article provides a literature review\nof academic research on AI for EO detection in clearance operations. It finds\nthat research can be grouped into two main streams: AI for EO object detection\nand AI for EO risk prediction, with the latter being much less studied than the\nformer. From the literature review, we develop three opportunities for future\nresearch. These include a call for renewed efforts in the use of AI for EO risk\nprediction, the combination of different AI systems and data sources, and novel\napproaches to improve EO risk prediction performance, such as pattern-based\npredictions. Finally, we provide a perspective on the future of AI for EO\ndetection in clearance operations. We emphasize the role of traditional machine\nlearning (ML) for this task, the need to dynamically incorporate expert\nknowledge into the models, and the importance of effectively integrating AI\nsystems with real-world operations.", "comment": "The research paper was accepted for publication in The Journal of\n  Conventional Weapons Destruction", "pdf_url": "http://arxiv.org/pdf/2411.05813v2", "cate": "cs.LG", "date": "2024-10-31", "updated": "2025-07-15", "AI": {"title_translation": "人工智能在爆炸物清除行动中的探测应用：研究现状", "tldr": "该论文综述了人工智能在爆炸物探测和清除行动中的研究现状，发现主要分为物体探测和风险预测两大方向，并提出了未来的研究机会。", "motivation": "爆炸物（EO）的探测和清除仍然是一个主要依靠人工且高风险的过程，效率和有效性有待提高。尽管人工智能（AI）在EO探测方面的研究近年来显著增长，但由于研究领域广泛，难以全面了解当前趋势和发展。", "method": "本文通过对人工智能在爆炸物清除行动中探测应用的学术研究进行文献综述。", "result": "研究发现，相关研究可分为两大主流：AI用于EO物体探测和AI用于EO风险预测。后者受到的研究远少于前者。文献综述提出了未来研究的三个机会。", "conclusion": "未来的研究机会包括：重新关注AI在EO风险预测中的应用、结合不同的AI系统和数据源，以及开发新的方法来提高EO风险预测性能（如基于模式的预测）。文章强调了传统机器学习在EO探测任务中的作用、动态整合专家知识的必要性以及有效将AI系统与实际操作相结合的重要性。", "translation": "爆炸物（EO）的探测和清除仍然是一个主要依靠人工且高风险的过程，可以通过技术进步来提高其效率和有效性。近年来，人工智能（AI）在清除行动中EO探测的研究显著增长。然而，这项研究涵盖了广泛的领域，使得全面了解当前趋势和发展变得困难。因此，本文对人工智能在清除行动中EO探测的学术研究进行了文献综述。研究发现，相关研究可分为两大主流：AI用于EO物体探测和AI用于EO风险预测，其中后者受到的研究远少于前者。通过文献综述，我们提出了未来研究的三个机会。这些机会包括：呼吁重新努力利用AI进行EO风险预测、结合不同的AI系统和数据源，以及开发新的方法来提高EO风险预测性能，例如基于模式的预测。最后，我们对人工智能在清除行动中EO探测的未来进行了展望。我们强调了传统机器学习（ML）在此任务中的作用、将专家知识动态整合到模型中的必要性，以及有效将AI系统与实际操作相结合的重要性。", "summary": "本文对人工智能在爆炸物清除行动中探测应用的研究现状进行了全面的文献综述。研究指出，该领域主要分为AI用于爆炸物物体探测和AI用于爆炸物风险预测两大方向，其中风险预测研究不足。基于此，文章提出了未来研究的三个关键机会，并展望了AI在此领域的发展前景，强调了传统机器学习、专家知识整合以及AI系统与实际操作融合的重要性。", "keywords": "爆炸物探测, 人工智能, 文献综述, 风险预测, 清除行动", "comments": "这篇综述性论文非常有价值，因为它系统地梳理了AI在爆炸物探测领域的现有研究，并明确指出了未来的研究方向和未被充分探索的领域（如风险预测）。其创新点在于对现有研究的分类和对未来研究机会的清晰阐述，对于推动该领域的发展具有指导意义。"}}
{"id": "2507.11423", "title": "Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?", "authors": ["Yanjian Zhang", "Guillaume Wisniewski", "Nadi Tomeh", "Thierry Charnois"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11423v2", "summary": "Human reasoning involves different strategies, each suited to specific\nproblems. Prior work shows that large language model (LLMs) tend to favor a\nsingle reasoning strategy, potentially limiting their effectiveness in diverse\nreasoning challenges. In this work, we investigate whether prompting can\ncontrol LLMs reasoning strategies and assess its impact on logical\nproblem-solving. While our experiments show that no single strategy\nconsistently improves accuracy, performance could be enhanced if models could\nadaptively choose the optimal strategy. We propose methods to guide LLMs in\nstrategy selection, highlighting new ways to refine their reasoning abilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11423v2", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "大型语言模型中的推理策略：它们能遵循、偏好和优化吗？", "tldr": "本文研究了提示工程能否控制大型语言模型的推理策略，并评估了其对逻辑问题解决的影响。研究发现，虽然单一策略无法持续提升准确性，但如果模型能自适应选择最优策略，性能可以提高。作者提出了指导LLM策略选择的方法。", "motivation": "人类推理涉及多种策略，而现有大型语言模型（LLMs）倾向于单一推理策略，这可能限制了它们在多样化推理挑战中的有效性。因此，本文旨在探究提示工程是否能控制LLMs的推理策略，并评估其对逻辑问题解决的影响。", "method": "本文通过实验调查了提示工程对LLMs推理策略的控制能力及其对逻辑问题解决的影响。研究者提出了指导LLMs进行策略选择的方法。", "result": "实验结果表明，没有单一的推理策略能够持续提高准确性。然而，如果模型能够自适应地选择最优策略，其性能可以得到提升。", "conclusion": "虽然单一的推理策略未能持续提高LLMs的准确性，但通过引导LLMs自适应选择最佳策略，可以显著提升其推理能力。本文提出了改进LLM推理能力的新方法。", "translation": "人类推理涉及不同的策略，每种策略都适用于特定的问题。先前的研究表明，大型语言模型（LLMs）倾向于单一推理策略，这可能会限制它们在各种推理挑战中的有效性。在这项工作中，我们研究了提示工程是否可以控制LLMs的推理策略，并评估其对逻辑问题解决的影响。虽然我们的实验表明，没有单一策略能持续提高准确性，但如果模型能够自适应地选择最优策略，性能可以得到提升。我们提出了指导LLMs进行策略选择的方法，强调了完善其推理能力的新途径。", "summary": "本文探讨了通过提示工程控制大型语言模型（LLMs）推理策略的可能性及其对逻辑问题解决的影响。研究发现，尽管单一策略无法始终提升准确性，但如果LLMs能够自适应地选择最佳推理策略，其性能将显著提高。文章提出了引导LLMs进行策略选择的新方法，旨在提升其整体推理能力。", "keywords": "大型语言模型, 推理策略, 提示工程, 策略选择, 逻辑问题解决", "comments": "这篇论文的创新点在于它不仅仅是评估LLM的推理能力，而是深入探讨了如何通过策略控制来优化这种能力。它指出了LLM目前单一策略的局限性，并提出了自适应策略选择的概念，这对于未来LLM在复杂推理任务中的应用具有重要意义。该研究为提升LLM的泛化能力和鲁棒性提供了新的思路。"}}
{"id": "2507.11599", "title": "Neuroaesthetics and the Science of Visual Experience", "authors": ["Harish Vijayakumar"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2507.11599v1", "summary": "Neuroaesthetics is an interdisciplinary field that brings together\nneuroscience, psychology, and the arts to explore how the human brain perceives\nand responds to visual beauty. This paper examines the neural mechanisms behind\naesthetic experiences, aiming to explain why certain designs or artworks feel\nemotionally or cognitively \"right.\" By analyzing the interaction between\nperception, emotion, and cognition, neuroaesthetics reveals how beauty is\nconstructed in the brain and how this understanding can inform fields such as\ngraphic and interface design. This paper offers a clear and accessible overview\nof core neuroaesthetic principles, making the subject approachable to a wide\naudience. The findings suggest that impactful design is more than surface-level\nappeal: well-crafted visual experiences can engage, support, and connect people\nin meaningful ways.", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2507.11599v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "神经美学与视觉体验科学", "tldr": "神经美学探讨大脑如何感知和响应视觉美，揭示其神经机制及其对设计领域的启示。", "motivation": "本文旨在探讨人类大脑如何感知和响应视觉美，并解释为何某些设计或艺术品在情感或认知上令人感到“正确”。", "method": "本文通过分析感知、情感和认知之间的相互作用，审视审美体验背后的神经机制，并对核心神经美学原理进行了清晰易懂的概述，因此可视为一篇综述性分析文章。", "result": "神经美学揭示了美在大脑中是如何构建的，以及这种理解如何能为图形和界面设计等领域提供信息。研究结果表明，有影响力的设计不仅仅是表面吸引力：精心制作的视觉体验能够以有意义的方式吸引、支持和连接人们。", "conclusion": "神经美学提供了一个理解视觉美如何在大脑中构建的框架，并强调了这种理解对设计领域的重要性，指出有影响力的设计能够深层次地连接人们。", "translation": "神经美学是一个跨学科领域，它将神经科学、心理学和艺术结合起来，探索人脑如何感知和响应视觉美。本文审视了审美体验背后的神经机制，旨在解释为什么某些设计或艺术品在情感或认知上令人感到“正确”。通过分析感知、情感和认知之间的相互作用，神经美学揭示了美在大脑中是如何构建的，以及这种理解如何能为图形和界面设计等领域提供信息。本文对核心神经美学原理提供了清晰易懂的概述，使该主题易于广大读者理解。研究结果表明，有影响力的设计不仅仅是表面吸引力：精心制作的视觉体验能够以有意义的方式吸引、支持和连接人们。", "summary": "本文介绍了神经美学，一个结合神经科学、心理学和艺术的跨学科领域，旨在探索大脑如何处理视觉美。它深入探讨了审美体验的神经机制，解释了设计与艺术如何影响人的情感和认知。通过分析感知、情感和认知互动，揭示了美在大脑中的构建过程，并强调了这些见解对图形和界面设计等领域的应用价值，指出优秀设计能深层次地连接用户。", "keywords": "神经美学, 视觉体验, 审美, 大脑, 设计", "comments": "这篇论文对于理解视觉美在大脑中的构建机制提供了一个全面的概述，强调了神经美学在设计领域的实际应用价值。其创新之处在于将复杂的神经科学原理以易懂的方式呈现给广泛受众，促进了跨学科的交流。重要性在于它为设计师提供了科学依据，以创造更具影响力、能引起情感共鸣的作品。"}}
{"id": "2507.12240", "title": "Characterization and constructions of binary self-orthogonal singly-even linear codes", "authors": ["Kangquan Li", "Hao Chen", "Wengang Jin", "Longjiang Qu"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12240v1", "summary": "Recent research has focused extensively on constructing binary\nself-orthogonal (SO) linear codes due to their applications in quantum\ninformation theory, lattice design, and related areas. Despite significant\nactivity, the fundamental characterization remains unchanged: binary SO codes\nare necessarily even (all codeword weights even), while doubly-even codes\n(weights divisible by $4$) are automatically SO.\n  This paper advances the theory by addressing the understudied case of\nsingly-even (even but not doubly-even) SO codes. We first provide a complete\ncharacterization of binary SO linear codes, and a necessary and sufficient\ncondition for binary SO singly-even linear codes is given. Moreover, we give a\ngeneral approach to generating many binary SO linear codes from two known SO\nlinear codes, yielding three infinite classes of binary SO singly-even linear\ncodes with few weights. Note that these new codes are also minimal and violate\nthe Aschikhmin-Barg condition. Their weight distributions are determined.\nFurthermore, we give a necessary and sufficient condition for a Boolean\nfunction $f$ such that the linear code proposed from $f$ via a well-known\ngeneric construction is SO singly-even, and a general approach to constructing\nBoolean functions satisfying this condition is provided, yielding several\ninfinite classes of binary SO singly-even minimal linear codes with few\nweights. Finally, we would like to emphasize that using the methods in this\npaper, we can construct more binary linear codes that are SO, singly-even,\nminimal, violating the AB condition, and with few weights at the same time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12240v1", "cate": "cs.IT", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "二元自正交单偶线性码的刻画与构造", "tldr": "本文刻画并构造了二元自正交单偶线性码，解决了该领域研究不足的问题，并发现了新的极小码。", "motivation": "二元自正交（SO）线性码在量子信息理论、格设计及相关领域有重要应用。现有研究主要关注一般的SO码，但对单偶SO码的研究不足，因此需要对其进行深入探究。", "method": "本文首先对二元SO线性码进行了完整刻画，并给出了二元SO单偶线性码的充要条件。其次，提出了一种从两个已知SO线性码生成更多二元SO线性码的通用方法。此外，还给出了一个布尔函数$f$的充要条件，使得通过通用构造从$f$得到的线性码是SO单偶的，并提供了一种构造满足此条件的布尔函数的通用方法。", "result": "本文给出了二元SO线性码的完整刻画以及二元SO单偶线性码的充要条件。通过通用构造方法，得到了三类无限的二元SO单偶线性码，它们具有少量权重，是极小码并违反了Aschikhmin-Barg条件，其权重分布也已确定。此外，还得到了几类无限的、具有少量权重的二元SO单偶极小线性码，这些码是通过特定布尔函数构造的。", "conclusion": "本文提出的方法可以构造更多同时具有自正交、单偶、极小性、违反AB条件以及少量权重特性的二元线性码。", "translation": "最近的研究广泛关注二元自正交（SO）线性码的构造，因为它们在量子信息理论、格设计和相关领域有应用。尽管研究活动频繁，但基本特性保持不变：二元SO码必然是偶码（所有码字权重为偶数），而双偶码（权重可被4整除）则自动是SO码。本文通过解决对单偶（偶数但非双偶）SO码的研究不足问题，推进了该理论。我们首先提供了二元SO线性码的完整刻画，并给出了二元SO单偶线性码的充要条件。此外，我们提出了一种从两个已知SO线性码生成许多二元SO线性码的通用方法，从而得到了三类无限的、具有少量权重的二元SO单偶线性码。值得注意的是，这些新码也是极小码，并且违反了Aschikhmin-Barg条件。它们的权重分布也已确定。此外，我们给出了布尔函数$f$的充要条件，使得通过一个众所周知的通用构造从$f$提出的线性码是SO单偶的，并提供了一种构造满足此条件的布尔函数的通用方法，从而得到了几类无限的、具有少量权重的二元SO单偶极小线性码。最后，我们想强调的是，使用本文中的方法，我们可以构造更多同时是SO、单偶、极小、违反AB条件且具有少量权重的二元线性码。", "summary": "本文通过关注研究不足的单偶自正交（SO）线性码，推进了二元SO线性码的理论。文章提供了二元SO码的完整刻画和单偶SO码的充要条件，并提出了通用的构造方法。这些方法产生了无限类新的二元SO单偶线性码，它们是极小码，违反了Aschikhmin-Barg条件，并具有少量权重，其权重分布也已确定。此外，论文还提供了布尔函数生成此类码的条件和构造方法。", "keywords": "二元码, 自正交码, 单偶码, 线性码, 布尔函数", "comments": "本文通过对单偶自正交码这一研究不足领域的完整刻画和新构造方法，做出了重要贡献。发现的极小码以及违反Aschikhmin-Barg条件的码对于编码理论而言具有创新性和重要性。"}}
{"id": "2507.11959", "title": "PoTPTQ: A Two-step Power-of-Two Post-training for LLMs", "authors": ["Xinyu Wang", "Vahid Partovi Nia", "Peng Lu", "Jerry Huang", "Xiao-Wen Chang", "Boxing Chen", "Yufei Cui"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at ECAI 2025 (European Conference on Artificial Intelligence)", "url": "http://arxiv.org/abs/2507.11959v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious natural language processing (NLP) tasks. However, their deployment is\nchallenging due to the substantial computational resources required.\nPower-of-two (PoT) quantization is a general tool to counteract this\ndifficulty. Albeit previous works on PoT quantization can be efficiently\ndequantized on CPUs using fixed-point addition, it showed less effectiveness on\nGPUs. The reason is entanglement of the sign bit and sequential bit\nmanipulations needed for dequantization. We propose a novel POT quantization\nframework for LLM weights that (i) outperforms state-of-the-art accuracy in\nextremely low-precision number formats, and (ii) enables faster inference\nthrough more efficient dequantization. To maintain the accuracy of the\nquantized model, we introduce a two-step post-training algorithm: (i)\ninitialize the quantization scales with a robust starting point, and (ii)\nrefine these scales using a minimal calibration set. The performance of our PoT\npost-training algorithm surpasses the current state-of-the-art in integer\nquantization, particularly at low precisions such as 2- and 3-bit formats. Our\nPoT quantization accelerates the dequantization step required for the floating\npoint inference and leads to $3.67\\times$ speed up on a NVIDIA V100, and\n$1.63\\times$ on a NVIDIA RTX 4090, compared to uniform integer dequantization.", "comment": "Accepted at ECAI 2025 (European Conference on Artificial\n  Intelligence)", "pdf_url": "http://arxiv.org/pdf/2507.11959v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "PoTPTQ：一种用于LLM的两步幂次后训练量化方法", "tldr": "PoTPTQ是一种用于LLM的两步幂次后训练量化方法，可在极低精度下实现SOTA精度并加速推理，解决了现有幂次量化在GPU上效率低的问题。", "motivation": "大型语言模型（LLM）的部署需要大量计算资源。现有2的幂次（PoT）量化虽然可以在CPU上高效去量化，但在GPU上效果不佳，原因是符号位纠缠和去量化所需的顺序位操作。", "method": "本文提出一种新颖的LLM权重PoT量化框架，包含两步后训练算法：(i) 使用鲁棒的起始点初始化量化尺度；(ii) 使用最小校准集细化这些尺度，旨在提高精度并实现更高效的去量化。", "result": "在2位和3位等低精度格式下，性能超越当前整数量化的最先进水平。PoT量化加速了去量化步骤，与均匀整数去量化相比，在NVIDIA V100上实现了3.67倍的加速，在NVIDIA RTX 4090上实现了1.63倍的加速。", "conclusion": "PoTPTQ通过两步后训练算法，在保持甚至超越现有精度SOTA的同时，显著加速了LLM在GPU上的推理过程，尤其在低精度量化方面表现出色。", "translation": "大型语言模型（LLM）在各种自然语言处理（NLP）任务中展现出卓越的性能。然而，由于所需的大量计算资源，它们的部署面临挑战。2的幂次（PoT）量化是克服这一困难的通用工具。尽管之前关于PoT量化的工作可以在CPU上使用定点加法高效地进行去量化，但在GPU上效果不佳。原因是符号位纠缠以及去量化所需的顺序位操作。我们提出了一种新颖的LLM权重PoT量化框架，它（i）在极低精度数字格式下超越了最先进的准确性，并且（ii）通过更高效的去量化实现了更快的推理。为了保持量化模型的准确性，我们引入了一种两步后训练算法：（i）使用鲁棒的起始点初始化量化尺度，以及（ii）使用最小校准集细化这些尺度。我们的PoT后训练算法的性能超越了当前整数量化的最先进水平，特别是在2位和3位等低精度格式下。我们的PoT量化加速了浮点推理所需的去量化步骤，与均匀整数去量化相比，在NVIDIA V100上实现了3.67倍的加速，在NVIDIA RTX 4090上实现了1.63倍的加速。", "summary": "本文提出了一种名为PoTPTQ的LLM权重两步幂次后训练量化框架，旨在解决现有幂次量化在GPU上效率低下的问题。该方法通过鲁棒的尺度初始化和最小校准集精炼，在极低精度下实现了超越SOTA的准确性，并显著加速了去量化过程，从而提升了LLM的推理速度，尤其在GPU上表现优异。", "keywords": "幂次量化, 大型语言模型, 后训练量化, 低精度, 模型加速", "comments": "这篇论文通过提出一种创新的两步后训练算法，有效地解决了LLM在GPU上部署时面临的计算资源挑战和现有PoT量化效率低下的问题。其在极低精度下保持甚至超越SOTA精度的能力，并实现显著的推理加速，对于推动LLM的实际应用具有重要意义。特别是在GPU上的性能提升，弥补了现有PoT量化的不足。"}}
{"id": "2507.11724", "title": "Approaching Optimality for Solving Dense Linear Systems with Low-Rank Structure", "authors": ["Michał Dereziński", "Aaron Sidford"], "categories": ["cs.DS", "cs.NA", "math.NA", "math.OC", "stat.ML"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11724v1", "summary": "We provide new high-accuracy randomized algorithms for solving linear systems\nand regression problems that are well-conditioned except for $k$ large singular\nvalues. For solving such $d \\times d$ positive definite system our algorithms\nsucceed whp. and run in time $\\tilde O(d^2 + k^\\omega)$. For solving such\nregression problems in a matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ our\nmethods succeed whp. and run in time $\\tilde O(\\mathrm{nnz}(\\mathbf{A}) + d^2 +\nk^\\omega)$ where $\\omega$ is the matrix multiplication exponent and\n$\\mathrm{nnz}(\\mathbf{A})$ is the number of non-zeros in $\\mathbf{A}$. Our\nmethods nearly-match a natural complexity limit under dense inputs for these\nproblems and improve upon a trade-off in prior approaches that obtain running\ntimes of either $\\tilde O(d^{2.065}+k^\\omega)$ or $\\tilde O(d^2 +\ndk^{\\omega-1})$ for $d\\times d$ systems. Moreover, we show how to obtain these\nrunning times even under the weaker assumption that all but $k$ of the singular\nvalues have a suitably bounded generalized mean. Consequently, we give the\nfirst nearly-linear time algorithm for computing a multiplicative approximation\nto the nuclear norm of an arbitrary dense matrix. Our algorithms are built on\nthree general recursive preconditioning frameworks, where matrix sketching and\nlow-rank update formulas are carefully tailored to the problems' structure.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11724v1", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "解决低秩结构稠密线性系统的逼近最优算法", "tldr": "本文提出了新的高精度随机算法，用于求解具有低秩结构的稠密线性系统和回归问题，实现了接近最优的运行时间，并首次实现了核范数的近线性时间近似计算。", "motivation": "现有的求解稠密线性系统和回归问题的方法存在运行时间上的权衡（如 $\\tilde O(d^{2.065}+k^\\omega)$ 或 $\\tilde O(d^2 + dk^{\\omega-1})$），未能达到理论上的复杂性极限。本研究旨在提供接近最优运行时间的高精度算法。", "method": "算法基于三个通用的递归预处理框架，其中矩阵草图（matrix sketching）和低秩更新公式根据问题的结构进行了精心定制。即使在除 $k$ 个奇异值外，所有奇异值都具有适当有界的广义均值的较弱假设下，也能获得高效的运行时间。", "result": "对于 $d \\times d$ 正定系统，算法运行时间为 $\\tilde O(d^2 + k^\\omega)$。对于 $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ 矩阵的回归问题，运行时间为 $\\tilde O(\\mathrm{nnz}(\\mathbf{A}) + d^2 + k^\\omega)$。这些时间接近于这些问题在稠密输入下的自然复杂性极限，并改进了现有方法。此外，首次实现了任意稠密矩阵核范数乘法近似的近线性时间算法。", "conclusion": "本文提出的高精度随机算法在求解具有低秩结构的稠密线性系统和回归问题方面取得了显著进展，实现了接近最优的计算效率，并克服了现有方法的局限性。这些算法在理论和实践中都具有重要意义，尤其是在核范数近似计算方面。", "translation": "我们提供了新的高精度随机算法，用于求解除 $k$ 个大奇异值外条件良好的线性系统和回归问题。对于求解此类 $d \\times d$ 正定系统，我们的算法以高概率成功，运行时间为 $\\tilde O(d^2 + k^\\omega)$。对于求解 $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ 矩阵中的此类回归问题，我们的方法以高概率成功，运行时间为 $\\tilde O(\\mathrm{nnz}(\\mathbf{A}) + d^2 + k^\\omega)$，其中 $\\omega$ 是矩阵乘法指数，$\\mathrm{nnz}(\\mathbf{A})$ 是 $\\mathbf{A}$ 中的非零元素数量。我们的方法在这些问题的稠密输入下几乎达到了自然复杂性极限，并改进了现有方法中的权衡，后者对于 $d \\times d$ 系统获得的运行时间为 $\\tilde O(d^{2.065}+k^\\omega)$ 或 $\\tilde O(d^2 + dk^{\\omega-1})$。此外，我们展示了即使在更弱的假设下，即除 $k$ 个奇异值外，所有奇异值都具有适当有界的广义均值，也能获得这些运行时间。因此，我们首次给出了计算任意稠密矩阵核范数乘法近似的近线性时间算法。我们的算法建立在三个通用的递归预处理框架上，其中矩阵草图和低秩更新公式根据问题的结构进行了精心定制。", "summary": "本文提出了一系列新的高精度随机算法，用于高效求解具有低秩结构的稠密线性系统和回归问题。这些算法在运行时间上达到了接近理论最优的复杂度，对于 $d \\times d$ 系统为 $\\tilde O(d^2 + k^\\omega)$，对于回归问题为 $\\tilde O(\\mathrm{nnz}(\\mathbf{A}) + d^2 + k^\\omega)$，显著优于现有方法。算法核心在于递归预处理框架、矩阵草图和低秩更新公式的结合。此外，本研究首次实现了任意稠密矩阵核范数乘法近似的近线性时间计算。", "keywords": "低秩结构, 线性系统, 随机算法, 矩阵草图, 核范数", "comments": "本文的创新之处在于通过结合递归预处理、矩阵草图和低秩更新等先进技术，为具有低秩结构的稠密线性系统和回归问题实现了接近最优的计算效率。这不仅在计算复杂性理论上取得了突破，还为核范数的高效近似计算提供了首个近线性时间算法，具有重要的理论和实际应用价值。其在较弱假设下仍能保持性能的鲁棒性也值得称赞。"}}
{"id": "2501.14930", "title": "Moving-Boundary Port-Hamiltonian Systems", "authors": ["T. J. Meijer", "A. Das", "S. Weiland"], "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.14930v2", "summary": "In this paper, we consider linear boundary port-Hamiltonian distributed\nparameter systems on a time-varying spatial domain. We derive the specific\ntime-varying Dirac structure that these systems give rise to and use it to\nformally establish a new class of moving-boundary port-Hamiltonian systems by\nshowing that these distributed parameter systems on a time-varying spatial\ndomain admit a port-Hamiltonian representation. We demonstrate that our results\ncan be leveraged to develop a spatial discretization scheme with dynamic\nmeshing for approximating the telegrapher's equations on a time-varying spatial\ndomain, which we subsequently verify numerically.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.14930v2", "cate": "math.OC", "date": "2025-01-24", "updated": "2025-07-15", "AI": {"title_translation": "移动边界端口哈密顿系统", "tldr": "本文引入了一类新的移动边界端口哈密顿系统，适用于时变空间域上的分布参数系统，并展示了其在空间离散化中的应用。", "motivation": "旨在正式建立一类新的移动边界端口哈密顿系统，用于描述时变空间域上的分布参数系统。", "method": "作者考虑了时变空间域上的线性边界端口哈密顿分布参数系统，推导了其特定的时变狄拉克结构，并利用该结构证明这些系统具有端口哈密顿表示。随后，他们展示了该方法在开发具有动态网格划分的空间离散化方案中的应用。", "result": "成功建立了一类新的移动边界端口哈密顿系统，并证明了这些系统具有端口哈密顿表示。研究结果可用于开发一种具有动态网格划分的空间离散化方案，以近似时变空间域上的电报方程，并已通过数值验证。", "conclusion": "论文成功建立了一个用于移动边界端口哈密顿系统的新框架，并展示了其在数值近似中的实际应用。", "translation": "在本文中，我们考虑了时变空间域上的线性边界端口哈密顿分布参数系统。我们推导了这些系统产生的特定时变狄拉克结构，并利用它通过证明这些时变空间域上的分布参数系统具有端口哈密顿表示，从而正式建立了一类新的移动边界端口哈密顿系统。我们证明了我们的结果可以用于开发一种具有动态网格划分的空间离散化方案，用于近似时变空间域上的电报方程，随后我们对其进行了数值验证。", "summary": "本文介绍并正式建立了一类新的移动边界端口哈密顿系统。研究重点是时变空间域上的线性边界端口哈密顿分布参数系统，通过推导其时变狄拉克结构来证明它们具有端口哈密顿表示。论文通过开发和数值验证一种用于时变域上电报方程的动态网格空间离散化方案，展示了这些发现的实用性。", "keywords": "移动边界系统, 端口哈密顿系统, 分布参数系统, 时变空间域, 空间离散化", "comments": "本文在将端口哈密顿框架扩展到具有移动边界的系统方面具有创新性，这是一项重要的理论贡献。其在空间离散化动态网格划分中的应用突出了其对具有演化域的复杂系统的实际相关性，例如电报方程所描述的系统。"}}
{"id": "2504.21042", "title": "What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift", "authors": ["Jiamin Chang", "Haoyang Li", "Hammond Pearce", "Ruoxi Sun", "Bo Li", "Minhui Xue"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted to The ACM Conference on Computer and Communications Security (CCS) 2025", "url": "http://arxiv.org/abs/2504.21042v3", "summary": "The growing adoption of artificial intelligence (AI) has amplified concerns\nabout trustworthiness, including integrity, privacy, robustness, and bias. To\nassess and attribute these threats, we propose ConceptLens, a generic framework\nthat leverages pre-trained multimodal models to identify the root causes of\nintegrity threats by analyzing Concept Shift in probing samples. ConceptLens\ndemonstrates strong detection performance for vanilla data poisoning attacks\nand uncovers vulnerabilities to bias injection, such as the generation of\ncovert advertisements through malicious concept shifts. It identifies privacy\nrisks in unaltered but high-risk samples, filters them before training, and\nprovides insights into model weaknesses arising from incomplete or imbalanced\ntraining data. Additionally, at the model level, it attributes concepts that\nthe target model is overly dependent on, identifies misleading concepts, and\nexplains how disrupting key concepts negatively impacts the model. Furthermore,\nit uncovers sociological biases in generative content, revealing disparities\nacross sociological contexts. Strikingly, ConceptLens reveals how safe training\nand inference data can be unintentionally and easily exploited, potentially\nundermining safety alignment. Our study informs actionable insights to breed\ntrust in AI systems, thereby speeding adoption and driving greater innovation.", "comment": "Accepted to The ACM Conference on Computer and Communications\n  Security (CCS) 2025", "pdf_url": "http://arxiv.org/pdf/2504.21042v3", "cate": "cs.CR", "date": "2025-04-28", "updated": "2025-07-16", "AI": {"title_translation": "幕后主使是谁？通过概念漂移评估AI训练和推理中的完整性和归因", "tldr": "提出ConceptLens框架，通过分析概念漂移来评估AI训练和推理中的完整性和归因，有效检测数据投毒、偏见注入、隐私风险和模型弱点，并揭示安全数据被利用的风险。", "motivation": "人工智能（AI）的日益普及加剧了人们对信任度的担忧，包括完整性、隐私、鲁棒性和偏见。为了评估和归因这些威胁，本研究旨在提出一个通用框架。", "method": "提出ConceptLens框架，它利用预训练的多模态模型，通过分析探测样本中的“概念漂移”（Concept Shift）来识别完整性威胁的根本原因。", "result": "ConceptLens在检测普通数据投毒攻击方面表现出强大的性能，并揭示了偏见注入的脆弱性（例如通过恶意概念漂移生成隐蔽广告）。它能识别未被篡改但高风险样本中的隐私风险，并在训练前对其进行过滤，提供因不完整或不平衡训练数据导致的模型弱点的见解。在模型层面，它能归因目标模型过度依赖的概念，识别误导性概念，并解释扰乱关键概念如何对模型产生负面影响。此外，它还揭示了生成内容中的社会学偏见，揭示了不同社会学背景下的差异。值得注意的是，ConceptLens揭示了安全的训练和推理数据如何被无意中且轻易地利用，可能破坏安全对齐。", "conclusion": "本研究提供了可操作的见解，以在AI系统中建立信任，从而加速AI的采用并推动更大的创新。", "translation": "人工智能（AI）的日益普及加剧了人们对信任度的担忧，包括完整性、隐私、鲁棒性和偏见。为了评估和归因这些威胁，我们提出了ConceptLens，一个通用的框架，它利用预训练的多模态模型，通过分析探测样本中的“概念漂移”（Concept Shift）来识别完整性威胁的根本原因。ConceptLens在检测普通数据投毒攻击方面表现出强大的性能，并揭示了偏见注入的脆弱性，例如通过恶意概念漂移生成隐蔽广告。它能识别未被篡改但高风险样本中的隐私风险，并在训练前对其进行过滤，提供因不完整或不平衡训练数据导致的模型弱点的见解。此外，在模型层面，它能归因目标模型过度依赖的概念，识别误导性概念，并解释扰乱关键概念如何对模型产生负面影响。此外，它还揭示了生成内容中的社会学偏见，揭示了不同社会学背景下的差异。值得注意的是，ConceptLens揭示了安全的训练和推理数据如何被无意中且轻易地利用，可能破坏安全对齐。我们的研究提供了可操作的见解，以在AI系统中建立信任，从而加速AI的采用并推动更大的创新。", "summary": "本论文提出了一个名为ConceptLens的通用框架，旨在解决AI系统中的信任问题，特别是完整性、归因、隐私和偏见。ConceptLens利用预训练的多模态模型，通过分析“概念漂移”来识别这些威胁的根源。该框架在检测数据投毒、偏见注入和隐私风险方面表现出色，并能揭示模型因数据不平衡或特定概念依赖而产生的弱点。它还发现安全的训练和推理数据可能被无意利用的风险，强调了其在提高AI系统信任度方面的重要性。", "keywords": "AI信任, 概念漂移, 完整性, 归因, 数据投毒, 偏见注入", "comments": "ConceptLens框架的创新之处在于其通过“概念漂移”来评估AI完整性和归因的通用方法，利用了预训练的多模态模型。这为理解和缓解数据投毒、偏见注入和隐私风险提供了新的视角。尤其重要的是，它揭示了即使是看似安全的数据也可能被利用，这对于AI安全对齐领域具有重要意义。该研究为建立可信赖的AI系统提供了实用的工具和见解。"}}
{"id": "2507.11709", "title": "Double Duty: FPGA Architecture to Enable Concurrent LUT and Adder Chain Usage", "authors": ["Junius Pun", "Xilai Dai", "Grace Zgheib", "Mahesh A. Iyer", "Andrew Boutros", "Vaughn Betz", "Mohamed S. Abdelfattah"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      accepted at FPL 2025", "url": "http://arxiv.org/abs/2507.11709v1", "summary": "Flexibility and customization are key strengths of Field-Programmable Gate\nArrays (FPGAs) when compared to other computing devices. For instance, FPGAs\ncan efficiently implement arbitrary-precision arithmetic operations, and can\nperform aggressive synthesis optimizations to eliminate ineffectual operations.\nMotivated by sparsity and mixed-precision in deep neural networks (DNNs), we\ninvestigate how to optimize the current logic block architecture to increase\nits arithmetic density. We find that modern FPGA logic block architectures\nprevent the independent use of adder chains, and instead only allow adder chain\ninputs to be fed by look-up table (LUT) outputs. This only allows one of the\ntwo primitives -- either adders or LUTs -- to be used independently in one\nlogic element and prevents their concurrent use, hampering area optimizations.\nIn this work, we propose the Double Duty logic block architecture to enable the\nconcurrent use of the adders and LUTs within a logic element. Without adding\nexpensive logic cluster inputs, we use 4 of the existing inputs to bypass the\nLUTs and connect directly to the adder chain inputs. We accurately model our\nchanges at both the circuit and CAD levels using open-source FPGA development\ntools. Our experimental evaluation on a Stratix-10-like architecture\ndemonstrates area reductions of 21.6% on adder-intensive circuits from the\nKratos benchmarks, and 9.3% and 8.2% on the more general Koios and VTR\nbenchmarks respectively. These area improvements come without an impact to\ncritical path delay, demonstrating that higher density is feasible on modern\nFPGA architectures by adding more flexibility in how the adder chain is used.\nAveraged across all circuits from our three evaluated benchmark set, our Double\nDuty FPGA architecture improves area-delay product by 9.7%.", "comment": "accepted at FPL 2025", "pdf_url": "http://arxiv.org/pdf/2507.11709v1", "cate": "cs.AR", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "双重职责：实现LUT和加法器链并发使用的FPGA架构", "tldr": "提出了一种名为“双重职责”的FPGA逻辑块架构，通过允许查找表（LUT）和加法器链并发使用，显著减少了FPGA面积，同时不影响关键路径延迟。", "motivation": "受深度神经网络（DNN）中稀疏性和混合精度的启发，研究旨在优化当前FPGA逻辑块架构以提高其算术密度。发现现代FPGA逻辑块架构阻止了加法器链的独立使用，仅允许其输入来自查找表（LUT）输出，从而阻碍了面积优化。", "method": "提出“双重职责”逻辑块架构，以实现在一个逻辑单元内同时使用加法器和LUT。通过利用现有输入（4个）绕过LUT，直接连接到加法器链输入，避免了增加昂贵的逻辑簇输入。使用开源FPGA开发工具在电路和CAD级别精确建模了这些改变。", "result": "在类Stratix-10架构上的实验评估显示，在加法器密集型Kratos基准测试中面积减少了21.6%，在更通用的Koios和VTR基准测试中分别减少了9.3%和8.2%。这些面积改进没有影响关键路径延迟。平均而言，所提出的“双重职责”FPGA架构将面积-延迟积提高了9.7%。", "conclusion": "通过增加加法器链使用的灵活性，在现代FPGA架构上实现更高的密度是可行的。", "translation": "灵活性和定制化是现场可编程门阵列（FPGA）相对于其他计算设备的关键优势。例如，FPGA可以高效地实现任意精度算术运算，并能执行激进的综合优化以消除无效操作。受深度神经网络（DNN）中稀疏性和混合精度的启发，我们研究了如何优化当前的逻辑块架构以提高其算术密度。我们发现，现代FPGA逻辑块架构阻止了加法器链的独立使用，而只允许加法器链的输入由查找表（LUT）输出提供。这使得在一个逻辑单元中只能独立使用两种原语之一——无论是加法器还是LUT——并阻止了它们的并发使用，从而阻碍了面积优化。在这项工作中，我们提出了“双重职责”逻辑块架构，以实现在一个逻辑单元内加法器和LUT的并发使用。在不增加昂贵的逻辑簇输入的情况下，我们使用4个现有输入绕过LUT并直接连接到加法器链输入。我们使用开源FPGA开发工具在电路和CAD级别精确建模了我们的更改。我们对类Stratix-10架构的实验评估表明，在Kratos基准测试中，加法器密集型电路的面积减少了21.6%，在更通用的Koios和VTR基准测试中分别减少了9.3%和8.2%。这些面积改进没有影响关键路径延迟，这表明通过增加加法器链使用的灵活性，在现代FPGA架构上实现更高的密度是可行的。在我们的三个评估基准测试集的所有电路中，我们的“双重职责”FPGA架构平均将面积-延迟积提高了9.7%。", "summary": "该论文提出了名为“双重职责”的新型FPGA逻辑块架构，旨在解决现有FPGA设计中加法器链和查找表（LUT）无法并发使用的问题，从而限制了算术密度和面积优化。受DNN应用启发，该架构通过巧妙利用现有输入直接连接加法器链，实现了加法器和LUT的同步操作。实验结果显示，该架构在不同基准测试中实现了显著的面积缩减（最高达21.6%），同时保持了关键路径延迟不变，平均将面积-延迟积提高了9.7%，证明了在现代FPGA上实现更高密度的可行性。", "keywords": "FPGA架构, 加法器链, 查找表, 并发使用, 面积优化", "comments": "这项工作创新性地解决了FPGA逻辑块中LUT和加法器链并发使用受限的问题，通过修改现有输入路径而非增加昂贵的新逻辑，实现了显著的面积优化。其重要性在于，在不牺牲性能（关键路径延迟）的前提下，提高了FPGA的算术密度，这对于需要高计算效率的深度学习等应用尤为关键。该方法具有较高的实用性，因为它是基于现有架构的改进，且通过开源工具进行验证。"}}
{"id": "2507.12002", "title": "Detecting In-Person Conversations in Noisy Real-World Environments with Smartwatch Audio and Motion Sensing", "authors": ["Alice Zhang", "Callihan Bertley", "Dawei Liang", "Edison Thomaz"], "categories": ["cs.LG", "I.2.0; J.4"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12002v1", "summary": "Social interactions play a crucial role in shaping human behavior,\nrelationships, and societies. It encompasses various forms of communication,\nsuch as verbal conversation, non-verbal gestures, facial expressions, and body\nlanguage. In this work, we develop a novel computational approach to detect a\nfoundational aspect of human social interactions, in-person verbal\nconversations, by leveraging audio and inertial data captured with a commodity\nsmartwatch in acoustically-challenging scenarios. To evaluate our approach, we\nconducted a lab study with 11 participants and a semi-naturalistic study with\n24 participants. We analyzed machine learning and deep learning models with 3\ndifferent fusion methods, showing the advantages of fusing audio and inertial\ndata to consider not only verbal cues but also non-verbal gestures in\nconversations. Furthermore, we perform a comprehensive set of evaluations\nacross activities and sampling rates to demonstrate the benefits of multimodal\nsensing in specific contexts. Overall, our framework achieved 82.0$\\pm$3.0%\nmacro F1-score when detecting conversations in the lab and 77.2$\\pm$1.8% in the\nsemi-naturalistic setting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12002v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "在嘈杂的现实环境中利用智能手表音频和运动传感检测面对面对话", "tldr": "该研究开发了一种新颖的计算方法，利用智能手表捕获的音频和惯性数据，在嘈杂环境中检测面对面口头对话，并通过融合多种数据模态实现了较高的检测准确率。", "motivation": "社交互动在塑造人类行为、关系和社会方面起着至关重要的作用。本研究旨在开发一种计算方法来检测人类社交互动的一个基础方面——面对面口头对话，尤其是在声学挑战性场景中。", "method": "研究开发了一种利用智能手表捕获的音频和惯性数据来检测面对面口头对话的计算方法。通过一项包含11名参与者的实验室研究和一项包含24名参与者的半自然研究来评估该方法。分析了机器学习和深度学习模型，并使用了3种不同的融合方法，以结合口头线索和非口头手势。还对不同活动和采样率进行了全面的评估。", "result": "该框架在实验室环境中检测对话时达到了82.0±3.0%的宏观F1分数，在半自然环境中达到了77.2±1.8%的宏观F1分数。研究结果显示了融合音频和惯性数据在考虑口头线索和非口头手势方面的优势，并证明了多模态传感在特定上下文中的益处。", "conclusion": "本研究成功开发并评估了一种利用智能手表多模态数据在嘈杂现实环境中检测面对面口头对话的方法，证明了融合音频和惯性数据对于提高检测准确性的有效性。", "translation": "社交互动在塑造人类行为、关系和社会方面起着至关重要的作用。它包括各种形式的交流，如口头对话、非口头手势、面部表情和身体语言。在这项工作中，我们开发了一种新颖的计算方法，通过利用在声学挑战性场景中商品智能手表捕获的音频和惯性数据，来检测人类社交互动的一个基础方面——面对面口头对话。为了评估我们的方法，我们进行了一项包含11名参与者的实验室研究和一项包含24名参与者的半自然研究。我们分析了具有3种不同融合方法的机器学习和深度学习模型，结果显示融合音频和惯性数据在对话中不仅考虑口头线索，还考虑非口头手势的优势。此外，我们对不同活动和采样率进行了一套全面的评估，以证明多模态传感在特定上下文中的益处。总的来说，我们的框架在实验室中检测对话时达到了82.0±3.0%的宏观F1分数，在半自然环境中达到了77.2±1.8%的宏观F1分数。", "summary": "该研究提出了一种利用智能手表采集的音频和惯性数据，在嘈杂现实环境中检测面对面口头对话的新型计算方法。通过实验室和半自然研究，评估了机器学习和深度学习模型结合三种数据融合方法。结果表明，融合音频和惯性多模态数据（同时考虑口头和非口头线索）显著提高了对话检测的准确性，在实验室和半自然环境中分别达到了82.0%和77.2%的宏观F1分数。", "keywords": "智能手表, 对话检测, 多模态传感, 音频, 惯性数据", "comments": "这项研究的创新之处在于利用商品智能手表的多模态传感能力（音频和惯性数据）来解决在嘈杂现实环境中检测面对面对话的挑战。其重要性在于为理解和量化人类社交互动提供了一种非侵入式且可穿戴的解决方案，这在行为科学、健康监测和智能环境等领域具有广泛应用潜力。方法的优势在于融合了口头和非口头线索，提升了检测的鲁棒性。未来的工作可以探索更多复杂的交互模式或在更广泛的真实世界场景中进行验证。"}}
{"id": "2507.12295", "title": "Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding", "authors": ["Feng Xiao", "Jicong Fan"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12295v1", "summary": "Text anomaly detection is a critical task in natural language processing\n(NLP), with applications spanning fraud detection, misinformation\nidentification, spam detection and content moderation, etc. Despite significant\nadvances in large language models (LLMs) and anomaly detection algorithms, the\nabsence of standardized and comprehensive benchmarks for evaluating the\nexisting anomaly detection methods on text data limits rigorous comparison and\ndevelopment of innovative approaches. This work performs a comprehensive\nempirical study and introduces a benchmark for text anomaly detection,\nleveraging embeddings from diverse pre-trained language models across a wide\narray of text datasets. Our work systematically evaluates the effectiveness of\nembedding-based text anomaly detection by incorporating (1) early language\nmodels (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI\n(small, ada, large)); (3) multi-domain text datasets (news, social media,\nscientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).\nOur experiments reveal a critical empirical insight: embedding quality\nsignificantly governs anomaly detection efficacy, and deep learning-based\napproaches demonstrate no performance advantage over conventional shallow\nalgorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived\nembeddings.In addition, we observe strongly low-rank characteristics in\ncross-model performance matrices, which enables an efficient strategy for rapid\nmodel evaluation (or embedding evaluation) and selection in practical\napplications. Furthermore, by open-sourcing our benchmark toolkit that includes\nall embeddings from different models and code at\nhttps://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work\nprovides a foundation for future research in robust and scalable text anomaly\ndetection systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12295v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Text-ADBench：基于LLMs嵌入的文本异常检测基准", "tldr": "本文提出了一个名为Text-ADBench的文本异常检测基准，利用多种LLM嵌入评估了现有方法，并发现嵌入质量是关键，浅层算法在使用LLM嵌入时表现不逊于深度学习方法。", "motivation": "尽管大型语言模型和异常检测算法取得了显著进展，但缺乏标准化和全面的基准来评估文本数据上的现有异常检测方法，这限制了严格的比较和创新方法的开发。", "method": "本研究进行了一项全面的实证研究，并引入了一个文本异常检测基准。该基准利用来自不同预训练语言模型（包括早期语言模型如GloVe、BERT和多种LLM如LLaMa-2、LLama-3、Mistral、OpenAI）的嵌入，并在广泛的多领域文本数据集（新闻、社交媒体、科学出版物）上进行评估，采用AUROC和AUPRC等综合评估指标。", "result": "实验揭示了关键的经验洞察：嵌入质量显著影响异常检测效果；在使用LLM派生的嵌入时，基于深度学习的方法相对于传统的浅层算法（如KNN、Isolation Forest）没有性能优势。此外，跨模型性能矩阵中存在强烈的低秩特性，这为实际应用中快速模型（或嵌入）评估和选择提供了高效策略。", "conclusion": "这项工作为未来在鲁棒和可扩展的文本异常检测系统方面的研究奠定了基础，并通过开源其基准工具包（包含所有模型的嵌入和代码）做出了贡献。", "translation": "文本异常检测是自然语言处理（NLP）中的一项关键任务，其应用涵盖欺诈检测、错误信息识别、垃圾邮件检测和内容审核等。尽管大型语言模型（LLMs）和异常检测算法取得了显著进展，但缺乏标准化和全面的基准来评估文本数据上的现有异常检测方法，这限制了严格的比较和创新方法的开发。这项工作进行了一项全面的实证研究，并引入了一个文本异常检测基准，该基准利用来自各种预训练语言模型的嵌入，并在广泛的文本数据集上进行。我们的工作通过整合以下方面系统地评估了基于嵌入的文本异常检测的有效性：(1) 早期语言模型（GloVe、BERT）；(2) 多个大型语言模型（LLaMa-2、LLama-3、Mistral、OpenAI（small、ada、large））；(3) 多领域文本数据集（新闻、社交媒体、科学出版物）；(4) 综合评估指标（AUROC、AUPRC）。我们的实验揭示了一个关键的经验洞察：嵌入质量显著影响异常检测效果，并且在使用LLM派生的嵌入时，基于深度学习的方法相对于传统的浅层算法（例如KNN、Isolation Forest）没有性能优势。此外，我们观察到跨模型性能矩阵中存在强烈的低秩特性，这使得在实际应用中能够实现快速模型评估（或嵌入评估）和选择的高效策略。此外，通过开源我们的基准工具包（包括来自不同模型的所有嵌入和代码，网址为https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark），这项工作为未来在鲁棒和可扩展的文本异常检测系统方面的研究奠定了基础。", "summary": "本文提出了Text-ADBench，一个全面的文本异常检测基准，旨在解决现有评估标准的缺失。该基准系统地评估了多种语言模型（包括早期模型和LLMs）生成的文本嵌入在多领域数据集上的异常检测性能。研究发现嵌入质量是决定检测效果的关键因素，且在使用LLM嵌入时，传统的浅层算法表现不逊于深度学习方法。此外，观察到跨模型性能的低秩特性，这有助于实现高效的模型选择。该工作通过开源其基准工具包，为未来的研究提供了基础。", "keywords": "文本异常检测, LLMs嵌入, 基准测试, 异常检测, 语言模型", "comments": "本文的创新之处在于构建了一个全面且标准化的文本异常检测基准，填补了该领域在评估方面的空白。其重要性体现在揭示了LLM嵌入质量对异常检测的决定性作用，并挑战了深度学习方法在LLM嵌入背景下的绝对优势，指出浅层算法的有效性。此外，开源的基准工具包极大地促进了未来研究的进展。观察到的低秩特性也为高效模型选择提供了新思路。"}}
{"id": "2507.11764", "title": "AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles", "authors": ["Matteo Fasulo", "Luca Babboni", "Luca Tedeschini"], "categories": ["cs.CL", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      14 pages, 6 figures, accepted at CLEF 2025 CheckThat! Lab", "url": "http://arxiv.org/abs/2507.11764v1", "summary": "This paper presents AI Wizards' participation in the CLEF 2025 CheckThat! Lab\nTask 1: Subjectivity Detection in News Articles, classifying sentences as\nsubjective/objective in monolingual, multilingual, and zero-shot settings.\nTraining/development datasets were provided for Arabic, German, English,\nItalian, and Bulgarian; final evaluation included additional unseen languages\n(e.g., Greek, Romanian, Polish, Ukrainian) to assess generalization. Our\nprimary strategy enhanced transformer-based classifiers by integrating\nsentiment scores, derived from an auxiliary model, with sentence\nrepresentations, aiming to improve upon standard fine-tuning. We explored this\nsentiment-augmented architecture with mDeBERTaV3-base, ModernBERT-base\n(English), and Llama3.2-1B. To address class imbalance, prevalent across\nlanguages, we employed decision threshold calibration optimized on the\ndevelopment set. Our experiments show sentiment feature integration\nsignificantly boosts performance, especially subjective F1 score. This\nframework led to high rankings, notably 1st for Greek (Macro F1 = 0.51).", "comment": "14 pages, 6 figures, accepted at CLEF 2025 CheckThat! Lab", "pdf_url": "http://arxiv.org/pdf/2507.11764v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "AI Wizards在CheckThat! 2025：通过情感增强基于Transformer的嵌入用于新闻文章中的主观性检测", "tldr": "AI Wizards团队在CLEF 2025 CheckThat! Lab中，通过将情感分数整合到基于Transformer的分类器中，显著提升了新闻文章主观性检测的性能，尤其是在多语言和零样本设置下。", "motivation": "本研究旨在参与CLEF 2025 CheckThat! Lab任务1：新闻文章中的主观性检测，对句子进行主观/客观分类，并探索在单语、多语和零样本设置下的性能。", "method": "研究团队通过将辅助模型获得的情感分数与句子表示相结合，增强了基于Transformer的分类器，以改进标准微调。他们探索了mDeBERTaV3-base、ModernBERT-base（英语）和Llama3.2-1B模型，并采用决策阈值校准来解决跨语言的类别不平衡问题。", "result": "实验结果表明，情感特征的整合显著提升了性能，特别是主观F1分数。该框架获得了高排名，其中希腊语（Macro F1 = 0.51）排名第一。", "conclusion": "通过将情感特征整合到基于Transformer的分类器中，可以有效提升新闻文章主观性检测的性能，尤其是在多语言和零样本场景下表现出色。", "translation": "本文介绍了AI Wizards团队参与CLEF 2025 CheckThat! Lab任务1：新闻文章中的主观性检测的情况，该任务旨在对单语、多语和零样本设置下的句子进行主观/客观分类。研究提供了阿拉伯语、德语、英语、意大利语和保加利亚语的训练/开发数据集；最终评估包括额外的未见语言（例如希腊语、罗马尼亚语、波兰语、乌克兰语）以评估泛化能力。我们的主要策略是通过将辅助模型获得的情感分数与句子表示相结合，增强基于Transformer的分类器，旨在改进标准微调。我们使用mDeBERTaV3-base、ModernBERT-base（英语）和Llama3.2-1B探索了这种情感增强架构。为了解决跨语言普遍存在的类别不平衡问题，我们采用了在开发集上优化的决策阈值校准。我们的实验表明，情感特征的整合显著提升了性能，特别是主观F1分数。该框架获得了高排名，其中希腊语（Macro F1 = 0.51）排名第一。", "summary": "AI Wizards团队参与了CLEF 2025 CheckThat! Lab的新闻文章主观性检测任务。他们提出了一种新颖的方法，通过将情感分数整合到基于Transformer的嵌入中来增强分类器，并在mDeBERTaV3-base、ModernBERT-base和Llama3.2-1B等模型上进行了测试。为解决类别不平衡问题，采用了决策阈值校准。实验证明，情感特征的整合显著提升了性能，尤其是在多语言和零样本设置下，并在希腊语任务中取得了第一名的成绩。", "keywords": "主观性检测, Transformer, 情感分析, 多语言, CheckThat! Lab", "comments": "该论文的创新点在于将情感分数作为辅助特征整合到基于Transformer的分类器中，以提高新闻文章主观性检测的性能。这种方法在多语言和零样本设置下表现出良好的泛化能力，并在CheckThat! Lab中取得了优异的排名，显示了其重要性和实用性。然而，抽象中并未深入探讨不同语言间性能差异的具体原因或模型的计算成本。"}}
{"id": "2507.11381", "title": "From Observational Data to Clinical Recommendations: A Causal Framework for Estimating Patient-level Treatment Effects and Learning Policies", "authors": ["Rom Gutman", "Shimon Sheiba", "Omer Noy Klein", "Naama Dekel Bird", "Amit Gruber", "Doron Aronson", "Oren Caspi", "Uri Shalit"], "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11381v2", "summary": "We propose a framework for building patient-specific treatment recommendation\nmodels, building on the large recent literature on learning patient-level\ncausal models and inspired by the target trial paradigm of Hernan and Robins.\nWe focus on safety and validity, including the crucial issue of causal\nidentification when using observational data. We do not provide a specific\nmodel, but rather a way to integrate existing methods and know-how into a\npractical pipeline. We further provide a real world use-case of treatment\noptimization for patients with heart failure who develop acute kidney injury\nduring hospitalization. The results suggest our pipeline can improve patient\noutcomes over the current treatment regime.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11381v2", "cate": "stat.ML", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "从观察数据到临床建议：一个用于估计患者层面治疗效果和学习策略的因果框架", "tldr": "本文提出了一个利用观察数据构建患者特异性治疗推荐模型的因果框架，旨在通过解决因果识别问题来改善患者预后。", "motivation": "旨在利用观察数据为患者提供个性化治疗建议，并解决使用观察数据时因果识别的安全性与有效性这一关键问题。", "method": "提出了一个将现有方法和知识整合到实践性管道中的框架，而非提供特定模型。该框架建立在学习患者层面因果模型的文献基础上，并受到Hernan和Robins目标试验范式的启发，专注于因果识别。", "result": "在针对住院期间发生急性肾损伤的心力衰竭患者的治疗优化真实案例中，结果表明该管道能够改善患者预后，优于当前的治疗方案。", "conclusion": "该框架能够通过整合现有方法和知识，利用观察数据生成患者特异性治疗建议，并有望改善患者预后。", "translation": "我们提出了一个构建患者特异性治疗推荐模型的框架，该框架建立在近期大量关于学习患者层面因果模型的文献基础上，并受到Hernan和Robins目标试验范式的启发。我们关注安全性和有效性，包括使用观察数据时因果识别的关键问题。我们不提供一个具体的模型，而是一种将现有方法和知识整合到实际管道中的方式。我们进一步提供了一个真实世界的用例，即针对住院期间发生急性肾损伤的心力衰竭患者的治疗优化。结果表明，我们的管道可以改善患者预后，优于当前的治疗方案。", "summary": "本文提出了一个从观察数据中构建患者特异性治疗推荐模型的因果框架。该框架强调因果识别的安全性和有效性，并旨在整合现有方法形成一个实用的管道。通过一个心力衰竭患者急性肾损伤的真实案例，研究表明该管道能够改善患者治疗结果，优于现有方案。", "keywords": "因果推断, 患者特异性治疗, 观察数据, 临床推荐, 治疗效果", "comments": "该论文的创新之处在于提出了一个将观察数据转化为临床建议的因果框架，而非单一模型，强调了因果识别的重要性。它提供了一个实用的管道，有望桥接因果推断理论与临床实践，为个性化医疗提供了潜在的改进途径。"}}
{"id": "2502.05843", "title": "From Objects to Events: Unlocking Complex Visual Understanding in Object Detectors via LLM-guided Symbolic Reasoning", "authors": ["Yuhui Zeng", "Haoxiang Wu", "Wenjie Nie", "Xiawu Zheng", "Guangyao Chen", "Yunhang Shen", "Jun Peng", "Yonghong Tian", "Rongrong Ji"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures", "url": "http://arxiv.org/abs/2502.05843v4", "summary": "Current object detectors excel at entity localization and classification, yet\nexhibit inherent limitations in event recognition capabilities. This deficiency\narises from their architecture's emphasis on discrete object identification\nrather than modeling the compositional reasoning, inter-object correlations,\nand contextual semantics essential for comprehensive event understanding. To\naddress this challenge, we present a novel framework that expands the\ncapability of standard object detectors beyond mere object recognition to\ncomplex event understanding through LLM-guided symbolic reasoning. Our key\ninnovation lies in bridging the semantic gap between object detection and event\nunderstanding without requiring expensive task-specific training. The proposed\nplug-and-play framework interfaces with any open-vocabulary detector while\nextending their inherent capabilities across architectures. At its core, our\napproach combines (i) a symbolic regression mechanism exploring relationship\npatterns among detected entities and (ii) a LLM-guided strategically guiding\nthe search toward meaningful expressions. These discovered symbolic rules\ntransform low-level visual perception into interpretable event understanding,\nproviding a transparent reasoning path from objects to events with strong\ntransferability across domains.We compared our training-free framework against\nspecialized event recognition systems across diverse application domains.\nExperiments demonstrate that our framework enhances multiple object detector\narchitectures to recognize complex events such as illegal fishing activities\n(75% AUROC, +8.36% improvement), construction safety violations (+15.77%), and\nabnormal crowd behaviors (+23.16%). Code is available at\n\\href{https://github.com/MAC-AutoML/SymbolicDet}{here}.", "comment": "10 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2502.05843v4", "cate": "cs.CV", "date": "2025-02-09", "updated": "2025-07-16", "AI": {"title_translation": "从物体到事件：通过大型语言模型引导的符号推理解锁物体检测器中的复杂视觉理解", "tldr": "本文提出一个新颖的框架，通过大型语言模型引导的符号推理，将现有物体检测器的能力从简单的物体识别扩展到复杂的事件理解，无需昂贵的特定任务训练。", "motivation": "当前物体检测器在实体定位和分类方面表现出色，但在事件识别能力上存在固有限制。这种不足源于其架构侧重于离散物体识别，而非建模事件理解所需的组合推理、物体间关联和上下文语义。", "method": "本文提出了一个新颖的即插即用框架，通过大型语言模型（LLM）引导的符号推理，将标准物体检测器扩展到复杂事件理解。该框架无需昂贵的特定任务训练，即可弥合物体检测与事件理解之间的语义鸿沟。其核心结合了(i) 探索检测实体之间关系模式的符号回归机制，以及(ii) 大型语言模型策略性地指导搜索有意义的表达。", "result": "实验表明，该无训练框架能够增强多种物体检测器架构，以识别复杂事件，例如非法捕鱼活动（75% AUROC，提升8.36%）、建筑安全违规（提升15.77%）和异常人群行为（提升23.16%）。", "conclusion": "该框架成功地将低级视觉感知转化为可解释的事件理解，提供了一条从物体到事件的透明推理路径，并具有强大的跨领域可迁移性，有效解决了物体检测器在事件识别方面的局限性。", "translation": "当前物体检测器在实体定位和分类方面表现出色，但在事件识别能力上存在固有限制。这种不足源于其架构侧重于离散物体识别，而非建模事件理解所需的组合推理、物体间关联和上下文语义。为了解决这一挑战，我们提出了一个新颖的框架，通过大型语言模型引导的符号推理，将标准物体检测器的能力从单纯的物体识别扩展到复杂的事件理解。我们的关键创新在于，无需昂贵的特定任务训练，即可弥合物体检测与事件理解之间的语义鸿沟。所提出的即插即用框架可以与任何开放词汇检测器接口，同时扩展其跨架构的固有能力。其核心方法结合了（i）探索检测实体之间关系模式的符号回归机制，以及（ii）大型语言模型策略性地指导搜索有意义的表达。这些发现的符号规则将低级视觉感知转化为可解释的事件理解，提供了一条从物体到事件的透明推理路径，并具有强大的跨领域可迁移性。我们将我们的无训练框架与不同应用领域的专业事件识别系统进行了比较。实验表明，我们的框架增强了多种物体检测器架构，以识别复杂事件，例如非法捕鱼活动（75% AUROC，提升8.36%）、建筑安全违规（提升15.77%）和异常人群行为（提升23.16%）。代码可在\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "summary": "该研究针对现有物体检测器在复杂事件理解方面的局限性，提出了一个新颖的即插即用框架。该框架通过结合符号回归机制和LLM引导的策略性搜索，将低级视觉感知转化为可解释的事件理解。其核心创新在于无需昂贵的特定任务训练，即可弥合物体检测与事件理解之间的语义鸿沟。实验证明，该无训练框架能显著提升多种物体检测器在识别非法捕鱼、建筑安全违规和异常人群行为等复杂事件上的能力，并具有强大的跨领域可迁移性。", "keywords": "物体检测, 事件识别, LLM, 符号推理, 视觉理解", "comments": "本文的创新点在于提出了一个无需特定任务训练的“即插即用”框架，通过结合符号回归和LLM引导的推理，有效弥合物体检测与复杂事件理解之间的语义鸿沟。这种方法不仅提升了现有物体检测器的能力，还提供了透明的推理路径和强大的跨领域可迁移性，具有重要的理论和应用价值。"}}
{"id": "2503.02445", "title": "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling", "authors": ["Hao Li", "Yu-Hao Huang", "Chang Xu", "Viktor Schlegel", "Renhe Jiang", "Riza Batista-Navarro", "Goran Nenadic", "Jiang Bian"], "categories": ["cs.LG", "cs.CL", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025 Main Conference", "url": "http://arxiv.org/abs/2503.02445v5", "summary": "Time-series Generation (TSG) is a prominent research area with broad\napplications in simulations, data augmentation, and counterfactual analysis.\nWhile existing methods have shown promise in unconditional single-domain TSG,\nreal-world applications demand for cross-domain approaches capable of\ncontrolled generation tailored to domain-specific constraints and\ninstance-level requirements. In this paper, we argue that text can provide\nsemantic insights, domain information and instance-specific temporal patterns,\nto guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused\non generating realistic time series by incorporating textual descriptions. To\naddress data scarcity in this setting, we propose a novel LLM-based Multi-Agent\nframework that synthesizes diverse, realistic text-to-TS datasets. Furthermore,\nwe introduce BRIDGE, a hybrid text-controlled TSG framework that integrates\nsemantic prototypes with text description for supporting domain-level guidance.\nThis approach achieves state-of-the-art generation fidelity on 11 of 12\ndatasets, and improves controllability by up to 12% on MSE and 6% MAE compared\nto no text input generation, highlighting its potential for generating tailored\ntime-series data.", "comment": "ICML 2025 Main Conference", "pdf_url": "http://arxiv.org/pdf/2503.02445v5", "cate": "cs.LG", "date": "2025-03-04", "updated": "2025-07-16", "AI": {"title_translation": "BRIDGE：通过多智能体迭代优化和扩散建模引导文本控制时间序列生成", "tldr": "BRIDGE提出了一种文本控制的时间序列生成（TSG）方法，利用大型语言模型（LLM）驱动的多智能体框架生成文本到TS数据集，并结合语义原型实现领域级指导，在多项数据集上取得了最先进的生成效果和显著的可控性提升。", "motivation": "现有的时间序列生成（TSG）方法在无条件单领域生成方面表现良好，但现实世界应用需要能够根据特定领域约束和实例级需求进行受控生成的跨领域方法。本文提出文本可以提供语义洞察、领域信息和实例特定的时间模式来指导和改进TSG。", "method": "本文引入了“文本控制时间序列生成（Text-Controlled TSG）”任务。为解决数据稀缺问题，提出了一种新颖的基于LLM的多智能体框架来合成多样化、逼真的文本到TS数据集。此外，本文提出了BRIDGE，一个混合文本控制TSG框架，它将语义原型与文本描述相结合，以支持领域级指导。", "result": "BRIDGE方法在12个数据集中的11个上实现了最先进的生成保真度，并且与无文本输入生成相比，在MSE上将可控性提高了12%，在MAE上提高了6%。", "conclusion": "BRIDGE方法突出了其生成定制化时间序列数据的潜力。", "translation": "时间序列生成（TSG）是一个重要的研究领域，在模拟、数据增强和反事实分析中具有广泛应用。虽然现有方法在无条件单领域TSG中显示出前景，但现实世界的应用需要能够针对领域特定约束和实例级需求进行受控生成的跨领域方法。在本文中，我们认为文本可以提供语义洞察、领域信息和实例特定的时间模式，以指导和改进TSG。我们引入了“文本控制TSG”，这是一项通过整合文本描述来生成逼真时间序列的任务。为了解决这种设置中的数据稀缺性，我们提出了一种新颖的基于LLM的多智能体框架，该框架可以合成多样化、逼真的文本到TS数据集。此外，我们介绍了BRIDGE，一个混合文本控制TSG框架，它将语义原型与文本描述相结合，以支持领域级指导。这种方法在12个数据集中的11个上实现了最先进的生成保真度，并且与无文本输入生成相比，在MSE上将可控性提高了12%，在MAE上提高了6%，突出了其生成定制化时间序列数据的潜力。", "summary": "本文提出了“文本控制时间序列生成（Text-Controlled TSG）”任务，旨在通过文本描述生成逼真时间序列，以满足现实世界应用中对受控跨领域TSG的需求。为解决数据稀缺问题，研究引入了一个基于LLM的多智能体框架来合成文本到TS数据集。核心贡献是BRIDGE，一个混合文本控制TSG框架，它结合语义原型和文本描述进行领域指导。实验结果表明，BRIDGE在多项数据集上实现了最先进的生成保真度，并显著提升了可控性。", "keywords": "时间序列生成, 文本控制, 多智能体, 扩散模型, BRIDGE", "comments": "本文的创新点在于提出了“文本控制时间序列生成”这一新任务，并开发了BRIDGE框架来解决该任务中的数据稀缺和可控性问题。通过结合LLM驱动的多智能体数据合成和混合文本控制TSG，该研究为生成定制化时间序列数据提供了有效途径，具有重要的应用潜力。"}}
{"id": "2507.11949", "title": "MOSPA: Human Motion Generation Driven by Spatial Audio", "authors": ["Shuyang Xu", "Zhiyang Dou", "Mingyi Shi", "Liang Pan", "Leo Ho", "Jingbo Wang", "Yuan Liu", "Cheng Lin", "Yuexin Ma", "Wenping Wang", "Taku Komura"], "categories": ["cs.GR", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11949v1", "summary": "Enabling virtual humans to dynamically and realistically respond to diverse\nauditory stimuli remains a key challenge in character animation, demanding the\nintegration of perceptual modeling and motion synthesis. Despite its\nsignificance, this task remains largely unexplored. Most previous works have\nprimarily focused on mapping modalities like speech, audio, and music to\ngenerate human motion. As of yet, these models typically overlook the impact of\nspatial features encoded in spatial audio signals on human motion. To bridge\nthis gap and enable high-quality modeling of human movements in response to\nspatial audio, we introduce the first comprehensive Spatial Audio-Driven Human\nMotion (SAM) dataset, which contains diverse and high-quality spatial audio and\nmotion data. For benchmarking, we develop a simple yet effective\ndiffusion-based generative framework for human MOtion generation driven by\nSPatial Audio, termed MOSPA, which faithfully captures the relationship between\nbody motion and spatial audio through an effective fusion mechanism. Once\ntrained, MOSPA could generate diverse realistic human motions conditioned on\nvarying spatial audio inputs. We perform a thorough investigation of the\nproposed dataset and conduct extensive experiments for benchmarking, where our\nmethod achieves state-of-the-art performance on this task. Our model and\ndataset will be open-sourced upon acceptance. Please refer to our supplementary\nvideo for more details.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11949v1", "cate": "cs.GR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MOSPA：空间音频驱动的人体运动生成", "tldr": "本文提出了首个空间音频驱动人体运动数据集SAM和基于扩散的MOSPA模型，实现了高质量的空间音频驱动人体运动生成，并取得了最先进的性能。", "motivation": "虚拟人物对多样听觉刺激做出动态真实响应是角色动画的关键挑战，但该任务仍未被充分探索。现有工作主要关注语音、音频和音乐到运动的映射，但忽略了空间音频信号中编码的空间特征对人体运动的影响。", "method": "为了弥补现有研究的不足并实现高质量的空间音频驱动人体运动建模，本文引入了首个综合性的空间音频驱动人体运动（SAM）数据集，其中包含多样化、高质量的空间音频和运动数据。在此基础上，开发了一个简单而有效的基于扩散的生成框架MOSPA，用于空间音频驱动的人体运动生成，该框架通过有效的融合机制忠实地捕捉身体运动与空间音频之间的关系。", "result": "一旦训练完成，MOSPA能够根据不同的空间音频输入生成多样化且真实的人体运动。通过对所提出数据集的深入研究和广泛的基准实验，MOSPA在该任务上取得了最先进的性能。", "conclusion": "本文成功提出了首个空间音频驱动人体运动数据集SAM和扩散模型MOSPA，有效解决了空间音频驱动人体运动生成这一未充分探索的挑战，并取得了最先进的性能。", "translation": "启用虚拟人物对多样化听觉刺激做出动态且真实的响应，仍然是角色动画中的一个关键挑战，需要整合感知建模和运动合成。尽管其重要性，这项任务在很大程度上仍未被充分探索。大多数先前的工作主要集中于将语音、音频和音乐等模态映射到生成人体运动。然而，这些模型通常忽略了空间音频信号中编码的空间特征对人体运动的影响。为了弥补这一差距并实现对空间音频响应的人体运动的高质量建模，我们引入了第一个综合性的空间音频驱动人体运动（SAM）数据集，其中包含多样化和高质量的空间音频和运动数据。为了进行基准测试，我们开发了一个简单而有效的基于扩散的生成框架，用于空间音频驱动的人体运动生成，称为MOSPA，它通过有效的融合机制忠实地捕捉了身体运动与空间音频之间的关系。一旦训练完成，MOSPA可以根据不同的空间音频输入生成多样化且真实的人体运动。我们对所提出的数据集进行了彻底的调查，并进行了广泛的基准实验，我们的方法在该任务上取得了最先进的性能。我们的模型和数据集将在接受后开源。请参阅我们的补充视频以获取更多详细信息。", "summary": "本文针对虚拟人物响应空间音频的运动生成这一未充分探索的挑战，提出了首个综合性的空间音频驱动人体运动（SAM）数据集。同时，开发了一个基于扩散的生成模型MOSPA，该模型通过有效的融合机制捕捉身体运动与空间音频的关系。实验证明，MOSPA能够生成多样且真实的人体运动，并在该任务上取得了最先进的性能。该模型和数据集承诺开源。", "keywords": "空间音频, 人体运动生成, 扩散模型, 数据集, 角色动画", "comments": "本文的创新点在于首次关注空间音频对人体运动生成的影响，并为此构建了第一个大规模高质量的SAM数据集。提出的MOSPA模型结合扩散机制和有效融合，实现了SOTA性能。该研究填补了现有音频驱动运动生成领域的一个重要空白，并承诺开源数据集和模型，对未来的研究具有重要推动作用。"}}
{"id": "2507.11990", "title": "ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation", "authors": ["Hyun-Jun Jin", "Young-Eun Kim", "Seong-Whan Lee"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11990v1", "summary": "Recently, personalized portrait generation with a text-to-image diffusion\nmodel has significantly advanced with Textual Inversion, emerging as a\npromising approach for creating high-fidelity personalized images. Despite its\npotential, current Textual Inversion methods struggle to maintain consistent\nfacial identity due to semantic misalignments between textual and visual\nembedding spaces regarding identity. We introduce ID-EA, a novel framework that\nguides text embeddings to align with visual identity embeddings, thereby\nimproving identity preservation in a personalized generation. ID-EA comprises\ntwo key components: the ID-driven Enhancer (ID-Enhancer) and the ID-conditioned\nAdapter (ID-Adapter). First, the ID-Enhancer integrates identity embeddings\nwith a textual ID anchor, refining visual identity embeddings derived from a\nface recognition model using representative text embeddings. Then, the\nID-Adapter leverages the identity-enhanced embedding to adapt the text\ncondition, ensuring identity preservation by adjusting the cross-attention\nmodule in the pre-trained UNet model. This process encourages the text features\nto find the most related visual clues across the foreground snippets. Extensive\nquantitative and qualitative evaluations demonstrate that ID-EA substantially\noutperforms state-of-the-art methods in identity preservation metrics while\nachieving remarkable computational efficiency, generating personalized\nportraits approximately 15 times faster than existing approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11990v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "ID-EA：基于身份驱动的文本增强与适应，结合文本反演实现个性化文本到图像生成", "tldr": "ID-EA通过文本增强和适应，解决了文本反演在个性化文本到图像生成中身份一致性差的问题，显著提高了身份保留和生成速度。", "motivation": "现有的文本反演方法在个性化肖像生成中，由于文本和视觉嵌入空间中身份相关的语义不对齐，难以保持一致的面部身份。", "method": "提出ID-EA框架，包含ID驱动增强器（ID-Enhancer）和ID条件适配器（ID-Adapter）。ID-Enhancer将身份嵌入与文本ID锚点集成，利用代表性文本嵌入细化从人脸识别模型获得的视觉身份嵌入。ID-Adapter利用增强后的身份嵌入调整文本条件，通过调整预训练UNet模型中的交叉注意力模块来确保身份保留，促使文本特征找到前景片段中最相关的视觉线索。", "result": "ID-EA在身份保留指标上显著优于现有最先进方法，并实现了卓越的计算效率，生成个性化肖像的速度比现有方法快约15倍。", "conclusion": "ID-EA通过其创新的文本增强和适应机制，有效解决了个性化文本到图像生成中身份保持的挑战，并显著提升了生成效率。", "translation": "最近，利用文本到图像扩散模型进行个性化肖像生成在文本反演技术的推动下取得了显著进展，成为创建高保真个性化图像的一种有前景的方法。尽管其潜力巨大，但当前的文本反演方法由于文本和视觉嵌入空间在身份方面的语义不对齐，难以保持一致的面部身份。我们引入了ID-EA，一个新颖的框架，它引导文本嵌入与视觉身份嵌入对齐，从而改善个性化生成中的身份保留。ID-EA包含两个关键组件：ID驱动增强器（ID-Enhancer）和ID条件适配器（ID-Adapter）。首先，ID-Enhancer将身份嵌入与文本ID锚点集成，利用代表性文本嵌入细化从人脸识别模型获得的视觉身份嵌入。然后，ID-Adapter利用经过身份增强的嵌入来适应文本条件，通过调整预训练UNet模型中的交叉注意力模块来确保身份保留。这个过程鼓励文本特征在前景色块中找到最相关的视觉线索。广泛的定量和定性评估表明，ID-EA在身份保留指标上显著优于现有最先进方法，同时实现了卓越的计算效率，生成个性化肖像的速度比现有方法快约15倍。", "summary": "ID-EA是一个新颖的框架，旨在解决文本到图像生成中个性化肖像身份一致性差的问题。它通过ID驱动增强器细化视觉身份嵌入，并通过ID条件适配器调整文本条件以保持身份。实验证明，ID-EA在身份保留和计算效率方面均显著优于现有方法，生成速度提升15倍。", "keywords": "文本到图像生成, 文本反演, 身份保留, 个性化生成, 扩散模型", "comments": "这篇论文的创新点在于提出了一个双组件框架ID-EA，通过同时增强身份嵌入和适应文本条件来解决文本到图像生成中身份一致性差的问题。其显著的性能提升，尤其是在生成速度上的巨大优势（快15倍），使其在个性化图像生成领域具有重要的实用价值和影响力。"}}
{"id": "2507.12341", "title": "Nonlinear Concept Erasure: a Density Matching Approach", "authors": ["Antoine Saillenfest", "Pirmin Lemberger"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      17 pages, 10 figures, accepted for publication in ECAI 2025 (28th European Conference on Artificial Intelligence)", "url": "http://arxiv.org/abs/2507.12341v1", "summary": "Ensuring that neural models used in real-world applications cannot infer\nsensitive information, such as demographic attributes like gender or race, from\ntext representations is a critical challenge when fairness is a concern. We\naddress this issue through concept erasure, a process that removes information\nrelated to a specific concept from distributed representations while preserving\nas much of the remaining semantic information as possible. Our approach\ninvolves learning an orthogonal projection in the embedding space, designed to\nmake the class-conditional feature distributions of the discrete concept to\nerase indistinguishable after projection. By adjusting the rank of the\nprojector, we control the extent of information removal, while its\northogonality ensures strict preservation of the local structure of the\nembeddings. Our method, termed $\\overline{\\mathrm{L}}$EOPARD, achieves\nstate-of-the-art performance in nonlinear erasure of a discrete attribute on\nclassic natural language processing benchmarks. Furthermore, we demonstrate\nthat $\\overline{\\mathrm{L}}$EOPARD effectively mitigates bias in deep nonlinear\nclassifiers, thereby promoting fairness.", "comment": "17 pages, 10 figures, accepted for publication in ECAI 2025 (28th\n  European Conference on Artificial Intelligence)", "pdf_url": "http://arxiv.org/pdf/2507.12341v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "非线性概念擦除：一种密度匹配方法", "tldr": "本文提出了一种名为 $\\overline{\\mathrm{L}}$EOPARD 的非线性概念擦除方法，通过学习正交投影来消除文本表示中的敏感信息，同时保留语义信息，并在NLP基准测试中达到了最先进的性能，有效缓解了深度非线性分类器中的偏见。", "motivation": "在现实世界的应用中，确保神经网络模型无法从文本表示中推断出敏感信息（如性别或种族等人口统计学属性）是一个关键挑战，尤其是在关注公平性时。本文旨在通过概念擦除来解决这个问题，即从分布式表示中移除与特定概念相关的信息，同时尽可能保留其余的语义信息。", "method": "本文通过学习嵌入空间中的一个正交投影来实现概念擦除。该投影旨在使要擦除的离散概念的类别条件特征分布在投影后变得无法区分。通过调整投影器（projector）的秩，可以控制信息移除的程度，而其正交性则确保了嵌入局部结构的严格保留。该方法被称为 $\\overline{\\mathrm{L}}$EOPARD。", "result": "本文提出的 $\\overline{\\mathrm{L}}$EOPARD 方法在经典自然语言处理基准测试中，对离散属性的非线性擦除达到了最先进的性能。此外，研究表明 $\\overline{\\mathrm{L}}$EOPARD 有效地缓解了深度非线性分类器中的偏见。", "conclusion": "$\\overline{\\mathrm{L}}$EOPARD 是一种有效的非线性概念擦除方法，通过正交投影在消除敏感信息的同时保留了语义信息，并在NLP公平性任务中表现出色，能够缓解深度非线性分类器中的偏见。", "translation": "确保在现实世界应用中使用的神经网络模型无法从文本表示中推断出敏感信息，例如性别或种族等人口统计学属性，是公平性关注的一个关键挑战。我们通过概念擦除来解决这个问题，这是一个从分布式表示中移除与特定概念相关信息的过程，同时尽可能保留其余的语义信息。我们的方法涉及在嵌入空间中学习一个正交投影，旨在使要擦除的离散概念的类别条件特征分布在投影后变得无法区分。通过调整投影器（projector）的秩，我们可以控制信息移除的程度，而其正交性确保了嵌入局部结构的严格保留。我们的方法，命名为 $\\overline{\\mathrm{L}}$EOPARD，在经典自然语言处理基准测试中，对离散属性的非线性擦除达到了最先进的性能。此外，我们证明 $\\overline{\\mathrm{L}}$EOPARD 有效地缓解了深度非线性分类器中的偏见，从而促进了公平性。", "summary": "本文提出了一种名为 $\\overline{\\mathrm{L}}$EOPARD 的非线性概念擦除方法，旨在解决神经网络模型从文本表示中推断敏感信息（如人口统计学属性）的问题，以促进公平性。该方法通过学习嵌入空间中的一个正交投影，使得待擦除离散概念的类别条件特征分布在投影后变得不可区分。通过调整投影器秩来控制信息移除量，同时正交性保证了嵌入局部结构的严格保留。实验结果表明，$\\overline{\\mathrm{L}}$EOPARD 在非线性概念擦除方面达到了最先进的性能，并且能够有效缓解深度非线性分类器中的偏见。", "keywords": "概念擦除, 公平性, 非线性, 正交投影, 密度匹配", "comments": "该论文提出了一种新颖的非线性概念擦除方法 $\\overline{\\mathrm{L}}$EOPARD，其创新点在于利用正交投影来精确控制信息移除的程度，同时严格保留嵌入的局部语义结构。这种方法在解决模型公平性问题上具有重要意义，尤其是在处理文本表示中的敏感属性时。其在NLP基准测试中取得的最先进性能，以及对深度非线性分类器偏见的有效缓解，都突显了其在实际应用中的潜力。"}}
{"id": "2507.11866", "title": "Similarity-Guided Diffusion for Contrastive Sequential Recommendation", "authors": ["Jinkyeong Choi", "Yejin Noh", "Donghyeon Park"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      14 pages, 5 figures", "url": "http://arxiv.org/abs/2507.11866v1", "summary": "In sequential recommendation systems, data augmentation and contrastive\nlearning techniques have recently been introduced using diffusion models to\nachieve robust representation learning. However, most of the existing\napproaches use random augmentation, which risk damaging the contextual\ninformation of the original sequence. Accordingly, we propose a\nSimilarity-Guided Diffusion for Contrastive Sequential Recommendation. Our\nmethod leverages the similarity between item embedding vectors to generate\nsemantically consistent noise. Moreover, we utilize high confidence score in\nthe denoising process to select our augmentation positions. This approach more\neffectively reflects contextual and structural information compared to\naugmentation at random positions. From a contrastive learning perspective, the\nproposed augmentation technique provides more discriminative positive and\nnegative samples, simultaneously improving training efficiency and\nrecommendation performance. Experimental results on five benchmark datasets\nshow that SimDiffRec outperforms the existing baseline models.", "comment": "14 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.11866v1", "cate": "cs.IR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "相似性引导扩散用于对比序列推荐", "tldr": "本文提出SimDiffRec，一种用于序列推荐的相似性引导扩散模型，通过生成语义一致的噪声和基于高置信度选择增强位置，解决了传统随机增强破坏上下文信息的问题，从而在对比学习中提供更具区分性的样本，提升了推荐性能。", "motivation": "现有序列推荐系统中，基于扩散模型的随机数据增强方法可能破坏原始序列的上下文信息。", "method": "本文提出SimDiffRec模型，利用物品嵌入向量的相似性生成语义一致的噪声，并在去噪过程中基于高置信度分数选择数据增强位置，以更好地反映上下文和结构信息，为对比学习提供更具区分性的正负样本。", "result": "在五个基准数据集上的实验结果表明，SimDiffRec的性能优于现有基线模型。", "conclusion": "本文提出了一种新的相似性引导扩散模型SimDiffRec，通过改进数据增强策略，有效解决了随机增强破坏上下文信息的问题，显著提升了序列推荐的性能和训练效率。", "translation": "在序列推荐系统中，最近引入了使用扩散模型的数据增强和对比学习技术，以实现鲁棒的表示学习。然而，大多数现有方法使用随机增强，这有破坏原始序列上下文信息的风险。因此，我们提出了一种用于对比序列推荐的相似性引导扩散模型。我们的方法利用物品嵌入向量之间的相似性来生成语义一致的噪声。此外，我们在去噪过程中利用高置信度分数来选择我们的增强位置。与随机位置的增强相比，这种方法更有效地反映了上下文和结构信息。从对比学习的角度来看，所提出的增强技术提供了更具区分性的正负样本，同时提高了训练效率和推荐性能。在五个基准数据集上的实验结果表明，SimDiffRec优于现有基线模型。", "summary": "本文针对序列推荐系统中扩散模型随机数据增强可能破坏上下文信息的问题，提出了一种名为SimDiffRec的相似性引导扩散模型。该模型通过利用物品嵌入相似性生成语义一致的噪声，并根据去噪过程中的高置信度选择增强位置。这种方法能更有效地保留上下文和结构信息，从而为对比学习提供更具区分性的样本，最终提高了训练效率和推荐性能。实验结果表明，SimDiffRec在多个基准数据集上优于现有基线模型。", "keywords": "序列推荐, 对比学习, 扩散模型, 数据增强, 相似性引导", "comments": "论文创新性地将相似性引导机制引入扩散模型的数据增强过程，解决了传统随机增强可能破坏序列上下文信息的问题。通过生成语义一致的噪声和基于置信度选择增强位置，提高了数据增强的质量，从而提升了对比学习的效果和推荐性能。这是一个有潜力的方向，可以进一步探索其在不同类型序列数据上的泛化能力。"}}
{"id": "2507.11889", "title": "NemeSys: An Online Underwater Explorer with Goal-Driven Adaptive Autonomy", "authors": ["Adnan Abdullah", "Alankrit Gupta", "Vaishnav Ramesh", "Shivali Patel", "Md Jahidul Islam"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      10 pages, V1", "url": "http://arxiv.org/abs/2507.11889v1", "summary": "Adaptive mission control and dynamic parameter reconfiguration are essential\nfor autonomous underwater vehicles (AUVs) operating in GPS-denied,\ncommunication-limited marine environments. However, most current AUV platforms\nexecute static, pre-programmed missions or rely on tethered connections and\nhigh-latency acoustic channels for mid-mission updates, significantly limiting\ntheir adaptability and responsiveness. In this paper, we introduce NemeSys, a\nnovel AUV system designed to support real-time mission reconfiguration through\ncompact optical and magnetoelectric (OME) signaling facilitated by floating\nbuoys. We present the full system design, control architecture, and a semantic\nmission encoding framework that enables interactive exploration and task\nadaptation via low-bandwidth communication. The proposed system is validated\nthrough analytical modeling, controlled experimental evaluations, and\nopen-water trials. Results confirm the feasibility of online mission adaptation\nand semantic task updates, highlighting NemeSys as an online AUV platform for\ngoal-driven adaptive autonomy in dynamic and uncertain underwater environments.", "comment": "10 pages, V1", "pdf_url": "http://arxiv.org/pdf/2507.11889v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "NemeSys: 一种具有目标驱动自适应自主能力的在线水下探测器", "tldr": "NemeSys是一个新型AUV系统，通过紧凑的光学和磁电信号以及浮标实现实时任务重配置，解决了水下环境AUV适应性和响应性差的问题。", "motivation": "当前大多数AUV平台执行静态预编程任务，或依赖系绳连接和高延迟声学信道进行任务中期更新，这严重限制了它们在GPS拒止、通信受限的海洋环境中的适应性和响应性。", "method": "本文引入了NemeSys，一种新型AUV系统，通过浮标辅助的紧凑光学和磁电（OME）信令支持实时任务重配置。系统包括完整系统设计、控制架构和语义任务编码框架，通过低带宽通信实现交互式探索和任务适应。通过分析建模、受控实验评估和开阔水域试验对系统进行了验证。", "result": "结果证实了在线任务适应和语义任务更新的可行性。", "conclusion": "NemeSys是一个用于动态和不确定水下环境中，实现目标驱动自适应自主的在线AUV平台。", "translation": "自适应任务控制和动态参数重配置对于在GPS拒止、通信受限的海洋环境中运行的自主水下航行器（AUV）至关重要。然而，当前大多数AUV平台执行静态的预编程任务或依赖系绳连接和高延迟声学信道进行任务中期更新，这严重限制了它们的适应性和响应性。在本文中，我们介绍了NemeSys，一种新型AUV系统，旨在通过浮标辅助的紧凑光学和磁电（OME）信令支持实时任务重配置。我们展示了完整的系统设计、控制架构以及一个语义任务编码框架，该框架通过低带宽通信实现交互式探索和任务适应。所提出的系统通过分析建模、受控实验评估和开阔水域试验进行了验证。结果证实了在线任务适应和语义任务更新的可行性，突出了NemeSys作为在动态和不确定水下环境中实现目标驱动自适应自主的在线AUV平台。", "summary": "NemeSys是一个针对水下AUV在GPS拒止、通信受限环境中适应性差的问题而设计的新型系统。它通过浮标辅助的紧凑光学和磁电（OME）信号，实现了实时任务重配置和低带宽通信下的交互式探索与任务适应。该系统经过分析建模、实验和开阔水域试验验证，证明了其在线任务适应和语义任务更新的能力，为水下AUV的自适应自主提供了解决方案。", "keywords": "AUV, 自适应自主, 任务重配置, OME信令, 水下探索", "comments": "NemeSys的创新之处在于利用紧凑的光学和磁电（OME）信号结合浮标，解决了水下AUV实时通信和任务重配置的难题，尤其是在GPS拒止和通信受限的恶劣环境中。其语义任务编码框架也提升了系统的智能性和适应性，对于未来水下自主探索具有重要意义。"}}
{"id": "2507.11625", "title": "MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering", "authors": ["Varun Srivastava", "Fan Lei", "Srija Mukhopadhyay", "Vivek Gupta", "Ross Maciejewski"], "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Published as a conference paper at COLM 2025", "url": "http://arxiv.org/abs/2507.11625v1", "summary": "Recent advancements in multimodal large language models (MLLMs) have driven\nresearchers to explore how well these models read data visualizations, e.g.,\nbar charts, scatter plots. More recently, attention has shifted to visual\nquestion answering with maps (Map-VQA). However, Map-VQA research has primarily\nfocused on choropleth maps, which cover only a limited range of thematic\ncategories and visual analytical tasks. To address these gaps, we introduce\nMapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three\nmap types: choropleth maps, cartograms, and proportional symbol maps spanning\ntopics from six distinct themes (e.g., housing, crime). We evaluate multiple\nMLLMs using six visual analytical tasks, comparing their performance against\none another and a human baseline. An additional experiment examining the impact\nof map design changes (e.g., altered color schemes, modified legend designs,\nand removal of map elements) provides insights into the robustness and\nsensitivity of MLLMs, their reliance on internal geographic knowledge, and\npotential avenues for improving Map-VQA performance.", "comment": "Published as a conference paper at COLM 2025", "pdf_url": "http://arxiv.org/pdf/2507.11625v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "MapIQ：基准测试多模态大型语言模型在地图问答方面的表现", "tldr": "引入了MapIQ数据集，用于评估多模态大语言模型在不同地图类型和视觉分析任务上的问答能力，并探讨了地图设计变化对模型性能的影响。", "motivation": "现有的地图视觉问答（Map-VQA）研究主要集中在专题地图，覆盖的主题和视觉分析任务有限，存在研究空白。", "method": "引入了MapIQ基准数据集，包含14,706个问答对，涵盖专题地图、变形地图和比例符号地图三种类型，涉及六个不同主题。使用六种视觉分析任务评估了多个多模态大型语言模型，并与人类基线进行比较。额外实验探讨了地图设计变化（如颜色方案、图例设计、地图元素移除）的影响。", "result": "通过评估比较了不同多模态大型语言模型的性能，并揭示了地图设计变化对模型鲁棒性、敏感性、对内部地理知识的依赖以及改进Map-VQA性能的潜在途径的影响。", "conclusion": "MapIQ数据集和相关实验为评估和改进多模态大型语言模型在地图问答方面的能力提供了基准和见解，有助于未来Map-VQA性能的提升。", "translation": "多模态大型语言模型（MLLMs）的最新进展促使研究人员探索这些模型阅读数据可视化（例如，条形图、散点图）的程度。最近，注意力已转向地图视觉问答（Map-VQA）。然而，Map-VQA研究主要集中在专题地图，这只涵盖了有限的主题类别和视觉分析任务。为了解决这些空白，我们引入了MapIQ，这是一个基准数据集，包含14,706个问答对，涵盖三种地图类型：专题地图、变形地图和比例符号地图，涉及六个不同主题（例如，住房、犯罪）。我们使用六种视觉分析任务评估了多个MLLMs，并比较了它们彼此以及与人类基线之间的性能。一项额外实验检查了地图设计变化（例如，改变颜色方案、修改图例设计和移除地图元素）的影响，提供了关于MLLMs鲁棒性和敏感性、它们对内部地理知识的依赖以及改进Map-VQA性能的潜在途径的见解。", "summary": "本研究针对现有地图视觉问答（Map-VQA）研究在地图类型和分析任务上的局限性，提出了MapIQ，一个包含14,706个问答对的基准数据集，涵盖专题地图、变形地图和比例符号地图，以及六个不同主题。研究评估了多个多模态大型语言模型（MLLMs）在六种视觉分析任务上的表现，并与人类基线进行对比。此外，通过探究地图设计变化对模型性能的影响，揭示了MLLMs的鲁棒性、敏感性及其对地理知识的依赖，为未来Map-VQA的改进提供了方向。", "keywords": "多模态大型语言模型, 地图问答, 基准数据集, MapIQ, 地图可视化", "comments": "MapIQ的创新之处在于其构建了一个更全面、多样化的地图问答数据集，超越了以往仅关注专题地图的局限，涵盖了多种地图类型和主题。这项工作对于推动多模态大型语言模型在复杂地理数据理解和问答领域的应用具有重要意义，尤其是在评估模型对地图设计变化的鲁棒性方面，为模型改进提供了宝贵的见解。"}}
{"id": "2507.00406", "title": "Partnering with AI: A Pedagogical Feedback System for LLM Integration into Programming Education", "authors": ["Niklas Scholz", "Manh Hung Nguyen", "Adish Singla", "Tomohiro Nagashima"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      This is an extended version of a poster paper accepted and published at ECTEL-2025", "url": "http://arxiv.org/abs/2507.00406v2", "summary": "Feedback is one of the most crucial components to facilitate effective\nlearning. With the rise of large language models (LLMs) in recent years,\nresearch in programming education has increasingly focused on automated\nfeedback generation to help teachers provide timely support to every student.\nHowever, prior studies often overlook key pedagogical principles, such as\nmastery and progress adaptation, that shape effective feedback strategies. This\npaper introduces a novel pedagogical framework for LLM-driven feedback\ngeneration derived from established feedback models and local insights from\nsecondary school teachers. To evaluate this framework, we implemented a\nweb-based application for Python programming with LLM-based feedback that\nfollows the framework and conducted a mixed-method evaluation with eight\nsecondary-school computer science teachers. Our findings suggest that teachers\nconsider that, when aligned with the framework, LLMs can effectively support\nstudents and even outperform human teachers in certain scenarios through\ninstant and precise feedback. However, we also found several limitations, such\nas its inability to adapt feedback to dynamic classroom contexts. Such a\nlimitation highlights the need to complement LLM-generated feedback with human\nexpertise to ensure effective student learning. This work demonstrates an\neffective way to use LLMs for feedback while adhering to pedagogical standards\nand highlights important considerations for future systems.", "comment": "This is an extended version of a poster paper accepted and published\n  at ECTEL-2025", "pdf_url": "http://arxiv.org/pdf/2507.00406v2", "cate": "cs.CY", "date": "2025-07-01", "updated": "2025-07-16", "AI": {"title_translation": "与AI合作：一个将LLM集成到编程教育中的教学反馈系统", "tldr": "本文提出了一个基于教学原则的LLM驱动反馈框架，并通过一个Python编程应用进行评估。研究发现LLM在提供即时精确反馈方面有效，但仍需人类专业知识补充以适应动态课堂。", "motivation": "现有编程教育中的自动化反馈系统常忽视关键教学原则（如掌握和进度适应性）。随着大型语言模型（LLMs）的兴起，研究需要探索如何利用LLMs生成符合教学标准的反馈，以帮助教师及时支持学生。", "method": "本文提出了一个源自既有反馈模型和中学教师本地洞察的LLM驱动反馈生成教学框架。为评估该框架，作者实现了一个基于该框架的、带有LLM反馈的Python编程网络应用，并与八名中学计算机科学教师进行了混合方法评估。", "result": "研究发现，当与所提框架对齐时，教师认为LLMs能有效支持学生，甚至在某些场景下通过即时精确反馈优于人类教师。然而，也发现了局限性，例如LLM无法适应动态课堂环境。", "conclusion": "这项工作展示了一种在遵守教学标准的同时有效使用LLMs进行反馈的方法，并强调了未来系统需要考虑的重要因素，即LLM生成的反馈需要人类专业知识的补充以确保有效的学生学习。", "translation": "反馈是促进有效学习最关键的组成部分之一。近年来，随着大型语言模型（LLMs）的兴起，编程教育领域的研究日益关注自动化反馈生成，以帮助教师为每位学生提供及时支持。然而，以往的研究往往忽视了塑造有效反馈策略的关键教学原则，例如掌握和进度适应性。本文介绍了一种新颖的、源自既有反馈模型和中学教师本地洞察的LLM驱动反馈生成教学框架。为了评估该框架，我们实现了一个基于该框架的、带有LLM反馈的Python编程网络应用，并与八名中学计算机科学教师进行了混合方法评估。我们的研究结果表明，教师们认为，当与该框架对齐时，LLMs可以有效支持学生，甚至在某些场景下通过即时精确反馈超越人类教师。然而，我们也发现了一些局限性，例如它无法适应动态课堂环境。这种局限性凸显了需要用人类专业知识补充LLM生成的反馈，以确保学生有效学习。这项工作展示了一种在遵守教学标准的同时有效使用LLMs进行反馈的方法，并强调了未来系统需要考虑的重要因素。", "summary": "本文针对编程教育中自动化反馈系统忽视教学原则的问题，提出了一个基于既有模型和教师洞察的LLM驱动教学反馈框架。通过开发一个Python编程Web应用并进行混合方法评估，研究发现LLM能有效提供即时精确反馈，甚至在某些方面超越人类教师。然而，LLM在适应动态课堂环境方面存在局限性，表明LLM反馈需与人类专业知识结合。该研究为LLM在教育反馈中的应用提供了有效途径和未来发展方向。", "keywords": "LLM, 教学反馈, 编程教育, 人工智能, 教学原则", "comments": "该论文的创新之处在于提出了一个结合教学原则和本地教师洞察的LLM驱动反馈框架，这弥补了现有自动化反馈系统在教学有效性上的不足。其重要性在于证明了LLM在编程教育中提供即时精确反馈的潜力，并提出了“人机协作”的理念，即LLM应与人类专业知识互补，以应对动态复杂的教学场景，这为未来教育AI系统的发展提供了重要指导。"}}
{"id": "2507.12177", "title": "Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification", "authors": ["Zahid Ullah", "Dragan Pamucar", "Jihie Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12177v1", "summary": "Magnetic Resonance Imaging (MRI) is widely recognized as the most reliable\ntool for detecting tumors due to its capability to produce detailed images that\nreveal their presence. However, the accuracy of diagnosis can be compromised\nwhen human specialists evaluate these images. Factors such as fatigue, limited\nexpertise, and insufficient image detail can lead to errors. For example, small\ntumors might go unnoticed, or overlap with healthy brain regions could result\nin misidentification. To address these challenges and enhance diagnostic\nprecision, this study proposes a novel double ensembling framework, consisting\nof ensembled pre-trained deep learning (DL) models for feature extraction and\nensembled fine-tuned hyperparameter machine learning (ML) models to efficiently\nclassify brain tumors. Specifically, our method includes extensive\npreprocessing and augmentation, transfer learning concepts by utilizing various\npre-trained deep convolutional neural networks and vision transformer networks\nto extract deep features from brain MRI, and fine-tune hyperparameters of ML\nclassifiers. Our experiments utilized three different publicly available Kaggle\nMRI brain tumor datasets to evaluate the pre-trained DL feature extractor\nmodels, ML classifiers, and the effectiveness of an ensemble of deep features\nalong with an ensemble of ML classifiers for brain tumor classification. Our\nresults indicate that the proposed feature fusion and classifier fusion improve\nupon the state of the art, with hyperparameter fine-tuning providing a\nsignificant enhancement over the ensemble method. Additionally, we present an\nablation study to illustrate how each component contributes to accurate brain\ntumor classification.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12177v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "混合集成方法：最优深度特征融合与超参数调优分类器集成，用于增强脑肿瘤分类", "tldr": "提出一种双重集成框架，结合深度特征融合和超参数调优的分类器集成，以提高脑肿瘤MRI图像的诊断精度。", "motivation": "人工评估MRI图像诊断肿瘤存在疲劳、专业知识有限和图像细节不足等问题，导致诊断准确性受损，如漏诊小肿瘤或误识别。", "method": "本研究提出一种新颖的双重集成框架，包括：1) 集成预训练深度学习（DL）模型用于特征提取，具体利用各种预训练的深度卷积神经网络和视觉Transformer网络从脑部MRI中提取深度特征；2) 集成超参数调优的机器学习（ML）模型进行高效分类。方法还包括广泛的预处理和数据增强，并利用迁移学习概念。实验在三个公开的Kaggle MRI脑肿瘤数据集上进行评估。", "result": "所提出的特征融合和分类器融合方法优于现有技术水平。超参数微调比集成方法提供了显著的增强。此外，通过消融研究说明了每个组件对准确脑肿瘤分类的贡献。", "conclusion": "本文提出的双重集成框架，结合深度特征融合和超参数调优的分类器集成，能够有效提高脑肿瘤MRI图像的诊断精度，并超越现有技术水平。", "translation": "磁共振成像（MRI）因其能够生成揭示肿瘤存在的详细图像而被广泛认为是检测肿瘤最可靠的工具。然而，当人类专家评估这些图像时，诊断的准确性可能会受到影响。疲劳、专业知识有限和图像细节不足等因素可能导致错误。例如，小肿瘤可能被忽视，或者与健康脑区域的重叠可能导致误识别。为了解决这些挑战并提高诊断精度，本研究提出了一种新颖的双重集成框架，该框架由用于特征提取的集成预训练深度学习（DL）模型和用于有效分类脑肿瘤的集成超参数调优机器学习（ML）模型组成。具体来说，我们的方法包括广泛的预处理和数据增强，通过利用各种预训练的深度卷积神经网络和视觉Transformer网络从脑部MRI中提取深度特征的迁移学习概念，以及对ML分类器进行超参数微调。我们的实验利用三个不同的公开Kaggle MRI脑肿瘤数据集来评估预训练的DL特征提取器模型、ML分类器，以及深度特征集成与ML分类器集成在脑肿瘤分类中的有效性。我们的结果表明，所提出的特征融合和分类器融合改进了现有技术水平，其中超参数微调比集成方法提供了显著的增强。此外，我们还进行了一项消融研究，以说明每个组件如何有助于准确的脑肿瘤分类。", "summary": "本文提出一种新颖的双重集成框架，用于增强脑肿瘤MRI图像的诊断精度。该框架结合了深度学习模型的特征提取集成和超参数调优的机器学习分类器集成。通过广泛的预处理、数据增强和迁移学习，从MRI图像中提取深度特征并进行分类。实验证明，该方法在特征融合和分类器融合方面优于现有技术，且超参数调优显著提升了性能。", "keywords": "脑肿瘤分类, 深度特征融合, 分类器集成, 超参数调优, 磁共振成像", "comments": "本文的创新点在于提出了一个双重集成框架，结合了深度特征融合和超参数调优的机器学习分类器集成，有效解决了人工诊断脑肿瘤的局限性。其方法论结合了深度学习和传统机器学习的优势，并通过消融研究验证了各组件的贡献，具有较高的实用价值和研究意义。"}}
{"id": "2502.12272", "title": "Learning to Reason at the Frontier of Learnability", "authors": ["Thomas Foster", "Jakob Foerster"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.12272v4", "summary": "Reinforcement learning is now widely adopted as the final stage of large\nlanguage model training, especially for reasoning-style tasks such as maths\nproblems. Typically, models attempt each question many times during a single\ntraining step and attempt to learn from their successes and failures. However,\nwe demonstrate that throughout training with two popular algorithms (PPO and\nVinePPO) on two widely used datasets, many questions are either solved by all\nattempts - meaning they are already learned - or by none - providing no\nmeaningful training signal. To address this, we adapt a method from the\nreinforcement learning literature - sampling for learnability - and apply it to\nthe reinforcement learning stage of LLM training. Our curriculum prioritises\nquestions with high variance of success, i.e. those where the agent sometimes\nsucceeds, but not always. Our findings demonstrate that this curriculum\nconsistently boosts training performance across multiple algorithms and\ndatasets, paving the way for more efficient and effective reinforcement\nlearning with LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.12272v4", "cate": "cs.LG", "date": "2025-02-17", "updated": "2025-07-16", "AI": {"title_translation": "在可学习性前沿学习推理", "tldr": "针对大型语言模型（LLMs）的强化学习，研究发现许多问题要么已被完全掌握，要么完全无法解决，导致训练信号无效。本文提出一种基于“可学习性采样”的课程学习方法，优先处理成功率变异大的问题，从而显著提升了LLMs的训练性能。", "motivation": "强化学习在LLM训练中面临效率问题：许多问题要么已经学会，要么完全学不会，导致训练信号不足或无效。", "method": "本文引入并修改了强化学习文献中的“可学习性采样”方法，将其应用于大型语言模型（LLM）的强化学习阶段。该课程学习策略优先选择那些成功率方差高（即代理有时成功但并非总是成功）的问题。", "result": "提出的课程学习方法在多种算法（PPO和VinePPO）和数据集上始终如一地提升了训练性能。", "conclusion": "通过优先处理具有高成功率方差的问题，可以实现更高效、更有效的LLM强化学习。", "translation": "强化学习现已广泛应用于大型语言模型训练的最后阶段，特别是在数学问题等推理型任务中。通常，模型在单个训练步骤中会多次尝试每个问题，并试图从成功和失败中学习。然而，我们发现，在使用两种流行算法（PPO和VinePPO）和两个广泛使用的数据集进行训练时，许多问题要么通过所有尝试都解决了——这意味着它们已经学会了——要么一个都没有解决——这没有提供有意义的训练信号。为了解决这个问题，我们改编了强化学习文献中的一种方法——可学习性采样——并将其应用于大型语言模型训练的强化学习阶段。我们的课程优先处理成功率方差高的问题，即代理有时成功但并非总是成功的问题。我们的研究结果表明，这种课程在多种算法和数据集上始终如一地提升了训练性能，为大型语言模型更高效、更有效的强化学习铺平了道路。", "summary": "本文研究了大型语言模型（LLMs）在强化学习阶段的效率问题，指出现有方法中许多问题未能提供有效的训练信号。为解决此问题，作者引入并调整了“可学习性采样”方法，构建了一个课程学习策略，优先关注那些模型成功率变差大的问题。实验结果表明，该策略能显著提升LLMs在推理任务上的训练性能，从而实现更高效的强化学习。", "keywords": "强化学习, 大型语言模型, 可学习性采样, 课程学习, 推理任务", "comments": "这篇论文通过引入“可学习性采样”的概念，解决了LLM强化学习中训练效率低下的痛点。其创新之处在于将传统的强化学习概念巧妙地应用于LLM的微调阶段，通过优先学习“边缘问题”来优化训练信号。这种方法有望显著提高LLM在推理任务上的学习效率和性能，具有重要的实践意义。"}}
{"id": "2507.11916", "title": "A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS", "authors": ["Ehsan Futuhi", "Nathan R. Sturtevant"], "categories": ["cs.AI", "cs.DC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11916v1", "summary": "The rapid advancement of GPU technology has unlocked powerful parallel\nprocessing capabilities, creating new opportunities to enhance classic search\nalgorithms. A recent successful application of GPUs is in compressing large\npattern database (PDB) heuristics using neural networks while preserving\nheuristic admissibility. However, very few algorithms have been designed to\nexploit GPUs during search. Several variants of A* exist that batch GPU\ncomputations. In this paper we introduce a method for batching GPU computations\nin depth first search. In particular, we describe a new cost-bounded\ndepth-first search (CB-DFS) method that leverages the combined parallelism of\nmodern CPUs and GPUs. This is used to create algorithms like \\emph{Batch IDA*},\nan extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an\nextensions of Budgeted Tree Search. Our approach builds on the general approach\nused by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality\nguarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding\ntile puzzle (STP), showing that GPU operations can be efficiently batched in\nDFS. Additionally, we conduct extensive experiments to analyze the effects of\nhyperparameters, neural network heuristic size, and hardware resources on\nperformance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11916v1", "cate": "cs.AI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "一种用于成本限制DFS的并行CPU-GPU框架及其在IDA*和BTS中的应用", "tldr": "本文提出了一种新的并行CPU-GPU框架，用于成本限制的深度优先搜索（CB-DFS），并将其应用于Batch IDA*和Batch BTS，实现了GPU操作在DFS中的高效批处理。", "motivation": "尽管GPU技术在压缩模式数据库（PDB）启发式算法方面取得了成功，但很少有算法被设计用于在搜索过程中利用GPU的并行能力。", "method": "本文介绍了一种新的成本限制深度优先搜索（CB-DFS）方法，该方法结合了现代CPU和GPU的并行性，实现了深度优先搜索中GPU计算的批处理。该方法用于创建Batch IDA*和Batch BTS等算法，并建立在异步并行IDA*（AIDA*）的通用方法之上，同时保持最优性保证。", "result": "该方法在3x3魔方和4x4滑动拼图上进行了评估，结果表明GPU操作可以在DFS中高效地进行批处理。此外，还对超参数、神经网络启发式大小和硬件资源对性能的影响进行了广泛实验分析。", "conclusion": "本文成功开发并验证了一个并行CPU-GPU框架，用于成本限制的深度优先搜索，有效利用了GPU的并行能力来加速经典搜索算法，同时保持最优性。", "translation": "GPU技术的快速发展释放了强大的并行处理能力，为增强经典搜索算法创造了新的机会。GPU最近的一个成功应用是在使用神经网络压缩大型模式数据库（PDB）启发式算法时，同时保持启发式算法的可容许性。然而，很少有算法被设计用于在搜索过程中利用GPU。A*算法的几种变体存在批处理GPU计算的方法。在本文中，我们介绍了一种在深度优先搜索中批处理GPU计算的方法。特别是，我们描述了一种新的成本限制深度优先搜索（CB-DFS）方法，该方法利用了现代CPU和GPU的组合并行性。这被用于创建诸如Batch IDA*（迭代深化A*（IDA*）算法的扩展）或Batch BTS（预算树搜索的扩展）等算法。我们的方法建立在异步并行IDA*（AIDA*）使用的通用方法之上，同时保持最优性保证。我们在3x3魔方和4x4滑动拼图（STP）上评估了该方法，表明GPU操作可以在DFS中高效地进行批处理。此外，我们还进行了广泛的实验，分析超参数、神经网络启发式大小和硬件资源对性能的影响。", "summary": "本文提出了一种新颖的并行CPU-GPU框架，用于成本限制的深度优先搜索（CB-DFS），旨在弥补现有搜索算法在利用GPU并行性方面的不足。该框架通过结合CPU和GPU的并行能力，实现了深度优先搜索中GPU计算的高效批处理，并在此基础上开发了Batch IDA*和Batch BTS。实验结果表明，该方法在魔方和滑动拼图等问题上能够有效批处理GPU操作，并保持最优性，为经典搜索算法的加速提供了新途径。", "keywords": "并行计算, CPU-GPU, 深度优先搜索, IDA*, 批处理", "comments": "本文的创新之处在于提出了一种在深度优先搜索（DFS）过程中有效利用GPU并行性的方法，解决了现有算法在搜索阶段GPU利用率不足的问题。通过结合CPU和GPU的并行能力，并引入批处理机制，该框架有望显著加速成本限制的搜索问题，并在保持最优性方面具有重要意义。其在经典难题上的成功应用也展示了其潜力。"}}
{"id": "2507.11759", "title": "Torsional-GFN: a conditional conformation generator for small molecules", "authors": ["Alexandra Volokhova", "Léna Néhale Ezzine", "Piotr Gaiński", "Luca Scimeca", "Emmanuel Bengio", "Prudencio Tossou", "Yoshua Bengio", "Alex Hernandez-Garcia"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The two first authors are Alexandra Volokhova and Léna Néhale Ezzine, with equal contribution", "url": "http://arxiv.org/abs/2507.11759v1", "summary": "Generating stable molecular conformations is crucial in several drug\ndiscovery applications, such as estimating the binding affinity of a molecule\nto a target. Recently, generative machine learning methods have emerged as a\npromising, more efficient method than molecular dynamics for sampling of\nconformations from the Boltzmann distribution. In this paper, we introduce\nTorsional-GFN, a conditional GFlowNet specifically designed to sample\nconformations of molecules proportionally to their Boltzmann distribution,\nusing only a reward function as training signal. Conditioned on a molecular\ngraph and its local structure (bond lengths and angles), Torsional-GFN samples\nrotations of its torsion angles. Our results demonstrate that Torsional-GFN is\nable to sample conformations approximately proportional to the Boltzmann\ndistribution for multiple molecules with a single model, and allows for\nzero-shot generalization to unseen bond lengths and angles coming from the MD\nsimulations for such molecules. Our work presents a promising avenue for\nscaling the proposed approach to larger molecular systems, achieving zero-shot\ngeneralization to unseen molecules, and including the generation of the local\nstructure into the GFlowNet model.", "comment": "The two first authors are Alexandra Volokhova and L\\'ena N\\'ehale\n  Ezzine, with equal contribution", "pdf_url": "http://arxiv.org/pdf/2507.11759v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "Torsional-GFN：一种小分子条件构象生成器", "tldr": "Torsional-GFN是一种条件GFlowNet，能够高效地生成符合玻尔兹曼分布的小分子构象，并展现出零样本泛化能力。", "motivation": "在药物发现应用中，生成稳定的分子构象至关重要，例如用于估算分子与靶点的结合亲和力。传统的分子动力学方法效率较低，而生成式机器学习方法为从玻尔兹曼分布中采样构象提供了一种有前景且更高效的替代方案。", "method": "本文引入了Torsional-GFN，这是一种专门用于以与其玻尔兹曼分布成比例的方式采样分子构象的条件GFlowNet。它仅使用奖励函数作为训练信号。Torsional-GFN以分子图及其局部结构（键长和键角）为条件，对扭转角的旋转进行采样。", "result": "结果表明，Torsional-GFN能够用单个模型对多个分子的构象进行近似比例于玻尔兹曼分布的采样，并且允许对这些分子来自MD模拟的未见键长和键角进行零样本泛化。", "conclusion": "Torsional-GFN为将所提出的方法扩展到更大的分子系统、实现对未见分子的零样本泛化以及将局部结构生成纳入GFlowNet模型提供了一条有前景的途径。", "translation": "生成稳定的分子构象在多种药物发现应用中至关重要，例如估算分子与靶点的结合亲和力。最近，生成式机器学习方法已成为一种有前景、比分子动力学更高效的从玻尔兹曼分布中采样构象的方法。在本文中，我们引入了Torsional-GFN，这是一种专门设计用于以与其玻尔兹曼分布成比例的方式采样分子构象的条件GFlowNet，仅使用奖励函数作为训练信号。Torsional-GFN以分子图及其局部结构（键长和键角）为条件，对扭转角的旋转进行采样。我们的结果表明，Torsional-GFN能够用单个模型对多个分子的构象进行近似比例于玻尔兹曼分布的采样，并允许对这些分子来自MD模拟的未见键长和键角进行零样本泛化。我们的工作为将所提出的方法扩展到更大的分子系统、实现对未见分子的零样本泛化以及将局部结构生成纳入GFlowNet模型提供了一条有前景的途径。", "summary": "Torsional-GFN是一种新颖的条件GFlowNet，旨在高效准确地采样小分子构象。它通过采样扭转角，并以分子图和局部结构为条件，生成与玻尔兹曼分布成比例的构象。该模型对新的键长和键角表现出有效的零样本泛化能力，为药物发现应用提供了一个可扩展的解决方案。", "keywords": "Torsional-GFN, 构象生成, GFlowNet, 玻尔兹曼分布, 药物发现", "comments": "Torsional-GFN的创新之处在于利用条件GFlowNet高效采样玻尔兹曼分布的构象，并实现零样本泛化，解决了药物发现中的一个关键挑战。其仅依赖奖励函数进行训练也值得关注。该方法在扩展到更大分子系统和完整分子结构生成方面的潜力巨大。"}}
{"id": "2507.11849", "title": "Mobility Extraction and Analysis of GaN HEMTs for RF Applications Using TCAD and Experimental Data", "authors": ["Tanjim Rahman"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      5 pages, 7 figures", "url": "http://arxiv.org/abs/2507.11849v1", "summary": "This paper presents an analysis of GaN high-electron-mobility transistors\n(HEMTs) using both TCAD simulation and experimental characterization. The\nenergy band structure was studied using Nextnano simulation software to observe\ntwo-dimensional electron gas (2DEG) formation and carrier confinement under\nequilibrium conditions. Additionally, I-V and C-V data from fabricated\nresearch-grade GaN HEMTs were analyzed to extract key electrical parameters.\nThe device demonstrated an ON current of 1.9 mA and an OFF current of 0.01 mA,\nindicating a strong ON/OFF current ratio. A subthreshold swing of 80 mV/decade\nand a DIBL of 5 mV/V were observed, confirming good gate control and\nshort-channel suppression. The ON-resistance was 22.72 ohm per micron, with a\nsaturation voltage of 1 V . The peak transconductance was extracted as 0.18 mS\nin the linear region and 0.5 mS in saturation. Field-effect mobility was\ncalculated using the transconductance method, with a maximum value of\napproximately 1200 cm2/V.s at low drain bias. The combined simulation and\nexperimental approach provided comprehensive insight into GaN HEMT behavior,\nenabling a deeper understanding of structure-performance relationships critical\nto advanced transistor design.", "comment": "5 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.11849v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "利用TCAD和实验数据对射频应用GaN HEMT进行迁移率提取与分析", "tldr": "本文结合TCAD仿真和实验数据，对GaN HEMT的迁移率和关键电学参数进行了提取和分析，以深入理解其结构-性能关系。", "motivation": "深入理解GaN HEMT的结构-性能关系，这对于先进晶体管设计至关重要。", "method": "本文结合TCAD仿真（使用Nextnano软件研究能带结构和2DEG形成）和实验表征（分析制作的GaN HEMT的I-V和C-V数据）来提取关键电学参数。场效应迁移率通过跨导法计算。", "result": "器件表现出1.9 mA的开态电流和0.01 mA的关态电流，具有很强的开/关电流比。观察到80 mV/decade的亚阈值摆幅和5 mV/V的DIBL。开态电阻为22.72欧姆每微米，饱和电压为1 V。线性区峰值跨导为0.18 mS，饱和区为0.5 mS。在低漏极偏压下，场效应迁移率最大值约为1200 cm2/V.s。", "conclusion": "结合仿真和实验方法为GaN HEMT行为提供了全面的洞察，从而加深了对对先进晶体管设计至关重要的结构-性能关系的理解。", "translation": "本文结合TCAD仿真和实验表征，对GaN高电子迁移率晶体管（HEMT）进行了分析。利用Nextnano仿真软件研究了能带结构，以观察平衡条件下的二维电子气（2DEG）形成和载流子限制。此外，分析了已制备的研究级GaN HEMT的I-V和C-V数据，以提取关键电学参数。该器件表现出1.9 mA的开态电流和0.01 mA的关态电流，表明具有很强的开/关电流比。观察到80 mV/decade的亚阈值摆幅和5 mV/V的DIBL，证实了良好的栅极控制和短沟道抑制。开态电阻为22.72欧姆每微米，饱和电压为1 V。峰值跨导在线性区提取为0.18 mS，在饱和区提取为0.5 mS。场效应迁移率通过跨导法计算，在低漏极偏压下最大值约为1200 cm2/V.s。结合仿真和实验方法为GaN HEMT行为提供了全面的洞察，从而加深了对对先进晶体管设计至关重要的结构-性能关系的理解。", "summary": "本文通过TCAD仿真（Nextnano）和实验表征相结合的方法，对GaN HEMT的特性进行了深入分析。研究了2DEG形成和载流子限制，并提取了关键电学参数，如开/关电流、亚阈值摆幅、DIBL、开态电阻、饱和电压和峰值跨导。通过跨导法计算得到场效应迁移率，最大值约为1200 cm2/V.s。这种综合方法为理解GaN HEMT的结构-性能关系提供了全面的洞察，对先进晶体管设计具有重要意义。", "keywords": "GaN HEMT, 迁移率提取, TCAD仿真, 实验表征, 射频应用", "comments": "本文通过结合TCAD仿真和实验数据，为GaN HEMT的特性分析提供了一个全面的方法。这种双管齐下的方法增强了对器件物理行为的理解，特别是对二维电子气形成和载流子限制的洞察。提取的详细电学参数对于优化GaN HEMT的射频应用性能具有重要价值。这种方法对于先进的晶体管设计具有重要的指导意义。"}}
{"id": "2506.15026", "title": "Algorithmic Approaches to Enhance Safety in Autonomous Vehicles: Minimizing Lane Changes and Merging", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.15026v2", "summary": "The rapid advancements in autonomous vehicle (AV) technology promise enhanced\nsafety and operational efficiency. However, frequent lane changes and merging\nmaneuvers continue to pose significant safety risks and disrupt traffic flow.\nThis paper introduces the Minimizing Lane Change Algorithm (MLCA), a\nstate-machine-based approach designed to reduce unnecessary lane changes,\nthereby enhancing both traffic safety and efficiency. The MLCA algorithm\nprioritizes maintaining lane stability unless safety-critical conditions\nnecessitate a lane change. The algorithm's effectiveness was evaluated through\nsimulations conducted on the SUMO platform, comparing its performance against\nestablished models, including LC2017 and MOBIL. Results demonstrate substantial\nreductions in lane changes and collisions, leading to smoother traffic flow and\nimproved safety metrics. Additionally, the study highlights the MLCA's\nadaptability to various traffic densities and roadway configurations,\nshowcasing its potential for wide-scale deployment in real-world AV systems.\nFuture work aims to validate these findings in more complex scenarios using the\nCARLA simulator, which will enable the testing of the algorithm under more\ndynamic and high-fidelity conditions, such as urban traffic environments with\ndiverse road users. Moreover, the integration of cybersecurity measures for\nvehicle-to-vehicle (V2V) communication will be explored to ensure robust and\nsecure data exchange, further enhancing the reliability and safety of AV\noperations. This research contributes to the broader goal of developing\nintelligent traffic systems that optimize both individual vehicle performance\nand overall traffic network efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.15026v2", "cate": "eess.SY", "date": "2025-06-17", "updated": "2025-07-16", "AI": {"title_translation": "自动驾驶汽车安全增强的算法方法：最小化变道和并道", "tldr": "本文提出了一种最小化变道算法（MLCA），通过减少不必要的变道来提高自动驾驶汽车的安全性和交通效率，并在模拟中取得了显著效果。", "motivation": "自动驾驶技术虽有进步，但频繁变道和并道操作仍然带来显著的安全风险并扰乱交通流，因此需要一种算法来解决这些问题。", "method": "本文提出了一种基于状态机的最小化变道算法（MLCA），旨在减少不必要的变道。该算法优先保持车道稳定性，除非安全关键条件需要变道。通过在SUMO平台上进行仿真评估，并将其性能与包括LC2017和MOBIL在内的既有模型进行比较。", "result": "仿真结果表明，MLCA显著减少了变道和碰撞，从而使交通流更顺畅，安全指标得到改善。此外，MLCA对各种交通密度和道路配置表现出良好的适应性。", "conclusion": "该研究通过提出的最小化变道算法（MLCA）有效提升了自动驾驶汽车的安全性和交通效率，为开发优化单个车辆性能和整体交通网络效率的智能交通系统做出了贡献，并展示了其在实际AV系统中的大规模部署潜力。", "translation": "自动驾驶汽车（AV）技术的快速发展预示着更高的安全性和运行效率。然而，频繁的变道和并道操作仍然带来显著的安全风险并扰乱交通流。本文引入了最小化变道算法（MLCA），这是一种基于状态机的方法，旨在减少不必要的变道，从而同时提高交通安全性和效率。MLCA算法优先保持车道稳定性，除非安全关键条件要求变道。该算法的有效性通过在SUMO平台上进行的仿真进行评估，并将其性能与包括LC2017和MOBIL在内的既有模型进行了比较。结果表明，变道和碰撞显著减少，从而使交通流更顺畅，安全指标得到改善。此外，研究强调了MLCA对各种交通密度和道路配置的适应性，展示了其在实际AV系统中大规模部署的潜力。未来的工作旨在利用CARLA模拟器在更复杂的场景中验证这些发现，这将使得该算法能够在更动态和高保真条件下进行测试，例如具有不同道路使用者的城市交通环境。此外，还将探索为车对车（V2V）通信集成网络安全措施，以确保健壮和安全的数据交换，进一步增强AV操作的可靠性和安全性。这项研究有助于实现开发智能交通系统的更广泛目标，从而优化单个车辆性能和整体交通网络效率。", "summary": "本文提出了一种名为最小化变道算法（MLCA）的基于状态机方法，旨在解决自动驾驶汽车中频繁变道和并道带来的安全风险和交通扰乱问题。MLCA通过优先保持车道稳定性来减少不必要的变道。在SUMO平台进行的仿真结果表明，与现有模型相比，MLCA显著减少了变道和碰撞，改善了交通流和安全指标，并展现出对不同交通环境的良好适应性。该研究为智能交通系统发展做出了贡献。", "keywords": "自动驾驶汽车, 变道, 交通安全, 最小化变道算法, 交通效率", "comments": "这篇论文提出了一种实用的算法来解决自动驾驶中的核心安全问题，即频繁变道。其创新性在于提出了MLCA这一基于状态机的方法，并强调了车道稳定性优先级。通过在SUMO平台进行仿真验证，并与现有模型对比，提供了有力的证据支持其有效性。该研究的潜在影响在于提高自动驾驶汽车的实际部署安全性和交通效率。未来的工作计划在更复杂的CARLA环境中进行验证，并考虑网络安全，这表明了研究的全面性和前瞻性。"}}
{"id": "2411.09127", "title": "Complexity-Aware Training of Deep Neural Networks for Optimal Structure Discovery", "authors": ["Valentin Frank Ingmar Guenter", "Athanasios Sideris"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      31 pages, 6 figures, 6 tables. Restructured Sections 1 and 3, added simulation data in Section 5 and added appendices", "url": "http://arxiv.org/abs/2411.09127v2", "summary": "We propose a novel algorithm for combined unit and layer pruning of deep\nneural networks that functions during training and without requiring a\npre-trained network to apply. Our algorithm optimally trades-off learning\naccuracy and pruning levels while balancing layer vs. unit pruning and\ncomputational vs. parameter complexity using only three user-defined\nparameters, which are easy to interpret and tune. We formulate a stochastic\noptimization problem over the network weights and the parameters of variational\nBernoulli distributions for binary Random Variables taking values either 0 or 1\nand scaling the units and layers of the network. Optimal network structures are\nfound as the solution to this optimization problem. Pruning occurs when a\nvariational parameter converges to 0 rendering the corresponding structure\npermanently inactive, thus saving computations both during training and\nprediction. A key contribution of our approach is to define a cost function\nthat combines the objectives of prediction accuracy and network pruning in a\ncomputational/parameter complexity-aware manner and the automatic selection of\nthe many regularization parameters. We show that the proposed algorithm\nconverges to solutions of the optimization problem corresponding to\ndeterministic networks. We analyze the ODE system that underlies our stochastic\noptimization algorithm and establish domains of attraction for the dynamics of\nthe network parameters. These theoretical results lead to practical pruning\nconditions avoiding the premature pruning of units and layers during training.\nWe evaluate our method on the CIFAR-10/100 and ImageNet datasets using ResNet\narchitectures and demonstrate that it gives improved results with respect to\npruning ratios and test accuracy over layer-only or unit-only pruning and\nfavorably competes with combined unit and layer pruning algorithms requiring\npre-trained networks.", "comment": "31 pages, 6 figures, 6 tables. Restructured Sections 1 and 3, added\n  simulation data in Section 5 and added appendices", "pdf_url": "http://arxiv.org/pdf/2411.09127v2", "cate": "cs.LG", "date": "2024-11-14", "updated": "2025-07-16", "AI": {"title_translation": "深度神经网络复杂性感知训练，用于最优结构发现", "tldr": "提出一种在训练期间进行深度神经网络单元和层联合剪枝的新算法，无需预训练网络，通过优化复杂性感知成本函数实现，并在多个数据集上取得了更好的剪枝率和准确性。", "motivation": "现有的深度神经网络剪枝方法通常需要预训练网络，并且在剪枝粒度（单元或层）和复杂性平衡方面存在挑战。本文旨在提出一种在训练期间进行联合剪枝的算法，以优化网络结构，同时平衡准确性和计算/参数复杂性。", "method": "提出一种新的算法，在训练过程中对深度神经网络进行单元和层联合剪枝，无需预训练网络。该算法通过将网络权重和变分伯努利分布参数（用于缩放单元和层）构建为随机优化问题来工作。它定义了一个结合预测精度和网络剪枝的复杂性感知成本函数，并自动选择正则化参数。当变分参数收敛到0时，实现剪枝。该方法还分析了其随机优化算法的ODE系统，以建立吸引域并避免过早剪枝。", "result": "该算法在CIFAR-10/100和ImageNet数据集上使用ResNet架构进行评估，结果显示其在剪枝率和测试精度方面优于仅层剪枝或仅单元剪枝的方法。它还能与需要预训练网络的联合单元和层剪枝算法相媲美。理论上，该算法收敛到对应确定性网络的优化问题解。", "conclusion": "本文提出了一种新颖的深度神经网络复杂性感知训练期间联合单元和层剪枝算法，该算法无需预训练网络，通过优化问题寻找最优结构，并在经验和理论上均表现出优越性，有效平衡了准确性和模型复杂性。", "translation": "我们提出了一种新颖的算法，用于深度神经网络的单元和层联合剪枝，该算法在训练期间运行，并且无需预训练网络即可应用。我们的算法在使用仅三个用户定义参数的情况下，最优地权衡学习精度和剪枝水平，同时平衡层与单元剪枝以及计算与参数复杂性，这些参数易于解释和调整。我们针对网络权重以及变分伯努利分布的参数（用于取值0或1并缩放网络单元和层的二元随机变量）构建了一个随机优化问题。最优网络结构作为此优化问题的解被找到。当变分参数收敛到0时，对应的结构永久性失效，从而在训练和预测期间都节省了计算。我们方法的一个关键贡献是定义了一个成本函数，该函数以计算/参数复杂性感知的方式结合了预测精度和网络剪枝的目标，并自动选择许多正则化参数。我们表明，所提出的算法收敛到对应确定性网络的优化问题的解。我们分析了支撑我们随机优化算法的ODE系统，并建立了网络参数动力学的吸引域。这些理论结果导出了实用的剪枝条件，避免了训练期间单元和层的过早剪枝。我们在CIFAR-10/100和ImageNet数据集上使用ResNet架构评估了我们的方法，并证明它在剪枝率和测试精度方面优于仅层剪枝或仅单元剪枝，并与需要预训练网络的联合单元和层剪枝算法具有竞争力。", "summary": "本文提出了一种新颖的深度神经网络复杂性感知训练算法，用于在训练过程中进行单元和层联合剪枝，无需预训练网络。该算法通过将剪枝问题表述为随机优化问题，利用变分伯努利分布和自定义的复杂性感知成本函数来平衡预测精度与计算/参数复杂性，并自动选择正则化参数。理论分析表明算法收敛，并提供了避免过早剪枝的实用条件。实验结果在CIFAR-10/100和ImageNet数据集上使用ResNet架构验证了该方法在剪枝率和测试精度方面的优越性，并能与需要预训练网络的现有方法竞争。", "keywords": "深度神经网络剪枝, 复杂性感知训练, 联合单元和层剪枝, 随机优化, 结构发现", "comments": "这篇论文的创新点在于提出了一个无需预训练网络即可在训练期间进行深度神经网络联合单元和层剪枝的算法。其核心在于将剪枝问题转化为一个随机优化问题，并引入了一个复杂性感知成本函数，能够自动平衡精度和模型复杂性。理论分析为实际剪枝提供了指导，避免了过早剪枝。这对于资源受限或需要从头训练小模型的场景具有重要意义。"}}
{"id": "2507.11570", "title": "SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery", "authors": ["Ha Na Cho", "Sairam Sutari", "Alexander Lopez", "Hansen Bow", "Kai Zheng"], "categories": ["cs.LG", "cs.AI", "eess.IV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11570v1", "summary": "Objective: To develop and evaluate machine learning (ML) models for\npredicting length of stay (LOS) in elective spine surgery, with a focus on the\nbenefits of temporal modeling and model interpretability. Materials and\nMethods: We compared traditional ML models (e.g., linear regression, random\nforest, support vector machine (SVM), and XGBoost) with our developed model,\nSurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an\nattention, using structured perioperative electronic health records (EHR) data.\nPerformance was evaluated using the coefficient of determination (R2), and key\npredictors were identified using explainable AI. Results: SurgeryLSTM achieved\nthe highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)\nand baseline models. The attention mechanism improved interpretability by\ndynamically identifying influential temporal segments within preoperative\nclinical sequences, allowing clinicians to trace which events or features most\ncontributed to each LOS prediction. Key predictors of LOS included bone\ndisorder, chronic kidney disease, and lumbar fusion identified as the most\nimpactful predictors of LOS. Discussion: Temporal modeling with attention\nmechanisms significantly improves LOS prediction by capturing the sequential\nnature of patient data. Unlike static models, SurgeryLSTM provides both higher\naccuracy and greater interpretability, which are critical for clinical\nadoption. These results highlight the potential of integrating attention-based\ntemporal models into hospital planning workflows. Conclusion: SurgeryLSTM\npresents an effective and interpretable AI solution for LOS prediction in\nelective spine surgery. Our findings support the integration of temporal,\nexplainable ML approaches into clinical decision support systems to enhance\ndischarge readiness and individualized patient care.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11570v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "SurgeryLSTM：一种用于脊柱手术后住院时长预测的准确且可解释的时间感知神经网络模型", "tldr": "SurgeryLSTM模型利用时间序列数据和注意力机制，显著提高了脊柱手术后住院时长预测的准确性和可解释性。", "motivation": "开发和评估机器学习模型，用于预测择期脊柱手术的住院时长（LOS），重点关注时间建模和模型可解释性的优势。", "method": "比较了传统机器学习模型（如线性回归、随机森林、支持向量机 (SVM) 和 XGBoost）与自研的SurgeryLSTM模型（一种带有注意力机制的掩蔽双向长短期记忆网络 (BiLSTM)），使用围手术期结构化电子健康记录 (EHR) 数据。性能通过决定系数 (R2) 评估，并使用可解释AI识别关键预测因子。", "result": "SurgeryLSTM 取得了最高的预测准确性 (R2=0.86)，优于 XGBoost (R2 = 0.85) 和基线模型。注意力机制通过动态识别术前临床序列中有影响的时间段，提高了可解释性，允许临床医生追踪哪些事件或特征对每次 LOS 预测贡献最大。骨骼疾病、慢性肾病和腰椎融合被确定为 LOS 最具影响力的预测因子。", "conclusion": "SurgeryLSTM 为择期脊柱手术的 LOS 预测提供了一种有效且可解释的 AI 解决方案。研究结果支持将时间感知、可解释的机器学习方法整合到临床决策支持系统中，以提高出院准备度和个性化患者护理。", "translation": "目的：开发和评估机器学习（ML）模型，用于预测择期脊柱手术的住院时长（LOS），重点关注时间建模和模型可解释性的优势。材料和方法：我们比较了传统机器学习模型（例如，线性回归、随机森林、支持向量机（SVM）和XGBoost）与我们开发的模型SurgeryLSTM，这是一种带有注意力机制的掩蔽双向长短期记忆（BiLSTM），使用结构化的围手术期电子健康记录（EHR）数据。性能使用决定系数（R2）进行评估，并使用可解释AI识别关键预测因子。结果：SurgeryLSTM取得了最高的预测准确性（R2=0.86），优于XGBoost（R2 = 0.85）和基线模型。注意力机制通过动态识别术前临床序列中有影响的时间段，提高了可解释性，允许临床医生追踪哪些事件或特征对每次LOS预测贡献最大。骨骼疾病、慢性肾病和腰椎融合被确定为LOS最具影响力的预测因子。讨论：带有注意力机制的时间建模通过捕获患者数据的序列性质，显著改善了LOS预测。与静态模型不同，SurgeryLSTM提供了更高的准确性和更大的可解释性，这对于临床应用至关重要。这些结果突出了将基于注意力的时间模型整合到医院规划工作流程中的潜力。结论：SurgeryLSTM为择期脊柱手术的LOS预测提供了一种有效且可解释的AI解决方案。我们的发现支持将时间感知、可解释的ML方法整合到临床决策支持系统中，以增强出院准备度和个性化患者护理。", "summary": "SurgeryLSTM是一种基于时间感知的BiLSTM模型，结合注意力机制，用于预测择期脊柱手术后的住院时长。该模型在预测准确性（R2=0.86）上优于传统ML模型，并能通过注意力机制提供可解释性，识别关键的时间段和预测因子。研究强调了时间建模和可解释AI在临床决策支持中的重要性，支持将其整合到临床实践中。", "keywords": "住院时长预测, 脊柱手术, 机器学习, LSTM, 可解释AI", "comments": "该论文的创新点在于结合了BiLSTM和注意力机制来处理时间序列数据，并强调了模型的可解释性。这对于医疗领域的AI应用至关重要，因为可解释性能够增加临床医生对模型的信任度，并帮助他们理解预测背后的原因，从而促进AI在临床决策支持系统中的实际采纳和应用。"}}
{"id": "2507.11821", "title": "MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory", "authors": ["Pouya Shaeri", "Arash Karimi", "Ariane Middel"], "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Submitted to a computer science conference", "url": "http://arxiv.org/abs/2507.11821v1", "summary": "Neural networks are often benchmarked using standard datasets such as MNIST,\nFashionMNIST, or other variants of MNIST, which, while accessible, are limited\nto generic classes such as digits or clothing items. For researchers working on\ndomain-specific tasks, such as classifying trees, food items, or other\nreal-world objects, these data sets are insufficient and irrelevant.\nAdditionally, creating and publishing a custom dataset can be time consuming,\nlegally constrained, or beyond the scope of individual projects. We present\nMNIST-Gen, an automated, modular, and adaptive framework for generating\nMNIST-style image datasets tailored to user-specified categories using\nhierarchical semantic categorization. The system combines CLIP-based semantic\nunderstanding with reinforcement learning and human feedback to achieve\nintelligent categorization with minimal manual intervention. Our hierarchical\napproach supports complex category structures with semantic characteristics,\nenabling fine-grained subcategorization and multiple processing modes:\nindividual review for maximum control, smart batch processing for large\ndatasets, and fast batch processing for rapid creation. Inspired by category\ntheory, MNIST-Gen models each data transformation stage as a composable\nmorphism, enhancing clarity, modularity, and extensibility. As proof of\nconcept, we generate and benchmark two novel datasets-\\textit{Tree-MNIST} and\n\\textit{Food-MNIST}-demonstrating MNIST-Gen's utility for producing\ntask-specific evaluation data while achieving 85\\% automatic categorization\naccuracy and 80\\% time savings compared to manual approaches.", "comment": "Submitted to a computer science conference", "pdf_url": "http://arxiv.org/pdf/2507.11821v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MNIST-Gen：一种使用分层语义、强化学习和范畴论的模块化MNIST风格数据集生成方法", "tldr": "MNIST-Gen是一个自动化、模块化、自适应的框架，用于根据用户指定类别生成MNIST风格的图像数据集，解决了现有数据集的局限性和自定义数据集创建的困难，并提高了效率和准确性。", "motivation": "现有的标准数据集（如MNIST）对于特定领域的任务（如分类树木、食物）来说不足且不相关。此外，创建和发布自定义数据集耗时、受法律限制或超出个人项目范围。", "method": "MNIST-Gen结合了基于CLIP的语义理解、强化学习和人类反馈，实现了智能分类，并支持分层语义分类。它提供多种处理模式：单独审查、智能批量处理和快速批量处理。受范畴论启发，它将每个数据转换阶段建模为可组合的态射。", "result": "作为概念验证，生成并基准测试了两个新数据集——Tree-MNIST和Food-MNIST。MNIST-Gen在自动分类准确率上达到85%，与手动方法相比节省了80%的时间。", "conclusion": "MNIST-Gen能够有效地生成任务特定的评估数据。", "translation": "神经网络通常使用标准数据集（如MNIST、FashionMNIST或其他MNIST变体）进行基准测试，这些数据集虽然易于获取，但仅限于数字或服装等通用类别。对于从事领域特定任务（如分类树木、食物或其他真实世界物体）的研究人员来说，这些数据集是不足且不相关的。此外，创建和发布自定义数据集可能耗时、受法律限制或超出个人项目的范围。我们提出了MNIST-Gen，一个自动化、模块化和自适应的框架，用于使用分层语义分类生成针对用户指定类别量身定制的MNIST风格图像数据集。该系统结合了基于CLIP的语义理解、强化学习和人类反馈，以最少的人工干预实现智能分类。我们的分层方法支持具有语义特征的复杂类别结构，实现细粒度子分类和多种处理模式：用于最大控制的单独审查、用于大型数据集的智能批量处理以及用于快速创建的快速批量处理。受范畴论的启发，MNIST-Gen将每个数据转换阶段建模为可组合的态射，从而增强了清晰度、模块化和可扩展性。作为概念验证，我们生成并基准测试了两个新颖的数据集——Tree-MNIST和Food-MNIST——展示了MNIST-Gen在生成任务特定评估数据方面的实用性，同时实现了85%的自动分类准确率，与手动方法相比节省了80%的时间。", "summary": "MNIST-Gen是一个创新的自动化框架，旨在解决现有标准数据集在领域特定任务中的局限性以及自定义数据集创建的挑战。该系统利用CLIP的语义理解、强化学习和人类反馈，结合分层语义分类，能够为用户指定类别生成模块化、适应性强的MNIST风格图像数据集。它通过将数据转换建模为可组合态射来增强清晰度和模块化。通过生成Tree-MNIST和Food-MNIST，该研究证明了MNIST-Gen在创建任务特定评估数据方面的有效性，显著提高了自动化分类准确性并节省了时间。", "keywords": "MNIST-Gen, 数据集生成, 分层语义, 强化学习, 范畴论", "comments": "该论文提出了一种新颖且实用的方法来解决领域特定数据集稀缺的问题。其创新点在于结合了分层语义、强化学习和范畴论，实现了数据集生成的自动化和模块化。特别是引入范畴论来建模数据转换阶段，提升了系统的可扩展性和清晰度，这在数据集生成领域是不常见的。MNIST-Gen对于需要定制化数据集的研究人员来说具有重要意义，能够显著提高效率并降低人工成本。"}}
{"id": "2312.07003", "title": "RACER: Rational Artificial Intelligence Car-following-model Enhanced by Reality", "authors": ["Tianyi Li", "Alexander Halatsis", "Raphael Stern"], "categories": ["cs.AI", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2312.07003v2", "summary": "This paper introduces RACER, the Rational Artificial Intelligence\nCar-following model Enhanced by Reality, a cutting-edge deep learning\ncar-following model, that satisfies partial derivative constraints, designed to\npredict Adaptive Cruise Control (ACC) driving behavior while staying\ntheoretically feasible. Unlike conventional models, RACER effectively\nintegrates Rational Driving Constraints (RDCs), crucial tenets of actual\ndriving, resulting in strikingly accurate and realistic predictions. Against\nestablished models like the Optimal Velocity Relative Velocity (OVRV), a\ncar-following Neural Network (NN), and a car-following Physics-Informed Neural\nNetwork (PINN), RACER excels across key metrics, such as acceleration,\nvelocity, and spacing. Notably, it displays a perfect adherence to the RDCs,\nregistering zero violations, in stark contrast to other models. This study\nhighlights the immense value of incorporating physical constraints within AI\nmodels, especially for augmenting safety measures in transportation. It also\npaves the way for future research to test these models against human driving\ndata, with the potential to guide safer and more rational driving behavior. The\nversatility of the proposed model, including its potential to incorporate\nadditional derivative constraints and broader architectural applications,\nenhances its appeal and broadens its impact within the scientific community.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2312.07003v2", "cate": "cs.AI", "date": "2023-12-12", "updated": "2025-07-16", "AI": {"title_translation": "RACER：现实增强的理性人工智能跟驰模型", "tldr": "RACER是一种新型深度学习跟驰模型，通过集成理性驾驶约束，能更准确、安全地预测ACC行为，且零违反物理约束。", "motivation": "现有跟驰模型可能无法完全满足理论可行性和实际驾驶约束，导致预测不准确。本文旨在开发一个能预测ACC驾驶行为，同时满足偏导数约束和理性驾驶约束的跟驰模型，以提高预测的准确性和现实性。", "method": "本文提出RACER模型，一个前沿的深度学习跟驰模型。该模型旨在预测自适应巡航控制（ACC）驾驶行为，通过满足偏导数约束并有效地集成理性驾驶约束（RDCs）来实现理论可行性和预测准确性。", "result": "RACER在加速度、速度和间距等关键指标上优于现有模型（如最优速度相对速度模型OVRV、跟驰神经网络NN和跟驰物理信息神经网络PINN）。它完美遵守理性驾驶约束（RDCs），实现了零违规，这与其他模型形成鲜明对比。", "conclusion": "研究强调了在AI模型中融入物理约束的巨大价值，尤其是在增强交通安全措施方面。RACER的提出为未来研究铺平了道路，可以针对人类驾驶数据测试这些模型，并有可能指导更安全、更理性的驾驶行为。该模型的通用性，包括其结合额外导数约束和更广泛架构应用的可能性，增强了其吸引力并扩大了其在科学界的影响。", "translation": "本文介绍了RACER，一个由现实增强的理性人工智能跟驰模型，这是一种尖端深度学习跟驰模型，它满足偏导数约束，旨在预测自适应巡航控制（ACC）驾驶行为，同时保持理论上的可行性。与传统模型不同，RACER有效地整合了理性驾驶约束（RDCs），这是实际驾驶的关键原则，从而产生了惊人的准确和现实的预测。与最优速度相对速度（OVRV）模型、跟驰神经网络（NN）和跟驰物理信息神经网络（PINN）等成熟模型相比，RACER在加速度、速度和间距等关键指标上表现出色。值得注意的是，它完美遵守RDCs，记录了零违规，这与其他模型形成了鲜明对比。这项研究突出了在人工智能模型中融入物理约束的巨大价值，特别是对于增强交通安全措施。它也为未来的研究铺平了道路，以针对人类驾驶数据测试这些模型，并有可能指导更安全、更理性的驾驶行为。所提出模型的通用性，包括其结合额外导数约束和更广泛架构应用的可能性，增强了其吸引力并扩大了其在科学界的影响。", "summary": "本文介绍了RACER，一种创新的深度学习跟驰模型，它通过满足偏导数约束并整合理性驾驶约束（RDCs），旨在准确预测自适应巡航控制（ACC）的驾驶行为。与传统模型相比，RACER在加速度、速度和间距等关键指标上表现卓越，并完美遵守RDCs，实现了零违规。研究强调了在AI模型中融入物理约束对于提升交通安全的重要性，并展望了未来将该模型应用于人类驾驶数据以促进更安全驾驶的研究方向。", "keywords": "深度学习, 跟驰模型, 理性驾驶约束, 自适应巡航控制, 物理约束", "comments": "RACER的创新之处在于其将深度学习与物理约束（如偏导数约束和理性驾驶约束RDCs）的深度融合。这种结合不仅提高了模型的预测准确性和现实性，更重要的是，确保了模型在理论上的可行性和在实际应用中的安全性，尤其是在交通领域。零违反RDCs的特性是其显著优势，这对于自动驾驶和辅助驾驶系统的可靠性至关重要。"}}
{"id": "2507.01881", "title": "A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs", "authors": ["Niccolò McConnell", "Pardeep Vasudev", "Daisuke Yamada", "Daryl Cheng", "Mehran Azimbagirad", "John McCabe", "Shahab Aslani", "Ahmed H. Shahin", "Yukun Zhou", "The SUMMIT Consortium", "Andre Altmann", "Yipeng Hu", "Paul Taylor", "Sam M. Janes", "Daniel C. Alexander", "Joseph Jacob"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.01881v2", "summary": "Low-dose computed tomography (LDCT) imaging employed in lung cancer screening\n(LCS) programs is increasing in uptake worldwide. LCS programs herald a\ngenerational opportunity to simultaneously detect cancer and non-cancer-related\nearly-stage lung disease. Yet these efforts are hampered by a shortage of\nradiologists to interpret scans at scale. Here, we present TANGERINE, a\ncomputationally frugal, open-source vision foundation model for volumetric LDCT\nanalysis. Designed for broad accessibility and rapid adaptation, TANGERINE can\nbe fine-tuned off the shelf for a wide range of disease-specific tasks with\nlimited computational resources and training data. Relative to models trained\nfrom scratch, TANGERINE demonstrates fast convergence during fine-tuning,\nthereby requiring significantly fewer GPU hours, and displays strong label\nefficiency, achieving comparable or superior performance with a fraction of\nfine-tuning data. Pretrained using self-supervised learning on over 98,000\nthoracic LDCTs, including the UK's largest LCS initiative to date and 27 public\ndatasets, TANGERINE achieves state-of-the-art performance across 14 disease\nclassification tasks, including lung cancer and multiple respiratory diseases,\nwhile generalising robustly across diverse clinical centres. By extending a\nmasked autoencoder framework to 3D imaging, TANGERINE offers a scalable\nsolution for LDCT analysis, departing from recent closed, resource-intensive\nmodels by combining architectural simplicity, public availability, and modest\ncomputational requirements. Its accessible, open-source lightweight design lays\nthe foundation for rapid integration into next-generation medical imaging tools\nthat could transform LCS initiatives, allowing them to pivot from a singular\nfocus on lung cancer detection to comprehensive respiratory disease management\nin high-risk populations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01881v2", "cate": "eess.IV", "date": "2025-07-02", "updated": "2025-07-15", "AI": {"title_translation": "一种计算经济型开源基础模型，用于肺癌筛查项目中胸部疾病检测", "tldr": "TANGERINE是一个计算经济、开源的视觉基础模型，用于低剂量CT分析，通过自监督学习在大量胸部LDCT数据上预训练，实现了对多种胸部疾病的SOTA检测性能，并能以极低的计算资源和数据进行微调。", "motivation": "肺癌筛查（LCS）项目中低剂量CT（LDCT）成像的应用日益增加，但由于缺乏足够的放射科医生来大规模解读扫描结果，这些工作受到了阻碍。现有模型往往是封闭的、资源密集型的。因此，需要一个计算经济、可扩展的解决方案来应对这一挑战。", "method": "本文提出了TANGERINE，一个计算经济型、开源的视觉基础模型，用于容积LDCT分析。它通过将掩码自编码器框架扩展到3D成像来实现。TANGERINE使用自监督学习在超过98,000张胸部LDCT图像上进行预训练，其中包括英国最大的LCS项目和27个公共数据集。", "result": "相对于从头开始训练的模型，TANGERINE在微调过程中展示了快速收敛，显著减少了GPU小时数，并表现出强大的标签效率，仅用一小部分微调数据就能达到可比或更优的性能。它在14项疾病分类任务（包括肺癌和多种呼吸系统疾病）上取得了最先进的性能，并在不同的临床中心之间展现出强大的泛化能力。", "conclusion": "TANGERINE提供了一个可扩展的LDCT分析解决方案，通过结合架构的简洁性、公共可用性和适度的计算要求，与近期封闭、资源密集型的模型不同。其易于获取的开源轻量级设计为快速整合到下一代医学成像工具奠定了基础，有望将LCS从单一的肺癌检测转变为高危人群的全面呼吸系统疾病管理。", "translation": "低剂量计算机断层扫描（LDCT）成像应用于肺癌筛查（LCS）项目在全球范围内日益普及。LCS项目预示着一个世代机遇，可以同时检测癌症和非癌症相关的早期肺部疾病。然而，由于缺乏足够的放射科医生来大规模解读扫描结果，这些努力受到了阻碍。在此，我们介绍了TANGERINE，一个计算经济型、开源的视觉基础模型，用于容积LDCT分析。TANGERINE旨在实现广泛的可访问性和快速适应性，可以用有限的计算资源和训练数据进行开箱即用的微调，适用于各种疾病特异性任务。相对于从头开始训练的模型，TANGERINE在微调过程中展示了快速收敛，从而显著减少了GPU小时数，并表现出强大的标签效率，仅用一小部分微调数据就能达到可比或更优的性能。TANGERINE使用自监督学习在超过98,000张胸部LDCT上进行预训练，其中包括英国迄今为止最大的LCS项目和27个公共数据集，在14项疾病分类任务（包括肺癌和多种呼吸系统疾病）上取得了最先进的性能，同时在不同的临床中心之间展现出强大的泛化能力。通过将掩码自编码器框架扩展到3D成像，TANGERINE提供了一个可扩展的LDCT分析解决方案，通过结合架构的简洁性、公共可用性和适度的计算要求，与近期封闭、资源密集型的模型不同。其易于获取的开源轻量级设计为快速整合到下一代医学成像工具奠定了基础，这些工具可以改变LCS计划，使其从单一关注肺癌检测转向高危人群的全面呼吸系统疾病管理。", "summary": "本文提出TANGERINE，一个计算经济型、开源的视觉基础模型，专为肺癌筛查中的低剂量CT（LDCT）分析设计。该模型通过将掩码自编码器框架扩展到3D成像，并在超过98,000张胸部LDCT图像上进行自监督预训练。TANGERINE在微调时展现出快速收敛和高标签效率，仅需少量计算资源和数据即可达到或超越现有模型的性能，并在14项胸部疾病分类任务上实现最先进水平。其开源和轻量级设计旨在解决放射科医生短缺问题，并推动LCS项目从单一癌症检测转向全面的呼吸系统疾病管理。", "keywords": "肺癌筛查, 低剂量CT, 基础模型, 胸部疾病检测, 自监督学习", "comments": "TANGERINE的创新之处在于其“计算经济型”和“开源”的特性，这与当前许多封闭、资源密集型的大型模型形成鲜明对比。它将掩码自编码器框架扩展到3D医学影像，并利用大规模自监督预训练，显著降低了模型部署和适应的门槛，对于资源受限的医疗环境尤其重要。其在多疾病检测上的SOTA表现和强大的泛化能力，预示着其在临床应用中的巨大潜力，有望推动肺癌筛查向更全面的呼吸系统疾病管理转型。"}}
{"id": "2502.12567", "title": "DeltaDiff: Reality-Driven Diffusion with AnchorResiduals for Faithful SR", "authors": ["Chao Yang", "Yong Fan", "Qichao Zhang", "Cheng Lu", "Zhijing Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.12567v2", "summary": "Recently, the transfer application of diffusion models in super-resolu-tion\ntasks has faced the problem ofdecreased fidelity. Due to the inherent\nrandomsampling characteristics ofdiffusion models, direct application in\nsuper-resolu-tion tasks can result in generated details deviating from the true\ndistribution ofhigh-resolution images. To address this, we propose DeltaDiff, a\nnovel frame.work that constrains the difusion process, its essence is to\nestablish a determin-istic mapping path between HR and LR, rather than the\nrandom noise disturbanceprocess oftraditional difusion models. Theoretical\nanalysis demonstrates a 25%reduction in diffusion entropy in the residual space\ncompared to pixel-space diffiusion, effectively suppressing irrelevant noise\ninterference. The experimentalresults show that our method surpasses\nstate-of-the-art models and generates re-sults with better fidelity. This work\nestablishes a new low-rank constrained par-adigm for applying diffusion models\nto image reconstruction tasks, balancingstochastic generation with structural\nfidelity. Our code and model are publiclyavailable at\nhttps://github.com/continueyang/DeltaDiff .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.12567v2", "cate": "cs.CV", "date": "2025-02-18", "updated": "2025-07-16", "AI": {"title_translation": "DeltaDiff：基于锚点残差的真实感扩散模型用于高保真超分辨率", "tldr": "提出DeltaDiff，通过约束扩散过程建立HR-LR确定性映射路径，解决扩散模型在超分辨率中保真度下降问题，实现更高保真度的结果。", "motivation": "扩散模型在超分辨率任务中的应用面临保真度下降的问题，因为其固有的随机采样特性可能导致生成的细节偏离真实高分辨率图像的分布。", "method": "提出DeltaDiff框架，通过约束扩散过程来解决保真度问题。其核心是在高分辨率（HR）和低分辨率（LR）之间建立确定性映射路径，而非传统扩散模型的随机噪声扰动过程。理论分析表明，在残差空间中的扩散熵比像素空间扩散减少25%，有效抑制了无关噪声干扰。", "result": "实验结果表明，DeltaDiff超越了现有最先进的模型，并生成了具有更好保真度的结果。", "conclusion": "该工作为将扩散模型应用于图像重建任务建立了一种新的低秩约束范式，平衡了随机生成和结构保真度。", "translation": "近期，扩散模型在超分辨率任务中的迁移应用面临保真度下降的问题。由于扩散模型固有的随机采样特性，直接应用于超分辨率任务可能导致生成的细节偏离高分辨率图像的真实分布。为解决此问题，我们提出了DeltaDiff，一个新颖的框架，它约束了扩散过程，其本质是在高分辨率（HR）和低分辨率（LR）之间建立确定性映射路径，而非传统扩散模型的随机噪声扰动过程。理论分析表明，与像素空间扩散相比，在残差空间中的扩散熵减少了25%，有效抑制了无关噪声干扰。实验结果表明，我们的方法超越了现有最先进的模型，并生成了具有更好保真度的结果。这项工作为将扩散模型应用于图像重建任务建立了一种新的低秩约束范式，平衡了随机生成和结构保真度。我们的代码和模型已在 https://github.com/continueyang/DeltaDiff 公开可用。", "summary": "DeltaDiff是一种新型的扩散模型框架，旨在解决扩散模型在超分辨率任务中保真度下降的问题。该方法通过在高分辨率和低分辨率图像之间建立确定性映射路径来约束扩散过程，而非依赖随机噪声扰动。理论分析显示，这种方法在残差空间中能显著降低扩散熵，有效抑制噪声。实验证明，DeltaDiff在生成高保真度结果方面优于现有最先进的模型，并为图像重建任务中的扩散模型应用提供了一种新的低秩约束范式，成功平衡了生成的多样性与结构保真度。", "keywords": "扩散模型, 超分辨率, 保真度, 图像重建, 低秩约束", "comments": "DeltaDiff的创新在于通过建立HR-LR确定性映射路径来解决扩散模型在超分辨率中保真度下降的固有问题，这与传统扩散模型的随机性形成对比。它引入的低秩约束范式，在平衡随机生成和结构保真度方面具有重要意义，对图像重建领域具有潜在的广泛应用价值。理论上降低扩散熵25%的发现也支持了其方法的有效性。"}}
{"id": "2507.11628", "title": "DiaryPlay: AI-Assisted Authoring of Interactive Vignettes for Everyday Storytelling", "authors": ["Jiangnan Xu", "Haeseul Cha", "Gosu Choi", "Gyu-cheol Lee", "Yeo-Jin Yoon", "Zucheul Lee", "Konstantinos Papangelis", "Dae Hyun Kim", "Juho Kim"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11628v1", "summary": "An interactive vignette is a popular and immersive visual storytelling\napproach that invites viewers to role-play a character and influences the\nnarrative in an interactive environment. However, it has not been widely used\nby everyday storytellers yet due to authoring complexity, which conflicts with\nthe immediacy of everyday storytelling. We introduce DiaryPlay, an AI-assisted\nauthoring system for interactive vignette creation in everyday storytelling. It\ntakes a natural language story as input and extracts the three core elements of\nan interactive vignette (environment, characters, and events), enabling authors\nto focus on refining these elements instead of constructing them from scratch.\nThen, it automatically transforms the single-branch story input into a\nbranch-and-bottleneck structure using an LLM-powered narrative planner, which\nenables flexible viewer interactions while freeing the author from\nmulti-branching. A technical evaluation (N=16) shows that DiaryPlay-generated\ncharacter activities are on par with human-authored ones regarding\nbelievability. A user study (N=16) shows that DiaryPlay effectively supports\nauthors in creating interactive vignette elements, maintains authorial intent\nwhile reacting to viewer interactions, and provides engaging viewing\nexperiences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11628v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "DiaryPlay：AI辅助的日常叙事互动短篇故事创作", "tldr": "DiaryPlay是一个AI辅助系统，帮助日常叙事者轻松创作互动短篇故事，通过提取关键元素和LLM驱动的叙事规划器简化复杂性，并经评估证明有效。", "motivation": "互动短篇故事因创作复杂性，尚未被日常叙事者广泛使用，这与日常叙事的即时性相冲突。", "method": "DiaryPlay接收自然语言故事作为输入，提取互动短篇故事的三个核心元素（环境、角色和事件）。然后，它使用LLM驱动的叙事规划器将单分支故事自动转换为分支-瓶颈结构，从而实现灵活的观众互动并解放作者。", "result": "技术评估（N=16）表明，DiaryPlay生成的角色活动在可信度方面与人类创作的相当。用户研究（N=16）表明，DiaryPlay有效支持作者创建互动短篇故事元素，在响应观众互动的同时保持作者意图，并提供引人入胜的观看体验。", "conclusion": "DiaryPlay成功地解决了互动短篇故事创作的复杂性问题，使日常叙事者能够更轻松地创作和分享互动内容，并提供了高质量的创作辅助和观看体验。", "translation": "互动短篇故事是一种流行且沉浸式的视觉叙事方法，它邀请观众扮演一个角色并在互动环境中影响叙事。然而，由于创作复杂性，它尚未被日常叙事者广泛使用，这与日常叙事的即时性相冲突。我们介绍了DiaryPlay，一个用于日常叙事中互动短篇故事创作的AI辅助创作系统。它接收自然语言故事作为输入，并提取互动短篇故事的三个核心元素（环境、角色和事件），使作者能够专注于完善这些元素，而不是从头开始构建它们。然后，它使用LLM驱动的叙事规划器自动将单分支故事输入转换为分支-瓶颈结构，这使得灵活的观众互动成为可能，同时使作者摆脱多分支的困扰。一项技术评估（N=16）表明，DiaryPlay生成的角色活动在可信度方面与人类创作的相当。一项用户研究（N=16）表明，DiaryPlay有效支持作者创建互动短篇故事元素，在响应观众互动的同时保持作者意图，并提供引人入胜的观看体验。", "summary": "DiaryPlay是一个AI辅助系统，旨在简化日常叙事者创作互动短篇故事的复杂性。该系统接收自然语言故事，自动提取核心元素（环境、角色、事件），并利用LLM驱动的叙事规划器将单分支故事转换为分支-瓶颈结构，从而实现观众互动。技术评估和用户研究均证实了DiaryPlay在生成可信角色活动、保持作者意图以及提供引人入胜的观看体验方面的有效性，显著降低了互动叙事的创作门槛。", "keywords": "互动短篇故事, AI辅助创作, 日常叙事, 大型语言模型, 叙事规划", "comments": "这篇论文提出了一种创新的AI辅助创作工具DiaryPlay，有效解决了互动短篇故事创作的复杂性，使其更适合日常叙事。其亮点在于结合了自然语言处理和大型语言模型（LLM）来自动化故事元素提取和叙事分支规划，极大地降低了作者的负担。通过分支-瓶颈结构，它在提供互动性的同时避免了传统多分支叙事的复杂性。这项工作对于推动互动叙事在更广泛用户群体中的普及具有重要意义。"}}
{"id": "2505.02274", "title": "On the Need for a Statistical Foundation in Scenario-Based Testing of Autonomous Vehicles", "authors": ["Xingyu Zhao", "Robab Aghazadeh-Chakherlou", "Chih-Hong Cheng", "Peter Popov", "Lorenzo Strigini"], "categories": ["cs.SE", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted by ITSC 2025", "url": "http://arxiv.org/abs/2505.02274v2", "summary": "Scenario-based testing has emerged as a common method for autonomous vehicles\n(AVs) safety assessment, offering a more efficient alternative to mile-based\ntesting by focusing on high-risk scenarios. However, fundamental questions\npersist regarding its stopping rules, residual risk estimation, debug\neffectiveness, and the impact of simulation fidelity on safety claims. This\npaper argues that a rigorous statistical foundation is essential to address\nthese challenges and enable rigorous safety assurance. By drawing parallels\nbetween AV testing and established software testing methods, we identify shared\nresearch gaps and reusable solutions. We propose proof-of-concept models to\nquantify the probability of failure per scenario (\\textit{pfs}) and evaluate\ntesting effectiveness under varying conditions. Our analysis reveals that\nneither scenario-based nor mile-based testing universally outperforms the\nother. Furthermore, we give an example of formal reasoning about alignment of\nsynthetic and real-world testing outcomes, a first step towards supporting\nstatistically defensible simulation-based safety claims.", "comment": "Accepted by ITSC 2025", "pdf_url": "http://arxiv.org/pdf/2505.02274v2", "cate": "cs.SE", "date": "2025-05-04", "updated": "2025-07-15", "AI": {"title_translation": "自动驾驶汽车场景测试中统计基础的必要性", "tldr": "自动驾驶汽车的场景测试缺乏统计基础，导致停止规则、残余风险等问题。本文认为需要严格的统计基础来解决这些挑战，并提出了概念验证模型来量化故障概率和评估测试有效性。研究表明两种测试方法无绝对优势，并提出了支持基于仿真的安全声明的初步方法。", "motivation": "自动驾驶汽车的场景测试在停止规则、残余风险估计、调试有效性以及仿真保真度对安全声明的影响方面存在基本问题，这些都阻碍了严格的安全保障。", "method": "本文通过对比自动驾驶汽车测试与成熟的软件测试方法，识别共同的研究空白和可重用解决方案。提出了概念验证模型来量化每个场景的故障概率（pfs），并在不同条件下评估测试有效性。此外，还给出了一个关于合成测试结果与真实世界测试结果对齐的正式推理示例。", "result": "分析表明，场景测试和里程测试都没有普遍优于对方。研究还为支持统计上可辩护的基于仿真的安全声明迈出了第一步，通过对合成和真实世界测试结果对齐进行形式化推理。", "conclusion": "严格的统计基础对于解决自动驾驶汽车场景测试中的挑战和实现严格的安全保障至关重要。", "translation": "场景测试已成为自动驾驶汽车（AV）安全评估的常用方法，通过侧重于高风险场景，提供了一种比基于里程测试更高效的替代方案。然而，关于其停止规则、残余风险估计、调试有效性以及仿真保真度对安全声明的影响等基本问题依然存在。本文认为，严谨的统计基础对于解决这些挑战并实现严格的安全保障至关重要。通过将自动驾驶汽车测试与已建立的软件测试方法进行类比，我们识别了共同的研究空白和可重用解决方案。我们提出了概念验证模型来量化每个场景的故障概率（pfs）并评估不同条件下的测试有效性。我们的分析表明，场景测试和里程测试都没有普遍优于对方。此外，我们给出了一个关于合成和真实世界测试结果对齐的形式化推理示例，这是支持统计上可辩护的基于仿真的安全声明的第一步。", "summary": "本文探讨了自动驾驶汽车场景测试中缺乏严格统计基础的问题，该问题导致了停止规则、残余风险估计和仿真保真度等方面的挑战。作者主张建立一个坚实的统计框架来确保AVs的安全性，并借鉴了现有软件测试的经验。文中提出了概念验证模型来量化场景故障概率和评估测试效率，并指出场景测试和里程测试均无绝对优势。此外，论文还展示了如何通过形式化推理来协调合成与真实世界测试结果，为实现基于仿真的、具有统计学依据的安全声明奠定基础。", "keywords": "自动驾驶汽车, 场景测试, 统计基础, 安全评估, 仿真保真度", "comments": "这篇论文强调了在自动驾驶汽车场景测试中引入统计学严谨性的重要性，这对于解决当前测试方法中的不确定性和局限性至关重要。其创新点在于提出通过统计模型量化故障概率和评估测试有效性，并尝试弥合仿真与真实世界测试之间的鸿沟。论文指出了现有测试方法的不足，并为未来自动驾驶汽车的安全验证提供了新的思路和方法论基础。"}}
{"id": "2507.11987", "title": "Formal Verification of Neural Certificates Done Dynamically", "authors": ["Thomas A. Henzinger", "Konstantin Kueffner", "Emily Yu"], "categories": ["cs.SC", "cs.AI"], "primary_category": "Subjects:       Symbolic Computation (cs.SC)", "pdf_link": null, "comments": "Comments:      Accepted at RV'25", "url": "http://arxiv.org/abs/2507.11987v1", "summary": "Neural certificates have emerged as a powerful tool in cyber-physical systems\ncontrol, providing witnesses of correctness. These certificates, such as\nbarrier functions, often learned alongside control policies, once verified,\nserve as mathematical proofs of system safety. However, traditional formal\nverification of their defining conditions typically faces scalability\nchallenges due to exhaustive state-space exploration. To address this\nchallenge, we propose a lightweight runtime monitoring framework that\nintegrates real-time verification and does not require access to the underlying\ncontrol policy. Our monitor observes the system during deployment and performs\non-the-fly verification of the certificate over a lookahead region to ensure\nsafety within a finite prediction horizon. We instantiate this framework for\nReLU-based control barrier functions and demonstrate its practical\neffectiveness in a case study. Our approach enables timely detection of safety\nviolations and incorrect certificates with minimal overhead, providing an\neffective but lightweight alternative to the static verification of the\ncertificates.", "comment": "Accepted at RV'25", "pdf_url": "http://arxiv.org/pdf/2507.11987v1", "cate": "cs.SC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "神经网络证书的动态形式化验证", "tldr": "本文提出了一种轻量级的运行时监控框架，用于实时验证神经网络证书，以解决传统形式化验证的扩展性挑战，并在案例研究中证明了其有效性。", "motivation": "传统上，神经网络证书（如障碍函数）的形式化验证面临由于穷举状态空间探索导致的扩展性挑战。", "method": "本文提出了一种轻量级的运行时监控框架，该框架集成了实时验证功能，且无需访问底层控制策略。该监控器在系统部署期间观察系统，并在前瞻区域内对证书进行即时验证，以确保有限预测范围内的安全性。该框架已针对基于ReLU的控制障碍函数进行了实例化。", "result": "该方法能够在最小开销下及时检测安全违规和不正确的证书，并在案例研究中证明了其在基于ReLU的控制障碍函数上的实际有效性。", "conclusion": "本文提出的方法提供了一种有效但轻量级的替代方案，用于替代证书的静态验证，能够及时检测安全违规和不正确的证书，且开销极小。", "translation": "神经网络证书已成为网络物理系统控制中的强大工具，提供了正确性的证据。这些证书，例如障碍函数，通常与控制策略一起学习，一旦经过验证，即可作为系统安全性的数学证明。然而，其定义条件的传统形式化验证通常由于穷举状态空间探索而面临可扩展性挑战。为了解决这一挑战，我们提出了一种轻量级的运行时监控框架，该框架集成了实时验证功能，并且不需要访问底层控制策略。我们的监控器在部署期间观察系统，并在前瞻区域内对证书进行即时验证，以确保有限预测范围内的安全性。我们针对基于ReLU的控制障碍函数实例化了该框架，并在案例研究中证明了其在实践中的有效性。我们的方法能够以最小的开销及时检测安全违规和不正确的证书，为证书的静态验证提供了一种有效但轻量级的替代方案。", "summary": "本文针对神经网络证书的传统形式化验证面临的扩展性问题，提出了一种创新的轻量级运行时监控框架。该框架无需访问底层控制策略，通过在系统部署期间对证书进行实时、即时验证，确保系统在有限预测范围内的安全性。研究通过在基于ReLU的控制障碍函数上的实例化和案例研究，证明了该方法能够以极低的开销，及时有效地检测安全违规和不正确的证书，为静态验证提供了一种动态且高效的替代方案。", "keywords": "神经网络证书, 形式化验证, 运行时监控, 网络物理系统, 安全性", "comments": "这项工作通过引入动态运行时监控框架，有效解决了神经网络证书静态形式化验证中的可扩展性瓶颈。其创新之处在于无需访问底层控制策略即可进行实时验证，大大降低了验证的复杂性和开销，使其在实际部署中更具可行性。该方法为网络物理系统等需要高可靠性的领域提供了一个有价值的轻量级安全保障工具。"}}
{"id": "2302.00646", "title": "Epic-Sounds: A Large-scale Dataset of Actions That Sound", "authors": ["Jaesung Huh", "Jacob Chalk", "Evangelos Kazakos", "Dima Damen", "Andrew Zisserman"], "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted at TPAMI", "url": "http://arxiv.org/abs/2302.00646v3", "summary": "We introduce EPIC-SOUNDS, a large-scale dataset of audio annotations\ncapturing temporal extents and class labels within the audio stream of the\negocentric videos. We propose an annotation pipeline where annotators\ntemporally label distinguishable audio segments and describe the action that\ncould have caused this sound. We identify actions that can be discriminated\npurely from audio, through grouping these free-form descriptions of audio into\nclasses. For actions that involve objects colliding, we collect human\nannotations of the materials of these objects (e.g. a glass object being placed\non a wooden surface), which we verify from video, discarding ambiguities.\nOverall, EPIC-SOUNDS includes 78.4k categorised segments of audible events and\nactions, distributed across 44 classes as well as 39.2k non-categorised\nsegments. We train and evaluate state-of-the-art audio recognition and\ndetection models on our dataset, for both audio-only and audio-visual methods.\nWe also conduct analysis on: the temporal overlap between audio events, the\ntemporal and label correlations between audio and visual modalities, the\nambiguities in annotating materials from audio-only input, the importance of\naudio-only labels and the limitations of current models to understand actions\nthat sound.", "comment": "Accepted at TPAMI", "pdf_url": "http://arxiv.org/pdf/2302.00646v3", "cate": "cs.SD", "date": "2023-02-01", "updated": "2025-07-16", "AI": {"title_translation": "Epic-Sounds：一个大规模的声音动作数据集", "tldr": "Epic-Sounds是一个大型数据集，包含7.84万个带标签的声音事件和动作片段，以及3.92万个未分类片段，用于训练和评估音频识别与检测模型，并分析了音频事件、音视模态关联以及当前模型局限性。", "motivation": "该论文旨在创建一个大规模的音频标注数据集，用于捕获自我中心视频中音频流的时间范围和类别标签，并识别纯粹从音频中可区分的动作，以推动对声音动作的理解和模型开发。", "method": "作者提出了一个标注流程，标注员对可区分的音频片段进行时间标记，并描述可能导致该声音的动作。通过将自由形式的音频描述分组，识别出纯粹通过音频可区分的动作。对于涉及物体碰撞的动作，收集了物体材料的人工标注，并通过视频验证以消除歧义。然后，使用该数据集训练和评估了最先进的音频识别和检测模型，包括纯音频和音视结合的方法。此外，还分析了音频事件的时间重叠、音频和视觉模态之间的时间和标签关联、仅从音频输入标注材料的模糊性、纯音频标签的重要性以及当前模型理解声音动作的局限性。", "result": "EPIC-SOUNDS数据集总共包含7.84万个已分类的声音事件和动作片段，分布在44个类别中，以及3.92万个未分类片段。研究人员在该数据集上训练并评估了最先进的音频识别和检测模型，并进行了关于音频事件时间重叠、音频与视觉模态关联、纯音频标注材料模糊性、纯音频标签重要性以及当前模型理解声音动作局限性的分析。", "conclusion": "该论文引入了一个大规模的音频标注数据集EPIC-SOUNDS，并展示了其在训练和评估音频识别与检测模型方面的应用。研究结果揭示了音频事件的复杂性、音频与视觉信息之间的相互作用，以及当前模型在理解声音动作方面的局限性，强调了未来研究的方向。", "translation": "我们引入了EPIC-SOUNDS，这是一个大规模的音频标注数据集，用于捕获自我中心视频中音频流的时间范围和类别标签。我们提出了一种标注流程，标注员对可区分的音频片段进行时间标记，并描述可能导致该声音的动作。我们通过将这些自由形式的音频描述分组为类别，来识别纯粹通过音频可区分的动作。对于涉及物体碰撞的动作，我们收集了这些物体材料的人工标注（例如玻璃物体被放置在木质表面上），并通过视频进行验证，以消除歧义。总体而言，EPIC-SOUNDS包含7.84万个已分类的声音事件和动作片段，分布在44个类别中，以及3.92万个未分类片段。我们还在我们的数据集上训练和评估了最先进的音频识别和检测模型，包括纯音频和音视结合的方法。我们还对以下方面进行了分析：音频事件之间的时间重叠、音频和视觉模态之间的时间和标签关联、仅从音频输入标注材料的模糊性、纯音频标签的重要性以及当前模型理解声音动作的局限性。", "summary": "该论文介绍了EPIC-SOUNDS，一个大规模的自我中心视频音频标注数据集。该数据集通过独特的标注流程，捕捉了音频流中的时间范围和动作类别，并识别出纯粹通过音频可区分的动作。它包含7.84万个分类声音事件（44个类别）和3.92万个未分类片段，部分数据还包含物体材料标注。研究者利用此数据集训练和评估了音频识别与检测模型，并深入分析了音频事件的时间重叠、音视模态关联、纯音频标注的挑战以及现有模型在理解声音动作方面的局限性。", "keywords": "音频数据集, 动作识别, 声音事件, 音视学习, EPIC-SOUNDS", "comments": "EPIC-SOUNDS数据集的创新之处在于其大规模的音频事件标注，特别是对“声音动作”的关注和对物体材料的细致标注，这对于推进纯音频动作识别和多模态理解具有重要意义。它不仅提供了数据，还进行了深入的分析，揭示了当前模型在理解声音动作方面的不足，为未来的研究指明了方向。该数据集的构建方法，特别是对纯音频可区分动作的识别和歧义处理，也值得称赞。"}}
{"id": "2507.11832", "title": "ILID: Native Script Language Identification for Indian Languages", "authors": ["Yash Ingle", "Pruthwik Mishra"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      8 pages, 1 figure, 7 tables, Paper accepted in RANLP 2025", "url": "http://arxiv.org/abs/2507.11832v1", "summary": "The language identification task is a crucial fundamental step in NLP. Often\nit serves as a pre-processing step for widely used NLP applications such as\nmultilingual machine translation, information retrieval, question and\nanswering, and text summarization. The core challenge of language\nidentification lies in distinguishing languages in noisy, short, and code-mixed\nenvironments. This becomes even harder in case of diverse Indian languages that\nexhibit lexical and phonetic similarities, but have distinct differences. Many\nIndian languages share the same script making the task even more challenging.\nIn this paper, we release a dataset of 230K sentences consisting of English and\nall 22 official Indian languages labeled with their language identifiers where\ndata in most languages are newly created. We also develop and release robust\nbaseline models using state-of-the-art approaches in machine learning and deep\nlearning that can aid the research in this field. Our baseline models are\ncomparable to the state-of-the-art models for the language identification task.", "comment": "8 pages, 1 figure, 7 tables, Paper accepted in RANLP 2025", "pdf_url": "http://arxiv.org/pdf/2507.11832v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "ILID：印度语言的本地文字语言识别", "tldr": "本文发布了一个包含23万句子的印度语言和英语数据集，并开发了强大的基线模型，用于解决印度语言中具有挑战性的本地文字语言识别任务。", "motivation": "语言识别是自然语言处理中的一个关键基础步骤，常作为多语言机器翻译、信息检索、问答和文本摘要等应用的预处理步骤。区分嘈杂、简短和代码混合环境中的语言是一个核心挑战，特别是对于词汇和语音相似但有明显差异的印度语言，许多印度语言共享同一文字，这使得任务更具挑战性。", "method": "本文发布了一个包含23万句子的数据集，该数据集包含英语和所有22种官方印度语言，并带有语言标识符，其中大多数语言的数据是新创建的。此外，还使用机器学习和深度学习领域的最新方法开发并发布了强大的基线模型。", "result": "所开发的基线模型在语言识别任务上与现有最先进的模型相当。", "conclusion": "Not mentioned in abstract", "translation": "语言识别任务是自然语言处理中的一个关键基础步骤。它通常作为广泛使用的自然语言处理应用（如多语言机器翻译、信息检索、问答和文本摘要）的预处理步骤。语言识别的核心挑战在于在嘈杂、简短和代码混合的环境中区分语言。对于词汇和语音相似但有明显差异的印度多样化语言来说，这变得更加困难。许多印度语言共享相同的文字，这使得任务更具挑战性。在本文中，我们发布了一个包含23万个句子的数据集，其中包含英语和所有22种官方印度语言，并带有语言标识符，其中大多数语言的数据是新创建的。我们还使用机器学习和深度学习领域的最新方法开发并发布了强大的基线模型，这些模型可以帮助该领域的研究。我们的基线模型在语言识别任务上与现有最先进的模型相当。", "summary": "本文针对印度语言的本地文字语言识别任务，发布了一个包含英语和22种官方印度语言共23万句子的新数据集，并开发了基于机器学习和深度学习的强大基线模型。这些模型在语言识别任务上表现与现有最先进模型相当，旨在促进该领域的研究。", "keywords": "语言识别, 印度语言, 本地文字, 数据集, 基线模型", "comments": "这篇论文通过发布一个新的大规模数据集和提供强大的基线模型，为印度语言的本地文字语言识别领域做出了重要贡献。考虑到印度语言的复杂性（词汇/语音相似性、共享文字），这项工作对于多语言NLP应用具有重要意义。数据集的新创建和模型的发布将极大地推动该领域的研究。"}}
{"id": "2507.11831", "title": "Generative Intelligence Systems in the Flow of Group Emotions", "authors": ["Fernando Koch", "Jessica Nahulan", "Jeremy Fox", "Martin Keen"], "categories": ["cs.ET"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "Comments:      8 pages, 10 figures", "url": "http://arxiv.org/abs/2507.11831v1", "summary": "Emotional cues frequently arise and shape group dynamics in interactive\nsettings where multiple humans and artificial agents communicate through shared\ndigital channels. While artificial agents lack intrinsic emotional states, they\ncan simulate affective behavior using synthetic modalities such as text or\nspeech. This work introduces a model for orchestrating emotion contagion,\nenabling agents to detect emotional signals, infer group mood patterns, and\ngenerate targeted emotional responses. The system captures human emotional\nexchanges and uses this insight to produce adaptive, generative responses that\ninfluence group affect in real time. The model supports applications in\ncollaborative, educational, and social environments by shifting affective\ncomputing from individual-level reactions to coordinated, group-level emotion\nmodulation. We present the system architecture and provide experimental results\nthat illustrate its effectiveness in sensing and steering group mood dynamics.", "comment": "8 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.11831v1", "cate": "cs.ET", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "群体情感流动中的生成式智能系统", "tldr": "该研究引入了一个用于协调情感传染的模型，使人工智能代理能够检测、推断和生成情感响应，以实时影响群体情绪。", "motivation": "在多人和人工智能代理通过共享数字渠道进行通信的互动环境中，情感线索频繁出现并影响群体动态。虽然人工智能代理缺乏内在情感，但它们可以模拟情感行为。该研究旨在使人工智能代理能够影响群体情感，以支持协作、教育和社交环境中的应用。", "method": "该工作引入了一个用于协调情感传染的模型，使代理能够检测情感信号、推断群体情绪模式并生成有针对性的情感响应。该系统捕获人类情感交流，并利用这些洞察生成自适应的、生成式的响应，实时影响群体情感。该模型将情感计算从个体层面反应转向协调的、群体层面的情感调节。", "result": "研究展示了系统架构，并提供了实验结果，这些结果说明了其在感知和引导群体情绪动态方面的有效性。", "conclusion": "该模型通过将情感计算从个体层面反应转向协调的、群体层面的情感调节，支持协作、教育和社交环境中的应用，并有效感知和引导群体情绪动态。", "translation": "在多人和人工智能代理通过共享数字渠道进行通信的互动环境中，情感线索频繁出现并影响群体动态。虽然人工智能代理缺乏内在情感状态，但它们可以使用文本或语音等合成模式模拟情感行为。这项工作引入了一个协调情感传染的模型，使代理能够检测情感信号，推断群体情绪模式，并生成有针对性的情感响应。该系统捕获人类情感交流，并利用这些洞察生成自适应的、生成式的响应，实时影响群体情感。该模型通过将情感计算从个体层面反应转向协调的、群体层面的情感调节，支持协作、教育和社交环境中的应用。我们展示了系统架构并提供了实验结果，这些结果说明了其在感知和引导群体情绪动态方面的有效性。", "summary": "本研究提出了一种生成式智能系统，旨在通过协调情感传染来实时影响群体情绪。该系统使人工智能代理能够检测人类情感信号，推断群体情绪模式，并生成自适应的情感响应。通过将情感计算从个体层面扩展到群体层面，该模型在协作、教育和社交环境中具有潜在应用价值，并通过实验证明了其在感知和引导群体情绪动态方面的有效性。", "keywords": "情感计算, 群体情绪, 人工智能代理, 情感传染, 生成式系统", "comments": "该研究的创新之处在于将情感计算从个体层面提升到群体层面，并引入了生成式智能系统来主动影响群体情绪，而非仅仅被动响应。这对于构建更具同理心和适应性的AI系统，尤其是在协作和社交互动中具有重要意义。未来研究可以探索其在不同文化背景下的普适性以及潜在的伦理问题。"}}
{"id": "2507.11761", "title": "Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning", "authors": ["Fan Shi", "Bin Li", "Xiangyang Xue"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11761v1", "summary": "Abstract visual reasoning (AVR) enables humans to quickly discover and\ngeneralize abstract rules to new scenarios. Designing intelligent systems with\nhuman-like AVR abilities has been a long-standing topic in the artificial\nintelligence community. Deep AVR solvers have recently achieved remarkable\nsuccess in various AVR tasks. However, they usually use task-specific designs\nor parameters in different tasks. In such a paradigm, solving new tasks often\nmeans retraining the model, and sometimes retuning the model architectures,\nwhich increases the cost of solving AVR problems. In contrast to task-specific\napproaches, this paper proposes a novel Unified Conditional Generative Solver\n(UCGS), aiming to address multiple AVR tasks in a unified framework. First, we\nprove that some well-known AVR tasks can be reformulated as the problem of\nestimating the predictability of target images in problem panels. Then, we\nillustrate that, under the proposed framework, training one conditional\ngenerative model can solve various AVR tasks. The experiments show that with a\nsingle round of multi-task training, UCGS demonstrates abstract reasoning\nability across various AVR tasks. Especially, UCGS exhibits the ability of\nzero-shot reasoning, enabling it to perform abstract reasoning on problems from\nunseen AVR tasks in the testing phase.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11761v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "超越任务特定推理：一个统一的条件生成框架用于抽象视觉推理", "tldr": "本文提出了一种名为统一条件生成求解器（UCGS）的新方法，旨在解决抽象视觉推理（AVR）中的多任务问题，通过一个统一的框架克服了传统任务特定方法的局限性，并展示了出色的零样本推理能力。", "motivation": "目前的深度抽象视觉推理（AVR）求解器通常采用任务特定的设计或参数，导致解决新任务时需要重新训练或调整模型，从而增加了解决AVR问题的成本。本文的动机是提出一个统一的框架来解决多个AVR任务，以克服这些限制。", "method": "本文提出了一种新颖的统一条件生成求解器（UCGS）。首先，将一些著名的AVR任务重新表述为估计问题面板中目标图像可预测性的问题。然后，在一个统一框架下，通过训练一个条件生成模型来解决各种AVR任务。", "result": "实验表明，通过单轮多任务训练，UCGS在各种AVR任务中展示了抽象推理能力。特别是，UCGS在测试阶段对来自未见过的AVR任务的问题表现出零样本推理能力。", "conclusion": "本文提出的统一条件生成求解器（UCGS）提供了一个统一的框架，能够解决各种抽象视觉推理（AVR）任务，并展示了对未见任务的零样本推理能力，从而克服了任务特定方法的局限性。", "translation": "抽象视觉推理（AVR）使人类能够快速发现抽象规则并将其推广到新场景。设计具有类人AVR能力的智能系统一直是人工智能领域的长期课题。深度AVR求解器最近在各种AVR任务中取得了显著成功。然而，它们通常在不同任务中使用任务特定的设计或参数。在这种范式下，解决新任务通常意味着重新训练模型，有时甚至需要重新调整模型架构，这增加了解决AVR问题的成本。与任务特定方法相反，本文提出了一种新颖的统一条件生成求解器（UCGS），旨在在一个统一框架中解决多个AVR任务。首先，我们证明了一些著名的AVR任务可以被重新表述为估计问题面板中目标图像可预测性的问题。然后，我们阐明，在所提出的框架下，训练一个条件生成模型可以解决各种AVR任务。实验表明，通过单轮多任务训练，UCGS在各种AVR任务中展示了抽象推理能力。特别是，UCGS展现了零样本推理能力，使其能够在测试阶段对来自未见过的AVR任务的问题进行抽象推理。", "summary": "本文提出了一种名为统一条件生成求解器（UCGS）的新型框架，旨在解决抽象视觉推理（AVR）中的多任务问题，以克服现有任务特定方法的局限性。UCGS将AVR任务重新定义为目标图像可预测性估计问题，并通过训练单个条件生成模型实现多任务学习。实验证明，UCGS在多种AVR任务中表现出强大的抽象推理能力，包括对未见任务的零样本推理，有效降低了与任务特定模型相关的成本。", "keywords": "抽象视觉推理, 统一条件生成求解器, 零样本推理, 多任务学习, 生成模型", "comments": "创新点在于提出了一个统一的条件生成框架（UCGS），它超越了传统的任务特定设计，使一个模型能够解决多种抽象视觉推理（AVR）任务，并展现出零样本推理能力，这是迈向更通用人工智能的重要一步。其重要性体现在解决了为每个新AVR任务重新训练或调整模型所带来的高成本问题。零样本能力对于实际应用尤其有价值。然而，摘要中没有详细说明所涵盖的AVR任务的具体类型、“重新表述”的复杂性，或“各种”任务的规模。此外，也没有详细提及性能指标或与现有最先进任务特定模型的具体比较。"}}
{"id": "2507.12011", "title": "DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning", "authors": ["Yao Lu", "Hongyu Gao", "Zhuangzhi Chen", "Dongwei Xu", "Yun Lin", "Qi Xuan", "Guan Gui"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12011v1", "summary": "Although deep neural networks have made remarkable achievements in the field\nof automatic modulation recognition (AMR), these models often require a large\namount of labeled data for training. However, in many practical scenarios, the\navailable target domain data is scarce and difficult to meet the needs of model\ntraining. The most direct way is to collect data manually and perform expert\nannotation, but the high time and labor costs are unbearable. Another common\nmethod is data augmentation. Although it can enrich training samples to a\ncertain extent, it does not introduce new data and therefore cannot\nfundamentally solve the problem of data scarcity. To address these challenges,\nwe introduce a data expansion framework called Dynamic Uncertainty-driven\nSample Expansion (DUSE). Specifically, DUSE uses an uncertainty scoring\nfunction to filter out useful samples from relevant AMR datasets and employs an\nactive learning strategy to continuously refine the scorer. Extensive\nexperiments demonstrate that DUSE consistently outperforms 8 coreset selection\nbaselines in both class-balance and class-imbalance settings. Besides, DUSE\nexhibits strong cross-architecture generalization for unseen models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12011v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "DUSE：一种基于主动学习的低资源自动调制识别数据扩展框架", "tldr": "DUSE是一个数据扩展框架，它利用不确定性驱动的样本选择和主动学习，解决了低资源场景下自动调制识别（AMR）模型训练所需大量标注数据的问题。", "motivation": "深度神经网络在自动调制识别（AMR）领域取得了显著成就，但其训练需要大量标注数据。然而，在许多实际场景中，目标域数据稀缺，无法满足模型训练需求。手动收集和专家标注成本高昂，而数据增强虽然能丰富样本但不能从根本上解决数据稀缺问题。", "method": "本研究引入了一个名为动态不确定性驱动样本扩展（DUSE）的数据扩展框架。DUSE利用不确定性评分函数从相关AMR数据集中筛选出有用样本，并采用主动学习策略持续优化该评分器。", "result": "DUSE在类别平衡和类别不平衡设置下，均持续优于8种核心集选择基线方法。此外，DUSE对未见过的模型表现出强大的跨架构泛化能力。", "conclusion": "DUSE框架能有效解决低资源场景下自动调制识别的数据稀缺问题，并通过不确定性驱动的样本选择和主动学习显著提升模型性能和泛化能力。", "translation": "尽管深度神经网络在自动调制识别（AMR）领域取得了显著成就，但这些模型通常需要大量标注数据进行训练。然而，在许多实际场景中，可用的目标域数据稀缺，难以满足模型训练需求。最直接的方法是手动收集数据并进行专家标注，但高昂的时间和人力成本是无法承受的。另一种常见方法是数据增强。尽管它可以在一定程度上丰富训练样本，但它没有引入新数据，因此无法从根本上解决数据稀缺问题。为了应对这些挑战，我们引入了一个名为动态不确定性驱动样本扩展（DUSE）的数据扩展框架。具体来说，DUSE使用不确定性评分函数从相关AMR数据集中筛选出有用样本，并采用主动学习策略持续优化评分器。大量的实验表明，DUSE在类别平衡和类别不平衡设置下，均持续优于8种核心集选择基线方法。此外，DUSE对未见过的模型表现出强大的跨架构泛化能力。", "summary": "本文提出了一个名为DUSE（动态不确定性驱动样本扩展）的数据扩展框架，旨在解决低资源场景下自动调制识别（AMR）模型训练所需大量标注数据的问题。DUSE通过不确定性评分函数从现有数据集中筛选出有价值的样本，并结合主动学习策略持续优化样本选择过程。实验结果表明，DUSE在不同类别设置下均优于现有基线方法，并展现出良好的跨架构泛化能力，有效缓解了数据稀缺对AMR模型训练的限制。", "keywords": "自动调制识别, 数据扩展, 主动学习, 低资源, 深度学习", "comments": "DUSE框架的创新性在于将不确定性驱动的样本选择与主动学习相结合，以高效地从现有数据中筛选出最有价值的样本，从而有效解决深度学习模型在低资源AMR场景下的数据依赖问题。这种方法不仅降低了人工标注成本，还显著提升了模型性能和泛化能力，对于实际应用具有重要意义。"}}
{"id": "2507.12311", "title": "An Ecosystem for Ontology Interoperability", "authors": ["Zhangcheng Qiang"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      4 pages, 8 figures", "url": "http://arxiv.org/abs/2507.12311v1", "summary": "Ontology interoperability is one of the complicated issues that restricts the\nuse of ontologies in knowledge graphs (KGs). Different ontologies with\nconflicting and overlapping concepts make it difficult to design, develop, and\ndeploy an interoperable ontology for downstream tasks. We propose an ecosystem\nfor ontology interoperability. The ecosystem employs three state-of-the-art\nsemantic techniques in different phases of the ontology engineering life cycle:\nontology design patterns (ODPs) in the design phase, ontology matching and\nversioning (OM\\&OV) in the develop phase, and ontology-compliant knowledge\ngraphs (OCKGs) in the deploy phase, to achieve better ontology interoperability\nin real-world applications. A case study in the building domain validates the\nusefulness of the proposed ecosystem.", "comment": "4 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.12311v1", "cate": "cs.IR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "本体互操作性生态系统", "tldr": "该论文提出了一个本体互操作性生态系统，通过在本体工程生命周期的不同阶段采用本体设计模式、本体匹配与版本控制以及符合本体的知识图谱来解决知识图谱中本体互操作性的复杂问题。", "motivation": "本体互操作性是限制本体在知识图谱（KGs）中使用的复杂问题之一。具有冲突和重叠概念的不同本体使得为下游任务设计、开发和部署可互操作的本体变得困难。", "method": "本文提出了一个本体互操作性生态系统。该生态系统在本体工程生命周期的不同阶段采用了三种最先进的语义技术：设计阶段的本体设计模式（ODPs）、开发阶段的本体匹配与版本控制（OM&OV），以及部署阶段的符合本体的知识图谱（OCKGs），以在实际应用中实现更好的本体互操作性。", "result": "在建筑领域的案例研究验证了所提出生态系统的实用性。", "conclusion": "该研究通过提出一个集成了多种先进语义技术的生态系统，有效地提升了本体在知识图谱中的互操作性，并在实际应用中得到了验证。", "translation": "本体互操作性是限制本体在知识图谱（KGs）中使用的复杂问题之一。具有冲突和重叠概念的不同本体使得为下游任务设计、开发和部署可互操作的本体变得困难。我们提出了一个本体互操作性生态系统。该生态系统在本体工程生命周期的不同阶段采用了三种最先进的语义技术：设计阶段的本体设计模式（ODPs）、开发阶段的本体匹配与版本控制（OM&OV），以及部署阶段的符合本体的知识图谱（OCKGs），以在实际应用中实现更好的本体互操作性。在建筑领域的案例研究验证了所提出生态系统的实用性。", "summary": "本文针对知识图谱中本体互操作性面临的挑战，提出了一个创新的本体互操作性生态系统。该系统将本体工程生命周期分为设计、开发和部署三个阶段，并分别引入了本体设计模式、本体匹配与版本控制以及符合本体的知识图谱等先进语义技术。通过在建筑领域的案例研究，验证了该生态系统在实际应用中提升本体互操作性的有效性。", "keywords": "本体互操作性, 知识图谱, 本体设计模式, 本体匹配, 本体版本控制", "comments": "该论文的创新之处在于提出了一个全面的本体互操作性生态系统，将本体生命周期中的关键阶段与相应的先进语义技术相结合，提供了一个结构化的解决方案。其重要性在于解决了知识图谱领域中本体互操作性这一核心难题，有望促进本体在实际应用中的更广泛采用。"}}
{"id": "2507.12047", "title": "Pathfinding in Self-Deleting Graphs", "authors": ["Michal Dvořák", "Dušan Knop", "Michal Opler", "Jan Pokorný", "Ondřej Suchý", "Krisztina Szilágyi"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12047v1", "summary": "In this paper, we study the problem of pathfinding on traversal-dependent\ngraphs, i.e., graphs whose edges change depending on the previously visited\nvertices. In particular, we study \\emph{self-deleting graphs}, introduced by\nCarmesin et al. (Sarah Carmesin, David Woller, David Parker, Miroslav Kulich,\nand Masoumeh Mansouri. The Hamiltonian cycle and travelling salesperson\nproblems with traversal-dependent edge deletion. J. Comput. Sci.), which\nconsist of a graph $G=(V, E)$ and a function $f\\colon V\\rightarrow 2^E$, where\n$f(v)$ is the set of edges that will be deleted after visiting the vertex $v$.\nIn the \\textsc{(Shortest) Self-Deleting $s$-$t$-path} problem we are given a\nself-deleting graph and its vertices $s$ and $t$, and we are asked to find a\n(shortest) path from $s$ to $t$, such that it does not traverse an edge in\n$f(v)$ after visiting $v$ for any vertex $v$.\n  We prove that \\textsc{Self-Deleting $s$-$t$-path} is NP-hard even if the\ngiven graph is outerplanar, bipartite, has maximum degree $3$, bandwidth $2$\nand $|f(v)|\\leq 1$ for each vertex $v$. We show that \\textsc{Shortest\nSelf-Deleting $s$-$t$-path} is W[1]-complete parameterized by the length of the\nsought path and that \\textsc{Self-Deleting $s$-$t$-path} is \\W{1}-complete\nparameterized by the vertex cover number, feedback vertex set number and\ntreedepth. We also show that the problem becomes FPT when we parameterize by\nthe maximum size of $f(v)$ and several structural parameters. Lastly, we show\nthat the problem does not admit a polynomial kernel even for parameterization\nby the vertex cover number and the maximum size of $f(v)$ combined already on\n2-outerplanar graphs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12047v1", "cate": "cs.DS", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "自删除图中的寻路问题", "tldr": "研究了自删除图上的寻路问题，证明了其在多种约束下的计算复杂性，包括NP-hard、W[1]-complete和FPT，并探讨了多项式核的存在性。", "motivation": "论文研究了遍历依赖图（即边随访问过的顶点而变化的图）上的寻路问题，特别是自删除图。自删除图的特点是访问某个顶点后，会有一组边被删除。", "method": "作者通过理论证明来分析自删除图上寻路问题的计算复杂性，包括NP-hard性、W[1]-完全性以及在特定参数化下的固定参数可解性（FPT）和多项式核的存在性。", "result": "1. “自删除s-t路径”问题是NP-hard的，即使在给定图是外平面图、二分图、最大度为3、带宽为2且每个顶点v的|f(v)|≤1的严格限制条件下。2. “最短自删除s-t路径”问题以所求路径的长度为参数是W[1]-完全的。3. “自删除s-t路径”问题以顶点覆盖数、反馈顶点集数和树深度为参数是W[1]-完全的。4. 当以f(v)的最大大小和几个结构参数为参数时，问题变为FPT。5. 即使在2-外平面图上，当以顶点覆盖数和f(v)的最大大小组合为参数时，问题也不支持多项式核。", "conclusion": "该研究全面分析了自删除图上寻路问题的计算复杂性，揭示了其在多种图结构和参数化下的难解性和可解性边界，并排除了某些情况下多项式核的存在。", "translation": "在本文中，我们研究了遍历依赖图上的寻路问题，即边的变化取决于先前访问过的顶点的图。我们特别研究了由Carmesin等人（Sarah Carmesin, David Woller, David Parker, Miroslav Kulich, and Masoumeh Mansouri. The Hamiltonian cycle and travelling salesperson problems with traversal-dependent edge deletion. J. Comput. Sci.）引入的“自删除图”，它由一个图G=(V, E)和一个函数f: V→2^E组成，其中f(v)是访问顶点v后将被删除的边集。在“（最短）自删除s-t路径”问题中，我们给定一个自删除图及其顶点s和t，要求找到一条从s到t的（最短）路径，使得在访问任何顶点v后，路径不会遍历f(v)中的边。\n我们证明了“自删除s-t路径”问题是NP-难的，即使在给定图是外平面图、二分图、最大度为3、带宽为2且每个顶点v的|f(v)|≤1的情况下也是如此。我们表明，“最短自删除s-t路径”问题以所求路径的长度为参数是W[1]-完全的，并且“自删除s-t路径”问题以顶点覆盖数、反馈顶点集数和树深度为参数是W[1]-完全的。我们还表明，当以f(v)的最大大小和几个结构参数为参数时，问题变为FPT。最后，我们表明，即使在2-外平面图上，当以顶点覆盖数和f(v)的最大大小组合为参数时，该问题也不支持多项式核。", "summary": "本文深入研究了自删除图上的寻路问题，这类图的特点是边的存在性会因顶点访问而动态改变。研究定义了自删除图和（最短）自删除s-t路径问题，并系统地分析了其计算复杂性。结果表明，即使在严格的图结构限制下，该问题仍是NP-hard的，并在多种参数化下是W[1]-完全的。然而，对于某些参数化（如f(v)的最大大小），问题变为固定参数可解（FPT）。此外，研究还排除了某些参数组合下多项式核的存在性，全面揭示了该问题的计算边界。", "keywords": "自删除图, 寻路问题, 计算复杂性, 参数化复杂性, NP-hard", "comments": "这篇论文对自删除图这一新型图模型中的寻路问题进行了系统的计算复杂性分析。其创新之处在于引入了边随遍历动态删除的概念，这在现实世界的动态网络或资源消耗问题中具有潜在应用。论文通过严谨的理论证明，揭示了该问题在不同图结构和参数化下的计算难度，为后续算法设计和实际应用提供了重要的理论基础。特别是对NP-hard、W[1]-完全性以及FPT的界定，为理解这类动态图问题的固有复杂性提供了深刻见解。"}}
{"id": "2505.00894", "title": "Non-Adaptive Cryptanalytic Time-Space Lower Bounds via a Shearer-like Inequality for Permutations", "authors": ["Itai Dinur", "Nathan Keller", "Avichai Marmor"], "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00894v2", "summary": "The power of adaptivity in algorithms has been intensively studied in diverse\nareas of theoretical computer science. In this paper, we obtain a number of\nsharp lower bound results which show that adaptivity provides a significant\nextra power in cryptanalytic time-space tradeoffs with (possibly unlimited)\npreprocessing time.\n  Most notably, we consider the discrete logarithm (DLOG) problem in a generic\ngroup of $N$ elements. The classical `baby-step giant-step' algorithm for the\nproblem has time complexity $T=O(\\sqrt{N})$, uses $O(\\sqrt{N})$ bits of space\n(up to logarithmic factors in $N$) and achieves constant success probability.\n  We examine a generalized setting where an algorithm obtains an advice string\nof $S$ bits and is allowed to make $T$ arbitrary non-adaptive queries that\ndepend on the advice string (but not on the challenge group element).\n  We show that in this setting, the $T=O(\\sqrt{N})$ online time complexity of\nthe baby-step giant-step algorithm cannot be improved, unless the advice string\nis more than $\\Omega(\\sqrt{N})$ bits long. This lies in stark contrast with the\nclassical adaptive Pollard's rho algorithm for DLOG, which can exploit\npreprocessing to obtain the tradeoff curve $ST^2=O(N)$. We obtain similar sharp\nlower bounds for several other cryptanalytic problems.\n  To obtain our results, we present a new model that allows analyzing\nnon-adaptive preprocessing algorithms for a wide array of search and decision\nproblems in a unified way. Since previous proof techniques inherently cannot\ndistinguish between adaptive and non-adaptive algorithms for the problems in\nour model, they cannot be used to obtain our results. Consequently, our proof\nuses a variant of Shearer's lemma for this setting, due to Barthe,\nCordero-Erausquin, Ledoux, and Maurey (2011). This seems to be the first time a\nvariant of Shearer's lemma for permutations is used in an algorithmic context.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00894v2", "cate": "cs.CR", "date": "2025-05-01", "updated": "2025-07-16", "AI": {"title_translation": "非自适应密码分析时空下限通过置换的类 Shearer 不等式", "tldr": "本文研究表明，在密码分析时空权衡中，自适应性提供了显著的额外能力；非自适应算法在离散对数等问题上存在严格的时空下限，除非预处理空间巨大，这与自适应算法形成对比。", "motivation": "理解并量化算法中适应性在密码分析时空权衡中的额外能力，并通过建立非自适应算法的严格下限来突出其重要性。", "method": "研究了一个广义设置，其中算法接收一个建议字符串并进行非自适应查询。提出了一种新的统一模型，用于分析各种搜索和决策问题的非自适应预处理算法。证明过程首次在算法背景下使用了Barthe等人（2011）提出的Shearer引理的置换变体。", "result": "研究表明，适应性在密码分析时空权衡中提供了显著的额外能力。对于通用群中的离散对数（DLOG）问题，证明了除非建议字符串超过$\\\\Omega(\\\\sqrt{N})$比特，否则经典小步大步算法的$T=O(\\\\sqrt{N})$在线时间复杂度无法改进。这与自适应Pollard's rho算法能实现$ST^2=O(N)$的权衡形成鲜明对比。对其他几个密码分析问题也获得了类似的尖锐下限。", "conclusion": "本文得出结论，适应性在密码分析时空权衡中具有显著优势，并通过建立离散对数等问题的严格非自适应下限，突出了自适应算法的优越性。新提出的统一模型和Shearer引理变体的创新应用是实现这些结果的关键。", "translation": "算法中适应性（adaptivity）的力量在理论计算机科学的各个领域得到了深入研究。在本文中，我们获得了一些尖锐的下限结果，表明适应性在密码分析时空权衡（可能具有无限预处理时间）中提供了显著的额外能力。\n最值得注意的是，我们考虑了$N$个元素的通用群中的离散对数（DLOG）问题。该问题的经典“小步大步”算法时间复杂度为$T=O(\\\\sqrt{N})$，使用$O(\\\\sqrt{N})$比特空间（忽略$N$的对数因子），并达到恒定的成功概率。\n我们研究了一个广义设置，其中算法获取一个$S$比特的建议字符串，并被允许进行$T$次任意的非自适应查询，这些查询依赖于建议字符串（但不依赖于挑战群元素）。\n我们表明，在此设置下，除非建议字符串的长度超过$\\\\Omega(\\\\sqrt{N})$比特，否则小步大步算法的$T=O(\\\\sqrt{N})$在线时间复杂度无法改进。这与经典的自适应Pollard's rho算法形成鲜明对比，后者可以利用预处理获得$ST^2=O(N)$的权衡曲线。我们对其他几个密码分析问题也获得了类似的尖锐下限。\n为了获得我们的结果，我们提出了一种新模型，该模型允许以统一的方式分析各种搜索和决策问题的非自适应预处理算法。由于以前的证明技术本质上无法区分我们模型中问题的自适应和非自适应算法，因此它们无法用于获得我们的结果。因此，我们的证明使用了Barthe、Cordero-Erausquin、Ledoux和Maurey（2011）提出的Shearer引理的变体。这似乎是Shearer引理的置换变体首次在算法背景下使用。", "summary": "本文深入探讨了算法适应性在密码分析时空权衡中的能力，并指出适应性提供了显著的优势。针对离散对数（DLOG）问题，论文建立了严格的非自适应下限，表明在没有大量预处理空间的情况下，小步大步算法的$O(\\\\sqrt{N})$在线时间复杂度无法提升。这与自适应算法（如Pollard's rho算法）形成鲜明对比。作者引入了一种新的统一模型来分析非自适应预处理算法，并创新性地应用了Shearer引理的置换变体来证明其结果。", "keywords": "密码分析, 时空权衡, 非自适应算法, 下限, 离散对数, Shearer引理", "comments": "该论文通过量化适应性在密码分析时空权衡中的优势，做出了重要贡献，尤其突出了非自适应方法的局限性。引入新的统一模型和创新性地应用Shearer引理的置换变体是方法论上的显著进步，使得能够实现先前技术无法完成的证明。这项工作加深了对密码学中计算复杂度的理解。"}}
{"id": "2312.06875", "title": "Eywa: Automating Model Based Testing using LLMs", "authors": ["Rajdeep Mondal", "Rathin Singha", "Todd Millstein", "George Varghese", "Ryan Beckett", "Siva Kesava Reddy Kakarla"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2312.06875v2", "summary": "Model-based testing (MBT), whereby a model of the system under test is\nanalyzed to generate high-coverage test cases, has been used to test protocol\nimplementations. A key barrier to the use of MBT is the need for users to\nunderstand protocol RFCs in detail to create a compliant model. Our new\napproach to MBT uses LLMs to automatically build rich models of intended\nprotocol behavior from knowledge embedded in RFCs, blogs, and other natural\nlanguage sources. Our approach addresses key challenges with using LLMs,\nincluding hallucinations and their inability to monolithically generate complex\nprotocol models. We realize our approach through a novel protocol testing\nframework Eywa,and demonstrate its effectiveness through extensive case studies\nof DNS and BGP and a smaller study of SMTP. Despite minimal user effort,\napplying Eywa enabled the discovery of 32 unique bugs across widely used DNS,\nBGP, and SMTP implementations, 15 of which were previously undiscovered despite\nextensive prior testing with manually crafted models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2312.06875v2", "cate": "cs.NI", "date": "2023-12-11", "updated": "2025-07-16", "AI": {"title_translation": "Eywa: 使用大型语言模型自动化基于模型的测试", "tldr": "Eywa利用LLM自动从自然语言源构建协议模型进行基于模型的测试，并在DNS、BGP和SMTP中发现了32个bug，其中15个是新发现的，显著提高了测试效率和bug发现能力。", "motivation": "传统基于模型的测试（MBT）需要用户详细理解协议RFC才能创建合规模型，这是一个主要障碍，限制了MBT的广泛应用。", "method": "该论文提出一种新的MBT方法，利用大型语言模型（LLMs）从RFC、博客和其他自然语言源中自动构建预期的协议行为模型。该方法解决了LLMs在模型构建中可能出现的幻觉和无法整体生成复杂模型的问题。通过名为Eywa的新颖协议测试框架实现了这一方法。", "result": "通过对DNS和BGP的广泛案例研究以及对SMTP的较小研究，Eywa在用户投入极少的情况下，发现了32个独特的bug，这些bug存在于广泛使用的DNS、BGP和SMTP实现中，其中15个是以前未被发现的，即使在之前已通过手动模型进行广泛测试的情况下。", "conclusion": "Eywa通过利用LLM自动化协议模型的构建，显著降低了基于模型测试的门槛并提高了测试效率，能够发现传统手动测试难以发现的新bug，证明了其在协议测试领域的强大有效性。", "translation": "基于模型的测试（MBT）通过分析待测系统的模型来生成高覆盖率的测试用例，已被用于测试协议实现。使用MBT的一个主要障碍是用户需要详细理解协议RFC才能创建合规模型。我们新的MBT方法使用大型语言模型（LLMs）从RFC、博客和其他自然语言源中嵌入的知识自动构建预期的协议行为的丰富模型。我们的方法解决了使用LLMs的关键挑战，包括幻觉以及它们无法整体生成复杂协议模型的问题。我们通过一个新颖的协议测试框架Eywa实现了我们的方法，并通过对DNS和BGP的广泛案例研究以及对SMTP的较小研究证明了其有效性。尽管用户投入极少，应用Eywa使得在广泛使用的DNS、BGP和SMTP实现中发现了32个独特的错误，其中15个是以前未被发现的，尽管之前已经通过手动制作的模型进行了广泛测试。", "summary": "Eywa是一个创新的基于模型的测试框架，它利用大型语言模型（LLMs）自动从自然语言源（如RFCs、博客）构建复杂的协议行为模型，从而克服了传统MBT中手动模型构建的障碍。该框架有效解决了LLMs的局限性（如幻觉和整体生成能力），并通过对DNS、BGP和SMTP的广泛测试，成功发现了32个独特的bug，其中15个是此前未知的，证明了其在自动化测试和提高bug发现效率方面的显著能力。", "keywords": "基于模型的测试, 大型语言模型, 协议测试, 自动化, Bug发现", "comments": "这篇论文通过引入LLMs来自动化基于模型的测试中的模型构建过程，解决了该领域的一个关键痛点，即手动创建模型的复杂性和耗时性。其创新之处在于利用LLMs处理自然语言协议描述，并特别指出克服了LLMs在生成复杂模型时的挑战（如幻觉和整体性问题）。Eywa在实际协议（DNS、BGP、SMTP）中发现大量新bug的成果，突显了其在提高协议测试效率和深度方面的巨大潜力，对于提升网络协议的健壮性具有重要意义。"}}
{"id": "2507.11994", "title": "SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation", "authors": ["Jun Yin", "Fei Wu", "Yupeng Ren", "Jisheng Huang", "Qiankun Li", "Heng jin", "Jianhai Fu", "Chanjie Cui"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      IGARSS2025 accepted, Correspondence: fujianhai2024@gmail.com (J.F.), cuichj@mail2. this http URL (C.C.)", "url": "http://arxiv.org/abs/2507.11994v1", "summary": "Public remote sensing datasets often face limitations in universality due to\nresolution variability and inconsistent land cover category definitions. To\nharness the vast pool of unlabeled remote sensing data, we propose SAMST, a\nsemi-supervised semantic segmentation method. SAMST leverages the strengths of\nthe Segment Anything Model (SAM) in zero-shot generalization and boundary\ndetection. SAMST iteratively refines pseudo-labels through two main components:\nsupervised model self-training using both labeled and pseudo-labeled data, and\na SAM-based Pseudo-label Refiner. The Pseudo-label Refiner comprises three\nmodules: a Threshold Filter Module for preprocessing, a Prompt Generation\nModule for extracting connected regions and generating prompts for SAM, and a\nLabel Refinement Module for final label stitching. By integrating the\ngeneralization power of large models with the training efficiency of small\nmodels, SAMST improves pseudo-label accuracy, thereby enhancing overall model\nperformance. Experiments on the Potsdam dataset validate the effectiveness and\nfeasibility of SAMST, demonstrating its potential to address the challenges\nposed by limited labeled data in remote sensing semantic segmentation.", "comment": "IGARSS2025 accepted, Correspondence: fujianhai2024@gmail.com (J.F.),\n  cuichj@mail2.sysu.edu.cn (C.C.)", "pdf_url": "http://arxiv.org/pdf/2507.11994v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "SAMST：一种基于SAM伪标签过滤的Transformer遥感半监督语义分割框架", "tldr": "SAMST利用SAM改进伪标签，实现遥感图像的半监督语义分割，有效解决标注数据不足的问题。", "motivation": "公共遥感数据集因分辨率变化和土地覆盖类别定义不一致而面临通用性限制，且大量遥感数据未被标注。为了利用这些未标注数据，本文旨在开发一种半监督语义分割方法。", "method": "SAMST是一种半监督语义分割方法，通过迭代细化伪标签。它包含两个主要组件：使用标注数据和伪标注数据进行监督模型自训练，以及一个基于SAM的伪标签细化器。伪标签细化器由阈值过滤器模块、提示生成模块和标签细化模块组成，用于预处理、提取连接区域并为SAM生成提示，以及最终的标签拼接。", "result": "在Potsdam数据集上的实验验证了SAMST的有效性和可行性，证明了其在解决遥感语义分割中有限标注数据挑战的潜力。", "conclusion": "SAMST通过结合大型模型的泛化能力和小型模型的训练效率，提高了伪标签的准确性，从而增强了整体模型性能，有效解决了遥感语义分割中标注数据有限的问题。", "translation": "公共遥感数据集常因分辨率变化和土地覆盖类别定义不一致而面临通用性限制。为了利用大量的未标注遥感数据，我们提出了SAMST，一种半监督语义分割方法。SAMST利用Segment Anything Model (SAM) 在零样本泛化和边界检测方面的优势。SAMST通过两个主要组件迭代细化伪标签：使用标注和伪标注数据进行监督模型自训练，以及一个基于SAM的伪标签细化器。伪标签细化器包含三个模块：用于预处理的阈值过滤器模块，用于提取连接区域并为SAM生成提示的提示生成模块，以及用于最终标签拼接的标签细化模块。通过整合大型模型的泛化能力和小型模型的训练效率，SAMST提高了伪标签准确性，从而增强了整体模型性能。在Potsdam数据集上的实验验证了SAMST的有效性和可行性，证明了其解决遥感语义分割中有限标注数据挑战的潜力。", "summary": "SAMST是一种用于遥感图像半监督语义分割的新型Transformer框架。该方法旨在解决标注数据不足的问题，通过结合监督模型自训练和基于SAM的伪标签细化器来迭代优化伪标签。伪标签细化器利用SAM的零样本泛化和边界检测能力，通过阈值过滤、提示生成和标签拼接模块提高伪标签的准确性。实验证明SAMST在处理有限标注数据方面有效且可行。", "keywords": "遥感, 半监督语义分割, SAM, 伪标签过滤, Transformer", "comments": "该论文的创新点在于将Segment Anything Model (SAM) 集成到半监督学习框架中，用于遥感图像的伪标签精炼。这种方法有效地利用了SAM强大的零样本泛化能力和边界检测能力，弥补了传统半监督方法中伪标签质量的不足，从而提高了模型性能，对于解决遥感领域标注数据稀缺的挑战具有重要意义。"}}
{"id": "2507.12318", "title": "Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models", "authors": ["Samuel Lavoie", "Michael Noukhovitch", "Aaron Courville"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      In submission, 22 pages, 7 tables, 12 figures", "url": "http://arxiv.org/abs/2507.12318v1", "summary": "We argue that diffusion models' success in modeling complex distributions is,\nfor the most part, coming from their input conditioning. This paper\ninvestigates the representation used to condition diffusion models from the\nperspective that ideal representations should improve sample fidelity, be easy\nto generate, and be compositional to allow out-of-training samples generation.\nWe introduce Discrete Latent Code (DLC), an image representation derived from\nSimplicial Embeddings trained with a self-supervised learning objective. DLCs\nare sequences of discrete tokens, as opposed to the standard continuous image\nembeddings. They are easy to generate and their compositionality enables\nsampling of novel images beyond the training distribution. Diffusion models\ntrained with DLCs have improved generation fidelity, establishing a new\nstate-of-the-art for unconditional image generation on ImageNet. Additionally,\nwe show that composing DLCs allows the image generator to produce\nout-of-distribution samples that coherently combine the semantics of images in\ndiverse ways. Finally, we showcase how DLCs can enable text-to-image generation\nby leveraging large-scale pretrained language models. We efficiently finetune a\ntext diffusion language model to generate DLCs that produce novel samples\noutside of the image generator training distribution.", "comment": "In submission, 22 pages, 7 tables, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.12318v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "用于高保真、高效率扩散模型的组合式离散潜在代码", "tldr": "本文引入了离散潜在代码（DLC），一种基于自监督学习的图像表示，它能够提高扩散模型的生成保真度、实现训练外样本生成，并支持文本到图像的生成。", "motivation": "扩散模型在建模复杂分布方面的成功主要来源于其输入条件。本文从理想表示应能提高样本保真度、易于生成且具有组合性以允许生成训练外样本的角度，研究了用于条件化扩散模型的表示。", "method": "本文引入了离散潜在代码（DLC），这是一种从通过自监督学习目标训练的单纯形嵌入中导出的图像表示。DLC是离散标记序列，与标准的连续图像嵌入不同。", "result": "使用DLC训练的扩散模型提高了生成保真度，在ImageNet上的无条件图像生成方面建立了新的最先进水平。此外，组合DLC允许图像生成器生成连贯组合图像语义的分布外样本。DLC还能通过利用大规模预训练语言模型实现文本到图像的生成，通过高效微调文本扩散语言模型生成DLC，从而产生图像生成器训练分布之外的新颖样本。", "conclusion": "离散潜在代码（DLC）作为一种新的图像表示，显著提高了扩散模型的生成能力，包括更高的保真度、生成训练外样本的能力以及实现高效的文本到图像生成，证明了其在图像生成领域的巨大潜力。", "translation": "我们认为扩散模型在建模复杂分布方面的成功，在很大程度上来自于它们的输入条件。本文从理想表示应能提高样本保真度、易于生成且具有组合性以允许生成训练外样本的角度，研究了用于条件化扩散模型的表示。我们引入了离散潜在代码（DLC），一种从通过自监督学习目标训练的单纯形嵌入中导出的图像表示。DLC是离散标记序列，与标准的连续图像嵌入不同。它们易于生成，并且其组合性使得能够生成训练分布之外的新颖图像样本。使用DLC训练的扩散模型提高了生成保真度，在ImageNet上的无条件图像生成方面建立了新的最先进水平。此外，我们展示了组合DLC如何允许图像生成器生成连贯组合不同图像语义的分布外样本。最后，我们展示了DLC如何通过利用大规模预训练语言模型实现文本到图像的生成。我们高效地微调了一个文本扩散语言模型以生成DLC，从而产生图像生成器训练分布之外的新颖样本。", "summary": "本文提出了一种名为离散潜在代码（DLC）的新型图像表示，旨在优化扩散模型的输入条件。DLC是离散的、易于生成且具有组合性，能够提高生成样本的保真度，并实现训练外和分布外图像的生成。研究表明，基于DLC训练的扩散模型在无条件图像生成方面达到了新的SOTA，并能通过结合语义生成新颖图像。此外，DLC还能与大型预训练语言模型结合，实现高效的文本到图像生成。", "keywords": "扩散模型, 离散潜在代码, 图像生成, 组合性, 文本到图像", "comments": "该论文的创新点在于提出了离散潜在代码（DLC）作为扩散模型的输入条件表示。DLC的离散性和组合性是关键，它不仅提升了生成图像的保真度，更重要的是实现了传统方法难以达到的训练外和分布外样本生成能力。这对于提高生成模型的泛化性和创造性具有重要意义。此外，DLC与预训练语言模型的结合，也为文本到图像生成提供了新的高效途径。"}}
{"id": "2502.13497", "title": "Towards Geo-Culturally Grounded LLM Generations", "authors": ["Piyawat Lertvittayakumjorn", "David Kinney", "Vinodkumar Prabhakaran", "Donald Martin Jr.", "Sunipa Dev"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025 (main conference)", "url": "http://arxiv.org/abs/2502.13497v4", "summary": "Generative large language models (LLMs) have demonstrated gaps in diverse\ncultural awareness across the globe. We investigate the effect of retrieval\naugmented generation and search-grounding techniques on LLMs' ability to\ndisplay familiarity with various national cultures. Specifically, we compare\nthe performance of standard LLMs, LLMs augmented with retrievals from a bespoke\nknowledge base (i.e., KB grounding), and LLMs augmented with retrievals from a\nweb search (i.e., search grounding) on multiple cultural awareness benchmarks.\nWe find that search grounding significantly improves the LLM performance on\nmultiple-choice benchmarks that test propositional knowledge (e.g., cultural\nnorms, artifacts, and institutions), while KB grounding's effectiveness is\nlimited by inadequate knowledge base coverage and a suboptimal retriever.\nHowever, search grounding also increases the risk of stereotypical judgments by\nlanguage models and fails to improve evaluators' judgments of cultural\nfamiliarity in a human evaluation with adequate statistical power. These\nresults highlight the distinction between propositional cultural knowledge and\nopen-ended cultural fluency when it comes to evaluating LLMs' cultural\nawareness.", "comment": "ACL 2025 (main conference)", "pdf_url": "http://arxiv.org/pdf/2502.13497v4", "cate": "cs.CL", "date": "2025-02-19", "updated": "2025-07-16", "AI": {"title_translation": "迈向地理文化背景下的LLM生成", "tldr": "大型语言模型（LLM）在文化多样性方面存在不足。研究发现，检索增强生成（特别是网络搜索）能显著提高LLM在命题性文化知识方面的表现，但会增加刻板印象的风险，且未能改善人类对文化熟悉度的判断。这揭示了命题性文化知识与开放性文化流利度之间的区别。", "motivation": "生成式大型语言模型（LLM）在全球范围内的文化意识多样性方面表现出不足，因此研究旨在探究检索增强生成和搜索接地技术对LLM展示不同民族文化熟悉度能力的影响。", "method": "研究比较了标准LLM、通过定制知识库（即KB接地）增强的LLM以及通过网络搜索（即搜索接地）增强的LLM在多个文化意识基准测试上的表现，包括测试命题性知识的多项选择题和人类评估。", "result": "搜索接地显著提高了LLM在测试命题性知识（如文化规范、文物和制度）的多项选择题基准上的性能。定制知识库接地（KB接地）的有效性受到知识库覆盖不足和检索器次优的限制。然而，搜索接地也增加了语言模型产生刻板印象判断的风险，并且在具有足够统计效力的人类评估中未能改善评估者对文化熟悉度的判断。", "conclusion": "这些结果强调了在评估LLM文化意识时，命题性文化知识与开放性文化流利度之间的区别。", "translation": "生成式大型语言模型（LLM）在全球范围内的文化意识多样性方面表现出不足。我们调查了检索增强生成和搜索接地技术对LLM展示各种民族文化熟悉度能力的影响。具体来说，我们比较了标准LLM、通过定制知识库（即KB接地）检索增强的LLM，以及通过网络搜索（即搜索接地）检索增强的LLM在多个文化意识基准测试上的表现。我们发现，搜索接地显著提高了LLM在测试命题性知识（例如文化规范、文物和制度）的多项选择题基准上的性能，而定制知识库接地的有效性受到知识库覆盖不足和检索器次优的限制。然而，搜索接地也增加了语言模型产生刻板印象判断的风险，并且在具有足够统计效力的人类评估中未能改善评估者对文化熟悉度的判断。这些结果强调了在评估LLM文化意识时，命题性文化知识与开放性文化流利度之间的区别。", "summary": "生成式大型语言模型（LLM）在文化意识方面存在不足。本研究探讨了检索增强生成（包括定制知识库接地和网络搜索接地）如何影响LLM对不同民族文化的熟悉度。结果显示，网络搜索接地能显著提升LLM在命题性文化知识（如文化规范）上的表现，但同时增加了产生刻板印象的风险，且在人类评估中未能提高对文化流利度的感知。这揭示了LLM文化意识中命题性知识与开放性流利度之间的关键区别。", "keywords": "LLM, 文化意识, 检索增强生成, 搜索接地, 刻板印象", "comments": "这篇论文深入探讨了LLM在文化意识方面的核心挑战。其创新之处在于明确区分了“命题性文化知识”与“开放性文化流利度”这两个概念，并指出通过检索增强（特别是网络搜索）虽然能提高前者，但却可能加剧刻板印象并无法有效提升后者。这表明，简单地增加数据或信息检索并不能使LLM真正具备细致入微的文化理解能力，为未来LLM的文化对齐研究提供了重要的方向和挑战。"}}
{"id": "2507.08958", "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "authors": ["Xiaowen Zhang", "Zhenyu Bi", "Patrick Lachance", "Xuan Wang", "Tiziana Di Matteo", "Rupert A. C. Croft"], "categories": ["astro-ph.IM", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Instrumentation and Methods for Astrophysics (astro-ph.IM)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures", "url": "http://arxiv.org/abs/2507.08958v2", "summary": "As cosmological simulations and their associated software become increasingly\ncomplex, physicists face the challenge of searching through vast amounts of\nliterature and user manuals to extract simulation parameters from dense\nacademic papers, each using different models and formats. Translating these\nparameters into executable scripts remains a time-consuming and error-prone\nprocess. To improve efficiency in physics research and accelerate the\ncosmological simulation process, we introduce SimAgents, a multi-agent system\ndesigned to automate both parameter configuration from the literature and\npreliminary analysis for cosmology research. SimAgents is powered by\nspecialized LLM agents capable of physics reasoning, simulation software\nvalidation, and tool execution. These agents collaborate through structured\ncommunication, ensuring that extracted parameters are physically meaningful,\ninternally consistent, and software-compliant. We also construct a cosmological\nparameter extraction evaluation dataset by collecting over 40 simulations in\npublished papers from Arxiv and leading journals that cover diverse simulation\ntypes. Experiments on the dataset demonstrate a strong performance of\nSimAgents, highlighting its effectiveness and potential to accelerate\nscientific research for physicists. Our demonstration video is available at:\nhttps://youtu.be/w1zLpm_CaWA. The complete system and dataset are publicly\navailable at https://github.com/xwzhang98/SimAgents.", "comment": "6 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.08958v2", "cate": "astro-ph.IM", "date": "2025-07-11", "updated": "2025-07-15", "AI": {"title_translation": "通过多智能体大型语言模型系统连接文献与宇宙", "tldr": "SimAgents是一个多智能体LLM系统，旨在自动化宇宙学模拟中的参数配置和初步分析，显著提高物理学研究效率。", "motivation": "随着宇宙学模拟及其相关软件日益复杂，物理学家在海量文献和用户手册中搜索并提取模拟参数，然后将其转换为可执行脚本的过程耗时且易错，严重影响研究效率。", "method": "我们引入了SimAgents，一个多智能体系统，由专门的LLM智能体驱动，这些智能体具备物理推理、模拟软件验证和工具执行能力。这些智能体通过结构化通信协作，确保提取的参数在物理上、内部一致性以及软件兼容性方面均有效。我们还构建了一个包含40多个模拟的宇宙学参数提取评估数据集。", "result": "在所构建的数据集上进行的实验表明，SimAgents表现出色，突出了其在加速物理学家科学研究方面的有效性和潜力。", "conclusion": "SimAgents通过自动化宇宙学模拟中的参数配置和初步分析，显著提高了物理学研究的效率，并有望加速科学发现。", "translation": "随着宇宙学模拟及其相关软件变得日益复杂，物理学家面临着在海量文献和用户手册中搜索并从密集的学术论文中提取模拟参数的挑战，每篇论文都使用不同的模型和格式。将这些参数转换为可执行脚本仍然是一个耗时且容易出错的过程。为了提高物理研究效率并加速宇宙学模拟过程，我们引入了SimAgents，一个多智能体系统，旨在自动化文献中的参数配置和宇宙学研究的初步分析。SimAgents由专业的LLM智能体驱动，这些智能体能够进行物理推理、模拟软件验证和工具执行。这些智能体通过结构化通信协作，确保提取的参数在物理上是有意义的、内部一致的且符合软件要求。我们还通过收集来自Arxiv和主要期刊的40多个涵盖不同模拟类型的已发表论文中的模拟，构建了一个宇宙学参数提取评估数据集。在数据集上的实验证明了SimAgents的强大性能，突出了其有效性以及加速物理学家科学研究的潜力。我们的演示视频可在：https://youtu.be/w1zLpm_CaWA 获取。完整的系统和数据集可在 https://github.com/xwzhang98/SimAgents 公开获取。", "summary": "本研究提出SimAgents，一个多智能体大型语言模型系统，旨在解决物理学家在宇宙学模拟中从复杂文献中提取和配置参数的效率低下问题。SimAgents利用具备物理推理、软件验证和工具执行能力的LLM智能体进行协作，自动化参数提取和初步分析。通过构建并评估一个包含多种模拟类型的数据集，实验证明SimAgents能有效提高参数配置的准确性和效率，从而加速宇宙学研究。", "keywords": "多智能体系统,大型语言模型,宇宙学模拟,参数提取,科学研究自动化", "comments": "该论文提出了一种创新性的多智能体LLM系统SimAgents，通过自动化宇宙学模拟中的参数提取和配置，显著提高了物理学研究的效率。其创新点在于结合了物理推理、软件验证和工具执行能力，并通过结构化通信确保参数的准确性和一致性。这项工作对于加速复杂科学领域的发现具有重要意义。"}}
{"id": "2507.12329", "title": "Neural Polar Decoders for Deletion Channels", "authors": ["Ziv Aharoni", "Henry D. Pfister"], "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12329v1", "summary": "This paper introduces a neural polar decoder (NPD) for deletion channels with\na constant deletion rate. Existing polar decoders for deletion channels exhibit\nhigh computational complexity of $O(N^4)$, where $N$ is the block length. This\nlimits the application of polar codes for deletion channels to\nshort-to-moderate block lengths. In this work, we demonstrate that employing\nNPDs for deletion channels can reduce the computational complexity. First, we\nextend the architecture of the NPD to support deletion channels. Specifically,\nthe NPD architecture consists of four neural networks (NNs), each replicating\nfundamental successive cancellation (SC) decoder operations. To support\ndeletion channels, we change the architecture of only one. The computational\ncomplexity of the NPD is $O(AN\\log N)$, where the parameter $A$ represents a\ncomputational budget determined by the user and is independent of the channel.\nWe evaluate the new extended NPD for deletion channels with deletion rates\n$\\delta\\in\\{0.01, 0.1\\}$ and we verify the NPD with the ground truth given by\nthe trellis decoder by Tal et al. We further show that due to the reduced\ncomplexity of the NPD, we are able to incorporate list decoding and further\nimprove performance. We believe that the extended NPD presented here could have\napplications in future technologies like DNA storage.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12329v1", "cate": "cs.IT", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "神经网络极性译码器用于删除信道", "tldr": "本文提出了一种用于删除信道的神经网络极性译码器（NPD），显著降低了现有译码器的高计算复杂度（从O(N^4)降至O(AN log N)），从而扩展了极性码在删除信道中的应用范围，并可进一步结合列表译码提升性能。", "motivation": "现有的删除信道极性译码器计算复杂度高达O(N^4)，严重限制了极性码在删除信道中应用于中等及以上块长度的实际部署。", "method": "本文通过扩展神经网络极性译码器（NPD）的架构来支持删除信道。具体来说，NPD架构由四个神经网络组成，每个网络复制了基本的逐次消除（SC）译码器操作，而为了支持删除信道，仅修改了其中一个神经网络的架构。", "result": "所提出的NPD将计算复杂度从O(N^4)显著降低至O(AN log N)。这种降低的复杂性使得能够结合列表译码进一步提高译码性能。该NPD在删除率为0.01和0.1的删除信道上进行了评估，并与Tal等人提出的网格译码器的真值进行了验证。", "conclusion": "本文提出的扩展神经网络极性译码器（NPD）为删除信道提供了一种低复杂度的极性译码解决方案，在DNA存储等未来技术中具有潜在应用价值。", "translation": "本文介绍了一种用于具有恒定删除率的删除信道的神经网络极性译码器（NPD）。现有的删除信道极性译码器具有O(N^4)的高计算复杂度，其中N是块长度。这限制了极性码在删除信道中应用于短到中等块长度。在这项工作中，我们证明了在删除信道中采用NPD可以降低计算复杂度。首先，我们扩展了NPD的架构以支持删除信道。具体来说，NPD架构由四个神经网络（NN）组成，每个神经网络复制了基本的逐次消除（SC）译码器操作。为了支持删除信道，我们只改变了其中一个的架构。NPD的计算复杂度为O(AN log N)，其中参数A表示由用户确定的计算预算，并且独立于信道。我们评估了针对删除率δ∈{0.01, 0.1}的删除信道的新扩展NPD，并使用Tal等人给出的网格译码器的真实值验证了NPD。我们进一步表明，由于NPD复杂度的降低，我们能够结合列表译码并进一步提高性能。我们相信这里提出的扩展NPD可能在未来的技术中，如DNA存储，具有应用前景。", "summary": "本文提出了一种用于删除信道的神经网络极性译码器（NPD），旨在解决现有极性译码器在删除信道中高计算复杂度（O(N^4)）的问题。通过修改NPD架构中的一个神经网络，实现了计算复杂度的大幅降低至O(AN log N)。这种低复杂度使得可以集成列表译码以进一步提升性能。该NPD已在不同删除率下进行验证，并被认为在DNA存储等未来技术中具有潜在应用。", "keywords": "神经网络极性译码器, 删除信道, 计算复杂度, 极性码, DNA存储", "comments": "本文通过引入神经网络极性译码器（NPD）来解决删除信道中极性译码器计算复杂度过高的问题，具有显著的创新性。将复杂度从O(N^4)降低到O(AN log N)是核心贡献，极大地提升了极性码在删除信道中的实用性。此外，由于复杂度的降低，能够集成列表译码进一步优化性能，展现了该方法的灵活性和高效性。这项工作为未来在DNA存储等对译码效率要求高的领域应用极性码奠定了基础。"}}
{"id": "2507.10559", "title": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research", "authors": ["Shomir Wilson"], "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2507.10559v2", "summary": "Recent developments in large language models (LLMs) have been accompanied by\nrapidly growing public interest in natural language processing (NLP). This\nattention is reflected by major news venues, which sometimes invite NLP\nresearchers to share their knowledge and views with a wide audience.\nRecognizing the opportunities of the present, for both the research field and\nfor individual researchers, this paper shares recommendations for communicating\nwith a general audience about the capabilities and limitations of NLP. These\nrecommendations cover three themes: vague terminology as an obstacle to public\nunderstanding, unreasonable expectations as obstacles to sustainable growth,\nand ethical failures as obstacles to continued support. Published NLP research\nand popular news coverage are cited to illustrate these themes with examples.\nThe recommendations promote effective, transparent communication with the\ngeneral public about NLP, in order to strengthen public understanding and\nencourage support for research.", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2507.10559v2", "cate": "cs.CY", "date": "2025-07-02", "updated": "2025-07-16", "AI": {"title_translation": "自然语言处理走向世界：旨在改善与公众关于自然语言处理研究的对话", "tldr": "鉴于公众对自然语言处理（NLP）日益增长的兴趣，本文为NLP研究人员提供了与公众有效沟通的建议，以解决术语模糊、不切实际的期望和伦理失误等问题。", "motivation": "随着大型语言模型（LLM）的快速发展，公众对自然语言处理（NLP）的兴趣日益增长。为了抓住当前对研究领域和研究人员个人都存在的机遇，需要改善NLP研究人员与公众的沟通方式。", "method": "本文提出了与普通大众沟通NLP能力和局限性的建议，涵盖了三个主题：模糊的术语、不合理的期望和伦理失误。这些主题通过已发表的NLP研究和流行新闻报道中的例子进行阐述。", "result": "本文提供了一系列建议，旨在指导NLP研究人员与公众进行有效、透明的沟通，以增强公众对NLP的理解并鼓励对研究的支持。这些建议聚焦于解决模糊术语、不合理期望和伦理失误等沟通障碍。", "conclusion": "为了增强公众对自然语言处理的理解并鼓励对研究的支持，与普通大众进行有效、透明的沟通至关重要。", "translation": "大型语言模型（LLM）的最新进展伴随着公众对自然语言处理（NLP）日益增长的兴趣。这种关注体现在主要新闻媒体上，它们有时会邀请NLP研究人员向广大受众分享他们的知识和观点。认识到当前对研究领域和个人研究人员都存在的机遇，本文分享了关于如何与普通受众沟通NLP能力和局限性的建议。这些建议涵盖了三个主题：模糊的术语是公众理解的障碍，不合理的期望是可持续增长的障碍，以及伦理失误是持续支持的障碍。文中引用了已发表的NLP研究和流行新闻报道来通过例子说明这些主题。这些建议旨在促进与公众关于NLP的有效、透明沟通，以加强公众理解并鼓励对研究的支持。", "summary": "本文探讨了在大型语言模型（LLM）推动下，公众对自然语言处理（NLP）兴趣日益增长的背景。它为NLP研究人员提供了与普通大众有效沟通的建议，重点解决了三大障碍：模糊术语导致的理解障碍、不切实际的期望阻碍可持续发展，以及伦理失误影响持续支持。文章通过引用已发表的NLP研究和新闻报道中的例子来阐述这些主题，旨在促进透明沟通，以增强公众对NLP的理解和对研究的支持。", "keywords": "自然语言处理, 公众沟通, 大型语言模型, 研究传播, 伦理AI", "comments": "本文及时且重要，它解决了在人工智能日益普及的时代，如何弥合前沿研究与公众认知之间鸿沟的关键问题。其关注实用沟通策略，特别是针对行业术语、过度炒作和伦理担忧等常见陷阱，对改善公众理解至关重要。通过明确识别具体主题的结构化方法，使得这些建议具有很强的可操作性。"}}
{"id": "2507.12380", "title": "Heat Kernel Goes Topological", "authors": ["Maximilian Krahn", "Vikas Garg"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12380v1", "summary": "Topological neural networks have emerged as powerful successors of graph\nneural networks. However, they typically involve higher-order message passing,\nwhich incurs significant computational expense. We circumvent this issue with a\nnovel topological framework that introduces a Laplacian operator on\ncombinatorial complexes (CCs), enabling efficient computation of heat kernels\nthat serve as node descriptors. Our approach captures multiscale information\nand enables permutation-equivariant representations, allowing easy integration\ninto modern transformer-based architectures.\n  Theoretically, the proposed method is maximally expressive because it can\ndistinguish arbitrary non-isomorphic CCs. Empirically, it significantly\noutperforms existing topological methods in terms of computational efficiency.\nBesides demonstrating competitive performance with the state-of-the-art\ndescriptors on standard molecular datasets, it exhibits superior capability in\ndistinguishing complex topological structures and avoiding blind spots on\ntopological benchmarks. Overall, this work advances topological deep learning\nby providing expressive yet scalable representations, thereby opening up\nexciting avenues for molecular classification and property prediction tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12380v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "热核走向拓扑", "tldr": "提出一种基于组合复形上拉普拉斯算子的新型拓扑框架，通过高效计算热核解决了现有拓扑神经网络计算成本高的问题，实现了表达性和可扩展性，并在分子任务上表现出色。", "motivation": "现有的拓扑神经网络通常涉及高阶消息传递，导致显著的计算开销。", "method": "提出一种新的拓扑框架，在组合复形（CCs）上引入拉普拉斯算子，从而能够高效计算作为节点描述符的热核。该方法能捕获多尺度信息并实现置换等变表示，易于集成到现代基于Transformer的架构中。", "result": "理论上，所提方法具有最大表达能力，可以区分任意非同构的组合复形。经验上，它在计算效率上显著优于现有拓扑方法。在标准分子数据集上，它与最先进的描述符表现出有竞争力的性能，并在区分复杂拓扑结构和避免拓扑基准测试中的盲点方面表现出卓越的能力。", "conclusion": "这项工作通过提供表达性强且可扩展的表示，推动了拓扑深度学习的发展，为分子分类和性质预测任务开辟了新的途径。", "translation": "拓扑神经网络已成为图神经网络的强大继承者。然而，它们通常涉及高阶消息传递，这会带来显著的计算开销。我们通过一种新颖的拓扑框架规避了这个问题，该框架在组合复形（CCs）上引入了拉普拉斯算子，从而能够高效计算作为节点描述符的热核。我们的方法捕获多尺度信息并实现了置换等变表示，从而易于集成到现代基于Transformer的架构中。理论上，所提出的方法具有最大的表达能力，因为它能够区分任意非同构的组合复形。经验上，它在计算效率方面显著优于现有拓扑方法。除了在标准分子数据集上展示出与最先进描述符有竞争力的性能外，它还在区分复杂拓扑结构和避免拓扑基准测试中的盲点方面表现出卓越的能力。总的来说，这项工作通过提供表达性强但可扩展的表示，推动了拓扑深度学习的发展，从而为分子分类和性质预测任务开辟了激动人心的途径。", "summary": "本文提出一种新颖的拓扑框架，通过在组合复形上引入拉普拉斯算子，实现了热核的高效计算，解决了现有拓扑神经网络计算成本高的问题。该方法不仅理论上具有最大表达能力，能区分任意非同构组合复形，而且在计算效率上显著优于现有方法。在分子数据集上，它表现出与SOTA相当的性能，并在处理复杂拓扑结构和避免盲点方面展现出优越性。这项工作为拓扑深度学习提供了高效且表达力强的表示，对分子任务具有重要意义。", "keywords": "拓扑神经网络, 热核, 组合复形, 拉普拉斯算子, 计算效率", "comments": "这项工作创新性地将热核的概念引入到拓扑神经网络中，通过构建组合复形上的拉普拉斯算子，有效解决了传统拓扑神经网络计算成本高昂的问题。其方法不仅理论上保证了最大表达能力，能够区分复杂的拓扑结构，而且在实际应用中展现出卓越的计算效率和性能，为分子分类和性质预测等任务提供了强大的新工具，具有重要的应用前景和理论价值。"}}
{"id": "2411.10438", "title": "MARS: Unleashing the Power of Variance Reduction for Training Large Models", "authors": ["Huizhuo Yuan", "Yifeng Liu", "Shuang Wu", "Xun Zhou", "Quanquan Gu"], "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      35 pages, 19 figures, 12 tables", "url": "http://arxiv.org/abs/2411.10438v3", "summary": "Training deep neural networks--and more recently, large models demands\nefficient and scalable optimizers. Adaptive gradient algorithms like Adam,\nAdamW, and their variants have been central to this task. Despite the\ndevelopment of numerous variance reduction algorithms in the past decade aimed\nat accelerating stochastic optimization in both convex and nonconvex settings,\nvariance reduction has not found widespread success in training deep neural\nnetworks or large language models. Consequently, it has remained a less favored\napproach in modern AI. In this paper, to unleash the power of variance\nreduction for efficient training of large models, we propose a unified\noptimization framework, MARS (Make vAriance Reduction Shine), which reconciles\npreconditioned gradient methods with variance reduction via a scaled stochastic\nrecursive momentum technique. Within our framework, we introduce three\ninstances of MARS that leverage preconditioned gradient updates based on AdamW,\nLion, and Shampoo, respectively. We also draw a connection between our\nalgorithms and existing optimizers. Experimental results on training GPT-2\nmodels indicate that MARS consistently outperforms AdamW by a large margin. The\nimplementation of MARS is available at https://github.com/AGI-Arena/MARS.", "comment": "35 pages, 19 figures, 12 tables", "pdf_url": "http://arxiv.org/pdf/2411.10438v3", "cate": "cs.LG", "date": "2024-11-15", "updated": "2025-07-16", "AI": {"title_translation": "MARS：释放方差削减在训练大型模型中的力量", "tldr": "MARS 是一种新的优化框架，通过结合预处理梯度方法和方差削减，显著提升了大型模型（如 GPT-2）的训练效率，优于 AdamW。", "motivation": "现有的方差削减算法在深度神经网络和大型语言模型训练中应用不广，未能发挥其潜力，而大型模型训练需要高效可扩展的优化器。", "method": "本文提出了一个统一的优化框架 MARS (Make vAriance Reduction Shine)，它通过缩放的随机递归动量技术将预处理梯度方法与方差削减相结合。该框架引入了 MARS 的三个实例，分别基于 AdamW、Lion 和 Shampoo 的预处理梯度更新。", "result": "在训练 GPT-2 模型上的实验结果表明，MARS 持续大幅优于 AdamW。", "conclusion": "MARS 成功地将方差削减应用于大型模型的训练，并显著提高了效率，证明了其潜力。", "translation": "训练深度神经网络——以及最近的大型模型——需要高效和可扩展的优化器。Adam、AdamW及其变体等自适应梯度算法一直是这项任务的核心。尽管在过去十年中开发了许多旨在加速凸和非凸设置下随机优化的方差削减算法，但方差削减在训练深度神经网络或大型语言模型方面尚未获得广泛成功。因此，它在现代AI中仍然是一种不太受青睐的方法。在本文中，为了释放方差削减在高效训练大型模型方面的力量，我们提出了一个统一的优化框架 MARS（Make vAriance Reduction Shine），它通过缩放的随机递归动量技术将预处理梯度方法与方差削减相结合。在我们的框架内，我们引入了 MARS 的三个实例，它们分别利用基于 AdamW、Lion 和 Shampoo 的预处理梯度更新。我们还建立了我们的算法与现有优化器之间的联系。在训练 GPT-2 模型上的实验结果表明，MARS 持续大幅优于 AdamW。MARS 的实现可在 https://github.com/AGI-Arena/MARS 获取。", "summary": "本文提出了 MARS (Make vAriance Reduction Shine)，一个统一的优化框架，旨在将方差削减技术应用于大型模型的训练中。MARS 通过结合预处理梯度方法和缩放的随机递归动量技术，克服了现有方差削减算法在深度学习领域应用不广的局限性。实验证明，MARS 在训练 GPT-2 模型时显著优于 AdamW，展现了方差削减在大型模型优化中的巨大潜力。", "keywords": "方差削减, 大型模型训练, 优化器, MARS, 深度神经网络", "comments": "这篇论文的创新点在于成功地将方差削减这一在凸/非凸优化中表现良好的技术引入到大型深度学习模型的训练中，并通过一个统一的框架 MARS 实现了与现有高效优化器（如 AdamW、Lion、Shampoo）的结合。其重要性在于为大型模型训练提供了一种新的、更高效的优化范式，有望突破传统自适应梯度算法的瓶颈，提升训练速度和稳定性。"}}
{"id": "2507.11920", "title": "Hybrid Conformal Prediction-based Risk-Aware Model Predictive Planning in Dense, Uncertain Environments", "authors": ["Jeongyong Yang", "KwangBin Lee", "SooJean Han"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11920v1", "summary": "Real-time path planning in dense, uncertain environments remains a\nchallenging problem, as predicting the future motions of numerous dynamic\nobstacles is computationally burdensome and unrealistic. To address this, we\nintroduce Hybrid Prediction-based Risk-Aware Planning (HyPRAP), a\nprediction-based risk-aware path-planning framework which uses a hybrid\ncombination of models to predict local obstacle movement. HyPRAP uses a novel\nPrediction-based Collision Risk Index (P-CRI) to evaluate the risk posed by\neach obstacle, enabling the selective use of predictors based on whether the\nagent prioritizes high predictive accuracy or low computational prediction\noverhead. This selective routing enables the agent to focus on high-risk\nobstacles while ignoring or simplifying low-risk ones, making it suitable for\nenvironments with a large number of obstacles. Moreover, HyPRAP incorporates\nuncertainty quantification through hybrid conformal prediction by deriving\nconfidence bounds simultaneously achieved by multiple predictions across\ndifferent models. Theoretical analysis demonstrates that HyPRAP effectively\nbalances safety and computational efficiency by leveraging the diversity of\nprediction models. Extensive simulations validate these insights for more\ngeneral settings, confirming that HyPRAP performs better compared to single\npredictor methods, and P-CRI performs better over naive proximity-based risk\nassessment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11920v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "密集不确定环境下基于混合保形预测的风险感知模型预测规划", "tldr": "HyPRAP是一个新的路径规划框架，通过混合预测模型和风险评估，在密集不确定环境中平衡安全性和计算效率。", "motivation": "在密集不确定环境中进行实时路径规划是一个挑战性问题，因为预测大量动态障碍物的未来运动计算成本高且不切实际。", "method": "本文引入了基于混合预测的风险感知规划（HyPRAP）框架，它使用混合模型来预测局部障碍物运动。HyPRAP采用新颖的基于预测的碰撞风险指数（P-CRI）来评估每个障碍物带来的风险，从而根据代理是优先考虑高预测精度还是低计算预测开销来选择性地使用预测器。此外，HyPRAP通过混合保形预测量化不确定性，从多个模型中同时获得置信区间。", "result": "理论分析表明，HyPRAP通过利用预测模型的多样性，有效地平衡了安全性和计算效率。广泛的模拟验证了这些见解在更一般设置下的有效性，证实HyPRAP比单一预测器方法表现更好，并且P-CRI比基于朴素邻近的风险评估表现更好。", "conclusion": "HyPRAP框架通过结合混合预测模型和风险感知评估，成功解决了密集不确定环境中的实时路径规划挑战，并在安全性和计算效率之间取得了有效平衡。", "translation": "在密集不确定环境中进行实时路径规划仍然是一个具有挑战性的问题，因为预测大量动态障碍物的未来运动计算负担重且不切实际。为了解决这个问题，我们引入了基于混合预测的风险感知规划（HyPRAP），这是一个基于预测的风险感知路径规划框架，它使用模型的混合组合来预测局部障碍物运动。HyPRAP使用一种新颖的基于预测的碰撞风险指数（P-CRI）来评估每个障碍物造成的风险，从而能够根据代理是优先考虑高预测精度还是低计算预测开销来选择性地使用预测器。这种选择性路由使代理能够专注于高风险障碍物，同时忽略或简化低风险障碍物，使其适用于障碍物数量众多的环境。此外，HyPRAP通过混合保形预测量化不确定性，通过从不同模型中同时获得多个预测所实现的置信区间。理论分析表明，HyPRAP通过利用预测模型的多样性，有效地平衡了安全性和计算效率。广泛的模拟验证了这些见解在更一般设置下的有效性，证实HyPRAP比单一预测器方法表现更好，并且P-CRI比基于朴素邻近的风险评估表现更好。", "summary": "本文提出了一种名为HyPRAP的混合预测风险感知规划框架，旨在解决密集不确定环境中的实时路径规划问题。该框架利用混合模型预测局部障碍物运动，并通过新颖的P-CRI评估障碍物风险，实现预测器的选择性使用，以平衡预测精度和计算开销。HyPRAP还通过混合保形预测量化不确定性。理论分析和模拟结果表明，HyPRAP在安全性和计算效率方面优于单一预测器方法，且P-CRI比传统方法更有效。", "keywords": "路径规划, 风险感知, 混合预测, 保形预测, 障碍物规避", "comments": "HyPRAP的创新之处在于其混合预测模型和选择性使用预测器的策略，以及引入P-CRI来有效评估风险。这种方法在处理大量动态障碍物时，能够有效平衡计算效率和规划安全性，对于自动驾驶和机器人导航等领域具有重要意义。混合保形预测的使用也增强了不确定性量化的能力。"}}
{"id": "2507.12418", "title": "High-Performance Pipelined NTT Accelerators with Homogeneous Digit-Serial Modulo Arithmetic", "authors": ["George Alexakis", "Dimitrios Schoinianakis", "Giorgos Dimitrakopoulos"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      28th Euromicro Conference Series on Digital System Design (DSD 2025)", "url": "http://arxiv.org/abs/2507.12418v1", "summary": "The Number Theoretic Transform (NTT) is a fundamental operation in\nprivacy-preserving technologies, particularly within fully homomorphic\nencryption (FHE). The efficiency of NTT computation directly impacts the\noverall performance of FHE, making hardware acceleration a critical technology\nthat will enable realistic FHE applications. Custom accelerators, in FPGAs or\nASICs, offer significant performance advantages due to their ability to exploit\nmassive parallelism and specialized optimizations. However, the operation of\nNTT over large moduli requires large word-length modulo arithmetic that limits\nachievable clock frequencies in hardware and increases hardware area costs. To\novercome such deficits, digit-serial arithmetic has been explored for modular\nmultiplication and addition independently. The goal of this work is to leverage\ndigit-serial modulo arithmetic combined with appropriate redundant data\nrepresentation to design modular pipelined NTT accelerators that operate\nuniformly on arbitrary small digits, without the need for intermediate\n(de)serialization. The proposed architecture enables high clock frequencies\nthrough regular pipelining while maintaining parallelism. Experimental results\ndemonstrate that the proposed approach outperforms state-of-the-art\nimplementations and reduces hardware complexity under equal performance and\ninput-output bandwidth constraints.", "comment": "28th Euromicro Conference Series on Digital System Design (DSD 2025)", "pdf_url": "http://arxiv.org/pdf/2507.12418v1", "cate": "cs.AR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "采用同构数字串行模运算的高性能流水线NTT加速器", "tldr": "本文提出了一种结合数字串行模运算和冗余数据表示的流水线NTT加速器，以克服传统大模数运算的频率和面积限制，实现了高性能和低硬件复杂度的NTT计算。", "motivation": "数论变换（NTT）是隐私保护技术（特别是全同态加密FHE）中的基本操作。NTT计算效率直接影响FHE的整体性能，因此硬件加速是实现实际FHE应用的关键技术。然而，在大模数上进行NTT操作需要长字长模运算，这限制了硬件中可实现的频率并增加了硬件面积成本。", "method": "本文利用数字串行模运算结合适当的冗余数据表示来设计模块化流水线NTT加速器。该加速器能够均匀地对任意小数字进行操作，无需中间（反）序列化。所提出的架构通过常规流水线实现了高时钟频率，同时保持了并行性。", "result": "实验结果表明，所提出的方法在同等性能和输入输出带宽约束下，优于最先进的实现，并降低了硬件复杂度。", "conclusion": "该工作成功设计了一种高性能流水线NTT加速器，通过采用同构数字串行模运算和冗余数据表示，克服了传统大模数NTT实现的频率和面积限制，为FHE等隐私保护技术提供了高效的硬件支持。", "translation": "数论变换（NTT）是隐私保护技术，特别是全同态加密（FHE）中的基本操作。NTT计算的效率直接影响FHE的整体性能，使得硬件加速成为实现实际FHE应用的关键技术。定制加速器，无论是FPGA还是ASIC，由于能够利用大规模并行性和专业优化，提供了显著的性能优势。然而，在大模数上进行NTT操作需要大字长模运算，这限制了硬件中可实现的运行时钟频率并增加了硬件面积成本。为了克服这些缺陷，数字串行算术已被独立地探索用于模乘法和模加法。这项工作的目标是利用数字串行模算术结合适当的冗余数据表示来设计模块化流水线NTT加速器，这些加速器能够均匀地对任意小数字进行操作，而无需中间（反）序列化。所提出的架构通过常规流水线实现了高时钟频率，同时保持了并行性。实验结果表明，所提出的方法在同等性能和输入输出带宽约束下，优于最先进的实现，并降低了硬件复杂度。", "summary": "本文提出了一种创新的高性能流水线数论变换（NTT）加速器架构，旨在解决全同态加密（FHE）中大模数NTT运算的频率和面积限制问题。通过结合同构数字串行模运算和冗余数据表示，该加速器实现了高时钟频率和并行处理，无需复杂的中间数据转换。实验证明，与现有技术相比，该方法在相同性能和带宽条件下，不仅性能更优，而且显著降低了硬件复杂度，为FHE等隐私保护技术的实际应用提供了高效的硬件支持。", "keywords": "NTT加速器, 数字串行, 模运算, 流水线, 全同态加密", "comments": "这篇论文的创新点在于将数字串行模运算与冗余数据表示相结合，设计出一种能够均匀处理小数字的流水线NTT加速器。这种方法有效克服了传统大模数NTT在硬件实现上的频率限制和面积成本问题，对于推动全同态加密等隐私保护技术的实际应用具有重要意义。其提出的架构在保持并行性的同时提高了时钟频率，并被证明优于现有技术，显示出其在硬件加速领域的潜力。"}}
{"id": "2507.11872", "title": "Algorithm Design and Comparative Test of Natural Gradient Gaussian Approximation Filter", "authors": ["Wenhan Cao", "Tianyi Zhang", "Shengbo Eben Li"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11872v1", "summary": "Popular Bayes filters typically rely on linearization techniques such as\nTaylor series expansion and stochastic linear regression to use the structure\nof standard Kalman filter. These techniques may introduce large estimation\nerrors in nonlinear and non-Gaussian systems. This paper overviews a recent\nbreakthrough in filtering algorithm design called \\textit{N}atural\nGr\\textit{a}dient Gaussia\\textit{n} Appr\\textit{o}ximation (NANO) filter and\ncompare its performance over a large class of nonlinear filters. The NANO\nfilter interprets Bayesian filtering as solutions to two distinct optimization\nproblems, which allows to define optimal Gaussian approximation and derive its\ncorresponding extremum conditions. The algorithm design still follows the\ntwo-step structure of Bayes filters. In the prediction step, NANO filter\ncalculates the first two moments of the prior distribution, and this process is\nequivalent to a moment-matching filter. In the update step, natural gradient\ndescent is employed to directly minimize the objective of the update step,\nthereby avoiding errors caused by model linearization. Comparative tests are\nconducted on four classic systems, including the damped linear oscillator,\nsequence forecasting, modified growth model, and robot localization, under\nGaussian, Laplace, and Beta noise to evaluate the NANO filter's capability in\nhandling nonlinearity. Additionally, we validate the NANO filter's robustness\nto data outliers using a satellite attitude estimation example. It is observed\nthat the NANO filter outperforms popular Kalman filters family such as extended\nKalman filter (EKF), unscented Kalman filter (UKF), iterated extended Kalman\nfilter (IEKF) and posterior linearization filter (PLF), while having similar\ncomputational burden.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11872v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "自然梯度高斯近似滤波器的算法设计与比较测试", "tldr": "本文介绍了NANO滤波器，它通过使用自然梯度下降来避免贝叶斯滤波中非线性/非高斯系统的线性化误差，与卡尔曼滤波器相比，在相似的计算成本下表现出更好的性能。", "motivation": "流行的贝叶斯滤波器依赖于线性化技术，这在非线性非高斯系统中可能引入大的估计误差。本文旨在解决这一问题。", "method": "本文概述了自然梯度高斯近似（NANO）滤波器。它将贝叶斯滤波解释为两个优化问题的解决方案，定义了最优高斯近似并推导了极值条件。算法遵循贝叶斯滤波的两步结构：预测步骤计算先验分布的前两个矩（等效于矩匹配滤波器）；更新步骤采用自然梯度下降法直接最小化目标，避免模型线性化误差。在阻尼线性振子、序列预测、改进生长模型和机器人定位四个经典系统上，在高斯、拉普拉斯和Beta噪声下进行了比较测试，并使用卫星姿态估计示例验证了对数据异常值的鲁棒性。", "result": "NANO滤波器优于流行的卡尔曼滤波器家族（如EKF、UKF、IEKF和PLF），同时计算负担相似。", "conclusion": "NANO滤波器为非线性非高斯系统提供了一种优于传统卡尔曼滤波器的方法，它通过自然梯度下降方法避免了线性化误差，表现出更好的性能且计算成本相当。", "translation": "流行的贝叶斯滤波器通常依赖于泰勒级数展开和随机线性回归等线性化技术来利用标准卡尔曼滤波器的结构。这些技术可能在非线性和非高斯系统中引入较大的估计误差。本文概述了一种最近在滤波算法设计方面的突破，称为自然梯度高斯近似（NANO）滤波器，并将其性能与大量非线性滤波器进行了比较。NANO滤波器将贝叶斯滤波解释为两个不同优化问题的解决方案，这使得能够定义最优高斯近似并推导出其相应的极值条件。该算法设计仍然遵循贝叶斯滤波器的两步结构。在预测步骤中，NANO滤波器计算先验分布的前两个矩，此过程等效于矩匹配滤波器。在更新步骤中，采用自然梯度下降法直接最小化更新步骤的目标，从而避免了模型线性化引起的误差。在阻尼线性振子、序列预测、改进生长模型和机器人定位这四个经典系统上，在高斯、拉普拉斯和Beta噪声下进行了比较测试，以评估NANO滤波器处理非线性的能力。此外，我们还使用卫星姿态估计示例验证了NANO滤波器对数据异常值的鲁棒性。结果表明，NANO滤波器优于流行的卡尔曼滤波器家族，如扩展卡尔曼滤波器（EKF）、无迹卡尔曼滤波器（UKF）、迭代扩展卡尔曼滤波器（IEKF）和后验线性化滤波器（PLF），同时计算负担相似。", "summary": "本文介绍了一种名为自然梯度高斯近似（NANO）滤波器的新型贝叶斯滤波方法，旨在解决传统基于线性化的卡尔曼滤波器在非线性非高斯系统中的局限性。NANO滤波器将贝叶斯滤波重新解释为两个优化问题，在预测步骤中使用矩匹配，在更新步骤中采用自然梯度下降法直接最小化目标，从而避免了线性化误差。通过在各种非线性系统和不同噪声类型下的比较测试，结果表明NANO滤波器在精度上优于常见的卡尔曼滤波器（EKF、UKF、IEKF、PLF），同时保持了相似的计算效率和对异常值的鲁棒性。", "keywords": "自然梯度高斯近似滤波器, NANO滤波器, 贝叶斯滤波, 非线性系统, 卡尔曼滤波器", "comments": "该论文的创新之处在于利用自然梯度下降法直接优化更新步骤，从而避免了线性化，而线性化是传统卡尔曼滤波器在非线性系统中常见的误差来源。在各种系统和噪声类型下进行的全面比较测试，以及对异常值鲁棒性的验证，增强了该论文的发现。"}}
{"id": "2507.12201", "title": "RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models", "authors": ["Yiqi Tian", "Pengfei Jin", "Mingze Yuan", "Na Li", "Bo Zeng", "Quanzheng Li"], "categories": ["cs.CV", "math.OC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12201v1", "summary": "Diffusion models have achieved state-of-the-art performance in generative\nmodeling, yet their sampling procedures remain vulnerable to hallucinations,\noften stemming from inaccuracies in score approximation. In this work, we\nreinterpret diffusion sampling through the lens of optimization and introduce\nRODS (Robust Optimization-inspired Diffusion Sampler), a novel method that\ndetects and corrects high-risk sampling steps using geometric cues from the\nloss landscape. RODS enforces smoother sampling trajectories and adaptively\nadjusts perturbations, reducing hallucinations without retraining and at\nminimal additional inference cost. Experiments on AFHQv2, FFHQ, and 11k-hands\ndemonstrate that RODS improves both sampling fidelity and robustness, detecting\nover 70% of hallucinated samples and correcting more than 25%, all while\navoiding the introduction of new artifacts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12201v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "RODS：受鲁棒优化启发的扩散采样，用于检测和减少生成模型中的幻觉", "tldr": "RODS是一种新的扩散采样方法，通过鲁棒优化原理检测和纠正生成模型中的幻觉，无需重新训练，且推理成本极低。", "motivation": "扩散模型在生成建模中表现出色，但其采样过程容易产生幻觉，这通常源于分数近似的不准确性。", "method": "RODS（受鲁棒优化启发的扩散采样器）通过优化视角重新解释扩散采样，并利用损失景观的几何线索检测和纠正高风险采样步骤。它强制执行更平滑的采样轨迹并自适应调整扰动。", "result": "在AFHQv2、FFHQ和11k-hands上的实验表明，RODS提高了采样保真度和鲁棒性，检测出超过70%的幻觉样本并纠正了超过25%，同时避免引入新的伪影。", "conclusion": "RODS通过引入鲁棒优化原理来改进扩散采样，有效地检测和减少了生成模型中的幻觉，提高了模型的保真度和鲁棒性，且成本效益高。", "translation": "扩散模型在生成建模中取得了最先进的性能，但其采样过程仍然容易受到幻觉的影响，这通常源于分数近似的不准确性。在这项工作中，我们通过优化的视角重新解释了扩散采样，并引入了RODS（受鲁棒优化启发的扩散采样器），这是一种利用损失景观的几何线索检测和纠正高风险采样步骤的新方法。RODS强制执行更平滑的采样轨迹并自适应调整扰动，无需重新训练且只需极小的额外推理成本即可减少幻觉。在AFHQv2、FFHQ和11k-hands上的实验表明，RODS提高了采样保真度和鲁棒性，检测出超过70%的幻觉样本并纠正了超过25%，同时避免引入新的伪影。", "summary": "RODS是一种新颖的扩散采样器，它将扩散采样重新解释为优化问题，并通过利用损失景观的几何线索来检测和纠正高风险采样步骤，从而减少生成模型中的幻觉。该方法无需重新训练，且仅需极小的额外推理成本，即可强制执行更平滑的采样轨迹并自适应调整扰动。实验证明，RODS显著提高了采样保真度和鲁棒性，有效检测并纠正了幻觉样本，且不引入新的伪影。", "keywords": "扩散模型, 幻觉, 鲁棒优化, 采样, 生成模型", "comments": "这项工作的创新之处在于将鲁棒优化原理引入到扩散模型的采样过程中，以解决幻觉问题。它提供了一种无需模型重训练的后处理方法，具有较低的推理成本，这对于实际应用非常重要。其通过几何线索检测和纠正高风险采样步骤的机制是其核心亮点。"}}
{"id": "2502.15203", "title": "FlipConcept: Tuning-Free Multi-Concept Personalization for Text-to-Image Generation", "authors": ["Young Beom Woo", "Sun Eung Kim", "Seong-Whan Lee"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE SMC 2025", "url": "http://arxiv.org/abs/2502.15203v2", "summary": "Integrating multiple personalized concepts into a single image has recently\ngained attention in text-to-image (T2I) generation. However, existing methods\noften suffer from performance degradation in complex scenes due to distortions\nin non-personalized regions and the need for additional fine-tuning, limiting\ntheir practicality. To address this issue, we propose FlipConcept, a novel\napproach that seamlessly integrates multiple personalized concepts into a\nsingle image without requiring additional tuning. We introduce guided\nappearance attention to enhance the visual fidelity of personalized concepts.\nAdditionally, we introduce mask-guided noise mixing to protect non-personalized\nregions during concept integration. Lastly, we apply background dilution to\nminimize concept leakage, i.e., the undesired blending of personalized concepts\nwith other objects in the image. In our experiments, we demonstrate that the\nproposed method, despite not requiring tuning, outperforms existing models in\nboth single and multiple personalized concept inference. These results\ndemonstrate the effectiveness and practicality of our approach for scalable,\nhigh-quality multi-concept personalization.", "comment": "Accepted by IEEE SMC 2025", "pdf_url": "http://arxiv.org/pdf/2502.15203v2", "cate": "cs.CV", "date": "2025-02-21", "updated": "2025-07-16", "AI": {"title_translation": "FlipConcept：免调优的文本到图像生成多概念个性化", "tldr": "FlipConcept是一种免调优方法，用于将多个个性化概念无缝集成到文本到图像生成中，通过解决现有方法的性能下降和微调需求，实现了更好的视觉保真度和非个性化区域保护。", "motivation": "现有文本到图像生成的多概念个性化方法在复杂场景中表现不佳，存在非个性化区域失真问题，且需要额外的微调，限制了其实用性。", "method": "本文提出FlipConcept方法，无需额外调优即可集成多概念。该方法引入了引导式外观注意力以增强个性化概念的视觉保真度；引入了掩码引导噪声混合以保护非个性化区域；并应用背景稀释以最小化概念泄漏。", "result": "实验表明，尽管无需调优，所提出的方法在单概念和多概念个性化推理方面均优于现有模型。", "conclusion": "FlipConcept方法证明了其在可扩展、高质量多概念个性化方面的有效性和实用性。", "translation": "将多个个性化概念整合到单一图像中，在文本到图像（T2I）生成领域近期备受关注。然而，现有方法在复杂场景中常因非个性化区域的失真和需要额外的微调而导致性能下降，限制了其实用性。为解决此问题，我们提出了FlipConcept，这是一种无需额外调优即可将多个个性化概念无缝整合到单一图像中的新颖方法。我们引入了引导式外观注意力以增强个性化概念的视觉保真度。此外，我们引入了掩码引导噪声混合以在概念整合过程中保护非个性化区域。最后，我们应用背景稀释以最小化概念泄漏，即个性化概念与图像中其他物体之间不希望出现的混合。在我们的实验中，我们证明了所提出的方法，尽管无需调优，但在单概念和多概念个性化推理方面均优于现有模型。这些结果证明了我们方法在可扩展、高质量多概念个性化方面的有效性和实用性。", "summary": "本文提出FlipConcept，一种针对文本到图像生成的多概念个性化新方法，旨在解决现有方法在复杂场景中的性能下降和对额外微调的需求。FlipConcept通过引入引导式外观注意力、掩码引导噪声混合和背景稀释，实现了无需调优即可无缝集成多个个性化概念，同时增强了视觉保真度、保护了非个性化区域并减少了概念泄漏。实验结果表明，FlipConcept在单概念和多概念推理中均优于现有模型，展现了其在高质量、可扩展多概念个性化方面的有效性和实用性。", "keywords": "文本到图像生成, 多概念个性化, 免调优, 扩散模型, 概念泄漏", "comments": "FlipConcept的创新点在于其“免调优”特性，这显著提升了多概念个性化方法的实用性。通过引入引导式外观注意力、掩码引导噪声混合和背景稀释等机制，该方法有效解决了现有技术中的核心痛点，如非个性化区域失真和概念泄漏。其在无需额外调优的情况下超越现有模型的表现，预示着其在实际应用中具有巨大的潜力，尤其是在需要快速、高质量生成复杂图像的场景。"}}
{"id": "2507.11988", "title": "Aime: Towards Fully-Autonomous Multi-Agent Framework", "authors": ["Yexuan Shi", "Mingyu Wang", "Yunxiang Cao", "Hongjie Lai", "Junjian Lan", "Xin Han", "Yu Wang", "Jie Geng", "Zhenan Li", "Zihao Xia", "Xiang Chen", "Chen Li", "Jian Xu", "Wenbo Duan", "Yuanshuo Zhu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      14 pages, 1 figures,", "url": "http://arxiv.org/abs/2507.11988v1", "summary": "Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are\nemerging as a powerful paradigm for solving complex, multifaceted problems.\nHowever, the potential of these systems is often constrained by the prevalent\nplan-and-execute framework, which suffers from critical limitations: rigid plan\nexecution, static agent capabilities, and inefficient communication. These\nweaknesses hinder their adaptability and robustness in dynamic environments.\nThis paper introduces Aime, a novel multi-agent framework designed to overcome\nthese challenges through dynamic, reactive planning and execution. Aime\nreplaces the conventional static workflow with a fluid and adaptive\narchitecture. Its core innovations include: (1) a Dynamic Planner that\ncontinuously refines the overall strategy based on real-time execution\nfeedback; (2) an Actor Factory that implements Dynamic Actor instantiation,\nassembling specialized agents on-demand with tailored tools and knowledge; and\n(3) a centralized Progress Management Module that serves as a single source of\ntruth for coherent, system-wide state awareness. We empirically evaluated Aime\non a diverse suite of benchmarks spanning general reasoning (GAIA), software\nengineering (SWE-bench Verified), and live web navigation (WebVoyager). The\nresults demonstrate that Aime consistently outperforms even highly specialized\nstate-of-the-art agents in their respective domains. Its superior adaptability\nand task success rate establish Aime as a more resilient and effective\nfoundation for multi-agent collaboration.", "comment": "14 pages, 1 figures,", "pdf_url": "http://arxiv.org/pdf/2507.11988v1", "cate": "cs.AI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Aime: 面向全自主多智能体框架", "tldr": "Aime是一个新的多智能体框架，通过动态规划、按需智能体实例化和集中式状态管理，克服了现有LLM驱动多智能体系统的局限性，在多个基准测试中表现优于现有技术。", "motivation": "现有的由大型语言模型（LLM）驱动的多智能体系统（MAS）受限于普遍的“计划-执行”框架，该框架存在僵硬的计划执行、静态的智能体能力和低效的通信等问题，这些弱点阻碍了它们在动态环境中的适应性和鲁棒性。", "method": "本文引入了Aime，一个新颖的多智能体框架，旨在通过动态、响应式规划和执行来克服现有挑战。其核心创新包括：1）一个动态规划器，根据实时执行反馈持续优化整体策略；2）一个智能体工厂，实现动态智能体实例化，按需组装具有定制工具和知识的专业智能体；3）一个集中式进度管理模块，作为系统范围连贯状态感知的单一真实来源。", "result": "Aime在涵盖通用推理（GAIA）、软件工程（SWE-bench Verified）和实时网络导航（WebVoyager）的各种基准测试中进行了实证评估。结果表明，Aime在各自领域中始终优于甚至高度专业化的最先进智能体。", "conclusion": "Aime卓越的适应性和任务成功率使其成为多智能体协作更具韧性和有效的基础。", "translation": "由大型语言模型（LLM）驱动的多智能体系统（MAS）正在成为解决复杂多方面问题的强大范式。然而，这些系统的潜力往往受到普遍的“计划-执行”框架的限制，该框架存在关键局限性：僵硬的计划执行、静态的智能体能力和低效的通信。这些弱点阻碍了它们在动态环境中的适应性和鲁棒性。本文介绍了Aime，一个新颖的多智能体框架，旨在通过动态、响应式规划和执行来克服这些挑战。Aime用流畅自适应的架构取代了传统的静态工作流。其核心创新包括：(1) 一个动态规划器，根据实时执行反馈持续优化整体策略；(2) 一个智能体工厂，实现动态智能体实例化，按需组装具有定制工具和知识的专业智能体；以及 (3) 一个集中式进度管理模块，作为连贯的系统范围状态感知的单一真实来源。我们对Aime在涵盖通用推理（GAIA）、软件工程（SWE-bench Verified）和实时网络导航（WebVoyager）的各种基准测试上进行了实证评估。结果表明，Aime在各自领域中始终优于甚至高度专业化的最先进智能体。其卓越的适应性和任务成功率使Aime成为多智能体协作更具韧性和有效的基础。", "summary": "Aime是一个新颖的多智能体框架，旨在通过动态规划、按需智能体实例化和集中式状态管理来克服现有基于LLM的多智能体系统的局限性，例如僵硬的执行和静态能力。该框架在通用推理、软件工程和网络导航等多个基准测试中表现出色，其卓越的适应性和任务成功率使其成为更具韧性和有效性的多智能体协作基础。", "keywords": "多智能体系统, 大型语言模型, 动态规划, 智能体框架, 自主性", "comments": "Aime的创新之处在于其动态和响应式架构，特别是动态规划器、智能体工厂和集中式进度管理模块的引入，解决了传统“计划-执行”框架的固有缺陷。这对于提升LLM驱动的多智能体系统在动态和复杂环境中的实用性和鲁棒性具有重要意义。"}}
{"id": "2507.11975", "title": "Online Training and Pruning of Deep Reinforcement Learning Networks", "authors": ["Valentin Frank Ingmar Guenter", "Athanasios Sideris"], "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      25 pages, 5 figures, 4 tables", "url": "http://arxiv.org/abs/2507.11975v1", "summary": "Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms\nhas been shown to enhance performance when feature extraction networks are used\nbut the gained performance comes at the significant expense of increased\ncomputational and memory complexity. Neural network pruning methods have\nsuccessfully addressed this challenge in supervised learning. However, their\napplication to RL is underexplored. We propose an approach to integrate\nsimultaneous training and pruning within advanced RL methods, in particular to\nRL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our\nnetworks (XiNet) are trained to solve stochastic optimization problems over the\nRL networks' weights and the parameters of variational Bernoulli distributions\nfor 0/1 Random Variables $\\xi$ scaling each unit in the networks. The\nstochastic problem formulation induces regularization terms that promote\nconvergence of the variational parameters to 0 when a unit contributes little\nto the performance. In this case, the corresponding structure is rendered\npermanently inactive and pruned from its network. We propose a cost-aware,\nsparsity-promoting regularization scheme, tailored to the DenseNet architecture\nof OFENets expressing the parameter complexity of involved networks in terms of\nthe parameters of the RVs in these networks. Then, when matching this cost with\nthe regularization terms, the many hyperparameters associated with them are\nautomatically selected, effectively combining the RL objectives and network\ncompression. We evaluate our method on continuous control benchmarks (MuJoCo)\nand the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned\nconsiderably with minimal loss in performance. Furthermore, our results confirm\nthat pruning large networks during training produces more efficient and higher\nperforming RL agents rather than training smaller networks from scratch.", "comment": "25 pages, 5 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.11975v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "深度强化学习网络的在线训练与剪枝", "tldr": "提出一种在强化学习中同时进行网络训练和剪枝的方法（XiNet），显著减少计算和内存开销，同时保持或提升性能。", "motivation": "深度强化学习网络在提升性能的同时带来了显著的计算和内存开销。监督学习中的剪枝方法已成功解决此问题，但在强化学习中的应用尚未充分探索。", "method": "提出一种将同时训练和剪枝整合到先进强化学习方法（特别是基于OFENet的算法）中的方法，称为XiNet。XiNet通过解决强化学习网络权重和变分伯努利分布参数上的随机优化问题进行训练。随机问题公式引入了正则化项，当单元对性能贡献较小时，促使变分参数趋于0，从而永久性地使相应结构失效并剪枝。他们还提出了一种成本感知、稀疏性促进的正则化方案，专为OFENet的DenseNet架构定制，该方案能自动选择超参数，有效结合RL目标和网络压缩。", "result": "在连续控制基准（MuJoCo）和Soft Actor-Critic RL代理上的评估表明，OFENet可以大幅剪枝，性能损失极小。此外，在训练过程中剪枝大型网络比从头开始训练小型网络能产生更高效、更高性能的RL代理。", "conclusion": "本文提出了一种在强化学习中同时进行网络训练和剪枝的有效方法，显著降低了计算和内存复杂性，同时保持甚至提升了RL智能体的性能。研究结果表明，通过在训练过程中剪枝大型网络，可以获得比从头训练小型网络更优的RL智能体。", "translation": "深度神经网络（NN）在强化学习（RL）算法中的扩展已被证明在使用特征提取网络时能增强性能，但性能的提升伴随着计算和内存复杂性显著增加的巨大代价。神经网络剪枝方法已成功解决了监督学习中的这一挑战。然而，它们在强化学习中的应用尚未充分探索。我们提出了一种方法，将同步训练和剪枝整合到先进的强化学习方法中，特别是增强了在线特征提取网络（OFENet）的强化学习算法。我们的网络（XiNet）经过训练，旨在解决强化学习网络权重和变分伯努利分布参数上的随机优化问题，这些参数用于缩放网络中每个单元的0/1随机变量$\\xi$。随机问题公式引入了正则化项，当单元对性能贡献很小时，这些项会促进变分参数收敛到0。在这种情况下，相应的结构被永久性地禁用并从网络中剪枝。我们提出了一种成本感知、促进稀疏性的正则化方案，该方案专为OFENet的DenseNet架构量身定制，以网络中随机变量的参数来表达所涉及网络的参数复杂性。然后，当将此成本与正则化项匹配时，与之相关的许多超参数会自动选择，从而有效地结合了强化学习目标和网络压缩。我们在连续控制基准（MuJoCo）和Soft Actor-Critic强化学习代理上评估了我们的方法，结果表明OFENet可以显著剪枝，而性能损失极小。此外，我们的结果证实，在训练过程中剪枝大型网络比从头开始训练小型网络能产生更高效、更高性能的强化学习代理。", "summary": "本文提出了一种在深度强化学习（RL）中同时进行网络训练和剪枝的新方法，称为XiNet，以解决现有RL算法中深度神经网络带来的高计算和内存开销问题。该方法通过引入基于变分伯努利分布的随机变量和成本感知正则化方案，在训练过程中自动识别并移除不重要的网络单元，从而实现网络压缩。在MuJoCo连续控制基准上的实验结果表明，XiNet能够大幅剪枝OFENet而性能损失极小，并且在训练过程中剪枝大型网络比从头训练小型网络能产生更高效、性能更优的RL智能体。", "keywords": "深度强化学习, 神经网络剪枝, 在线训练, 计算效率, 模型压缩", "comments": "本文的创新之处在于将神经网络剪枝技术与强化学习的在线训练过程相结合，有效解决了深度RL网络计算和内存复杂度过高的问题。通过引入随机优化和成本感知正则化方案，实现了在训练过程中自动进行结构性剪枝，这对于提升RL算法的实用性和效率具有重要意义。特别值得关注的是，研究发现训练中剪枝大型网络比从头训练小型网络效果更好，这为未来RL模型设计提供了新的思路。"}}
{"id": "2507.11846", "title": "Directional Measurements and Analysis for FR3 Low-Altitude Channels in a Campus Environment", "authors": ["Yulu Guo", "Tongjia Zhang", "Xiangwen Gu", "Shu Sun", "Meixia Tao", "Ruifeng Gao"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11846v1", "summary": "In this paper, we present detailed low-altitude channel measurements at the\nFR3 band in an outdoor campus environment. Using a time-domain channel sounder\nsystem, we conduct two types of measurements: path loss measurements by moving\nthe transmitter (Tx) at one-meter intervals along a 26-point rooftop path, and\ndirectional power angular spectrum measurements through antenna scanning at\nhalf-power beam width intervals. The path loss analysis across different Rx\nshows that the close-in model outperforms conventional 3GPP models and\nheight-corrected variants, with path loss exponents close to free space values\nindicating line-of-sight dominance. The power angular spectrum measurements\nshow that propagation behavior varies significantly with environmental\nconditions. Closer Rx exhibit stronger sensitivity to ground reflections during\ndownward Tx tilting, while obstructed links display uniform angular\ncharacteristics due to dominant scattering effects, and corridor environments\nproduce asymmetric power distributions. These results indicate that\nlow-altitude propagation is characterized by complex interactions between Tx\nheight and ground scattering mechanisms, providing fundamental insights for\nchannel modeling in emerging mid-band communication systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11846v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "校园环境中FR3低空信道的方向性测量与分析", "tldr": "本文对校园FR3频段低空信道进行了详细测量和分析，发现近距离模型优于传统模型，传播行为随环境变化显著，为中频段通信系统信道建模提供了见解。", "motivation": "为新兴中频段通信系统提供信道建模的基础性见解，因为低空传播具有发射机高度和地面散射机制之间复杂的相互作用。", "method": "使用时域信道探测系统，进行了两种测量：沿26点屋顶路径以一米间隔移动发射机进行路径损耗测量，以及通过天线扫描进行方向性功率角谱测量。", "result": "路径损耗分析显示，近距离模型优于传统3GPP模型和高度校正变体，路径损耗指数接近自由空间值，表明视距传播占主导。功率角谱测量显示传播行为随环境条件显著变化。较近的接收机在发射机向下倾斜时对地面反射表现出更强的敏感性。受阻链路由于主导散射效应表现出均匀的角特性。走廊环境产生不对称的功率分布。", "conclusion": "低空传播的特点是发射机高度和地面散射机制之间存在复杂的相互作用，为新兴中频段通信系统中的信道建模提供了基础性见解。", "translation": "本文介绍了在室外校园环境中FR3频段的详细低空信道测量。使用时域信道探测系统，我们进行了两种类型的测量：通过发射机（Tx）沿26点屋顶路径以一米间隔移动进行的路径损耗测量，以及通过半功率波束宽度间隔的天线扫描进行的方向性功率角谱测量。对不同接收机（Rx）的路径损耗分析表明，近距离模型优于传统的3GPP模型和高度校正变体，其路径损耗指数接近自由空间值，表明视距传播占主导地位。功率角谱测量表明传播行为随环境条件显著变化。较近的接收机在发射机向下倾斜时对地面反射表现出更强的敏感性，而受阻链路由于主导散射效应显示出均匀的角特性，走廊环境产生不对称的功率分布。这些结果表明，低空传播的特点是发射机高度和地面散射机制之间存在复杂的相互作用，为新兴中频段通信系统中的信道建模提供了基础性见解。", "summary": "本文在校园FR3频段进行了详细的低空信道测量与分析。研究采用时域信道探测系统，进行了路径损耗和方向性功率角谱两类测量。结果显示，近距离路径损耗模型优于传统模型，且视距传播占主导。功率角谱测量揭示传播行为受环境显著影响，如近距离接收机对地面反射敏感，受阻链路呈现均匀角特性，走廊环境功率分布不对称。研究强调低空传播中发射机高度与地面散射的复杂相互作用，为中频段通信系统信道建模提供了重要基础。", "keywords": "FR3信道, 低空传播, 路径损耗, 功率角谱, 校园环境", "comments": "这篇论文通过在实际校园环境中对FR3频段低空信道进行详细测量和分析，提供了重要的传播特性见解。其创新之处在于结合了路径损耗和方向性功率角谱测量，并细致分析了不同环境（如视距、受阻和走廊）下的传播行为。研究结果，特别是近距离模型表现优异以及Tx高度与地面散射的复杂相互作用，对未来中频段通信系统的信道建模具有重要指导意义，有助于提高通信系统的性能和可靠性。"}}
{"id": "2504.03205", "title": "BondMatcher: H-Bond Stability Analysis in Molecular Systems", "authors": ["Thomas Daniel", "Malgorzata Olejniczak", "Julien Tierny"], "categories": ["cs.LG", "eess.IV", "physics.chem-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      To appear in IEEE Transactions on Visualization and Computer Graphics (Proc. of IEEE VIS 2025)", "url": "http://arxiv.org/abs/2504.03205v2", "summary": "This application paper investigates the stability of hydrogen bonds\n(H-bonds), as characterized by the Quantum Theory of Atoms in Molecules\n(QTAIM). First, we contribute a database of 4544 electron densities associated\nto four isomers of water hexamers (the so-called Ring, Book, Cage and Prism),\ngenerated by distorting their equilibrium geometry under various structural\nperturbations, modeling the natural dynamic behavior of molecular systems.\nSecond, we present a new stability measure, called bond occurrence rate,\nassociating each bond path present at equilibrium with its rate of occurrence\nwithin the input ensemble. We also provide an algorithm, called BondMatcher,\nfor its automatic computation, based on a tailored, geometry-aware partial\nisomorphism estimation between the extremum graphs of the considered electron\ndensities. Our new stability measure allows for the automatic identification of\ndensities lacking H-bond paths, enabling further visual inspections.\nSpecifically, the topological analysis enabled by our framework corroborates\nexperimental observations and provides refined geometrical criteria for\ncharacterizing the disappearance of H-bond paths. Our electron density database\nand our C++ implementation are available at this address:\nhttps://github.com/thom-dani/BondMatcher.", "comment": "To appear in IEEE Transactions on Visualization and Computer Graphics\n  (Proc. of IEEE VIS 2025)", "pdf_url": "http://arxiv.org/pdf/2504.03205v2", "cate": "cs.LG", "date": "2025-04-04", "updated": "2025-07-16", "AI": {"title_translation": "BondMatcher：分子系统中氢键稳定性分析", "tldr": "该论文引入了BondMatcher，这是一种算法和新的稳定性度量（键发生率），用于利用QTAIM分析分子系统中的氢键稳定性，基于水六聚体电子密度数据库。它有助于识别缺失的氢键路径并细化几何标准。", "motivation": "研究由分子中原子量子理论（QTAIM）表征的氢键（H-键）的稳定性，通过模拟分子系统在结构扰动下的自然动态行为。", "method": "1. 创建了一个包含4544个电子密度的数据集，用于四种水六聚体异构体（环状、书状、笼状和棱柱状），通过扭曲其平衡几何结构生成。2. 提出了一种新的稳定性度量，称为“键发生率”。3. 开发了一种名为“BondMatcher”的算法，用于自动计算键发生率，该算法基于对所考虑电子密度的极值图之间进行量身定制的、几何感知的局部同构估计。", "result": "1. 新的稳定性度量允许自动识别缺乏氢键路径的密度，从而可以进行进一步的视觉检查。2. 拓扑分析证实了实验观察结果。3. 为表征氢键路径的消失提供了更精细的几何标准。", "conclusion": "该框架能够自动识别氢键路径的缺失，并提供精细的几何标准，从而证实了实验观察结果。", "translation": "这篇应用论文研究了分子系统中氢键（H-键）的稳定性，其特征通过分子中原子量子理论（QTAIM）来表征。首先，我们贡献了一个包含4544个电子密度的数据集，这些电子密度与水六聚体（即环状、书状、笼状和棱柱状）的四种异构体相关联，通过在各种结构扰动下扭曲其平衡几何结构生成，以模拟分子系统的自然动态行为。其次，我们提出了一种新的稳定性度量，称为键发生率，将每个在平衡状态下存在的键路径与其在输入集合中的发生率相关联。我们还提供了一种名为BondMatcher的算法，用于其自动计算，该算法基于对所考虑电子密度的极值图之间进行量身定制的、几何感知的局部同构估计。我们的新稳定性度量允许自动识别缺乏氢键路径的密度，从而可以进行进一步的视觉检查。具体而言，我们的框架所支持的拓扑分析证实了实验观察结果，并为表征氢键路径的消失提供了更精细的几何标准。我们的电子密度数据库和我们的C++实现可在以下地址获取：https://github.com/thom-dani/BondMatcher。", "summary": "本文介绍了BondMatcher，这是一种利用分子中原子量子理论（QTAIM）分析分子系统中氢键稳定性的新应用。它引入了一个在结构扰动下水六聚体的电子密度数据库，并提出“键发生率”作为一种新的稳定性度量。BondMatcher算法利用几何感知的局部同构自动计算该发生率，从而能够识别缺失的氢键路径。该框架的拓扑分析证实了实验结果，并为表征氢键消失提供了精细的几何标准。", "keywords": "氢键稳定性, QTAIM, BondMatcher, 电子密度, 水六聚体, 键发生率", "comments": "该论文通过提供一种新的计算工具和一种用于分析氢键动力学的新稳定性度量，做出了有价值的贡献，这对于理解分子行为至关重要。为扰动下的水六聚体创建专门的电子密度数据库也是一项重要资产。自动识别缺失的氢键路径和几何标准的细化是实用的创新。数据库和C++实现的可用性进一步增强了其实用性和可重复性。"}}
{"id": "2507.11862", "title": "Cross-Domain Transfer and Few-Shot Learning for Personal Identifiable Information Recognition", "authors": ["Junhong Ye", "Xu Yuan", "Xinying Qiu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to CLNLP 2025", "url": "http://arxiv.org/abs/2507.11862v1", "summary": "Accurate recognition of personally identifiable information (PII) is central\nto automated text anonymization. This paper investigates the effectiveness of\ncross-domain model transfer, multi-domain data fusion, and sample-efficient\nlearning for PII recognition. Using annotated corpora from healthcare (I2B2),\nlegal (TAB), and biography (Wikipedia), we evaluate models across four\ndimensions: in-domain performance, cross-domain transferability, fusion, and\nfew-shot learning. Results show legal-domain data transfers well to\nbiographical texts, while medical domains resist incoming transfer. Fusion\nbenefits are domain-specific, and high-quality recognition is achievable with\nonly 10% of training data in low-specialization domains.", "comment": "Accepted to CLNLP 2025", "pdf_url": "http://arxiv.org/pdf/2507.11862v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "跨领域迁移与小样本学习用于个人身份信息识别", "tldr": "本文研究了跨领域模型迁移、多领域数据融合以及样本高效学习在个人身份信息 (PII) 识别中的有效性，发现法律领域数据迁移效果好，医学领域差，且在低专业领域少量数据即可实现高质量识别。", "motivation": "准确识别个人身份信息 (PII) 对自动化文本匿名化至关重要。", "method": "使用来自医疗 (I2B2)、法律 (TAB) 和传记 (Wikipedia) 的标注语料库，评估模型在域内性能、跨域可迁移性、融合和小样本学习四个维度上的表现。", "result": "法律领域数据能很好地迁移到传记文本，而医疗领域抵制传入迁移。融合的益处是领域特定的。在低专业化领域，仅用10%的训练数据即可实现高质量的PII识别。", "conclusion": "跨领域迁移、数据融合和小样本学习在PII识别中表现出不同的有效性，其效果取决于领域特性，且在某些情况下，少量数据即可获得良好表现。", "translation": "准确识别个人身份信息 (PII) 对自动化文本匿名化至关重要。本文研究了跨领域模型迁移、多领域数据融合以及样本高效学习在 PII 识别中的有效性。我们使用来自医疗 (I2B2)、法律 (TAB) 和传记 (Wikipedia) 的标注语料库，从四个维度评估了模型：域内性能、跨域可迁移性、融合和小样本学习。结果显示，法律领域数据能很好地迁移到传记文本，而医疗领域则抵制传入迁移。融合的益处是领域特定的，并且在低专业化领域中，仅用 10% 的训练数据即可实现高质量识别。", "summary": "该论文探讨了在个人身份信息 (PII) 识别中，跨领域模型迁移、多领域数据融合以及小样本学习的有效性。通过对医疗、法律和传记领域语料库的评估，研究发现法律领域数据具有良好的跨域迁移性，而医疗领域则较差。此外，数据融合的效益具有领域特异性，且在低专业化领域中，仅需少量训练数据即可实现高效的 PII 识别。", "keywords": "个人身份信息识别, 跨领域迁移, 小样本学习, 数据融合, 文本匿名化", "comments": "该研究在PII识别领域探索了多种数据利用策略，特别是跨领域迁移和小样本学习，这对于数据稀缺或隐私敏感的场景具有重要意义。其发现不同领域的数据迁移特性，为实际应用提供了指导。"}}
{"id": "2507.11574", "title": "Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators", "authors": ["Kazuma Kobayashi", "Shailesh Garg", "Farid Ahmed", "Souvik Chakraborty", "Syed Bahauddin Alam"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11574v1", "summary": "Robust uncertainty quantification (UQ) remains a critical barrier to the safe\ndeployment of deep learning in real-time virtual sensing, particularly in\nhigh-stakes domains where sparse, noisy, or non-collocated sensor data are the\nnorm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework\nthat transforms neural operator-based virtual sensing with calibrated,\ndistribution-free prediction intervals. By unifying Monte Carlo dropout with\nsplit conformal prediction in a single DeepONet architecture, CMCO achieves\nspatially resolved uncertainty estimates without retraining, ensembling, or\ncustom loss design. Our method addresses a longstanding challenge: how to endow\noperator learning with efficient and reliable UQ across heterogeneous domains.\nThrough rigorous evaluation on three distinct applications: turbulent flow,\nelastoplastic deformation, and global cosmic radiation dose estimation-CMCO\nconsistently attains near-nominal empirical coverage, even in settings with\nstrong spatial gradients and proxy-based sensing. This breakthrough offers a\ngeneral-purpose, plug-and-play UQ solution for neural operators, unlocking\nreal-time, trustworthy inference in digital twins, sensor fusion, and\nsafety-critical monitoring. By bridging theory and deployment with minimal\ncomputational overhead, CMCO establishes a new foundation for scalable,\ngeneralizable, and uncertainty-aware scientific machine learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11574v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "基于共形化神经算子的无分布不确定性感知虚拟传感", "tldr": "CMCO通过结合蒙特卡洛dropout和分段共形预测，为神经算子提供了一种无需分布假设、高效可靠的不确定性量化方法，用于虚拟传感。", "motivation": "在实时虚拟传感中，鲁棒的不确定性量化（UQ）是深度学习安全部署的关键障碍，尤其是在数据稀疏、有噪声或非共置的高风险领域。现有算子学习在异构域中缺乏高效可靠的UQ方法。", "method": "本文提出了共形化蒙特卡洛算子（CMCO）框架，该框架将蒙特卡洛dropout与分段共形预测统一在一个DeepONet架构中。CMCO无需重新训练、集成或自定义损失函数，即可实现空间解析的不确定性估计。", "result": "CMCO在湍流、弹塑性变形和全球宇宙辐射剂量估计这三个不同应用中，即使在具有强空间梯度和基于代理的传感设置下，也能始终达到接近标称的经验覆盖率。", "conclusion": "CMCO为神经算子提供了一个通用的、即插即用的不确定性量化解决方案，可在数字孪生、传感器融合和安全关键监控中实现实时、可信的推理。它以最小的计算开销，为可扩展、可泛化和不确定性感知的科学机器学习奠定了新基础。", "translation": "鲁棒的不确定性量化（UQ）仍然是深度学习在实时虚拟传感中安全部署的关键障碍，特别是在稀疏、噪声或非共置传感器数据是常态的高风险领域。我们引入了共形化蒙特卡洛算子（CMCO），这是一个通过校准的、无分布的预测区间来转换基于神经算子的虚拟传感的框架。通过在单个DeepONet架构中统一蒙特卡洛dropout和分段共形预测，CMCO无需重新训练、集成或自定义损失设计，即可实现空间解析的不确定性估计。我们的方法解决了一个长期存在的挑战：如何赋予算子学习在异构域中高效可靠的UQ能力。通过在三个不同应用——湍流、弹塑性变形和全球宇宙辐射剂量估计——上的严格评估，CMCO始终能达到接近标称的经验覆盖率，即使在具有强空间梯度和基于代理的传感设置下也是如此。这一突破为神经算子提供了一个通用的、即插即用的UQ解决方案，从而在数字孪生、传感器融合和安全关键监控中实现了实时、可信的推理。通过以最小的计算开销弥合理论与部署之间的鸿沟，CMCO为可扩展、可泛化和不确定性感知的科学机器学习建立了新基础。", "summary": "本文提出了一种名为共形化蒙特卡洛算子（CMCO）的新框架，它通过在单个DeepONet架构中集成蒙特卡洛dropout和分段共形预测，为神经算子提供了无分布的不确定性量化能力。CMCO无需重新训练或自定义损失函数，即可提供空间解析的不确定性估计。在湍流、弹塑性变形和宇宙辐射剂量估计等应用中的严格评估表明，CMCO即使在复杂条件下也能 consistently 达到接近标称的经验覆盖率，为实时、可信的虚拟传感提供了通用且高效的解决方案。", "keywords": "不确定性量化, 神经算子, 共形预测, 虚拟传感, 蒙特卡洛dropout", "comments": "该论文的创新之处在于将蒙特卡洛dropout和共形预测巧妙地整合到DeepONet架构中，从而为神经算子提供了一种无需分布假设、计算效率高且可靠的不确定性量化方法。这对于在高风险实时虚拟传感场景中部署深度学习模型至关重要，因为它能提供可信赖的推理结果，显著推动了科学机器学习的实际应用。"}}
{"id": "2507.11634", "title": "Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation", "authors": ["Farideh Majidi", "Ziaeddin Beheshtifard"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Proceedings of the First National Conference on Artificial Intelligence and Emerging Research: Convergence of Humans and Intelligent Systems", "url": "http://arxiv.org/abs/2507.11634v1", "summary": "This research examines cross-lingual sentiment analysis using few-shot\nlearning and incremental learning methods in Persian. The main objective is to\ndevelop a model capable of performing sentiment analysis in Persian using\nlimited data, while getting prior knowledge from high-resource languages. To\nachieve this, three pre-trained multilingual models (XLM-RoBERTa, mDeBERTa, and\nDistilBERT) were employed, which were fine-tuned using few-shot and incremental\nlearning approaches on small samples of Persian data from diverse sources,\nincluding X, Instagram, Digikala, Snappfood, and Taaghche. This variety enabled\nthe models to learn from a broad range of contexts. Experimental results show\nthat the mDeBERTa and XLM-RoBERTa achieved high performances, reaching 96%\naccuracy on Persian sentiment analysis. These findings highlight the\neffectiveness of combining few-shot learning and incremental learning with\nmultilingual pre-trained models.", "comment": "Proceedings of the First National Conference on Artificial\n  Intelligence and Emerging Research: Convergence of Humans and Intelligent\n  Systems", "pdf_url": "http://arxiv.org/pdf/2507.11634v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "波斯语情感分析中的跨语言小样本学习与增量适应", "tldr": "本研究结合小样本学习和增量学习，使用多语言预训练模型（mDeBERTa和XLM-RoBERTa）在有限的波斯语数据上实现了高精度的情感分析（96%准确率）。", "motivation": "在波斯语中进行情感分析时，面临数据量有限的挑战，需要利用高资源语言的先验知识来开发有效的模型。", "method": "采用XLM-RoBERTa、mDeBERTa和DistilBERT三种多语言预训练模型，利用小样本学习和增量学习方法，在来自X、Instagram、Digikala、Snappfood和Taaghche等不同来源的少量波斯语数据集上进行微调。", "result": "实验结果显示，mDeBERTa和XLM-RoBERTa模型在波斯语情感分析中表现出色，准确率达到96%。", "conclusion": "结合小样本学习、增量学习和多语言预训练模型的方法，在处理资源稀缺语言（如波斯语）的情感分析任务上是有效的。", "translation": "本研究探讨了在波斯语中使用小样本学习和增量学习方法进行跨语言情感分析。主要目标是开发一个能够利用有限数据进行波斯语情感分析的模型，同时从高资源语言中获取先验知识。为了实现这一目标，本研究采用了三种预训练的多语言模型（XLM-RoBERTa、mDeBERTa和DistilBERT），这些模型利用小样本学习和增量学习方法，在来自X、Instagram、Digikala、Snappfood和Taaghche等不同来源的少量波斯语数据样本上进行了微调。这种多样性使得模型能够从广泛的语境中学习。实验结果表明，mDeBERTa和XLM-RoBERTa取得了高性能，在波斯语情感分析上达到了96%的准确率。这些发现强调了将小样本学习和增量学习与多语言预训练模型相结合的有效性。", "summary": "本研究旨在解决波斯语情感分析中数据稀缺的问题，通过结合跨语言小样本学习和增量学习方法，利用多语言预训练模型（XLM-RoBERTa、mDeBERTa和DistilBERT）在少量波斯语数据上进行微调。实验证明，mDeBERTa和XLM-RoBERTa模型表现优异，在波斯语情感分析中取得了96%的准确率，验证了该方法在低资源语言情感分析任务上的有效性。", "keywords": "跨语言情感分析, 小样本学习, 增量学习, 波斯语, 多语言预训练模型", "comments": "这项研究通过结合小样本学习和增量学习，有效地解决了波斯语这种低资源语言的情感分析挑战，创新性在于利用多语言预训练模型迁移知识，并取得了显著的高准确率。其方法对于其他低资源语言的情感分析任务具有重要的参考价值。"}}
{"id": "2404.06050", "title": "Incremental Joint Learning of Depth, Pose and Implicit Scene Representation on Monocular Camera in Large-scale Scenes", "authors": ["Tianchen Deng", "Nailin Wang", "Chongdi Wang", "Shenghai Yuan", "Jingchuan Wang", "Hesheng Wang", "Danwei Wang", "Weidong Chen"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.06050v3", "summary": "Dense scene reconstruction for photo-realistic view synthesis has various\napplications, such as VR/AR, autonomous vehicles. However, most existing\nmethods have difficulties in large-scale scenes due to three core challenges:\n\\textit{(a) inaccurate depth input.} Accurate depth input is impossible to get\nin real-world large-scale scenes. \\textit{(b) inaccurate pose estimation.} Most\nexisting approaches rely on accurate pre-estimated camera poses. \\textit{(c)\ninsufficient scene representation capability.} A single global radiance field\nlacks the capacity to effectively scale to large-scale scenes. To this end, we\npropose an incremental joint learning framework, which can achieve accurate\ndepth, pose estimation, and large-scale scene reconstruction. A vision\ntransformer-based network is adopted as the backbone to enhance performance in\nscale information estimation. For pose estimation, a feature-metric bundle\nadjustment (FBA) method is designed for accurate and robust camera tracking in\nlarge-scale scenes. In terms of implicit scene representation, we propose an\nincremental scene representation method to construct the entire large-scale\nscene as multiple local radiance fields to enhance the scalability of 3D scene\nrepresentation. Extended experiments have been conducted to demonstrate the\neffectiveness and accuracy of our method in depth estimation, pose estimation,\nand large-scale scene reconstruction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.06050v3", "cate": "cs.CV", "date": "2024-04-09", "updated": "2025-07-16", "AI": {"title_translation": "单目相机在大规模场景下深度、姿态和隐式场景表示的增量联合学习", "tldr": "提出一种增量联合学习框架，用于在单目相机大规模场景中实现准确的深度、姿态估计和场景重建，解决了现有方法在大规模场景中的挑战。", "motivation": "现有方法在VR/AR、自动驾驶等应用中进行大规模场景的密集重建时面临三大挑战：深度输入不准确、姿态估计不准确以及场景表示能力不足（单一全局辐射场难以扩展到大规模场景）。", "method": "本文提出一个增量联合学习框架。该框架采用基于Vision Transformer的网络作为骨干以增强尺度信息估计性能。为解决姿态估计问题，设计了一种特征度量束调整（FBA）方法用于大规模场景中的准确鲁棒相机跟踪。在隐式场景表示方面，提出增量场景表示方法，将整个大规模场景构建为多个局部辐射场，以增强3D场景表示的可扩展性。", "result": "扩展实验证明了该方法在深度估计、姿态估计和大规模场景重建方面的有效性和准确性。", "conclusion": "该方法能够有效解决大规模场景中深度、姿态估计不准确及场景表示能力不足的问题，从而实现准确的大规模场景重建。", "translation": "光真实感视图合成的密集场景重建在VR/AR、自动驾驶等领域有广泛应用。然而，大多数现有方法在大规模场景中面临三个核心挑战：(a) 深度输入不准确。在真实世界的大规模场景中难以获得准确的深度输入。(b) 姿态估计不准确。大多数现有方法依赖于准确的预估计相机姿态。(c) 场景表示能力不足。单一的全局辐射场缺乏有效扩展到大规模场景的能力。为此，我们提出了一种增量联合学习框架，可以实现准确的深度、姿态估计和大规模场景重建。采用基于Vision Transformer的网络作为骨干，以提高尺度信息估计的性能。对于姿态估计，设计了一种特征度量束调整（FBA）方法，用于大规模场景中准确鲁棒的相机跟踪。在隐式场景表示方面，我们提出了一种增量场景表示方法，将整个大规模场景构建为多个局部辐射场，以增强3D场景表示的可扩展性。通过扩展实验证明了我们方法在深度估计、姿态估计和大规模场景重建方面的有效性和准确性。", "summary": "本文提出一种增量联合学习框架，旨在解决单目相机在大规模场景中进行密集重建时面临的深度、姿态估计不准确和场景表示能力不足的问题。该框架结合了基于Vision Transformer的骨干网络、特征度量束调整（FBA）姿态估计以及多局部辐射场的增量场景表示方法，实现了在大规模场景中准确的深度、姿态估计和高效的场景重建。实验结果验证了其有效性和准确性。", "keywords": "增量学习, 深度估计, 姿态估计, 隐式场景表示, 大规模场景", "comments": "该论文提出了一种创新的增量联合学习框架，有效地解决了大规模场景下单目相机进行深度、姿态估计和场景重建的难题。其亮点在于结合了Vision Transformer提升尺度估计、FBA实现鲁棒姿态跟踪以及通过局部辐射场增强场景表示的可扩展性，这些协同工作显著提升了在大规模真实世界场景中的应用潜力，对于VR/AR和自动驾驶等领域具有重要意义。"}}
{"id": "2505.04457", "title": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration", "authors": ["Shigeki Karita", "Yuma Koizumi", "Heiga Zen", "Haruko Ishikawa", "Robin Scheibler", "Michiel Bacchiani"], "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE WASPAA2025", "url": "http://arxiv.org/abs/2505.04457v3", "summary": "Training data cleaning is a new application for generative model-based speech\nrestoration (SR). This paper introduces Miipher-2, an SR model designed for\nmillion-hour scale data, for training data cleaning for large-scale generative\nmodels like large language models. Key challenges addressed include\ngeneralization to unseen languages, operation without explicit conditioning\n(e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a\nfrozen, pre-trained Universal Speech Model (USM), supporting over 300\nlanguages, as a robust, conditioning-free feature extractor. To optimize\nefficiency and minimize memory, Miipher-2 incorporates parallel adapters for\npredicting clean USM features from noisy inputs and employs the WaveFit neural\nvocoder for waveform synthesis. These components were trained on 3,000 hours of\nmulti-lingual, studio-quality recordings with augmented degradations, while USM\nparameters remained fixed. Experimental results demonstrate Miipher-2's\nsuperior or comparable performance to conventional SR models in\nword-error-rate, speaker similarity, and both objective and subjective sound\nquality scores across all tested languages. Miipher-2 operates efficiently on\nconsumer-grade accelerators, achieving a real-time factor of 0.0078, enabling\nthe processing of a million-hour speech dataset in approximately three days\nusing only 100 such accelerators.", "comment": "Accepted to IEEE WASPAA2025", "pdf_url": "http://arxiv.org/pdf/2505.04457v3", "cate": "cs.SD", "date": "2025-05-07", "updated": "2025-07-16", "AI": {"title_translation": "Miipher-2：一个用于百万小时级数据恢复的通用语音恢复模型", "tldr": "Miipher-2是一个高效的通用语音恢复模型，能够处理百万小时级语音数据，用于大型生成模型的训练数据清洗，无需显式条件，并在多语言上表现出色。", "motivation": "动机是解决生成模型（如大型语言模型）训练数据清洗中语音恢复的应用挑战，特别是需要处理百万小时级数据、泛化到未见语言、无需显式条件（如文本、说话人ID）以及提高计算效率。", "method": "Miipher-2利用一个冻结的、预训练的通用语音模型（USM）作为特征提取器，该USM支持300多种语言。为优化效率和内存，它集成了并行适配器来预测干净的USM特征，并使用WaveFit神经声码器进行波形合成。模型在3000小时的多语言、录音室质量的带降级录音数据上进行训练，同时USM参数保持固定。", "result": "Miipher-2在所有测试语言中，在词错误率、说话人相似度以及客观和主观音质评分方面均优于或与传统语音恢复模型相当。它能在消费级加速器上高效运行，实时因子达到0.0078，使用100个加速器大约三天即可处理百万小时的语音数据集。", "conclusion": "Miipher-2是一个高效且性能卓越的通用语音恢复模型，能够有效解决大规模训练数据的清洗问题，尤其适用于百万小时级的数据处理。", "translation": "训练数据清洗是基于生成模型的语音恢复（SR）的一个新应用。本文介绍了Miipher-2，一个专为百万小时级数据设计的SR模型，用于大型生成模型（如大型语言模型）的训练数据清洗。解决的关键挑战包括对未见语言的泛化能力、无需显式条件（例如文本、说话人ID）的操作以及计算效率。Miipher-2利用一个冻结的、预训练的通用语音模型（USM）作为鲁棒的、无需条件的特征提取器，该模型支持300多种语言。为了优化效率和最小化内存，Miipher-2集成了并行适配器，用于从嘈杂输入中预测干净的USM特征，并采用WaveFit神经声码器进行波形合成。这些组件在3000小时的多语言、录音室质量的带增强降级录音数据上进行训练，而USM参数保持固定。实验结果表明，Miipher-2在所有测试语言中，在词错误率、说话人相似度以及客观和主观音质评分方面均优于或与传统SR模型相当。Miipher-2在消费级加速器上高效运行，实时因子达到0.0078，使用100个加速器大约三天即可处理百万小时的语音数据集。", "summary": "Miipher-2是一个为大规模训练数据清洗设计的通用语音恢复模型，特别是针对百万小时级数据。它通过利用预训练的通用语音模型作为无条件特征提取器，并结合并行适配器和WaveFit声码器，解决了多语言泛化、无条件操作和计算效率等挑战。实验证明，Miipher-2在性能上优于或与现有模型相当，并且在消费级硬件上具有极高的处理效率，能够快速处理海量语音数据。", "keywords": "语音恢复, 数据清洗, 通用语音模型, 大规模数据, 计算效率", "comments": "Miipher-2的创新之处在于其针对百万小时级数据清洗的超大规模处理能力和效率，以及其无需显式条件即可在多语言环境下进行语音恢复的能力。这对于大型生成模型的数据预处理具有重要意义，因为它能显著降低数据清洗的成本和时间，并提高数据质量。其在消费级硬件上的高效运行也大大降低了部署门槛。"}}
{"id": "2507.12378", "title": "Developing Visual Augmented Q&A System using Scalable Vision Embedding Retrieval & Late Interaction Re-ranker", "authors": ["Rachna Saxena", "Abhijeet Kumar", "Suresh Shanmugam"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Presented at NLP@IR workshop at SIGIR conference", "url": "http://arxiv.org/abs/2507.12378v1", "summary": "Traditional information extraction systems face challenges with text only\nlanguage models as it does not consider infographics (visual elements of\ninformation) such as tables, charts, images etc. often used to convey complex\ninformation to readers. Multimodal LLM (MLLM) face challenges of finding needle\nin the haystack problem i.e., either longer context length or substantial\nnumber of documents as search space. Late interaction mechanism over visual\nlanguage models has shown state of the art performance in retrieval-based\nvision augmented Q&A tasks. There are yet few challenges using it for RAG based\nmulti-modal Q&A. Firstly, many popular and widely adopted vector databases do\nnot support native multi-vector retrieval. Secondly, late interaction requires\ncomputation which inflates space footprint and can hinder enterprise adoption.\nLastly, the current state of late interaction mechanism does not leverage the\napproximate neighbor search indexing methods for large speed ups in retrieval\nprocess. This paper explores a pragmatic approach to make vision retrieval\nprocess scalable and efficient without compromising on performance quality. We\npropose multi-step custom implementation utilizing widely adopted hybrid search\n(metadata & embedding) and state of the art late interaction re-ranker to\nretrieve best matching pages. Finally, MLLM are prompted as reader to generate\nanswers from contextualized best matching pages. Through experiments, we\nobserve that the proposed design is scalable (significant speed up) and stable\n(without degrading performance quality), hence can be used as production\nsystems at enterprises.", "comment": "Presented at NLP@IR workshop at SIGIR conference", "pdf_url": "http://arxiv.org/pdf/2507.12378v1", "cate": "cs.IR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "开发基于可扩展视觉嵌入检索和后期交互重排器的视觉增强型问答系统", "tldr": "本文提出了一种实用方法，通过多步自定义实现，结合混合搜索和后期交互重排器，使视觉检索过程可扩展且高效，解决了传统信息提取系统和多模态LLM在处理视觉信息时的挑战。", "motivation": "传统信息提取系统面临无法处理信息图（如表格、图表、图像等）的挑战，因为它们只依赖文本语言模型。多模态LLM（MLLM）在处理长上下文或大量文档作为搜索空间时存在“大海捞针”问题。尽管后期交互机制在基于检索的视觉增强型问答任务中表现出色，但仍面临多向量检索支持不足、计算量大导致空间占用增加、以及未能利用近似邻居搜索索引方法进行加速等挑战。", "method": "本文提出了一种实用方法，通过多步自定义实现，利用广泛采用的混合搜索（元数据和嵌入）和最先进的后期交互重排器来检索最佳匹配页面。最后，使用MLLM作为阅读器，从上下文化后的最佳匹配页面生成答案。", "result": "实验表明，所提出的设计具有可扩展性（显著加速）和稳定性（不降低性能质量）。", "conclusion": "所提出的视觉增强型问答系统设计是可扩展且稳定的，因此可以在企业中用作生产系统。", "translation": "传统信息提取系统面临仅使用文本语言模型的挑战，因为它不考虑信息图（信息的视觉元素），如表格、图表、图像等，这些信息图常用于向读者传达复杂信息。多模态LLM（MLLM）面临“大海捞针”问题，即上下文长度过长或搜索空间中的文档数量巨大。基于视觉语言模型的后期交互机制在基于检索的视觉增强型问答任务中表现出最先进的性能。然而，将其用于基于RAG的多模态问答仍存在一些挑战。首先，许多流行且广泛采用的向量数据库不支持原生的多向量检索。其次，后期交互需要计算，这会增加空间占用并可能阻碍企业采用。最后，当前后期交互机制未能利用近似邻居搜索索引方法来大幅提高检索速度。本文探索一种实用方法，在不影响性能质量的情况下，使视觉检索过程可扩展且高效。我们提出多步自定义实现，利用广泛采用的混合搜索（元数据和嵌入）和最先进的后期交互重排器来检索最佳匹配页面。最后，MLLM被提示作为阅读器，从上下文化后的最佳匹配页面生成答案。通过实验，我们观察到所提出的设计具有可扩展性（显著加速）和稳定性（不降低性能质量），因此可以在企业中用作生产系统。", "summary": "本文针对传统信息提取系统和多模态LLM在处理视觉信息方面的挑战，提出了一种可扩展且高效的视觉增强型问答系统。该系统通过结合混合搜索和先进的后期交互重排器进行多步检索，并利用MLLM生成答案。实验证明，该设计在不牺牲性能的情况下实现了显著的加速和稳定性，适用于企业级生产系统。", "keywords": "视觉问答, 多模态LLM, 检索增强生成, 后期交互, 混合搜索", "comments": "这项工作通过提出一种实用的、可扩展的视觉检索方法，解决了多模态问答系统在企业应用中的关键障碍。其创新点在于结合了混合搜索和后期交互重排器，有效应对了现有向量数据库限制和计算效率问题。该研究对于推动多模态LLM在实际生产环境中的部署具有重要意义。"}}
{"id": "2507.11677", "title": "CLAImate: AI-Enabled Climate Change Communication through Personalized and Localized Narrative Visualizations", "authors": ["Mashrur Rashik", "Jean-Daniel Fekete", "Narges Mahyar"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      To appear in the IEEE Visualization and Visual Analytics (VIS) Conference, Short Paper, 2025", "url": "http://arxiv.org/abs/2507.11677v1", "summary": "Communicating climate change remains challenging, as climate reports, though\nrich in data and visualizations, often feel too abstract or technical for the\npublic. Although personalization can enhance communication, most tools still\nlack the narrative and visualization tailoring needed to connect with\nindividual experiences. We present CLAImate, an AI-enabled prototype that\npersonalizes conversation narratives and localizes visualizations based on\nusers' climate knowledge and geographic location. We evaluated CLAImate through\ninternal verification of factual correctness, a formative study with experts,\nand a pilot with UK residents. CLAImate achieved 66% SNLI accuracy and 70%\nFACTSCORE. Visualization experts appreciated its clarity and personalization,\nand seven out of ten UK participants reported better understanding and local\nrelevance of climate risks with CLAImate. We also discuss design challenges in\npersonalization, accuracy, and scalability, and outline future directions for\nintegrating visualizations in personalized conversational interfaces.", "comment": "To appear in the IEEE Visualization and Visual Analytics (VIS)\n  Conference, Short Paper, 2025", "pdf_url": "http://arxiv.org/pdf/2507.11677v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "CLAImate：通过个性化和本地化叙事可视化实现AI驱动的气候变化交流", "tldr": "CLAImate是一个AI工具，通过个性化对话和本地化可视化帮助公众更好地理解气候变化，提高了理解度和本地相关性。", "motivation": "气候变化报告对公众来说过于抽象或技术性，现有工具缺乏个性化叙事和可视化，难以与个人经验建立联系，因此需要一种新的方法来提升气候变化信息的有效传播。", "method": "本文提出了CLAImate，一个AI驱动的原型，它根据用户的气候知识和地理位置个性化对话叙事并本地化可视化。通过内部事实正确性验证、与专家的形成性研究以及与英国居民的试点评估了CLAImate。", "result": "CLAImate在SNLI准确率上达到66%，FACTSCORE达到70%。可视化专家赞赏其清晰度和个性化。十名英国参与者中有七名表示通过CLAImate更好地理解了气候风险和本地相关性。", "conclusion": "CLAImate通过个性化和本地化叙事可视化有效提升了公众对气候变化的理解和本地相关性，但仍面临个性化、准确性和可扩展性方面的设计挑战，未来将探索在个性化对话界面中集成可视化。", "translation": "气候变化交流仍然充满挑战，因为气候报告尽管数据和可视化丰富，但对公众来说往往过于抽象或技术性。尽管个性化可以增强交流，但大多数工具仍缺乏与个人经验建立联系所需的叙事和可视化定制。我们提出了CLAImate，一个由人工智能驱动的原型，它根据用户的气候知识和地理位置个性化对话叙事并本地化可视化。我们通过事实正确性的内部验证、与专家的形成性研究以及与英国居民的试点评估了CLAImate。CLAImate实现了66%的SNLI准确率和70%的FACTSCORE。可视化专家赞赏其清晰度和个性化，十名英国参与者中有七名表示通过CLAImate更好地理解了气候风险和本地相关性。我们还讨论了个性化、准确性和可扩展性方面的设计挑战，并概述了在个性化对话界面中集成可视化的未来方向。", "summary": "本文介绍了CLAImate，一个AI驱动的原型，旨在通过个性化对话叙事和本地化可视化来改善气候变化信息的公众传播。该工具根据用户的气候知识和地理位置进行定制，并通过内部验证、专家研究和英国居民试点进行评估。结果显示，CLAImate在准确性方面表现良好，并显著提高了用户对气候风险的理解和本地相关性。文章还讨论了在个性化、准确性和可扩展性方面的设计挑战。", "keywords": "气候变化交流, 个性化, 本地化, 人工智能, 可视化", "comments": "CLAImate的创新之处在于结合AI实现个性化和本地化的气候变化沟通，这对于提升公众理解和参与度至关重要。其通过用户反馈和量化指标验证了效果，并指出了未来在集成可视化和解决可扩展性方面的方向，具有很强的实用价值和研究潜力。"}}
{"id": "2507.11771", "title": "Scaling laws for activation steering with Llama 2 models and refusal mechanisms", "authors": ["Sheikh Abdur Raheem Ali", "Justin Xu", "Ivory Yang", "Jasmine Xinze Li", "Ayse Arslan", "Clark Benham"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11771v1", "summary": "As large language models (LLMs) evolve in complexity and capability, the\nefficacy of less widely deployed alignment techniques are uncertain. Building\non previous work on activation steering and contrastive activation addition\n(CAA), this paper explores the effectiveness of CAA with model scale using the\nfamily of Llama 2 models (7B, 13B, and 70B). CAA works by finding desirable\n'directions' in the model's residual stream vector space using contrastive\npairs (for example, hate to love) and adding this direction to the residual\nstream during the forward pass. It directly manipulates the residual stream and\naims to extract features from language models to better control their outputs.\nUsing answer matching questions centered around the refusal behavior, we found\nthat 1) CAA is most effective when applied at early-mid layers. 2) The\neffectiveness of CAA diminishes with model size. 3) Negative steering has more\npronounced effects than positive steering across all model sizes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11771v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "Llama 2 模型和拒绝机制的激活操纵标度律", "tldr": "本文研究了对比激活加法（CAA）在Llama 2模型中对LLM拒绝行为的有效性，发现CAA在早期-中期层最有效，但其有效性随模型规模减弱，且负向操纵效果比正向更显著。", "motivation": "随着大型语言模型（LLMs）复杂性和能力的演变，不那么广泛部署的对齐技术的有效性存在不确定性。本文旨在探索对比激活加法（CAA）在不同模型规模下的有效性，以更好地控制LLM输出。", "method": "本文在激活操纵和对比激活加法（CAA）的先前工作基础上，使用Llama 2系列模型（7B、13B和70B）进行实验。CAA通过使用对比对（如“恨到爱”）在模型的残差流向量空间中找到期望的“方向”，并在前向传播期间将其添加到残差流中，从而直接操纵残差流以控制模型输出。研究通过围绕拒绝行为的答案匹配问题进行评估。", "result": "1) 对比激活加法（CAA）在早期-中期层应用时最有效。2) CAA的有效性随模型规模的增大而减弱。3) 负向操纵在所有模型规模下都比正向操纵具有更显著的效果。", "conclusion": "对比激活加法（CAA）是一种能够影响大型语言模型行为（如拒绝机制）的技术，其效果受应用层数、模型规模和操纵方向的影响。", "translation": "随着大型语言模型（LLMs）在复杂性和能力上的演变，不那么广泛部署的对齐技术的有效性变得不确定。本文在激活操纵和对比激活加法（CAA）的先前工作基础上，探讨了CAA在Llama 2系列模型（7B、13B和70B）中随模型规模变化的有效性。CAA通过使用对比对（例如，恨到爱）在模型的残差流向量空间中找到期望的“方向”，并在前向传播期间将此方向添加到残差流中。它直接操纵残差流，旨在从语言模型中提取特征以更好地控制其输出。通过使用围绕拒绝行为的答案匹配问题，我们发现：1) CAA在早期-中期层应用时最有效。2) CAA的有效性随模型规模的增大而减弱。3) 在所有模型规模下，负向操纵比正向操纵具有更显著的效果。", "summary": "本文研究了对比激活加法（CAA）在Llama 2系列模型（7B、13B、70B）中对LLM行为控制的有效性，特别是针对拒绝机制。研究发现，CAA在模型早期-中期层应用时效果最佳，但其有效性随模型规模的增加而降低，且负向操纵比正向操纵效果更显著。CAA通过直接操纵残差流来引导模型输出。", "keywords": "激活操纵, 对比激活加法, Llama 2, 拒绝机制, 标度律", "comments": "这项研究通过系统地探索激活操纵技术在不同规模Llama 2模型上的表现，为理解和控制大型语言模型的行为提供了宝贵的见解。特别是，它量化了CAA在模型层级和规模上的有效性变化，并指出了负向操纵的独特效果，这对于未来的模型对齐和行为修正研究具有重要意义。"}}
{"id": "2507.12006", "title": "Frequency-Dynamic Attention Modulation for Dense Prediction", "authors": ["Linwei Chen", "Lin Gu", "Ying Fu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.12006v1", "summary": "Vision Transformers (ViTs) have significantly advanced computer vision,\ndemonstrating strong performance across various tasks. However, the attention\nmechanism in ViTs makes each layer function as a low-pass filter, and the\nstacked-layer architecture in existing transformers suffers from frequency\nvanishing. This leads to the loss of critical details and textures. We propose\na novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention\nModulation (FDAM), which can be easily plugged into ViTs. FDAM directly\nmodulates the overall frequency response of ViTs and consists of two\ntechniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling\n(FreqScale). Since circuit theory uses low-pass filters as fundamental\nelements, we introduce AttInv, a method that generates complementary high-pass\nfiltering by inverting the low-pass filter in the attention matrix, and\ndynamically combining the two. We further design FreqScale to weight different\nfrequency components for fine-grained adjustments to the target response\nfunction. Through feature similarity analysis and effective rank evaluation, we\ndemonstrate that our approach avoids representation collapse, leading to\nconsistent performance improvements across various models, including SegFormer,\nDeiT, and MaskDINO. These improvements are evident in tasks such as semantic\nsegmentation, object detection, and instance segmentation. Additionally, we\napply our method to remote sensing detection, achieving state-of-the-art\nresults in single-scale settings. The code is available at\n\\href{https://github.com/Linwei-Chen/FDAM}{https://github.com/Linwei-Chen/FDAM}.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.12006v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "用于密集预测的频率动态注意力调制", "tldr": "ViT中的注意力机制会导致频率消失和细节丢失。本文提出频率动态注意力调制（FDAM），通过注意力反转和频率动态缩放来避免表示坍塌，并在多种密集预测任务中取得性能提升。", "motivation": "现有的Vision Transformers（ViTs）中的注意力机制使每个层充当低通滤波器，导致堆叠层架构在频率上出现消失现象，从而丢失关键细节和纹理信息。", "method": "本文提出一种受电路理论启发的频率动态注意力调制（FDAM）策略，可轻松集成到ViTs中。FDAM直接调制ViTs的整体频率响应，包含两种技术：注意力反转（AttInv）和频率动态缩放（FreqScale）。AttInv通过反转注意力矩阵中的低通滤波器生成互补的高通滤波，并动态结合两者。FreqScale用于加权不同频率分量，以对目标响应函数进行精细调整。", "result": "通过特征相似性分析和有效秩评估，该方法避免了表示坍塌，并在SegFormer、DeiT和MaskDINO等多种模型上实现了持续的性能提升。这些改进在语义分割、目标检测和实例分割等任务中表现明显。此外，在遥感检测的单尺度设置中也取得了最先进的结果。", "conclusion": "本文提出的频率动态注意力调制（FDAM）通过解决ViT中注意力机制导致的频率消失问题，有效避免了表示坍塌，并在多种密集预测任务和模型上实现了显著的性能提升。", "translation": "视觉Transformer（ViT）极大地推动了计算机视觉的发展，在各种任务中展现出强大的性能。然而，ViT中的注意力机制使得每一层都像一个低通滤波器，现有Transformer中的堆叠层架构存在频率消失的问题。这导致关键细节和纹理的丢失。我们提出了一种新颖的、受电路理论启发的策略，称为频率动态注意力调制（FDAM），它可以轻松地插入到ViT中。FDAM直接调制ViT的整体频率响应，由两种技术组成：注意力反转（AttInv）和频率动态缩放（FreqScale）。由于电路理论使用低通滤波器作为基本元件，我们引入了AttInv，这是一种通过反转注意力矩阵中的低通滤波器来生成互补高通滤波，并动态结合两者的方。我们进一步设计了FreqScale，用于加权不同的频率分量，以对目标响应函数进行精细调整。通过特征相似性分析和有效秩评估，我们证明了我们的方法避免了表示坍塌，从而在包括SegFormer、DeiT和MaskDINO在内的各种模型上实现了持续的性能改进。这些改进在语义分割、目标检测和实例分割等任务中表现明显。此外，我们将我们的方法应用于遥感检测，在单尺度设置中取得了最先进的结果。代码可在https://github.com/Linwei-Chen/FDAM获取。", "summary": "本文提出一种名为频率动态注意力调制（FDAM）的新颖策略，旨在解决Vision Transformers（ViTs）中注意力机制导致的频率消失和细节丢失问题。FDAM受电路理论启发，通过注意力反转（AttInv）生成互补高通滤波，并利用频率动态缩放（FreqScale）进行精细频率调整。该方法有效避免了表示坍塌，并在语义分割、目标检测和实例分割等密集预测任务以及遥感检测中，对包括SegFormer、DeiT和MaskDINO在内的多个ViT模型实现了持续且显著的性能提升。", "keywords": "Vision Transformers, 频率动态注意力调制, 密集预测, 频率消失, 注意力机制", "comments": "该论文创新性地将电路理论引入到ViT的注意力机制优化中，通过频率动态调制有效解决了现有ViT中注意力作为低通滤波器导致的频率消失和细节丢失问题。其提出的注意力反转和频率动态缩放机制具有很强的通用性和可插拔性，能够轻松集成到多种ViT架构中，并在多个密集预测任务中展现出显著的性能提升，具有重要的实践意义和理论价值。"}}
{"id": "2507.12130", "title": "Weighted $k$-Server Admits an Exponentially Competitive Algorithm", "authors": ["Adithya Bijoy", "Ankit Mondal", "Ashish Chiplunkar"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12130v1", "summary": "The weighted $k$-server is a variant of the $k$-server problem, where the\ncost of moving a server is the server's weight times the distance through which\nit moves. The problem is famous for its intriguing properties and for evading\nstandard techniques for designing and analyzing online algorithms. Even on\nuniform metric spaces with sufficiently many points, the deterministic\ncompetitive ratio of weighted $k$-server is known to increase doubly\nexponentially with respect to $k$, while the behavior of its randomized\ncompetitive ratio is not fully understood. Specifically, no upper bound better\nthan doubly exponential is known, while the best known lower bound is singly\nexponential in $k$. In this paper, we close the exponential gap between these\nbounds by giving an $\\exp(O(k^2))$-competitive randomized online algorithm for\nthe weighted $k$-server problem on uniform metrics, thus breaking the doubly\nexponential barrier for deterministic algorithms for the first time. This is\nachieved by a recursively defined notion of a phase which, on the one hand,\nforces a lower bound on the cost of any offline solution, while, on the other\nhand, also admits a randomized online algorithm with bounded expected cost. The\nalgorithm is also recursive; it involves running several algorithms virtually\nand in parallel and following the decisions of one of them in a random order.\nWe also show that our techniques can be lifted to construct an\n$\\exp(O(k^2))$-competitive randomized online algorithm for the generalized\n$k$-server problem on weighted uniform metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12130v1", "cate": "cs.DS", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "加权k-服务器问题存在指数级竞争算法", "tldr": "本文为加权k-服务器问题在统一度量空间上提供了一个指数级竞争的随机在线算法，首次打破了确定性算法的双指数障碍。", "motivation": "加权k-服务器问题因其复杂性而闻名，并且难以使用标准在线算法技术来解决。尽管已知确定性竞争比率随k呈双指数增长，但随机竞争比率的上限仍未突破双指数，而最佳下限仅为单指数，存在一个指数级的差距。", "method": "通过递归定义“阶段”的概念，一方面强制离线解的成本下限，另一方面允许随机在线算法具有有限的期望成本。该算法本身也是递归的，涉及虚拟并行运行多个算法，并以随机顺序遵循其中一个的决策。该技术还可应用于广义k-服务器问题。", "result": "提出了一个在统一度量空间上针对加权k-服务器问题的$\\exp(O(k^2))$-竞争随机在线算法，首次打破了确定性算法的双指数障碍。该技术还可应用于加权统一度量空间上的广义k-服务器问题，构造出$\\exp(O(k^2))$-竞争的随机在线算法。", "conclusion": "本文通过引入一种新颖的递归算法，成功地缩小了加权k-服务器问题随机竞争比率的已知上下限之间的指数差距，并为在线算法领域提供了新的工具和见解。", "translation": "加权k-服务器问题是k-服务器问题的一个变体，其中服务器移动的成本是服务器的权重乘以其移动的距离。这个问题以其有趣的特性和规避在线算法设计和分析的标准技术而闻名。即使在具有足够多点的统一度量空间上，加权k-服务器的确定性竞争比率已知随k呈双指数增长，而其随机竞争比率的行为尚未完全理解。具体来说，目前还没有比双指数更好的上限，而已知最佳下限是k的单指数。在本文中，我们通过为统一度量空间上的加权k-服务器问题提供一个$\\exp(O(k^2))$-竞争的随机在线算法，从而弥补了这些界限之间的指数差距，首次打破了确定性算法的双指数障碍。这是通过递归定义的“阶段”概念实现的，一方面它强制任何离线解决方案的成本下限，另一方面也允许具有有限期望成本的随机在线算法。该算法也是递归的；它涉及虚拟地并行运行多个算法，并以随机顺序遵循其中一个的决策。我们还表明，我们的技术可以提升以构建一个在加权统一度量空间上针对广义k-服务器问题的$\\exp(O(k^2))$-竞争随机在线算法。", "summary": "本文研究了加权k-服务器问题，该问题在在线算法设计中极具挑战性。针对统一度量空间上的随机竞争比率存在的指数级差距，作者提出了一种创新的$\\exp(O(k^2))$-竞争随机在线算法。该算法通过递归定义的“阶段”概念和并行运行多个子算法来实现，成功地将随机竞争比率的上限从双指数降至指数级，首次突破了确定性算法的双指数壁垒。此外，该技术也被证明适用于广义k-服务器问题。", "keywords": "加权k-服务器, 在线算法, 竞争比率, 统一度量空间, 随机算法", "comments": "这篇论文的创新点在于首次为加权k-服务器问题在统一度量空间上提供了一个指数级竞争的随机在线算法，成功打破了长期存在的双指数竞争比率障碍。其递归定义的“阶段”概念和并行算法运行的策略为在线算法的设计和分析提供了新的思路，对于理解和解决此类复杂问题具有重要意义。"}}
{"id": "2502.16994", "title": "FADE: Why Bad Descriptions Happen to Good Features", "authors": ["Bruno Puri", "Aakriti Jain", "Elena Golimblevskaia", "Patrick Kahardipraja", "Thomas Wiegand", "Wojciech Samek", "Sebastian Lapuschkin"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.16994v2", "summary": "Recent advances in mechanistic interpretability have highlighted the\npotential of automating interpretability pipelines in analyzing the latent\nrepresentations within LLMs. While this may enhance our understanding of\ninternal mechanisms, the field lacks standardized evaluation methods for\nassessing the validity of discovered features. We attempt to bridge this gap by\nintroducing FADE: Feature Alignment to Description Evaluation, a scalable\nmodel-agnostic framework for automatically evaluating feature-to-description\nalignment. FADE evaluates alignment across four key metrics - Clarity,\nResponsiveness, Purity, and Faithfulness - and systematically quantifies the\ncauses of the misalignment between features and their descriptions. We apply\nFADE to analyze existing open-source feature descriptions and assess key\ncomponents of automated interpretability pipelines, aiming to enhance the\nquality of descriptions. Our findings highlight fundamental challenges in\ngenerating feature descriptions, particularly for SAEs compared to MLP neurons,\nproviding insights into the limitations and future directions of automated\ninterpretability. We release FADE as an open-source package at:\nhttps://github.com/brunibrun/FADE", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.16994v2", "cate": "cs.LG", "date": "2025-02-24", "updated": "2025-07-16", "AI": {"title_translation": "FADE：为什么好的特征会遇到糟糕的描述", "tldr": "本文引入了FADE框架，一个可扩展、模型无关的工具，用于自动评估大型语言模型中特征与其文本描述的对齐质量，并揭示了当前描述生成所面临的挑战。", "motivation": "机械可解释性领域缺乏评估LLMs中发现特征有效性的标准化方法，尤其是在自动化可解释性管道中，这阻碍了对模型内部机制的深入理解。", "method": "本文提出了FADE（Feature Alignment to Description Evaluation），一个可扩展且模型无关的框架。FADE通过评估清晰度、响应性、纯度和忠实度这四个关键指标来量化特征到描述的对齐程度，并系统地识别不对齐的原因。该框架被应用于分析开源特征描述和自动化可解释性管道的关键组件。", "result": "FADE的应用揭示了生成高质量特征描述所面临的基本挑战，特别是对于稀疏自编码器（SAE）而非多层感知机（MLP）神经元。这些发现为自动化可解释性的局限性和未来发展方向提供了关键见解。", "conclusion": "FADE框架为自动化可解释性管道中特征描述的质量评估提供了一个急需的标准化工具，并明确指出了在为SAE生成高质量特征描述方面的挑战，为未来研究和改进自动化可解释性方法奠定了基础。", "translation": "近期机械可解释性的进展突显了自动化可解释性管道在分析大型语言模型（LLMs）内部潜在表示方面的潜力。虽然这可能增强我们对内部机制的理解，但该领域缺乏评估所发现特征有效性的标准化方法。我们试图通过引入FADE：特征对齐到描述评估来弥补这一空白，这是一个可扩展、模型无关的框架，用于自动评估特征到描述的对齐。FADE通过四个关键指标——清晰度、响应性、纯度和忠实度——评估对齐情况，并系统地量化了特征与其描述之间不对齐的原因。我们将FADE应用于分析现有开源特征描述，并评估自动化可解释性管道的关键组件，旨在提高描述的质量。我们的发现突出了生成特征描述方面的基本挑战，特别是对于SAE（稀疏自编码器）而非MLP神经元，为自动化可解释性的局限性和未来方向提供了见解。我们以开源包的形式发布FADE，网址为：https://github.com/brunibrun/FADE", "summary": "本文提出了FADE（Feature Alignment to Description Evaluation）框架，旨在解决大型语言模型（LLMs）中特征描述有效性评估的标准化问题。FADE是一个可扩展、模型无关的工具，通过清晰度、响应性、纯度和忠实度四个指标来自动评估特征与描述的对齐程度，并量化不对齐的原因。研究通过应用FADE发现，在自动化可解释性中，为稀疏自编码器（SAE）生成高质量特征描述比为多层感知机（MLP）神经元更具挑战性，从而揭示了自动化可解释性的当前局限性并指明了未来研究方向。", "keywords": "机械可解释性, 特征描述, LLM, 评估框架, FADE", "comments": "FADE框架的提出为当前新兴的机械可解释性领域提供了一个关键的评估工具，解决了LLM特征描述缺乏标准化评估的痛点。其创新性在于不仅提出了量化对齐的方法，还通过实证分析揭示了不同类型特征（SAE vs. MLP）在描述生成上的差异，这对于指导未来自动化可解释性工具的开发和改进具有重要指导意义。"}}
{"id": "2507.12373", "title": "Emerging Paradigms in the Energy Sector: Forecasting and System Control Optimisation", "authors": ["Dariush Pourkeramati", "Gareth Wadge", "Rachel Hassall", "Charlotte Mitchell", "Anish Khadka", "Shiwang Jaiswal", "Andrew Duncan", "Rossella Arcucci"], "categories": ["cs.ET"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12373v1", "summary": "The energy sector is experiencing rapid transformation due to increasing\nrenewable energy integration, decentralisation of power systems, and a\nheightened focus on efficiency and sustainability. With energy demand becoming\nincreasingly dynamic and generation sources more variable, advanced forecasting\nand optimisation strategies are crucial for maintaining grid stability,\ncost-effectiveness, and environmental sustainability. This paper explores\nemerging paradigms in energy forecasting and management, emphasizing four\ncritical domains: Energy Demand Forecasting integrated with Weather Data,\nBuilding Energy Optimisation, Heat Network Optimisation, and Energy Management\nSystem (EMS) Optimisation within a System of Systems (SoS) framework.\nLeveraging machine learning techniques and Model Predictive Control (MPC), the\nstudy demonstrates substantial enhancements in energy efficiency across scales\n-- from individual buildings to complex interconnected energy networks.\nWeather-informed demand forecasting significantly improves grid resilience and\nresource allocation strategies. Smart building optimisation integrates\npredictive analytics to substantially reduce energy consumption without\ncompromising occupant comfort. Optimising CHP-based heat networks achieves cost\nand carbon savings while adhering to operational and asset constraints. At the\nsystems level, sophisticated EMS optimisation ensures coordinated control of\ndistributed resources, storage solutions, and demand-side flexibility. Through\nreal-world case studies we highlight the potential of AI-driven automation and\nintegrated control solutions in facilitating a resilient, efficient, and\nsustainable energy future.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12373v1", "cate": "cs.ET", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "能源领域的新兴范式：预测与系统控制优化", "tldr": "本文探讨了能源领域中，利用机器学习和模型预测控制在四个关键领域（能源需求预测、建筑能源优化、热力网络优化和能源管理系统优化）实现能源效率提升和系统优化的新兴范式。", "motivation": "能源领域正经历快速转型，可再生能源整合增加、电力系统去中心化以及对效率和可持续性的高度关注，使得能源需求更具动态性，发电来源更具可变性。因此，先进的预测和优化策略对于维持电网稳定性、成本效益和环境可持续性至关重要。", "method": "本文探索了能源预测和管理中的新兴范式，重点关注四个关键领域：结合天气数据的能源需求预测、建筑能源优化、热力网络优化以及系统之系统(SoS)框架内的能源管理系统(EMS)优化。方法上利用了机器学习技术和模型预测控制(MPC)。通过真实案例研究进行验证。", "result": "研究表明，利用机器学习和模型预测控制，能源效率在不同尺度（从单个建筑到复杂的互联能源网络）上得到了显著提升。具体表现为：天气信息化的需求预测显著改善了电网弹性和资源分配策略；智能建筑优化在不影响居住者舒适度的情况下显著降低了能源消耗；优化基于热电联产的热力网络实现了成本和碳排放节约，同时遵守了运行和资产限制；在系统层面，复杂的EMS优化确保了分布式资源、储能解决方案和需求侧灵活性的协调控制。", "conclusion": "通过真实案例研究，本文强调了人工智能驱动的自动化和集成控制解决方案在促进弹性、高效和可持续能源未来方面的潜力。", "translation": "能源领域正经历快速转型，这得益于可再生能源整合的增加、电力系统的去中心化以及对效率和可持续性的高度关注。随着能源需求变得日益动态化和发电来源更具可变性，先进的预测和优化策略对于维持电网稳定性、成本效益和环境可持续性至关重要。本文探讨了能源预测和管理中的新兴范式，强调了四个关键领域：与天气数据相结合的能源需求预测、建筑能源优化、热力网络优化以及系统之系统（SoS）框架内的能源管理系统（EMS）优化。研究利用机器学习技术和模型预测控制（MPC），展示了在不同尺度（从单个建筑到复杂的互联能源网络）上能源效率的显著提升。天气信息化的需求预测显著改善了电网弹性和资源分配策略。智能建筑优化通过集成预测分析，在不影响居住者舒适度的情况下大幅降低了能源消耗。优化基于热电联产的热力网络实现了成本和碳排放节约，同时遵守了运行和资产限制。在系统层面，复杂的EMS优化确保了分布式资源、储能解决方案和需求侧灵活性的协调控制。通过真实案例研究，我们强调了人工智能驱动的自动化和集成控制解决方案在促进弹性、高效和可持续能源未来方面的潜力。", "summary": "本文探讨了在可再生能源整合和系统去中心化背景下，能源领域面临的挑战。研究提出并分析了四种新兴的能源预测和管理范式：集成天气数据的能源需求预测、建筑能源优化、热力网络优化和系统之系统框架下的能源管理系统优化。通过应用机器学习和模型预测控制，研究在不同尺度上显著提升了能源效率，并展示了AI驱动的自动化和集成控制解决方案在构建弹性、高效和可持续能源未来中的巨大潜力。", "keywords": "能源预测, 系统控制优化, 机器学习, 模型预测控制, 能源管理系统", "comments": "本文创新性地将机器学习和模型预测控制应用于能源领域的多个关键子系统，并强调了AI驱动的集成控制在应对当前能源转型挑战中的重要性。通过多尺度优化和真实案例研究，为构建更智能、更可持续的能源系统提供了有价值的见解和实践方向。"}}
{"id": "2507.11857", "title": "Measuring and predicting visual fidelity", "authors": ["Benjamin Watson", "Alinda Friedman", "Aaron McGaffey"], "categories": ["cs.GR", "cs.HC"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11857v1", "summary": "This paper is a study of techniques for measuring and predicting visual\nfidelity. As visual stimuli we use polygonal models, and vary their fidelity\nwith two different model simplification algorithms. We also group the stimuli\ninto two object types: animals and man made artifacts. We examine three\ndifferent experimental techniques for measuring these fidelity changes: naming\ntimes, ratings, and preferences. All the measures were sensitive to the type of\nsimplification and level of simplification. However, the measures differed from\none another in their response to object type. We also examine several automatic\ntechniques for predicting these experimental measures, including techniques\nbased on images and on the models themselves. Automatic measures of fidelity\nwere successful at predicting experimental ratings, less successful at\npredicting preferences, and largely failures at predicting naming times. We\nconclude with suggestions for use and improvement of the experimental and\nautomatic measures of visual fidelity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11857v1", "cate": "cs.GR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "测量和预测视觉保真度", "tldr": "本文研究了测量和预测视觉保真度的技术，使用多边形模型和不同的简化算法，并评估了命名时间、评分和偏好等实验测量方法以及基于图像和模型的自动预测方法。", "motivation": "本文旨在研究测量和预测视觉保真度的技术。", "method": "研究使用了多边形模型作为视觉刺激，并通过两种不同的模型简化算法改变其保真度。刺激分为动物和人造物品两类。实验测量技术包括命名时间、评分和偏好。自动预测技术则基于图像和模型本身。", "result": "所有实验测量方法都对简化类型和简化级别敏感，但它们对物体类型的反应不同。自动保真度测量在预测实验评分方面是成功的，在预测偏好方面不太成功，而在预测命名时间方面则基本失败。", "conclusion": "论文最后提出了关于视觉保真度的实验和自动测量方法的使用和改进建议。", "translation": "本文研究了测量和预测视觉保真度的技术。我们使用多边形模型作为视觉刺激，并通过两种不同的模型简化算法改变其保真度。我们还将刺激分为两类物体：动物和人造物品。我们研究了三种不同的实验技术来测量这些保真度变化：命名时间、评分和偏好。所有测量方法都对简化类型和简化级别敏感。然而，这些测量方法在对物体类型的反应上彼此不同。我们还研究了几种预测这些实验测量的自动技术，包括基于图像和模型本身的技术。自动保真度测量在预测实验评分方面是成功的，在预测偏好方面不太成功，而在预测命名时间方面则基本失败。最后，我们对视觉保真度的实验和自动测量方法的使用和改进提出了建议。", "summary": "本文研究了测量和预测视觉保真度的技术。通过使用多边形模型，并利用不同的简化算法和物体类型（动物和人造物品）来改变视觉刺激的保真度。研究评估了命名时间、评分和偏好等实验测量方法，以及基于图像和模型的自动预测技术。结果显示，实验测量对简化类型和级别敏感，但对物体类型的反应不同。自动方法在预测评分方面表现良好，但在预测偏好方面效果较差，在预测命名时间方面则基本失败。论文最后对这些测量和预测方法的应用和改进提出了建议。", "keywords": "视觉保真度, 多边形模型, 模型简化, 感知测量, 自动预测", "comments": "本文探讨了视觉感知领域的一个重要问题，即如何量化和预测视觉保真度。其创新之处在于结合了人类感知实验与自动预测技术，并详细分析了不同测量方法对不同因素（如简化类型、物体类型）的敏感性。论文揭示了自动预测方法在不同感知任务（如评分、偏好、命名时间）上的表现差异，这对于开发更有效的视觉质量评估工具具有重要指导意义。"}}
{"id": "2507.12041", "title": "Granular feedback merits sophisticated aggregation", "authors": ["Anmol Kagrecha", "Henrik Marklund", "Potsawee Manakul", "Richard Zeckhauser", "Benjamin Van Roy"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      31 pages, 8 figures", "url": "http://arxiv.org/abs/2507.12041v1", "summary": "Human feedback is increasingly used across diverse applications like training\nAI models, developing recommender systems, and measuring public opinion -- with\ngranular feedback often being preferred over binary feedback for its greater\ninformativeness. While it is easy to accurately estimate a population's\ndistribution of feedback given feedback from a large number of individuals,\ncost constraints typically necessitate using smaller groups. A simple method to\napproximate the population distribution is regularized averaging: compute the\nempirical distribution and regularize it toward a prior. Can we do better? As\nwe will discuss, the answer to this question depends on feedback granularity.\n  Suppose one wants to predict a population's distribution of feedback using\nfeedback from a limited number of individuals. We show that, as feedback\ngranularity increases, one can substantially improve upon predictions of\nregularized averaging by combining individuals' feedback in ways more\nsophisticated than regularized averaging.\n  Our empirical analysis using questions on social attitudes confirms this\npattern. In particular, with binary feedback, sophistication barely reduces the\nnumber of individuals required to attain a fixed level of performance. By\ncontrast, with five-point feedback, sophisticated methods match the performance\nof regularized averaging with about half as many individuals.", "comment": "31 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.12041v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "细粒度反馈值得复杂的聚合", "tldr": "当反馈是细粒度时，使用比正则化平均更复杂的聚合方法可以显著提高对总体反馈分布的预测，从而减少所需个体数量。", "motivation": "在训练AI模型、开发推荐系统和衡量公众舆论等应用中，细粒度人类反馈因其信息量大而被广泛使用。然而，成本限制通常导致只能获取有限数量的个体反馈。现有的简单方法如正则化平均可能不足以充分利用细粒度反馈的潜力，因此需要探索是否存在更优的聚合方法来准确预测总体反馈分布。", "method": "研究通过结合个体反馈，采用比正则化平均更复杂的聚合方式来预测人口反馈分布。论文通过对社会态度问题的实证分析来验证这种方法的效果，并比较了不同反馈粒度（如二元反馈和五点反馈）下复杂方法与正则化平均的表现。", "result": "研究发现，随着反馈粒度的增加，复杂聚合方法可以显著改善正则化平均的预测效果。具体而言，对于二元反馈，复杂方法在减少所需个体数量方面几乎没有优势；然而，对于五点反馈，复杂方法只需约一半的个体数量即可达到与正则化平均相同的性能水平。", "conclusion": "对于细粒度反馈，应采用比简单正则化平均更复杂的聚合方法，因为这能显著提高预测准确性并有效减少所需的数据量或个体数量，从而在成本受限的应用中提供更好的性能。", "translation": "人类反馈越来越多地应用于各种应用，如训练人工智能模型、开发推荐系统和衡量公众舆论——其中细粒度反馈因其信息量更大而常被优选而非二元反馈。虽然在给定大量个体反馈的情况下，准确估计人口反馈分布很容易，但成本限制通常需要使用较小的群体。近似人口分布的一个简单方法是正则化平均：计算经验分布并将其正则化到一个先验。我们能做得更好吗？正如我们将讨论的，这个问题的答案取决于反馈粒度。假设一个人想用有限数量的个体反馈来预测人口的反馈分布。我们表明，随着反馈粒度的增加，通过比正则化平均更复杂的方式结合个体反馈，可以显著改善正则化平均的预测。我们对社会态度问题的实证分析证实了这种模式。特别是，对于二元反馈，复杂性几乎不减少达到固定性能水平所需的个体数量。相比之下，对于五点反馈，复杂方法可以以大约一半的个体数量达到与正则化平均相同的性能。", "summary": "这篇论文探讨了在有限数据量下，如何更有效地聚合人类反馈以预测总体分布。研究指出，对于细粒度反馈，采用比传统正则化平均更复杂的聚合方法能显著提高预测准确性，并减少所需样本量。实证分析表明，这种优势在二元反馈中不明显，但在五点反馈中，复杂方法能以更少的个体达到相同的性能。", "keywords": "细粒度反馈, 反馈聚合, 正则化平均, 预测, 样本效率", "comments": "这篇论文的创新点在于强调了反馈粒度对聚合方法选择的重要性。它挑战了简单正则化平均的普适性，并指出对于信息量更大的细粒度反馈，更复杂的聚合策略能带来显著的效率提升。这对于AI训练、推荐系统和民意调查等依赖人类反馈的领域具有重要实践意义，能帮助在成本受限的情况下获取更准确的群体洞察。"}}
{"id": "2507.11794", "title": "Real-Time Cloth Simulation Using WebGPU: Evaluating Limits of High-Resolution", "authors": ["Nak-Jun Sung", "Jun Ma", "TaeHeon Kim", "Yoo-joo Choi", "Min-Hyung Choi", "Min Hong"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11794v1", "summary": "This study explores the capabilities of WebGPU, an emerging web graphics\nparadigm, for real-time cloth simulation. Traditional WebGL-based methods have\nbeen in handling complex physical simulations due to their emphasis on graphics\nrendering rather than general-purpose GPU (GPGPU) operations. WebGPU, designed\nto provide modern 3D graphics and computational capabilities, offers\nsignificant improvements through parallel processing and support for\ncomputational shaders. In this work, we implemented a cloth simulation system\nusing the Mass-Spring Method within the WebGPU framework, integrating collision\ndetection and response handling with the 3D surface model. First, comparative\nperformance evaluations demonstrate that WebGPU substantially outperforms\nWebGL, particularly in high-resolution simulations, maintaining 60 frames per\nsecond (fps) even with up to 640K nodes. The second experiment aimed to\ndetermine the real-time limitations of WebGPU and confirmed that WebGPU can\nhandle real-time collisions between 4K and 100k cloth node models and a 100K\ntriangle surface model in real-time. These experiments also highlight the\nimportance of balancing real-time performance with realistic rendering when\nhandling collisions between cloth models and complex 3D objects. Our source\ncode is available at https://github.com/nakjun/Cloth-Simulation-WebGPU", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11794v1", "cate": "cs.GR", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "使用WebGPU进行实时布料模拟：评估高分辨率的极限", "tldr": "本研究探索了WebGPU在实时高分辨率布料模拟中的能力，发现它在性能上显著优于WebGL，并能处理复杂的实时碰撞。", "motivation": "传统WebGL在复杂物理模拟方面表现不佳，因为它侧重图形渲染而非GPGPU操作。WebGPU作为新兴技术，提供现代3D图形和计算能力，通过并行处理和计算着色器带来显著提升，因此本研究旨在探索其在实时布料模拟中的潜力。", "method": "研究人员在WebGPU框架内使用质量-弹簧方法实现了布料模拟系统，并集成了与3D表面模型的碰撞检测和响应处理。通过比较性能评估和确定实时限制的实验来验证其能力。", "result": "WebGPU在性能上显著优于WebGL，尤其在高分辨率模拟中，即使在高达64万个节点的情况下也能保持60帧/秒。WebGPU可以实时处理4K到10万个布料节点模型与10万个三角形表面模型之间的碰撞。", "conclusion": "WebGPU能够有效进行高分辨率实时布料模拟，并处理复杂的实时碰撞。研究强调了在处理布料模型与复杂3D对象碰撞时，平衡实时性能与真实感渲染的重要性。", "translation": "本研究探讨了WebGPU（一种新兴的网页图形范式）在实时布料模拟中的能力。传统的基于WebGL的方法在处理复杂物理模拟方面一直存在不足，因为它们侧重于图形渲染而非通用GPU（GPGPU）操作。WebGPU旨在提供现代3D图形和计算能力，通过并行处理和对计算着色器的支持，提供了显著的改进。在这项工作中，我们使用WebGPU框架内的质量-弹簧方法实现了一个布料模拟系统，并集成了与3D表面模型的碰撞检测和响应处理。首先，比较性能评估表明，WebGPU显著优于WebGL，特别是在高分辨率模拟中，即使在高达64万个节点的情况下也能保持每秒60帧（fps）。第二个实验旨在确定WebGPU的实时限制，并证实WebGPU可以实时处理4K到10万个布料节点模型与10万个三角形表面模型之间的实时碰撞。这些实验还强调了在处理布料模型与复杂3D对象碰撞时，平衡实时性能与真实感渲染的重要性。我们的源代码可在https://github.com/nakjun/Cloth-Simulation-WebGPU获取。", "summary": "本研究评估了WebGPU在实时高分辨率布料模拟中的潜力。针对传统WebGL在复杂物理模拟上的不足，研究者利用WebGPU的并行处理和计算着色器能力，实现了基于质量-弹簧法的布料模拟系统，并集成了碰撞检测。实验结果表明，WebGPU在性能上显著超越WebGL，在高分辨率下仍能保持高帧率，并能有效处理布料与复杂3D模型的实时碰撞，为网页端复杂物理模拟提供了可行方案。", "keywords": "WebGPU, 实时布料模拟, 高分辨率, 质量-弹簧方法, 碰撞检测", "comments": "这篇论文创新性地将WebGPU应用于实时高分辨率布料模拟，解决了传统WebGL在GPGPU操作方面的局限性。其重要性在于展示了WebGPU在复杂物理模拟领域的强大潜力，为网页端高性能图形应用开辟了新途径。论文通过具体的性能数据验证了WebGPU的优越性，并探讨了其实时处理复杂碰撞的能力，为未来的网页图形开发提供了宝贵的参考。"}}
{"id": "2412.10543", "title": "METIS: Fast Quality-Aware RAG Systems with Configuration Adaptation", "authors": ["Siddhant Ray", "Rui Pan", "Zhuohan Gu", "Kuntai Du", "Shaoting Feng", "Ganesh Ananthanarayanan", "Ravi Netravali", "Junchen Jiang"], "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      17 pages, 18 figures", "url": "http://arxiv.org/abs/2412.10543v2", "summary": "RAG (Retrieval Augmented Generation) allows LLMs (large language models) to\ngenerate better responses with external knowledge, but using more external\nknowledge often improves generation quality at the expense of response delay.\nPrior work either reduces the response delay (through better scheduling of RAG\nqueries) or strives to maximize quality (which involves tuning the RAG\nworkflow), but they fall short in optimizing the tradeoff between the delay and\nquality of RAG responses. This paper presents METIS, the first RAG system that\njointly schedules queries and adapts the key RAG configurations of each query,\nsuch as the number of retrieved text chunks and synthesis methods, in order to\nbalance quality optimization and response delay reduction. Using 4 popular\nRAG-QA datasets, we show that compared with the state-of-the-art RAG\noptimization schemes, METIS reduces the generation latency by $1.64-2.54\\times$\nwithout sacrificing generation quality.", "comment": "17 pages, 18 figures", "pdf_url": "http://arxiv.org/pdf/2412.10543v2", "cate": "cs.LG", "date": "2024-12-13", "updated": "2025-07-16", "AI": {"title_translation": "METIS: 具有配置自适应的快速质量感知RAG系统", "tldr": "METIS是一个RAG系统，它通过联合调度查询和自适应关键RAG配置来平衡响应质量和延迟，从而在不牺牲质量的情况下显著降低生成延迟。", "motivation": "RAG系统在利用外部知识提高LLM响应质量的同时，也面临着响应延迟增加的问题。现有工作未能有效权衡延迟和质量之间的优化。", "method": "本文提出了METIS系统，它是第一个联合调度查询并自适应每个查询关键RAG配置（如检索文本块数量和合成方法）的RAG系统，以平衡质量优化和响应延迟降低。", "result": "在4个流行的RAG-QA数据集上，METIS与最先进的RAG优化方案相比，在不牺牲生成质量的情况下，将生成延迟降低了1.64-2.54倍。", "conclusion": "METIS通过联合调度和配置自适应，有效解决了RAG系统中质量与延迟之间的权衡问题，显著提升了RAG系统的性能。", "translation": "RAG（检索增强生成）允许大型语言模型（LLM）利用外部知识生成更好的响应，但使用更多的外部知识通常以响应延迟为代价来提高生成质量。先前的研究要么通过更好地调度RAG查询来减少响应延迟，要么努力最大化质量（这涉及调整RAG工作流），但它们在优化RAG响应的延迟和质量之间的权衡方面存在不足。本文提出了METIS，这是第一个联合调度查询并自适应每个查询关键RAG配置（例如检索文本块的数量和合成方法）的RAG系统，以平衡质量优化和响应延迟的减少。使用4个流行的RAG-QA数据集，我们表明，与最先进的RAG优化方案相比，METIS在不牺牲生成质量的情况下，将生成延迟降低了1.64-2.54倍。", "summary": "METIS是一个创新的RAG系统，旨在解决现有RAG方案中响应质量与延迟之间的权衡问题。它通过首次联合调度RAG查询并动态调整关键RAG配置（如检索块数量和合成方法），实现了在不牺牲生成质量的前提下，显著降低生成延迟（1.64-2.54倍）。", "keywords": "RAG系统, 延迟优化, 质量感知, 配置自适应, LLM", "comments": "METIS的创新之处在于其联合调度和配置自适应的方法，有效解决了RAG系统中的核心挑战——性能与质量的平衡。这对于提升实际RAG应用的效率和用户体验具有重要意义。"}}
{"id": "2505.18384", "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents", "authors": ["Boyi Wei", "Benedikt Stroebl", "Jiacen Xu", "Joie Zhang", "Zhou Li", "Peter Henderson"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      26 pages, 11 figures", "url": "http://arxiv.org/abs/2505.18384v3", "summary": "Foundation models are increasingly becoming better autonomous programmers,\nraising the prospect that they could also automate dangerous offensive\ncyber-operations. Current frontier model audits probe the cybersecurity risks\nof such agents, but most fail to account for the degrees of freedom available\nto adversaries in the real world. In particular, with strong verifiers and\nfinancial incentives, agents for offensive cybersecurity are amenable to\niterative improvement by would-be adversaries. We argue that assessments should\ntake into account an expanded threat model in the context of cybersecurity,\nemphasizing the varying degrees of freedom that an adversary may possess in\nstateful and non-stateful environments within a fixed compute budget. We show\nthat even with a relatively small compute budget (8 H100 GPU Hours in our\nstudy), adversaries can improve an agent's cybersecurity capability on\nInterCode CTF by more than 40\\% relative to the baseline -- without any\nexternal assistance. These results highlight the need to evaluate agents'\ncybersecurity risk in a dynamic manner, painting a more representative picture\nof risk.", "comment": "26 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2505.18384v3", "cate": "cs.CR", "date": "2025-05-23", "updated": "2025-07-16", "AI": {"title_translation": "攻击性网络安全代理的动态风险评估", "tldr": "现有对AI网络安全代理的风险评估未考虑真实世界中对手的迭代改进能力，研究表明即使计算资源有限，对手也能显著提升AI代理的攻击能力，因此需要动态评估风险。", "motivation": "基础模型日益成为自主程序员，可能自动化危险的攻击性网络操作。当前对这些代理的网络安全风险审计未能充分考虑对手在现实世界中可用的自由度，特别是对手可以通过迭代改进来增强攻击性网络安全代理。", "method": "本文提出评估应考虑扩展的威胁模型，强调对手在固定计算预算下，在有状态和无状态环境中可能拥有的不同自由度。通过实验，作者展示了即使使用相对较小的计算预算（8 H100 GPU小时），对手也能在InterCode CTF上将代理的网络安全能力相对于基线提高40%以上，且无需外部协助。", "result": "在8 H100 GPU小时的计算预算下，对手可以将InterCode CTF上代理的网络安全能力相对基线提高40%以上，且无需外部协助。", "conclusion": "这些结果强调需要以动态方式评估代理的网络安全风险，以描绘更具代表性的风险图景。", "translation": "基础模型正日益成为更优秀的自主程序员，这带来了它们也可能自动化危险的攻击性网络操作的可能性。当前的尖端模型审计会探测此类代理的网络安全风险，但大多数未能考虑到对手在现实世界中可用的自由度。特别是，在强大的验证器和财务激励下，攻击性网络安全代理易于被潜在对手进行迭代改进。我们认为，评估应在网络安全背景下考虑扩展的威胁模型，强调对手在固定计算预算下，在有状态和无状态环境中可能拥有的不同自由度。我们展示了即使在相对较小的计算预算（我们研究中的8 H100 GPU小时）下，对手也能在InterCode CTF上将代理的网络安全能力相对于基线提高40%以上——无需任何外部协助。这些结果突出表明需要以动态方式评估代理的网络安全风险，描绘出更具代表性的风险图景。", "summary": "本文探讨了基础模型在自动化攻击性网络操作方面的风险评估。研究指出，现有评估未能充分考虑真实世界中对手通过迭代改进提升AI代理攻击能力的可能性。作者提出应采用扩展的威胁模型，考虑对手在不同环境和固定计算预算下的自由度。实验证明，即使仅用8小时的H100 GPU计算资源，对手也能将AI代理在InterCode CTF上的网络安全能力提升超过40%。这强调了对AI网络安全代理进行动态风险评估的必要性，以更准确地反映实际风险。", "keywords": "动态风险评估, 攻击性网络安全, 基础模型, 对手能力, 网络安全代理", "comments": "本文的创新之处在于提出了动态风险评估的概念，并扩展了AI网络安全代理的威胁模型，考虑了对手通过迭代改进提升攻击能力的可能性。其重要性在于揭示了当前AI安全审计的潜在盲点，即未能充分考虑真实世界中对手的适应性和演化能力。研究结果令人警醒，表明即使是有限的计算资源，也足以让恶意行为者显著增强AI驱动的攻击能力，这对于AI安全研究和政策制定具有重要的指导意义。"}}
{"id": "2506.23234", "title": "From Release to Adoption: Challenges in Reusing Pre-trained AI Models for Downstream Developers", "authors": ["Peerachai Banyongrakkul", "Mansooreh Zahedi", "Patanamon Thongtanunam", "Christoph Treude", "Haoyu Gao"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Recently accepted at ICSME 2025", "url": "http://arxiv.org/abs/2506.23234v2", "summary": "Pre-trained models (PTMs) have gained widespread popularity and achieved\nremarkable success across various fields, driven by their groundbreaking\nperformance and easy accessibility through hosting providers. However, the\nchallenges faced by downstream developers in reusing PTMs in software systems\nare less explored. To bridge this knowledge gap, we qualitatively created and\nanalyzed a dataset of 840 PTM-related issue reports from 31 OSS GitHub\nprojects. We systematically developed a comprehensive taxonomy of PTM-related\nchallenges that developers face in downstream projects. Our study identifies\nseven key categories of challenges that downstream developers face in reusing\nPTMs, such as model usage, model performance, and output quality. We also\ncompared our findings with existing taxonomies. Additionally, we conducted a\nresolution time analysis and, based on statistical tests, found that\nPTM-related issues take significantly longer to be resolved than issues\nunrelated to PTMs, with significant variation across challenge categories. We\ndiscuss the implications of our findings for practitioners and possibilities\nfor future research.", "comment": "Recently accepted at ICSME 2025", "pdf_url": "http://arxiv.org/pdf/2506.23234v2", "cate": "cs.SE", "date": "2025-06-29", "updated": "2025-07-16", "AI": {"title_translation": "从发布到采用：下游开发者复用预训练AI模型的挑战", "tldr": "本研究通过分析GitHub问题报告，识别并分类了下游开发者在使用预训练模型时面临的七大挑战，发现这些问题的解决时间显著长于非预训练模型问题。", "motivation": "预训练模型（PTMs）虽然普及且易于获取，但下游开发者在软件系统中复用PTMs所面临的挑战却鲜有探索，本研究旨在弥补这一知识空白。", "method": "研究定性地创建并分析了来自31个开源GitHub项目的840份与预训练模型相关的问题报告，系统地开发了开发者在下游项目中面临的预训练模型相关挑战的综合分类法，并进行了解决时间分析。", "result": "研究识别出下游开发者在复用预训练模型时面临的七个关键挑战类别，如模型使用、模型性能和输出质量。研究还发现，与预训练模型相关的问题比不相关的问题需要更长的解决时间，并且不同挑战类别之间存在显著差异。", "conclusion": "本研究揭示了下游开发者在复用预训练模型时面临的实际挑战，并指出这些问题的解决耗时更长，为从业者提供了启示并指明了未来研究方向。", "translation": "预训练模型（PTMs）因其突破性的性能和通过托管服务提供商易于获取的特点，已在各个领域获得广泛普及并取得了显著成功。然而，下游开发者在软件系统中复用PTMs所面临的挑战却鲜有探索。为了弥补这一知识空白，我们定性地创建并分析了来自31个开源GitHub项目的840份与PTM相关的问题报告数据集。我们系统地开发了一个全面的PTM相关挑战分类法，这些挑战是开发者在下游项目中面临的。我们的研究识别出下游开发者在复用PTMs时面临的七个关键挑战类别，例如模型使用、模型性能和输出质量。我们还将我们的发现与现有分类法进行了比较。此外，我们进行了解决时间分析，并基于统计测试发现，与PTM相关的问题比与PTM无关的问题需要显著更长的时间来解决，并且在不同挑战类别之间存在显著差异。我们讨论了我们的发现对从业者的影响以及未来研究的可能性。", "summary": "本文旨在填补预训练模型（PTMs）在下游开发中复用挑战研究的空白。通过分析840份GitHub问题报告，研究构建了一个全面的挑战分类法，识别出模型使用、性能、输出质量等七大挑战类别。结果显示，与PTMs相关的问题解决时间显著长于非PTMs问题，且各类别间存在差异。研究为从业者提供了见解，并指明了未来研究方向。", "keywords": "预训练模型, 复用挑战, 下游开发, 问题报告, 分类法", "comments": "这项研究通过对真实世界GitHub问题报告的定性分析，揭示了预训练模型在实际应用中面临的挑战，具有很强的实践意义。其创新之处在于构建了一个系统的挑战分类法，并量化了解决这些问题所需的时间，为未来的模型发布者和下游开发者提供了宝贵的指导。"}}
{"id": "2507.12001", "title": "AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation", "authors": ["Hao Li", "Ju Dai", "Feng Zhou", "Kaida Ning", "Lei Li", "Junjun Pan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.12001v1", "summary": "While 3D facial animation has made impressive progress, challenges still\nexist in realizing fine-grained stylized 3D facial expression manipulation due\nto the lack of appropriate datasets. In this paper, we introduce the\nAUBlendSet, a 3D facial dataset based on AU-Blendshape representation for\nfine-grained facial expression manipulation across identities. AUBlendSet is a\nblendshape data collection based on 32 standard facial action units (AUs)\nacross 500 identities, along with an additional set of facial postures\nannotated with detailed AUs. Based on AUBlendSet, we propose AUBlendNet to\nlearn AU-Blendshape basis vectors for different character styles. AUBlendNet\npredicts, in parallel, the AU-Blendshape basis vectors of the corresponding\nstyle for a given identity mesh, thereby achieving stylized 3D emotional facial\nmanipulation. We comprehensively validate the effectiveness of AUBlendSet and\nAUBlendNet through tasks such as stylized facial expression manipulation,\nspeech-driven emotional facial animation, and emotion recognition data\naugmentation. Through a series of qualitative and quantitative experiments, we\ndemonstrate the potential and importance of AUBlendSet and AUBlendNet in 3D\nfacial animation tasks. To the best of our knowledge, AUBlendSet is the first\ndataset, and AUBlendNet is the first network for continuous 3D facial\nexpression manipulation for any identity through facial AUs. Our source code is\navailable at https://github.com/wslh852/AUBlendNet.git.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.12001v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "AU-Blendshape用于精细化风格化3D面部表情操纵", "tldr": "本文提出了AUBlendSet数据集和AUBlendNet网络，用于通过面部动作单元（AUs）实现精细化风格化的3D面部表情操纵。", "motivation": "由于缺乏合适的数据集，实现精细化风格化的3D面部表情操纵仍然面临挑战。", "method": "本文引入了AUBlendSet，一个基于AU-Blendshape表示的3D面部数据集，用于跨身份的精细化面部表情操纵。该数据集包含基于32个标准面部动作单元（AUs）的混合形数据，涵盖500个身份。在此基础上，提出了AUBlendNet网络，用于学习不同角色风格的AU-Blendshape基础向量，从而实现风格化的3D情感面部操纵。", "result": "通过风格化面部表情操纵、语音驱动情感面部动画和情感识别数据增强等任务，全面验证了AUBlendSet和AUBlendNet的有效性。定性和定量实验证明了它们在3D面部动画任务中的潜力和重要性。", "conclusion": "AUBlendSet是首个通过面部AUs对任意身份进行连续3D面部表情操纵的数据集，而AUBlendNet是首个实现此功能的网络，它们在3D面部动画任务中展现了潜力和重要性。", "translation": "尽管3D面部动画取得了令人瞩目的进展，但由于缺乏合适的数据集，实现精细化风格化的3D面部表情操纵仍然存在挑战。在本文中，我们引入了AUBlendSet，一个基于AU-Blendshape表示的3D面部数据集，用于跨身份的精细化面部表情操纵。AUBlendSet是一个混合形数据集合，基于500个身份的32个标准面部动作单元（AUs），以及一套额外标注了详细AUs的面部姿态。基于AUBlendSet，我们提出了AUBlendNet来学习不同角色风格的AU-Blendshape基础向量。AUBlendNet并行预测给定身份网格的相应风格的AU-Blendshape基础向量，从而实现风格化的3D情感面部操纵。我们通过风格化面部表情操纵、语音驱动情感面部动画和情感识别数据增强等任务，全面验证了AUBlendSet和AUBlendNet的有效性。通过一系列定性和定量实验，我们证明了AUBlendSet和AUBlendNet在3D面部动画任务中的潜力和重要性。据我们所知，AUBlendSet是首个数据集，而AUBlendNet是首个通过面部AUs对任意身份进行连续3D面部表情操纵的网络。我们的源代码可在https://github.com/wslh852/AUBlendNet.git获取。", "summary": "本文针对3D面部表情操纵中缺乏合适数据集的挑战，提出了一套解决方案。核心贡献是AUBlendSet，一个基于AU-Blendshape的3D面部数据集，包含500个身份的32个AU数据。在此基础上，开发了AUBlendNet，一个能够学习并预测不同风格AU-Blendshape基础向量的网络，从而实现精细化、风格化的3D情感面部操纵。该方法通过多项任务验证了其有效性，显著提升了3D面部动画的潜能。AUBlendSet和AUBlendNet被认为是首次实现通过AU对任意身份进行连续3D面部表情操纵的数据集和网络。", "keywords": "AU-Blendshape, 3D面部表情, 风格化操纵, 数据集, 神经网络", "comments": "该论文的创新之处在于解决了3D面部表情操纵中数据稀缺的关键问题，并首次提出了能够实现任意身份连续、风格化3D面部表情操纵的数据集（AUBlendSet）和网络（AUBlendNet）。这为更可控和富有表现力的3D面部动画提供了新的方法和基础。"}}
{"id": "2507.12359", "title": "Cluster Contrast for Unsupervised Visual Representation Learning", "authors": ["Nikolaos Giakoumoglou", "Tania Stathaki"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICIP 2025", "url": "http://arxiv.org/abs/2507.12359v1", "summary": "We introduce Cluster Contrast (CueCo), a novel approach to unsupervised\nvisual representation learning that effectively combines the strengths of\ncontrastive learning and clustering methods. Inspired by recent advancements,\nCueCo is designed to simultaneously scatter and align feature representations\nwithin the feature space. This method utilizes two neural networks, a query and\na key, where the key network is updated through a slow-moving average of the\nquery outputs. CueCo employs a contrastive loss to push dissimilar features\napart, enhancing inter-class separation, and a clustering objective to pull\ntogether features of the same cluster, promoting intra-class compactness. Our\nmethod achieves 91.40% top-1 classification accuracy on CIFAR-10, 68.56% on\nCIFAR-100, and 78.65% on ImageNet-100 using linear evaluation with a ResNet-18\nbackbone. By integrating contrastive learning with clustering, CueCo sets a new\ndirection for advancing unsupervised visual representation learning.", "comment": "ICIP 2025", "pdf_url": "http://arxiv.org/pdf/2507.12359v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "用于无监督视觉表示学习的聚类对比", "tldr": "CueCo是一种结合对比学习和聚类的新型无监督视觉表示学习方法，在多个数据集上取得了高分类精度。", "motivation": "该研究旨在结合对比学习和聚类方法的优点，以有效进行无监督视觉表示学习，同时在特征空间中分散和对齐特征表示。", "method": "CueCo使用两个神经网络（查询网络和键网络），其中键网络通过查询输出的慢速移动平均进行更新。它采用对比损失来分离不相似的特征以增强类间分离，并使用聚类目标来聚集同一聚类的特征以促进类内紧凑性。", "result": "CueCo在CIFAR-10上实现了91.40%的top-1分类精度，在CIFAR-100上实现了68.56%的top-1分类精度，在ImageNet-100上实现了78.65%的top-1分类精度，均使用ResNet-18骨干进行线性评估。", "conclusion": "通过将对比学习与聚类相结合，CueCo为推进无监督视觉表示学习开辟了新方向。", "translation": "我们引入了聚类对比（CueCo），这是一种新颖的无监督视觉表示学习方法，它有效地结合了对比学习和聚类方法的优点。受最新进展的启发，CueCo旨在同时在特征空间中分散和对齐特征表示。该方法利用两个神经网络，一个查询网络和一个键网络，其中键网络通过查询输出的慢速移动平均进行更新。CueCo采用对比损失来推开不相似的特征，增强类间分离，并采用聚类目标来拉近同一聚类的特征，促进类内紧凑性。我们的方法在使用ResNet-18骨干进行线性评估时，在CIFAR-10上取得了91.40%的top-1分类精度，在CIFAR-100上取得了68.56%的top-1分类精度，在ImageNet-100上取得了78.65%的top-1分类精度。通过将对比学习与聚类相结合，CueCo为推进无监督视觉表示学习开辟了新方向。", "summary": "CueCo是一种创新的无监督视觉表示学习方法，它巧妙地融合了对比学习和聚类技术的优势。该方法通过一个查询网络和一个键网络运作，并结合对比损失以增加类间分离，同时利用聚类目标以增强类内紧凑性。实验结果表明，CueCo在多个标准数据集上，如CIFAR-10、CIFAR-100和ImageNet-100，均取得了显著的分类性能，为无监督视觉表示学习领域指明了新的发展方向。", "keywords": "无监督学习, 视觉表示学习, 对比学习, 聚类, CueCo", "comments": "CueCo的创新之处在于其将对比学习和聚类方法有效结合，解决了传统方法可能存在的类内紧凑性或类间分离不足的问题。通过同时优化这两个目标，模型能够学习到更鲁棒和判别性的特征表示。其在多个数据集上取得的高精度证明了其方法的有效性和潜力，为无监督学习领域提供了一个有价值的新范式。"}}
{"id": "2502.17066", "title": "DUNIA: Pixel-Sized Embeddings via Cross-Modal Alignment for Earth Observation Applications", "authors": ["Ibrahim Fayad", "Max Zimmer", "Martin Schwartz", "Fabian Gieseke", "Philippe Ciais", "Gabriel Belouze", "Sarah Brood", "Aurelien De Truchis", "Alexandre d'Aspremont"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      26 pages, 8 figures", "url": "http://arxiv.org/abs/2502.17066v2", "summary": "Significant efforts have been directed towards adapting self-supervised\nmultimodal learning for Earth observation applications. However, most current\nmethods produce coarse patch-sized embeddings, limiting their effectiveness and\nintegration with other modalities like LiDAR. To close this gap, we present\nDUNIA, an approach to learn pixel-sized embeddings through cross-modal\nalignment between images and full-waveform LiDAR data. As the model is trained\nin a contrastive manner, the embeddings can be directly leveraged in the\ncontext of a variety of environmental monitoring tasks in a zero-shot setting.\nIn our experiments, we demonstrate the effectiveness of the embeddings for\nseven such tasks: canopy height mapping, fractional canopy cover, land cover\nmapping, tree species identification, plant area index, crop type\nclassification, and per-pixel waveform-based vertical structure mapping. The\nresults show that the embeddings, along with zero-shot classifiers, often\noutperform specialized supervised models, even in low-data regimes. In the\nfine-tuning setting, we show strong performances near or better than the\nstate-of-the-art on five out of six tasks.", "comment": "26 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2502.17066v2", "cate": "cs.CV", "date": "2025-02-24", "updated": "2025-07-16", "AI": {"title_translation": "DUNIA：通过跨模态对齐实现地球观测应用的像素级嵌入", "tldr": "DUNIA通过图像和LiDAR数据的跨模态对齐，学习像素级嵌入，在多种地球观测任务中表现出色，甚至超越一些监督模型。", "motivation": "当前地球观测应用中的自监督多模态学习方法生成的是粗糙的块级嵌入，这限制了它们的有效性以及与LiDAR等其他模态的集成。", "method": "提出DUNIA方法，通过图像和全波形LiDAR数据之间的跨模态对齐来学习像素级嵌入。模型以对比学习的方式训练，生成的嵌入可以直接用于各种环境监测任务的零样本设置。", "result": "实验证明，DUNIA嵌入在七项环境监测任务中有效，包括冠层高度测绘、分数冠层覆盖、土地覆盖测绘等。在零样本设置下，这些嵌入结合零样本分类器，即使在低数据量情况下也常优于专门的监督模型。在微调设置中，在六项任务中的五项上表现接近或优于当前最先进水平。", "conclusion": "DUNIA通过学习像素级嵌入，显著提升了地球观测应用中跨模态学习的有效性，并在零样本和微调设置下展现出超越或接近现有最佳方法的性能。", "translation": "大量精力已投入到使自监督多模态学习适应地球观测应用。然而，当前大多数方法产生的是粗糙的块级嵌入，这限制了它们的有效性以及与LiDAR等其他模态的集成。为了弥补这一差距，我们提出了DUNIA，一种通过图像和全波形LiDAR数据之间的跨模态对齐来学习像素级嵌入的方法。由于模型以对比学习的方式训练，这些嵌入可以直接用于各种环境监测任务的零样本设置。在我们的实验中，我们展示了这些嵌入在七项此类任务中的有效性：冠层高度测绘、分数冠层覆盖、土地覆盖测绘、树种识别、植物面积指数、作物类型分类以及基于像素波形的垂直结构测绘。结果表明，这些嵌入与零样本分类器结合使用时，即使在低数据量情况下，也常常优于专门的监督模型。在微调设置中，我们在六项任务中的五项上表现出接近或优于当前最先进水平的强大性能。", "summary": "DUNIA是一个新的框架，旨在通过图像和全波形LiDAR数据之间的跨模态对齐，生成用于地球观测应用的像素级嵌入。与现有产生粗糙块级嵌入的方法不同，DUNIA的像素级嵌入增强了多模态集成和有效性。该模型采用对比学习训练，使其嵌入在零样本设置下可直接用于多种环境监测任务，并在实验中显示出在七个任务上的优异表现，包括在低数据量下超越监督模型，并在微调设置中达到或超越最先进水平。", "keywords": "像素级嵌入, 跨模态对齐, 地球观测, LiDAR, 自监督学习", "comments": "DUNIA的创新在于其能够生成像素级而非传统的块级嵌入，这显著提升了地球观测中多模态数据（尤其是与LiDAR结合）的集成和利用效率。其在零样本和低数据量情境下的优异表现，凸显了其在实际环境监测应用中的巨大潜力，减少了对大量标注数据的依赖。"}}
{"id": "2507.10644", "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "authors": ["Tatiana Petrova", "Boris Bliznioukov", "Aleksandr Puzikov", "Radu State"], "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.HC", "cs.MA", "I.2.11; I.2.7; C.2.4; K.6.5; I.2.4"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      33 pages, 9 figures, 8 tables", "url": "http://arxiv.org/abs/2507.10644v2", "summary": "The concept of the Web of Agents (WoA), which transforms the static,\ndocument-centric Web into an environment of autonomous agents acting on users'\nbehalf, has attracted growing interest as large language models (LLMs) become\nmore capable. However, research in this area is still fragmented across\ndifferent communities. Contemporary surveys catalog the latest LLM-powered\nframeworks, while the rich histories of Multi-Agent Systems (MAS) and the\nSemantic Web are often treated as separate, legacy domains. This fragmentation\nobscures the intellectual lineage of modern systems and hinders a holistic\nunderstanding of the field's trajectory. We present the first comprehensive\nevolutionary overview of the WoA. We show that modern protocols like A2A and\nthe MCP, are direct evolutionary responses to the well-documented limitations\nof earlier standards like FIPA standards and OWL-based semantic agents. To\nsystematize this analysis, we introduce a four-axis taxonomy (semantic\nfoundation, communication paradigm, locus of intelligence, discovery\nmechanism). This framework provides a unified analytical lens for comparing\nagent architectures across all generations, revealing a clear line of descent\nwhere others have seen a disconnect. Our analysis identifies a paradigm shift\nin the 'locus of intelligence': from being encoded in external data (Semantic\nWeb) or the platform (MAS) to being embedded within the agent's core model\n(LLM). This shift is foundational to modern Agentic AI, enabling the scalable\nand adaptive systems the WoA has long envisioned. We conclude that while new\nprotocols are essential, they are insufficient for building a robust, open,\ntrustworthy ecosystem. Finally, we argue that the next research frontier lies\nin solving persistent socio-technical challenges, and we map out a new agenda\nfocused on decentralized identity, economic models, security, and governance\nfor the emerging WoA.", "comment": "33 pages, 9 figures, 8 tables", "pdf_url": "http://arxiv.org/pdf/2507.10644v2", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "从语义网和多智能体系统到智能体AI：智能体网络的统一叙事", "tldr": "本文首次全面梳理了智能体网络（WoA）的演进历史，提出了一个四轴分类法，揭示了智能体智能中心从外部数据/平台到智能体核心模型的范式转变，并指出了构建鲁棒WoA生态系统所需解决的社会技术挑战。", "motivation": "随着大型语言模型（LLMs）能力的提升，智能体网络（WoA）的概念日益受到关注，但该领域的研究在不同社区之间仍存在碎片化。现有的调查多关注最新的LLM驱动框架，而多智能体系统（MAS）和语义网的丰富历史常被视为独立遗留领域，这种碎片化阻碍了对现代系统知识传承的理解和对领域发展轨迹的整体把握。", "method": "本文首次提供了智能体网络（WoA）的全面演进概述。通过分析，展示了现代协议（如A2A和MCP）是对早期标准（如FIPA标准和基于OWL的语义智能体）局限性的直接演进响应。为了系统化分析，引入了一个四轴分类法（语义基础、通信范式、智能中心、发现机制）。", "result": "本文的分析揭示了智能“智能中心”的范式转变：从编码在外部数据（语义网）或平台（多智能体系统）中，转变为嵌入到智能体核心模型（LLM）中。这种转变是现代智能体AI的基础，使得WoA长期以来设想的可扩展和自适应系统成为可能。", "conclusion": "虽然新协议至关重要，但它们不足以构建一个鲁棒、开放、可信赖的智能体网络生态系统。未来的研究前沿在于解决持久的社会技术挑战，包括去中心化身份、经济模型、安全和治理。", "translation": "智能体网络（WoA）的概念，即将静态的、以文档为中心的网络转变为由自主智能体代表用户行动的环境，随着大型语言模型（LLMs）能力的增强而日益受到关注。然而，该领域的研究在不同社区之间仍然碎片化。当代的调查报告罗列了最新的LLM驱动框架，而多智能体系统（MAS）和语义网的丰富历史常被视为独立的、遗留的领域。这种碎片化模糊了现代系统的知识传承，并阻碍了对该领域发展轨迹的整体理解。我们首次提供了智能体网络的全面演进概述。我们表明，诸如A2A和MCP等现代协议，是对早期标准（如FIPA标准和基于OWL的语义智能体）已充分记录的局限性的直接演进响应。为了系统化这一分析，我们引入了一个四轴分类法（语义基础、通信范式、智能中心、发现机制）。这个框架提供了一个统一的分析视角，用于比较所有代的智能体架构，揭示了一条清晰的传承线索，而其他研究者可能看到了断裂。我们的分析确定了“智能中心”的范式转变：从编码在外部数据（语义网）或平台（多智能体系统）中，转变为嵌入到智能体的核心模型（LLM）中。这种转变是现代智能体AI的基础，使得WoA长期以来设想的可扩展和自适应系统成为可能。我们得出结论，虽然新协议至关重要，但它们不足以构建一个鲁棒、开放、可信赖的生态系统。最后，我们认为下一个研究前沿在于解决持久的社会技术挑战，并为新兴的WoA制定了一个新的议程，重点关注去中心化身份、经济模型、安全和治理。", "summary": "本文首次提供了智能体网络（WoA）的全面演进概述，追溯了其从语义网和多智能体系统到智能体AI的发展历程。通过引入一个四轴分类法，作者揭示了智能体“智能中心”从外部数据/平台向智能体核心模型（LLM）的范式转变，并指出这一转变对现代智能体AI的重要性。文章强调，尽管新协议至关重要，但构建鲁棒、开放、可信赖的WoA生态系统还需要解决去中心化身份、经济模型、安全和治理等社会技术挑战。", "keywords": "智能体网络, 智能体AI, 语义网, 多智能体系统, LLM", "comments": "该论文通过整合语义网、多智能体系统和新兴的智能体AI，提供了一个统一且全面的智能体网络演进视角，填补了现有研究碎片化的空白。其提出的四轴分类法为理解和比较不同代的智能体架构提供了宝贵的分析工具，并精准地指出了智能中心从外部编码到智能体内部模型的核心范式转变。论文不仅梳理了历史，还对未来智能体网络面临的社会技术挑战提出了前瞻性议程，对于推动该领域的可持续发展具有重要意义。"}}
{"id": "2507.11834", "title": "CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning", "authors": ["Peiwen Xia", "Tangfei Liao", "Wei Zhu", "Danhuai Zhao", "Jianjun Ke", "Kaihao Zhang", "Tong Lu", "Tao Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ECAI 2025", "url": "http://arxiv.org/abs/2507.11834v1", "summary": "Establishing reliable correspondences between image pairs is a fundamental\ntask in computer vision, underpinning applications such as 3D reconstruction\nand visual localization. Although recent methods have made progress in pruning\noutliers from dense correspondence sets, they often hypothesize consistent\nvisual domains and overlook the challenges posed by diverse scene structures.\nIn this paper, we propose CorrMoE, a novel correspondence pruning framework\nthat enhances robustness under cross-domain and cross-scene variations. To\naddress domain shift, we introduce a De-stylization Dual Branch, performing\nstyle mixing on both implicit and explicit graph features to mitigate the\nadverse influence of domain-specific representations. For scene diversity, we\ndesign a Bi-Fusion Mixture of Experts module that adaptively integrates\nmulti-perspective features through linear-complexity attention and dynamic\nexpert routing. Extensive experiments on benchmark datasets demonstrate that\nCorrMoE achieves superior accuracy and generalization compared to\nstate-of-the-art methods. The code and pre-trained models are available at\nhttps://github.com/peiwenxia/CorrMoE.", "comment": "Accepted by ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.11834v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "CorrMoE：结合去风格化学习的专家混合模型，用于跨场景和跨域对应关系剪枝", "tldr": "CorrMoE是一个新的对应关系剪枝框架，通过去风格化学习和专家混合模块，提高了在跨域和跨场景变化下的鲁棒性，并在基准数据集上表现优异。", "motivation": "建立可靠的图像对对应关系是计算机视觉中的一项基础任务，但现有方法在处理多样化的场景结构和跨域变化时面临挑战，往往假设视觉域一致并忽略场景多样性。", "method": "本文提出CorrMoE，一个新颖的对应关系剪枝框架，旨在增强跨域和跨场景变化下的鲁棒性。为解决域偏移，引入了一个去风格化双分支（De-stylization Dual Branch），对隐式和显式图特征进行风格混合。为处理场景多样性，设计了一个双融合专家混合模块（Bi-Fusion Mixture of Experts module），通过线性复杂度注意力和动态专家路由自适应整合多视角特征。", "result": "在基准数据集上的大量实验表明，CorrMoE比现有最先进的方法取得了更高的准确性和泛化能力。", "conclusion": "CorrMoE通过其创新的去风格化学习和专家混合机制，成功解决了跨域和跨场景变化下对应关系剪枝的挑战，显著提升了对应关系建立的鲁棒性和性能。", "translation": "在图像对之间建立可靠的对应关系是计算机视觉中的一项基本任务，支撑着3D重建和视觉定位等应用。尽管最近的方法在从密集对应关系集中剪枝离群值方面取得了进展，但它们通常假设视觉域一致并忽视了多样场景结构带来的挑战。在本文中，我们提出了CorrMoE，一个新颖的对应关系剪枝框架，旨在增强跨域和跨场景变化下的鲁棒性。为了解决域偏移问题，我们引入了一个去风格化双分支，对隐式和显式图特征进行风格混合，以减轻特定域表示的不利影响。对于场景多样性，我们设计了一个双融合专家混合模块，通过线性复杂度注意力和动态专家路由自适应地整合多视角特征。在基准数据集上的大量实验表明，CorrMoE比现有最先进的方法取得了更高的准确性和泛化能力。代码和预训练模型可在https://github.com/peiwenxia/CorrMoE获取。", "summary": "CorrMoE是一个针对图像对之间对应关系剪枝的新框架，旨在解决现有方法在跨域和跨场景变化下的局限性。它通过引入去风格化双分支来处理域偏移，以及设计双融合专家混合模块来应对场景多样性。实验证明，CorrMoE在准确性和泛化能力上优于现有技术。", "keywords": "对应关系剪枝, 去风格化学习, 专家混合, 跨域, 跨场景", "comments": "该论文提出CorrMoE框架，通过结合去风格化学习和专家混合模型，创新性地解决了跨域和跨场景图像对应关系剪枝的挑战。其核心贡献在于引入了去风格化双分支以缓解域偏移，以及双融合专家混合模块以适应场景多样性，显著提升了对应关系建立的鲁棒性和泛化能力，对3D重建和视觉定位等应用具有重要意义。"}}
{"id": "2403.08802", "title": "Governance of Generative Artificial Intelligence for Companies", "authors": ["Johannes Schneider", "Pauline Kuss", "Rene Abraham", "Christian Meske"], "categories": ["cs.AI", "cs.CY", "cs.LG", "I.2.m"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      This paper is under submission", "url": "http://arxiv.org/abs/2403.08802v4", "summary": "Generative Artificial Intelligence (GenAI), specifically large language\nmodels(LLMs) like ChatGPT, has swiftly entered organizations without adequate\ngovernance, posing both opportunities and risks. Despite extensive debates on\nGenAI's transformative nature and regulatory measures, limited research\naddresses organizational governance, encompassing technical and business\nperspectives. Although numerous frameworks for governance of AI exist, it is\nnot clear to what extent they apply to GenAI. Our review paper fills this gap\nby surveying recent works with the purpose of better understanding fundamental\ncharacteristics of GenAI and adjusting prior frameworks specifically towards\nGenAI governance within companies. To do so, it extends Nickerson's framework\ndevelopment processes to include prior conceptualizations. Our framework\noutlines the scope, objectives, and governance mechanisms tailored to harness\nbusiness opportunities as well as mitigate risks associated with GenAI\nintegration. Our research contributes a focused approach to GenAI governance,\noffering practical insights for companies navigating the challenges of GenAI\nadoption and highlighting research gaps.", "comment": "This paper is under submission", "pdf_url": "http://arxiv.org/pdf/2403.08802v4", "cate": "cs.AI", "date": "2024-02-05", "updated": "2025-07-16", "AI": {"title_translation": "企业生成式人工智能治理", "tldr": "本综述论文旨在通过调整现有框架，为企业生成式AI（GenAI）治理提供一个定制化框架，以应对GenAI在组织中带来的机遇和风险。", "motivation": "生成式人工智能（GenAI），特别是大型语言模型（LLMs），已迅速进入组织，但缺乏足够的治理，既带来了机遇也带来了风险。尽管关于GenAI的变革性质和监管措施进行了广泛辩论，但针对组织治理（包括技术和业务视角）的研究有限。现有的AI治理框架是否适用于GenAI尚不明确，本研究旨在填补这一空白。", "method": "本文是一篇综述论文，通过调查近期工作，旨在更好地理解GenAI的基本特征，并调整先前的框架，使其专门适用于公司内部的GenAI治理。为此，它扩展了Nickerson的框架开发流程，以包含先前的概念化。", "result": "本研究提出的框架概述了为利用商业机会和减轻与GenAI集成相关的风险而量身定制的范围、目标和治理机制。", "conclusion": "本研究为GenAI治理提供了一种集中的方法，为公司应对GenAI采用的挑战提供了实践见解，并强调了研究空白。", "translation": "生成式人工智能（GenAI），特别是像ChatGPT这样的大型语言模型（LLMs），已经迅速进入组织，但缺乏足够的治理，这既带来了机遇也带来了风险。尽管关于GenAI的变革性质和监管措施进行了广泛辩论，但针对组织治理（包括技术和业务视角）的研究有限。尽管存在许多人工智能治理框架，但尚不清楚它们在多大程度上适用于GenAI。我们的综述论文通过调查近期工作来填补这一空白，目的是更好地理解GenAI的基本特征，并专门针对公司内部的GenAI治理调整先前的框架。为此，它扩展了Nickerson的框架开发流程，以包含先前的概念化。我们的框架概述了为利用商业机会以及减轻与GenAI集成相关的风险而量身定制的范围、目标和治理机制。我们的研究为GenAI治理贡献了一种集中的方法，为公司应对GenAI采用的挑战提供了实践见解，并强调了研究空白。", "summary": "本综述论文旨在解决企业在引入生成式人工智能（GenAI）时面临的治理空白。鉴于现有AI治理框架对GenAI的适用性不明确，作者通过调查近期研究并扩展现有框架开发流程，提出了一个专门针对公司GenAI治理的定制化框架。该框架旨在明确GenAI治理的范围、目标和机制，以帮助企业把握机遇并规避风险。本研究为企业GenAI治理提供了实用指导，并指出了未来的研究方向。", "keywords": "生成式AI, 治理, 企业, 框架, 大型语言模型", "comments": "该论文及时地解决了生成式AI在企业应用中面临的关键治理挑战。其创新之处在于认识到现有AI治理框架的局限性，并提出一个专门为GenAI量身定制的治理框架。这对于帮助企业有效管理GenAI带来的机遇和风险具有重要实践意义。此外，论文还指出了研究空白，为未来研究提供了方向。"}}
{"id": "2507.12383", "title": "Improving Reinforcement Learning Sample-Efficiency using Local Approximation", "authors": ["Mohit Prashant", "Arvind Easwaran"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.12383v1", "summary": "In this study, we derive Probably Approximately Correct (PAC) bounds on the\nasymptotic sample-complexity for RL within the infinite-horizon Markov Decision\nProcess (MDP) setting that are sharper than those in existing literature. The\npremise of our study is twofold: firstly, the further two states are from each\nother, transition-wise, the less relevant the value of the first state is when\nlearning the $\\epsilon$-optimal value of the second; secondly, the amount of\n'effort', sample-complexity-wise, expended in learning the $\\epsilon$-optimal\nvalue of a state is independent of the number of samples required to learn the\n$\\epsilon$-optimal value of a second state that is a sufficient number of\ntransitions away from the first. Inversely, states within each other's vicinity\nhave values that are dependent on each other and will require a similar number\nof samples to learn. By approximating the original MDP using smaller MDPs\nconstructed using subsets of the original's state-space, we are able to reduce\nthe sample-complexity by a logarithmic factor to $O(SA \\log A)$ timesteps,\nwhere $S$ and $A$ are the state and action space sizes. We are able to extend\nthese results to an infinite-horizon, model-free setting by constructing a\nPAC-MDP algorithm with the aforementioned sample-complexity. We conclude with\nshowing how significant the improvement is by comparing our algorithm against\nprior work in an experimental setting.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.12383v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "使用局部近似改进强化学习的样本效率", "tldr": "本研究通过局部近似方法，在无限视野MDP设置下，显著提高了强化学习的样本效率，将样本复杂度降低至O(SA log A)。", "motivation": "现有文献中关于无限视野马尔可夫决策过程（MDP）的渐近样本复杂度PAC界限不够尖锐，且未充分利用状态之间的局部依赖关系来提高学习效率。", "method": "本研究基于两个前提：一是状态间距离越远，其值相关性越低；二是局部邻近状态的值相互依赖。通过使用原始状态空间的子集构建较小的MDP来近似原始MDP，从而降低样本复杂度。该方法还扩展到了无限视野、无模型设置，构建了一个具有改进样本复杂度的PAC-MDP算法。", "result": "成功将样本复杂度降低了对数因子，达到O(SA log A)时间步，其中S和A分别是状态空间和动作空间的大小。并将这些结果扩展到无限视野、无模型的设置。", "conclusion": "通过实验比较，证明了所提出的算法相对于现有工作的显著改进。", "translation": "本研究在无限视野马尔可夫决策过程（MDP）设置下，推导出了比现有文献更尖锐的强化学习渐近样本复杂度（PAC）界限。本研究的前提是双重的：首先，两个状态在转移上距离越远，学习第二个状态的ε-最优值时，第一个状态的值的相关性越低；其次，学习一个状态的ε-最优值所需的“努力”（样本复杂度）与学习距离第一个状态足够远的第二个状态的ε-最优值所需的样本数量无关。反之，相互邻近的状态其值相互依赖，并且需要相似的样本数量来学习。通过使用原始状态空间的子集构建较小的MDP来近似原始MDP，我们能够将样本复杂度降低一个对数因子，达到O(SA log A)时间步，其中S和A分别是状态空间和动作空间的大小。我们通过构建一个具有上述样本复杂度的PAC-MDP算法，将这些结果扩展到无限视野、无模型的设置。最后，我们通过在实验设置中将我们的算法与现有工作进行比较，展示了改进的显著性。", "summary": "本论文提出了一种通过局部近似改进强化学习样本效率的方法。在无限视野MDP框架下，研究者推导出了比现有方法更尖锐的渐近样本复杂度（PAC）界限。核心思想是利用状态之间的局部依赖性，即远距离状态相关性低，近距离状态相关性高。通过将原始MDP近似为由状态空间子集构建的更小MDP，成功将样本复杂度降低至O(SA log A)。该方法还扩展到了无模型的无限视野设置，并通过实验验证了其相对于现有工作的显著改进。", "keywords": "强化学习, 样本效率, 局部近似, PAC界限, 马尔可夫决策过程", "comments": "本文通过引入局部近似的概念，为强化学习的样本效率问题提供了新的视角和解决方案。其创新点在于利用状态之间的空间（转移）依赖性来优化学习过程，突破了传统全局学习的局限性。理论上，将样本复杂度降低到O(SA log A)是一个显著的进步，尤其是在处理大规模状态空间时，具有重要的实际意义。将理论成果扩展到无模型设置，进一步提升了其应用价值。"}}
{"id": "2507.11867", "title": "COLA-GEC: A Bidirectional Framework for Enhancing Grammatical Acceptability and Error Correction", "authors": ["Xiangyu Yang", "Xinying Qiu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to CLNLP 2025", "url": "http://arxiv.org/abs/2507.11867v1", "summary": "Grammatical Error Correction (GEC) and grammatical acceptability judgment\n(COLA) are core tasks in natural language processing, sharing foundational\ngrammatical knowledge yet typically evolving independently. This paper\nintroduces COLA-GEC, a novel bidirectional framework that enhances both tasks\nthrough mutual knowledge transfer. First, we augment grammatical acceptability\nmodels using GEC datasets, significantly improving their performance across\nmultiple languages. Second, we integrate grammatical acceptability signals into\nGEC model training via a dynamic loss function, effectively guiding corrections\ntoward grammatically acceptable outputs. Our approach achieves state-of-the-art\nresults on several multilingual benchmarks. Comprehensive error analysis\nhighlights remaining challenges, particularly in punctuation error correction,\nproviding insights for future improvements in grammatical modeling.", "comment": "Accepted to CLNLP 2025", "pdf_url": "http://arxiv.org/pdf/2507.11867v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "COLA-GEC：一种增强语法可接受性和纠错的双向框架", "tldr": "COLA-GEC是一个双向框架，通过相互知识迁移同时提升语法可接受性判断（COLA）和语法纠错（GEC）任务。", "motivation": "语法纠错（GEC）和语法可接受性判断（COLA）是自然语言处理中的核心任务，它们共享基础语法知识，但通常独立发展。", "method": "本文提出了COLA-GEC，一个新颖的双向框架。首先，使用GEC数据集增强语法可接受性模型。其次，通过动态损失函数将语法可接受性信号整合到GEC模型训练中，以指导纠错。", "result": "该方法在多个多语言基准测试上取得了最先进的结果。全面的错误分析揭示了尚存的挑战，尤其是在标点符号纠错方面。", "conclusion": "全面的错误分析指出了现有挑战，特别是标点符号纠错，为未来语法建模的改进提供了见解。", "translation": "语法纠错（GEC）和语法可接受性判断（COLA）是自然语言处理中的核心任务，它们共享基础语法知识，但通常独立发展。本文介绍了COLA-GEC，一个新颖的双向框架，通过相互知识迁移来增强这两个任务。首先，我们使用GEC数据集增强了语法可接受性模型，显著提高了它们在多种语言上的性能。其次，我们通过动态损失函数将语法可接受性信号整合到GEC模型训练中，有效地引导纠错生成语法上可接受的输出。我们的方法在多个多语言基准测试上取得了最先进的结果。全面的错误分析揭示了尚存的挑战，尤其是在标点符号纠错方面，为未来语法建模的改进提供了见解。", "summary": "本文提出了COLA-GEC，一个新颖的双向框架，旨在通过相互知识迁移同时提升语法纠错（GEC）和语法可接受性判断（COLA）任务。该框架通过使用GEC数据集增强COLA模型，并利用动态损失函数将COLA信号整合到GEC模型训练中，成功在多语言基准测试上取得了最先进的性能。研究还进行了错误分析，指出了标点符号纠错等方面的挑战。", "keywords": "语法纠错, 语法可接受性, 双向框架, 知识迁移, 动态损失函数", "comments": "该论文的创新之处在于提出了一个双向框架，打破了GEC和COLA任务独立发展的传统，实现了知识的相互迁移，从而提升了两个任务的性能。这种协同工作的方式为未来的语法建模提供了新的思路。"}}
{"id": "2507.11938", "title": "A Multi-Level Similarity Approach for Single-View Object Grasping: Matching, Planning, and Fine-Tuning", "authors": ["Hao Chen", "Takuya Kiyokawa", "Zhengtao Hu", "Weiwei Wan", "Kensuke Harada"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE T-RO", "url": "http://arxiv.org/abs/2507.11938v1", "summary": "Grasping unknown objects from a single view has remained a challenging topic\nin robotics due to the uncertainty of partial observation. Recent advances in\nlarge-scale models have led to benchmark solutions such as GraspNet-1Billion.\nHowever, such learning-based approaches still face a critical limitation in\nperformance robustness for their sensitivity to sensing noise and environmental\nchanges. To address this bottleneck in achieving highly generalized grasping,\nwe abandon the traditional learning framework and introduce a new perspective:\nsimilarity matching, where similar known objects are utilized to guide the\ngrasping of unknown target objects. We newly propose a method that robustly\nachieves unknown-object grasping from a single viewpoint through three key\nsteps: 1) Leverage the visual features of the observed object to perform\nsimilarity matching with an existing database containing various object models,\nidentifying potential candidates with high similarity; 2) Use the candidate\nmodels with pre-existing grasping knowledge to plan imitative grasps for the\nunknown target object; 3) Optimize the grasp quality through a local\nfine-tuning process. To address the uncertainty caused by partial and noisy\nobservation, we propose a multi-level similarity matching framework that\nintegrates semantic, geometric, and dimensional features for comprehensive\nevaluation. Especially, we introduce a novel point cloud geometric descriptor,\nthe C-FPFH descriptor, which facilitates accurate similarity assessment between\npartial point clouds of observed objects and complete point clouds of database\nmodels. In addition, we incorporate the use of large language models, introduce\nthe semi-oriented bounding box, and develop a novel point cloud registration\napproach based on plane detection to enhance matching accuracy under\nsingle-view conditions. Videos are available at https://youtu.be/qQDIELMhQmk.", "comment": "Accepted by IEEE T-RO", "pdf_url": "http://arxiv.org/pdf/2507.11938v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "单视角物体抓取的层次相似性方法：匹配、规划与微调", "tldr": "本文提出了一种新的基于相似性匹配的单视角未知物体抓取方法，通过匹配数据库中的已知物体、规划模仿抓取并进行局部微调来实现鲁棒抓取，并通过多层次相似性框架和新的几何描述符提高匹配精度。", "motivation": "从单视角抓取未知物体在机器人领域仍是一个挑战，因为部分观测存在不确定性。现有的基于学习的方法（如GraspNet-1Billion）对感知噪声和环境变化敏感，导致性能鲁棒性受限。为解决这一泛化抓取瓶颈，作者放弃传统学习框架，引入相似性匹配的新视角。", "method": "本文提出了一种新的方法，通过三个关键步骤实现单视角未知物体抓取：1) 利用观测物体的视觉特征与现有物体模型数据库进行相似性匹配，识别潜在的高相似度候选；2) 利用具有预存抓取知识的候选模型为未知目标物体规划模仿抓取；3) 通过局部微调过程优化抓取质量。为解决部分和噪声观测带来的不确定性，作者提出了一种集成了语义、几何和维度特征的多层次相似性匹配框架。特别地，引入了一种新颖的点云几何描述符C-FPFH，用于观测物体部分点云与数据库模型完整点云之间的准确相似性评估。此外，还结合了大型语言模型，引入了半定向边界框，并开发了一种基于平面检测的新颖点云配准方法，以提高单视角条件下的匹配精度。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "从单视角抓取未知物体在机器人领域仍然是一个具有挑战性的话题，因为部分观测存在不确定性。大型模型的最新进展带来了基准解决方案，例如GraspNet-1Billion。然而，此类基于学习的方法在性能鲁棒性方面仍面临一个关键限制，因为它们对感知噪声和环境变化敏感。为了解决实现高度泛化抓取的这一瓶颈，我们放弃了传统的学习框架，引入了一个新的视角：相似性匹配，即利用相似的已知物体来指导未知目标物体的抓取。我们新提出了一种方法，通过三个关键步骤从单视角鲁棒地实现未知物体抓取：1）利用观测物体的视觉特征与现有包含各种物体模型的数据库进行相似性匹配，识别具有高相似度的潜在候选；2）利用具有预存抓取知识的候选模型为未知目标物体规划模仿抓取；3）通过局部微调过程优化抓取质量。为了解决部分和噪声观测引起的不确定性，我们提出了一种多层次相似性匹配框架，该框架集成了语义、几何和维度特征以进行全面评估。特别是，我们引入了一种新颖的点云几何描述符C-FPFH，它有助于观测物体部分点云与数据库模型完整点云之间进行准确的相似性评估。此外，我们还结合了大型语言模型的使用，引入了半定向边界框，并开发了一种基于平面检测的新颖点云配准方法，以提高单视角条件下的匹配精度。视频可在 https://youtu.be/qQDIELMhQmk 查看。", "summary": "本文提出了一种新颖的多层次相似性方法，用于解决单视角未知物体抓取的鲁棒性问题。与传统的学习框架不同，该方法通过利用已知物体数据库进行相似性匹配来指导抓取。核心流程包括：首先，通过视觉特征匹配识别相似的已知物体；其次，利用这些相似物体的预存抓取知识规划模仿抓取；最后，通过局部微调优化抓取质量。为应对部分和噪声观测，该研究引入了整合语义、几何和维度特征的多层次相似性框架，并提出了一种新的C-FPFH点云描述符以提高匹配精度。此外，还结合了大型语言模型和基于平面检测的点云配准技术。", "keywords": "单视角抓取, 相似性匹配, 多层次相似性, 点云描述符, 机器人抓取", "comments": "本文的创新点在于放弃了传统的端到端学习框架，转而采用基于相似性匹配的新范式来解决单视角未知物体抓取的泛化性和鲁棒性问题。通过多层次的特征整合（语义、几何、维度）以及新颖的C-FPFH点云描述符，有效提升了在不确定观测条件下的匹配精度。引入大型语言模型和改进的点云配准方法也增强了其实用性。这种方法为机器人抓取领域提供了一个有潜力的替代方案，尤其是在数据有限或环境多变的应用场景中。"}}
{"id": "2403.05192", "title": "An End-to-End Pipeline Perspective on Video Streaming in Best-Effort Networks: A Survey and Tutorial", "authors": ["Leonardo Peroni", "Sergey Gorinsky"], "categories": ["cs.NI", "cs.MM"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.05192v4", "summary": "Remaining a dominant force in Internet traffic, video streaming captivates\nend users, service providers, and researchers. This paper takes a pragmatic\napproach to reviewing recent advances in the field by focusing on the prevalent\nstreaming paradigm that involves delivering long-form two-dimensional videos\nover the best-effort Internet with client-side adaptive bitrate (ABR)\nalgorithms and assistance from content delivery networks (CDNs). To enhance\naccessibility, we supplement the survey with tutorial material. Unlike existing\nsurveys that offer fragmented views, our work provides a holistic perspective\non the entire end-to-end streaming pipeline, from video capture by a\ncamera-equipped device to playback by the end user. Our novel perspective\ncovers the ingestion, processing, and distribution stages of the pipeline and\naddresses key challenges such as video compression, upload, transcoding, ABR\nalgorithms, CDN support, and quality of experience. We review over 200 papers\nand classify streaming designs by their problem-solving methodology, whether\nbased on intuition (simple heuristics), theory (formal optimization), or\nmachine learning (generalizable data patterns). The survey further refines\nthese methodology-based categories and characterizes each design by additional\ntraits such as compatible codecs and use of super resolution. We connect the\nreviewed research to real-world applications by discussing the practices of\ncommercial streaming platforms. Finally, the survey highlights prominent\ncurrent trends and outlines future directions in video streaming.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.05192v4", "cate": "cs.NI", "date": "2024-03-08", "updated": "2025-07-15", "AI": {"title_translation": "在尽力而为网络中视频流的端到端管道视角：一项调查与教程", "tldr": "这是一篇关于尽力而为网络中视频流的端到端管道的全面调查和教程，涵盖了从捕获到播放的各个阶段。", "motivation": "视频流在互联网流量中占据主导地位，但现有调查提供的是碎片化的视角。本文旨在提供一个关于端到端视频流管道的整体视角，并回顾该领域的最新进展。", "method": "本文通过审查200多篇论文，对尽力而为网络中视频流的端到端管道进行了全面调查和教程。它将流媒体设计按问题解决方法（直觉、理论或机器学习）进行分类，并根据兼容编解码器和超分辨率等额外特征进一步细化这些类别。", "result": "调查涵盖了管道的摄取、处理和分发阶段，解决了视频压缩、上传、转码、ABR算法、CDN支持和体验质量等关键挑战。它将研究与商业流媒体平台的实践联系起来，并突出了当前的趋势和未来的方向。", "conclusion": "本文通过提供一个关于视频流端到端管道的整体、全面的视角，并对现有设计进行系统分类，为研究人员和从业者提供了宝贵的资源，并指明了未来的研究方向。", "translation": "视频流作为互联网流量的主导力量，吸引着终端用户、服务提供商和研究人员。本文采取务实的方法，通过关注当前流行的流媒体范式来回顾该领域的最新进展，该范式涉及通过尽力而为的互联网传输长格式二维视频，并结合客户端自适应比特率（ABR）算法和内容分发网络（CDN）的协助。为了提高可访问性，我们为调查补充了教程材料。与提供碎片化视图的现有调查不同，我们的工作提供了关于整个端到端流媒体管道的整体视角，从摄像头设备捕获视频到终端用户播放。我们新颖的视角涵盖了管道的摄取、处理和分发阶段，并解决了视频压缩、上传、转码、ABR算法、CDN支持和体验质量等关键挑战。我们审查了200多篇论文，并根据其问题解决方法（无论是基于直觉（简单启发式）、理论（形式优化）还是机器学习（可泛化数据模式））对流媒体设计进行分类。该调查进一步细化了这些基于方法论的类别，并根据兼容编解码器和超分辨率的使用等额外特征来描述每种设计。我们通过讨论商业流媒体平台的实践，将所审查的研究与现实世界应用联系起来。最后，该调查强调了当前突出的趋势，并概述了视频流的未来方向。", "summary": "这是一篇关于尽力而为网络中视频流的综合性调查和教程。它提供了从视频捕获到播放的端到端管道的整体视角，涵盖了摄取、处理、分发等阶段的关键挑战。文章审查了200多篇论文，根据问题解决方法（直觉、理论、机器学习）对流媒体设计进行分类，并讨论了商业实践、当前趋势和未来方向。", "keywords": "视频流, 端到端管道, 尽力而为网络, 自适应比特率, CDN, 调查", "comments": "这篇论文通过提供一个全面的端到端视角，填补了现有流媒体调查碎片化的空白。其创新之处在于将流媒体设计按问题解决方法进行分类，并结合了实践应用和未来展望，对于该领域的研究人员和工程师具有重要的参考价值。"}}
{"id": "2507.11924", "title": "Advantages of Feedback in Distributed Data-Gathering for Accurate and Power-Efficient State-Estimation", "authors": ["Hyeongmin Choe", "Soojean Han"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Archived version. Related work under further development", "url": "http://arxiv.org/abs/2507.11924v1", "summary": "In distributed target-tracking sensor networks, efficient data gathering\nmethods are necessary to save communication resources and assure information\naccuracy. This paper proposes a Feedback (FB) distributed data-gathering method\nwhich lets the central unit feed information back to the mobile sensors; each\nsensor then uses it to cancel redundant transmissions and reduce communication\ncongestion. We rigorously compare its performance, in terms of mean-squared\nerror (MSE) and cost of power per sensor, against more conventional\nNon-Feedback (NF) architectures by evaluating conditions of feasibility and\nadvantage under different architecture specifications (e.g., communication\ndelay rate, power cost rate, maximum back-off time, sampling period,\nobservation noise). Here, we defined the advantage as the performance gain\nachieved by FB over NF, while FB is said to be feasible if the advantage region\nis nonempty. Our theoretical analyses show that the feasibility of FB depends\nmore on the communication power cost, while the advantage depends on the\nsensors' propagation delay per transmission interval; we derive concrete\nconditions under which these outcomes hold. Using extensive numerical\nsimulations under a variety of settings, we confirm the accuracy of the derived\nconditions, and show that our theoretical results hold even for more complex\nscenarios where the simplifying assumptions no longer hold.", "comment": "Archived version. Related work under further development", "pdf_url": "http://arxiv.org/pdf/2507.11924v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "分布式数据采集中反馈的优势：实现准确且节能的状态估计", "tldr": "本文提出了一种基于反馈的分布式数据收集方法，用于传感器网络，与非反馈方法相比，该方法可减少冗余传输并提高能效和准确性。", "motivation": "在分布式目标跟踪传感器网络中，需要高效的数据收集方法以节省通信资源并确保信息准确性。", "method": "本文提出了一种反馈（FB）分布式数据收集方法，其中中央单元将信息反馈给移动传感器，传感器利用该信息取消冗余传输。通过评估不同架构规格（如通信延迟率、功耗率等）下的可行性和优势条件，在均方误差（MSE）和每个传感器的功耗成本方面，将其性能与传统非反馈（NF）架构进行了严格比较。研究利用了理论分析和广泛的数值模拟。", "result": "理论分析表明，FB的可行性更多地取决于通信功耗成本，而优势则取决于传感器每次传输间隔的传播延迟。论文推导了这些结果成立的具体条件。广泛的数值模拟证实了导出条件的准确性，并表明即使在简化假设不再成立的更复杂场景中，理论结果也仍然成立。", "conclusion": "在分布式数据收集中引入反馈机制，对于状态估计的准确性和能效具有显著优势，其可行性和性能增益取决于通信功耗成本和传播延迟等特定系统参数。", "translation": "在分布式目标跟踪传感器网络中，高效的数据收集方法对于节省通信资源和确保信息准确性至关重要。本文提出了一种反馈（FB）分布式数据收集方法，该方法允许中央单元将信息反馈给移动传感器；每个传感器随后利用该信息取消冗余传输并减少通信拥塞。我们通过评估在不同架构规格（例如，通信延迟率、功耗率、最大回退时间、采样周期、观测噪声）下的可行性和优势条件，严格比较了其在均方误差（MSE）和每个传感器的功耗成本方面的性能，与更传统的非反馈（NF）架构进行对比。这里，我们将优势定义为FB相对于NF所获得的性能增益，而如果优势区域非空，则称FB是可行的。我们的理论分析表明，FB的可行性更多地取决于通信功耗成本，而优势则取决于传感器每次传输间隔的传播延迟；我们推导出了这些结果成立的具体条件。通过在各种设置下进行广泛的数值模拟，我们证实了导出条件的准确性，并表明即使在简化假设不再成立的更复杂场景中，我们的理论结果也仍然成立。", "summary": "本文介绍了一种用于目标跟踪传感器网络的反馈（FB）分布式数据收集方法。通过允许中央单元将信息反馈给移动传感器，该方法使传感器能够减少冗余传输和通信拥塞，从而提高准确性（更低的MSE）和能效。严格的理论分析和广泛的模拟表明，FB优于传统的非反馈（NF）架构。研究揭示，FB的可行性主要受通信功耗成本的影响，而其性能优势则取决于传感器的传播延迟。", "keywords": "分布式数据收集, 反馈, 传感器网络, 状态估计, 能效", "comments": "该论文提出了一种用于分布式数据收集的新颖反馈机制，解决了传感器网络中通信资源效率和数据准确性的关键问题。其优势在于严谨的理论分析并辅以广泛的模拟，这证实了所推导条件即使在复杂场景下的实际适用性。识别影响可行性和优势的具体参数是其关键贡献。"}}
{"id": "2507.12232", "title": "MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM", "authors": ["Tao Chen", "Jingyi Zhang", "Decheng Liu", "Chunlei Peng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12232v1", "summary": "Recent studies have utilized visual large language models (VLMs) to answer\nnot only \"Is this face a forgery?\" but also \"Why is the face a forgery?\" These\nstudies introduced forgery-related attributes, such as forgery location and\ntype, to construct deepfake VQA datasets and train VLMs, achieving high\naccuracy while providing human-understandable explanatory text descriptions.\nHowever, these methods still have limitations. For example, they do not fully\nleverage face quality-related attributes, which are often abnormal in forged\nfaces, and they lack effective training strategies for forgery-aware VLMs. In\nthis paper, we extend the VQA dataset to create DD-VQA+, which features a\nricher set of attributes and a more diverse range of samples. Furthermore, we\nintroduce a novel forgery detection framework, MGFFD-VLM, which integrates an\nAttribute-Driven Hybrid LoRA Strategy to enhance the capabilities of Visual\nLarge Language Models (VLMs). Additionally, our framework incorporates\nMulti-Granularity Prompt Learning and a Forgery-Aware Training Strategy. By\ntransforming classification and forgery segmentation results into prompts, our\nmethod not only improves forgery classification but also enhances\ninterpretability. To further boost detection performance, we design multiple\nforgery-related auxiliary losses. Experimental results demonstrate that our\napproach surpasses existing methods in both text-based forgery judgment and\nanalysis, achieving superior accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12232v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MGFFD-VLM：基于VLM的多粒度提示学习人脸伪造检测", "tldr": "本文提出MGFFD-VLM框架，通过多粒度提示学习和改进的训练策略，显著提升了VLM在人脸伪造检测中的性能和可解释性。", "motivation": "现有基于视觉大型语言模型（VLM）的人脸伪造检测方法未能充分利用人脸质量相关属性，且缺乏有效的伪造感知训练策略。", "method": "本文扩展了VQA数据集创建了DD-VQA+，增加了属性和样本多样性。提出了新颖的MGFFD-VLM伪造检测框架，该框架集成了属性驱动的混合LoRA策略、多粒度提示学习和伪造感知训练策略。通过将分类和伪造分割结果转化为提示，提升了伪造分类和可解释性。此外，还设计了多个伪造相关的辅助损失。", "result": "实验结果表明，MGFFD-VLM在基于文本的伪造判断和分析方面超越了现有方法，并取得了更高的准确性。", "conclusion": "MGFFD-VLM通过创新的数据集扩展、多粒度提示学习和伪造感知训练策略，有效提升了人脸伪造检测的分类性能和可解释性。", "translation": "近期研究已利用视觉大型语言模型（VLMs）不仅回答“这张脸是否是伪造的？”，还能回答“这张脸为什么是伪造的？”这些研究引入了与伪造相关的属性，如伪造位置和类型，以构建深度伪造VQA数据集并训练VLMs，在提供人类可理解的解释性文本描述的同时实现了高精度。然而，这些方法仍有局限性。例如，它们未能充分利用人脸质量相关属性（伪造人脸中通常异常），并且缺乏有效的伪造感知VLM训练策略。在本文中，我们扩展了VQA数据集以创建DD-VQA+，该数据集具有更丰富的属性集和更多样化的样本范围。此外，我们引入了一种新颖的伪造检测框架MGFFD-VLM，它集成了属性驱动的混合LoRA策略来增强视觉大型语言模型（VLMs）的能力。此外，我们的框架还结合了多粒度提示学习和伪造感知训练策略。通过将分类和伪造分割结果转化为提示，我们的方法不仅改进了伪造分类，还增强了可解释性。为了进一步提高检测性能，我们设计了多个与伪造相关的辅助损失。实验结果表明，我们的方法在基于文本的伪造判断和分析方面均超越现有方法，并取得了更高的准确性。", "summary": "本文针对当前VLM人脸伪造检测方法在利用人脸质量属性和有效训练策略上的不足，提出了一种名为MGFFD-VLM的新型框架。该框架首先通过构建更丰富的DD-VQA+数据集来增强数据多样性。接着，MGFFD-VLM集成了属性驱动的混合LoRA策略、多粒度提示学习以及伪造感知训练策略，通过将分类和伪造分割结果转化为提示，显著提升了伪造分类的准确性和模型的可解释性。此外，为进一步优化检测性能，文中还设计了多种伪造相关的辅助损失。实验结果验证了MGFFD-VLM在文本伪造判断和分析方面均优于现有方法，并展现出卓越的准确性。", "keywords": "人脸伪造检测, VLM, 多粒度提示学习, 伪造感知训练, 可解释性", "comments": "该研究通过引入多粒度提示学习和伪造感知训练策略，并构建更丰富的数据集，有效解决了现有VLM在人脸伪造检测中对质量属性利用不足和训练策略缺乏的问题。其将分类和分割结果转化为提示的方法，不仅提升了检测精度，也增强了模型的可解释性，具有较高的创新性和实用价值。"}}
{"id": "2507.11907", "title": "SIEVE: Effective Filtered Vector Search with Collection of Indexes", "authors": ["Zhaoheng Li", "Silu Huang", "Wei Ding", "Yongjoo Park", "Jianjun Chen"], "categories": ["cs.DB", "cs.IR"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11907v1", "summary": "Many real-world tasks such as recommending videos with the kids tag can be\nreduced to finding most similar vectors associated with hard predicates. This\ntask, filtered vector search, is challenging as prior state-of-the-art\ngraph-based (unfiltered) similarity search techniques quickly degenerate when\nhard constraints are considered. That is, effective graph-based filtered\nsimilarity search relies on sufficient connectivity for reaching the most\nsimilar items within just a few hops. To consider predicates, recent works\npropose modifying graph traversal to visit only the items that may satisfy\npredicates. However, they fail to offer the just-a-few-hops property for a wide\nrange of predicates: they must restrict predicates significantly or lose\nefficiency if only a small fraction of items satisfy predicates.\n  We propose an opposite approach: instead of constraining traversal, we build\nmany indexes each serving different predicate forms. For effective\nconstruction, we devise a three-dimensional analytical model capturing\nrelationships among index size, search time, and recall, with which we follow a\nworkload-aware approach to pack as many useful indexes as possible into a\ncollection. At query time, the analytical model is employed yet again to\ndiscern the one that offers the fastest search at a given recall. We show\nsuperior performance and support on datasets with varying selectivities and\nforms: our approach achieves up to 8.06x speedup while having as low as 1%\nbuild time versus other indexes, with less than 2.15x memory of a standard HNSW\ngraph and modest knowledge of past workloads.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11907v1", "cate": "cs.DB", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "SIEVE：基于索引集合的高效过滤向量搜索", "tldr": "SIEVE通过构建多个索引来解决带硬性谓词的过滤向量搜索效率低下的问题，实现显著加速和低构建时间。", "motivation": "现有的图基向量相似度搜索技术在处理带硬性谓词的过滤向量搜索时性能显著下降，无法保持“少量跳数”的特性，尤其当满足谓词的项很少时效率低下。", "method": "本文提出一种相反的方法：不限制图遍历，而是构建许多索引，每个索引服务不同的谓词形式。为此，设计了一个三维分析模型来捕获索引大小、搜索时间、召回率之间的关系，并采用工作负载感知方法将尽可能多的有用索引打包到一个集合中。在查询时，该分析模型再次被用于识别在给定召回率下提供最快搜索的索引。", "result": "在不同选择性和形式的数据集上，SIEVE表现出卓越的性能，实现了高达8.06倍的加速，构建时间低至其他索引的1%，内存仅为标准HNSW图的2.15倍以下，且仅需适度的历史工作负载知识。", "conclusion": "SIEVE通过其多索引集合和分析模型，有效解决了过滤向量搜索的挑战，显著提升了性能并降低了构建成本。", "translation": "许多现实世界的任务，例如推荐带有儿童标签的视频，可以归结为查找与硬性谓词关联的最相似向量。这项任务，即过滤向量搜索，具有挑战性，因为现有的最先进的基于图的（未过滤）相似度搜索技术在考虑硬性约束时会迅速退化。也就是说，有效的基于图的过滤相似度搜索依赖于足够的连通性，以便在几次跳跃内找到最相似的项。为了考虑谓词，最近的工作提出修改图遍历，只访问可能满足谓词的项。然而，它们未能为广泛的谓词提供“少量跳数”的特性：如果只有一小部分项满足谓词，它们必须显著限制谓词或失去效率。\n我们提出了一种相反的方法：不限制遍历，而是构建许多索引，每个索引服务于不同的谓词形式。为了有效构建，我们设计了一个三维分析模型，捕获索引大小、搜索时间、召回率之间的关系，并以此遵循工作负载感知方法，将尽可能多的有用索引打包到一个集合中。在查询时，该分析模型再次被用于识别在给定召回率下提供最快搜索的索引。我们展示了在具有不同选择性和形式的数据集上的卓越性能和支持：我们的方法实现了高达8.06倍的加速，而构建时间仅为其他索引的1%，内存仅为标准HNSW图的2.15倍以下，且仅需适度的历史工作负载知识。", "summary": "本文提出了SIEVE，一种用于高效过滤向量搜索的新方法。针对现有图基方法在处理硬性谓词时性能退化的问题，SIEVE不限制图遍历，而是构建一个包含多个索引的集合，每个索引服务于不同的谓词形式。通过一个三维分析模型，SIEVE能够工作负载感知地构建和选择最合适的索引，从而在各种数据集上实现了显著的搜索加速（高达8.06倍）和极低的构建时间（低至1%），同时保持合理的内存消耗。", "keywords": "过滤向量搜索, 索引集合, 相似度搜索, 谓词, 工作负载感知", "comments": "SIEVE的创新之处在于其“反向”思维，即通过构建索引集合而非限制遍历来解决过滤向量搜索的挑战。这种方法通过结合工作负载感知和分析模型，实现了性能和构建成本的显著提升，为实际应用中的带约束向量搜索提供了有效解决方案。"}}
{"id": "2507.11992", "title": "Understanding visual attention beehind bee-inspired UAV navigation", "authors": ["Pranav Rajbhandari", "Abhi Veda", "Matthew Garratt", "Mandayam Srinivasan", "Sridhar Ravi"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11992v1", "summary": "Bio-inspired design is often used in autonomous UAV navigation due to the\ncapacity of biological systems for flight and obstacle avoidance despite\nlimited sensory and computational capabilities. In particular, honeybees mainly\nuse the sensory input of optic flow, the apparent motion of objects in their\nvisual field, to navigate cluttered environments. In our work, we train a\nReinforcement Learning agent to navigate a tunnel with obstacles using only\noptic flow as sensory input. We inspect the attention patterns of trained\nagents to determine the regions of optic flow on which they primarily base\ntheir motor decisions. We find that agents trained in this way pay most\nattention to regions of discontinuity in optic flow, as well as regions with\nlarge optic flow magnitude. The trained agents appear to navigate a cluttered\ntunnel by avoiding the obstacles that produce large optic flow, while\nmaintaining a centered position in their environment, which resembles the\nbehavior seen in flying insects. This pattern persists across independently\ntrained agents, which suggests that this could be a good strategy for\ndeveloping a simple explicit control law for physical UAVs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11992v1", "cate": "cs.AI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "了解蜜蜂启发式无人机导航背后的视觉注意力", "tldr": "研究人员训练了一个强化学习智能体，使其仅利用光流在复杂环境中导航，并发现其视觉注意力集中在光流不连续和幅度大的区域，这种策略类似于蜜蜂，可用于开发无人机控制律。", "motivation": "生物系统（特别是蜜蜂）在有限的感知和计算能力下仍能有效飞行和避障，这启发了无人机导航的设计。研究旨在理解蜜蜂启发式无人机导航中视觉注意力的机制。", "method": "训练一个强化学习（RL）智能体，使其仅使用光流作为感知输入，在有障碍物的隧道中导航。然后检查训练后的智能体的注意力模式，以确定它们主要基于哪些光流区域做出运动决策。", "result": "训练后的智能体主要关注光流不连续区域以及光流幅度大的区域。这些智能体通过避开产生大光流的障碍物并保持在环境中的中心位置来导航混乱的隧道，这与飞行昆虫的行为相似。这种模式在独立训练的智能体中持续存在。", "conclusion": "智能体所表现出的视觉注意力模式（关注光流不连续和高幅度区域）和导航策略（避障和居中）是一种有效的导航策略，可用于为物理无人机开发简单的显式控制律。", "translation": "生物启发设计常用于自主无人机导航，因为生物系统尽管感知和计算能力有限，但仍能进行飞行和避障。特别是，蜜蜂主要利用光流（即物体在其视野中的视在运动）作为感官输入来导航杂乱的环境。在我们的工作中，我们训练了一个强化学习智能体，使其仅使用光流作为感官输入来导航一个有障碍物的隧道。我们检查了训练后智能体的注意力模式，以确定它们主要基于哪些光流区域做出运动决策。我们发现，以这种方式训练的智能体最关注光流不连续区域以及光流幅度大的区域。训练后的智能体似乎通过避开产生大光流的障碍物，同时保持在环境中的中心位置来导航杂乱的隧道，这类似于飞行昆虫中观察到的行为。这种模式在独立训练的智能体中持续存在，这表明这可能是为物理无人机开发简单显式控制律的一个好策略。", "summary": "本文研究了蜜蜂启发式无人机导航中的视觉注意力机制。研究人员训练了一个强化学习智能体，使其仅依赖光流在模拟隧道中导航。结果显示，该智能体主要将注意力集中在光流不连续和幅度大的区域。其导航行为类似于飞行昆虫，通过避开产生大光流的障碍物并保持居中位置。这项发现为开发简单的无人机控制律提供了潜在策略。", "keywords": "光流, 强化学习, 无人机导航, 视觉注意力, 生物启发", "comments": "这项研究通过模拟和强化学习，深入探讨了生物启发式导航中视觉注意力的作用，特别是在光流感知方面。其创新之处在于将蜜蜂的导航策略与强化学习相结合，并揭示了智能体在复杂环境中如何分配视觉注意力。研究结果为开发更鲁棒、更高效的自主无人机导航系统提供了宝贵的见解，特别是通过揭示一种可能适用于简单显式控制律的通用策略。"}}
{"id": "2507.12368", "title": "Efficient Remote Monitoring through Noisy Random Access with Retransmissions", "authors": ["Sergey Foss", "Dmitriy Kim", "Andrey Turlikov"], "categories": ["cs.IT", "math.IT", "math.PR"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12368v1", "summary": "We consider a rare event monitoring system consisting of a set of devices and\na base station, where devices transmit information about rare events to the\nbase station using a random multiple access scheme. We introduce a model in\nwhich the presence of noise in the multiple access channel can cause message\nloss even in the absence of transmission collisions. The occurrence of events\nis modeled by a family of independent two-state Markov chains (with states 0\nand 1). We analyze how repeated transmissions affect system performance. Two\nefficiency criteria are proposed and studied: the maximum probability that a\nmessage about an event from a fixed device is successfully delivered to the\nbase station and the maximum frequency at which the base station successfully\nreceives updates about the entire system. For each criterion, we determine the\noptimal number of retransmissions as a function of the system parameters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12368v1", "cate": "cs.IT", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "带有重传的噪声随机接入高效远程监控", "tldr": "研究了一个稀有事件监控系统，其中设备通过有噪声的随机接入信道发送信息，即使没有冲突也会丢失消息。通过分析重传对系统性能的影响，并为两个效率标准确定了最优重传次数。", "motivation": "在稀有事件监控系统中，设备通过随机多址接入方案向基站传输信息时，即使没有传输冲突，信道中的噪声也可能导致消息丢失，因此需要研究如何通过重传来提高系统性能。", "method": "引入了一个模型，其中事件的发生由独立的二态马尔可夫链建模。分析了重复传输（重传）如何影响系统性能。提出了两个效率标准：特定设备事件消息成功送达基站的最大概率和基站成功接收整个系统更新的最大频率。针对每个标准，根据系统参数确定了最优重传次数。", "result": "针对所提出的两个效率标准（特定设备事件消息成功送达的最大概率和基站成功接收整个系统更新的最大频率），研究确定了作为系统参数函数的最佳重传次数。", "conclusion": "通过分析，可以为在有噪声随机接入信道中进行稀有事件监控的系统确定最优重传次数，从而在特定效率标准下优化系统性能。", "translation": "我们考虑一个由一组设备和一个基站组成的稀有事件监控系统，其中设备使用随机多址接入方案向基站传输稀有事件信息。我们引入了一个模型，其中多址接入信道中噪声的存在即使在没有传输冲突的情况下也可能导致消息丢失。事件的发生由一系列独立的二态马尔可夫链（状态0和1）建模。我们分析了重复传输如何影响系统性能。提出了并研究了两个效率标准：来自固定设备的事件消息成功送达基站的最大概率，以及基站成功接收整个系统更新的最大频率。对于每个标准，我们确定了作为系统参数函数的最佳重传次数。", "summary": "这篇论文研究了一个稀有事件监控系统，其中设备通过有噪声的随机多址接入信道向基站发送信息，即使没有冲突也可能发生消息丢失。作者引入了一个模型来分析重复传输对系统性能的影响，并提出了两个关键的效率标准：单个消息成功送达的概率和系统更新的频率。研究为每个标准确定了最优的重传次数，这些次数是系统参数的函数。", "keywords": "稀有事件监控, 随机接入, 重传, 噪声信道, 性能优化", "comments": "这项研究通过考虑信道噪声和重传机制，为稀有事件监控系统提供了实用的性能优化方案。其创新之处在于将噪声引起的丢包与随机接入机制相结合，并为特定效率目标确定了最优重传策略，这对于资源受限或对实时性有要求的监控系统具有重要意义。"}}
{"id": "2507.11912", "title": "Joint UAV Placement and Transceiver Design in Multi-User Wireless Relay Networks", "authors": ["Tzu-Hsuan Chou", "Nicolo Michelusi", "David J. Love", "James V. Krogmeier"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This paper is accepted for publication in IEEE Transactions on Communications. 17 pages", "url": "http://arxiv.org/abs/2507.11912v1", "summary": "In this paper, a novel approach is proposed to improve the minimum\nsignal-to-interference-plus-noise-ratio (SINR) among users in non-orthogonal\nmulti-user wireless relay networks, by optimizing the placement of unmanned\naerial vehicle (UAV) relays, relay beamforming, and receive combining. The\ndesign is separated into two problems: beamforming-aware UAV placement\noptimization and transceiver design for minimum SINR maximization. A\nsignificant challenge in beamforming-aware UAV placement optimization is the\nlack of instantaneous channel state information (CSI) prior to deploying UAV\nrelays, making it difficult to derive the beamforming SINR in non-orthogonal\nmulti-user transmission. To address this issue, an approximation of the\nexpected beamforming SINR is derived using the narrow beam property of a\nmassive MIMO base station. Based on this, a UAV placement algorithm is proposed\nto provide UAV positions that improve the minimum expected beamforming SINR\namong users, using a difference-of-convex framework. Subsequently, after\ndeploying the UAV relays to the optimized positions, and with estimated CSI\navailable, a joint relay beamforming and receive combining (JRBC) algorithm is\nproposed to optimize the transceiver to improve the minimum beamforming SINR\namong users, using a block-coordinate descent approach. Numerical results show\nthat the UAV placement algorithm combined with the JRBC algorithm provides a\n4.6 dB SINR improvement over state-of-the-art schemes.", "comment": "This paper is accepted for publication in IEEE Transactions on\n  Communications. 17 pages", "pdf_url": "http://arxiv.org/pdf/2507.11912v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "多用户无线中继网络中无人机部署与收发机联合设计", "tldr": "本文提出了一种新颖的方法，通过优化无人机中继的部署、中继波束成形和接收合并，以提高非正交多用户无线中继网络中用户的最小信干噪比（SINR）。该方法将设计分为两个问题：波束成形感知无人机部署优化和最小SINR最大化的收发机设计，并取得了显著的SINR性能提升。", "motivation": "在非正交多用户无线中继网络中，通过优化无人机中继的部署、中继波束成形和接收合并来提高用户最小信干噪比（SINR）。", "method": "本文将设计分为两个问题：1) 波束成形感知无人机部署优化：针对部署前缺乏瞬时信道状态信息（CSI）的挑战，利用大规模MIMO基站的窄波束特性推导出预期波束成形SINR的近似值，并提出基于凸差分框架的无人机部署算法。2) 最小SINR最大化的收发机设计：在无人机部署到优化位置并获得估计CSI后，提出基于块坐标下降法的联合中继波束成形和接收合并（JRBC）算法来优化收发机。", "result": "数值结果表明，无人机部署算法与JRBC算法相结合，比现有最先进方案提供了4.6 dB的SINR性能提升。", "conclusion": "通过联合优化无人机部署、中继波束成形和接收合并，本研究提出的方法显著提高了多用户无线中继网络中的最小SINR，尤其是在处理部署前CSI缺失问题上表现出色。", "translation": "在本文中，提出了一种新颖的方法，通过优化无人机（UAV）中继的部署、中继波束成形和接收合并，以提高非正交多用户无线中继网络中用户的最小信干噪比（SINR）。该设计分为两个问题：波束成形感知无人机部署优化和最小SINR最大化的收发机设计。波束成形感知无人机部署优化中的一个显著挑战是，在部署无人机中继之前缺乏瞬时信道状态信息（CSI），这使得难以在非正交多用户传输中推导出波束成形SINR。为了解决这个问题，利用大规模MIMO基站的窄波束特性推导出预期波束成形SINR的近似值。在此基础上，提出了一种无人机部署算法，利用凸差分框架提供改善用户间最小预期波束成形SINR的无人机位置。随后，在将无人机中继部署到优化位置并获得估计CSI后，提出了一种联合中继波束成形和接收合并（JRBC）算法，采用块坐标下降法优化收发机以提高用户间最小波束成形SINR。数值结果表明，无人机部署算法与JRBC算法相结合，比现有最先进方案提供了4.6 dB的SINR性能提升。", "summary": "本文提出了一种在多用户无线中继网络中优化无人机中继部署、中继波束成形和接收合并的新方法，旨在提高用户的最小信干噪比（SINR）。该方法将问题分解为波束成形感知的无人机部署优化和收发机设计两个阶段。针对部署前CSI缺失的挑战，研究利用大规模MIMO的窄波束特性近似预期SINR，并提出基于凸差分框架的无人机部署算法。随后，在无人机部署后，采用块坐标下降法的联合中继波束成形和接收合并（JRBC）算法进一步优化收发机。数值结果表明，该联合方法能比现有技术实现4.6 dB的SINR显著提升。", "keywords": "无人机中继, 波束成形, 信干噪比, 无线通信, 联合优化", "comments": "本文的创新点在于将无人机部署与收发机设计联合优化，并巧妙地解决了部署前CSI缺失的难题，通过近似预期SINR和分阶段优化来克服实际挑战。其提出的分阶段优化方法和利用大规模MIMO特性进行SINR近似是值得关注的亮点。该研究在提高多用户无线网络性能方面具有重要意义。"}}
{"id": "2505.15670", "title": "Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model", "authors": ["Ke Hu", "Ehsan Hosseini-Asl", "Chen Chen", "Edresson Casanova", "Subhankar Ghosh", "Piotr Żelasko", "Zhehuai Chen", "Jason Li", "Jagadeesh Balam", "Boris Ginsburg"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to Interspeech 2025", "url": "http://arxiv.org/abs/2505.15670v3", "summary": "Spoken dialogue is an intuitive form of human-computer interaction, yet\ncurrent speech language models often remain constrained to turn-based\nexchanges, lacking real-time adaptability such as user barge-in. We propose a\nnovel duplex speech to speech (S2S) architecture featuring continuous user\ninputs and codec agent outputs with channel fusion that directly models\nsimultaneous user and agent streams. Using a pretrained streaming encoder for\nuser input enables the first duplex S2S model without requiring speech\npretrain. Separate architectures for agent and user modeling facilitate codec\nfine-tuning for better agent voices and halve the bitrate (0.6 kbps) compared\nto previous works. Experimental results show that the proposed model\noutperforms previous duplex models in reasoning, turn-taking, and barge-in\nabilities. The model requires significantly less speech data, as speech\npretrain is skipped, which markedly simplifies the process of building a duplex\nS2S model from any LLMs. Finally, it is the first openly available duplex S2S\nmodel with training and inference code to foster reproducibility.", "comment": "Accepted to Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2505.15670v3", "cate": "cs.CL", "date": "2025-05-21", "updated": "2025-07-15", "AI": {"title_translation": "高效直接的双工建模用于语音到语音语言模型", "tldr": "提出了一种新型双工语音到语音（S2S）架构，支持连续用户输入和实时适应，无需语音预训练，降低了比特率，并在推理、轮流和打断能力上优于现有模型，是首个开源的双工S2S模型。", "motivation": "当前语音语言模型受限于回合制交互，缺乏实时适应性，如用户打断（barge-in）功能。", "method": "提出了一种新型双工语音到语音（S2S）架构，具有连续用户输入和编解码器代理输出，并结合信道融合，直接建模同步的用户和代理流。使用预训练的流式编码器处理用户输入，使得该模型成为首个无需语音预训练的双工S2S模型。代理和用户建模采用独立架构，便于编解码器微调以获得更好的代理声音，并将比特率减半至0.6 kbps。", "result": "实验结果表明，所提出的模型在推理、轮流和打断能力方面优于先前的双工模型。模型所需语音数据显著减少，因为跳过了语音预训练，这极大地简化了从任何大型语言模型（LLMs）构建双工S2S模型的过程。比特率相比之前的工作减半（0.6 kbps）。", "conclusion": "该研究提出了一种高效、直接的双工语音到语音（S2S）模型，解决了现有模型实时交互不足的问题。通过创新的架构设计，实现了无需语音预训练，显著降低了数据需求和比特率，并在关键交互能力上超越了现有模型。此外，该模型是首个开源的双工S2S模型，有助于研究的复现和发展。", "translation": "口语对话是一种直观的人机交互形式，但当前的语音语言模型通常仍受限于回合制交流，缺乏实时适应性，例如用户打断。我们提出了一种新颖的双工语音到语音（S2S）架构，其特点是连续的用户输入和编解码器代理输出，并结合信道融合，直接建模同步的用户和代理流。使用预训练的流式编码器进行用户输入，使得该模型成为首个无需语音预训练的双工S2S模型。代理和用户建模的独立架构有助于编解码器微调以获得更好的代理声音，并将比特率（0.6 kbps）与先前的工作相比减半。实验结果表明，所提出的模型在推理、轮流和打断能力方面优于先前的双工模型。该模型所需的语音数据显著减少，因为跳过了语音预训练，这显著简化了从任何大型语言模型（LLMs）构建双工S2S模型的过程。最后，它是第一个公开可用的双工S2S模型，附带训练和推理代码，以促进可复现性。", "summary": "本文提出了一种高效直接的双工语音到语音（S2S）架构，旨在克服现有语音语言模型在实时交互（如用户打断）方面的局限性。该模型通过连续的用户输入和编解码器代理输出，直接建模同步的用户和代理流，并且是首个无需语音预训练的双工S2S模型。它显著减少了所需语音数据量，降低了比特率，并在推理、轮流和打断能力上超越了现有双工模型。此外，该模型是首个提供开源代码的双工S2S模型，促进了研究的可复现性。", "keywords": "双工S2S, 语音到语音, 实时交互, 用户打断, 语音语言模型", "comments": "该论文在语音到语音交互领域提出了重要的创新。其核心贡献在于引入了一种直接的双工建模方法，有效解决了传统回合制S2S模型的实时交互瓶颈，特别是对用户打断的支持。无需语音预训练极大地降低了模型构建的复杂性和数据需求，这对于S2S技术的大规模应用具有重要意义。同时，开源代码的发布也体现了其对社区贡献的决心，有助于加速该领域的研究进展。"}}
{"id": "2503.11167", "title": "Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction", "authors": ["Haonan Wang", "Qixiang Zhang", "Lehan Wang", "Xuanqi Huang", "Xiaomeng Li"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025, camera ready version", "url": "http://arxiv.org/abs/2503.11167v3", "summary": "Decoding visual stimuli from neural activity is essential for understanding\nthe human brain. While fMRI methods have successfully reconstructed static\nimages, fMRI-to-video reconstruction faces challenges due to the need for\ncapturing spatiotemporal dynamics like motion and scene transitions. Recent\napproaches have improved semantic and perceptual alignment but struggle to\nintegrate coarse fMRI data with detailed visual features. Inspired by the\nhierarchical organization of the visual system, we propose NEURONS, a novel\nframework that decouples learning into four correlated sub-tasks: key object\nsegmentation, concept recognition, scene description, and blurry video\nreconstruction. This approach simulates the visual cortex's functional\nspecialization, allowing the model to capture diverse video content. In the\ninference stage, NEURONS generates robust conditioning signals for a\npre-trained text-to-video diffusion model to reconstruct the videos. Extensive\nexperiments demonstrate that NEURONS outperforms state-of-the-art baselines,\nachieving solid improvements in video consistency (26.6%) and semantic-level\naccuracy (19.1%). Notably, NEURONS shows a strong functional correlation with\nthe visual cortex, highlighting its potential for brain-computer interfaces and\nclinical applications. Code and model weights are available at:\nhttps://github.com/xmed-lab/NEURONS.", "comment": "Accepted by ICCV 2025, camera ready version", "pdf_url": "http://arxiv.org/pdf/2503.11167v3", "cate": "cs.CV", "date": "2025-03-14", "updated": "2025-07-16", "AI": {"title_translation": "神经元：模仿人类视觉皮层提高fMRI到视频重建的保真度和可解释性", "tldr": "NEURONS是一个受视觉皮层启发的框架，通过解耦学习子任务和使用扩散模型，显著提高了fMRI到视频重建的视频一致性和语义准确性，并与视觉皮层功能高度相关。", "motivation": "从神经活动中解码视觉刺激对于理解人脑至关重要。虽然fMRI已成功重建静态图像，但fMRI到视频的重建在捕捉时空动态（如运动和场景转换）方面面临挑战，且现有方法难以整合粗糙的fMRI数据与详细的视觉特征。", "method": "受视觉系统分层组织的启发，本文提出了NEURONS框架。该框架将学习解耦为四个相关的子任务：关键对象分割、概念识别、场景描述和模糊视频重建。这种方法模拟了视觉皮层的功能特化，以捕捉多样化的视频内容。在推理阶段，NEURONS为预训练的文本到视频扩散模型生成鲁棒的条件信号，以重建视频。", "result": "NEURONS在实验中表现优于SOTA基线，在视频一致性方面取得了26.6%的显著提升，在语义级别准确性方面取得了19.1%的提升。值得注意的是，NEURONS与视觉皮层显示出强大的功能相关性。", "conclusion": "NEURONS框架通过模拟人类视觉皮层的分层处理，显著提高了fMRI到视频重建的保真度和可解释性，并展示了其在脑机接口和临床应用中的巨大潜力。", "translation": "从神经活动中解码视觉刺激对于理解人脑至关重要。虽然fMRI方法已成功重建静态图像，但fMRI到视频的重建面临挑战，因为它需要捕捉运动和场景转换等时空动态。最近的方法改善了语义和感知对齐，但在整合粗糙的fMRI数据与详细的视觉特征方面仍面临困难。受视觉系统分层组织的启发，我们提出了NEURONS，一个新颖的框架，将学习解耦为四个相关的子任务：关键对象分割、概念识别、场景描述和模糊视频重建。这种方法模拟了视觉皮层的功能特化，使模型能够捕捉多样化的视频内容。在推理阶段，NEURONS为预训练的文本到视频扩散模型生成鲁棒的条件信号，以重建视频。广泛的实验表明，NEURONS优于最先进的基线，在视频一致性（26.6%）和语义级别准确性（19.1%）方面取得了显著改进。值得注意的是，NEURONS与视觉皮层显示出强大的功能相关性，突显了其在脑机接口和临床应用中的潜力。代码和模型权重可在以下网址获取：https://github.com/xmed-lab/NEURONS。", "summary": "本文提出NEURONS框架，旨在通过模拟人类视觉皮层的分层处理来解决fMRI到视频重建的挑战。该框架将学习过程解耦为关键对象分割、概念识别、场景描述和模糊视频重建四个子任务，以捕捉复杂的视频内容。NEURONS利用预训练的文本到视频扩散模型进行重建，并在实验中显著提升了视频一致性和语义准确性，同时展现出与视觉皮层的高度功能相关性，预示其在脑机接口和临床应用中的潜力。", "keywords": "fMRI到视频重建, 视觉皮层, 神经网络, 扩散模型, 脑机接口", "comments": "该论文的创新点在于模仿人类视觉皮层的分层处理机制来解决fMRI到视频重建的复杂性问题。通过将任务解耦为多个子任务，NEURONS能够更有效地整合fMRI的粗粒度信息和视频的细粒度特征。其在性能上的显著提升以及与视觉皮层的高度相关性，为其在脑机接口和神经科学研究领域开辟了新的可能性，具有重要的应用前景和理论价值。"}}
{"id": "2507.11589", "title": "Einstein Fields: A Neural Perspective To Computational General Relativity", "authors": ["Sandeep Suresh Cranganore", "Andrei Bodnar", "Arturs Berzins", "Johannes Brandstetter"], "categories": ["cs.LG", "gr-qc"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      63 pages, 22 figures, 10 Tables, Github: this https URL", "url": "http://arxiv.org/abs/2507.11589v1", "summary": "We introduce Einstein Fields, a neural representation that is designed to\ncompress computationally intensive four-dimensional numerical relativity\nsimulations into compact implicit neural network weights. By modeling the\n\\emph{metric}, which is the core tensor field of general relativity, Einstein\nFields enable the derivation of physical quantities via automatic\ndifferentiation. However, unlike conventional neural fields (e.g., signed\ndistance, occupancy, or radiance fields), Einstein Fields are \\emph{Neural\nTensor Fields} with the key difference that when encoding the spacetime\ngeometry of general relativity into neural field representations, dynamics\nemerge naturally as a byproduct. Einstein Fields show remarkable potential,\nincluding continuum modeling of 4D spacetime, mesh-agnosticity, storage\nefficiency, derivative accuracy, and ease of use. We address these challenges\nacross several canonical test beds of general relativity and release an open\nsource JAX-based library, paving the way for more scalable and expressive\napproaches to numerical relativity. Code is made available at\nhttps://github.com/AndreiB137/EinFields", "comment": "63 pages, 22 figures, 10 Tables, Github:\n  https://github.com/AndreiB137/EinFields", "pdf_url": "http://arxiv.org/pdf/2507.11589v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "爱因斯坦场：计算广义相对论的神经视角", "tldr": "爱因斯坦场是一种新的神经表示，旨在将计算密集型四维数值相对论模拟压缩到紧凑的隐式神经网络权重中，并能通过自动微分推导物理量。", "motivation": "传统的四维数值相对论模拟计算量大，本研究旨在通过引入一种紧凑的神经网络表示来压缩这些模拟。", "method": "本文提出了爱因斯坦场，这是一种神经张量场，通过建模广义相对论的核心张量场——度规，将四维数值相对论模拟压缩到隐式神经网络权重中。它通过自动微分推导物理量，并且动力学作为副产品自然产生。", "result": "爱因斯坦场在连续建模四维时空、网格无关性、存储效率、导数精度和易用性方面显示出显著潜力，并在广义相对论的多个典型测试平台中解决了相关挑战。", "conclusion": "爱因斯坦场为数值相对论提供了更具可扩展性和表现力的方法，并已发布开源JAX库。", "translation": "我们引入了爱因斯坦场，这是一种神经表示，旨在将计算密集型四维数值相对论模拟压缩到紧凑的隐式神经网络权重中。通过建模度规（广义相对论的核心张量场），爱因斯坦场能够通过自动微分推导物理量。然而，与传统的神经场（例如，符号距离场、占用场或辐射场）不同，爱因斯坦场是神经张量场，其关键区别在于，在将广义相对论的时空几何编码到神经场表示中时，动力学自然而然地作为副产品出现。爱因斯坦场显示出非凡的潜力，包括四维时空的连续建模、网格无关性、存储效率、导数精度和易用性。我们在广义相对论的几个典型测试平台中解决了这些挑战，并发布了一个基于JAX的开源库，为数值相对论提供了更具可扩展性和表现力的方法。代码可在https://github.com/AndreiB137/EinFields获取。", "summary": "本文提出了“爱因斯坦场”，一种新型神经张量场表示，用于高效压缩和建模四维数值相对论模拟。它通过神经网络权重编码广义相对论的度规，实现物理量的自动微分推导，并能自然地涌现动力学。该方法在连续时空建模、存储效率和导数精度等方面展现出显著优势，为数值相对论提供了更具扩展性和表现力的新途径。", "keywords": "爱因斯坦场, 神经张量场, 广义相对论, 数值相对论, 自动微分", "comments": "这项工作具有显著的创新性，它将神经网络引入到广义相对论的计算中，特别是提出了“神经张量场”的概念，这与传统的神经场有本质区别，因为它能够自然地涌现动力学。这为高维物理模拟的压缩和分析提供了一个全新的视角，有望大大降低计算成本并提高效率。其网格无关性和存储效率的特性也使其在实际应用中具有巨大潜力。"}}
{"id": "2507.12442", "title": "Characterizing State Space Model (SSM) and SSM-Transformer Hybrid Language Model Performance with Long Context Length", "authors": ["Saptarshi Mitra", "Rachid Karami", "Haocheng Xu", "Sitao Huang", "Hyoukjun Kwon"], "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      12 pages, 7 figures", "url": "http://arxiv.org/abs/2507.12442v1", "summary": "The demand for machine intelligence capable of processing continuous,\nlong-context inputs on local devices is growing rapidly. However, the quadratic\ncomplexity and memory requirements of traditional Transformer architectures\nmake them inefficient and often unusable for these tasks. This has spurred a\nparadigm shift towards new architectures like State Space Models (SSMs) and\nhybrids, which promise near-linear scaling. While most current research focuses\non the accuracy and theoretical throughput of these models, a systematic\nperformance characterization on practical consumer hardware is critically\nneeded to guide system-level optimization and unlock new applications.\n  To address this gap, we present a comprehensive, comparative benchmarking of\ncarefully selected Transformer, SSM, and hybrid models specifically for\nlong-context inference on consumer and embedded GPUs. Our analysis reveals that\nSSMs are not only viable but superior for this domain, capable of processing\nsequences up to 220K tokens on a 24GB consumer GPU-approximately 4x longer than\ncomparable Transformers. While Transformers may be up to 1.8x faster at short\nsequences, SSMs demonstrate a dramatic performance inversion, becoming up to 4x\nfaster at very long contexts (~57K tokens). Our operator-level analysis reveals\nthat custom, hardware-aware SSM kernels dominate the inference runtime,\naccounting for over 55% of latency on edge platforms, identifying them as a\nprimary target for future hardware acceleration. We also provide detailed,\ndevice-specific characterization results to guide system co-design for the\nedge. To foster further research, we will open-source our characterization\nframework.", "comment": "12 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.12442v1", "cate": "cs.AR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "表征状态空间模型 (SSM) 和 SSM-Transformer 混合语言模型在长上下文长度下的性能", "tldr": "本研究系统地表征了状态空间模型（SSM）在消费级GPU上处理长上下文的性能，发现SSM在长序列处理上显著优于Transformer，能够处理更长的序列并实现更快的推理速度，并指出了SSM内核是未来硬件加速的关键目标。", "motivation": "对能够在本地设备上处理连续、长上下文输入的机器智能的需求迅速增长。然而，传统Transformer架构的二次方复杂性和内存需求使其效率低下且通常无法使用。尽管有新的架构如状态空间模型（SSM）及其混合模型，但目前大多数研究集中在这些模型的准确性和理论吞吐量，因此迫切需要对实际消费硬件上的系统性能进行表征，以指导系统级优化和解锁新的应用。", "method": "我们对精心挑选的Transformer、SSM和混合模型进行了全面、比较性的基准测试，专门针对消费级和嵌入式GPU上的长上下文推理。此外，我们还进行了算子级别的分析。研究团队将开源其表征框架。", "result": "SSM不仅可行，而且在长上下文推理领域表现更优，能够在24GB消费级GPU上处理长达220K tokens的序列，大约是同类Transformer的4倍。虽然Transformer在短序列上可能快1.8倍，但SSM在非常长的上下文（约57K tokens）下表现出显著的性能逆转，速度可达4倍。我们的算子级分析表明，定制的、硬件感知的SSM内核主导了推理运行时，占边缘平台延迟的55%以上。研究还提供了详细的、设备特定的表征结果。", "conclusion": "SSM是消费级硬件上长上下文推理的可行且更优的架构选择，在该领域显著优于Transformer。未来的优化工作应重点关注SSM内核的硬件加速。本研究为边缘系统协同设计提供了指导。", "translation": "对能够处理本地设备上连续、长上下文输入的机器智能的需求正在迅速增长。然而，传统Transformer架构的二次方复杂性和内存需求使其在这些任务中效率低下且通常无法使用。这促使了向状态空间模型（SSM）和混合模型等新架构的范式转变，这些架构有望实现接近线性的扩展。虽然目前大多数研究都集中在这些模型的准确性和理论吞吐量上，但迫切需要对实际消费硬件上的系统性能进行表征，以指导系统级优化并解锁新的应用。\n为了弥补这一空白，我们对精心挑选的Transformer、SSM和混合模型进行了全面、比较性的基准测试，专门针对消费级和嵌入式GPU上的长上下文推理。我们的分析表明，SSM不仅可行，而且在该领域表现更优，能够在24GB消费级GPU上处理长达220K tokens的序列——大约是同类Transformer的4倍。虽然Transformer在短序列上可能快1.8倍，但SSM在非常长的上下文（约57K tokens）下表现出显著的性能逆转，速度可达4倍。我们的算子级分析表明，定制的、硬件感知的SSM内核主导了推理运行时，占边缘平台延迟的55%以上，这表明它们是未来硬件加速的主要目标。我们还提供了详细的、设备特定的表征结果，以指导边缘系统的协同设计。为了促进进一步的研究，我们将开源我们的表征框架。", "summary": "本论文对Transformer、状态空间模型（SSM）和混合模型在消费级GPU上的长上下文推理性能进行了基准测试。研究发现，SSM在处理长序列方面表现更优，能够处理高达220K tokens的序列（是Transformer的4倍），并在非常长的上下文（约57K tokens）下速度快4倍，尽管Transformer在短序列上更快。算子级分析强调，SSM内核因其在推理运行时的主导地位，是未来硬件加速的关键目标。本研究提供了设备特定的性能表征结果，并开源了其框架，旨在指导边缘应用的系统协同设计。", "keywords": "状态空间模型,长上下文,性能表征,消费级GPU,语言模型", "comments": "这篇论文解决了长上下文语言模型评估中的一个关键实际空白，将评估从理论基准转向了真实世界的硬件性能。它系统地比较并确定了SSM在消费级GPU上长上下文处理方面的优势，并通过算子级分析将SSM内核确定为加速目标，这对指导未来的硬件和软件协同设计具有极高价值。开源其框架也是促进进一步研究和开发高效长上下文处理的重要贡献。"}}
{"id": "2507.11545", "title": "The AI Shadow War: SaaS vs. Edge Computing Architectures", "authors": ["Rhea Pritham Marpu", "Kevin J McNamara", "Preeti Gupta"], "categories": ["cs.DC", "cs.ET", "cs.NE"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11545v1", "summary": "The very DNA of AI architecture presents conflicting paths: centralized\ncloud-based models (Software-as-a-Service) versus decentralized edge AI (local\nprocessing on consumer devices). This paper analyzes the competitive\nbattleground across computational capability, energy efficiency, and data\nprivacy. Recent breakthroughs show edge AI challenging cloud systems on\nperformance, leveraging innovations like test-time training and\nmixture-of-experts architectures. Crucially, edge AI boasts a 10,000x\nefficiency advantage: modern ARM processors consume merely 100 microwatts\nforinference versus 1 watt for equivalent cloud processing. Beyond efficiency,\nedge AI secures data sovereignty by keeping processing local, dismantling\nsingle points of failure in centralized architectures. This democratizes access\nthroughaffordable hardware, enables offline functionality, and reduces\nenvironmental impact by eliminating data transmission costs. The edge AI market\nprojects explosive growth from $9 billion in 2025 to $49.6 billion by 2030\n(38.5% CAGR), fueled by privacy demands and real-time analytics. Critical\napplications including personalized education, healthcare monitoring,\nautonomous transport, and smart infrastructure rely on edge AI's ultra-low\nlatency (5-10ms versus 100-500ms for cloud). The convergence of architectural\ninnovation with fundamental physics confirms edge AI's distributed approach\naligns with efficient information processing, signaling the inevitable\nemergence of hybrid edge-cloud ecosystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11545v1", "cate": "cs.DC", "date": "2025-07-09", "updated": "2025-07-09", "AI": {"title_translation": "AI暗战：SaaS与边缘计算架构之争", "tldr": "本文分析了AI架构中SaaS（云端集中式）与边缘计算（设备本地处理）的竞争，指出边缘AI在性能、能效、数据隐私、成本和延迟方面具有显著优势，并预测其市场将爆炸式增长，最终将形成混合的边缘-云生态系统。", "motivation": "AI架构的本质DNA呈现出相互冲突的路径：集中式云端模型（SaaS）与去中心化边缘AI（消费者设备上的本地处理）。本文旨在分析这两种架构在计算能力、能效和数据隐私方面的竞争态势。", "method": "本文分析了SaaS与边缘计算架构在计算能力、能效和数据隐私方面的竞争战场。", "result": "研究发现，边缘AI在性能上正挑战云系统，利用测试时训练和专家混合架构等创新。边缘AI拥有10,000倍的能效优势（ARM处理器推理仅需100微瓦，而云处理需1瓦）。它通过本地处理确保数据主权，消除集中式架构的单点故障，实现可负担的硬件访问，支持离线功能，并减少环境影响。边缘AI市场预计将从2025年的90亿美元增长到2030年的496亿美元（复合年增长率38.5%），主要受隐私需求和实时分析推动。关键应用如个性化教育、医疗监控、自动驾驶和智能基础设施都依赖边缘AI的超低延迟（5-10毫秒，而云端为100-500毫秒）。", "conclusion": "建筑创新与基本物理学的结合证实，边缘AI的分布式方法与高效信息处理相符，预示着混合边缘-云生态系统的必然出现。", "translation": "AI架构的本质DNA呈现出相互冲突的路径：集中式云端模型（软件即服务）与去中心化边缘AI（消费者设备上的本地处理）。本文分析了计算能力、能效和数据隐私方面的竞争战场。最近的突破表明，边缘AI在性能上正在挑战云系统，利用测试时训练和专家混合架构等创新。至关重要的是，边缘AI拥有10,000倍的效率优势：现代ARM处理器进行推理仅消耗100微瓦，而同等云处理则需1瓦。除了效率，边缘AI通过保持本地处理来确保数据主权，从而瓦解了集中式架构中的单点故障。这通过可负担的硬件实现了民主化访问，支持离线功能，并通过消除数据传输成本来减少环境影响。受隐私需求和实时分析的推动，边缘AI市场预计将从2025年的90亿美元爆炸式增长到2030年的496亿美元（复合年增长率38.5%）。包括个性化教育、医疗监控、自动交通和智能基础设施在内的关键应用都依赖边缘AI的超低延迟（5-10毫秒，而云端为100-500毫秒）。架构创新与基本物理学的融合证实，边缘AI的分布式方法与高效信息处理相一致，预示着混合边缘-云生态系统的必然出现。", "summary": "本文深入分析了AI架构中SaaS（集中式云）与边缘计算（去中心化本地处理）的竞争。研究指出，边缘AI在计算能力、能效、数据隐私、成本和延迟方面具有显著优势，其能效比云端高10,000倍，并能提供超低延迟。报告预测边缘AI市场将实现爆炸式增长，并强调其在个性化教育、医疗和自动驾驶等关键应用中的重要性。最终，论文认为边缘AI的分布式特性与高效信息处理相符，预示着未来将是混合边缘-云生态系统。", "keywords": "边缘AI, SaaS, 边缘计算, AI架构, 数据隐私", "comments": "本文创新性地将SaaS与边缘计算的竞争比喻为“AI暗战”，并提供了具体的能效数据（10,000倍优势）和市场增长预测，强调了边缘AI在数据主权、离线功能和环境影响方面的优势。其重要性在于明确指出了边缘AI作为未来AI架构发展方向的必然性，并预见了混合边缘-云生态系统的形成。"}}
{"id": "2409.15615", "title": "KISS-Matcher: Fast and Robust Point Cloud Registration Revisited", "authors": ["Hyungtae Lim", "Daebeom Kim", "Gunhee Shin", "Jingnan Shi", "Ignacio Vizzo", "Hyun Myung", "Jaesik Park", "Luca Carlone"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 9 figures", "url": "http://arxiv.org/abs/2409.15615v3", "summary": "While global point cloud registration systems have advanced significantly in\nall aspects, many studies have focused on specific components, such as feature\nextraction, graph-theoretic pruning, or pose solvers. In this paper, we take a\nholistic view on the registration problem and develop an open-source and\nversatile C++ library for point cloud registration, called KISS-Matcher.\nKISS-Matcher combines a novel feature detector, Faster-PFH, that improves over\nthe classical fast point feature histogram (FPFH). Moreover, it adopts a\n$k$-core-based graph-theoretic pruning to reduce the time complexity of\nrejecting outlier correspondences. Finally, it combines these modules in a\ncomplete, user-friendly, and ready-to-use pipeline. As verified by extensive\nexperiments, KISS-Matcher has superior scalability and broad applicability,\nachieving a substantial speed-up compared to state-of-the-art outlier-robust\nregistration pipelines while preserving accuracy. Our code will be available at\nhttps://github.com/MIT-SPARK/KISS-Matcher.", "comment": "9 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2409.15615v3", "cate": "cs.CV", "date": "2024-09-23", "updated": "2025-07-16", "AI": {"title_translation": "KISS-Matcher：快速鲁棒的点云配准再探", "tldr": "KISS-Matcher是一个开源的C++库，用于快速鲁棒的点云配准，它结合了新的特征检测器和基于k-core的图论剪枝，实现了显著的速度提升并保持了精度。", "motivation": "尽管全局点云配准系统在各个方面都取得了显著进展，但许多研究都集中在特定组件上。本文旨在从整体角度解决配准问题，开发一个全面、用户友好且即插即用的点云配准库。", "method": "本文开发了KISS-Matcher，一个开源的C++点云配准库。它结合了：1) 一种新颖的特征检测器Faster-PFH，改进了经典的快速点特征直方图(FPFH)；2) 基于k-core的图论剪枝，以减少剔除异常对应关系的时间复杂度。这些模块被整合到一个完整的、用户友好的即用型管道中。", "result": "通过广泛的实验验证，KISS-Matcher展现出卓越的可扩展性和广泛的适用性。与最先进的对异常值鲁棒的配准管道相比，它在保持精度的同时实现了显著的加速。", "conclusion": "KISS-Matcher是一个快速、鲁棒且准确的开源C++库，为点云配准提供了一个整体解决方案，并在速度和鲁棒性方面优于现有技术。", "translation": "尽管全局点云配准系统在各个方面都取得了显著进展，但许多研究都集中在特定组件上，例如特征提取、图论剪枝或姿态求解器。在本文中，我们对配准问题采取了整体视角，并开发了一个名为KISS-Matcher的开源多功能C++点云配准库。KISS-Matcher结合了一种新颖的特征检测器Faster-PFH，它改进了经典的快速点特征直方图（FPFH）。此外，它采用了基于k-core的图论剪枝来减少剔除异常对应关系的时间复杂度。最后，它将这些模块组合成一个完整、用户友好且即插即用的管道。通过广泛的实验验证，KISS-Matcher具有卓越的可扩展性和广泛的适用性，与最先进的对异常值鲁棒的配准管道相比，它在保持精度的同时实现了显著的加速。我们的代码将在https://github.com/MIT-SPARK/KISS-Matcher上提供。", "summary": "KISS-Matcher是一个开源的C++点云配准库，旨在通过一种整体方法解决配准问题。它引入了Faster-PFH特征检测器和基于k-core的图论剪枝技术，以提高效率和鲁棒性。实验证明，KISS-Matcher在保持精度的同时，相比现有技术实现了显著的加速和更强的可扩展性。", "keywords": "点云配准, KISS-Matcher, Faster-PFH, k-core剪枝, 鲁棒性", "comments": "KISS-Matcher的创新在于其整体性方法，将改进的特征检测、高效的异常值剔除和用户友好的管道集成在一起。作为一个开源库，它有望为点云配准领域提供一个实用且高性能的工具，促进后续研究和应用。其强调速度和鲁棒性，同时保持精度，解决了实际应用中的关键挑战。"}}
{"id": "2507.11636", "title": "JSQA: Speech Quality Assessment with Perceptually-Inspired Contrastive Pretraining Based on JND Audio Pairs", "authors": ["Junyi Fan", "Donald Williamson"], "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted to WASPAA 2025", "url": "http://arxiv.org/abs/2507.11636v1", "summary": "Speech quality assessment (SQA) is often used to learn a mapping from a\nhigh-dimensional input space to a scalar that represents the mean opinion score\n(MOS) of the perceptual speech quality. Learning such a mapping is challenging\nfor many reasons, but largely because MOS exhibits high levels of inherent\nvariance due to perceptual and experimental-design differences. Many solutions\nhave been proposed, but many approaches do not properly incorporate perceptual\nfactors into their learning algorithms (beyond the MOS label), which could lead\nto unsatisfactory results. To this end, we propose JSQA, a two-stage framework\nthat pretrains an audio encoder using perceptually-guided contrastive learning\non just noticeable difference (JND) pairs, followed by fine-tuning for MOS\nprediction. We first generate pairs of audio data within JND levels, which are\nthen used to pretrain an encoder to leverage perceptual quality similarity\ninformation and map it into an embedding space. The JND pairs come from clean\nLibriSpeech utterances that are mixed with background noise from CHiME-3, at\ndifferent signal-to-noise ratios (SNRs). The encoder is later fine-tuned with\naudio samples from the NISQA dataset for MOS prediction. Experimental results\nsuggest that perceptually-inspired contrastive pretraining significantly\nimproves the model performance evaluated by various metrics when compared\nagainst the same network trained from scratch without pretraining. These\nfindings suggest that incorporating perceptual factors into pretraining greatly\ncontributes to the improvement in performance for SQA.", "comment": "Accepted to WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.11636v1", "cate": "eess.AS", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "JSQA：基于JND音频对的感知启发式对比预训练语音质量评估", "tldr": "提出JSQA，一个两阶段框架，通过感知启发的对比预训练（基于JND音频对）显著改善语音质量评估性能。", "motivation": "语音质量评估（SQA）将高维输入映射到表示平均意见得分（MOS）的标量是具有挑战性的，因为MOS存在固有的高方差，且许多现有方法未能充分将感知因素纳入学习算法。", "method": "本文提出了JSQA，一个两阶段框架。第一阶段，使用感知引导的对比学习在“刚刚可察觉差异”（JND）音频对上预训练音频编码器，这些JND对通过将LibriSpeech语音与CHiME-3背景噪声混合生成。第二阶段，预训练的编码器在NISQA数据集上进行微调以进行MOS预测。", "result": "实验结果表明，感知启发式对比预训练显著提高了模型的性能，优于未经预训练的相同网络。", "conclusion": "将感知因素纳入预训练对语音质量评估的性能提升有巨大贡献。", "translation": "语音质量评估（SQA）通常用于学习将高维输入空间映射到表示感知语音质量平均意见得分（MOS）的标量。学习这种映射具有挑战性，原因有很多，但主要是由于感知和实验设计差异，MOS表现出固有的高方差。尽管已提出许多解决方案，但许多方法未能将感知因素（除了MOS标签之外）适当地纳入其学习算法中，这可能导致不尽如人意的结果。为此，我们提出了JSQA，一个两阶段框架，它首先使用基于“刚刚可察觉差异”（JND）对的感知引导对比学习预训练音频编码器，然后进行MOS预测的微调。我们首先生成JND级别内的音频数据对，然后将其用于预训练编码器，以利用感知质量相似性信息并将其映射到嵌入空间。JND对来自干净的LibriSpeech语音，这些语音与CHiME-3的背景噪声以不同的信噪比（SNR）混合。该编码器随后使用NISQA数据集中的音频样本进行微调以进行MOS预测。实验结果表明，与未经预训练的相同网络相比，感知启发式对比预训练显著提高了模型的性能，并通过各种指标进行评估。这些发现表明，将感知因素纳入预训练极大地有助于提高SQA的性能。", "summary": "本文提出了JSQA，一个用于语音质量评估的两阶段框架。针对MOS高方差和现有方法未充分整合感知因素的问题，JSQA首先利用“刚刚可察觉差异”（JND）音频对进行感知引导的对比预训练，将感知相似性映射到嵌入空间。这些JND对通过混合LibriSpeech和CHiME-3数据集生成。随后，预训练的编码器在NISQA数据集上微调以预测MOS。实验证明，这种感知启发式预训练显著提升了模型在语音质量评估任务上的表现。", "keywords": "语音质量评估, 对比学习, 预训练, 刚刚可察觉差异, 感知", "comments": "这篇论文的创新点在于将“刚刚可察觉差异”（JND）的概念引入到语音质量评估的预训练阶段，通过构建感知相似的音频对进行对比学习，有效地将人类听觉感知特性融入到模型中。这种方法克服了传统MOS标签方差大、信息利用不充分的局限性，为语音质量评估模型提供了一个更具感知意义的初始化。其重要性在于，通过结合人类感知机制，模型能够更好地理解和区分语音质量的细微变化，从而提高评估的准确性和鲁棒性。"}}
{"id": "2507.12304", "title": "A near-complete resolution of the exponential-time complexity of k-opt for the traveling salesman problem", "authors": ["Sophia Heimann", "Hung P. Hoang", "Stefan Hougardy"], "categories": ["cs.DS", "cs.DM", "68W25, 68W40, 68Q25, 90C27", "F.2.2; G.2.1; G.2.2"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      41 pages, 19 figures", "url": "http://arxiv.org/abs/2507.12304v1", "summary": "The $k$-opt algorithm is one of the simplest and most widely used heuristics\nfor solving the traveling salesman problem. Starting from an arbitrary tour,\nthe $k$-opt algorithm improves the current tour in each iteration by exchanging\nup to $k$ edges. The algorithm continues until no further improvement of this\nkind is possible. For a long time, it remained an open question how many\niterations the $k$-opt algorithm might require for small values of $k$,\nassuming the use of an optimal pivot rule. In this paper, we resolve this\nquestion for the cases $k = 3$ and $k = 4$ by proving that in both these cases\nan exponential number of iterations may be needed even if an optimal pivot rule\nis used. Combined with a recent result from Heimann, Hoang, and Hougardy (ICALP\n2024), this provides a complete answer for all $k \\geq 3$ regarding the number\nof iterations the $k$-opt algorithm may require under an optimal pivot rule. In\naddition we establish an analogous exponential lower bound for the 2.5-opt\nalgorithm, a variant that generalizes 2-opt and is a restricted version of\n3-opt. All our results hold for both the general and the metric traveling\nsalesman problem.", "comment": "41 pages, 19 figures", "pdf_url": "http://arxiv.org/pdf/2507.12304v1", "cate": "cs.DS", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "旅行商问题k-opt算法指数时间复杂度的近乎完全解决", "tldr": "本文证明了旅行商问题中k-opt算法（k=3和k=4）即使使用最优枢轴规则，也可能需要指数级迭代次数，从而基本解决了k≥3时k-opt迭代次数的开放问题，并对2.5-opt算法给出了类似下界。", "motivation": "k-opt算法是解决旅行商问题的一种常用启发式算法。长期以来，对于小k值，在使用最优枢轴规则的情况下，k-opt算法可能需要多少次迭代一直是一个悬而未决的问题。", "method": "通过证明，本文解决了k=3和k=4的情况，即证明了在这两种情况下，即使使用最优枢轴规则，也可能需要指数级的迭代次数。此外，还为2.5-opt算法建立了类似的指数下界。", "result": "本文证明了对于k=3和k=4的k-opt算法，即使使用最优枢轴规则，也可能需要指数级的迭代次数。结合Heimann, Hoang和Hougardy (ICALP 2024)的最新结果，这为所有k≥3的k-opt算法在最优枢轴规则下的迭代次数问题提供了完整的答案。此外，还为2.5-opt算法建立了一个类似的指数下界。所有结果都适用于通用和度量旅行商问题。", "conclusion": "本文的证明基本解决了k≥3时k-opt算法在最优枢轴规则下所需迭代次数的开放问题，揭示了即使在最优条件下，这些启发式算法也可能具有指数级的时间复杂度。", "translation": "k-opt算法是解决旅行商问题最简单和最广泛使用的启发式算法之一。从任意巡回路线开始，k-opt算法在每次迭代中通过交换最多k条边来改进当前巡回路线。该算法一直持续到无法再进行此类改进为止。长期以来，对于小k值，假设使用最优枢轴规则，k-opt算法可能需要多少次迭代一直是一个悬而未决的问题。在本文中，我们通过证明在k=3和k=4这两种情况下，即使使用最优枢轴规则，也可能需要指数级的迭代次数，从而解决了这个问题。结合Heimann, Hoang和Hougardy（ICALP 2024）的最新结果，这为所有k≥3的k-opt算法在最优枢轴规则下可能需要的迭代次数提供了完整的答案。此外，我们还为2.5-opt算法建立了一个类似的指数下界，该算法是2-opt的推广，也是3-opt的一种受限版本。我们所有的结果都适用于通用和度量旅行商问题。", "summary": "本文解决了旅行商问题中k-opt算法在最优枢轴规则下迭代次数的长期开放问题，特别是证明了k=3和k=4时可能需要指数级迭代次数。结合现有研究，这为所有k≥3的情况提供了完整答案。此外，还为2.5-opt算法建立了类似的指数下界。所有结果适用于通用和度量旅行商问题。", "keywords": "旅行商问题, k-opt算法, 指数时间复杂度, 迭代次数, 启发式算法", "comments": "该论文通过严格的数学证明，解决了k-opt算法在旅行商问题中一个重要的理论开放问题，揭示了其在最坏情况下的指数时间复杂度，即使在最优枢轴规则下也是如此。这一发现对于理解k-opt算法的局限性及其在实践中的性能具有重要意义，尤其是在大规模问题上。研究结果对启发式算法的理论分析和实际应用都提供了宝贵的见解。"}}
{"id": "2507.12043", "title": "Information-Theoretic Generalization Bounds of Replay-based Continual Learning", "authors": ["Wen Wen", "Tieliang Gong", "Yunjiao Zhang", "Zeyu Gao", "Weizhan Zhang", "Yong-Jin Liu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12043v1", "summary": "Continual learning (CL) has emerged as a dominant paradigm for acquiring\nknowledge from sequential tasks while avoiding catastrophic forgetting.\nAlthough many CL methods have been proposed to show impressive empirical\nperformance, the theoretical understanding of their generalization behavior\nremains limited, particularly for replay-based approaches. In this paper, we\nestablish a unified theoretical framework for replay-based CL, deriving a\nseries of information-theoretic bounds that explicitly characterize how the\nmemory buffer interacts with the current task to affect generalization.\nSpecifically, our hypothesis-based bounds reveal that utilizing the limited\nexemplars of previous tasks alongside the current task data, rather than\nexhaustive replay, facilitates improved generalization while effectively\nmitigating catastrophic forgetting. Furthermore, our prediction-based bounds\nyield tighter and computationally tractable upper bounds of the generalization\ngap through the use of low-dimensional variables. Our analysis is general and\nbroadly applicable to a wide range of learning algorithms, exemplified by\nstochastic gradient Langevin dynamics (SGLD) as a representative method.\nComprehensive experimental evaluations demonstrate the effectiveness of our\nderived bounds in capturing the generalization dynamics in replay-based CL\nsettings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12043v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于回放的持续学习的信息论泛化界限", "tldr": "本文为基于回放的持续学习建立了一个统一的理论框架，推导了一系列信息论界限，以表征记忆缓冲区与当前任务如何相互作用影响泛化能力，并实验验证了其有效性。", "motivation": "尽管许多持续学习（CL）方法在经验性能上表现出色，但对其泛化行为的理论理解仍然有限，特别是对于基于回放的方法。本文旨在弥补这一理论空白。", "method": "本文为基于回放的持续学习建立了一个统一的理论框架，推导了一系列信息论界限来明确表征记忆缓冲区与当前任务如何相互作用影响泛化。具体包括基于假设的界限和基于预测的界限。该分析具有通用性，适用于广泛的学习算法，并以随机梯度朗之万动力学（SGLD）为例。", "result": "基于假设的界限表明，利用有限的先前任务示例与当前任务数据相结合，而非详尽的回放，有助于提高泛化能力并有效减轻灾难性遗忘。基于预测的界限通过使用低维变量，获得了更紧密且计算上易于处理的泛化差距上限。全面的实验评估证明了所推导界限在捕捉基于回放的持续学习设置中泛化动态的有效性。", "conclusion": "本文为基于回放的持续学习提供了信息论泛化界限的理论框架，揭示了有限回放的有效性，并提供了更紧密的泛化界限，有助于深入理解其泛化行为。", "translation": "持续学习（CL）已成为从序列任务中获取知识同时避免灾难性遗忘的主导范式。尽管许多CL方法已被提出并显示出令人印象深刻的经验性能，但对其泛化行为的理论理解仍然有限，特别是对于基于回放的方法。在本文中，我们为基于回放的CL建立了一个统一的理论框架，推导了一系列信息论界限，明确表征了记忆缓冲区如何与当前任务相互作用以影响泛化。具体而言，我们基于假设的界限揭示，利用先前任务的有限示例与当前任务数据相结合，而非详尽的回放，有助于改善泛化能力，同时有效减轻灾难性遗忘。此外，我们基于预测的界限通过使用低维变量，获得了更紧密且计算上易于处理的泛化差距上限。我们的分析具有通用性，广泛适用于各种学习算法，以随机梯度朗之万动力学（SGLD）作为代表性方法。全面的实验评估证明了我们推导的界限在捕捉基于回放的CL设置中泛化动态的有效性。", "summary": "本文针对基于回放的持续学习（CL）泛化行为理论理解不足的问题，提出了一个统一的信息论框架。通过推导基于假设和基于预测的泛化界限，论文揭示了有限回放在提升泛化和减轻灾难性遗忘方面的有效性，并提供了更紧密、计算可行的泛化差距上限。该理论框架具有通用性，并通过实验验证了其在捕捉CL泛化动态方面的能力。", "keywords": "持续学习, 回放, 泛化界限, 信息论, 灾难性遗忘", "comments": "本文的创新之处在于首次为基于回放的持续学习提供了系统的信息论泛化界限，从理论层面解释了其泛化行为。特别是，它揭示了有限回放策略的有效性，这对于资源受限的持续学习场景具有重要指导意义。其提出的预测型界限在计算上更具可行性，扩大了理论分析的实用性。这项工作为理解和设计更有效的持续学习算法奠定了坚实的理论基础。"}}
{"id": "2507.12027", "title": "SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation", "authors": ["Beining Xu", "Siting Zhu", "Hesheng Wang"], "categories": ["cs.CV", "cs.RO", "I.4.8; I.2.9"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 2 figures, IROS 2025", "url": "http://arxiv.org/abs/2507.12027v1", "summary": "We propose SGLoc, a novel localization system that directly regresses camera\nposes from 3D Gaussian Splatting (3DGS) representation by leveraging semantic\ninformation. Our method utilizes the semantic relationship between 2D image and\n3D scene representation to estimate the 6DoF pose without prior pose\ninformation. In this system, we introduce a multi-level pose regression\nstrategy that progressively estimates and refines the pose of query image from\nthe global 3DGS map, without requiring initial pose priors. Moreover, we\nintroduce a semantic-based global retrieval algorithm that establishes\ncorrespondences between 2D (image) and 3D (3DGS map). By matching the extracted\nscene semantic descriptors of 2D query image and 3DGS semantic representation,\nwe align the image with the local region of the global 3DGS map, thereby\nobtaining a coarse pose estimation. Subsequently, we refine the coarse pose by\niteratively optimizing the difference between the query image and the rendered\nimage from 3DGS. Our SGLoc demonstrates superior performance over baselines on\n12scenes and 7scenes datasets, showing excellent capabilities in global\nlocalization without initial pose prior. Code will be available at\nhttps://github.com/IRMVLab/SGLoc.", "comment": "8 pages, 2 figures, IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.12027v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "SGLoc: 基于3D高斯泼溅表示的相机姿态估计语义定位系统", "tldr": "SGLoc是一种新颖的语义定位系统，它利用语义信息直接从3D高斯泼溅表示中回归相机姿态，无需初始姿态先验。", "motivation": "本文旨在解决无需初始姿态先验信息，直接从3D高斯泼溅（3DGS）表示中进行相机6自由度姿态估计的挑战。", "method": "SGLoc系统通过利用语义信息，直接从3D高斯泼溅（3DGS）表示中回归相机姿态。它引入了多级姿态回归策略，逐步估计和细化查询图像的姿态，无需初始姿态先验。此外，该系统引入了基于语义的全局检索算法，通过匹配2D查询图像和3DGS语义表示中提取的场景语义描述符来建立2D和3D之间的对应关系，从而获得粗略姿态估计。随后，通过迭代优化查询图像与3DGS渲染图像之间的差异来细化粗略姿态。", "result": "SGLoc在12scenes和7scenes数据集上表现出优于基线的性能，在没有初始姿态先验的情况下展示了出色的全局定位能力。", "conclusion": "SGLoc是一个无需初始姿态先验的语义定位系统，能够有效利用3D高斯泼溅（3DGS）表示进行相机姿态估计，并在多个数据集上取得了优异的性能，展示了其在全局定位方面的卓越能力。", "translation": "我们提出了SGLoc，这是一种新颖的定位系统，它通过利用语义信息，直接从3D高斯泼溅（3DGS）表示中回归相机姿态。我们的方法利用2D图像和3D场景表示之间的语义关系来估计6自由度姿态，而无需先验姿态信息。在该系统中，我们引入了一种多级姿态回归策略，该策略逐步从全局3DGS地图中估计和细化查询图像的姿态，无需初始姿态先验。此外，我们引入了一种基于语义的全局检索算法，该算法在2D（图像）和3D（3DGS地图）之间建立对应关系。通过匹配2D查询图像和3DGS语义表示中提取的场景语义描述符，我们将图像与全局3DGS地图的局部区域对齐，从而获得粗略的姿态估计。随后，我们通过迭代优化查询图像和从3DGS渲染的图像之间的差异来细化粗略姿态。我们的SGLoc在12scenes和7scenes数据集上表现出优于基线的性能，在没有初始姿态先验的情况下展示了出色的全局定位能力。代码将在https://github.com/IRMVLab/SGLoc提供。", "summary": "SGLoc是一种新颖的语义定位系统，旨在无需初始姿态先验的情况下，直接从3D高斯泼溅（3DGS）表示中估计相机6自由度姿态。该系统通过引入多级姿态回归策略和基于语义的全局检索算法，首先进行粗略姿态估计，然后通过迭代优化进行细化。实验结果表明，SGLoc在12scenes和7scenes数据集上优于现有基线，证明了其在全局定位方面的卓越能力。", "keywords": "语义定位, 相机姿态估计, 3D高斯泼溅, 6自由度姿态, 全局定位", "comments": "该论文提出了一种创新的方法，将语义信息与3D高斯泼溅表示相结合，实现了无需初始姿态先验的相机定位。其多级回归策略和语义全局检索算法是关键创新点，有效解决了在复杂3D场景中进行鲁棒定位的挑战。该工作对于AR/VR、机器人导航等领域具有重要意义。"}}
{"id": "2501.13916", "title": "PBM-VFL: Vertical Federated Learning with Feature and Sample Privacy", "authors": ["Linh Tran", "Timothy Castiglia", "Stacy Patterson", "Ana Milanova"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.13916v3", "summary": "We present Poisson Binomial Mechanism Vertical Federated Learning (PBM-VFL),\na communication-efficient Vertical Federated Learning algorithm with\nDifferential Privacy guarantees. PBM-VFL combines Secure Multi-Party\nComputation with the recently introduced Poisson Binomial Mechanism to protect\nparties' private datasets during model training. We define the novel concept of\nfeature privacy and analyze end-to-end feature and sample privacy of our\nalgorithm. We compare sample privacy loss in VFL with privacy loss in HFL. We\nalso provide the first theoretical characterization of the relationship between\nprivacy budget, convergence error, and communication cost in\ndifferentially-private VFL. Finally, we empirically show that our model\nperforms well with high levels of privacy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.13916v3", "cate": "cs.LG", "date": "2025-01-23", "updated": "2025-07-16", "AI": {"title_translation": "PBM-VFL：具有特征和样本隐私的垂直联邦学习", "tldr": "PBM-VFL是一种通信高效的垂直联邦学习算法，通过结合安全多方计算和泊松二项式机制，在保护特征和样本隐私的同时，实现了差分隐私保证。", "motivation": "在模型训练过程中保护各方私有数据集的隐私，并解决垂直联邦学习中特征和样本隐私的保护问题。", "method": "提出了PBM-VFL算法，该算法结合了安全多方计算（SMC）和泊松二项式机制（PBM）来保护私有数据集。文章定义了特征隐私的新概念，并分析了算法的端到端特征和样本隐私。", "result": "首次对差分隐私垂直联邦学习（VFL）中隐私预算、收敛误差和通信成本之间的关系进行了理论刻画。实证结果表明，该模型在高度隐私保护下仍能表现良好。", "conclusion": "PBM-VFL通过结合安全多方计算和泊松二项式机制，有效保护了垂直联邦学习中的特征和样本隐私，并在理论上和实证上验证了其在通信效率、隐私保护和性能方面的有效性。", "translation": "我们提出了泊松二项式机制垂直联邦学习（PBM-VFL），这是一种具有差分隐私保证的通信高效垂直联邦学习算法。PBM-VFL将安全多方计算与最近引入的泊松二项式机制相结合，以在模型训练期间保护各方的私有数据集。我们定义了特征隐私的新概念，并分析了我们算法的端到端特征和样本隐私。我们比较了VFL中的样本隐私损失与HFL中的隐私损失。我们还首次对差分隐私VFL中隐私预算、收敛误差和通信成本之间的关系进行了理论刻画。最后，我们通过实证表明，我们的模型在高度隐私保护下表现良好。", "summary": "本文提出了PBM-VFL，一种结合安全多方计算和泊松二项式机制的垂直联邦学习算法，旨在提供差分隐私保证并保护特征和样本隐私。文章定义了新的特征隐私概念，分析了算法的端到端隐私，并首次理论刻画了差分隐私VFL中隐私预算、收敛误差和通信成本的关系。实验结果表明该模型在高度隐私保护下仍能保持良好性能。", "keywords": "垂直联邦学习, 差分隐私, 特征隐私, 泊松二项式机制, 安全多方计算", "comments": "PBM-VFL的创新之处在于将泊松二项式机制引入垂直联邦学习，并首次明确定义了特征隐私的概念，同时提供了隐私预算、收敛误差和通信成本之间关系的理论刻画，这对于差分隐私VFL的理论和实践都具有重要意义。"}}
{"id": "2507.11971", "title": "HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing", "authors": ["Tielong Wang", "Yuxuan Xiong", "Jinfan Liu", "Zhifan Zhang", "Ye Chen", "Yue Shi", "Bingbing Ni"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11971v1", "summary": "Current 3D representations like meshes, voxels, point clouds, and NeRF-based\nneural implicit fields exhibit significant limitations: they are often\ntask-specific, lacking universal applicability across reconstruction,\ngeneration, editing, and driving. While meshes offer high precision, their\ndense vertex data complicates editing; NeRFs deliver excellent rendering but\nsuffer from structural ambiguity, hindering animation and manipulation; all\nrepresentations inherently struggle with the trade-off between data complexity\nand fidelity. To overcome these issues, we introduce a novel 3D Hierarchical\nProxy Node representation. Its core innovation lies in representing an object's\nshape and texture via a sparse set of hierarchically organized\n(tree-structured) proxy nodes distributed on its surface and interior. Each\nnode stores local shape and texture information (implicitly encoded by a small\nMLP) within its neighborhood. Querying any 3D coordinate's properties involves\nefficient neural interpolation and lightweight decoding from relevant nearby\nand parent nodes. This framework yields a highly compact representation where\nnodes align with local semantics, enabling direct drag-and-edit manipulation,\nand offers scalable quality-complexity control. Extensive experiments across 3D\nreconstruction and editing demonstrate our method's expressive efficiency,\nhigh-fidelity rendering quality, and superior editability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11971v1", "cate": "cs.GR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "HPR3D：用于高保真三维重建和可控编辑的层次代理表示", "tldr": "HPR3D提出了一种新颖的层次代理节点表示，以克服现有3D表示在重建、生成、编辑和驱动方面的局限性，实现了高保真、紧凑且可编辑的3D模型。", "motivation": "当前的3D表示（如网格、体素、点云和基于NeRF的神经隐式场）存在显著局限性：它们通常是任务特定的，缺乏在重建、生成、编辑和驱动方面的普遍适用性。网格数据密度大，编辑复杂；NeRF存在结构模糊性，阻碍动画和操作；所有表示都在数据复杂性和保真度之间挣扎。", "method": "本文引入了一种新颖的3D层次代理节点表示（Hierarchical Proxy Node representation）。其核心创新在于通过稀疏的、分层组织（树状结构）的代理节点集（分布在对象表面和内部）来表示对象的形状和纹理。每个节点在其邻域内存储局部形状和纹理信息（由小型MLP隐式编码）。查询任何3D坐标的属性涉及高效的神经插值和来自相关附近及父节点的轻量级解码。", "result": "HPR3D框架产生了一个高度紧凑的表示，其中节点与局部语义对齐，支持直接拖拽编辑，并提供可扩展的质量-复杂度控制。广泛的3D重建和编辑实验证明了该方法的表达效率、高保真渲染质量和卓越的可编辑性。", "conclusion": "HPR3D通过引入层次代理节点表示，成功克服了现有3D表示的局限性，实现了高保真、紧凑且易于编辑的3D模型，为3D重建和编辑提供了一个通用且高效的解决方案。", "translation": "当前的3D表示形式，如网格、体素、点云以及基于NeRF的神经隐式场，都存在显著局限性：它们通常是任务特定的，缺乏在重建、生成、编辑和驱动方面的普遍适用性。虽然网格提供了高精度，但其密集的顶点数据使得编辑复杂化；NeRF提供了出色的渲染效果，但存在结构模糊性，阻碍了动画和操作；所有表示形式都固有地在数据复杂性和保真度之间挣扎。为了克服这些问题，我们引入了一种新颖的3D层次代理节点表示。其核心创新在于通过一组稀疏的、分层组织（树状结构）的代理节点来表示对象的形状和纹理，这些节点分布在其表面和内部。每个节点在其邻域内存储局部形状和纹理信息（由小型MLP隐式编码）。查询任何3D坐标的属性涉及高效的神经插值以及来自相关附近和父节点的轻量级解码。该框架产生了一个高度紧凑的表示，其中节点与局部语义对齐，从而实现了直接的拖拽编辑，并提供了可扩展的质量-复杂度控制。在3D重建和编辑方面的大量实验证明了我们方法的表达效率、高保真渲染质量和卓越的可编辑性。", "summary": "HPR3D提出了一种新颖的层次代理节点3D表示，旨在克服现有3D表示（如网格、体素、点云和NeRF）在通用性、编辑复杂性和保真度-复杂性权衡方面的局限性。该方法通过稀疏的、分层组织的代理节点来编码对象的形状和纹理，每个节点存储局部信息并支持高效的神经插值。这种紧凑的表示不仅与局部语义对齐，使得直接拖拽编辑成为可能，还提供了可扩展的质量-复杂度控制。实验证明了其在3D重建和编辑中的高表达效率、高保真渲染质量和优越的可编辑性。", "keywords": "3D重建, 层次代理表示, 可控编辑, 神经隐式场, 高保真", "comments": "HPR3D的创新点在于其层次代理节点表示，这有效地解决了现有3D表示在通用性、编辑性和数据复杂性之间的矛盾。通过将形状和纹理信息分散存储在稀疏的、树状结构的节点中，并结合局部MLP和神经插值，该方法实现了高保真渲染的同时保持了高度紧凑性和卓越的可编辑性。这种方法为3D内容的创建和操作提供了一个有前景的通用框架，特别是在需要灵活编辑和高质量输出的场景中具有重要意义。"}}
{"id": "2507.12366", "title": "FactorHD: A Hyperdimensional Computing Model for Multi-Object Multi-Class Representation and Factorization", "authors": ["Yifei Zhou", "Xuchu Huang", "Chenyu Ni", "Min Zhou", "Zheyu Yan", "Xunzhao Yin", "Cheng Zhuo"], "categories": ["cs.SC", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Symbolic Computation (cs.SC)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures, 2 tables, to be published in the 62nd DAC (Design Automation Conference) proceedings", "url": "http://arxiv.org/abs/2507.12366v1", "summary": "Neuro-symbolic artificial intelligence (neuro-symbolic AI) excels in logical\nanalysis and reasoning. Hyperdimensional Computing (HDC), a promising\nbrain-inspired computational model, is integral to neuro-symbolic AI. Various\nHDC models have been proposed to represent class-instance and class-class\nrelations, but when representing the more complex class-subclass relation,\nwhere multiple objects associate different levels of classes and subclasses,\nthey face challenges for factorization, a crucial task for neuro-symbolic AI\nsystems. In this article, we propose FactorHD, a novel HDC model capable of\nrepresenting and factorizing the complex class-subclass relation efficiently.\nFactorHD features a symbolic encoding method that embeds an extra memorization\nclause, preserving more information for multiple objects. In addition, it\nemploys an efficient factorization algorithm that selectively eliminates\nredundant classes by identifying the memorization clause of the target class.\nSuch model significantly enhances computing efficiency and accuracy in\nrepresenting and factorizing multiple objects with class-subclass relation,\novercoming limitations of existing HDC models such as \"superposition\ncatastrophe\" and \"the problem of 2\". Evaluations show that FactorHD achieves\napproximately 5667x speedup at a representation size of 10^9 compared to\nexisting HDC models. When integrated with the ResNet-18 neural network,\nFactorHD achieves 92.48% factorization accuracy on the Cifar-10 dataset.", "comment": "7 pages, 5 figures, 2 tables, to be published in the 62nd DAC (Design\n  Automation Conference) proceedings", "pdf_url": "http://arxiv.org/pdf/2507.12366v1", "cate": "cs.SC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "FactorHD：一种用于多对象多类表示和分解的超维度计算模型", "tldr": "FactorHD是一个新的超维度计算模型，它能高效地表示和分解复杂的类-子类关系，解决了现有模型的局限性，显著提高了计算效率和分解准确性。", "motivation": "现有的超维度计算（HDC）模型在表示更复杂的类-子类关系时面临挑战，尤其是在分解方面，这对于神经符号人工智能系统至关重要。它们难以处理多对象关联不同层级类和子类的情况。", "method": "本文提出了FactorHD，一种新颖的HDC模型，能够高效地表示和分解复杂的类-子类关系。它采用了一种符号编码方法，嵌入了一个额外的记忆子句，为多个对象保留了更多信息。此外，它使用了一种高效的分解算法，通过识别目标类的记忆子句来选择性地消除冗余类。", "result": "FactorHD模型显著提高了表示和分解具有类-子类关系的多个对象的计算效率和准确性，克服了现有HDC模型的局限性，如“叠加灾难”和“2的问题”。评估显示，在10^9的表示大小下，FactorHD比现有HDC模型实现了约5667倍的加速。与ResNet-18神经网络集成时，FactorHD在Cifar-10数据集上达到了92.48%的分解准确率。", "conclusion": "FactorHD成功地解决了现有超维度计算模型在处理复杂类-子类关系表示和分解方面的挑战，并通过其创新的编码和分解方法显著提升了效率和准确性，为神经符号人工智能领域做出了重要贡献。", "translation": "神经符号人工智能（neuro-symbolic AI）在逻辑分析和推理方面表现出色。超维度计算（HDC）作为一种有前景的受大脑启发的计算模型，是神经符号人工智能不可或缺的一部分。已提出了各种HDC模型来表示类-实例和类-类关系，但当表示更复杂的类-子类关系时，即多个对象关联不同层级的类和子类时，它们在分解这一神经符号人工智能系统中的关键任务上遇到了挑战。在本文中，我们提出了FactorHD，一种新颖的HDC模型，能够高效地表示和分解复杂的类-子类关系。FactorHD的特点是一种符号编码方法，该方法嵌入了一个额外的记忆子句，为多个对象保留了更多信息。此外，它采用了一种高效的分解算法，通过识别目标类的记忆子句来选择性地消除冗余类。这种模型显著提高了表示和分解具有类-子类关系的多个对象的计算效率和准确性，克服了现有HDC模型如“叠加灾难”和“2的问题”的局限性。评估显示，与现有HDC模型相比，FactorHD在10^9的表示大小下实现了约5667倍的加速。当与ResNet-18神经网络集成时，FactorHD在Cifar-10数据集上达到了92.48%的分解准确率。", "summary": "FactorHD是一种新颖的超维度计算（HDC）模型，旨在解决现有HDC模型在表示和分解复杂多对象、多层级类-子类关系时的挑战。该模型通过引入一个带有额外记忆子句的符号编码方法和一种高效的分解算法，显著提高了计算效率和分解准确性。实验证明，FactorHD在表示大小为10^9时实现了5667倍的加速，并在与ResNet-18集成后在Cifar-10数据集上达到了92.48%的分解准确率，有效克服了“叠加灾难”和“2的问题”等现有模型的局限性。", "keywords": "超维度计算, 神经符号AI, 分解, 多对象, 类-子类", "comments": "FactorHD的创新之处在于其独特的符号编码方法（嵌入记忆子句）和高效的分解算法，这使其能够有效处理多对象多类关系，并克服了现有HDC模型（如“叠加灾难”和“2的问题”）的显著局限性。其在计算效率和准确性上的巨大提升，特别是5667倍的加速，显示了其在神经符号人工智能领域的重要应用潜力。"}}
{"id": "2507.11797", "title": "GIST: Group Interaction Sensing Toolkit for Mixed Reality", "authors": ["Diana Romero", "Yasra Chandio", "Fatima Anwar", "Salma Elmalaki"], "categories": ["cs.HC", "cs.ET"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      11 pages, 6 figures", "url": "http://arxiv.org/abs/2507.11797v1", "summary": "Understanding how teams coordinate, share work, and negotiate roles in\nimmersive environments is critical for designing effective mixed-reality (MR)\napplications that support real-time collaboration. However, existing methods\neither rely on external cameras and offline annotation or focus narrowly on\nsingle modalities, limiting their validity and applicability. To address this,\nwe present a novel group interaction sensing toolkit (GIST), a deployable\nsystem that passively captures multi-modal interaction data, such as speech,\ngaze, and spatial proximity from commodity MR headset's sensors and\nautomatically derives both overall static interaction networks and dynamic\nmoment-by-moment behavior patterns. We evaluate GIST with a human subject study\nwith 48 participants across 12 four-person groups performing an open-ended\nimage-sorting task in MR. Our analysis shows strong alignment between the\nidentified behavior modes and shifts in interaction network structure,\nconfirming that momentary changes in speech, gaze, and proximity data are\nobservable through the sensor data.", "comment": "11 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.11797v1", "cate": "cs.HC", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "GIST: 混合现实中的群组交互感知工具包", "tldr": "GIST是一个用于混合现实环境的群组交互感知工具包，它能被动捕获多模态数据并分析团队协作模式。", "motivation": "在沉浸式环境中理解团队协作对于设计有效的混合现实（MR）应用至关重要。然而，现有方法依赖外部摄像头和离线标注，或仅关注单一模态，限制了其有效性和适用性。", "method": "提出了GIST，一个可部署的系统，它被动地从商用MR头显传感器捕获多模态交互数据（如语音、凝视和空间接近度），并自动推导出整体静态交互网络和动态的瞬时行为模式。通过一项包含48名参与者（12个四人小组）的人体研究进行评估，他们在MR中执行开放式图像分类任务。", "result": "分析显示，识别出的行为模式与交互网络结构的变化高度一致，证实了语音、凝视和接近度数据的瞬时变化可以通过传感器数据观察到。", "conclusion": "GIST能够有效捕获和分析MR环境中团队的多模态交互数据，为理解和设计协作MR应用提供了新的工具和见解。", "translation": "了解团队如何在沉浸式环境中协调、分担工作和协商角色，对于设计支持实时协作的有效混合现实（MR）应用至关重要。然而，现有方法要么依赖外部摄像头和离线标注，要么只狭隘地关注单一模态，这限制了它们的有效性和适用性。为了解决这个问题，我们提出了一种新颖的群组交互感知工具包（GIST），这是一个可部署的系统，它能被动地从商用MR头显的传感器捕获多模态交互数据，例如语音、凝视和空间接近度，并自动推导出整体静态交互网络和动态的瞬时行为模式。我们通过一项人体研究评估了GIST，该研究有48名参与者（分为12个四人小组），他们在MR中执行开放式图像分类任务。我们的分析显示，识别出的行为模式与交互网络结构的变化之间存在很强的一致性，证实了语音、凝视和接近度数据的瞬时变化可以通过传感器数据观察到。", "summary": "本文介绍了一种名为GIST的群组交互感知工具包，旨在解决混合现实（MR）环境中团队协作数据捕获和分析的局限性。GIST利用商用MR头显的内置传感器，被动地收集多模态交互数据（如语音、凝视和空间接近度），并能自动识别团队的静态交互网络和动态行为模式。通过一项人体研究评估，结果表明GIST能够有效捕捉并揭示团队行为模式与交互网络结构之间的关联，为理解和优化MR中的实时协作提供了新的方法。", "keywords": "混合现实, 群组交互, 多模态感知, 团队协作, 传感器数据", "comments": "GIST的创新之处在于其利用商用MR头显的内置传感器实现多模态、被动式的数据捕获，避免了传统方法对外部设备的依赖和离线标注的繁琐。这大大提高了在真实MR环境中进行团队交互研究的可行性和效率。其能够识别动态行为模式的能力，对于深入理解团队协作机制、进而设计更有效的协作MR应用具有重要意义。"}}
{"id": "2507.11875", "title": "DualReward: A Dynamic Reinforcement Learning Framework for Cloze Tests Distractor Generation", "authors": ["Tianyou Huang", "Xinglu Chen", "Jingshen Zhang", "Xinying Qiu", "Ruiying Niu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to CCL 2025", "url": "http://arxiv.org/abs/2507.11875v1", "summary": "This paper introduces DualReward, a novel reinforcement learning framework\nfor automatic distractor generation in cloze tests. Unlike conventional\napproaches that rely primarily on supervised learning or static generative\nmodels, our method employs a dual reward structure with adaptive scaling that\ndifferentiates between human-created gold standard distractors and\nmodel-generated candidates. The framework dynamically adjusts reward signal\nintensity based on model performance and confidence. We evaluate our approach\non both passage-level (CLOTH-F) and sentence-level (MCQ) cloze test datasets,\ndemonstrating consistent improvements over state-of-the-art baselines.\nExperimental results show that our adaptive reward scaling mechanism provides\nmodest but consistent benefits on homogeneous datasets (CLOTH-F) and more\nsubstantial improvements (3.48-3.86% in P@1) on diverse, cross-domain data\n(MCQ), suggesting its particular effectiveness for handling varied question\ntypes and domains. Our work offers a flexible framework that effectively\nbalances learning from reliable human examples while exploring novel,\nhigh-quality distractors for automated test generation.", "comment": "Accepted to CCL 2025", "pdf_url": "http://arxiv.org/pdf/2507.11875v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "双重奖励：一种用于完形填空干扰项生成的动态强化学习框架", "tldr": "DualReward是一个新的强化学习框架，通过动态双重奖励结构生成完形填空干扰项，在不同数据集上均优于现有方法，尤其在多样化数据上表现更佳。", "motivation": "现有完形填空干扰项生成方法主要依赖监督学习或静态生成模型，存在局限性。本文旨在引入一种新颖的强化学习框架，以克服这些限制，实现自动、高质量的干扰项生成，并有效平衡从人类示例学习与探索新颖、高质量的干扰项。", "method": "本文介绍了DualReward，一个用于自动生成完形填空干扰项的新颖强化学习框架。该方法采用具有自适应缩放的双重奖励结构，能够区分人类创建的黄金标准干扰项和模型生成的候选项。框架根据模型性能和置信度动态调整奖励信号强度。", "result": "在篇章级（CLOTH-F）和句子级（MCQ）完形填空数据集上，DualReward均显示出持续优于现有最新基线。自适应奖励缩放机制在同质数据集（CLOTH-F）上提供了适度但持续的益处，在多样化、跨领域数据（MCQ）上提供了更显著的改进（P@1提升3.48-3.86%），表明其在处理各种问题类型和领域方面的特殊有效性。", "conclusion": "DualReward框架提供了一个灵活的解决方案，通过有效平衡从可靠的人类示例中学习与探索新颖、高质量的干扰项，实现了自动化测试生成，尤其在处理多样化数据时表现出色。", "translation": "本文介绍了DualReward，一个用于完形填空自动干扰项生成的新颖强化学习框架。与主要依赖监督学习或静态生成模型的传统方法不同，我们的方法采用了一种具有自适应缩放的双重奖励结构，该结构区分了人类创建的黄金标准干扰项和模型生成的候选项。该框架根据模型性能和置信度动态调整奖励信号强度。我们在篇章级（CLOTH-F）和句子级（MCQ）完形填空数据集上评估了我们的方法，结果表明其持续优于现有最新基线。实验结果显示，我们的自适应奖励缩放机制在同质数据集（CLOTH-F）上提供了适度但持续的益处，并在多样化、跨领域数据（MCQ）上提供了更显著的改进（P@1提升3.48-3.86%），这表明其在处理各种问题类型和领域方面的特殊有效性。我们的工作提供了一个灵活的框架，有效平衡了从可靠的人类示例中学习与探索新颖、高质量的干扰项，以实现自动化测试生成。", "summary": "DualReward是一个创新的强化学习框架，专为完形填空干扰项的自动化生成而设计。它引入了独特的双重奖励机制，能区分人工和模型生成的干扰项，并根据模型表现动态调整奖励。在CLOTH-F和MCQ数据集上的评估显示，DualReward持续超越现有基线，尤其在多样化数据上表现出显著提升，证明了其在平衡人类学习和新颖干扰项探索方面的有效性。", "keywords": "强化学习, 完形填空, 干扰项生成, 双重奖励, 自适应缩放", "comments": "DualReward的创新在于其动态的、自适应的双重奖励结构，这克服了传统监督学习和静态生成模型的局限性。通过区分人类和模型生成的干扰项并动态调整奖励，它能够更好地平衡学习现有知识和探索新颖高质量的干扰项，这对于自动化测试生成，尤其是在处理多样化和复杂语境下的干扰项生成具有重要意义。"}}
{"id": "2506.10323", "title": "ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space", "authors": ["Chuyang Chen", "Brendan Dolan-Gavitt", "Zhiqiang Lin"], "categories": ["cs.CR", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted by USENIX Security'25 Cycle 2", "url": "http://arxiv.org/abs/2506.10323v3", "summary": "Generation-based fuzzing produces appropriate testing cases according to\nspecifications of input grammars and semantic constraints to test systems and\nsoftware. However, these specifications require significant manual efforts to\nconstruct. This paper proposes a new approach, ELFuzz (Evolution Through Large\nLanguage Models for Fuzzing), that automatically synthesizes generation-based\nfuzzers tailored to a system under test (SUT) via LLM-driven synthesis over\nfuzzer space. At a high level, it starts with minimal seed fuzzers and propels\nthe synthesis by fully automated LLM-driven evolution with coverage guidance.\nCompared to previous approaches, ELFuzz can 1) seamlessly scale to SUTs of\nreal-world sizes -- up to 1,791,104 lines of code in our evaluation -- and 2)\nsynthesize efficient fuzzers that catch interesting grammatical structures and\nsemantic constraints in a human-understandable way. Our evaluation compared\nELFuzz with specifications manually written by domain experts and synthesized\nby state-of-the-art approaches. It shows that ELFuzz achieves up to 434.8% more\ncoverage and triggers up to 174.0% more artificially injected bugs. We also\nused ELFuzz to conduct a real-world fuzzing campaign on the newest version of\ncvc5 for 14 days, and encouragingly, it found five 0-day bugs (three are\nexploitable). Moreover, we conducted an ablation study, which shows that the\nfuzzer space model, the key component of ELFuzz, contributes the most (up to\n62.5%) to the effectiveness of ELFuzz. Further analysis of the fuzzers\nsynthesized by ELFuzz confirms that they catch interesting grammatical\nstructures and semantic constraints in a human-understandable way. The results\npresent the promising potential of ELFuzz for more automated, efficient, and\nextensible input generation for fuzzing.", "comment": "Accepted by USENIX Security'25 Cycle 2", "pdf_url": "http://arxiv.org/pdf/2506.10323v3", "cate": "cs.CR", "date": "2025-06-12", "updated": "2025-07-15", "AI": {"title_translation": "ELFuzz：通过LLM驱动的模糊器空间合成实现高效输入生成", "tldr": "本文提出了ELFuzz，一种通过LLM驱动的合成和覆盖率指导，自动生成高效模糊器的新方法，显著提高了代码覆盖率并发现了更多漏洞，包括零日漏洞。", "motivation": "现有基于生成的模糊测试方法需要大量人工构建输入语法和语义约束规范，耗时耗力。", "method": "本文提出ELFuzz（通过大型语言模型进行模糊测试的进化），通过LLM驱动的模糊器空间合成，自动为待测系统（SUT）定制生成基于生成的模糊器。它从最小种子模糊器开始，并通过LLM驱动的、有覆盖率指导的全自动化进化来推动合成。", "result": "ELFuzz能够无缝扩展到真实世界规模的SUT（高达1,791,104行代码），并合成高效且人类可理解的模糊器。与现有方法相比，ELFuzz的代码覆盖率提高了434.8%，触发的人工注入错误增加了174.0%。在对cvc5的14天真实世界模糊测试中，发现了五个零日漏洞（其中三个可利用）。消融研究表明，模糊器空间模型是ELFuzz的关键组件，贡献最大（高达62.5%）。", "conclusion": "ELFuzz在模糊测试中实现更自动化、高效和可扩展的输入生成方面具有广阔前景。", "translation": "基于生成的模糊测试根据输入语法和语义约束规范生成适当的测试用例，以测试系统和软件。然而，这些规范的构建需要大量人工努力。本文提出了一种新方法ELFuzz（通过大型语言模型进行模糊测试的进化），通过LLM驱动的模糊器空间合成，自动为待测系统（SUT）合成定制的基于生成的模糊器。从宏观上看，它从最小的种子模糊器开始，并通过LLM驱动的、有覆盖率指导的全自动化进化来推动合成。与以前的方法相比，ELFuzz能够1）无缝扩展到真实世界规模的SUT——在我们的评估中高达1,791,104行代码——以及2）以人类可理解的方式合成能够捕获有趣的语法结构和语义约束的高效模糊器。我们的评估将ELFuzz与领域专家手动编写的规范以及最先进方法合成的规范进行了比较。结果表明，ELFuzz的代码覆盖率提高了434.8%，触发的人工注入错误增加了174.0%。我们还使用ELFuzz对最新版本的cvc5进行了为期14天的真实世界模糊测试，令人鼓舞的是，它发现了五个零日漏洞（其中三个是可利用的）。此外，我们进行了一项消融研究，结果表明ELFuzz的关键组件——模糊器空间模型——对ELFuzz的有效性贡献最大（高达62.5%）。对ELFuzz合成的模糊器的进一步分析证实，它们以人类可理解的方式捕获了有趣的语法结构和语义约束。这些结果表明ELFuzz在模糊测试中实现更自动化、高效和可扩展的输入生成方面具有广阔前景。", "summary": "ELFuzz是一种新的模糊测试方法，它利用大型语言模型（LLM）驱动的模糊器空间合成，自动为待测系统生成定制的模糊器。该方法通过LLM驱动的进化和覆盖率指导，解决了传统基于生成模糊测试中手动构建输入规范的难题。实验结果表明，ELFuzz在代码覆盖率和发现漏洞方面显著优于现有方法，并成功发现了真实世界的零日漏洞，展现了其在自动化、高效和可扩展输入生成方面的巨大潜力。", "keywords": "模糊测试, LLM, 输入生成, 模糊器合成, 覆盖率指导", "comments": "ELFuzz的创新之处在于将大型语言模型（LLM）引入模糊测试的模糊器生成过程，通过LLM驱动的合成和进化，显著减少了人工构建测试规范的工作量。其重要性体现在能够自动化生成高效且人类可理解的模糊器，并在真实世界应用中展现出发现零日漏洞的能力。消融研究也突出了其核心组件——模糊器空间模型的关键作用。"}}
{"id": "2507.11776", "title": "Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network", "authors": ["Merel Kampere", "Ali Mohammed Mansoor Alsahag"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11776v1", "summary": "The Dutch railway network is one of the busiest in the world, with delays\nbeing a prominent concern for the principal passenger railway operator NS. This\nresearch addresses a gap in delay prediction studies within the Dutch railway\nnetwork by employing an XGBoost Classifier with a focus on topological\nfeatures. Current research predominantly emphasizes short-term predictions and\nneglects the broader network-wide patterns essential for mitigating ripple\neffects. This research implements and improves an existing methodology,\noriginally designed to forecast the evolution of the fast-changing US air\nnetwork, to predict delays in the Dutch Railways. By integrating Node\nCentrality Measures and comparing multiple classifiers like RandomForest,\nDecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is\nto predict delayed trajectories. However, the results reveal limited\nperformance, especially in non-simultaneous testing scenarios, suggesting the\nnecessity for more context-specific adaptations. Regardless, this research\ncontributes to the understanding of transportation network evaluation and\nproposes future directions for developing more robust predictive models for\ndelays.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11776v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "使用网络特征预测延迟轨迹：一项针对荷兰铁路网络的研究", "tldr": "本研究利用网络特征（XGBoost分类器）预测荷兰铁路的延迟轨迹，但发现模型性能有限，尤其在非同步测试场景下，表明需要更具体的情境适应。", "motivation": "荷兰铁路网络是世界上最繁忙的网络之一，延误是主要客运运营商NS关注的一个突出问题。当前研究主要强调短期预测，并忽视了对缓解连锁效应至关重要的更广泛的网络模式，本研究旨在弥补这一空白。", "method": "本研究采用XGBoost分类器，侧重拓扑特征。它实施并改进了一种现有方法（最初用于预测美国航空网络的演变），以预测荷兰铁路的延误。研究通过整合节点中心性度量，并比较了多种分类器，如随机森林（RandomForest）、决策树（DecisionTree）、梯度提升（GradientBoosting）、AdaBoost和逻辑回归（LogisticRegression）。", "result": "研究结果显示模型性能有限，特别是在非同步测试场景中，这表明需要更多特定于情境的适应。", "conclusion": "本研究有助于理解交通网络评估，并提出了开发更稳健的延迟预测模型的未来方向。", "translation": "荷兰铁路网络是世界上最繁忙的网络之一，延误是主要客运运营商NS关注的一个突出问题。本研究通过采用侧重拓扑特征的XGBoost分类器，弥补了荷兰铁路网络延误预测研究中的空白。当前研究主要强调短期预测，并忽视了对缓解连锁效应至关重要的更广泛的网络模式。本研究实施并改进了一种现有方法，该方法最初旨在预测快速变化的美国航空网络的演变，以预测荷兰铁路的延误。通过整合节点中心性度量并比较多种分类器，如随机森林、决策树、梯度提升、AdaBoost和逻辑回归，目标是预测延迟轨迹。然而，结果显示性能有限，特别是在非同步测试场景中，这表明需要更多特定于情境的适应。尽管如此，本研究有助于理解交通网络评估，并提出了开发更稳健的延迟预测模型的未来方向。", "summary": "本文针对荷兰铁路网络的延误问题，采用XGBoost分类器并结合拓扑特征及节点中心性度量，改进现有方法以预测延迟轨迹。研究比较了多种分类器，发现模型性能有限，尤其在非同步测试中。尽管如此，该研究仍为交通网络评估提供了见解，并指出了未来改进延迟预测模型的方向。", "keywords": "铁路延误预测, 网络特征, XGBoost, 荷兰铁路, 拓扑特征", "comments": "本研究的创新点在于将源于航空网络预测的方法应用于铁路网络，并侧重于网络拓扑特征，试图从更宏观的网络模式角度解决铁路延误的连锁效应问题。其重要性在于为繁忙的铁路网络延误预测提供了新的视角和尝试。然而，模型的有限性能揭示了将跨领域方法应用于特定复杂系统时可能面临的挑战，并强调了情境适应性和模型优化的必要性。"}}
{"id": "2507.12008", "title": "Dual form Complementary Masking for Domain-Adaptive Image Segmentation", "authors": ["Jiawen Wang", "Yinda Chen", "Xiaoyu Liu", "Che Liu", "Dong Liu", "Jianqing Gao", "Zhiwei Xiong"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICML 2025", "url": "http://arxiv.org/abs/2507.12008v1", "summary": "Recent works have correlated Masked Image Modeling (MIM) with consistency\nregularization in Unsupervised Domain Adaptation (UDA). However, they merely\ntreat masking as a special form of deformation on the input images and neglect\nthe theoretical analysis, which leads to a superficial understanding of masked\nreconstruction and insufficient exploitation of its potential in enhancing\nfeature extraction and representation learning. In this paper, we reframe\nmasked reconstruction as a sparse signal reconstruction problem and\ntheoretically prove that the dual form of complementary masks possesses\nsuperior capabilities in extracting domain-agnostic image features. Based on\nthis compelling insight, we propose MaskTwins, a simple yet effective UDA\nframework that integrates masked reconstruction directly into the main training\npipeline. MaskTwins uncovers intrinsic structural patterns that persist across\ndisparate domains by enforcing consistency between predictions of images masked\nin complementary ways, enabling domain generalization in an end-to-end manner.\nExtensive experiments verify the superiority of MaskTwins over baseline methods\nin natural and biological image segmentation. These results demonstrate the\nsignificant advantages of MaskTwins in extracting domain-invariant features\nwithout the need for separate pre-training, offering a new paradigm for\ndomain-adaptive segmentation.", "comment": "Accepted by ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.12008v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "域适应图像分割的双形式互补掩码", "tldr": "本文提出MaskTwins框架，通过理论证明双形式互补掩码在提取域无关特征方面的优越性，并将其集成到UDA训练流程中，实现了卓越的域适应图像分割性能。", "motivation": "现有MIM与UDA结合的工作未能充分理解掩码重建，且忽视理论分析，导致对特征提取和表示学习的潜力开发不足。", "method": "将掩码重建重构为稀疏信号重建问题，理论证明双形式互补掩码在提取域无关特征方面的优越性。在此基础上，提出MaskTwins框架，通过强制互补掩码图像预测之间的一致性，揭示跨域的内在结构模式，实现端到端的域泛化。", "result": "大量实验验证了MaskTwins在自然和生物图像分割中优于基线方法，无需单独预训练即可提取域不变特征。", "conclusion": "MaskTwins为域适应分割提供了一种新范式，证明了其在提取域不变特征方面的显著优势。", "translation": "近期工作已将掩码图像建模（MIM）与无监督域适应（UDA）中的一致性正则化相关联。然而，它们仅仅将掩码视为输入图像上的一种特殊形变，并忽视了理论分析，这导致对掩码重建的肤浅理解，以及对其在增强特征提取和表示学习方面潜力的利用不足。在本文中，我们将掩码重建重构为稀疏信号重建问题，并从理论上证明了互补掩码的双形式在提取域无关图像特征方面具有卓越的能力。基于这一引人注目的见解，我们提出了MaskTwins，一个简单而有效的UDA框架，它将掩码重建直接集成到主训练流程中。MaskTwins通过强制互补方式掩码图像的预测之间的一致性，揭示了跨不同域存在的内在结构模式，从而实现端到端的域泛化。大量的实验验证了MaskTwins在自然和生物图像分割方面优于基线方法。这些结果表明MaskTwins在无需单独预训练的情况下提取域不变特征方面具有显著优势，为域适应分割提供了一种新范式。", "summary": "本文针对现有掩码图像建模（MIM）在无监督域适应（UDA）中应用时理论不足、潜力未充分挖掘的问题，将掩码重建重构为稀疏信号重建，并理论证明双形式互补掩码能更有效地提取域无关特征。在此基础上，提出MaskTwins框架，通过强制互补掩码图像预测间的一致性，实现端到端的域泛化，并在图像分割任务上验证了其优越性，为域适应分割提供了新范式。", "keywords": "域适应, 图像分割, 掩码图像建模, 互补掩码, MaskTwins", "comments": "本文的创新点在于从理论上重新审视了掩码重建，并提出了“双形式互补掩码”的概念，这为域适应问题提供了一个新的视角。将理论洞察转化为实用的MaskTwins框架，并直接集成到UDA训练流程中，简化了流程并提升了性能，尤其强调了无需预训练即可提取域不变特征，具有重要的实际应用价值。"}}
{"id": "2507.12012", "title": "Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease", "authors": ["Matthias Perkonigg", "Nina Bastati", "Ahmed Ba-Ssalamah", "Peter Mesenbrink", "Alexander Goehler", "Miljen Martic", "Xiaofei Zhou", "Michael Trauner", "Georg Langs"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12012v1", "summary": "Quantifiable image patterns associated with disease progression and treatment\nresponse are critical tools for guiding individual treatment, and for\ndeveloping novel therapies. Here, we show that unsupervised machine learning\ncan identify a pattern vocabulary of liver tissue in magnetic resonance images\nthat quantifies treatment response in diffuse liver disease. Deep clustering\nnetworks simultaneously encode and cluster patches of medical images into a\nlow-dimensional latent space to establish a tissue vocabulary. The resulting\ntissue types capture differential tissue change and its location in the liver\nassociated with treatment response. We demonstrate the utility of the\nvocabulary on a randomized controlled trial cohort of non-alcoholic\nsteatohepatitis patients. First, we use the vocabulary to compare longitudinal\nliver change in a placebo and a treatment cohort. Results show that the method\nidentifies specific liver tissue change pathways associated with treatment, and\nenables a better separation between treatment groups than established\nnon-imaging measures. Moreover, we show that the vocabulary can predict biopsy\nderived features from non-invasive imaging data. We validate the method on a\nseparate replication cohort to demonstrate the applicability of the proposed\nmethod.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12012v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "识别图像表型特征以追踪肝病治疗反应", "tldr": "本研究展示了一种无监督机器学习方法，通过深度聚类网络识别肝脏MRI图像中的组织模式词汇，从而量化弥漫性肝病的治疗反应，并能更好地区分治疗组和预测活检特征。", "motivation": "量化图像模式与疾病进展和治疗反应相关，对于指导个体化治疗和开发新疗法至关重要。", "method": "研究使用无监督机器学习识别肝脏磁共振图像中的肝组织模式词汇。具体通过深度聚类网络同时编码和聚类医学图像的补丁到低维潜在空间，以建立组织词汇。", "result": "该方法识别出与治疗相关的特定肝组织变化途径；与现有非成像测量方法相比，能更好地分离治疗组；该词汇可以从非侵入性成像数据中预测活检衍生特征。该方法在独立的复制队列中得到了验证。", "conclusion": "所提出的方法能够通过识别图像表型特征来量化和追踪肝病的治疗反应，并提供比传统方法更好的治疗效果区分能力和活检特征预测能力，具有重要的临床应用潜力。", "translation": "与疾病进展和治疗反应相关的可量化图像模式是指导个体治疗和开发新疗法的关键工具。在此，我们展示了无监督机器学习可以识别磁共振图像中肝组织的模式词汇，从而量化弥漫性肝病的治疗反应。深度聚类网络同时对医学图像的补丁进行编码和聚类，将其映射到低维潜在空间，以建立组织词汇。由此产生的组织类型捕获了与治疗反应相关的肝脏差异组织变化及其位置。我们在非酒精性脂肪性肝炎患者的随机对照试验队列中展示了该词汇的实用性。首先，我们使用该词汇比较了安慰剂组和治疗组的纵向肝脏变化。结果表明，该方法识别出与治疗相关的特定肝组织变化途径，并且与现有非成像测量方法相比，能够更好地分离治疗组。此外，我们还表明该词汇可以从非侵入性成像数据中预测活检衍生的特征。我们在独立的复制队列中验证了该方法，以证明所提出方法的适用性。", "summary": "本研究开发了一种基于无监督机器学习的新方法，利用深度聚类网络从肝脏磁共振图像中识别出一种“组织词汇”，用于量化弥漫性肝病的治疗反应。该方法能够捕捉治疗引起的肝脏组织变化，并在非酒精性脂肪性肝炎患者的随机对照试验中，显示出比传统非成像方法更好的治疗组区分能力，并能预测活检特征。该方法已在独立的队列中得到验证，展示了其在追踪肝病治疗反应方面的潜力。", "keywords": "肝病, 治疗反应, 图像表型, 无监督机器学习, 深度聚类", "comments": "这项研究的创新之处在于利用无监督深度学习从医学图像中提取出可量化的“组织词汇”，从而实现了对肝病治疗反应的非侵入性、客观评估。它通过识别微观组织变化来追踪治疗效果，并能预测活检结果，这对于临床实践中指导个体化治疗和新药开发具有重要意义。该方法有望减少对侵入性活检的需求，并提供更精细的治疗效果评估。"}}
{"id": "2507.12399", "title": "ROC-n-reroll: How verifier imperfection affects test-time scaling", "authors": ["Florian E. Dorner", "Yatong Chen", "André F. Cruz", "Fanny Yang"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      35 pages, 9 Figures", "url": "http://arxiv.org/abs/2507.12399v1", "summary": "Test-time scaling aims to improve language model performance by leveraging\nadditional compute during inference. While many works have empirically studied\ntechniques like Best-of-N (BoN) and rejection sampling that make use of a\nverifier to enable test-time scaling, there is little theoretical understanding\nof how verifier imperfection affects performance. In this work, we address this\ngap. Specifically, we prove how instance-level accuracy of these methods is\nprecisely characterized by the geometry of the verifier's ROC curve.\nInterestingly, while scaling is determined by the local geometry of the ROC\ncurve for rejection sampling, it depends on global properties of the ROC curve\nfor BoN. As a consequence when the ROC curve is unknown, it is impossible to\nextrapolate the performance of rejection sampling based on the low-compute\nregime. Furthermore, while rejection sampling outperforms BoN for fixed\ncompute, in the infinite-compute limit both methods converge to the same level\nof accuracy, determined by the slope of the ROC curve near the origin. Our\ntheoretical results are confirmed by experiments on GSM8K using different\nversions of Llama and Qwen to generate and verify solutions.", "comment": "35 pages, 9 Figures", "pdf_url": "http://arxiv.org/pdf/2507.12399v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "ROC-n-reroll：验证器不完美如何影响测试时扩展", "tldr": "本文从理论上探究了验证器不完美对语言模型测试时扩展性能的影响，揭示了性能与验证器ROC曲线几何形状的精确关联，并发现不同扩展方法（如拒绝采样和BoN）与ROC曲线局部或全局特性相关，且在固定计算量下拒绝采样表现更优，在无限计算量下两者性能趋同。", "motivation": "现有关于语言模型测试时扩展技术（如BoN和拒绝采样）的研究多为经验性的，缺乏对验证器不完美如何影响性能的理论理解。本文旨在弥补这一理论空白。", "method": "通过理论证明，阐述了测试时扩展方法的实例级准确性如何由验证器ROC曲线的几何形状精确表征。并通过在GSM8K数据集上使用Llama和Qwen模型进行实验，验证了理论结果。", "result": "实例级准确性由验证器ROC曲线的几何形状精确表征。拒绝采样的扩展性能由ROC曲线的局部几何形状决定，而BoN的扩展性能由ROC曲线的全局特性决定。当ROC曲线未知时，无法根据低计算量情况推断拒绝采样的性能。在固定计算量下，拒绝采样优于BoN；但在无限计算量限制下，两种方法的准确性收敛到相同水平，由ROC曲线原点附近的斜率决定。理论结果已通过实验证实。", "conclusion": "验证器不完美对语言模型的测试时扩展性能有显著影响，其性能与验证器ROC曲线的几何特性密切相关。理解这些理论关系有助于指导未来测试时扩展方法的设计和优化。", "translation": "测试时扩展旨在通过在推理过程中利用额外的计算来提高语言模型的性能。虽然许多工作已经通过经验研究了利用验证器实现测试时扩展的技术，例如最佳N选择（BoN）和拒绝采样，但对于验证器不完美如何影响性能的理论理解却很少。在这项工作中，我们解决了这一空白。具体来说，我们证明了这些方法的实例级准确性如何精确地由验证器ROC曲线的几何形状来表征。有趣的是，虽然拒绝采样的扩展性能由ROC曲线的局部几何形状决定，但BoN的扩展性能却取决于ROC曲线的全局特性。因此，当ROC曲线未知时，不可能根据低计算量的情况来推断拒绝采样的性能。此外，虽然在固定计算量下拒绝采样优于BoN，但在无限计算量限制下，两种方法都收敛到相同的准确性水平，这由ROC曲线原点附近的斜率决定。我们的理论结果通过在GSM8K数据集上使用不同版本的Llama和Qwen生成和验证解决方案的实验得到了证实。", "summary": "本文针对语言模型测试时扩展中验证器不完美对性能影响的理论理解不足的问题，提出了深入的理论分析。研究证明，最佳N选择（BoN）和拒绝采样等方法的实例级准确性与验证器ROC曲线的几何形状密切相关，其中拒绝采样依赖于局部几何，而BoN依赖于全局特性。研究指出，在固定计算量下拒绝采样表现更优，但在无限计算量下两者性能趋同。这些理论发现已通过在GSM8K数据集上的实验得到验证，为优化语言模型推理效率提供了理论指导。", "keywords": "测试时扩展, 验证器不完美, ROC曲线, 语言模型, 拒绝采样", "comments": "这项工作通过引入ROC曲线的几何特性来理论分析验证器不完美对语言模型测试时扩展性能的影响，填补了现有研究的理论空白。其创新之处在于将传统的分类器性能评估工具应用于理解语言模型推理阶段的扩展机制，并揭示了不同扩展策略（BoN与拒绝采样）与ROC曲线局部及全局特性的关联。这项研究对于优化语言模型推理效率和性能具有重要指导意义。"}}
{"id": "2411.13789", "title": "LEADRE: Multi-Faceted Knowledge Enhanced LLM Empowered Display Advertisement Recommender System", "authors": ["Fengxin Li", "Yi Li", "Yue Liu", "Chao Zhou", "Yuan Wang", "Xiaoxiang Deng", "Wei Xue", "Dapeng Liu", "Lei Xiao", "Haijie Gu", "Jie Jiang", "Hongyan Liu", "Biao Qin", "Jun He"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted by VLDB 2025 Industrial Track", "url": "http://arxiv.org/abs/2411.13789v3", "summary": "Display advertising provides significant value to advertisers, publishers,\nand users. Traditional display advertising systems utilize a multi-stage\narchitecture consisting of retrieval, coarse ranking, and final ranking.\nHowever, conventional retrieval methods rely on ID-based learning to rank\nmechanisms and fail to adequately utilize the content information of ads, which\nhampers their ability to provide diverse recommendation lists.\n  To address this limitation, we propose leveraging the extensive world\nknowledge of LLMs. However, three key challenges arise when attempting to\nmaximize the effectiveness of LLMs: \"How to capture user interests\", \"How to\nbridge the knowledge gap between LLMs and advertising system\", and \"How to\nefficiently deploy LLMs\". To overcome these challenges, we introduce a novel\nLLM-based framework called LLM Empowered Display ADvertisement REcommender\nsystem (LEADRE). LEADRE consists of three core modules: (1) The Intent-Aware\nPrompt Engineering introduces multi-faceted knowledge and designs intent-aware\n<Prompt, Response> pairs that fine-tune LLMs to generate ads tailored to users'\npersonal interests. (2) The Advertising-Specific Knowledge Alignment\nincorporates auxiliary fine-tuning tasks and Direct Preference Optimization\n(DPO) to align LLMs with ad semantic and business value. (3) The Efficient\nSystem Deployment deploys LEADRE in an online environment by integrating both\nlatency-tolerant and latency-sensitive service. Extensive offline experiments\ndemonstrate the effectiveness of LEADRE and validate the contributions of\nindividual modules. Online A/B test shows that LEADRE leads to a 1.57% and\n1.17% GMV lift for serviced users on WeChat Channels and Moments separately.\nLEADRE has been deployed on both platforms, serving tens of billions of\nrequests each day.", "comment": "Accepted by VLDB 2025 Industrial Track", "pdf_url": "http://arxiv.org/pdf/2411.13789v3", "cate": "cs.IR", "date": "2024-11-21", "updated": "2025-07-16", "AI": {"title_translation": "LEADRE：多维度知识增强的LLM驱动展示广告推荐系统", "tldr": "LEADRE是一个LLM驱动的展示广告推荐系统，通过多维度知识增强解决传统系统推荐多样性不足和LLM部署挑战，显著提升了GMV。", "motivation": "传统展示广告系统依赖基于ID的学习排序机制，未能充分利用广告内容信息，导致推荐列表多样性不足。引入LLM面临“如何捕捉用户兴趣”、“LLM与广告系统知识鸿沟”和“如何高效部署LLM”的挑战。", "method": "本文提出LEADRE框架，包含三个核心模块：1. 意图感知提示工程：引入多维度知识并设计意图感知的<Prompt, Response>对，微调LLM生成符合用户兴趣的广告。2. 广告特定知识对齐：结合辅助微调任务和直接偏好优化（DPO），使LLM与广告语义和业务价值对齐。3. 高效系统部署：整合延迟容忍和延迟敏感服务，将LEADRE部署到在线环境中。", "result": "离线实验证明LEADRE的有效性及各模块贡献。在线A/B测试显示，LEADRE在微信视频号和朋友圈分别为服务用户带来了1.57%和1.17%的GMV提升。LEADRE已部署并每日处理数百亿请求。", "conclusion": "LEADRE通过利用LLM的多维度知识，有效解决了传统展示广告推荐系统的局限性及LLM部署挑战，显著提升了推荐效果和业务价值，并已成功应用于大规模线上环境。", "translation": "展示广告为广告商、发布商和用户提供了显著价值。传统的展示广告系统采用检索、粗排和精排的多阶段架构。然而，传统的检索方法依赖于基于ID的学习排序机制，未能充分利用广告的内容信息，这阻碍了它们提供多样化推荐列表的能力。为了解决这一限制，我们提出利用大型语言模型（LLMs）的广泛世界知识。然而，在尝试最大化LLMs的有效性时，出现了三个关键挑战：“如何捕捉用户兴趣”、“如何弥合LLMs与广告系统之间的知识鸿沟”以及“如何高效部署LLMs”。为了克服这些挑战，我们引入了一个新颖的基于LLM的框架，名为LLM驱动的展示广告推荐系统（LEADRE）。LEADRE由三个核心模块组成：(1) 意图感知提示工程引入多维度知识并设计意图感知的<Prompt, Response>对，微调LLMs以生成符合用户个人兴趣的广告。(2) 广告特定知识对齐结合辅助微调任务和直接偏好优化（DPO），使LLMs与广告语义和业务价值对齐。(3) 高效系统部署通过整合延迟容忍和延迟敏感服务，将LEADRE部署到在线环境中。广泛的离线实验证明了LEADRE的有效性，并验证了各个模块的贡献。在线A/B测试显示，LEADRE在微信视频号和朋友圈分别为服务用户带来了1.57%和1.17%的GMV提升。LEADRE已在这两个平台部署，每天处理数百亿的请求。", "summary": "本文提出LEADRE，一个利用LLM解决传统展示广告推荐系统多样性不足的框架。LEADRE通过意图感知提示工程捕获用户兴趣，通过广告特定知识对齐弥合LLM与广告系统间的知识鸿沟，并通过高效系统部署实现线上应用。实验证明LEADRE能显著提升GMV，并已成功部署于微信平台。", "keywords": "LLM, 推荐系统, 展示广告, 知识增强, DPO", "comments": "本文创新性地将大型语言模型（LLM）引入到展示广告推荐系统中，通过精心设计的模块解决了LLM在广告推荐中面临的关键挑战，包括用户兴趣捕捉、知识对齐和高效部署。其提出的多维度知识增强和DPO等技术为LLM在推荐领域的应用提供了新的思路。线上A/B测试的显著GMV提升和大规模部署也证明了其重要的实际应用价值。"}}
{"id": "2507.11940", "title": "IANN-MPPI: Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral Approach for Autonomous Driving", "authors": ["Kanghyun Ryu", "Minjun Sung", "Piyush Gupta", "Jovin D'sa", "Faizan M. Tariq", "David Isele", "Sangjae Bae"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      To be published in The IEEE International Conference on Intelligent Transportation Systems (ITSC) 2025", "url": "http://arxiv.org/abs/2507.11940v1", "summary": "Motion planning for autonomous vehicles (AVs) in dense traffic is\nchallenging, often leading to overly conservative behavior and unmet planning\nobjectives. This challenge stems from the AVs' limited ability to anticipate\nand respond to the interactive behavior of surrounding agents. Traditional\ndecoupled prediction and planning pipelines rely on non-interactive predictions\nthat overlook the fact that agents often adapt their behavior in response to\nthe AV's actions. To address this, we propose Interaction-Aware Neural\nNetwork-Enhanced Model Predictive Path Integral (IANN-MPPI) control, which\nenables interactive trajectory planning by predicting how surrounding agents\nmay react to each control sequence sampled by MPPI. To improve performance in\nstructured lane environments, we introduce a spline-based prior for the MPPI\nsampling distribution, enabling efficient lane-changing behavior. We evaluate\nIANN-MPPI in a dense traffic merging scenario, demonstrating its ability to\nperform efficient merging maneuvers. Our project website is available at\nhttps://sites.google.com/berkeley.edu/iann-mppi", "comment": "To be published in The IEEE International Conference on Intelligent\n  Transportation Systems (ITSC) 2025", "pdf_url": "http://arxiv.org/pdf/2507.11940v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "IANN-MPPI：交互感知神经网络增强模型预测路径积分自动驾驶方法", "tldr": "IANN-MPPI是一种新的自动驾驶运动规划方法，它通过预测周围车辆对自车行为的反应来实现交互式轨迹规划，并在密集交通场景中展示了高效的变道能力。", "motivation": "自动驾驶车辆在密集交通中的运动规划面临挑战，常导致过于保守的行为且无法达成规划目标，原因在于传统方法未能充分预测并响应周围车辆的交互行为，忽略了其他车辆会根据自车动作调整行为的事实。", "method": "本文提出了交互感知神经网络增强模型预测路径积分（IANN-MPPI）控制方法，通过预测周围智能体对MPPI采样的每个控制序列的反应来实现交互式轨迹规划。为了提高在结构化车道环境中的性能，引入了基于样条的先验知识作为MPPI采样分布。", "result": "在密集交通汇流场景中评估了IANN-MPPI，结果表明它能够执行高效的汇流操作。", "conclusion": "IANN-MPPI能够有效解决自动驾驶车辆在密集交通中的交互式运动规划问题，使其能够执行更高效的机动。", "translation": "自动驾驶车辆（AVs）在密集交通中的运动规划具有挑战性，常常导致过于保守的行为并无法实现规划目标。这一挑战源于自动驾驶车辆预测和响应周围智能体交互行为的能力有限。传统的解耦式预测和规划流程依赖于非交互式预测，这忽略了智能体通常会根据自动驾驶车辆的动作调整其行为的事实。为了解决这个问题，我们提出了交互感知神经网络增强模型预测路径积分（IANN-MPPI）控制方法，它通过预测周围智能体可能如何对MPPI采样的每个控制序列做出反应来实现交互式轨迹规划。为了提高在结构化车道环境中的性能，我们为MPPI采样分布引入了基于样条的先验知识，从而实现了高效的变道行为。我们在一个密集交通汇流场景中评估了IANN-MPPI，展示了其执行高效汇流操作的能力。我们的项目网站可在 https://sites.google.com/berkeley.edu/iann-mppi 访问。", "summary": "该论文提出了IANN-MPPI方法，旨在解决自动驾驶车辆在密集交通中运动规划过于保守的问题。IANN-MPPI通过结合神经网络预测周围智能体对自车动作的反应，实现了交互式轨迹规划。此外，它引入了基于样条的先验知识以优化结构化车道环境下的性能。实验结果表明，该方法在密集交通汇流场景中能有效执行高效的变道操作。", "keywords": "交互感知, 神经网络, 模型预测路径积分, 自动驾驶, 运动规划", "comments": "该论文的创新点在于将交互感知预测与MPPI控制框架相结合，通过神经网络预测其他车辆的反应，使得自动驾驶车辆能够进行更具交互性的轨迹规划，从而克服了传统方法中非交互式预测的局限性。引入样条基先验进一步提升了其在结构化车道环境中的实用性。这对于提升自动驾驶在复杂交通环境中的效率和安全性具有重要意义。"}}
{"id": "2503.08384", "title": "Prototype-Based Multiple Instance Learning for Gigapixel Whole Slide Image Classification", "authors": ["Susu Sun", "Dominique van Midden", "Geert Litjens", "Christian F. Baumgartner"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to MICCAI 2025", "url": "http://arxiv.org/abs/2503.08384v2", "summary": "Multiple Instance Learning (MIL) methods have succeeded remarkably in\nhistopathology whole slide image (WSI) analysis. However, most MIL models only\noffer attention-based explanations that do not faithfully capture the model's\ndecision mechanism and do not allow human-model interaction. To address these\nlimitations, we introduce ProtoMIL, an inherently interpretable MIL model for\nWSI analysis that offers user-friendly explanations and supports human\nintervention. Our approach employs a sparse autoencoder to discover\nhuman-interpretable concepts from the image feature space, which are then used\nto train ProtoMIL. The model represents predictions as linear combinations of\nconcepts, making the decision process transparent. Furthermore, ProtoMIL allows\nusers to perform model interventions by altering the input concepts.\nExperiments on two widely used pathology datasets demonstrate that ProtoMIL\nachieves a classification performance comparable to state-of-the-art MIL models\nwhile offering intuitively understandable explanations. Moreover, we\ndemonstrate that our method can eliminate reliance on diagnostically irrelevant\ninformation via human intervention, guiding the model toward being right for\nthe right reason. Code will be publicly available at\nhttps://github.com/ss-sun/ProtoMIL.", "comment": "Accepted to MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2503.08384v2", "cate": "cs.CV", "date": "2025-03-11", "updated": "2025-07-16", "AI": {"title_translation": "基于原型的多实例学习在千兆像素全玻片图像分类中的应用", "tldr": "ProtoMIL是一个可解释的多实例学习模型，用于全玻片图像分类，它通过可理解的概念提供解释并支持人工干预，在保持性能的同时提高模型透明度和可控性。", "motivation": "现有的多实例学习（MIL）模型在组织病理学全玻片图像（WSI）分析中虽然表现出色，但其基于注意力的解释未能忠实反映模型的决策机制，且不支持人机交互。", "method": "本文引入了ProtoMIL模型，这是一种固有可解释的MIL模型。它采用稀疏自编码器从图像特征空间中发现人类可解释的概念，并用这些概念训练ProtoMIL。模型将预测表示为概念的线性组合，使得决策过程透明。此外，ProtoMIL允许用户通过改变输入概念进行模型干预。", "result": "ProtoMIL在两个广泛使用的病理学数据集上实现了与最先进MIL模型相当的分类性能，同时提供了直观易懂的解释。此外，该方法通过人工干预，能够消除对诊断无关信息的依赖，引导模型做出正确且有根据的判断。", "conclusion": "ProtoMIL是一个具有可解释性和可控性的多实例学习模型，能够在保持高性能的同时，为全玻片图像分类提供透明的决策过程和人机交互能力，使其决策更加可靠和可信。", "translation": "多实例学习（MIL）方法在组织病理学全玻片图像（WSI）分析中取得了显著成功。然而，大多数MIL模型只提供基于注意力的解释，这些解释未能忠实地捕捉模型的决策机制，并且不允许人机交互。为了解决这些限制，我们引入了ProtoMIL，这是一种用于WSI分析的固有可解释MIL模型，它提供用户友好的解释并支持人工干预。我们的方法采用稀疏自编码器从图像特征空间中发现人类可解释的概念，然后用这些概念来训练ProtoMIL。该模型将预测表示为概念的线性组合，使决策过程透明。此外，ProtoMIL允许用户通过改变输入概念来执行模型干预。在两个广泛使用的病理学数据集上的实验表明，ProtoMIL在提供直观易懂的解释的同时，实现了与最先进MIL模型相当的分类性能。此外，我们证明了我们的方法可以通过人工干预消除对诊断无关信息的依赖，引导模型“因正确的原因而正确”。代码将在https://github.com/ss-sun/ProtoMIL 公开提供。", "summary": "本文提出了ProtoMIL，一种用于千兆像素全玻片图像分类的固有可解释多实例学习（MIL）模型。针对现有MIL模型解释性不足和缺乏人机交互的问题，ProtoMIL利用稀疏自编码器发现人类可解释的概念，并基于这些概念进行预测，使决策过程透明。实验证明，ProtoMIL在保持与SOTA模型相当性能的同时，提供了直观的解释，并通过人工干预能够消除无关信息的影响，提升了模型的可靠性。", "keywords": "多实例学习, 全玻片图像, 可解释性, 原型, 人工干预", "comments": "ProtoMIL的创新之处在于其固有的可解释性，通过将预测分解为人类可理解的概念，显著提高了模型的透明度。此外，它支持用户干预，允许专家指导模型消除诊断无关信息，这对于医疗领域的AI应用至关重要，因为它能增强模型的可信赖性和鲁棒性。"}}
{"id": "2507.11892", "title": "From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition", "authors": ["Yu Liu", "Leyuan Qu", "Hanlei Shi", "Di Gao", "Yuhua Zheng", "Taihao Li"], "categories": ["cs.CV", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11892v1", "summary": "Dynamic Facial Expression Recognition (DFER) aims to identify human emotions\nfrom temporally evolving facial movements and plays a critical role in\naffective computing. While recent vision-language approaches have introduced\nsemantic textual descriptions to guide expression recognition, existing methods\nstill face two key limitations: they often underutilize the subtle emotional\ncues embedded in generated text, and they have yet to incorporate sufficiently\neffective mechanisms for filtering out facial dynamics that are irrelevant to\nemotional expression. To address these gaps, We propose GRACE, Granular\nRepresentation Alignment for Cross-modal Emotion recognition that integrates\ndynamic motion modeling, semantic text refinement, and token-level cross-modal\nalignment to facilitate the precise localization of emotionally salient\nspatiotemporal features. Our method constructs emotion-aware textual\ndescriptions via a Coarse-to-fine Affective Text Enhancement (CATE) module and\nhighlights expression-relevant facial motion through a motion-difference\nweighting mechanism. These refined semantic and visual signals are aligned at\nthe token level using entropy-regularized optimal transport. Experiments on\nthree benchmark datasets demonstrate that our method significantly improves\nrecognition performance, particularly in challenging settings with ambiguous or\nimbalanced emotion classes, establishing new state-of-the-art (SOTA) results in\nterms of both UAR and WAR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11892v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "从粗粒度到细微：跨模态对齐细粒度语言线索与视觉显著区域用于动态情感识别", "tldr": "本文提出了GRACE，一个通过整合动态运动建模、语义文本细化和令牌级跨模态对齐，用于动态面部表情识别的新方法，并在基准数据集上取得了SOTA性能。", "motivation": "现有动态面部表情识别方法在利用生成文本中细微情感线索和过滤不相关面部动态方面存在局限性，导致识别精度不足。", "method": "本文提出了GRACE（Granular Representation Alignment for Cross-modal Emotion recognition）方法。该方法通过一个“从粗到细情感文本增强”（CATE）模块构建情感感知的文本描述，并通过运动差异加权机制突出与表情相关的面部运动。这些精炼的语义和视觉信号通过熵正则化最优传输在令牌级别进行对齐。", "result": "在三个基准数据集上的实验表明，GRACE方法显著提高了识别性能，尤其是在情感类别模糊或不平衡的挑战性设置下，并在UAR和WAR方面都取得了新的最先进（SOTA）结果。", "conclusion": "GRACE通过有效整合动态运动建模、语义文本细化和令牌级跨模态对齐，显著提升了动态面部表情识别的准确性，尤其是在复杂场景下，证明了其在情感计算领域的有效性和优越性。", "translation": "动态面部表情识别（DFER）旨在从随时间演变的面部运动中识别人类情感，并在情感计算中扮演着关键角色。尽管最近的视觉-语言方法引入了语义文本描述来指导表情识别，但现有方法仍面临两个关键限制：它们通常未充分利用生成文本中嵌入的细微情感线索，并且尚未纳入足够有效的机制来过滤掉与情感表达无关的面部动态。为了解决这些空白，我们提出了GRACE（Granular Representation Alignment for Cross-modal Emotion recognition），它集成了动态运动建模、语义文本细化和令牌级跨模态对齐，以促进情感显著时空特征的精确局部化。我们的方法通过一个“从粗到细情感文本增强”（CATE）模块构建情感感知的文本描述，并通过运动差异加权机制突出与表情相关的面部运动。这些精炼的语义和视觉信号通过熵正则化最优传输在令牌级别进行对齐。在三个基准数据集上的实验表明，我们的方法显著提高了识别性能，特别是在情感类别模糊或不平衡的挑战性设置下，并在UAR和WAR方面都取得了新的最先进（SOTA）结果。", "summary": "本文提出了一种名为GRACE的动态面部表情识别（DFER）新方法，旨在解决现有视觉-语言方法在利用细微情感线索和过滤不相关面部动态方面的不足。GRACE通过引入“从粗到细情感文本增强”（CATE）模块生成情感感知文本描述，并通过运动差异加权机制识别相关面部运动。这些精炼的跨模态信号通过熵正则化最优传输进行令牌级对齐，从而实现了情感显著时空特征的精确局部化。实验证明，GRACE在基准数据集上显著提升了识别性能，尤其在挑战性情境下，并取得了新的SOTA结果。", "keywords": "动态面部表情识别, 跨模态对齐, 情感计算, 细粒度, 视觉-语言", "comments": "本文的创新点在于提出了GRACE框架，通过引入CATE模块细化文本描述和运动差异加权机制过滤视觉噪声，并利用熵正则化最优传输进行令牌级跨模态对齐，有效地解决了现有方法在动态情感识别中的局限性。其在处理模糊或不平衡情感类别时的表现尤为突出，对情感计算领域具有重要意义。"}}
{"id": "2502.15873", "title": "Practical Principles for AI Cost and Compute Accounting", "authors": ["Stephen Casper", "Luke Bailey", "Tim Schreier"], "categories": ["cs.AI", "cs.CY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.15873v3", "summary": "Policymakers increasingly use development cost and compute as proxies for AI\ncapabilities and risks. Recent laws have introduced regulatory requirements\nthat are contingent on specific thresholds. However, technical ambiguities in\nhow to perform this accounting create loopholes that can undermine regulatory\neffectiveness. We propose seven principles for designing AI cost and compute\naccounting standards that (1) reduce opportunities for strategic gaming, (2)\navoid disincentivizing responsible risk mitigation, and (3) enable consistent\nimplementation across companies and jurisdictions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.15873v3", "cate": "cs.AI", "date": "2025-02-21", "updated": "2025-07-16", "AI": {"title_translation": "人工智能成本与计算核算的实用原则", "tldr": "鉴于AI成本和计算核算存在的模糊性可能削弱监管效力，本文提出了七项原则，旨在设计更有效、公平且一致的AI核算标准，以减少规避行为并鼓励负责任的风险规避。", "motivation": "政策制定者日益将人工智能的开发成本和计算量作为衡量其能力和风险的指标。然而，在进行这种核算时存在技术模糊性，这可能导致漏洞，从而削弱监管的有效性。", "method": "本文提出了设计人工智能成本和计算核算标准的七项原则。", "result": "这些原则旨在实现以下目标：(1) 减少策略性规避行为的机会；(2) 避免抑制负责任的风险缓解措施；(3) 使跨公司和跨司法管辖区的实施保持一致。", "conclusion": "通过应用所提出的七项原则，可以设计出更有效、公平且一致的AI成本和计算核算标准，从而更好地支持AI监管并避免负面激励。", "translation": "政策制定者日益将人工智能的开发成本和计算量作为衡量其能力和风险的代理指标。近期法律引入了以特定阈值为条件的监管要求。然而，在如何执行这种核算方面的技术模糊性造成了漏洞，这可能削弱监管的有效性。我们提出了设计人工智能成本和计算核算标准的七项原则，这些原则旨在 (1) 减少策略性规避行为的机会，(2) 避免抑制负责任的风险缓解措施，以及 (3) 使跨公司和跨司法管辖区的实施保持一致。", "summary": "鉴于政策制定者日益依赖AI成本和计算量作为评估AI能力和风险的依据，但现有核算方法存在技术模糊性，可能导致监管漏洞，本文提出了七项实用原则。这些原则旨在指导AI成本和计算核算标准的制定，以减少策略性规避行为，避免阻碍负责任的风险缓解，并确保跨企业和司法管辖区的一致性实施，从而提升AI监管的有效性。", "keywords": "AI成本, 计算核算, 监管, 原则, 政策", "comments": "该论文提出了在AI监管日益严格的背景下，解决AI成本和计算核算核心挑战的实用性框架。其创新点在于提出了一套具体的原则，旨在弥合技术实践与政策目标之间的鸿沟，对于未来的AI审计和合规性具有重要指导意义。"}}
{"id": "2507.12236", "title": "Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models", "authors": ["Felix Nützel", "Mischa Dombrowski", "Bernhard Kainz"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      20 pages, 6 figures. To appear in Proc. MIDL 2025 (PMLR)", "url": "http://arxiv.org/abs/2507.12236v1", "summary": "Phrase grounding, i.e., mapping natural language phrases to specific image\nregions, holds significant potential for disease localization in medical\nimaging through clinical reports. While current state-of-the-art methods rely\non discriminative, self-supervised contrastive models, we demonstrate that\ngenerative text-to-image diffusion models, leveraging cross-attention maps, can\nachieve superior zero-shot phrase grounding performance. Contrary to prior\nassumptions, we show that fine-tuning diffusion models with a frozen,\ndomain-specific language model, such as CXR-BERT, substantially outperforms\ndomain-agnostic counterparts. This setup achieves remarkable improvements, with\nmIoU scores doubling those of current discriminative methods. These findings\nhighlight the underexplored potential of generative models for phrase grounding\ntasks. To further enhance performance, we introduce Bimodal Bias Merging (BBM),\na novel post-processing technique that aligns text and image biases to identify\nregions of high certainty. BBM refines cross-attention maps, achieving even\ngreater localization accuracy. Our results establish generative approaches as a\nmore effective paradigm for phrase grounding in the medical imaging domain,\npaving the way for more robust and interpretable applications in clinical\npractice. The source code and model weights are available at\nhttps://github.com/Felix-012/generate_to_ground.", "comment": "20 pages, 6 figures. To appear in Proc. MIDL 2025 (PMLR)", "pdf_url": "http://arxiv.org/pdf/2507.12236v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "生成到定位：多模态文本条件提升医学视觉-语言模型中的短语定位", "tldr": "本文展示了生成式扩散模型在医学图像短语定位任务上超越了判别式方法，特别是结合领域特定语言模型和新的后处理技术BBM后，性能显著提升。", "motivation": "短语定位在医学影像中对疾病定位具有重要潜力，而当前最先进的方法依赖于判别式模型。本文旨在探索生成模型在这一任务上的潜力，以实现更鲁棒和可解释的临床应用。", "method": "作者提出使用生成式文本到图像扩散模型，利用交叉注意力图进行零样本短语定位。他们发现使用冻结的、领域特定语言模型（如CXR-BERT）对扩散模型进行微调，能显著优于领域无关模型。此外，引入了一种名为Bimodal Bias Merging (BBM) 的新型后处理技术，通过对齐文本和图像偏差来识别高确定性区域，从而优化交叉注意力图并提高定位精度。", "result": "该方法使mIoU分数比当前判别式方法翻倍。BBM进一步提高了定位精度。", "conclusion": "生成式方法在医学影像领域的短语定位任务中是一种更有效的范式，为更鲁棒和可解释的临床应用铺平了道路。", "translation": "短语定位，即将自然语言短语映射到特定的图像区域，通过临床报告在医学影像中的疾病定位方面具有巨大潜力。虽然当前最先进的方法依赖于判别式、自监督对比模型，但我们证明了利用交叉注意力图的生成式文本到图像扩散模型可以实现卓越的零样本短语定位性能。与之前的假设相反，我们表明使用冻结的、领域特定语言模型（如CXR-BERT）对扩散模型进行微调，其性能显著优于领域无关模型。这种设置实现了显著改进，mIoU分数是当前判别式方法的两倍。这些发现突出了生成模型在短语定位任务中尚未充分开发的潜力。为了进一步提高性能，我们引入了双模态偏差合并（BBM），这是一种新颖的后处理技术，它对齐文本和图像偏差以识别高确定性区域。BBM优化了交叉注意力图，实现了更高的定位精度。我们的结果确立了生成式方法作为医学影像领域短语定位的更有效范式，为临床实践中更鲁棒和可解释的应用铺平了道路。源代码和模型权重可在https://github.com/Felix-012/generate_to_ground获取。", "summary": "本文提出了一种基于生成式文本到图像扩散模型的新方法，用于医学图像中的短语定位任务。研究表明，通过使用冻结的领域特定语言模型（如CXR-BERT）对扩散模型进行微调，可以显著提升零样本短语定位性能，mIoU分数是现有判别式方法的两倍。此外，引入了Bimodal Bias Merging (BBM) 后处理技术，通过对齐文本和图像偏差来进一步提高定位精度。结果表明，生成式方法在医学影像短语定位中具有巨大潜力，为临床应用提供了更有效和可解释的解决方案。", "keywords": "短语定位, 生成模型, 扩散模型, 医学影像, 交叉注意力", "comments": "这篇论文的创新点在于首次将生成式文本到图像扩散模型应用于医学图像的短语定位任务，并证明了其优于传统判别式方法的潜力。特别是，结合领域特定语言模型进行微调以及引入BBM后处理技术，显著提升了性能，为医学影像分析提供了新的范式，具有重要的临床应用前景。"}}
{"id": "2507.11788", "title": "Simulated Language Acquisition in a Biologically Realistic Model of the Brain", "authors": ["Daniel Mitropolsky", "Christos Papadimitriou"], "categories": ["cs.NE", "cs.CL"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      13 pages, 6 figures", "url": "http://arxiv.org/abs/2507.11788v1", "summary": "Despite tremendous progress in neuroscience, we do not have a compelling\nnarrative for the precise way whereby the spiking of neurons in our brain\nresults in high-level cognitive phenomena such as planning and language. We\nintroduce a simple mathematical formulation of six basic and broadly accepted\nprinciples of neuroscience: excitatory neurons, brain areas, random synapses,\nHebbian plasticity, local inhibition, and inter-area inhibition. We implement a\nsimulated neuromorphic system based on this formalism, which is capable of\nbasic language acquisition: Starting from a tabula rasa, the system learns, in\nany language, the semantics of words, their syntactic role (verb versus noun),\nand the word order of the language, including the ability to generate novel\nsentences, through the exposure to a modest number of grounded sentences in the\nsame language. We discuss several possible extensions and implications of this\nresult.", "comment": "13 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.11788v1", "cate": "cs.NE", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "脑部生物真实模型中的模拟语言习得", "tldr": "该研究提出了一个基于六个神经科学原理的生物真实模型，模拟了语言习得过程，能够从零开始学习词义、语法角色和语序，并生成新句子。", "motivation": "尽管神经科学取得了巨大进展，但我们仍缺乏关于神经元放电如何产生规划和语言等高级认知现象的令人信服的解释。", "method": "作者提出了一种基于六个基本且广泛接受的神经科学原理（兴奋性神经元、脑区、随机突触、赫布可塑性、局部抑制和区域间抑制）的简单数学公式，并基于此实现了一个模拟神经形态系统。", "result": "该模拟系统能够进行基本的语言习得：从零开始，系统可以在任何语言中学习词语的语义、它们的句法角色（动词与名词）以及语言的词序，包括通过接触少量该语言中的具身句子来生成新句子的能力。", "conclusion": "该研究成功构建了一个能够模拟基本语言习得的生物真实神经形态系统，并讨论了其结果的可能扩展和影响。", "translation": "尽管神经科学取得了巨大进展，但我们对于大脑中神经元放电如何产生规划和语言等高级认知现象的精确方式，仍缺乏一个令人信服的叙述。我们引入了一个简单的数学公式，包含了六个基本且广泛接受的神经科学原理：兴奋性神经元、脑区、随机突触、赫布可塑性、局部抑制和区域间抑制。我们基于这种形式实现了一个模拟神经形态系统，该系统能够进行基本的语言习得：从零开始，该系统通过接触少量相同语言中的具身句子，学习任何语言中词语的语义、它们的句法角色（动词与名词）以及语言的词序，包括生成新句子的能力。我们讨论了这一结果的几种可能的扩展和影响。", "summary": "这篇论文介绍了一个基于六个核心神经科学原理（兴奋性神经元、脑区、随机突触、赫布可塑性、局部抑制、区域间抑制）的生物真实神经形态模型，旨在解释神经活动如何产生高级认知功能。该模型能够模拟基本的语言习得过程，从零开始学习词语语义、句法角色和语序，并通过少量输入生成新的句子。", "keywords": "语言习得, 神经形态系统, 生物真实模型, 赫布可塑性, 神经科学原理", "comments": "这项研究的创新之处在于，它尝试用一个简洁的数学框架和模拟系统来连接神经元活动与高级认知（如语言习得），提供了一个从生物学角度理解语言学习的潜在路径。其重要性在于为理解大脑如何处理语言提供了一个可验证的计算模型。局限性可能在于模型的简化程度，以及模拟结果与真实生物过程的完全对应性仍需深入验证。"}}
{"id": "2507.12110", "title": "Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs", "authors": ["Ye Han", "Lijun Zhang", "Dejian Meng", "Zhuang Zhang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      16 pages, 16 figures", "url": "http://arxiv.org/abs/2507.12110v1", "summary": "The exploration-exploitation trade-off constitutes one of the fundamental\nchallenges in reinforcement learning (RL), which is exacerbated in multi-agent\nreinforcement learning (MARL) due to the exponential growth of joint\nstate-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)\nmethod for optimizing cooperative decision-making of connected and autonomous\nvehicles (CAVs) in mixed traffic. This work presents two primary contributions:\nFirst, we construct a game topology tensor for dynamic traffic flow,\neffectively compressing high-dimensional traffic state information and decrease\nthe search space for MARL algorithms. Second, building upon the designed game\ntopology tensor and using QMIX as the backbone RL algorithm, we establish a\ntopology-enhanced MARL framework incorporating visit counts and agent mutual\ninformation. Extensive simulations across varying traffic densities and CAV\npenetration rates demonstrate the effectiveness of TPE-MARL. Evaluations\nencompassing training dynamics, exploration patterns, macroscopic traffic\nperformance metrics, and microscopic vehicle behaviors reveal that TPE-MARL\nsuccessfully balances exploration and exploitation. Consequently, it exhibits\nsuperior performance in terms of traffic efficiency, safety, decision\nsmoothness, and task completion. Furthermore, the algorithm demonstrates\ndecision-making rationality comparable to or exceeding that of human drivers in\nboth mixed-autonomy and fully autonomous traffic scenarios. Code of our work is\navailable at\n\\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.", "comment": "16 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.12110v1", "cate": "cs.AI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "拓扑增强型多智能体强化学习用于车联网环境下多车辆协同决策", "tldr": "针对多智能体强化学习（MARL）中探索-利用权衡的挑战，本文提出了一种拓扑增强型MARL方法（TPE-MARL），通过构建博弈拓扑张量和结合QMIX，有效提升了车联网（CAVs）环境下车辆协同决策的效率和安全性。", "motivation": "多智能体强化学习（MARL）中探索-利用权衡是一个基本挑战，且在联合状态-动作空间呈指数级增长的情况下问题更加突出，影响了车联网（CAVs）在混合交通中的协同决策优化。", "method": "本文提出了一种拓扑增强型MARL（TPE-MARL）方法。其主要贡献有两点：首先，构建了动态交通流的博弈拓扑张量，以有效压缩高维交通状态信息并减小MARL算法的搜索空间。其次，基于设计的博弈拓扑张量，并以QMIX作为骨干RL算法，建立了一个结合访问计数和智能体互信息的拓扑增强型MARL框架。", "result": "在不同交通密度和CAV渗透率下的广泛模拟表明，TPE-MARL是有效的。评估结果（涵盖训练动态、探索模式、宏观交通性能指标和微观车辆行为）显示，TPE-MARL成功平衡了探索与利用，并在交通效率、安全性、决策平滑性和任务完成度方面表现出卓越性能。此外，该算法在混合自动驾驶和全自动驾驶交通场景中，其决策合理性与人类驾驶员相当或超越。", "conclusion": "TPE-MARL方法通过有效平衡探索与利用，显著提升了车联网车辆在复杂交通环境下的协同决策性能，并在交通效率、安全性和决策合理性方面达到甚至超越人类驾驶员水平。", "translation": "探索-利用权衡是强化学习（RL）中的一个基本挑战，在多智能体强化学习（MARL）中由于联合状态-动作空间的指数级增长而变得更加严峻。本文提出了一种拓扑增强型MARL（TPE-MARL）方法，用于优化车联网（CAVs）在混合交通中的协同决策。这项工作提出了两个主要贡献：首先，我们为动态交通流构建了一个博弈拓扑张量，有效压缩了高维交通状态信息，并减小了MARL算法的搜索空间。其次，基于设计的博弈拓扑张量，并以QMIX作为骨干RL算法，我们建立了一个结合访问计数和智能体互信息的拓扑增强型MARL框架。在不同交通密度和CAV渗透率下的广泛模拟证明了TPE-MARL的有效性。涵盖训练动态、探索模式、宏观交通性能指标和微观车辆行为的评估显示，TPE-MARL成功平衡了探索与利用。因此，它在交通效率、安全性、决策平滑性和任务完成度方面表现出卓越的性能。此外，该算法在混合自动驾驶和全自动驾驶交通场景中，其决策合理性与人类驾驶员相当或超越。我们的代码可在\\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}获取。", "summary": "本文提出了一种名为TPE-MARL的拓扑增强型多智能体强化学习方法，旨在解决车联网（CAVs）在混合交通中协同决策的探索-利用权衡问题。该方法通过构建博弈拓扑张量来压缩高维交通状态，并结合QMIX与访问计数、智能体互信息来优化决策。实验证明，TPE-MARL在交通效率、安全性、决策平滑性及任务完成度上表现优异，且决策合理性可媲美甚至超越人类驾驶员。", "keywords": "多智能体强化学习, 车联网, 拓扑增强, 协同决策, 探索-利用权衡", "comments": "这项工作通过引入“博弈拓扑张量”来压缩高维状态空间，并结合了访问计数和智能体互信息，为MARL中的探索-利用权衡提供了一个新颖且有效的方法。它在车联网协同决策领域的应用展示了其在实际交通场景中的巨大潜力，尤其是在提升交通效率和安全性方面。开源代码也增加了其可复现性和影响力。"}}
{"id": "2410.03103", "title": "Planning-Aware Code Infilling via Horizon-Length Prediction", "authors": ["Yifeng Ding", "Hantian Ding", "Shiqi Wang", "Qing Sun", "Varun Kumar", "Zijian Wang"], "categories": ["cs.LG", "cs.CL", "cs.SE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.03103v3", "summary": "Fill-in-the-Middle (FIM), or infilling, has become integral to code language\nmodels, enabling generation of missing code given both left and right contexts.\nHowever, the current FIM training paradigm which performs next-token prediction\n(NTP) over reordered sequence often leads to models struggling to generate\ncontent that aligns well with the surrounding context. We hypothesize that NTP\nalone is insufficient for models to learn effective planning conditioned on the\ndistant right context, a critical factor for successful code infilling. To\novercome this, we propose Horizon-Length Prediction (HLP), a novel training\nobjective that teaches models to predict the number of remaining middle tokens\nat each step. HLP advances FIM with lookahead planning, enabling models to\ninherently learn infilling boundaries for arbitrary left and right contexts\nwithout relying on dataset-specific post-processing. Our evaluation across\ndifferent model families and sizes shows that HLP significantly improves FIM\nperformance by up to 24% relatively on diverse benchmarks, across file-level\nand repository-level. Furthermore, the enhanced planning capability gained\nthrough HLP boosts model performance on code reasoning. Importantly, HLP incurs\nnegligible training overhead and no additional inference cost, ensuring its\npracticality for real-world scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.03103v3", "cate": "cs.LG", "date": "2024-10-04", "updated": "2025-07-16", "AI": {"title_translation": "通过预测范围长度实现规划感知的代码填充", "tldr": "本文提出了一种名为水平长度预测（HLP）的新型训练目标，用于代码填充（FIM），通过预测剩余中间标记的数量来增强模型的规划能力，从而显著提高FIM性能并提升代码推理能力，且训练开销和推理成本可忽略不计。", "motivation": "当前的Fill-in-the-Middle (FIM) 训练范式（基于重新排序序列的下一个标记预测，NTP）导致模型难以生成与周围上下文良好对齐的内容。作者假设单独的NTP不足以让模型学习有效规划，而有效规划是成功代码填充的关键。", "method": "提出了一种名为“水平长度预测”（Horizon-Length Prediction, HLP）的新型训练目标。HLP通过在每一步训练模型预测剩余中间标记的数量，从而实现前瞻性规划，使模型能够固有地学习任意左右上下文的填充边界，而无需依赖数据集特定的后处理。", "result": "HLP显著提高了FIM性能，在不同基准测试中相对提升高达24%，涵盖文件级和仓库级。此外，通过HLP获得的增强规划能力提升了模型在代码推理方面的表现。", "conclusion": "Horizon-Length Prediction (HLP) 是一种有效且实用的训练目标，它通过引入规划能力解决了传统代码填充方法的局限性，显著提升了模型性能，并且几乎不增加训练和推理成本。", "translation": "填充中间（FIM），或称作填充，已成为代码语言模型不可或缺的一部分，它能够在给定左右上下文的情况下生成缺失的代码。然而，当前FIM训练范式通过对重新排序的序列执行下一个标记预测（NTP），常常导致模型难以生成与周围上下文良好对齐的内容。我们假设，仅靠NTP不足以让模型学习基于远距离右上下文的有效规划，而这正是成功代码填充的关键因素。为了克服这个问题，我们提出了水平长度预测（HLP），这是一种新颖的训练目标，它教导模型在每一步预测剩余中间标记的数量。HLP通过前瞻性规划推进FIM，使模型能够固有地学习任意左右上下文的填充边界，而无需依赖数据集特定的后处理。我们对不同模型家族和大小的评估表明，HLP在多样化的基准测试中显著提高了FIM性能，相对提升高达24%，涵盖文件级和仓库级。此外，通过HLP获得的增强规划能力提升了模型在代码推理方面的表现。重要的是，HLP带来的训练开销可以忽略不计，并且没有额外的推理成本，确保了其在实际场景中的实用性。", "summary": "本文提出了一种名为水平长度预测（HLP）的新型训练目标，旨在解决当前代码填充（FIM）模型在上下文对齐和规划能力上的不足。HLP通过训练模型预测每一步剩余中间标记的数量，从而增强了模型的规划能力，使其能够更好地学习填充边界。实验结果表明，HLP在多种基准测试中显著提升了FIM性能高达24%，并提高了代码推理能力。该方法具有训练开销和推理成本可忽略不计的优点，具有很高的实用价值。", "keywords": "代码填充, 规划感知, 水平长度预测, 语言模型, 代码生成", "comments": "该论文提出了一种创新性的方法HLP，通过引入“规划”的概念来改进代码填充任务，这解决了传统下一个标记预测方法的局限性。HLP的独特之处在于它让模型学习预测“范围长度”，从而在生成过程中获得前瞻性，这对于需要长距离依赖和上下文一致性的代码生成任务至关重要。其在提升性能的同时保持低开销的特点，使其在实际应用中具有很强的吸引力。"}}
{"id": "2507.12031", "title": "Towards Ultra-Reliable 6G in-X Subnetworks: Dynamic Link Adaptation by Deep Reinforcement Learning", "authors": ["Fateme Salehi", "Aamir Mahmood", "Sarder Fakhrul Abedin", "Kyi Thar", "Mikael Gidlund"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12031v1", "summary": "6G networks are composed of subnetworks expected to meet ultra-reliable\nlow-latency communication (URLLC) requirements for mission-critical\napplications such as industrial control and automation. An often-ignored aspect\nin URLLC is consecutive packet outages, which can destabilize control loops and\ncompromise safety in in-factory environments. Hence, the current work proposes\na link adaptation framework to support extreme reliability requirements using\nthe soft actor-critic (SAC)-based deep reinforcement learning (DRL) algorithm\nthat jointly optimizes energy efficiency (EE) and reliability under dynamic\nchannel and interference conditions. Unlike prior work focusing on average\nreliability, our method explicitly targets reducing burst/consecutive outages\nthrough adaptive control of transmit power and blocklength based solely on the\nobserved signal-to-interference-plus-noise ratio (SINR). The joint optimization\nproblem is formulated under finite blocklength and quality of service\nconstraints, balancing reliability and EE. Simulation results show that the\nproposed method significantly outperforms the baseline algorithms, reducing\noutage bursts while consuming only 18\\% of the transmission cost required by a\nfull/maximum resource allocation policy in the evaluated scenario. The\nframework also supports flexible trade-off tuning between EE and reliability by\nadjusting reward weights, making it adaptable to diverse industrial\nrequirements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12031v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "迈向超可靠6G内部子网络：基于深度强化学习的动态链路自适应", "tldr": "本研究提出了一种基于深度强化学习的链路自适应框架，用于6G网络中实现超可靠低延迟通信，通过联合优化能量效率和可靠性来减少连续性中断，并在仿真中表现出显著的性能提升。", "motivation": "6G网络中的超可靠低延迟通信（URLLC）对于工业控制和自动化等关键任务应用至关重要。然而，URLLC中常被忽视的一个方面是连续的数据包中断，这可能导致控制回路不稳定并危及工厂环境中的安全。现有工作主要关注平均可靠性，未能有效解决突发/连续中断问题。", "method": "本研究提出了一种链路自适应框架，采用基于软Actor-Critic (SAC)的深度强化学习(DRL)算法。该方法在动态信道和干扰条件下，联合优化能量效率(EE)和可靠性。它通过仅基于观测到的信干噪比(SINR)自适应控制发射功率和块长度，明确旨在减少突发/连续中断。联合优化问题在有限块长度和服务质量约束下进行表述。", "result": "仿真结果表明，所提出的方法显著优于基线算法，在评估场景中减少了中断突发，同时仅消耗了全/最大资源分配策略所需传输成本的18%。该框架还通过调整奖励权重支持能量效率和可靠性之间的灵活权衡调整，使其适应不同的工业需求。", "conclusion": "本研究提出的基于深度强化学习的链路自适应框架，能够有效解决6G网络中URLLC的连续中断问题，显著提升可靠性并优化能量效率，同时具备良好的适应性，为关键任务应用提供了有力的支持。", "translation": "6G网络由子网络组成，这些子网络有望满足工业控制和自动化等关键任务应用的超可靠低延迟通信（URLLC）要求。URLLC中一个常被忽视的方面是连续数据包中断，这可能导致控制回路不稳定并危及工厂环境中的安全。因此，当前工作提出了一种链路自适应框架，使用基于软Actor-Critic（SAC）的深度强化学习（DRL）算法来支持极端可靠性要求，该算法在动态信道和干扰条件下联合优化能量效率（EE）和可靠性。与以往专注于平均可靠性的工作不同，我们的方法通过仅基于观测到的信干噪比（SINR）自适应控制发射功率和块长度，明确旨在减少突发/连续中断。在有限块长度和服务质量约束下，制定了联合优化问题，以平衡可靠性和EE。仿真结果表明，所提出的方法显著优于基线算法，在评估场景中减少了中断突发，同时仅消耗了全/最大资源分配策略所需传输成本的18%。该框架还通过调整奖励权重支持EE和可靠性之间的灵活权衡调整，使其适应不同的工业要求。", "summary": "本论文提出了一种针对6G内部子网络的深度强化学习（DRL）驱动的动态链路自适应框架，旨在满足工业控制等关键任务应用对超可靠低延迟通信（URLLC）的严格要求。该框架利用基于软Actor-Critic（SAC）的DRL算法，在动态信道条件下联合优化能量效率（EE）和可靠性，尤其侧重于减少连续性数据包中断。通过自适应控制发射功率和块长度，该方法在仿真中表现出显著优于基线算法的性能，有效降低了中断突发，并大幅降低了传输成本，同时支持能量效率与可靠性之间的灵活权衡。", "keywords": "6G, 超可靠通信, 深度强化学习, 链路自适应, 能量效率, 连续中断", "comments": "该论文的创新点在于其明确关注并解决了URLLC中连续性数据包中断这一常被忽视的关键问题，而非仅仅关注平均可靠性。通过引入基于SAC的深度强化学习算法进行动态链路自适应，实现了能量效率和可靠性的联合优化，这对于资源受限且对安全性要求极高的工业应用场景至关重要。其在降低传输成本方面的表现也极具吸引力。该研究为未来6G网络中实现更高层次的超可靠通信提供了有价值的解决方案。"}}
{"id": "2506.18296", "title": "JIS: A Speech Corpus of Japanese Idol Speakers with Various Speaking Styles", "authors": ["Yuto Kondo", "Hirokazu Kameoka", "Kou Tanaka", "Takuhiro Kaneko"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted on Interspeech 2025", "url": "http://arxiv.org/abs/2506.18296v2", "summary": "We construct Japanese Idol Speech Corpus (JIS) to advance research in speech\ngeneration AI, including text-to-speech synthesis (TTS) and voice conversion\n(VC). JIS will facilitate more rigorous evaluations of speaker similarity in\nTTS and VC systems since all speakers in JIS belong to a highly specific\ncategory: \"young female live idols\" in Japan, and each speaker is identified by\na stage name, enabling researchers to recruit listeners familiar with these\nidols for listening experiments. With its unique speaker attributes, JIS will\nfoster compelling research, including generating voices tailored to listener\npreferences-an area not yet widely studied. JIS will be distributed free of\ncharge to promote research in speech generation AI, with usage restricted to\nnon-commercial, basic research. We describe the construction of JIS, provide an\noverview of Japanese live idol culture to support effective and ethical use of\nJIS, and offer a basic analysis to guide application of JIS.", "comment": "Accepted on Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2506.18296v2", "cate": "cs.SD", "date": "2025-06-23", "updated": "2025-07-15", "AI": {"title_translation": "JIS：一个包含多种说话风格的日本偶像说话者语音语料库", "tldr": "构建了一个名为JIS的日本偶像语音语料库，旨在推动语音生成AI研究，特别是TTS和VC，并支持更严格的说话者相似度评估和个性化语音生成。", "motivation": "旨在推进语音生成AI（包括文本到语音合成TTS和语音转换VC）的研究，并促进对TTS和VC系统中说话者相似度进行更严格的评估。此外，它还旨在促进生成符合听众偏好的个性化语音的研究。", "method": "论文描述了JIS语料库的构建过程，提供了日本现场偶像文化的概述以支持有效和道德的使用，并提供了一个基本分析来指导JIS的应用。", "result": "构建了日本偶像语音语料库（JIS），该语料库包含特定类别的说话者（日本年轻女性现场偶像），且每位说话者都有舞台名称可供识别。", "conclusion": "JIS语料库将免费分发，以促进语音生成AI的研究，其独特属性将有助于TTS和VC中更严格的说话者相似度评估，并开辟个性化语音生成等新研究领域。", "translation": "我们构建了日本偶像语音语料库（JIS），以推进语音生成AI（包括文本到语音合成（TTS）和语音转换（VC））的研究。JIS将促进对TTS和VC系统中说话者相似度进行更严格的评估，因为JIS中的所有说话者都属于一个高度特定的类别：“日本年轻女性现场偶像”，并且每位说话者都通过艺名识别，使研究人员能够招募熟悉这些偶像的听众进行听力实验。凭借其独特的说话者属性，JIS将促进引人入胜的研究，包括生成符合听众偏好的语音——这是一个尚未广泛研究的领域。JIS将免费分发，以促进语音生成AI的研究，使用范围仅限于非商业性基础研究。我们描述了JIS的构建过程，提供了日本现场偶像文化的概述以支持JIS的有效和道德使用，并提供了一个基本分析以指导JIS的应用。", "summary": "本文介绍了日本偶像语音语料库（JIS）的构建，该语料库专注于日本年轻女性现场偶像的语音，旨在推动文本到语音合成（TTS）和语音转换（VC）等语音生成AI的研究。JIS通过其独特的说话者属性，有助于更精确地评估说话者相似度，并支持开发个性化语音生成技术。该语料库将免费提供给非商业性基础研究使用，论文还提供了构建细节、文化背景和基本分析。", "keywords": "日本偶像语音语料库, 语音生成AI, 文本到语音合成, 语音转换, 说话者相似度", "comments": "该论文构建了一个高度专业化和独特的语音语料库，专注于日本偶像这一特定群体，这对于研究说话者相似度评估和个性化语音生成具有重要意义。通过提供可识别的说话者和免费分发，它有望促进相关领域的深入研究，特别是在以往未被广泛研究的“生成符合听众偏好”的语音方面。其创新之处在于数据集的独特性和对特定文化背景的考虑。"}}
{"id": "2503.15426", "title": "Visual Position Prompt for MLLM based Visual Grounding", "authors": ["Wei Tang", "Yanpeng Sun", "Qinying Gu", "Zechao Li"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.15426v4", "summary": "Although Multimodal Large Language Models (MLLMs) excel at various\nimage-related tasks, they encounter challenges in precisely aligning\ncoordinates with spatial information within images, particularly in\nposition-aware tasks such as visual grounding. This limitation arises from two\nkey factors. First, MLLMs lack explicit spatial references, making it difficult\nto associate textual descriptions with precise image locations. Second, their\nfeature extraction processes prioritize global context over fine-grained\nspatial details, leading to weak localization capability. To address these\nissues, we introduce VPP-LLaVA, an MLLM enhanced with Visual Position Prompt\n(VPP) to improve its grounding capability. VPP-LLaVA integrates two\ncomplementary mechanisms: the global VPP overlays a learnable, axis-like tensor\nonto the input image to provide structured spatial cues, while the local VPP\nincorporates position-aware queries to support fine-grained localization.To\neffectively train our model with spatial guidance, we further introduce\nVPP-SFT, a curated dataset of 0.6M high-quality visual grounding samples.\nDesigned in a compact format, it enables efficient training and is\nsignificantly smaller than datasets used by other MLLMs (e.g., ~21M samples in\nMiniGPT-v2), yet still provides a strong performance boost. The resulting\nmodel, VPP-LLaVA, not only achieves state-of-the-art results on standard visual\ngrounding benchmarks but also demonstrates strong zero-shot generalization to\nchallenging unseen datasets. The code and dataset are available at\nhttps://github.com/WayneTomas/VPP-LLaVA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.15426v4", "cate": "cs.CV", "date": "2025-03-19", "updated": "2025-07-16", "AI": {"title_translation": "面向MLLM的视觉定位提示用于视觉定位", "tldr": "MLLM在视觉定位任务中面临空间对齐挑战；本文提出VPP-LLaVA模型，通过视觉定位提示（VPP）和新的VPP-SFT数据集，显著提升了视觉定位能力并达到了SOTA水平。", "motivation": "多模态大型语言模型（MLLM）在将坐标与图像中的空间信息精确对齐方面存在挑战，尤其是在视觉定位等位置感知任务中。这主要是因为它们缺乏明确的空间参考，且特征提取过程偏重全局上下文而非细粒度空间细节，导致定位能力较弱。", "method": "本文引入了VPP-LLaVA，一个通过视觉定位提示（VPP）增强的MLLM，以提升其视觉定位能力。VPP-LLaVA结合了两种机制：全局VPP，将可学习的轴状张量叠加到输入图像上以提供结构化空间线索；局部VPP，结合位置感知查询以支持细粒度定位。此外，为有效训练模型，本文还引入了VPP-SFT，一个包含0.6M高质量视觉定位样本的精选数据集。", "result": "VPP-LLaVA模型不仅在标准视觉定位基准上取得了最先进（SOTA）的成果，而且对具有挑战性的未见数据集也展现出强大的零样本泛化能力。", "conclusion": "VPP-LLaVA通过引入视觉定位提示（VPP）和利用紧凑高效的VPP-SFT数据集，成功解决了MLLM在视觉定位方面的局限性，实现了最先进的性能和强大的泛化能力。", "translation": "尽管多模态大型语言模型（MLLM）在各种图像相关任务中表现出色，但它们在将坐标与图像中的空间信息精确对齐方面遇到挑战，尤其是在视觉定位等位置感知任务中。这种限制源于两个关键因素。首先，MLLM缺乏明确的空间参考，这使得将文本描述与精确的图像位置关联起来变得困难。其次，它们的特征提取过程优先考虑全局上下文而非细粒度的空间细节，导致定位能力较弱。为了解决这些问题，我们引入了VPP-LLaVA，一个通过视觉定位提示（VPP）增强的MLLM，以提高其定位能力。VPP-LLaVA整合了两种互补机制：全局VPP将一个可学习的、轴状张量叠加到输入图像上以提供结构化的空间线索，而局部VPP则结合了位置感知查询以支持细粒度定位。为了有效地用空间指导训练我们的模型，我们进一步引入了VPP-SFT，一个包含0.6M高质量视觉定位样本的精选数据集。它以紧凑格式设计，实现了高效训练，并且比其他MLLM使用的数据集（例如MiniGPT-v2中的约21M样本）小得多，但仍然提供了强大的性能提升。由此产生的模型VPP-LLaVA不仅在标准视觉定位基准上取得了最先进的成果，而且对具有挑战性的未见数据集也表现出强大的零样本泛化能力。代码和数据集可在https://github.com/WayneTomas/VPP-LLaVA获取。", "summary": "多模态大型语言模型（MLLM）在视觉定位等任务中难以进行精确的空间对齐。为解决此问题，本文提出了VPP-LLaVA，一个通过整合全局和局部视觉定位提示（VPP）增强的MLLM，旨在提供结构化空间线索和支持细粒度定位。研究者还构建了0.6M高质量的VPP-SFT数据集用于高效训练。实验结果表明，VPP-LLaVA在标准视觉定位基准上取得了最先进的性能，并展现出强大的零样本泛化能力。", "keywords": "视觉定位, MLLM, 视觉定位提示, 空间信息, VPP-LLaVA", "comments": "该论文通过引入视觉定位提示（VPP）为MLLM提供了明确的空间线索，创新性地解决了其在视觉定位任务中的核心痛点。同时，构建一个紧凑且高效的高质量数据集VPP-SFT，在数据量远小于现有主流数据集的情况下仍能实现SOTA表现，这对于提升模型训练效率和降低资源消耗具有重要意义。"}}
{"id": "2507.11590", "title": "Synthetic Tabular Data Generation: A Comparative Survey for Modern Techniques", "authors": ["Raju Challagundla", "Mohsen Dorodchi", "Pu Wang", "Minwoo Lee"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11590v1", "summary": "As privacy regulations become more stringent and access to real-world data\nbecomes increasingly constrained, synthetic data generation has emerged as a\nvital solution, especially for tabular datasets, which are central to domains\nlike finance, healthcare and the social sciences. This survey presents a\ncomprehensive and focused review of recent advances in synthetic tabular data\ngeneration, emphasizing methods that preserve complex feature relationships,\nmaintain statistical fidelity, and satisfy privacy requirements. A key\ncontribution of this work is the introduction of a novel taxonomy based on\npractical generation objectives, including intended downstream applications,\nprivacy guarantees, and data utility, directly informing methodological design\nand evaluation strategies. Therefore, this review prioritizes the actionable\ngoals that drive synthetic data creation, including conditional generation and\nrisk-sensitive modeling. Additionally, the survey proposes a benchmark\nframework to align technical innovation with real-world demands. By bridging\ntheoretical foundations with practical deployment, this work serves as both a\nroadmap for future research and a guide for implementing synthetic tabular data\nin privacy-critical environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11590v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "合成表格数据生成：现代技术比较综述", "tldr": "随着隐私法规日益严格，真实数据获取受限，合成表格数据生成成为关键解决方案。本文对近期合成表格数据生成方法进行了全面综述，提出了新的分类法和基准框架，旨在连接理论与实践。", "motivation": "随着隐私法规日益严格，真实数据访问日益受限，合成数据生成，尤其是表格数据集的生成，已成为金融、医疗和社会科学等领域的重要解决方案。因此，有必要对该领域的最新进展进行全面综述。", "method": "本综述对合成表格数据生成领域的最新进展进行了全面而重点突出的回顾，强调了那些能够保留复杂特征关系、保持统计保真度并满足隐私要求的方法。它引入了一种基于实际生成目标（包括预期的下游应用、隐私保证和数据效用）的新型分类法。此外，该综述还提出了一个基准框架，以使技术创新与实际需求保持一致。", "result": "本工作引入了一种基于实际生成目标（包括预期下游应用、隐私保证和数据效用）的新型分类法，直接为方法设计和评估策略提供了信息。它优先考虑了驱动合成数据创建的可行目标，包括条件生成和风险敏感建模。此外，该综述提出了一个基准框架，以使技术创新与实际需求保持一致。", "conclusion": "本工作通过连接理论基础与实际部署，为未来研究提供了路线图，并为在隐私关键环境中实施合成表格数据提供了指南。", "translation": "随着隐私法规日益严格，真实世界数据访问日益受限，合成数据生成已成为一个重要的解决方案，特别是对于表格数据集，它在金融、医疗和社会科学等领域至关重要。本综述对合成表格数据生成领域的最新进展进行了全面而重点突出的回顾，强调了那些能够保留复杂特征关系、保持统计保真度并满足隐私要求的方法。这项工作的一个关键贡献是引入了一种基于实际生成目标的新型分类法，包括预期的下游应用、隐私保证和数据效用，直接为方法设计和评估策略提供了信息。因此，本综述优先考虑了驱动合成数据创建的可行目标，包括条件生成和风险敏感建模。此外，该综述提出了一个基准框架，以使技术创新与实际需求保持一致。通过连接理论基础与实际部署，这项工作既为未来研究提供了路线图，也为在隐私关键环境中实施合成表格数据提供了指南。", "summary": "本文对现代合成表格数据生成技术进行了全面的比较综述，旨在应对日益严格的隐私法规和真实数据访问受限的挑战。该综述重点关注了保持数据保真度和隐私的方法，并提出了一个基于实际生成目标的新型分类法。此外，它还引入了一个基准框架，以促进技术创新与实际需求相结合。这项工作旨在为该领域的未来研究提供指导，并促进合成数据在隐私敏感环境中的实际应用。", "keywords": "合成数据生成, 表格数据, 隐私保护, 数据效用, 综述", "comments": "这篇综述的重要性在于它系统地整理了合成表格数据生成领域的最新进展，特别强调了实用性目标和隐私保护。其提出的新型分类法和基准框架有助于统一该领域的研究方向和评估标准，弥合了理论与实践之间的鸿沟，对于推动数据隐私保护和数据共享具有重要意义。"}}
{"id": "2507.11845", "title": "ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification", "authors": ["Kexuan Shi", "Zhuang Qi", "Jingjing Zhu", "Lei Meng", "Yaochen Zhang", "Haibei Huang", "Xiangxu Meng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted in ChinaMM and recommended to Displays", "url": "http://arxiv.org/abs/2507.11845v1", "summary": "Open-set few-shot image classification aims to train models using a small\namount of labeled data, enabling them to achieve good generalization when\nconfronted with unknown environments. Existing methods mainly use visual\ninformation from a single image to learn class representations to distinguish\nknown from unknown categories. However, these methods often overlook the\nbenefits of integrating rich contextual information. To address this issue,\nthis paper proposes a prototypical augmentation and alignment method, termed\nProtoConNet, which incorporates background information from different samples\nto enhance the diversity of the feature space, breaking the spurious\nassociations between context and image subjects in few-shot scenarios.\nSpecifically, it consists of three main modules: the clustering-based data\nselection (CDS) module mines diverse data patterns while preserving core\nfeatures; the contextual-enhanced semantic refinement (CSR) module builds a\ncontext dictionary to integrate into image representations, which boosts the\nmodel's robustness in various scenarios; and the prototypical alignment (PA)\nmodule reduces the gap between image representations and class prototypes,\namplifying feature distances for known and unknown classes. Experimental\nresults from two datasets verified that ProtoConNet enhances the effectiveness\nof representation learning in few-shot scenarios and identifies open-set\nsamples, making it superior to existing methods.", "comment": "Accepted in ChinaMM and recommended to Displays", "pdf_url": "http://arxiv.org/pdf/2507.11845v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "ProtoConNet：面向开放集少样本图像分类的原型增强与对齐", "tldr": "ProtoConNet通过原型增强和对齐机制，利用上下文信息改进了开放集少样本图像分类，表现优于现有方法。", "motivation": "现有开放集少样本图像分类方法主要利用单一图像视觉信息学习类别表示，但往往忽略了集成丰富上下文信息的好处，这可能导致上下文与图像主体之间的虚假关联。", "method": "论文提出了ProtoConNet，一种原型增强与对齐方法。它通过整合来自不同样本的背景信息来增强特征空间的 다양性，并打破少样本场景中上下文与图像主体之间的虚假关联。具体包括三个主要模块：基于聚类的数据选择（CDS）模块，用于挖掘多样数据模式并保留核心特征；上下文增强语义细化（CSR）模块，用于构建上下文词典并融入图像表示，提升模型在各种场景下的鲁棒性；原型对齐（PA）模块，用于缩小图像表示与类别原型之间的差距，放大已知和未知类别的特征距离。", "result": "在两个数据集上的实验结果验证了ProtoConNet能增强少样本场景中表示学习的有效性，并能识别开放集样本，使其优于现有方法。", "conclusion": "ProtoConNet通过其原型增强与对齐机制，有效解决了开放集少样本图像分类中上下文信息利用不足的问题，提升了模型在复杂环境下的泛化能力和开放集识别能力，超越了现有方法。", "translation": "开放集少样本图像分类旨在利用少量标注数据训练模型，使其在面对未知环境时也能获得良好的泛化能力。现有方法主要利用单一图像的视觉信息来学习类别表示，以区分已知和未知类别。然而，这些方法往往忽略了整合丰富上下文信息所带来的好处。为了解决这个问题，本文提出了一种原型增强与对齐方法，命名为ProtoConNet，它整合了来自不同样本的背景信息，以增强特征空间的多样性，打破少样本场景中上下文与图像主体之间的虚假关联。具体来说，它包含三个主要模块：基于聚类的数据选择（CDS）模块，用于挖掘多样数据模式，同时保留核心特征；上下文增强语义细化（CSR）模块，用于构建上下文词典并整合到图像表示中，从而提高模型在各种场景下的鲁棒性；以及原型对齐（PA）模块，用于缩小图像表示与类别原型之间的差距，放大已知和未知类别的特征距离。在两个数据集上的实验结果验证了ProtoConNet增强了少样本场景中表示学习的有效性，并能识别开放集样本，使其优于现有方法。", "summary": "本文提出了ProtoConNet，一种用于开放集少样本图像分类的原型增强与对齐方法。针对现有方法忽略上下文信息的不足，ProtoConNet通过整合不同样本的背景信息来丰富特征空间并消除虚假关联。该方法包含三个核心模块：基于聚类的数据选择（CDS）用于挖掘多样数据模式；上下文增强语义细化（CSR）构建上下文词典以增强鲁棒性；以及原型对齐（PA）以缩小表示与原型差距并放大类间距离。实验证明ProtoConNet在少样本表示学习和开放集样本识别方面优于现有方法。", "keywords": "开放集分类, 少样本学习, 原型网络, 上下文信息, 图像分类", "comments": "ProtoConNet的创新点在于其将背景上下文信息融入到少样本学习中，并通过原型增强与对齐机制来优化特征表示，有效解决了现有方法中上下文信息利用不足和虚假关联的问题，提升了开放集少样本分类的性能和鲁棒性。"}}
{"id": "2507.11913", "title": "Scene Graph-Aided Probabilistic Semantic Communication for Image Transmission", "authors": ["Chen Zhu", "Siyun Liang", "Zhouxiang Zhao", "Jianrong Bao", "Zhaohui Yang", "Zhaoyang Zhang", "Dusit Niyato"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11913v1", "summary": "Semantic communication emphasizes the transmission of meaning rather than raw\nsymbols. It offers a promising solution to alleviate network congestion and\nimprove transmission efficiency. In this paper, we propose a wireless image\ncommunication framework that employs probability graphs as shared semantic\nknowledge base among distributed users. High-level image semantics are\nrepresented via scene graphs, and a two-stage compression algorithm is devised\nto remove predictable components based on learned conditional and co-occurrence\nprobabilities. At the transmitter, the algorithm filters redundant relations\nand entity pairs, while at the receiver, semantic recovery leverages the same\nprobability graphs to reconstruct omitted information. For further research, we\nalso put forward a multi-round semantic compression algorithm with its\ntheoretical performance analysis. Simulation results demonstrate that our\nsemantic-aware scheme achieves superior transmission throughput and satiable\nsemantic alignment, validating the efficacy of leveraging high-level semantics\nfor image communication.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11913v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "场景图辅助的图像传输概率语义通信", "tldr": "提出一种基于场景图和概率图的无线图像语义通信框架，通过两阶段压缩算法提高传输效率和语义对齐。", "motivation": "语义通信旨在传输意义而非原始符号，为缓解网络拥堵和提高传输效率提供了有前景的解决方案。本文将此概念应用于无线图像通信。", "method": "本文提出了一种无线图像通信框架，该框架采用概率图作为分布式用户之间共享的语义知识库。通过场景图表示高级图像语义，并设计了一种两阶段压缩算法，该算法基于学习到的条件和共现概率来移除可预测的组件。在发射端，算法过滤冗余关系和实体对；在接收端，利用相同的概率图重建省略信息。此外，还提出了一种多轮语义压缩算法并进行了理论性能分析。", "result": "仿真结果表明，所提出的语义感知方案实现了卓越的传输吞吐量和令人满意的语义对齐。", "conclusion": "验证了利用高级语义进行图像通信的有效性。", "translation": "语义通信强调传输意义而非原始符号，为缓解网络拥堵和提高传输效率提供了有前景的解决方案。本文提出了一种无线图像通信框架，该框架采用概率图作为分布式用户之间共享的语义知识库。高级图像语义通过场景图表示，并设计了一种两阶段压缩算法，根据学习到的条件和共现概率来移除可预测的组件。在发射端，该算法过滤冗余关系和实体对；在接收端，语义恢复利用相同的概率图来重建省略的信息。为了进一步研究，我们还提出了一种多轮语义压缩算法及其理论性能分析。仿真结果表明，我们提出的语义感知方案实现了卓越的传输吞吐量和令人满意的语义对齐，验证了利用高级语义进行图像通信的有效性。", "summary": "本文提出了一种新颖的无线图像语义通信框架，旨在通过传输图像的高级语义而非原始数据来提高效率。该框架利用场景图表示图像语义，并基于共享的概率图设计了两阶段压缩算法，以去除冗余信息。发射端负责过滤，接收端则利用概率图重建。仿真结果证明了该方案在传输吞吐量和语义对齐方面的优越性，证实了高级语义在图像通信中的有效性。", "keywords": "语义通信, 图像传输, 场景图, 概率图, 语义压缩", "comments": "该论文的创新点在于将场景图与概率图结合应用于无线图像语义通信，并通过两阶段压缩算法实现高效传输。其重要性在于提供了一种潜在的解决方案来缓解网络拥堵并提高图像传输效率。"}}
{"id": "2507.12357", "title": "Online Block Packing", "authors": ["Ariel Ben Eliezer", "Noam Nisan"], "categories": ["cs.DS", "cs.GT"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12357v1", "summary": "We consider the algorithmic challenge that is faced by blockchains that have\nmultidimensional block constraints and serve quasi-patient bidders. We provide\nonline approximation algorithms for this problem, thus solving open problems\nleft by [Babaioff and Nisan, EC 2025].", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12357v1", "cate": "cs.DS", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "在线区块打包", "tldr": "论文提出了在线近似算法，解决了具有多维区块约束和准耐心竞标者的区块链所面临的算法挑战，从而解决了开放问题。", "motivation": "区块链在具有多维区块约束并服务准耐心竞标者时面临算法挑战，这是一个需要解决的开放问题。", "method": "提供了在线近似算法。", "result": "解决了[Babaioff 和 Nisan, EC 2025]留下的开放问题。", "conclusion": "Not mentioned in abstract", "translation": "我们考虑了具有多维区块约束并服务准耐心竞标者的区块链所面临的算法挑战。我们为这个问题提供了在线近似算法，从而解决了[Babaioff 和 Nisan, EC 2025]留下的开放问题。", "summary": "本文研究了具有多维区块约束并服务准耐心竞标者的区块链所面临的算法难题。作者提出了在线近似算法来解决这一问题，成功地解答了此前由Babaioff和Nisan在EC 2025中提出的开放性问题。", "keywords": "区块链, 在线近似算法, 区块打包, 多维约束, 约束", "comments": "这篇论文通过引入在线近似算法，为区块链在特定复杂约束条件下的区块打包问题提供了新的解决方案，解决了前人留下的开放问题，具有重要的理论和实践意义。"}}
{"id": "2501.17965", "title": "Variational Combinatorial Sequential Monte Carlo for Bayesian Phylogenetics in Hyperbolic Space", "authors": ["Alex Chen", "Philipe Chlenski", "Kenneth Munyuza", "Antonio Khalil Moretti", "Christian A. Naesseth", "Itsik Pe'er"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      24 pages, 10 figures", "url": "http://arxiv.org/abs/2501.17965v2", "summary": "Hyperbolic space naturally encodes hierarchical structures such as\nphylogenies (binary trees), where inward-bending geodesics reflect paths\nthrough least common ancestors, and the exponential growth of neighborhoods\nmirrors the super-exponential scaling of topologies. This scaling challenge\nlimits the efficiency of Euclidean-based approximate inference methods.\nMotivated by the geometric connections between trees and hyperbolic space, we\ndevelop novel hyperbolic extensions of two sequential search algorithms:\nCombinatorial and Nested Combinatorial Sequential Monte Carlo (\\textsc{Csmc}\nand \\textsc{Ncsmc}). Our approach introduces consistent and unbiased\nestimators, along with variational inference methods (\\textsc{H-Vcsmc} and\n\\textsc{H-Vncsmc}), which outperform their Euclidean counterparts. Empirical\nresults demonstrate improved speed, scalability and performance in\nhigh-dimensional phylogenetic inference tasks.", "comment": "24 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2501.17965v2", "cate": "cs.LG", "date": "2025-01-29", "updated": "2025-07-15", "AI": {"title_translation": "双曲空间中贝叶斯系统发育学的变分组合序贯蒙特卡罗方法", "tldr": "该研究开发了用于贝叶斯系统发育学的新型双曲扩展变分组合序贯蒙特卡罗方法，通过利用双曲空间固有的层次结构编码能力，解决了欧几里得方法在处理高维系统发育推断任务时效率受限的问题，并实现了更高的速度、可扩展性和性能。", "motivation": "欧几里得空间中的近似推断方法在处理系统发育学（二叉树）的超指数尺度问题时效率受限。由于树和双曲空间之间存在几何联系，双曲空间能自然地编码层次结构，这激发了研究者开发新的方法来提高高维系统发育推断的效率。", "method": "研究开发了组合序贯蒙特卡罗（CSMC）和嵌套组合序贯蒙特卡罗（NCSMC）两种序贯搜索算法的新型双曲扩展，并引入了变分推断方法（H-VCSMC和H-VNCSMC），以构建一致且无偏的估计器。", "result": "所提出的方法引入了一致且无偏的估计器，并且优于其欧几里得对应方法。实证结果表明，在高维系统发育推断任务中，该方法显著提高了速度、可扩展性和性能。", "conclusion": "通过利用双曲空间对层次结构的天然编码能力，所提出的双曲扩展变分组合序贯蒙特卡罗方法在贝叶斯系统发育学中展现出优于传统欧几里得方法的性能，特别是在高维推断任务中。", "translation": "双曲空间自然地编码层次结构，例如系统发育（二叉树），其中向内弯曲的测地线反映了通过最小共同祖先的路径，并且邻域的指数增长反映了拓扑的超指数尺度。这种尺度挑战限制了基于欧几里得的近似推断方法的效率。受树和双曲空间之间几何联系的启发，我们开发了两种序贯搜索算法的新型双曲扩展：组合序贯蒙特卡罗（CSMC）和嵌套组合序贯蒙特卡罗（NCSMC）。我们的方法引入了一致且无偏的估计器，以及变分推断方法（H-VCSMC和H-VNCSMC），它们优于其欧几里得对应方法。实证结果表明，在高维系统发育推断任务中，速度、可扩展性和性能均有所提高。", "summary": "该论文针对欧几里得空间在处理系统发育学中超指数尺度问题的效率限制，提出了在双曲空间中进行贝叶斯系统发育推断的新方法。研究者开发了组合序贯蒙特卡罗（CSMC）和嵌套组合序贯蒙特卡罗（NCSMC）算法的双曲扩展，并结合了变分推断（H-VCSMC和H-VNCSMC），以利用双曲空间对层次结构的天然编码能力。实验证明，这些新方法在高维系统发育推断任务中，相较于欧几里得对应方法，在速度、可扩展性和性能上均有显著提升。", "keywords": "双曲空间, 贝叶斯系统发育学, 序贯蒙特卡罗, 变分推断, 层次结构", "comments": "该论文的创新点在于将双曲几何引入贝叶斯系统发育学，并对经典的序贯蒙特卡罗方法进行了双曲扩展和变分推断的结合。通过利用双曲空间对层次结构的内在编码能力，有效解决了欧几里得方法在处理大规模系统发育推断时面临的效率和可扩展性问题，这对于计算生物学和机器学习领域具有重要意义。"}}
{"id": "2507.11841", "title": "\"Mapping What I Feel\": Understanding Affective Geovisualization Design Through the Lens of People-Place Relationships", "authors": ["Xingyu Lan", "Yutong Yang", "Yifan Wang"], "categories": ["cs.HC", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11841v1", "summary": "Affective visualization design is an emerging research direction focused on\ncommunicating and influencing emotion through visualization. However, as\nrevealed by previous research, this area is highly interdisciplinary and\ninvolves theories and practices from diverse fields and disciplines, thus\nawaiting analysis from more fine-grained angles. To address this need, this\nwork focuses on a pioneering and relatively mature sub-area, affective\ngeovisualization design, to further the research in this direction and provide\nmore domain-specific insights. Through an analysis of a curated corpus of\naffective geovisualization designs using the Person-Process-Place (PPP) model\nfrom geographic theory, we derived a design taxonomy that characterizes a\nvariety of methods for eliciting and enhancing emotions through geographic\nvisualization. We also identified four underlying high-level design paradigms\nof affective geovisualization design (e.g., computational, anthropomorphic)\nthat guide distinct approaches to linking geographic information with human\nexperience. By extending existing affective visualization design frameworks\nwith geographic specificity, we provide additional design examples,\ndomain-specific analyses, and insights to guide future research and practices\nin this underexplored yet highly innovative domain.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11841v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "“映射我的感受”：通过人地关系视角理解情感地理可视化设计", "tldr": "本文通过分析情感地理可视化设计，利用人-过程-地点模型，导出了设计分类法并识别了四种设计范式，为该领域的未来研究和实践提供了指导。", "motivation": "情感可视化设计是一个新兴的跨学科领域，需要更细致的分析。为了满足这一需求，本文专注于情感地理可视化设计这一相对成熟的子领域，以深化研究并提供特定领域的见解。", "method": "本文通过使用地理学理论中的人-过程-地点（PPP）模型，分析了精心策划的情感地理可视化设计语料库。", "result": "本文导出了一个设计分类法，该分类法描述了通过地理可视化引发和增强情感的各种方法。此外，还识别了情感地理可视化设计的四种底层高级设计范式（例如，计算型、拟人型），这些范式指导着将地理信息与人类体验联系起来的不同方法。", "conclusion": "通过扩展现有情感可视化设计框架并增加地理特异性，本文提供了额外的设计示例、领域特定分析和见解，以指导这一未充分探索但极具创新性的领域的未来研究和实践。", "translation": "情感可视化设计是一个新兴的研究方向，专注于通过可视化来传达和影响情感。然而，正如先前的研究所揭示的，该领域具有高度的跨学科性，涉及来自不同领域和学科的理论和实践，因此有待从更细粒度的角度进行分析。为了满足这一需求，这项工作专注于一个开创性且相对成熟的子领域——情感地理可视化设计，以推动该方向的研究并提供更多领域特定的见解。通过使用地理学理论中的人-过程-地点（PPP）模型对精心策划的情感地理可视化设计语料库进行分析，我们导出了一个设计分类法，该分类法描述了通过地理可视化引发和增强情感的各种方法。我们还识别了情感地理可视化设计的四种底层高级设计范式（例如，计算型、拟人型），这些范式指导着将地理信息与人类体验联系起来的不同方法。通过扩展现有情感可视化设计框架并增加地理特异性，我们提供了额外的设计示例、领域特定分析和见解，以指导这一未充分探索但极具创新性的领域的未来研究和实践。", "summary": "本文针对情感可视化设计领域需要更细致分析的需求，专注于情感地理可视化设计。通过应用人-过程-地点模型分析现有设计，研究者建立了一个用于描述情感地理可视化方法的设计分类法，并识别了四种核心设计范式。这项工作扩展了现有框架，提供了领域特定见解和设计示例，旨在为情感地理可视化未来的研究与实践提供指导。", "keywords": "情感可视化, 地理可视化, 人地关系, 设计范式, PPP模型", "comments": "这篇论文通过聚焦情感地理可视化设计，解决了情感可视化领域跨学科性强、缺乏细粒度分析的问题。其创新点在于引入了地理学中的人-过程-地点模型来分析情感地理可视化，并由此导出了独特的设计分类法和四种高级设计范式。这为理解和实践情感与地理信息结合提供了新的视角和工具，对于推动该新兴领域的理论发展和应用实践具有重要意义。"}}
{"id": "2501.01038", "title": "Energy-Efficient and Intelligent ISAC in V2X Networks with Spiking Neural Networks-Driven DRL", "authors": ["Chen Shang", "Jiadong Yu", "Dinh Thai Hoang"], "categories": ["cs.NI", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      14 pages, 12 figures", "url": "http://arxiv.org/abs/2501.01038v2", "summary": "Integrated sensing and communication (ISAC) is emerging as a key enabler for\nvehicle-to-everything (V2X) systems. However, designing efficient beamforming\nschemes for ISAC signals to achieve accurate sensing and enhance communication\nperformance in the dynamic and uncertain environments of V2X networks presents\nsignificant challenges. While artificial intelligence technologies offer\npromising solutions, the energy-intensive nature of neural networks imposes\nsubstantial burdens on communication infrastructures. To address these\nchallenges, this work proposes an energy-efficient and intelligent ISAC system\nfor V2X networks. Specifically, we first leverage a Markov Decision Process\nframework to model the dynamic and uncertain nature of V2X networks. This\nframework allows the roadside unit to develop beamforming schemes relying\nsolely on its current sensing information, eliminating the need for numerous\npilot signals and extensive CSI acquisition. We then introduce an advanced deep\nreinforcement learning (DRL) algorithm, enabling the joint optimization of\nbeamforming and power allocation to guarantee both communication rate and\nsensing accuracy in dynamic and uncertain V2X scenario. To alleviate the energy\ndemands of neural networks, we integrate spiking neural networks (SNNs) into\nthe DRL algorithm. The event-driven, sparse spike-based processing of SNNs\nsignificantly improves energy efficiency while maintaining strong performance.\nExtensive simulation results validate the effectiveness of the proposed scheme\nwith lower energy consumption, superior communication performance, and improved\nsensing accuracy.", "comment": "14 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2501.01038v2", "cate": "cs.NI", "date": "2025-01-02", "updated": "2025-07-16", "AI": {"title_translation": "具有脉冲神经网络驱动的深度强化学习的V2X网络中节能智能ISAC", "tldr": "本文提出一种基于脉冲神经网络驱动的深度强化学习（DRL）的节能智能集成传感与通信（ISAC）系统，用于V2X网络，通过联合优化波束成形和功率分配，在降低能耗的同时提高通信性能和传感精度。", "motivation": "在动态不确定的V2X网络环境中，设计高效的ISAC波束成形方案以实现精确传感和增强通信性能面临挑战。此外，传统神经网络的能耗高，给通信基础设施带来巨大负担。", "method": "1. 利用马尔可夫决策过程（MDP）框架建模V2X网络的动态和不确定性，使路边单元仅依赖当前感知信息进行波束成形，减少对导频信号和CSI获取的需求。 2. 引入先进的深度强化学习（DRL）算法，实现波束成形和功率分配的联合优化，以保证通信速率和传感精度。 3. 将脉冲神经网络（SNNs）集成到DRL算法中，利用SNN事件驱动、稀疏脉冲处理的特性，显著提高能源效率。", "result": "仿真结果验证了所提方案的有效性，表现出更低的能耗、卓越的通信性能和更高的传感精度。", "conclusion": "本文提出的基于SNNs驱动DRL的ISAC系统，在V2X网络中实现了能量效率、通信性能和传感精度的全面提升。", "translation": "集成传感与通信（ISAC）正在成为车联网（V2X）系统的关键使能技术。然而，在V2X网络动态不确定的环境中，设计高效的ISAC信号波束成形方案以实现精确传感和增强通信性能面临巨大挑战。尽管人工智能技术提供了有前景的解决方案，但神经网络的能源密集型特性给通信基础设施带来了巨大负担。为了应对这些挑战，本工作提出了一种用于V2X网络的节能智能ISAC系统。具体而言，我们首先利用马尔可夫决策过程框架对V2X网络的动态和不确定性进行建模。该框架允许路边单元仅依赖其当前感知信息来制定波束成形方案，从而消除了对大量导频信号和广泛CSI获取的需求。然后，我们引入了一种先进的深度强化学习（DRL）算法，实现波束成形和功率分配的联合优化，以保证动态不确定V2X场景下的通信速率和传感精度。为了减轻神经网络的能源需求，我们将脉冲神经网络（SNNs）集成到DRL算法中。SNN的事件驱动、基于稀疏脉冲的处理显著提高了能源效率，同时保持了强大的性能。大量的仿真结果验证了所提方案的有效性，具有更低的能耗、卓越的通信性能和更高的传感精度。", "summary": "本文提出一种面向V2X网络的节能智能ISAC系统，旨在解决动态不确定环境中ISAC波束成形设计的挑战及神经网络高能耗问题。该系统通过马尔可夫决策过程建模V2X环境，并引入基于脉冲神经网络（SNNs）的深度强化学习（DRL）算法，实现波束成形和功率分配的联合优化。SNNs的引入有效降低了能耗，同时保证了通信速率和传感精度。仿真结果证实了所提方案在能耗、通信性能和传感精度方面的显著优势。", "keywords": "ISAC, V2X, 深度强化学习, 脉冲神经网络, 节能", "comments": "这篇论文的创新点在于将脉冲神经网络（SNNs）集成到深度强化学习（DRL）中，以解决V2X网络中集成传感与通信（ISAC）系统的能耗问题。SNNs的事件驱动和稀疏处理特性，使其在保持性能的同时显著提升了能效，这对于资源受限的V2X环境非常重要。这种结合为未来节能AI在通信领域的应用提供了新的思路。"}}
{"id": "2503.06138", "title": "System 0/1/2/3: Quad-process theory for multi-timescale embodied collective cognitive systems", "authors": ["Tadahiro Taniguchi", "Yasushi Hirai", "Masahiro Suzuki", "Shingo Murata", "Takato Horii", "Kazutoshi Tanaka"], "categories": ["cs.AI", "cs.RO", "q-bio.NC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2503.06138v3", "summary": "This paper introduces the System 0/1/2/3 framework as an extension of\ndual-process theory, employing a quad-process model of cognition. Expanding\nupon System 1 (fast, intuitive thinking) and System 2 (slow, deliberative\nthinking), we incorporate System 0, which represents pre-cognitive embodied\nprocesses, and System 3, which encompasses collective intelligence and symbol\nemergence. We contextualize this model within Bergson's philosophy by adopting\nmulti-scale time theory to unify the diverse temporal dynamics of cognition.\nSystem 0 emphasizes morphological computation and passive dynamics,\nillustrating how physical embodiment enables adaptive behavior without explicit\nneural processing. Systems 1 and 2 are explained from a constructive\nperspective, incorporating neurodynamical and AI viewpoints. In System 3, we\nintroduce collective predictive coding to explain how societal-level adaptation\nand symbol emergence operate over extended timescales. This comprehensive\nframework ranges from rapid embodied reactions to slow-evolving collective\nintelligence, offering a unified perspective on cognition across multiple\ntimescales, levels of abstraction, and forms of human intelligence. The System\n0/1/2/3 model provides a novel theoretical foundation for understanding the\ninterplay between adaptive and cognitive processes, thereby opening new avenues\nfor research in cognitive science, AI, robotics, and collective intelligence.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2503.06138v3", "cate": "cs.AI", "date": "2025-03-08", "updated": "2025-07-16", "AI": {"title_translation": "系统0/1/2/3：多时间尺度具身集体认知系统的四过程理论", "tldr": "本文提出了System 0/1/2/3四过程认知理论，扩展了双过程理论，统一了从具身反应到集体智慧的多尺度认知。", "motivation": "本文旨在通过引入System 0/1/2/3四过程模型来扩展双过程理论，从而提供一个更全面的认知框架。", "method": "论文引入了System 0（前认知具身过程）和System 3（集体智能和符号涌现），并结合System 1（快速直觉思维）和System 2（慢速审慎思维），形成四过程模型。该模型通过采用多尺度时间理论在柏格森哲学中进行情境化，并分别解释了System 0的形态计算和被动动力学，System 1和2的建构性视角（神经动力学和AI观点），以及System 3的集体预测编码。", "result": "该框架统一了从快速具身反应到缓慢演进的集体智能，提供了跨越多个时间尺度、抽象层次和人类智能形式的统一认知视角。", "conclusion": "System 0/1/2/3模型为理解适应性过程与认知过程之间的相互作用提供了一个新颖的理论基础，为认知科学、人工智能、机器人学和集体智能领域的研究开辟了新途径。", "translation": "本文引入了System 0/1/2/3框架作为双过程理论的扩展，采用四过程认知模型。在System 1（快速、直觉思维）和System 2（慢速、审慎思维）的基础上，我们纳入了System 0，它代表前认知具身过程，以及System 3，它涵盖了集体智能和符号涌现。我们通过采用多尺度时间理论将该模型置于柏格森哲学中，以统一认知的多样化时间动态。System 0强调形态计算和被动动力学，说明了物理具身如何在没有明确神经处理的情况下实现适应性行为。System 1和System 2从建构性角度进行解释，结合了神经动力学和人工智能的观点。在System 3中，我们引入了集体预测编码来解释社会层面的适应和符号涌现是如何在更长的时间尺度上运作的。这个全面的框架涵盖了从快速具身反应到缓慢演进的集体智能，为跨多个时间尺度、抽象层次和人类智能形式的认知提供了统一的视角。System 0/1/2/3模型为理解适应性过程与认知过程之间的相互作用提供了新颖的理论基础，从而为认知科学、人工智能、机器人学和集体智能领域的研究开辟了新途径。", "summary": "本文提出了System 0/1/2/3四过程理论，扩展了传统的双过程理论，将认知过程划分为前认知具身过程（System 0）、快速直觉思维（System 1）、慢速审慎思维（System 2）和集体智能与符号涌现（System 3）。该模型通过多尺度时间理论与柏格森哲学相结合，旨在统一理解从快速身体反应到缓慢演进的集体智慧等不同时间尺度和抽象层次的认知现象。它为认知科学、人工智能等领域提供了新的理论基础。", "keywords": "四过程理论, 多时间尺度, 具身认知, 集体智能, 认知系统", "comments": "这篇论文通过将双过程理论扩展到四过程模型，并引入多时间尺度概念，提供了一个创新的认知框架，有助于整合不同层次和时间尺度的认知现象，特别是在具身认知和集体智能方面具有重要意义。"}}
{"id": "2507.12156", "title": "SmokeSVD: Smoke Reconstruction from A Single View via Progressive Novel View Synthesis and Refinement with Diffusion Models", "authors": ["Chen Li", "Shanshan Dong", "Sheng Qiu", "Jianmin Han", "Zan Gao", "Kemeng Huang", "Taku Komura"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12156v1", "summary": "Reconstructing dynamic fluids from sparse views is a long-standing and\nchallenging problem, due to the severe lack of 3D information from insufficient\nview coverage. While several pioneering approaches have attempted to address\nthis issue using differentiable rendering or novel view synthesis, they are\noften limited by time-consuming optimization and refinement processes under\nill-posed conditions. To tackle above challenges, we propose SmokeSVD, an\nefficient and effective framework to progressively generate and reconstruct\ndynamic smoke from a single video by integrating both the powerful generative\ncapabilities from diffusion models and physically guided consistency\noptimization towards realistic appearance and dynamic evolution. Specifically,\nwe first propose a physically guided side-view synthesizer based on diffusion\nmodels, which explicitly incorporates divergence and gradient guidance of\nvelocity fields to generate visually realistic and spatio-temporally consistent\nside-view images frame by frame, significantly alleviating the ill-posedness of\nsingle-view reconstruction without imposing additional constraints.\nSubsequently, we determine a rough estimation of density field from the pair of\nfront-view input and side-view synthetic image, and further refine 2D blurry\nnovel-view images and 3D coarse-grained density field through an iterative\nprocess that progressively renders and enhances the images from increasing\nnovel viewing angles, generating high-quality multi-view image sequences.\nFinally, we reconstruct and estimate the fine-grained density field, velocity\nfield, and smoke source via differentiable advection by leveraging the\nNavier-Stokes equations. Extensive quantitative and qualitative experiments\nshow that our approach achieves high-quality reconstruction and outperforms\nprevious state-of-the-art techniques.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12156v1", "cate": "cs.GR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "SmokeSVD：基于渐进式新视角合成和扩散模型细化的单视角烟雾重建", "tldr": "SmokeSVD提出了一种从单视角视频重建动态烟雾的框架，它结合了扩散模型的生成能力和物理引导的一致性优化，实现了高质量的重建并优于现有技术。", "motivation": "从稀疏视角重建动态流体是一个长期存在的挑战性问题，原因在于视角覆盖不足导致3D信息严重缺失。现有的方法通常受限于耗时的优化和细化过程，且在病态条件下表现不佳。", "method": "本文提出了SmokeSVD框架。首先，基于扩散模型提出了一个物理引导的侧视图合成器，通过明确引入速度场的散度和梯度指导，逐帧生成视觉真实且时空一致的侧视图图像。其次，从正面输入和合成的侧视图图像对中确定密度场的粗略估计，并通过迭代过程细化2D模糊的新视图图像和3D粗粒度密度场，该过程渐进地渲染和增强来自不断增加的新视角图像，生成高质量的多视角图像序列。最后，利用Navier-Stokes方程，通过可微分对流重建和估计细粒度密度场、速度场和烟雾源。", "result": "广泛的定量和定性实验表明，所提出的方法实现了高质量的重建，并优于现有的最先进技术。", "conclusion": "SmokeSVD通过结合扩散模型的强大生成能力和物理引导的一致性优化，有效解决了单视角动态烟雾重建的挑战，实现了高质量的重建结果。", "translation": "从稀疏视角重建动态流体是一个长期存在的挑战性问题，原因在于视角覆盖不足导致3D信息严重缺失。尽管一些开创性的方法试图通过可微分渲染或新视角合成来解决这个问题，但它们往往受限于病态条件下的耗时优化和细化过程。为了应对上述挑战，我们提出了SmokeSVD，一个高效且有效的框架，通过整合扩散模型的强大生成能力和物理引导的一致性优化，以实现逼真的外观和动态演变，从而从单个视频中渐进地生成和重建动态烟雾。具体来说，我们首先提出了一个基于扩散模型的物理引导侧视图合成器，该合成器明确地结合了速度场的散度和梯度指导，逐帧生成视觉真实且时空一致的侧视图图像，在不施加额外约束的情况下显著缓解了单视角重建的病态性。随后，我们从正面输入和侧视图合成图像对中确定密度场的粗略估计，并通过迭代过程进一步细化2D模糊的新视图图像和3D粗粒度密度场，该过程渐进地渲染和增强来自不断增加的新视角图像，生成高质量的多视角图像序列。最后，我们利用Navier-Stokes方程，通过可微分对流重建和估计细粒度密度场、速度场和烟雾源。广泛的定量和定性实验表明，我们的方法实现了高质量的重建，并优于现有的最先进技术。", "summary": "SmokeSVD是一种新颖的框架，旨在从单个视频中高效且有效地重建动态烟雾。它创新性地结合了扩散模型的强大生成能力和物理引导的一致性优化。该方法首先通过物理引导的扩散模型合成侧视图，减轻了单视角重建的病态性。随后，通过迭代过程逐步细化密度场和多视角图像序列，并最终利用Navier-Stokes方程进行可微分对流，重建精细的密度场、速度场和烟雾源。实验证明，SmokeSVD在高质量烟雾重建方面超越了现有最先进技术。", "keywords": "烟雾重建, 单视角, 扩散模型, 新视角合成, 物理引导", "comments": "本文提出了一种创新的单视角动态烟雾重建方法，通过巧妙地结合扩散模型的生成能力和物理引导，有效解决了该领域的长期挑战。其核心创新在于引入物理引导的侧视图合成器和渐进式迭代细化过程，显著缓解了单视角重建的病态性，并确保了物理一致性。该方法在实现高质量重建方面表现出色，为动态流体重建领域提供了重要进展。"}}
{"id": "2503.11579", "title": "Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers", "authors": ["Weiming Ren", "Wentao Ma", "Huan Yang", "Cong Wei", "Ge Zhang", "Wenhu Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 Camera Ready Version. Project Page: this https URL", "url": "http://arxiv.org/abs/2503.11579v2", "summary": "State-of-the-art transformer-based large multimodal models (LMMs) struggle to\nhandle hour-long video inputs due to the quadratic complexity of the causal\nself-attention operations, leading to high computational costs during training\nand inference. Existing token compression-based methods reduce the number of\nvideo tokens but often incur information loss and remain inefficient for\nextremely long sequences. In this paper, we explore an orthogonal direction to\nbuild a hybrid Mamba-Transformer model (VAMBA) that employs Mamba-2 blocks to\nencode video tokens with linear complexity. Without any token reduction, VAMBA\ncan encode more than 1024 frames (640$\\times$360) on a single GPU, while\ntransformer-based models can only encode 256 frames. On long video input, VAMBA\nachieves at least 50% reduction in GPU memory usage during training and\ninference, and nearly doubles the speed per training step compared to\ntransformer-based LMMs. Our experimental results demonstrate that VAMBA\nimproves accuracy by 4.3% on the challenging hour-long video understanding\nbenchmark LVBench over prior efficient video LMMs, and maintains strong\nperformance on a broad spectrum of long and short video understanding tasks.", "comment": "ICCV 2025 Camera Ready Version. Project Page:\n  https://tiger-ai-lab.github.io/Vamba/", "pdf_url": "http://arxiv.org/pdf/2503.11579v2", "cate": "cs.CV", "date": "2025-03-14", "updated": "2025-07-16", "AI": {"title_translation": "Vamba: 理解长达一小时的视频与混合Mamba-Transformer模型", "tldr": "VAMBA是一个混合Mamba-Transformer模型，通过使用Mamba-2块实现线性复杂度，有效解决了现有Transformer模型处理长视频时计算成本高和内存消耗大的问题，显著提升了长视频理解的效率和准确性。", "motivation": "现有的基于Transformer的大型多模态模型（LMMs）由于因果自注意力操作的二次复杂度，难以处理长达一小时的视频输入，导致训练和推理时计算成本高昂。现有的基于Token压缩的方法虽然减少了视频Token数量，但常导致信息丢失且对极长序列效率低下。", "method": "本文探索了一个正交方向来构建混合Mamba-Transformer模型（VAMBA），该模型采用Mamba-2块以线性复杂度编码视频Token，且不进行任何Token缩减。VAMBA可以在单个GPU上编码超过1024帧（640x360）的视频，而基于Transformer的模型只能编码256帧。", "result": "在长视频输入上，VAMBA在训练和推理期间将GPU内存使用量至少减少了50%，并且每个训练步骤的速度比基于Transformer的LMMs快近一倍。实验结果表明，VAMBA在具有挑战性的长达一小时的视频理解基准LVBench上，比之前的SOTA高效视频LMMs提高了4.3%的准确性，并在广泛的长短视频理解任务中保持了强大的性能。", "conclusion": "VAMBA通过引入混合Mamba-Transformer架构，有效解决了长视频理解中的计算效率瓶颈，显著提升了性能和资源利用率，是处理长时间视频输入的一种高效且准确的解决方案。", "translation": "最先进的基于Transformer的大型多模态模型（LMMs）由于因果自注意力操作的二次复杂度，难以处理长达一小时的视频输入，导致训练和推理时计算成本高昂。现有的基于Token压缩的方法虽然减少了视频Token数量，但常导致信息丢失且对极长序列效率低下。在本文中，我们探索了一个正交方向来构建混合Mamba-Transformer模型（VAMBA），该模型采用Mamba-2块以线性复杂度编码视频Token。在不进行任何Token缩减的情况下，VAMBA可以在单个GPU上编码超过1024帧（640x360）的视频，而基于Transformer的模型只能编码256帧。在长视频输入上，VAMBA在训练和推理期间将GPU内存使用量至少减少了50%，并且每个训练步骤的速度比基于Transformer的LMMs快近一倍。我们的实验结果表明，VAMBA在具有挑战性的长达一小时的视频理解基准LVBench上，比之前的SOTA高效视频LMMs提高了4.3%的准确性，并在广泛的长短视频理解任务中保持了强大的性能。", "summary": "本文提出VAMBA，一个混合Mamba-Transformer模型，旨在解决现有Transformer模型在处理长达一小时视频时面临的计算效率和内存限制。VAMBA利用Mamba-2块以线性复杂度编码视频Token，无需Token缩减，显著降低了GPU内存使用量（50%以上）并提升了训练速度（近一倍）。实验证明，VAMBA在长视频理解基准LVBench上实现了4.3%的准确性提升，并对长短视频任务均表现出强大性能，有效提升了长视频理解的效率和准确性。", "keywords": "长视频理解, 混合Mamba-Transformer, 线性复杂度, 大型多模态模型, 计算效率", "comments": "VAMBA的创新之处在于其将Mamba-2块与Transformer结构相结合，以线性复杂度处理长序列，有效规避了传统Transformer自注意力机制的二次复杂度瓶颈。这对于处理小时级视频数据是至关重要的突破，因为它在不牺牲信息量（无Token缩减）的前提下显著提升了计算效率和资源利用率。该工作为未来大型多模态模型处理超长序列提供了一个有前景的方向。"}}
{"id": "2507.12384", "title": "Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries", "authors": ["Bo Wen", "Guoyun Gao", "Zhicheng Xu", "Ruibin Mao", "Xiaojuan Qi", "X. Sharon Hu", "Xunzhao Yin", "Can Li"], "categories": ["cs.LG", "cs.ET"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12384v1", "summary": "The rapid advancement of artificial intelligence has raised concerns\nregarding its trustworthiness, especially in terms of interpretability and\nrobustness. Tree-based models like Random Forest and XGBoost excel in\ninterpretability and accuracy for tabular data, but scaling them remains\ncomputationally expensive due to poor data locality and high data dependence.\nPrevious efforts to accelerate these models with analog content addressable\nmemory (CAM) have struggled, due to the fact that the difficult-to-implement\nsharp decision boundaries are highly susceptible to device variations, which\nleads to poor hardware performance and vulnerability to adversarial attacks.\nThis work presents a novel hardware-software co-design approach using $MoS_2$\nFlash-based analog CAM with inherent soft boundaries, enabling efficient\ninference with soft tree-based models. Our soft tree model inference\nexperiments on $MoS_2$ analog CAM arrays show this method achieves exceptional\nrobustness against device variation and adversarial attacks while achieving\nstate-of-the-art accuracy. Specifically, our fabricated analog CAM arrays\nachieve $96\\%$ accuracy on Wisconsin Diagnostic Breast Cancer (WDBC) database,\nwhile maintaining decision explainability. Our experimentally calibrated model\nvalidated only a $0.6\\%$ accuracy drop on the MNIST dataset under $10\\%$ device\nthreshold variation, compared to a $45.3\\%$ drop for traditional decision\ntrees. This work paves the way for specialized hardware that enhances AI's\ntrustworthiness and efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12384v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于$MoS_2$闪存模拟内容寻址存储器和固有软边界的可信树基机器学习", "tldr": "本研究提出了一种基于$MoS_2$闪存模拟内容寻址存储器（CAM）的硬件-软件协同设计方法，通过引入固有软边界，实现了高效且可信赖的软树基模型推理，显著提高了模型对设备变异和对抗性攻击的鲁棒性。", "motivation": "人工智能的快速发展引发了对其可信赖性的担忧，特别是在可解释性和鲁棒性方面。虽然树基模型在表格数据上表现出色，但其计算成本高昂。现有使用模拟内容寻址存储器加速树基模型的方法因难以实现的尖锐决策边界易受设备变异影响，导致硬件性能差且易受攻击。", "method": "本研究提出了一种新颖的硬件-软件协同设计方法，使用基于$MoS_2$闪存的模拟内容寻址存储器（CAM），该存储器具有固有的软边界，从而能够高效地进行软树基模型推理。", "result": "在$MoS_2$模拟CAM阵列上进行的软树模型推理实验表明，该方法对设备变异和对抗性攻击具有卓越的鲁棒性，同时实现了最先进的准确性。具体而言，所制造的模拟CAM阵列在威斯康星诊断乳腺癌（WDBC）数据库上达到了$96\\%$的准确率，并保持了决策可解释性。在MNIST数据集上，当设备阈值变异为$10\\%$时，我们经过实验校准的模型准确率仅下降了$0.6\\%$，而传统决策树则下降了$45.3\\%$。", "conclusion": "这项工作为开发专用硬件铺平了道路，该硬件能够增强人工智能的可信赖性和效率。", "translation": "人工智能的快速发展引发了对其可信赖性的担忧，特别是在可解释性和鲁棒性方面。随机森林和XGBoost等树基模型在表格数据的可解释性和准确性方面表现出色，但由于数据局部性差和数据依赖性高，其扩展性仍然计算成本高昂。先前使用模拟内容寻址存储器（CAM）加速这些模型的努力遇到了困难，因为难以实现的尖锐决策边界极易受设备变异的影响，这导致硬件性能不佳，并且容易受到对抗性攻击。这项工作提出了一种新颖的硬件-软件协同设计方法，使用基于$MoS_2$闪存的模拟CAM，该CAM具有固有的软边界，能够实现软树基模型的高效推理。我们在$MoS_2$模拟CAM阵列上进行的软树模型推理实验表明，该方法对设备变异和对抗性攻击具有卓越的鲁棒性，同时实现了最先进的准确性。具体而言，我们制造的模拟CAM阵列在威斯康星诊断乳腺癌（WDBC）数据库上达到了$96\\%$的准确率，同时保持了决策可解释性。我们经过实验校准的模型在$10\\%$设备阈值变异下，在MNIST数据集上仅显示出$0.6\\%$的准确率下降，而传统决策树则下降了$45.3\\%$。这项工作为开发专用硬件铺平了道路，该硬件能够增强人工智能的可信赖性和效率。", "summary": "本论文提出了一种创新的硬件-软件协同设计方案，利用基于$MoS_2$闪存的模拟内容寻址存储器（CAM）及其固有的软边界，旨在解决传统树基模型在可扩展性和硬件实现中面临的鲁棒性问题。通过在$MoS_2$模拟CAM阵列上进行软树模型推理实验，研究展示了该方法在对抗设备变异和对抗性攻击方面的卓越鲁棒性，同时保持了高准确性和决策可解释性。具体而言，在WDBC数据集上实现了$96\\%$的准确率，并在MNIST数据集上，相比传统决策树在设备变异下的显著性能下降，该方法仅有微小下降。这项工作为构建更可信赖和高效的AI专用硬件奠定了基础。", "keywords": "树基模型, 模拟CAM, $MoS_2$闪存, 软边界, 鲁棒性", "comments": "这项研究的创新点在于将$MoS_2$闪存模拟CAM与固有软边界相结合，解决了传统模拟CAM加速树基模型时面临的设备变异敏感性和对抗性攻击脆弱性问题。其重要性在于通过硬件-软件协同设计，显著提升了树基模型在实际部署中的可信赖性和效率，为未来AI专用硬件的发展提供了新的方向。该方法在保持高准确率的同时，显著增强了模型对硬件噪声和恶意攻击的鲁棒性，具有重要的实际应用价值。"}}
{"id": "2507.11894", "title": "Context-Aware Search and Retrieval Over Erasure Channels", "authors": ["Sara Ghasvarianjahromi", "Yauhen Yakimenka", "Jörg Kliewer"], "categories": ["cs.IR", "cs.IT", "math.IT"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11894v1", "summary": "This paper introduces and analyzes a search and retrieval model that adopts\nkey semantic communication principles from retrieval-augmented generation. We\nspecifically present an information-theoretic analysis of a remote document\nretrieval system operating over a symbol erasure channel. The proposed model\nencodes the feature vector of a query, derived from term-frequency weights of a\nlanguage corpus by using a repetition code with an adaptive rate dependent on\nthe contextual importance of the terms. At the decoder, we select between two\ndocuments based on the contextual closeness of the recovered query. By\nleveraging a jointly Gaussian approximation for both the true and reconstructed\nsimilarity scores, we derive an explicit expression for the retrieval error\nprobability, i.e., the probability under which the less similar document is\nselected. Numerical simulations on synthetic and real-world data (Google NQ)\nconfirm the validity of the analysis. They further demonstrate that assigning\ngreater redundancy to critical features effectively reduces the error rate,\nhighlighting the effectiveness of semantic-aware feature encoding in\nerror-prone communication settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11894v1", "cate": "cs.IR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "上下文感知擦除信道上的搜索与检索", "tldr": "本文提出了一个基于语义通信原则的搜索与检索模型，分析了其在擦除信道下的性能，并通过实验证明了对关键特征分配冗余能有效降低错误率。", "motivation": "论文引入并分析了一个搜索与检索模型，该模型采用了检索增强生成中的关键语义通信原则，旨在解决在符号擦除信道上运行的远程文档检索系统中的问题。", "method": "本研究提出了一个搜索与检索模型，该模型采纳了检索增强生成中的语义通信原则。具体方法包括：使用重复码对查询的特征向量（来源于语言语料库的词频权重）进行编码，编码率根据词语的上下文重要性自适应调整。在解码器端，根据恢复的查询的上下文接近度，在两个文档中进行选择。通过利用真值和重建相似度分数的联合高斯近似，推导了检索错误概率的显式表达式。", "result": "数值模拟在合成数据和真实世界数据（Google NQ）上进行，证实了分析的有效性。实验进一步表明，将更大的冗余分配给关键特征能有效降低错误率，突出了在易出错的通信环境中语义感知特征编码的有效性。", "conclusion": "论文通过理论分析和数值模拟证明了所提出的上下文感知搜索与检索模型在擦除信道下的有效性，特别是通过对关键特征分配冗余可以显著降低检索错误率，突出了语义感知特征编码的重要性。", "translation": "本文介绍并分析了一个搜索与检索模型，该模型采纳了检索增强生成中的关键语义通信原则。我们特别对在符号擦除信道上运行的远程文档检索系统进行了信息论分析。所提出的模型使用重复码对查询的特征向量进行编码，该特征向量来源于语言语料库的词频权重，并且重复码的速率会根据词语的上下文重要性进行自适应调整。在解码器端，我们根据恢复查询的上下文接近度在两个文档之间进行选择。通过利用真实和重建相似度分数的联合高斯近似，我们推导出了检索错误概率的显式表达式，即选择相似度较低文档的概率。在合成数据和真实世界数据（Google NQ）上的数值模拟证实了分析的有效性。它们进一步表明，将更大的冗余分配给关键特征可以有效降低错误率，突出了在易出错的通信设置中语义感知特征编码的有效性。", "summary": "本论文提出了一个在擦除信道下运行的上下文感知搜索与检索模型。该模型结合了检索增强生成的语义通信原理，通过自适应重复编码查询的特征向量（基于词语的上下文重要性），并在解码时根据恢复查询的上下文接近度进行文档选择。通过信息论分析，特别是利用高斯近似推导了检索错误概率。实验结果在合成和真实数据集上验证了理论分析，并表明对关键特征分配更多冗余能显著降低错误率，凸显了语义感知特征编码在易错通信环境中的重要性。", "keywords": "上下文感知, 搜索与检索, 擦除信道, 语义通信, 错误概率", "comments": "这篇论文的创新点在于将语义通信原则应用于擦除信道下的搜索与检索问题，并提出了一个上下文感知的编码策略。其重要性体现在为在不可靠通信环境中进行高效准确的信息检索提供了理论基础和实用方法。通过理论分析和实验验证，明确了对关键语义特征进行冗余编码的有效性，这对于未来构建鲁棒的分布式信息检索系统具有指导意义。"}}
{"id": "2507.12017", "title": "SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection", "authors": ["Xiwei Zhang", "Chunjin Yang", "Yiming Xiao", "Runtong Zhang", "Fanman Meng"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 main-pages, 3 reference-pages, 5 figures, 6 tables", "url": "http://arxiv.org/abs/2507.12017v1", "summary": "Unsupervised domain adaptive object detection (UDAOD) from the visible domain\nto the infrared (RGB-IR) domain is challenging. Existing methods regard the RGB\ndomain as a unified domain and neglect the multiple subdomains within it, such\nas daytime, nighttime, and foggy scenes. We argue that decoupling the\ndomain-invariant (DI) and domain-specific (DS) features across these multiple\nsubdomains is beneficial for RGB-IR domain adaptation. To this end, this paper\nproposes a new SS-DC framework based on a decoupling-coupling strategy. In\nterms of decoupling, we design a Spectral Adaptive Idempotent Decoupling (SAID)\nmodule in the aspect of spectral decomposition. Due to the style and content\ninformation being highly embedded in different frequency bands, this module can\ndecouple DI and DS components more accurately and interpretably. A novel filter\nbank-based spectral processing paradigm and a self-distillation-driven\ndecoupling loss are proposed to improve the spectral domain decoupling. In\nterms of coupling, a new spatial-spectral coupling method is proposed, which\nrealizes joint coupling through spatial and spectral DI feature pyramids.\nMeanwhile, this paper introduces DS from decoupling to reduce the domain bias.\nExtensive experiments demonstrate that our method can significantly improve the\nbaseline performance and outperform existing UDAOD methods on multiple RGB-IR\ndatasets, including a new experimental protocol proposed in this paper based on\nthe FLIR-ADAS dataset.", "comment": "8 main-pages, 3 reference-pages, 5 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.12017v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "SS-DC: 跨可见光-红外间隙的空间-光谱解耦与耦合，用于域自适应目标检测", "tldr": "针对可见光到红外域自适应目标检测的挑战，本文提出SS-DC框架，通过空间-光谱解耦与耦合，有效处理多子域问题，显著提升了检测性能。", "motivation": "现有可见光到红外域自适应目标检测（UDAOD）方法将RGB域视为统一域，忽略了其中的多重子域（如白天、夜晚、雾天），导致域适应困难。论文认为解耦域不变（DI）和域特定（DS）特征对RGB-IR域适应有益。", "method": "提出SS-DC框架，基于解耦-耦合策略。解耦方面，设计光谱自适应幂等解耦（SAID）模块，通过光谱分解更准确地解耦DI和DS特征，并引入基于滤波器组的光谱处理范式和自蒸馏驱动的解耦损失。耦合方面，提出新的空间-光谱耦合方法，通过空间和光谱DI特征金字塔实现联合耦合，并引入DS特征以减少域偏差。", "result": "该方法显著提升了基线性能，并在多个RGB-IR数据集上优于现有UDAOD方法，包括基于FLIR-ADAS数据集提出的新实验协议。", "conclusion": "通过空间-光谱解耦与耦合策略，SS-DC框架有效解决了可见光到红外域自适应目标检测中多子域的挑战，显著提升了检测性能，证明了其在跨域自适应任务中的有效性和优越性。", "translation": "从可见光域到红外（RGB-IR）域的无监督域自适应目标检测（UDAOD）具有挑战性。现有方法将RGB域视为一个统一域，忽略了其中的多个子域，如白天、夜晚和雾天场景。我们认为，跨这些多个子域解耦域不变（DI）和域特定（DS）特征有利于RGB-IR域适应。为此，本文提出了一种基于解耦-耦合策略的新型SS-DC框架。在解耦方面，我们从光谱分解的角度设计了一个光谱自适应幂等解耦（SAID）模块。由于风格和内容信息高度嵌入在不同的频带中，该模块可以更准确、可解释地解耦DI和DS分量。提出了一个新的基于滤波器组的光谱处理范式和自蒸馏驱动的解耦损失，以改善光谱域解耦。在耦合方面，提出了一种新的空间-光谱耦合方法，通过空间和光谱DI特征金字塔实现联合耦合。同时，本文从解耦中引入DS以减少域偏差。大量实验表明，我们的方法可以显著提高基线性能，并在多个RGB-IR数据集上优于现有UDAOD方法，包括本文基于FLIR-ADAS数据集提出的新实验协议。", "summary": "本文针对从可见光到红外域的无监督域自适应目标检测中，现有方法忽略RGB域内部多子域（如白天、夜晚、雾天）的问题，提出SS-DC框架。该框架通过空间-光谱解耦（利用SAID模块和新颖的光谱处理范式、自蒸馏损失）和空间-光谱耦合（通过DI特征金字塔联合耦合，并引入DS特征减少域偏差）策略，有效解耦域不变和域特定特征。实验证明，SS-DC显著提升了基线性能，并超越了现有UDAOD方法。", "keywords": "域自适应目标检测, 空间-光谱解耦, 可见光-红外, 多子域, 特征解耦", "comments": "该论文的创新点在于提出了空间-光谱解耦与耦合（SS-DC）框架，特别关注了RGB域内的多子域问题，并通过SAID模块实现更精确和可解释的特征解耦。这种对域内子域的细致处理以及对空间和光谱特征的联合考量，为跨域自适应目标检测提供了新的视角和有效方法。其提出的滤波器组处理范式和自蒸馏解耦损失也增强了方法的鲁棒性。"}}
{"id": "2507.12379", "title": "Probing for Arithmetic Errors in Language Models", "authors": ["Yucheng Sun", "Alessandro Stolfo", "Mrinmaya Sachan"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12379v1", "summary": "We investigate whether internal activations in language models can be used to\ndetect arithmetic errors. Starting with a controlled setting of 3-digit\naddition, we show that simple probes can accurately decode both the model's\npredicted output and the correct answer from hidden states, regardless of\nwhether the model's output is correct. Building on this, we train lightweight\nerror detectors that predict model correctness with over 90% accuracy. We then\nextend our analysis to structured chain-of-thought traces on addition-only\nGSM8K problems and find that probes trained on simple arithmetic generalize\nwell to this more complex setting, revealing consistent internal\nrepresentations. Finally, we demonstrate that these probes can guide selective\nre-prompting of erroneous reasoning steps, improving task accuracy with minimal\ndisruption to correct outputs. Our findings suggest that arithmetic errors can\nbe anticipated from internal activations alone, and that simple probes offer a\nviable path toward lightweight model self-correction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12379v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "探测语言模型中的算术错误", "tldr": "研究表明，可以通过语言模型内部激活来检测算术错误，并使用简单探针实现轻量级模型自校正。", "motivation": "研究语言模型内部激活是否可用于检测算术错误。", "method": "首先在三位数加法受控设置中，使用简单探针从隐藏状态解码模型预测输出和正确答案。在此基础上，训练轻量级错误检测器预测模型正确性。然后将分析扩展到仅加法的GSM8K问题上的结构化思维链追踪。最后，演示这些探针可以指导对错误推理步骤的选择性重新提示。", "result": "简单探针可以准确解码模型预测输出和隐藏状态中的正确答案，无论模型输出是否正确。训练的轻量级错误检测器预测模型正确性准确率超过90%。在简单算术上训练的探针能够很好地推广到更复杂的设置，揭示一致的内部表示。这些探针可以指导对错误推理步骤的选择性重新提示，提高任务准确性，同时对正确输出的干扰最小。", "conclusion": "算术错误可以仅从内部激活中预测出来，并且简单的探针为轻量级模型自校正提供了可行的途径。", "translation": "我们研究语言模型中的内部激活是否可用于检测算术错误。从三位数加法的受控设置开始，我们展示了简单的探针可以从隐藏状态中准确解码模型的预测输出和正确答案，无论模型的输出是否正确。在此基础上，我们训练了轻量级错误检测器，其预测模型正确性的准确率超过90%。然后，我们将分析扩展到仅加法的GSM8K问题上的结构化思维链追踪，发现对简单算术训练的探针能够很好地推广到这种更复杂的设置，揭示了一致的内部表示。最后，我们证明这些探针可以指导对错误推理步骤的选择性重新提示，在最小化对正确输出的干扰下提高任务准确性。我们的发现表明，算术错误可以仅从内部激活中预测，并且简单的探针为轻量级模型自校正提供了可行的途径。", "summary": "该研究探讨了利用语言模型内部激活来检测算术错误的可行性。通过在三位数加法和更复杂的GSM8K问题上使用简单探针和轻量级错误检测器，作者证明了可以从隐藏状态中准确解码预测和正确答案，并以超过90%的准确率预测模型正确性。这些探针具有良好的泛化能力，并能有效指导错误的推理步骤重新提示，从而提高任务准确性。研究结果表明，内部激活可用于预测算术错误，并为模型自校正提供了一条轻量级途径。", "keywords": "语言模型, 算术错误, 内部激活, 探针, 自校正", "comments": "这项研究的创新之处在于，它提出了一种通过分析语言模型内部激活来检测甚至纠正算术错误的方法，而无需修改模型本身。通过使用“探针”和“错误检测器”，该方法为理解和改进大型语言模型在特定任务（如算术）上的可靠性提供了新的视角。其重要性在于为未来开发更可靠、能自我纠正的AI模型奠定了基础。"}}
{"id": "2507.11878", "title": "LLMs Encode Harmfulness and Refusal Separately", "authors": ["Jiachen Zhao", "Jing Huang", "Zhengxuan Wu", "David Bau", "Weiyan Shi"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11878v1", "summary": "LLMs are trained to refuse harmful instructions, but do they truly understand\nharmfulness beyond just refusing? Prior work has shown that LLMs' refusal\nbehaviors can be mediated by a one-dimensional subspace, i.e., a refusal\ndirection. In this work, we identify a new dimension to analyze safety\nmechanisms in LLMs, i.e., harmfulness, which is encoded internally as a\nseparate concept from refusal. There exists a harmfulness direction that is\ndistinct from the refusal direction. As causal evidence, steering along the\nharmfulness direction can lead LLMs to interpret harmless instructions as\nharmful, but steering along the refusal direction tends to elicit refusal\nresponses directly without reversing the model's judgment on harmfulness.\nFurthermore, using our identified harmfulness concept, we find that certain\njailbreak methods work by reducing the refusal signals without reversing the\nmodel's internal belief of harmfulness. We also find that adversarially\nfinetuning models to accept harmful instructions has minimal impact on the\nmodel's internal belief of harmfulness. These insights lead to a practical\nsafety application: The model's latent harmfulness representation can serve as\nan intrinsic safeguard (Latent Guard) for detecting unsafe inputs and reducing\nover-refusals that is robust to finetuning attacks. For instance, our Latent\nGuard achieves performance comparable to or better than Llama Guard 3 8B, a\ndedicated finetuned safeguard model, across different jailbreak methods. Our\nfindings suggest that LLMs' internal understanding of harmfulness is more\nrobust than their refusal decision to diverse input instructions, offering a\nnew perspective to study AI safety", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11878v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "大型语言模型（LLMs）独立编码有害性和拒绝性", "tldr": "本研究发现大型语言模型内部对有害性的理解与拒绝行为是独立编码的，有害性判断比拒绝决策更鲁棒，并提出一种基于潜在有害性表示的内在安全防护机制。", "motivation": "大型语言模型（LLMs）被训练以拒绝有害指令，但目前尚不清楚它们是否真正理解有害性，而不仅仅是执行拒绝行为。先前的研究表明LLMs的拒绝行为可以通过一个一维子空间（即拒绝方向）来调节，但缺乏对有害性本身内部编码的深入分析。", "method": "本研究识别出一个新的维度——有害性，并证明其作为独立于拒绝的内部概念被编码。通过因果证据，研究人员发现沿着有害性方向引导可以使LLMs将无害指令解释为有害，而沿着拒绝方向引导则直接引发拒绝响应，但不会改变模型对有害性的判断。此外，研究使用识别出的有害性概念来分析越狱方法，发现它们通过降低拒绝信号而非逆转模型内部对有害性的信念来起作用。研究还发现对抗性微调模型以接受有害指令对模型内部有害性信念的影响极小。", "result": "研究发现LLMs内部将有害性编码为一个独立于拒绝的概念，存在一个与拒绝方向不同的有害性方向。越狱方法通过减少拒绝信号来发挥作用，而非改变模型内部的有害性判断。对抗性微调对模型内部的有害性信念影响甚微。模型潜在的有害性表示可以作为一种内在的安全防护（Latent Guard），用于检测不安全输入并减少过度拒绝，且对微调攻击具有鲁棒性。例如，Latent Guard在不同越狱方法下的性能与Llama Guard 3 8B（一个专门的微调安全模型）相当或更优。", "conclusion": "LLMs内部对有害性的理解比其拒绝决策对各种输入指令更具鲁棒性，这为研究AI安全提供了新的视角。模型潜在的有害性表示可以作为一种有效的内在安全机制。", "translation": "大型语言模型（LLMs）被训练以拒绝有害指令，但它们是否真正理解有害性，而不仅仅是拒绝？先前的研究表明LLMs的拒绝行为可以通过一个一维子空间，即一个拒绝方向来调节。在这项工作中，我们识别出一个新的维度来分析LLMs中的安全机制，即有害性，它在内部被编码为一个独立于拒绝的概念。存在一个与拒绝方向不同的有害性方向。作为因果证据，沿着有害性方向引导可以导致LLMs将无害指令解释为有害，而沿着拒绝方向引导则倾向于直接引发拒绝响应，而不会逆转模型对有害性的判断。此外，使用我们识别出的有害性概念，我们发现某些越狱方法通过降低拒绝信号而不起作用，而不会逆转模型内部对有害性的信念。我们还发现，对抗性微调模型以接受有害指令对模型内部有害性信念的影响极小。这些见解导致了一个实际的安全应用：模型的潜在有害性表示可以作为一种内在的保障（Latent Guard），用于检测不安全输入并减少过度拒绝，并且对微调攻击具有鲁棒性。例如，我们的Latent Guard在不同越狱方法下的性能与Llama Guard 3 8B（一个专门的微调安全模型）相当或更优。我们的发现表明LLMs内部对有害性的理解比其拒绝决策对各种输入指令更具鲁棒性，为研究AI安全提供了新的视角。", "summary": "本研究揭示了大型语言模型（LLMs）内部对“有害性”的理解与“拒绝”行为是独立编码的两个概念。通过识别出独特的“有害性方向”，研究发现越狱和对抗性微调主要影响LLMs的拒绝机制，而非其内在的有害性判断。基于此，论文提出并验证了一种名为“Latent Guard”的内在安全机制，该机制利用模型潜在的有害性表示来有效检测不安全输入并减少过度拒绝，其性能优于或媲美现有专用安全模型，并对微调攻击具有鲁棒性。这为AI安全研究提供了新的视角，强调了LLMs内部有害性理解的鲁棒性。", "keywords": "LLMs, 有害性, 拒绝, AI安全, 潜在表示, 越狱", "comments": "这项研究的创新之处在于首次明确区分并量化了LLMs内部“有害性”和“拒绝”这两个独立的安全概念，并通过“有害性方向”的发现提供了因果证据。其重要性体现在：1) 改变了对LLMs安全机制的理解，揭示了模型深层有害性判断的鲁棒性；2) 提供了新的安全分析工具，能更细致地研究越狱和安全微调的影响；3) 提出了一种实用的“Latent Guard”内在安全方案，其鲁棒性和性能优势为构建更安全的LLMs提供了新途径。这项工作为AI安全领域带来了重要的理论和实践贡献。"}}
{"id": "2507.11671", "title": "Decision Models for Selecting Architecture Patterns and Strategies in Quantum Software Systems", "authors": ["Mst Shamima Aktar", "Peng Liang", "Muhammad Waseem", "Amjed Tahir", "Mojtaba Shahin", "Muhammad Azeem Akbar", "Arif Ali Khan", "Aakash Ahmad", "Musengamana Jean de Dieu", "Ruiyin Li"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      49 pages, 10 images, 16 tables, Manuscript submitted to a journal (2025)", "url": "http://arxiv.org/abs/2507.11671v1", "summary": "Quantum software represents disruptive technologies in terms of\nquantum-specific software systems, services, and applications - leverage the\nprinciples of quantum mechanics via programmable quantum bits (Qubits) that\nmanipulate quantum gates (QuGates) - to achieve quantum supremacy in computing.\nQuantum software architecture enables quantum software developers to abstract\naway implementation-specific details (i.e., mapping of Qubits and QuGates to\nhigh-level architectural components and connectors). Architectural patterns and\nstrategies can provide reusable knowledge and best practices to engineer\nquantum software systems effectively and efficiently. However, quantum software\npractitioners face significant challenges in selecting and implementing\nappropriate patterns and strategies due to the complexity of quantum software\nsystems and the lack of guidelines. To address these challenges, this study\nproposes decision models for selecting patterns and strategies in six critical\ndesign areas in quantum software systems: Communication, Decomposition, Data\nProcessing, Fault Tolerance, Integration and Optimization, and Algorithm\nImplementation. These decision models are constructed based on data collected\nfrom both a mining study (i.e., GitHub and Stack Exchange) and a Systematic\nLiterature Review, which were used to identify relevant patterns and strategies\nwith their involved Quality Attributes (QAs). We then conducted semi-structured\ninterviews with 16 quantum software practitioners to evaluate the familiarity,\nunderstandability, completeness, and usefulness of the proposed decision\nmodels. The results show that the proposed decision models can aid\npractitioners in selecting suitable patterns and strategies to address the\nchallenges related to the architecture design of quantum software systems. The\ndataset is available at [6], allowing the community to reproduce and build upon\nour findings.", "comment": "49 pages, 10 images, 16 tables, Manuscript submitted to a journal\n  (2025)", "pdf_url": "http://arxiv.org/pdf/2507.11671v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "量子软件系统架构模式和策略选择的决策模型", "tldr": "本研究提出了针对量子软件系统六个关键设计领域的决策模型，以帮助开发者选择合适的架构模式和策略，克服现有挑战。这些模型基于文献综述、代码库挖掘和专家访谈构建并验证。", "motivation": "量子软件从业者在选择和实施合适的架构模式和策略时面临巨大挑战，原因在于量子软件系统的复杂性以及缺乏相关指导方针。", "method": "本研究提出了针对量子软件系统六个关键设计领域（通信、分解、数据处理、容错、集成与优化、算法实现）的决策模型。这些模型是根据从挖掘研究（即GitHub和Stack Exchange）和系统文献综述中收集的数据构建的，这些数据用于识别相关的模式、策略及其所涉及的质量属性。随后，通过对16位量子软件从业者进行半结构化访谈，评估了所提出决策模型的熟悉度、可理解性、完整性和实用性。", "result": "结果表明，所提出的决策模型能够帮助从业者选择合适的模式和策略，以解决量子软件系统架构设计相关的挑战。", "conclusion": "所提出的决策模型能够有效帮助量子软件从业者克服在复杂量子软件系统架构设计中选择合适模式和策略的挑战。", "translation": "量子软件代表着颠覆性技术，体现在量子特定的软件系统、服务和应用程序——通过可编程量子比特（Qubits）操纵量子门（QuGates），利用量子力学原理——以实现计算领域的量子霸权。量子软件架构使量子软件开发人员能够抽象出特定于实现的细节（即，将量子比特和量子门映射到高级架构组件和连接器）。架构模式和策略可以提供可重用的知识和最佳实践，以有效和高效地设计量子软件系统。然而，由于量子软件系统的复杂性和指导方针的缺乏，量子软件从业者在选择和实施适当的模式和策略时面临重大挑战。为了应对这些挑战，本研究提出了在量子软件系统六个关键设计领域（通信、分解、数据处理、容错、集成与优化、算法实现）中选择模式和策略的决策模型。这些决策模型是根据从挖掘研究（即GitHub和Stack Exchange）和系统文献综述中收集的数据构建的，这些数据用于识别相关的模式和策略及其所涉及的质量属性（QAs）。然后，我们对16位量子软件从业者进行了半结构化访谈，评估了所提出的决策模型的熟悉度、可理解性、完整性和实用性。结果表明，所提出的决策模型可以帮助从业者选择合适的模式和策略，以解决与量子软件系统架构设计相关的挑战。数据集可在[6]中获取，以便社区重现和在此发现的基础上进行构建。", "summary": "本研究旨在解决量子软件从业者在选择和实施架构模式与策略方面的挑战。为此，论文提出了针对量子软件系统六个核心设计领域的决策模型，这些模型基于对GitHub、Stack Exchange数据挖掘和系统文献综述的结果构建。研究通过对16位量子软件从业者的访谈验证了模型的有效性，结果表明这些模型能有效指导从业者进行架构设计。", "keywords": "量子软件系统, 架构模式, 决策模型, 软件工程, 量子计算", "comments": "这篇论文通过提出一套实用的决策模型，填补了量子软件架构设计领域缺乏指导方针的空白，具有重要的实践意义。其结合了数据挖掘和专家访谈的混合研究方法增强了研究结果的可靠性。数据集的公开也有助于后续研究的开展。"}}
{"id": "2507.12308", "title": "Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization", "authors": ["Prashanth Vijayaraghavan", "Apoorva Nitsure", "Charles Mackin", "Luyao Shi", "Stefano Ambrogio", "Arvind Haran", "Viresh Paruthi", "Ali Elzein", "Dan Coops", "David Beymer", "Tyler Baldwin", "Ehsan Degan"], "categories": ["cs.CL", "cs.AI", "cs.AR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages (6 content pages + 4 supplementary), 5 figures, Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD. 2024 (MLCAD'24)", "url": "http://arxiv.org/abs/2507.12308v1", "summary": "Large Language Models (LLMs) have become widely used across diverse NLP tasks\nand domains, demonstrating their adaptability and effectiveness. In the realm\nof Electronic Design Automation (EDA), LLMs show promise for tasks like\nRegister-Transfer Level (RTL) code generation and summarization. However,\ndespite the proliferation of LLMs for general code-related tasks, there's a\ndearth of research focused on evaluating and refining these models for hardware\ndescription languages (HDLs), notably VHDL. In this study, we evaluate the\nperformance of existing code LLMs for VHDL code generation and summarization\nusing various metrics and two datasets -- VHDL-Eval and VHDL-Xform. The latter,\nan in-house dataset, aims to gauge LLMs' understanding of functionally\nequivalent code. Our findings reveal consistent underperformance of these\nmodels across different metrics, underscoring a significant gap in their\nsuitability for this domain. To address this challenge, we propose\nChain-of-Descriptions (CoDes), a novel approach to enhance the performance of\nLLMs for VHDL code generation and summarization tasks. CoDes involves\ngenerating a series of intermediate descriptive steps based on: (i) the problem\nstatement for code generation, and (ii) the VHDL code for summarization. These\nsteps are then integrated with the original input prompt (problem statement or\ncode) and provided as input to the LLMs to generate the final output. Our\nexperiments demonstrate that the CoDes approach significantly surpasses the\nstandard prompting strategy across various metrics on both datasets. This\nmethod not only improves the quality of VHDL code generation and summarization\nbut also serves as a framework for future research aimed at enhancing code LLMs\nfor VHDL.", "comment": "10 pages (6 content pages + 4 supplementary), 5 figures, Proceedings\n  of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD.\n  2024 (MLCAD'24)", "pdf_url": "http://arxiv.org/pdf/2507.12308v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "描述链：改进用于VHDL代码生成和摘要的代码大型语言模型", "tldr": "本研究评估了现有代码大型语言模型在VHDL代码生成和摘要方面的表现，发现其性能不佳。为解决此问题，提出了“描述链”（CoDes）方法，通过生成一系列中间描述步骤来显著提高LLM在VHDL任务上的性能。", "motivation": "尽管大型语言模型（LLMs）在通用代码任务中广泛应用，但在硬件描述语言（HDLs），尤其是VHDL的代码生成和摘要方面，缺乏对其评估和改进的研究。现有模型在此领域的表现不佳，存在显著差距，因此需要一种新方法来提升其性能。", "method": "本研究首先使用VHDL-Eval和VHDL-Xform（一个内部数据集，用于衡量LLM对功能等效代码的理解）两个数据集，通过各种指标评估了现有代码LLM在VHDL代码生成和摘要方面的性能。为解决性能不足问题，提出了“描述链”（CoDes）方法。CoDes通过生成一系列中间描述步骤来增强LLM的性能：对于代码生成，基于问题陈述生成描述；对于代码摘要，基于VHDL代码生成描述。这些步骤随后与原始输入（问题陈述或代码）结合，作为LLM的输入以生成最终输出。", "result": "研究发现，现有代码LLM在VHDL代码生成和摘要方面，在不同指标上表现持续不佳，凸显了其在该领域适用性上的显著差距。然而，所提出的CoDes方法在两个数据集上，通过各种指标，显著超越了标准的提示策略，有效提升了VHDL代码生成和摘要的质量。", "conclusion": "现有代码大型语言模型在VHDL代码生成和摘要任务上表现不佳。提出的“描述链”（CoDes）方法通过生成中间描述步骤，显著提升了LLM在这些VHDL任务上的性能，并为未来增强VHDL代码LLM的研究提供了框架。", "translation": "大型语言模型（LLMs）已广泛应用于各种NLP任务和领域，展示了其适应性和有效性。在电子设计自动化（EDA）领域，LLMs在寄存器传输级（RTL）代码生成和摘要等任务中展现出潜力。然而，尽管LLMs在通用代码相关任务中大量涌现，但针对评估和改进这些模型以处理硬件描述语言（HDLs），特别是VHDL的研究却非常匮乏。在本研究中，我们使用各种指标和两个数据集——VHDL-Eval和VHDL-Xform（后者是一个内部数据集，旨在衡量LLM对功能等效代码的理解）——评估了现有代码LLM在VHDL代码生成和摘要方面的性能。我们的发现揭示了这些模型在不同指标上持续表现不佳，突显了它们在该领域适用性上的显著差距。为解决这一挑战，我们提出了“描述链”（CoDes），一种新颖的方法，旨在提高LLM在VHDL代码生成和摘要任务中的性能。CoDes涉及生成一系列中间描述步骤，这些步骤基于：(i) 代码生成的问题陈述，和 (ii) 代码摘要的VHDL代码。然后将这些步骤与原始输入提示（问题陈述或代码）集成，并作为输入提供给LLM以生成最终输出。我们的实验表明，CoDes方法在两个数据集的各种指标上显著超越了标准提示策略。这种方法不仅提高了VHDL代码生成和摘要的质量，而且还为未来旨在增强VHDL代码LLM的研究提供了框架。", "summary": "本研究评估了现有代码大型语言模型在VHDL代码生成和摘要任务上的表现，发现其存在显著的性能不足。为解决此问题，论文提出了一种名为“描述链”（Chain-of-Descriptions, CoDes）的新颖方法。CoDes通过生成一系列中间描述步骤，并将其与原始输入结合后提供给LLM，从而显著提升了模型在VHDL代码生成和摘要任务上的性能。实验结果表明，CoDes方法在多个指标上均优于标准提示策略，为未来VHDL领域LLM的研究提供了有效框架。", "keywords": "VHDL, 大型语言模型, 代码生成, 代码摘要, 描述链", "comments": "该论文解决了LLM在硬件描述语言VHDL处理方面的一个重要空白，具有创新性。CoDes方法通过引入中间描述步骤，有效提升了模型性能，其思想可推广到其他代码生成和摘要任务。VHDL-Xform数据集的创建也为后续研究提供了有价值的资源。该研究对于将LLM应用于专业和特定领域具有指导意义，尤其是在需要深入理解领域知识的场景。"}}
{"id": "2507.12053", "title": "FloGAN: Scenario-Based Urban Mobility Flow Generation via Conditional GANs and Dynamic Region Decoupling", "authors": ["Seanglidet Yean", "Jiazu Zhou", "Bu-Sung Lee", "Markus Schläpfer"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      International Conference on Intelligent Digitization of Systems and Services, Valencia, Spain, 2025 (IDSS 2025)", "url": "http://arxiv.org/abs/2507.12053v1", "summary": "The mobility patterns of people in cities evolve alongside changes in land\nuse and population. This makes it crucial for urban planners to simulate and\nanalyze human mobility patterns for purposes such as transportation\noptimization and sustainable urban development. Existing generative models\nborrowed from machine learning rely heavily on historical trajectories and\noften overlook evolving factors like changes in population density and land\nuse. Mechanistic approaches incorporate population density and facility\ndistribution but assume static scenarios, limiting their utility for future\nprojections where historical data for calibration is unavailable. This study\nintroduces a novel, data-driven approach for generating origin-destination\nmobility flows tailored to simulated urban scenarios. Our method leverages\nadaptive factors such as dynamic region sizes and land use archetypes, and it\nutilizes conditional generative adversarial networks (cGANs) to blend\nhistorical data with these adaptive parameters. The approach facilitates rapid\nmobility flow generation with adjustable spatial granularity based on regions\nof interest, without requiring extensive calibration data or complex behavior\nmodeling. The promising performance of our approach is demonstrated by its\napplication to mobile phone data from Singapore, and by its comparison with\nexisting methods.", "comment": "International Conference on Intelligent Digitization of Systems and\n  Services, Valencia, Spain, 2025 (IDSS 2025)", "pdf_url": "http://arxiv.org/pdf/2507.12053v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "FloGAN：基于场景的城市出行流生成，结合条件GAN和动态区域解耦", "tldr": "FloGAN是一种基于cGANs的模型，用于为模拟城市场景生成出行流。它通过结合动态区域大小和土地利用等自适应因素来解决现有方法的局限性，并减少对大量历史校准数据的依赖。", "motivation": "城市中人们的出行模式随土地利用和人口变化而演变，城市规划者需要模拟和分析这些模式以优化交通和促进可持续发展。现有生成模型过度依赖历史轨迹，忽略了演变因素。机械方法假设静态场景，限制了其在缺乏历史校准数据时对未来预测的效用。因此，需要一种能够为模拟城市场景生成出行流且无需大量校准数据的新型数据驱动方法。", "method": "本研究引入了一种新颖的数据驱动方法，名为FloGAN，用于生成针对模拟城市场景的起点-终点出行流。该方法利用动态区域大小和土地利用原型等自适应因素，并使用条件生成对抗网络（cGANs）将历史数据与这些自适应参数融合。它能够在无需大量校准数据或复杂行为建模的情况下，根据感兴趣区域，以可调节的空间粒度快速生成出行流。", "result": "该方法在应用于新加坡的手机数据时，以及与现有方法进行比较时，都表现出了良好的性能。", "conclusion": "FloGAN有效地为模拟城市场景生成了城市出行流，通过整合自适应因素和cGANs，解决了现有方法的局限性，并在真实世界数据上展示了良好的性能。", "translation": "城市中人们的出行模式随着土地利用和人口的变化而演变。这使得城市规划者模拟和分析人类出行模式对于交通优化和可持续城市发展至关重要。现有机器学习借用的生成模型严重依赖历史轨迹，并且常常忽略人口密度和土地利用变化等演变因素。机械方法虽然考虑了人口密度和设施分布，但假设场景是静态的，这限制了它们在未来预测中的效用，因为未来预测可能没有历史数据进行校准。本研究引入了一种新颖的数据驱动方法，用于生成针对模拟城市场景的起点-终点出行流。我们的方法利用动态区域大小和土地利用原型等自适应因素，并利用条件生成对抗网络（cGANs）将历史数据与这些自适应参数融合。该方法能够根据感兴趣区域，以可调节的空间粒度快速生成出行流，而无需大量的校准数据或复杂的行为建模。该方法在新加坡手机数据上的应用以及与现有方法的比较证明了其良好的性能。", "summary": "本文提出了FloGAN，一种利用条件生成对抗网络（cGANs）和动态区域解耦的新型数据驱动方法，旨在为模拟城市场景生成起点-终点出行流。它通过整合动态区域大小和土地利用原型等自适应因素并将其与历史数据融合，解决了现有方法的局限性。FloGAN能够在无需大量校准数据的情况下，实现快速、空间粒度可调的出行流生成，并在新加坡手机数据上展示了良好的性能。", "keywords": "城市出行, 流生成, 条件GAN, 场景分析, 动态区域解耦", "comments": "该研究的创新之处在于将数据驱动的条件生成对抗网络（cGANs）与自适应的、基于场景的因素（如动态区域大小和土地利用原型）相结合，以解决现有出行模型在处理演变因素和未来预测方面的局限性。这种方法使得在不完全依赖历史数据或大量校准的情况下，也能为未来或假设的城市场景生成出行流，这对于城市规划具有重要意义。"}}
{"id": "2507.12412", "title": "NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data", "authors": ["Dzung Dinh", "Boqi Chen", "Marc Niethammer", "Junier Oliva"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12412v1", "summary": "In many critical applications, resource constraints limit the amount of\ninformation that can be gathered to make predictions. For example, in\nhealthcare, patient data often spans diverse features ranging from lab tests to\nimaging studies. Each feature may carry different information and must be\nacquired at a respective cost of time, money, or risk to the patient. Moreover,\ntemporal prediction tasks, where both instance features and labels evolve over\ntime, introduce additional complexity in deciding when or what information is\nimportant. In this work, we propose NOCTA, a Non-Greedy Objective Cost-Tradeoff\nAcquisition method that sequentially acquires the most informative features at\ninference time while accounting for both temporal dynamics and acquisition\ncost. We first introduce a cohesive estimation target for our NOCTA setting,\nand then develop two complementary estimators: 1) a non-parametric method based\non nearest neighbors to guide the acquisition (NOCTA-NP), and 2) a parametric\nmethod that directly predicts the utility of potential acquisitions (NOCTA-P).\nExperiments on synthetic and real-world medical datasets demonstrate that both\nNOCTA variants outperform existing baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12412v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "NOCTA：纵向数据的非贪婪目标成本权衡获取方法", "tldr": "该论文提出NOCTA，一种在纵向数据中顺序获取最具信息量特征的方法，同时考虑时间动态和获取成本，并在实验中表现优于现有基线。", "motivation": "在许多关键应用中，资源限制了可用于预测的信息量，尤其是在医疗保健领域，患者数据特征多样且获取成本（时间、金钱、风险）各异。此外，时间预测任务中特征和标签随时间演变，增加了决定何时或何种信息重要的复杂性。", "method": "本文提出了NOCTA（非贪婪目标成本权衡获取）方法，该方法在推理时序贯地获取最具信息量的特征，同时考虑时间动态和获取成本。NOCTA引入了一个内聚的估计目标，并开发了两种互补的估计器：1）基于最近邻的非参数方法（NOCTA-NP）指导获取；2）直接预测潜在获取效用的参数方法（NOCTA-P）。", "result": "在合成和真实世界医疗数据集上的实验表明，两种NOCTA变体都优于现有基线。", "conclusion": "NOCTA是一种有效的、考虑成本的纵向数据特征获取方法，在实验中表现出优越的性能，能够有效解决资源受限下的信息获取挑战。", "translation": "在许多关键应用中，资源限制了可用于做出预测的信息量。例如，在医疗保健领域，患者数据通常涵盖从实验室检查到影像学研究的各种特征。每个特征可能携带不同的信息，并且必须以相应的时间、金钱或患者风险成本获取。此外，时间预测任务（其中实例特征和标签都随时间演变）在决定何时或何种信息重要时引入了额外的复杂性。在这项工作中，我们提出了NOCTA，一种非贪婪目标成本权衡获取方法，它在推理时序贯地获取信息量最大的特征，同时考虑了时间动态和获取成本。我们首先为NOCTA设置引入了一个内聚的估计目标，然后开发了两种互补的估计器：1）一种基于最近邻的非参数方法来指导获取（NOCTA-NP），以及2）一种直接预测潜在获取效用的参数方法（NOCTA-P）。在合成和真实世界医疗数据集上的实验表明，两种NOCTA变体都优于现有基线。", "summary": "本文提出了NOCTA，一种非贪婪目标成本权衡获取方法，旨在解决在资源受限的时间预测任务中，尤其是在医疗领域，如何获取信息量大的特征的挑战。NOCTA在推理时序贯地选择最有价值的特征，同时考虑时间动态和获取成本。它引入了一个内聚的估计目标，并开发了两种估计器：基于最近邻的非参数方法（NOCTA-NP）和直接预测效用的参数方法（NOCTA-P）。在合成和真实世界医疗数据集上的实验结果表明，两种NOCTA变体均优于现有基线。", "keywords": "纵向数据, 特征获取, 成本权衡, 时间动态, 医疗保健", "comments": "该论文解决了一个在资源受限环境下（尤其是在医疗应用中）实际且重要的问题，其中数据获取具有实际成本和时间依赖性。其创新之处在于采用非贪婪方法，并开发了两种互补的估计器，提供了灵活性。其表现出的卓越性能预示着其潜在的影响力。"}}
{"id": "2507.03556", "title": "A Multistakeholder Approach to Value-Driven Co-Design of Recommender System Evaluation Metrics in Digital Archives", "authors": ["Florian Atzenhofer-Baumgartner", "Georg Vogeler", "Dominik Kowald"], "categories": ["cs.IR", "cs.DL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted at RecSys 2025", "url": "http://arxiv.org/abs/2507.03556v2", "summary": "This paper presents the first multistakeholder approach for translating\ndiverse stakeholder values into an evaluation metric setup for Recommender\nSystems (RecSys) in digital archives. While commercial platforms mainly rely on\nengagement metrics, cultural heritage domains require frameworks that balance\ncompeting priorities among archivists, platform owners, researchers, and other\nstakeholders. To address this challenge, we conducted high-profile focus groups\n(5 groups x 5 persons) with upstream, provider, system, consumer, and\ndownstream stakeholders, identifying value priorities across critical\ndimensions: visibility/representation, expertise adaptation, and\ntransparency/trust. Our analysis shows that stakeholder concerns naturally\nalign with four sequential research funnel stages: discovery, interaction,\nintegration, and impact. The resulting evaluation setup addresses\ndomain-specific challenges including collection representation imbalances,\nnon-linear research patterns, and tensions between specialized expertise and\nbroader accessibility. We propose directions for tailored metrics in each stage\nof this research journey, such as research path quality for discovery,\ncontextual appropriateness for interaction, metadata-weighted relevance for\nintegration, and cross-stakeholder value alignment for impact assessment. Our\ncontributions extend beyond digital archives to the broader RecSys community,\noffering transferable evaluation approaches for domains where value emerges\nthrough sustained engagement rather than immediate consumption.", "comment": "Accepted at RecSys 2025", "pdf_url": "http://arxiv.org/pdf/2507.03556v2", "cate": "cs.IR", "date": "2025-07-04", "updated": "2025-07-16", "AI": {"title_translation": "数字档案中推荐系统评估指标的价值驱动多利益相关者协同设计方法", "tldr": "开发了一种新的多利益相关者方法，用于在数字档案中共同设计推荐系统评估指标，以平衡不同利益相关者的价值并解决领域特定挑战。", "motivation": "商业平台主要依赖参与度指标，而文化遗产领域需要平衡档案管理员、平台所有者、研究人员和其他利益相关者之间相互竞争的优先事项的框架，以将多样化的利益相关者价值转化为推荐系统评估指标设置。", "method": "进行了高规格焦点小组讨论（5组x5人），参与者包括上游、提供者、系统、消费者和下游利益相关者，以识别在可见性/代表性、专业知识适应性和透明度/信任等关键维度上的价值优先事项。分析了利益相关者的关注点与发现、互动、整合和影响这四个顺序研究漏斗阶段的对齐情况。", "result": "识别出利益相关者关注点与发现、互动、整合和影响四个研究漏斗阶段自然对齐。由此产生的评估设置解决了领域特定挑战，包括馆藏代表性不平衡、非线性研究模式以及专业知识与更广泛可访问性之间的冲突。为研究旅程的每个阶段提出了定制指标的方向，例如发现阶段的研究路径质量、互动阶段的上下文适当性、整合阶段的元数据加权相关性以及影响评估阶段的跨利益相关者价值对齐。", "conclusion": "该研究的贡献超越了数字档案领域，为更广泛的推荐系统社区提供了可转移的评估方法，适用于价值通过持续参与而非即时消费产生的领域。", "translation": "本文提出了第一个多利益相关者方法，用于将数字档案中推荐系统（RecSys）的多样化利益相关者价值转化为评估指标设置。虽然商业平台主要依赖参与度指标，但文化遗产领域需要能够平衡档案管理员、平台所有者、研究人员和其他利益相关者之间相互竞争的优先事项的框架。为了解决这一挑战，我们与上游、提供者、系统、消费者和下游利益相关者进行了高规格焦点小组讨论（5组x5人），识别了在可见性/代表性、专业知识适应性和透明度/信任等关键维度上的价值优先事项。我们的分析表明，利益相关者的关注点自然地与四个顺序研究漏斗阶段对齐：发现、互动、整合和影响。由此产生的评估设置解决了领域特定挑战，包括馆藏代表性不平衡、非线性研究模式以及专业知识与更广泛可访问性之间的冲突。我们为研究旅程的每个阶段提出了定制指标的方向，例如发现阶段的研究路径质量、互动阶段的上下文适当性、整合阶段的元数据加权相关性以及影响评估阶段的跨利益相关者价值对齐。我们的贡献超越了数字档案领域，为更广泛的推荐系统社区提供了可转移的评估方法，适用于价值通过持续参与而非即时消费产生的领域。", "summary": "本文提出了一种新颖的多利益相关者方法，用于在数字档案中协同设计推荐系统（RecSys）的评估指标。该方法通过与多方利益相关者进行焦点小组讨论，识别了他们在可见性、专业性适应和透明度等方面的价值优先事项，并将其与发现、互动、整合和影响四个研究阶段相对应。研究结果形成了一套评估框架，旨在解决数字档案中特有的挑战，如馆藏不平衡和非线性研究模式。该工作为RecSys领域提供了在价值通过持续参与而非即时消费产生的领域中可转移的评估方法。", "keywords": "推荐系统, 数字档案, 多利益相关者, 评估指标, 协同设计", "comments": "这项研究的创新之处在于首次提出了一个多利益相关者方法来设计推荐系统评估指标，特别是在文化遗产这种价值产生模式不同于商业平台的领域。其重要性在于提供了一个更全面、更符合领域特定需求的评估框架，超越了传统的单一参与度指标，有助于提升数字档案中推荐系统的质量和用户满意度。该方法通过识别和整合不同利益相关者的价值优先级，为RecSys评估提供了一个更具普适性和可转移性的视角。"}}
{"id": "2506.23603", "title": "SoK: Semantic Privacy in Large Language Models", "authors": ["Baihe Ma", "Yanna Jiang", "Xu Wang", "Guangsheng Yu", "Qin Wang", "Caijun Sun", "Chen Li", "Xuelei Qi", "Ying He", "Wei Ni", "Ren Ping Liu"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23603v2", "summary": "As Large Language Models (LLMs) are increasingly deployed in sensitive\ndomains, traditional data privacy measures prove inadequate for protecting\ninformation that is implicit, contextual, or inferable - what we define as\nsemantic privacy. This Systematization of Knowledge (SoK) introduces a\nlifecycle-centric framework to analyze how semantic privacy risks emerge across\ninput processing, pretraining, fine-tuning, and alignment stages of LLMs. We\ncategorize key attack vectors and assess how current defenses, such as\ndifferential privacy, embedding encryption, edge computing, and unlearning,\naddress these threats. Our analysis reveals critical gaps in semantic-level\nprotection, especially against contextual inference and latent representation\nleakage. We conclude by outlining open challenges, including quantifying\nsemantic leakage, protecting multimodal inputs, balancing de-identification\nwith generation quality, and ensuring transparency in privacy enforcement. This\nwork aims to inform future research on designing robust, semantically aware\nprivacy-preserving techniques for LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23603v2", "cate": "cs.CR", "date": "2025-06-30", "updated": "2025-07-16", "AI": {"title_translation": "知识系统化：大型语言模型中的语义隐私", "tldr": "本文是一篇知识系统化（SoK）论文，分析了大型语言模型（LLMs）中语义隐私（隐性、上下文或可推断信息）的风险，提出了一个生命周期框架，并评估了现有防御措施，指出语义级保护存在关键空白，并提出了未来的研究挑战。", "motivation": "随着大型语言模型（LLMs）在敏感领域的广泛部署，传统的数据隐私措施不足以保护隐性、上下文或可推断的信息，即语义隐私。因此，需要系统化地分析语义隐私风险及其防御方法。", "method": "本文采用知识系统化（SoK）的方法，引入了一个以生命周期为中心的框架，分析语义隐私风险如何在LLMs的输入处理、预训练、微调和对齐阶段出现。论文对关键攻击向量进行了分类，并评估了差分隐私、嵌入加密、边缘计算和遗忘等现有防御措施如何应对这些威胁。", "result": "分析揭示了语义级保护中存在的关键空白，特别是在对抗上下文推断和潜在表示泄露方面。", "conclusion": "论文总结了开放的挑战，包括量化语义泄露、保护多模态输入、平衡去识别与生成质量，以及确保隐私执行的透明度。这项工作旨在为未来设计强大、语义感知的LLMs隐私保护技术提供信息。", "translation": "随着大型语言模型（LLMs）在敏感领域的日益部署，传统的数据隐私措施在保护隐性、上下文或可推断的信息方面显得不足——我们将其定义为语义隐私。本知识系统化（SoK）工作引入了一个以生命周期为中心的框架，以分析语义隐私风险如何在LLMs的输入处理、预训练、微调和对齐阶段中出现。我们对关键攻击向量进行了分类，并评估了差分隐私、嵌入加密、边缘计算和遗忘等现有防御措施如何应对这些威胁。我们的分析揭示了语义级保护中的关键空白，特别是在对抗上下文推断和潜在表示泄露方面。最后，我们概述了开放的挑战，包括量化语义泄露、保护多模态输入、平衡去识别与生成质量，以及确保隐私执行的透明度。这项工作旨在为未来设计强大、语义感知的LLMs隐私保护技术提供信息。", "summary": "本知识系统化（SoK）论文深入探讨了大型语言模型（LLMs）中的语义隐私问题，指出传统隐私措施不足以应对隐性、上下文或可推断的信息泄露。论文提出了一个生命周期框架来分析LLMs各阶段的语义隐私风险，并分类了攻击向量。通过评估现有防御措施，研究揭示了语义级保护的不足，尤其是在上下文推断和潜在表示泄露方面。最后，论文提出了量化泄露、保护多模态输入等未来研究挑战，旨在指导LLMs的隐私保护技术发展。", "keywords": "语义隐私, 大型语言模型, 知识系统化, 隐私保护, 攻击向量", "comments": "这篇SoK论文通过引入一个生命周期框架系统地分析了LLMs中的语义隐私风险，填补了传统数据隐私在LLMs应用中的不足。其创新之处在于明确定义了“语义隐私”并将其风险与LLM的各个生命周期阶段相关联。论文对现有防御措施的评估及其揭示的关键空白，为未来LLMs隐私保护研究指明了重要的方向和挑战，具有重要的指导意义。"}}
{"id": "2507.11563", "title": "Environmentally-Conscious Cloud Orchestration Considering Geo-Distributed Data Centers", "authors": ["Giulio Attenni", "Novella Bartolini"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      LOCO 2024, December 3, 2024, Glasgow/Online", "url": "http://arxiv.org/abs/2507.11563v1", "summary": "This paper presents a theoretical discussion for environmentally-conscious\njob deployment and migration in cloud environments, aiming to minimize the\nenvironmental impact of resource provisioning while incorporating\nsustainability requirements. As the demand for sustainable cloud services\ngrows, it is crucial for cloud customers to select data center operators based\non sustainability metrics and to accurately report the ecological footprint of\ntheir services. To this end, we analyze sustainability reports and define\ncomprehensive environmental impact profiles for data centers, incorporating key\nsustainability indicators. We formalize the problem as an optimization model,\nbalancing multiple environmental factors while respecting user preferences. A\nsimulative case study demonstrates the {potential} of our approach compared to\nbaseline strategies that optimize for single sustainability factors.", "comment": "LOCO 2024, December 3, 2024, Glasgow/Online", "pdf_url": "http://arxiv.org/pdf/2507.11563v1", "cate": "cs.DC", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "考虑地理分布式数据中心的环境意识云编排", "tldr": "本文提出了一种在云环境中部署和迁移作业的环境意识方法，旨在最小化资源配置的环境影响，并通过优化模型和案例研究展示其潜力。", "motivation": "随着对可持续云服务的需求增长，云客户根据可持续性指标选择数据中心运营商并准确报告其服务的生态足迹至关重要。因此，需要一种能够最小化资源配置环境影响并纳入可持续性要求的方法。", "method": "论文分析了可持续性报告，定义了数据中心的综合环境影响概况，并纳入了关键可持续性指标。问题被形式化为一个优化模型，该模型在尊重用户偏好的同时平衡了多个环境因素。", "result": "模拟案例研究表明，与仅优化单一可持续性因素的基线策略相比，该方法具有潜力。", "conclusion": "本文提出的环境意识云编排方法在平衡多个环境因素方面具有潜力，可以帮助云客户选择更可持续的数据中心并减少其服务的生态足迹。", "translation": "本文对云环境中具有环保意识的作业部署和迁移进行了理论探讨，旨在最大限度地减少资源配置对环境的影响，同时纳入可持续性要求。随着对可持续云服务的需求增长，云客户根据可持续性指标选择数据中心运营商并准确报告其服务的生态足迹至关重要。为此，我们分析了可持续性报告，并为数据中心定义了全面的环境影响概况，其中包含了关键的可持续性指标。我们将该问题形式化为一个优化模型，该模型在尊重用户偏好的同时平衡了多个环境因素。一项模拟案例研究表明，与仅优化单一可持续性因素的基线策略相比，我们的方法具有潜力。", "summary": "本文探讨了在云环境中实现具有环保意识的作业部署和迁移，旨在最小化资源配置的环境影响并满足可持续性要求。研究通过分析可持续性报告构建了数据中心的环境影响概况，并将问题建模为一个优化模型，以平衡多环境因素和用户偏好。模拟案例研究证实了该方法在提升可持续性方面的潜力。", "keywords": "云编排, 环境意识, 地理分布式数据中心, 可持续性, 优化模型", "comments": "本文的创新点在于将多个环境因素纳入到云资源编排的优化模型中，以实现环境友好型的云服务。这对于日益增长的绿色计算需求具有重要意义。局限性可能在于其仍是理论讨论和模拟案例研究，实际部署和大规模应用可能面临更复杂的工程挑战。"}}
{"id": "2507.12022", "title": "Dataset Ownership Verification for Pre-trained Masked Models", "authors": ["Yuechen Xie", "Jie Song", "Yicheng Shan", "Xiaoyan Zhang", "Yuanyu Wan", "Shengxuming Zhang", "Jiarui Duan", "Mingli Song"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.12022v1", "summary": "High-quality open-source datasets have emerged as a pivotal catalyst driving\nthe swift advancement of deep learning, while facing the looming threat of\npotential exploitation. Protecting these datasets is of paramount importance\nfor the interests of their owners. The verification of dataset ownership has\nevolved into a crucial approach in this domain; however, existing verification\ntechniques are predominantly tailored to supervised models and contrastive\npre-trained models, rendering them ill-suited for direct application to the\nincreasingly prevalent masked models. In this work, we introduce the inaugural\nmethodology addressing this critical, yet unresolved challenge, termed Dataset\nOwnership Verification for Masked Modeling (DOV4MM). The central objective is\nto ascertain whether a suspicious black-box model has been pre-trained on a\nparticular unlabeled dataset, thereby assisting dataset owners in safeguarding\ntheir rights. DOV4MM is grounded in our empirical observation that when a model\nis pre-trained on the target dataset, the difficulty of reconstructing masked\ninformation within the embedding space exhibits a marked contrast to models not\npre-trained on that dataset. We validated the efficacy of DOV4MM through ten\nmasked image models on ImageNet-1K and four masked language models on\nWikiText-103. The results demonstrate that DOV4MM rejects the null hypothesis,\nwith a $p$-value considerably below 0.05, surpassing all prior approaches. Code\nis available at https://github.com/xieyc99/DOV4MM.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.12022v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "预训练掩码模型的数据集所有权验证", "tldr": "本文提出了DOV4MM，一种用于验证黑盒掩码模型是否在特定未标记数据集上预训练的新方法。该方法基于模型在嵌入空间中重建掩码信息难度的差异，并在实验中表现出优于现有方法的性能，有效保护了数据集所有者的权益。", "motivation": "高质量的开源数据集促进了深度学习的快速发展，但其面临被滥用的威胁，保护数据集所有者的权益至关重要。现有数据集所有权验证技术主要针对监督模型和对比预训练模型，无法直接应用于日益流行的掩码模型，因此急需一种新的方法来解决这一未解决的挑战。", "method": "本文引入了DOV4MM（Dataset Ownership Verification for Masked Modeling），这是首个解决预训练掩码模型数据集所有权验证问题的方法。其核心思想是基于经验观察：当模型在一个目标数据集上进行预训练时，其在嵌入空间中重建掩码信息的难度与未在该数据集上预训练的模型相比，会表现出显著差异。DOV4MM利用这种差异来判断一个可疑的黑盒模型是否在一个特定的未标记数据集上进行了预训练。", "result": "DOV4MM在ImageNet-1K上的十个掩码图像模型和WikiText-103上的四个掩码语言模型上进行了验证。结果表明，DOV4MM拒绝了零假设，p值远低于0.05，并且超越了所有现有方法，证明了其有效性。", "conclusion": "本文成功提出了首个针对预训练掩码模型的数据集所有权验证方法DOV4MM，有效解决了现有技术无法应对掩码模型所有权验证的问题。该方法在多项实验中表现出显著优于现有方法的性能，为保护数据集所有者的权益提供了重要工具。", "translation": "高质量的开源数据集已成为推动深度学习快速发展的关键催化剂，同时面临潜在滥用的迫在眉睫的威胁。保护这些数据集对于其所有者的利益至关重要。数据集所有权验证已发展成为该领域的一种关键方法；然而，现有的验证技术主要针对监督模型和对比预训练模型，使其不适用于日益流行的掩码模型。在这项工作中，我们引入了第一个解决这一关键但未解决挑战的方法，称为用于掩码建模的数据集所有权验证（DOV4MM）。其核心目标是确定一个可疑的黑盒模型是否在一个特定的未标记数据集上进行了预训练，从而协助数据集所有者维护其权利。DOV4MM基于我们的经验观察：当模型在一个目标数据集上进行预训练时，其在嵌入空间中重建掩码信息的难度与未在该数据集上预训练的模型相比，会表现出显著差异。我们通过ImageNet-1K上的十个掩码图像模型和WikiText-103上的四个掩码语言模型验证了DOV4MM的有效性。结果表明，DOV4MM拒绝了零假设，p值远低于0.05，超越了所有现有方法。代码可在https://github.com/xieyc99/DOV4MM获取。", "summary": "本文提出了一种名为DOV4MM的新方法，旨在解决预训练掩码模型的数据集所有权验证问题。鉴于现有方法不适用于掩码模型且数据集面临滥用风险，DOV4MM通过观察模型在嵌入空间中重建掩码信息的难度差异来判断黑盒模型是否在特定未标记数据集上进行了预训练。实验证明，DOV4MM在图像和语言掩码模型上均表现出显著优于现有方法的性能，有效保障了数据集所有者的权益。", "keywords": "数据集所有权验证, 掩码模型, 预训练, 黑盒模型, DOV4MM", "comments": "这篇论文解决了深度学习领域一个日益重要且未被充分解决的问题：预训练掩码模型的数据集所有权验证。其创新点在于提出了基于嵌入空间中掩码信息重建难度差异的验证机制，这是一种新颖且有效的思路。该方法的提出对于保护开源数据集提供者的知识产权具有重要意义，尤其是在黑盒模型日益普及的背景下。其在多种模型和数据集上的广泛验证也增强了其可靠性和实用性。"}}
{"id": "2507.12245", "title": "Calisthenics Skills Temporal Video Segmentation", "authors": ["Antonio Finocchiaro", "Giovanni Maria Farinella", "Antonino Furnari"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures, In Proceedings of the 19th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 2", "url": "http://arxiv.org/abs/2507.12245v1", "summary": "Calisthenics is a fast-growing bodyweight discipline that consists of\ndifferent categories, one of which is focused on skills. Skills in calisthenics\nencompass both static and dynamic elements performed by athletes. The\nevaluation of static skills is based on their difficulty level and the duration\nof the hold. Automated tools able to recognize isometric skills from a video by\nsegmenting them to estimate their duration would be desirable to assist\nathletes in their training and judges during competitions. Although the video\nunderstanding literature on action recognition through body pose analysis is\nrich, no previous work has specifically addressed the problem of calisthenics\nskill temporal video segmentation. This study aims to provide an initial step\ntowards the implementation of automated tools within the field of Calisthenics.\nTo advance knowledge in this context, we propose a dataset of video footage of\nstatic calisthenics skills performed by athletes. Each video is annotated with\na temporal segmentation which determines the extent of each skill. We hence\nreport the results of a baseline approach to address the problem of skill\ntemporal segmentation on the proposed dataset. The results highlight the\nfeasibility of the proposed problem, while there is still room for improvement.", "comment": "9 pages, 6 figures, In Proceedings of the 19th International Joint\n  Conference on Computer Vision, Imaging and Computer Graphics Theory and\n  Applications - Volume 2", "pdf_url": "http://arxiv.org/pdf/2507.12245v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "徒手训练技能时间视频分割", "tldr": "本文提出了一个徒手训练技能视频数据集，并探索了自动时间分割徒手训练技能的可行性。", "motivation": "徒手训练技能的评估需要识别和估计静态技能的持续时间。目前缺乏专门针对徒手训练技能时间视频分割的自动化工具，而这类工具对于运动员训练和裁判评分非常有益。", "method": "提出一个包含运动员表演的静态徒手训练技能视频数据集。每个视频都进行了时间分割标注，以确定每个技能的范围。在此数据集上报告了基线方法的结果。", "result": "结果突出了所提出问题的可行性，但仍有改进空间。", "conclusion": "自动化徒手训练工具的实现迈出了初步一步，且所提出的技能时间分割问题是可行的，但仍需进一步研究。", "translation": "徒手训练是一项快速发展的自重训练项目，包含不同类别，其中一类专注于技能。徒手训练中的技能包括运动员执行的静态和动态元素。静态技能的评估基于其难度水平和保持时间。能够通过视频分割识别等距技能以估计其持续时间的自动化工具，对于协助运动员训练和比赛中的裁判将是可取的。尽管通过身体姿态分析进行动作识别的视频理解文献很丰富，但之前没有工作专门解决徒手训练技能时间视频分割问题。本研究旨在为徒手训练领域自动化工具的实施提供初步步骤。为了推进这方面的知识，我们提出了一个包含运动员表演的静态徒手训练技能视频数据集。每个视频都标注了时间分割，以确定每个技能的范围。因此，我们报告了在所提出的数据集上解决技能时间分割问题的基线方法的结果。结果突出了所提出问题的可行性，但仍有改进空间。", "summary": "本研究旨在解决徒手训练技能时间视频分割问题，以开发自动化工具辅助运动员和裁判。鉴于现有文献中缺乏相关工作，作者提出了一个包含静态徒手训练技能视频的数据集，并对视频进行了时间分割标注。在此数据集上，他们报告了基线方法的实验结果，证明了该问题的可行性，并指出未来仍有改进空间。", "keywords": "徒手训练, 视频分割, 技能识别, 数据集, 时间分割", "comments": "这项研究通过引入专门针对徒手训练技能时间视频分割的数据集和基线方法，填补了视频理解领域的一个空白。它为开发自动化工具以辅助徒手训练评估提供了重要的初步步骤，具有实际应用潜力。"}}
{"id": "2507.12306", "title": "MaCE: General Mass Conserving Dynamics for Cellular Automata", "authors": ["Vassilis Papadopoulos", "Etienne Guichard"], "categories": ["nlin.CG", "cs.NE", "nlin.AO"], "primary_category": "Subjects:       Cellular Automata and Lattice Gases (nlin.CG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12306v1", "summary": "We present Mass-Conserving Evolution (MaCE), a general method for\nimplementing mass conservation in Cellular Automata (CA). MaCE is a simple\nevolution rule that can be easily 'attached' to existing CAs to make them\nmass-conserving, which tends to produce interesting behaviours more often, as\npatterns can no longer explode or die out. We first show that MaCE is\nnumerically stable and admits a simple continuous limit. We then test MaCE on\nLenia, and through several experiments, we demonstrate that it produces a wide\nvariety of interesting behaviours, starting from the variety and abundance of\nsolitons up to hints of intrinsic evolution in resource-constrained\nenvironments. Finally, we showcase the versatility of MaCE by applying it to\nNeural-CAs and discrete CAs, and discuss promising research directions opened\nup by this scheme.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12306v1", "cate": "nlin.CG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MaCE：元胞自动机通用质量守恒动力学", "tldr": "MaCE是一种通用的质量守恒方法，可应用于现有元胞自动机，产生更丰富的行为，并已在Lenia等模型中验证其有效性和多功能性。", "motivation": "现有元胞自动机中的模式可能“爆炸”或“消失”，导致行为不够有趣。研究旨在提供一种通用方法来解决这个问题，从而产生更有趣的行为。", "method": "本文提出了一种名为MaCE（Mass-Conserving Evolution）的通用质量守恒方法。它是一个简单的演化规则，可以轻松地“附加”到现有元胞自动机上，使其实现质量守恒。", "result": "MaCE在数值上是稳定的，并允许简单的连续极限。在Lenia上测试，产生了各种有趣的行为，包括多种多样的孤子和资源受限环境中内在进化的迹象。展示了MaCE的多功能性，将其应用于神经元胞自动机和离散元胞自动机。", "conclusion": "MaCE是一个有前景的方案，通过实现质量守恒，能够产生更丰富、更稳定的元胞自动机行为，并为相关研究开辟了新的方向。", "translation": "我们提出了质量守恒演化（MaCE），这是一种在元胞自动机（CA）中实现质量守恒的通用方法。MaCE是一个简单的演化规则，可以很容易地“附加”到现有CA上，使其实现质量守恒，这往往能产生更有趣的行为，因为模式不再会“爆炸”或“消失”。我们首先展示了MaCE在数值上是稳定的，并允许一个简单的连续极限。然后，我们在Lenia上测试了MaCE，通过几次实验，我们证明它产生了各种有趣的行为，从孤子的多样性和丰富性到资源受限环境中内在进化的迹象。最后，我们通过将其应用于神经元胞自动机和离散元胞自动机，展示了MaCE的多功能性，并讨论了该方案开辟的有前景的研究方向。", "summary": "本文介绍了MaCE（Mass-Conserving Evolution），一种为元胞自动机（CA）引入质量守恒的通用方法。MaCE作为一种简单的演化规则，能方便地集成到现有CA中，从而避免模式的“爆炸”或“消失”，并产生更丰富的动态行为。研究证明了MaCE的数值稳定性及其连续极限，并通过在Lenia上的实验，展示了其在生成多样化孤子和模拟资源受限环境下的内在进化方面的有效性。此外，MaCE还成功应用于神经元胞自动机和离散CA，凸显了其广泛适用性和未来研究潜力。", "keywords": "质量守恒, 元胞自动机, MaCE, 演化规则, Lenia", "comments": "该论文提出了一种通用的、可附加的质量守恒演化规则MaCE，解决了传统元胞自动机中模式不稳定性（爆炸或消失）的问题。其创新点在于提供了一种普适性的方法来增强CA的行为多样性和稳定性。在Lenia上的实验结果表明MaCE能够产生丰富的复杂行为，甚至暗示了演化的可能性，这对于理解复杂系统和人工生命具有重要意义。该方法的通用性（适用于神经元胞自动机和离散CA）也展示了其广泛的应用前景。"}}
{"id": "2507.11974", "title": "A Review of Generative AI in Aquaculture: Foundations, Applications, and Future Directions for Smart and Sustainable Farming", "authors": ["Waseem Akram", "Muhayy Ud Din", "Lyes Saad Soud", "Irfan Hussain"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11974v1", "summary": "Generative Artificial Intelligence (GAI) has rapidly emerged as a\ntransformative force in aquaculture, enabling intelligent synthesis of\nmultimodal data, including text, images, audio, and simulation outputs for\nsmarter, more adaptive decision-making. As the aquaculture industry shifts\ntoward data-driven, automation and digital integration operations under the\nAquaculture 4.0 paradigm, GAI models offer novel opportunities across\nenvironmental monitoring, robotics, disease diagnostics, infrastructure\nplanning, reporting, and market analysis. This review presents the first\ncomprehensive synthesis of GAI applications in aquaculture, encompassing\nfoundational architectures (e.g., diffusion models, transformers, and retrieval\naugmented generation), experimental systems, pilot deployments, and real-world\nuse cases. We highlight GAI's growing role in enabling underwater perception,\ndigital twin modeling, and autonomous planning for remotely operated vehicle\n(ROV) missions. We also provide an updated application taxonomy that spans\nsensing, control, optimization, communication, and regulatory compliance.\nBeyond technical capabilities, we analyze key limitations, including limited\ndata availability, real-time performance constraints, trust and explainability,\nenvironmental costs, and regulatory uncertainty. This review positions GAI not\nmerely as a tool but as a critical enabler of smart, resilient, and\nenvironmentally aligned aquaculture systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11974v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "生成式人工智能在水产养殖中的应用综述：智能和可持续养殖的基础、应用和未来方向", "tldr": "本综述探讨了生成式人工智能（GAI）在水产养殖中的变革作用，涵盖其基础、应用和未来方向，旨在实现智能和可持续的农业，并分析了其局限性。", "motivation": "水产养殖业正在向数据驱动、自动化和数字化集成运营的“水产养殖4.0”范式转变。生成式人工智能（GAI）在此背景下为环境监测、机器人技术、疾病诊断、基础设施规划、报告和市场分析等领域提供了新的机遇。本综述旨在首次全面综合GAI在水产养殖中的应用。", "method": "本综述首次全面综合了生成式人工智能（GAI）在水产养殖中的应用，涵盖了基础架构（如扩散模型、Transformer和检索增强生成）、实验系统、试点部署和实际用例。此外，它还强调了GAI在水下感知、数字孪生建模和遥控潜水器（ROV）任务自主规划中的作用，并提供了一个更新的应用分类法。同时，本综述分析了GAI的关键局限性。", "result": "生成式人工智能（GAI）在实现水下感知、数字孪生建模和遥控潜水器（ROV）任务的自主规划方面发挥着日益重要的作用。本综述提供了一个涵盖传感、控制、优化、通信和法规遵从的更新应用分类法。同时，也识别了GAI在水产养殖中应用的主要局限性，包括数据可用性有限、实时性能约束、信任和可解释性问题、环境成本以及监管不确定性。", "conclusion": "生成式人工智能（GAI）不仅仅是一种工具，更是智能、弹性且与环境协调的水产养殖系统的关键推动者。", "translation": "生成式人工智能（GAI）已迅速成为水产养殖领域的一股变革力量，能够智能合成多模态数据，包括文本、图像、音频和模拟输出，以实现更智能、更具适应性的决策。随着水产养殖业在水产养殖4.0范式下转向数据驱动、自动化和数字集成运营，GAI模型在环境监测、机器人技术、疾病诊断、基础设施规划、报告和市场分析等领域提供了新的机遇。本综述首次全面综合了GAI在水产养殖中的应用，涵盖了基础架构（例如扩散模型、Transformer和检索增强生成）、实验系统、试点部署和实际用例。我们强调了GAI在实现水下感知、数字孪生建模和遥控潜水器（ROV）任务的自主规划方面日益增长的作用。我们还提供了一个更新的应用分类法，涵盖传感、控制、优化、通信和法规遵从。除了技术能力之外，我们还分析了主要的局限性，包括有限的数据可用性、实时性能约束、信任和可解释性、环境成本以及监管不确定性。本综述将GAI定位为智能、弹性、与环境协调的水产养殖系统的关键推动者，而不仅仅是一种工具。", "summary": "本综述论文探讨了生成式人工智能（GAI）在水产养殖中的变革性作用，特别是在水产养殖4.0范式下。它首次全面综合了GAI的应用、基础架构和实际用例，突出了其在水下感知和自主规划等领域的影响。该论文还提出了一个更新的应用分类法，并批判性地分析了主要局限性，最终将GAI定位为智能和可持续水产养殖系统的关键推动者。", "keywords": "生成式人工智能, 水产养殖, 智能养殖, 可持续养殖, 综述", "comments": "本综述具有重要意义，因为它首次全面综合了生成式人工智能在水产养殖中的应用，对这一新兴且具有变革性的技术在关键行业中的发展提供了及时的概述。它不仅涵盖了GAI的巨大潜力和应用，还批判性地探讨了其局限性，为未来的研究和部署提供了平衡的视角。其对“智能、弹性且与环境协调的水产养殖系统”的关注，突显了其与可持续发展目标的关联性。"}}
{"id": "2507.12083", "title": "Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics", "authors": ["Muleilan Pei", "Shaoshuai Shi", "Xuesong Chen", "Xu Liu", "Shaojie Shen"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.12083v1", "summary": "Motion forecasting for on-road traffic agents presents both a significant\nchallenge and a critical necessity for ensuring safety in autonomous driving\nsystems. In contrast to most existing data-driven approaches that directly\npredict future trajectories, we rethink this task from a planning perspective,\nadvocating a \"First Reasoning, Then Forecasting\" strategy that explicitly\nincorporates behavior intentions as spatial guidance for trajectory prediction.\nTo achieve this, we introduce an interpretable, reward-driven intention\nreasoner grounded in a novel query-centric Inverse Reinforcement Learning (IRL)\nscheme. Our method first encodes traffic agents and scene elements into a\nunified vectorized representation, then aggregates contextual features through\na query-centric paradigm. This enables the derivation of a reward distribution,\na compact yet informative representation of the target agent's behavior within\nthe given scene context via IRL. Guided by this reward heuristic, we perform\npolicy rollouts to reason about multiple plausible intentions, providing\nvaluable priors for subsequent trajectory generation. Finally, we develop a\nhierarchical DETR-like decoder integrated with bidirectional selective state\nspace models to produce accurate future trajectories along with their\nassociated probabilities. Extensive experiments on the large-scale Argoverse\nand nuScenes motion forecasting datasets demonstrate that our approach\nsignificantly enhances trajectory prediction confidence, achieving highly\ncompetitive performance relative to state-of-the-art methods.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.12083v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "运动中的预见：利用奖励启发式强化轨迹预测", "tldr": "该研究提出了一种新的运动预测方法，通过逆强化学习（IRL）推断交通代理的行为意图（奖励启发式），然后进行轨迹预测，从而提高预测置信度和性能。", "motivation": "道路交通代理的运动预测对于自动驾驶系统的安全至关重要，但现有的大多数数据驱动方法直接预测未来轨迹，缺乏对行为意图的明确考虑。", "method": "该方法提出“先推理，后预测”的策略，通过新颖的以查询为中心的逆强化学习（IRL）方案引入一个可解释的、奖励驱动的意图推理器。首先将交通代理和场景元素编码为统一的向量化表示，然后通过以查询为中心的范式聚合上下文特征，从而推导出奖励分布。在此奖励启发式的指导下，进行策略展开以推断多种可能意图，为后续轨迹生成提供先验信息。最后，开发了一个分层DETR类解码器，结合双向选择性状态空间模型，以生成准确的未来轨迹及其相关概率。", "result": "在大型Argoverse和nuScenes运动预测数据集上的广泛实验表明，该方法显著增强了轨迹预测置信度，并取得了与最先进方法相比极具竞争力的性能。", "conclusion": "该论文成功地引入了一种新的基于规划的轨迹预测框架，该框架利用逆强化学习（IRL）的奖励启发式来融入行为意图，从而在自动驾驶运动预测中提高了置信度和性能。", "translation": "道路交通代理的运动预测对于确保自动驾驶系统的安全来说，既是一个重大挑战，也是一个关键需求。与大多数直接预测未来轨迹的现有数据驱动方法不同，我们从规划的角度重新思考这项任务，倡导一种“先推理，后预测”的策略，该策略明确地将行为意图作为轨迹预测的空间指导。为此，我们引入了一个可解释的、奖励驱动的意图推理器，它基于一种新颖的以查询为中心的逆强化学习（IRL）方案。我们的方法首先将交通代理和场景元素编码为统一的向量化表示，然后通过以查询为中心的范式聚合上下文特征。这使得能够通过IRL推导出奖励分布，这是目标代理在给定场景上下文中的行为的一种紧凑而信息丰富的表示。在此奖励启发式的指导下，我们进行策略展开，以推断多种可能的意图，为后续轨迹生成提供有价值的先验信息。最后，我们开发了一个分层DETR类解码器，结合双向选择性状态空间模型，以生成准确的未来轨迹及其相关概率。在大型Argoverse和nuScenes运动预测数据集上的广泛实验表明，我们的方法显著增强了轨迹预测置信度，取得了与最先进方法相比极具竞争力的性能。", "summary": "本研究提出了一种名为“运动中的预见”的轨迹预测新方法，旨在提高自动驾驶的安全性。该方法摒弃了传统直接预测轨迹的模式，转而采用“先推理，后预测”的策略。通过引入一个基于新颖查询中心逆强化学习（IRL）的意图推理器，该系统能够从场景中推断出交通代理的奖励分布和行为意图。这些意图作为轨迹生成的空间指导和先验信息。最终，结合一个分层DETR类解码器和双向选择性状态空间模型，该方法能够生成高置信度和精确的未来轨迹。在Argoverse和nuScenes数据集上的实验验证了其优越性能。", "keywords": "轨迹预测, 逆强化学习, 自动驾驶, 运动预测, 意图推理", "comments": "该论文的创新之处在于其“先推理，后预测”的策略，通过将逆强化学习（IRL）引入轨迹预测，明确地将行为意图纳入考量。这种方法不仅可能提高预测的准确性，还可能增强模型的可解释性，对于自动驾驶中复杂多代理交互的预测尤为重要。结合分层DETR类解码器和状态空间模型的架构也体现了其技术上的先进性。"}}
{"id": "2507.10577", "title": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions", "authors": ["Cécile Logé", "Rehan Ghori"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10577v2", "summary": "Misinformation poses a significant threat in today's digital world, often\nspreading rapidly through platforms like YouTube. This paper introduces a novel\napproach to combating misinformation by developing an AI-powered system that\nnot only fact-checks claims made in YouTube videos but also actively engages\nusers in the comment section and challenge misleading narratives. Our system\ncomprises two main agents: Truth Sleuth and Trend Bender.\n  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented\nGeneration (RAG) approach - drawing on sources like Wikipedia, Google Search,\nGoogle FactCheck - to accurately assess their veracity and generates a nuanced\nand comprehensive report. Through rigorous prompt engineering, Trend Bender\nleverages this report along with a curated corpus of relevant articles to\ngenerate insightful and persuasive comments designed to stimulate a productive\ndebate. With a carefully set up self-evaluation loop, this agent is able to\niteratively improve its style and refine its output.\n  We demonstrate the system's capabilities through experiments on established\nbenchmark datasets and a real-world deployment on YouTube, showcasing its\npotential to engage users and potentially influence perspectives. Our findings\nhighlight the high accuracy of our fact-checking agent, and confirm the\npotential of AI-driven interventions in combating misinformation and fostering\na more informed online space.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10577v2", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-16", "AI": {"title_translation": "真相侦探与趋势扭转者：用于事实核查YouTube视频并影响观点的AI代理", "tldr": "本文介绍了一个名为“真相侦探与趋势扭转者”的AI系统，旨在通过事实核查YouTube视频内容并在评论区引导用户来打击虚假信息。", "motivation": "当今数字世界中，虚假信息构成重大威胁，通常通过YouTube等平台迅速传播。本文旨在开发一个AI驱动的系统来对抗这一问题。", "method": "本研究开发了一个AI驱动的系统，包含两个主要代理：\n1.  真相侦探（Truth Sleuth）：从YouTube视频中提取主张，并使用检索增强生成（RAG）方法（利用维基百科、谷歌搜索、谷歌事实核查等来源）准确评估其真实性，生成详细报告。\n2.  趋势扭转者（Trend Bender）：利用真相侦探的报告和精选文章语料库，通过严格的提示工程生成有洞察力和说服力的评论，旨在刺激富有成效的辩论，并通过自我评估循环迭代改进其输出。", "result": "系统在既定基准数据集上进行了实验，并在YouTube上进行了实际部署，展示了其吸引用户和潜在影响观点的能力。研究结果突出显示了事实核查代理的高准确性，并证实了AI驱动的干预措施在打击虚假信息和促进更知情的在线空间方面的潜力。", "conclusion": "AI驱动的“真相侦探与趋势扭转者”系统在打击YouTube上的虚假信息、通过积极互动纠正误导性叙述以及促进更知情的在线空间方面具有巨大潜力。", "translation": "当今数字世界中，虚假信息构成重大威胁，通常通过YouTube等平台迅速传播。本文介绍了一种新颖的打击虚假信息的方法，通过开发一个AI驱动的系统，该系统不仅能对YouTube视频中的主张进行事实核查，还能积极在评论区与用户互动并挑战误导性叙述。我们的系统包括两个主要代理：真相侦探（Truth Sleuth）和趋势扭转者（Trend Bender）。\n真相侦探从YouTube视频中提取主张，采用检索增强生成（RAG）方法——利用维基百科、谷歌搜索、谷歌事实核查等来源——准确评估其真实性并生成细致全面的报告。通过严格的提示工程，趋势扭转者利用这份报告以及精选的相关文章语料库，生成富有洞察力和说服力的评论，旨在激发富有成效的辩论。通过精心设置的自我评估循环，该代理能够迭代改进其风格和完善其输出。\n我们通过在既定基准数据集上的实验和在YouTube上的实际部署，展示了系统的能力，展示了其吸引用户并可能影响观点的潜力。我们的发现突出了我们的事实核查代理的高准确性，并证实了AI驱动的干预措施在打击虚假信息和促进更知情的在线空间方面的潜力。", "summary": "本文提出一个名为“真相侦探与趋势扭转者”的AI系统，旨在应对YouTube上的虚假信息。该系统由两个AI代理组成：真相侦探负责利用RAG技术对视频内容进行事实核查并生成报告；趋势扭转者则根据报告生成评论，在评论区引导用户并挑战误导性叙述，并通过自我评估不断优化。实验证明该系统在事实核查方面表现出高准确性，并显示出AI在打击虚假信息和塑造健康在线讨论方面的巨大潜力。", "keywords": "虚假信息, 事实核查, AI代理, YouTube, 检索增强生成", "comments": "该论文提出了一种创新的、主动干预虚假信息传播的AI系统，不仅限于被动的事实核查，还通过AI代理在评论区进行互动和引导，这是一种积极且具有社会影响力的尝试。其结合RAG和自我评估循环的设计也增加了系统的鲁棒性和适应性。然而，AI代理“影响观点”的伦理边界和潜在滥用风险值得进一步探讨。"}}
{"id": "2503.17070", "title": "A Thorough Assessment of the Non-IID Data Impact in Federated Learning", "authors": ["Daniel M. Jimenez-Gutierrez", "Mehrdad Hassanzadeh", "Aris Anagnostopoulos", "Ioannis Chatzigiannakis", "Andrea Vitaletti"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.17070v2", "summary": "Federated learning (FL) allows collaborative machine learning (ML) model\ntraining among decentralized clients' information, ensuring data privacy. The\ndecentralized nature of FL deals with non-independent and identically\ndistributed (non-IID) data. This open problem has notable consequences, such as\ndecreased model performance and more significant convergence times. Despite its\nimportance, experimental studies systematically addressing all types of data\nheterogeneity (a.k.a. non-IIDness) remain scarce. We aim to fill this gap by\nassessing and quantifying the non-IID effect through a thorough empirical\nanalysis. We use the Hellinger Distance (HD) to measure differences in\ndistribution among clients. Our study benchmarks four state-of-the-art\nstrategies for handling non-IID data, including label, feature, quantity, and\nspatiotemporal skewness, under realistic and controlled conditions. This is the\nfirst comprehensive analysis of the spatiotemporal skew effect in FL. Our\nfindings highlight the significant impact of label and spatiotemporal skew\nnon-IID types on FL model performance, with notable performance drops occurring\nat specific HD thresholds. Additionally, the FL performance is heavily affected\nmainly when the non-IIDness is extreme. Thus, we provide recommendations for FL\nresearch to tackle data heterogeneity effectively. Our work represents the most\nextensive examination of non-IIDness in FL, offering a robust foundation for\nfuture research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.17070v2", "cate": "cs.LG", "date": "2025-03-21", "updated": "2025-07-16", "AI": {"title_translation": "联邦学习中非独立同分布数据影响的彻底评估", "tldr": "本文对联邦学习中非独立同分布（non-IID）数据的影响进行了全面评估，特别关注标签和时空偏斜的显著影响，并提供了应对数据异质性的建议。", "motivation": "联邦学习（FL）中的数据非独立同分布（non-IID）是一个开放问题，会导致模型性能下降和收敛时间增加。尽管其重要性，系统性地解决所有类型数据异质性的实验研究仍然稀缺，本文旨在填补这一空白。", "method": "通过彻底的经验分析来评估和量化非IID效应。使用海林格距离（Hellinger Distance, HD）来测量客户端之间分布的差异。基准测试了四种最先进的非IID数据处理策略，包括标签、特征、数量和时空偏斜，并在真实和受控条件下进行。首次全面分析了FL中的时空偏斜效应。", "result": "标签和时空偏斜非IID类型对FL模型性能有显著影响，在特定的HD阈值下出现明显的性能下降。此外，FL性能主要在非IID程度极端时受到严重影响。", "conclusion": "非独立同分布数据对联邦学习的性能影响显著，尤其是在极端情况下。研究结果为联邦学习研究有效处理数据异质性提供了建议和坚实的基础。", "translation": "联邦学习（FL）允许去中心化客户端之间协作训练机器学习（ML）模型，同时确保数据隐私。FL的去中心化性质处理非独立同分布（non-IID）数据。这个开放问题带来了显著的后果，例如模型性能下降和收敛时间延长。尽管其重要性，系统性地解决所有类型数据异质性（又称非IID性）的实验研究仍然稀缺。我们旨在通过彻底的实证分析来评估和量化非IID效应，以填补这一空白。我们使用海林格距离（HD）来衡量客户端之间分布的差异。我们的研究在真实和受控条件下，对处理非IID数据的四种最先进策略进行了基准测试，包括标签、特征、数量和时空偏斜。这是对FL中时空偏斜效应的首次全面分析。我们的发现强调了标签和时空偏斜非IID类型对FL模型性能的显著影响，在特定的HD阈值下出现明显的性能下降。此外，FL性能主要在非IID程度极端时受到严重影响。因此，我们为FL研究有效处理数据异质性提供了建议。我们的工作代表了对FL中非IID性最广泛的检查，为未来的研究提供了坚实的基础。", "summary": "本研究对联邦学习（FL）中非独立同分布（non-IID）数据的影响进行了全面评估。通过使用海林格距离衡量数据分布差异，并基准测试了处理标签、特征、数量和时空偏斜的四种策略。研究发现，标签和时空偏斜对FL模型性能有显著影响，尤其是在非IID程度极端时，性能下降明显。本文为FL研究有效应对数据异质性提供了建议，并代表了对FL中non-IID性最广泛的检查。", "keywords": "联邦学习, 非独立同分布, 数据异质性, 海林格距离, 时空偏斜", "comments": "这项研究通过首次全面评估时空偏斜效应，并系统性地量化了不同类型非IID数据对联邦学习性能的影响，填补了现有研究的空白。其创新之处在于使用了海林格距离作为衡量标准，并提供了针对性的建议，为未来联邦学习在非IID环境下的模型优化提供了坚实的基础和重要的指导意义。"}}
{"id": "2507.12005", "title": "Kernelization for list $H$-coloring for graphs with small vertex cover", "authors": ["Marta Piecyk", "Astrid Pieterse", "Paweł Rzążewski", "Magnus Wahlström"], "categories": ["math.CO", "cs.DS"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12005v1", "summary": "For a fixed graph $H$, in the List $H$-Coloring problem, we are given a graph\n$G$ along with list $L(v) \\subseteq V(H)$ for every $v \\in V(G)$, and we have\nto determine if there exists a list homomorphism $\\varphi$ from $(G,L)$ to $H$,\ni.e., an edge preserving mapping $\\varphi: V(G)\\to V(H)$ that satisfies\n$\\varphi(v)\\in L(v)$ for every $v\\in V(G)$. Note that if $H$ is the complete\ngraph on $q$ vertices, the problem is equivalent to List $q$-Coloring. We\ninvestigate the kernelization properties of List $H$-Coloring parameterized by\nthe vertex cover number of $G$: given an instance $(G,L)$ and a vertex cover of\n$G$ of size $k$, can we reduce $(G,L)$ to an equivalent instance $(G',L')$ of\nList $H$-Coloring where the size of $G'$ is bounded by a low-degree polynomial\n$p(k)$ in $k$? This question has been investigated previously by Jansen and\nPieterse [Algorithmica 2019], who provided an upper bound, which turns out to\nbe optimal if $H$ is a complete graph, i.e., for List $q$-Coloring. This result\nwas one of the first applications of the method of kernelization via\nbounded-degree polynomials. We define two new integral graph invariants,\n$c^*(H)$ and $d^*(H)$, with $d^*(H) \\leq c^*(H) \\leq d^*(H)+1$, and show that\nfor every graph $H$, List $H$-Coloring\n  -- has a kernel with $\\mathcal{O}(k^{c^*(H)})$ vertices,\n  -- admits no kernel of size $\\mathcal{O}(k^{d^*(H)-\\varepsilon})$ for any\n$\\varepsilon > 0$, unless the polynomial hierarchy collapses.\n  -- Furthermore, if $c^*(H) > d^*(H)$, then there is a kernel with\n$\\mathcal{O}(k^{c^*(H)-\\varepsilon})$ vertices where $\\varepsilon \\geq\n2^{1-c^*(H)}$.\n  Additionally, we show that for some classes of graphs, including powers of\ncycles and graphs $H$ where $\\Delta(H) \\leq c^*(H)$ (which in particular\nincludes cliques), the bound $d^*(H)$ is tight, using the polynomial method. We\nconjecture that this holds in general.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12005v1", "cate": "math.CO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "列表$H$-着色问题在小顶点覆盖图上的核化", "tldr": "本文为列表$H$-着色问题在以顶点覆盖数为参数的图上，定义了新的图不变量$c^*(H)$和$d^*(H)$，并给出了其核化大小的上下界，证明了$d^*(H)$在某些图类上的紧性，并推测其普遍适用。", "motivation": "之前的研究（Jansen和Pieterse，2019）提供了列表$H$-着色问题在以图的顶点覆盖数为参数时的核化上界，该上界在$H$为完全图时是最佳的。本文旨在进一步探究列表$H$-着色问题在更一般图$H$上的核化性质，并为核大小提供更精确的上下界。", "method": "作者定义了两个新的整数图不变量$c^*(H)$和$d^*(H)$，并利用多项式方法（polynomial method）来推导和证明列表$H$-着色问题核化大小的界限，以及这些界限的紧性。", "result": "1. 列表$H$-着色问题存在一个具有$\\\\mathcal{O}(k^{c^*(H)})$个顶点的核。\n2. 除非多项式层级崩溃，否则不存在大小为$\\\\mathcal{O}(k^{d^*(H)-\\\\varepsilon})$的核（对于任意$\\\\varepsilon > 0$）。\n3. 如果$c^*(H) > d^*(H)$，则存在一个具有$\\\\mathcal{O}(k^{c^*(H)-\\\\varepsilon})$个顶点的核，其中$\\\\varepsilon \\\\geq 2^{1-c^*(H)}$。\n4. 对于某些图类（包括循环的幂和满足$\\\\Delta(H) \\\\leq c^*(H)$的图，特别是团图），使用多项式方法证明了$d^*(H)$的下界是紧的。", "conclusion": "本文为列表$H$-着色问题提供了基于新图不变量$c^*(H)$和$d^*(H)$的核化大小的精确上下界。研究结果表明，$d^*(H)$在某些图类上是紧的，作者推测此结论普遍适用。", "translation": "对于一个固定的图$H$，在列表$H$-着色问题中，给定一个图$G$以及对于每个$v \\\\in V(G)$的列表$L(v) \\\\subseteq V(H)$，我们需要确定是否存在一个从$(G,L)$到$H$的列表同态$\\\\varphi$，即一个保留边的映射$\\\\varphi: V(G)\\\\to V(H)$，满足对于每个$v\\\\in V(G)$有$\\\\varphi(v)\\\\in L(v)$。注意，如果$H$是$q$个顶点的完全图，则该问题等价于列表$q$-着色问题。我们研究了以$G$的顶点覆盖数$k$为参数的列表$H$-着色问题的核化性质：给定一个实例$(G,L)$和$G$的一个大小为$k$的顶点覆盖，我们能否将$(G,L)$规约成一个等价的列表$H$-着色问题实例$(G',L')$，其中$G'$的大小受限于$k$的一个低次多项式$p(k)$？这个问题之前由Jansen和Pieterse [Algorithmica 2019]研究过，他们提供了一个上界，当$H$是完全图时（即对于列表$q$-着色问题），该上界被证明是最佳的。这个结果是核化通过有界度多项式方法的最早应用之一。我们定义了两个新的整数图不变量$c^*(H)$和$d^*(H)$，其中$d^*(H) \\\\leq c^*(H) \\\\leq d^*(H)+1$，并表明对于每个图$H$，列表$H$-着色问题\n-- 具有$\\\\mathcal{O}(k^{c^*(H)})$个顶点的核，\n-- 除非多项式层级崩溃，否则不存在大小为$\\\\mathcal{O}(k^{d^*(H)-\\\\varepsilon})$的核（对于任何$\\\\varepsilon > 0$）。\n-- 此外，如果$c^*(H) > d^*(H)$，则存在一个具有$\\\\mathcal{O}(k^{c^*(H)-\\\\varepsilon})$个顶点的核，其中$\\\\varepsilon \\\\geq 2^{1-c^*(H)}$。\n此外，我们表明对于某些图类，包括循环的幂和满足$\\\\Delta(H) \\\\leq c^*(H)$的图（特别是团图），使用多项式方法证明了$d^*(H)$的界限是紧的。我们推测这普遍适用。", "summary": "本文研究了以图的顶点覆盖数为参数的列表$H$-着色问题的核化性质。作者引入了两个新的整数图不变量$c^*(H)$和$d^*(H)$，并基于这些不变量，为该问题的核大小建立了精确的上下界。研究结果表明，列表$H$-着色问题存在一个$\\\\mathcal{O}(k^{c^*(H)})$大小的核，并且除非多项式层级崩溃，否则不存在小于$\\\\mathcal{O}(k^{d^*(H)})$的核。文章进一步证明了在特定图类中$d^*(H)$的界限是紧的，并推测此紧性普遍成立。", "keywords": "列表$H$-着色, 核化, 顶点覆盖, 参数化复杂性, 图同态", "comments": "这篇论文的创新点在于引入了两个新的图不变量$c^*(H)$和$d^*(H)$，它们有效地刻画了列表$H$-着色问题在参数化复杂性理论中的核化行为。通过证明精确的核大小上下界，并指出在何种条件下这些界限是紧的，该研究显著推进了对列表$H$-着色问题复杂性的理解。特别是，它扩展了之前仅限于完全图$H$的结果，对更普遍的图$H$给出了深入分析。其重要性在于为未来研究提供了新的理论工具和基准。"}}
{"id": "2507.12186", "title": "Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation", "authors": ["Edward Kim", "Hanna Kurniawati"], "categories": ["cs.AI", "I.2.8; I.2.9"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      8 pages, 2 tables, 3 figures. To be presented at International Joint Conference on Artificial Intelligence 2025", "url": "http://arxiv.org/abs/2507.12186v1", "summary": "This paper proposes Partially Observable Reference Policy Programming, a\nnovel anytime online approximate POMDP solver which samples meaningful future\nhistories very deeply while simultaneously forcing a gradual policy update. We\nprovide theoretical guarantees for the algorithm's underlying scheme which say\nthat the performance loss is bounded by the average of the sampling\napproximation errors rather than the usual maximum, a crucial requirement given\nthe sampling sparsity of online planning. Empirical evaluations on two\nlarge-scale problems with dynamically evolving environments -- including a\nhelicopter emergency scenario in the Corsica region requiring approximately 150\nplanning steps -- corroborate the theoretical results and indicate that our\nsolver considerably outperforms current online benchmarks.", "comment": "8 pages, 2 tables, 3 figures. To be presented at International Joint\n  Conference on Artificial Intelligence 2025", "pdf_url": "http://arxiv.org/pdf/2507.12186v1", "cate": "cs.AI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "部分可观测参考策略规划：无需数值优化的POMDPs求解", "tldr": "本文提出了一种新颖的、无需数值优化的部分可观测马尔可夫决策过程（POMDP）求解器，名为部分可观测参考策略规划（PORPP），它通过深度采样和渐进策略更新来解决大型POMDPs，并提供了理论保证，在经验评估中优于现有在线基准。", "motivation": "为了解决部分可观测马尔可夫决策过程（POMDPs），特别是在线规划中采样稀疏性带来的挑战，以及现有求解器可能存在的性能限制。", "method": "本文提出部分可观测参考策略规划（Partially Observable Reference Policy Programming, PORPP），这是一种新颖的随时在线近似POMDP求解器。它通过深度采样有意义的未来历史，并同时强制执行渐进的策略更新。该算法的核心方案具有理论保证，即性能损失由采样近似误差的平均值而非最大值限定。", "result": "理论结果表明，算法的性能损失被采样近似误差的平均值所限制。在两个动态演化环境的大规模问题（包括科西嘉地区的直升机紧急情况，需要约150个规划步骤）上的实证评估证实了理论结果，并表明该求解器显著优于当前的在线基准。", "conclusion": "部分可观测参考策略规划（PORPP）是一种有效且具有理论支持的POMDP求解器，它在处理大型、复杂的部分可观测问题方面表现出色，并显著超越了现有在线方法。", "translation": "本文提出了部分可观测参考策略规划（Partially Observable Reference Policy Programming），这是一种新颖的、随时在线的近似POMDP求解器，它在深度采样有意义的未来历史的同时，强制执行渐进的策略更新。我们为该算法的基础方案提供了理论保证，即性能损失受限于采样近似误差的平均值而非通常的最大值，鉴于在线规划的采样稀疏性，这是一个关键要求。在两个具有动态演化环境的大规模问题（包括科西嘉地区需要大约150个规划步骤的直升机紧急情况）上的实证评估证实了理论结果，并表明我们的求解器显著优于当前的在线基准。", "summary": "本文介绍了一种名为“部分可观测参考策略规划”（PORPP）的新型在线POMDP求解器。该方法通过深入采样未来历史并逐步更新策略来解决部分可观测马尔可夫决策过程（POMDPs）。研究提供了理论保证，指出其性能损失由采样误差的平均值而非最大值决定，这对于在线规划的稀疏采样至关重要。实证评估在大型动态问题上（包括一个直升机紧急场景）证实了理论预测，并表明PORPP显著优于现有在线基准。", "keywords": "POMDP, 在线规划, 策略编程, 采样, 理论保证", "comments": "这项工作具有创新性，因为它提出了一种无需数值优化的POMDP求解方法，并解决了在线规划中采样稀疏性带来的挑战。其理论保证——性能损失由平均误差而非最大误差决定——是一个重要的贡献，提高了算法的鲁棒性。在复杂、大规模问题上的出色表现，特别是与现有基准的比较，凸显了其重要性和实用价值。"}}
{"id": "2507.11655", "title": "Counting Answer Sets of Disjunctive Answer Set Programs", "authors": ["Mohimenul Kabir", "Supratik Chakraborty", "Kuldeep S Meel"], "categories": ["cs.LO", "cs.AI"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "Comments:      Under consideration in Theory and Practice of Logic Programming (TPLP)", "url": "http://arxiv.org/abs/2507.11655v1", "summary": "Answer Set Programming (ASP) provides a powerful declarative paradigm for\nknowledge representation and reasoning. Recently, counting answer sets has\nemerged as an important computational problem with applications in\nprobabilistic reasoning, network reliability analysis, and other domains. This\nhas motivated significant research into designing efficient ASP counters. While\nsubstantial progress has been made for normal logic programs, the development\nof practical counters for disjunctive logic programs remains challenging.\n  We present SharpASP-SR, a novel framework for counting answer sets of\ndisjunctive logic programs based on subtractive reduction to projected\npropositional model counting. Our approach introduces an alternative\ncharacterization of answer sets that enables efficient reduction while ensuring\nthat intermediate representations remain of polynomial size. This allows\nSharpASP-SR to leverage recent advances in projected model counting technology.\nThrough extensive experimental evaluation on diverse benchmarks, we demonstrate\nthat SharpASP-SR significantly outperforms existing counters on instances with\nlarge answer set counts. Building on these results, we develop a hybrid\ncounting approach that combines enumeration techniques with SharpASP-SR to\nachieve state-of-the-art performance across the full spectrum of disjunctive\nprograms.", "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "pdf_url": "http://arxiv.org/pdf/2507.11655v1", "cate": "cs.LO", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "析取答案集程序的答案集计数", "tldr": "SharpASP-SR是一个用于计数析取逻辑程序答案集的新框架，它通过减法归约到投影命题模型计数，并在实验中表现出显著优于现有计数器的性能。", "motivation": "答案集计数是概率推理、网络可靠性分析等领域中的一个重要计算问题。尽管在普通逻辑程序方面取得了实质性进展，但为析取逻辑程序开发实用的计数器仍然具有挑战性。", "method": "本文提出了SharpASP-SR框架，通过将析取逻辑程序的答案集计数问题减法归约到投影命题模型计数。该方法引入了答案集的替代特征，实现了高效归约并确保中间表示保持多项式大小，从而利用了投影模型计数技术的最新进展。", "result": "通过在不同基准上的广泛实验评估，SharpASP-SR在答案集数量大的实例上显著优于现有计数器。在此基础上，开发了一种结合枚举技术与SharpASP-SR的混合计数方法，在所有析取程序上实现了最先进的性能。", "conclusion": "SharpASP-SR及其混合方法为析取逻辑程序的答案集计数问题提供了高效且最先进的解决方案。", "translation": "答案集编程（ASP）为知识表示和推理提供了一个强大的声明性范式。最近，答案集计数已成为一个重要的计算问题，在概率推理、网络可靠性分析和其他领域都有应用。这促使了对设计高效ASP计数器的大量研究。虽然在普通逻辑程序方面取得了实质性进展，但为析取逻辑程序开发实用的计数器仍然具有挑战性。\n我们提出了SharpASP-SR，这是一个用于计数析取逻辑程序答案集的新颖框架，它基于减法归约到投影命题模型计数。我们的方法引入了答案集的替代特征，从而实现了高效归约，同时确保中间表示保持多项式大小。这使得SharpASP-SR能够利用投影模型计数技术的最新进展。通过在不同基准上的广泛实验评估，我们证明了SharpASP-SR在具有大量答案集的实例上显著优于现有计数器。基于这些结果，我们开发了一种混合计数方法，将枚举技术与SharpASP-SR相结合，以在所有析取程序中实现最先进的性能。", "summary": "本文介绍了SharpASP-SR，这是一个专门用于计数析取逻辑程序答案集的新型框架。该方法通过创新的减法归约技术将问题转换为投影命题模型计数，并引入了答案集的替代特征，确保了高效归约和多项式大小的中间表示。实验结果表明，SharpASP-SR在处理大量答案集的实例时，性能显著优于现有计数器。此外，通过结合SharpASP-SR与枚举技术，提出了一种混合计数方法，在所有析取程序上均实现了最先进的性能。", "keywords": "答案集计数, 析取逻辑程序, SharpASP-SR, 投影模型计数, 减法归约", "comments": "该论文的创新点在于提出了SharpASP-SR框架，通过将析取逻辑程序的答案集计数问题巧妙地归约到投影命题模型计数，并引入了新的答案集特征以优化归约效率和中间表示大小。这对于解决长期存在的析取逻辑程序计数难题具有重要意义，尤其是在处理大规模答案集计数问题上取得了显著突破。"}}
{"id": "2507.12052", "title": "Distributed Resilient State Estimation and Control with Strategically Implemented Security Measures", "authors": ["Takumi Shinohara", "Karl H. Johansson", "Henrik Sandberg"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12052v1", "summary": "This paper addresses the problem of distributed resilient state estimation\nand control for linear time-invariant systems in the presence of malicious\nfalse data injection sensor attacks and bounded noise. We consider a system\noperator (defender) capable of deploying cybersecurity measures to counteract\nthe sensor compromises. Although such measures enhance resilience against\nadversarial attacks, they may incur substantial costs; hence, it is crucial to\nselect countermeasures to balance resilience gains and cost efficiency\nstrategically. We first demonstrate that the system's resilience against\nattacks is maximized through the appropriate implementation of security\nmeasures, implying that no attacker can execute undetectable sensor attacks.\nBuilding on this analysis, we propose an algorithm that identifies the optimal\nsecurity measure. While determining this measure is NP-hard in general, we also\nderive sufficient conditions under which efficient computation is feasible.\nFurthermore, we develop a distributed resilient state estimation and control\nscheme informed by the optimal security measure and establish conditions that\nguarantee bounded estimation and control errors. Finally, we validate the\nefficacy of our approach via numerical simulations of a vehicle platooning\nscenario.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12052v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "分布式弹性状态估计与控制，并策略性地实施安全措施", "tldr": "本文提出一种算法，用于在分布式弹性状态估计与控制中寻找最优安全措施，以抵御虚假数据注入攻击，确保有界误差并最大化系统弹性。", "motivation": "解决线性时不变系统在恶意虚假数据注入传感器攻击和有界噪声下的分布式弹性状态估计与控制问题。主要动机是战略性地选择网络安全对策，以平衡弹性收益和成本效率，因为安全措施可能成本高昂。", "method": "首先证明通过适当实施安全措施可以最大化系统对攻击的弹性，使得攻击者无法执行不可检测的传感器攻击。在此基础上，提出一种识别最优安全措施的算法，并推导出在何种条件下可以高效计算（通常为NP-hard问题）。此外，开发了一种基于最优安全措施的分布式弹性状态估计与控制方案，并建立了保证有界估计和控制误差的条件。", "result": "证明了通过适当实施安全措施可以最大化系统对攻击的弹性，意味着攻击者无法执行不可检测的传感器攻击。提出了一种识别最优安全措施的算法，并推导了其高效计算的充分条件。开发了一种分布式弹性状态估计与控制方案，并建立了保证有界估计和控制误差的条件。通过车辆编队场景的数值模拟验证了方法的有效性。", "conclusion": "本文通过策略性地实施安全措施，成功解决了分布式弹性状态估计与控制问题，提出了一种最优安全措施识别算法和一种保证有界误差的控制方案，并通过仿真验证了其有效性。", "translation": "本文研究了线性时不变系统在恶意虚假数据注入传感器攻击和有界噪声存在下的分布式弹性状态估计与控制问题。我们考虑了一个系统操作员（防御者），他能够部署网络安全措施来对抗传感器受损。尽管这些措施增强了对对抗性攻击的弹性，但它们可能产生高昂的成本；因此，战略性地选择对策以平衡弹性收益和成本效率至关重要。我们首先证明，通过适当实施安全措施，系统对攻击的弹性可以最大化，这意味着攻击者无法执行不可检测的传感器攻击。在此分析的基础上，我们提出了一种识别最优安全措施的算法。虽然确定这种措施通常是NP-hard问题，但我们也推导出了可以实现高效计算的充分条件。此外，我们开发了一种由最优安全措施指导的分布式弹性状态估计与控制方案，并建立了保证有界估计和控制误差的条件。最后，我们通过车辆编队场景的数值模拟验证了我们方法的有效性。", "summary": "本文研究了线性时不变系统在虚假数据注入攻击和噪声下的分布式弹性状态估计与控制问题。它提出了一种战略性部署网络安全措施的方法，以平衡系统弹性和成本。作者证明了最优安全措施的实施可以最大化系统弹性，防止不可检测的攻击。他们提出了一种寻找最优措施的算法（解决了其NP-hard性质，并提供了高效计算的条件），并开发了相应的分布式估计与控制方案，保证了有界误差。该方法的有效性通过车辆编队仿真得到了验证。", "keywords": "分布式控制, 状态估计, 网络安全, 虚假数据注入, 弹性", "comments": "该论文解决了在攻击下平衡控制系统安全性和成本的关键实际问题。其创新点在于“策略性地实施安全措施”和寻找“最优安全措施”，特别是考虑到NP-hard问题并推导出高效计算的条件。在车辆编队场景中的验证增加了实际相关性。"}}
{"id": "2507.12168", "title": "Shape Adaptation for 3D Hairstyle Retargeting", "authors": ["Lu Yu", "Zhong Ren", "Youyi Zheng", "Xiang Chen", "Kun Zhou"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12168v1", "summary": "It is demanding to author an existing hairstyle for novel characters in games\nand VR applications. However, it is a non-trivial task for artists due to the\ncomplicated hair geometries and spatial interactions to preserve. In this\npaper, we present an automatic shape adaptation method to retarget 3D\nhairstyles. We formulate the adaptation process as a constrained optimization\nproblem, where all the shape properties and spatial relationships are converted\ninto individual objectives and constraints. To make such an optimization on\nhigh-resolution hairstyles tractable, we adopt a multi-scale strategy to\ncompute the target positions of the hair strands in a coarse-to-fine manner.\nThe global solving for the inter-strands coupling is restricted to the coarse\nlevel, and the solving for fine details is made local and parallel. In\naddition, we present a novel hairline edit tool to allow for user customization\nduring retargeting. We achieve it by solving physics-based deformations of an\nembedded membrane to redistribute the hair roots with minimal distortion. We\ndemonstrate the efficacy of our method through quantitative and qualitative\nexperiments on various hairstyles and characters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12168v1", "cate": "cs.GR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "3D发型重定向的形状自适应", "tldr": "本文提出了一种自动形状自适应方法，用于将3D发型重定向到新角色，通过约束优化、多尺度策略和发际线编辑工具实现，有效解决了艺术家手动操作的复杂性问题。", "motivation": "在游戏和VR应用中，为新角色创作现有发型对艺术家而言是一项艰巨的任务，因为头发几何形状复杂且需要保留空间相互作用。", "method": "本文提出了一种自动形状自适应方法来重定向3D发型。该方法将自适应过程表述为一个约束优化问题，将所有形状属性和空间关系转换为目标和约束。为处理高分辨率发型，采用多尺度策略，以粗到细的方式计算发丝的目标位置，其中发丝间耦合的全局求解限制在粗略级别，而细节求解则局部并行。此外，还提出了一个新颖的发际线编辑工具，通过求解嵌入膜的基于物理的变形来重新分布发根，以实现用户自定义。", "result": "该方法通过对各种发型和角色的定量和定性实验，证明了其有效性。", "conclusion": "本文提出的自动形状自适应方法能有效解决3D发型重定向的复杂问题，为艺术家提供了实用的工具。", "translation": "在游戏和VR应用中，为新角色创作现有发型是一项艰巨的任务。然而，由于复杂的头发几何形状和需要保留的空间相互作用，这对艺术家来说并非易事。在本文中，我们提出了一种自动形状自适应方法来重定向3D发型。我们将自适应过程表述为一个约束优化问题，其中所有形状属性和空间关系都被转换为独立的优化目标和约束。为了使高分辨率发型的这种优化变得可行，我们采用了一种多尺度策略，以粗到细的方式计算发丝的目标位置。发丝间耦合的全局求解被限制在粗略级别，而精细细节的求解则局部化且并行。此外，我们提出了一种新颖的发际线编辑工具，允许用户在重定向过程中进行自定义。我们通过求解嵌入膜的基于物理的变形来实现这一点，以最小失真地重新分布发根。我们通过对各种发型和角色的定量和定性实验证明了我们方法的有效性。", "summary": "本文提出了一种针对3D发型重定向的自动形状自适应方法，旨在简化艺术家为新角色创作发型的复杂过程。该方法将发型自适应建模为约束优化问题，并引入多尺度策略以有效处理高分辨率发型。为增强用户自定义能力，论文还设计了一个基于物理变形的发际线编辑工具。实验结果表明，该方法在多种发型和角色上均表现出良好的性能。", "keywords": "3D发型, 形状自适应, 发型重定向, 约束优化, 多尺度策略", "comments": "该论文的创新之处在于将3D发型重定向问题转化为一个可管理的约束优化问题，并结合多尺度策略来处理高分辨率数据，这显著提高了效率和实用性。发际线编辑工具的引入也增加了用户自定义的灵活性，使其在游戏和VR等应用中具有重要价值。"}}
{"id": "2502.05668", "title": "The late-stage training dynamics of (stochastic) subgradient descent on homogeneous neural networks", "authors": ["Sholom Schechtman", "Nicolas Schreuder"], "categories": ["cs.LG", "cs.NE", "math.OC", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted/presented at the 38th Annual Conference on Learning Theory (COLT 2025)", "url": "http://arxiv.org/abs/2502.05668v2", "summary": "We analyze the implicit bias of constant step stochastic subgradient descent\n(SGD). We consider the setting of binary classification with homogeneous neural\nnetworks - a large class of deep neural networks with ReLU-type activation\nfunctions such as MLPs and CNNs without biases. We interpret the dynamics of\nnormalized SGD iterates as an Euler-like discretization of a conservative field\nflow that is naturally associated to the normalized classification margin.\nOwing to this interpretation, we show that normalized SGD iterates converge to\nthe set of critical points of the normalized margin at late-stage training\n(i.e., assuming that the data is correctly classified with positive normalized\nmargin). Up to our knowledge, this is the first extension of the analysis of\nLyu and Li (2020) on the discrete dynamics of gradient descent to the nonsmooth\nand stochastic setting. Our main result applies to binary classification with\nexponential or logistic losses. We additionally discuss extensions to more\ngeneral settings.", "comment": "Accepted/presented at the 38th Annual Conference on Learning Theory\n  (COLT 2025)", "pdf_url": "http://arxiv.org/pdf/2502.05668v2", "cate": "cs.LG", "date": "2025-02-08", "updated": "2025-07-16", "AI": {"title_translation": "同质神经网络上（随机）次梯度下降的后期训练动态", "tldr": "分析了常数步长随机次梯度下降（SGD）在同质神经网络上的隐式偏差，表明归一化SGD迭代在训练后期收敛到归一化边际的临界点。", "motivation": "分析常数步长随机次梯度下降（SGD）在同质神经网络上的隐式偏差，并将现有梯度下降分析扩展到非光滑和随机设置。", "method": "研究了二元分类场景下的同质神经网络（如无偏置的MLP和CNN），并将归一化SGD迭代的动态解释为与归一化分类边际相关的保守场流的类欧拉离散化，并基于此证明了收敛性。", "result": "归一化SGD迭代在训练后期（假设数据被正确分类且具有正归一化边际）收敛到归一化边际的临界点集。这是首次将Lyu和Li（2020）的梯度下降离散动态分析扩展到非光滑和随机设置。主要结果适用于使用指数或逻辑损失的二元分类。", "conclusion": "在同质神经网络上，归一化SGD迭代在训练后期收敛到归一化边际的临界点，这为理解其在非光滑和随机场景中的隐式偏差提供了理论基础。", "translation": "我们分析了常数步长随机次梯度下降（SGD）的隐式偏差。我们考虑了使用同质神经网络进行二元分类的设置——这是一大类具有ReLU型激活函数的深度神经网络，例如不带偏置的MLP和CNN。我们将归一化SGD迭代的动态解释为与归一化分类边际自然相关的保守场流的类欧拉离散化。由于这种解释，我们表明归一化SGD迭代在训练后期（即，假设数据被正确分类并具有正的归一化边际）收敛到归一化边际的临界点集。据我们所知，这是Lyu和Li（2020）关于梯度下降离散动态分析首次扩展到非光滑和随机设置。我们的主要结果适用于使用指数或逻辑损失的二元分类。我们还讨论了向更一般设置的扩展。", "summary": "本文研究了常数步长随机次梯度下降（SGD）应用于同质神经网络进行二元分类时的隐式偏差。通过将归一化SGD的动态解释为与归一化分类边际相关的离散保守场流，作者证明了归一化SGD迭代在训练后期收敛到该边际的临界点。这项工作将先前的梯度下降分析扩展到非光滑和随机环境，并适用于二元分类中的指数或逻辑损失。", "keywords": "随机次梯度下降, 同质神经网络, 隐式偏差, 后期训练, 二元分类", "comments": "该论文通过将梯度下降动态分析扩展到次梯度下降的更复杂的非光滑和随机设置，特别是对于同质神经网络，做出了重要的理论贡献。将SGD动态解释为保守场流具有创新性，为理解其在深度学习中的隐式偏差和收敛特性提供了新的视角。"}}
{"id": "2507.11620", "title": "Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification", "authors": ["Steven Dillmann", "Juan Rafael Martínez-Galarza"], "categories": ["cs.LG", "astro-ph.HE", "astro-ph.IM", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at the 2025 ICML Workshop on Machine Learning for Astrophysics, Code available at: this https URL", "url": "http://arxiv.org/abs/2507.11620v1", "summary": "Event time series are sequences of discrete events occurring at irregular\ntime intervals, each associated with a domain-specific observational modality.\nThey are common in domains such as high-energy astrophysics, computational\nsocial science, cybersecurity, finance, healthcare, neuroscience, and\nseismology. Their unstructured and irregular structure poses significant\nchallenges for extracting meaningful patterns and identifying salient phenomena\nusing conventional techniques. We propose novel two- and three-dimensional\ntensor representations for event time series, coupled with sparse autoencoders\nthat learn physically meaningful latent representations. These embeddings\nsupport a variety of downstream tasks, including anomaly detection,\nsimilarity-based retrieval, semantic clustering, and unsupervised\nclassification. We demonstrate our approach on a real-world dataset from X-ray\nastronomy, showing that these representations successfully capture temporal and\nspectral signatures and isolate diverse classes of X-ray transients. Our\nframework offers a flexible, scalable, and generalizable solution for analyzing\ncomplex, irregular event time series across scientific and industrial domains.", "comment": "Accepted at the 2025 ICML Workshop on Machine Learning for\n  Astrophysics, Code available at:\n  https://github.com/StevenDillmann/ml-xraytransients-mnras", "pdf_url": "http://arxiv.org/pdf/2507.11620v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "使用稀疏自编码器学习事件时间序列表示，用于异常检测、相似性搜索和无监督分类", "tldr": "本文提出了一种利用新型张量表示和稀疏自编码器处理不规则事件时间序列的方法，以实现异常检测、相似性搜索和无监督分类，并在X射线天文学数据上取得了成功。", "motivation": "事件时间序列具有非结构化和不规则的特点，使得传统技术难以从中提取有意义的模式和识别显著现象，这在天体物理学、计算社会科学、网络安全、金融、医疗、神经科学和地震学等领域普遍存在。", "method": "本文提出了用于事件时间序列的二维和三维张量表示，并结合稀疏自编码器来学习具有物理意义的潜在表示。这些嵌入支持异常检测、基于相似性的检索、语义聚类和无监督分类等下游任务。", "result": "在X射线天文学的真实世界数据集上，该方法成功捕获了时间和光谱特征，并分离出不同类别的X射线瞬变现象。", "conclusion": "该框架为分析跨科学和工业领域的复杂、不规则事件时间序列提供了一个灵活、可扩展和通用的解决方案。", "translation": "事件时间序列是离散事件以不规则时间间隔发生的序列，每个事件都与领域特定的观测模态相关联。它们在高能天体物理学、计算社会科学、网络安全、金融、医疗保健、神经科学和地震学等领域很常见。其非结构化和不规则的结构对使用传统技术提取有意义的模式和识别显著现象构成了重大挑战。我们提出了新颖的二维和三维张量表示用于事件时间序列，并结合稀疏自编码器来学习具有物理意义的潜在表示。这些嵌入支持各种下游任务，包括异常检测、基于相似性的检索、语义聚类和无监督分类。我们在来自X射线天文学的真实世界数据集上演示了我们的方法，表明这些表示成功捕获了时间和光谱特征并分离出不同类别的X射线瞬变现象。我们的框架为分析跨科学和工业领域的复杂、不规则事件时间序列提供了一个灵活、可扩展和通用的解决方案。", "summary": "本文提出了一种处理不规则事件时间序列的新方法，通过构建二维和三维张量表示，并结合稀疏自编码器学习有意义的潜在特征。这些表示能够支持异常检测、相似性搜索和无监督分类等多种下游任务。该方法在X射线天文学数据集上得到验证，成功捕捉了时空特征并识别了瞬变类别，为复杂事件时间序列分析提供了通用、灵活且可扩展的解决方案。", "keywords": "事件时间序列, 稀疏自编码器, 异常检测, 张量表示, 无监督分类", "comments": "这项工作创新性地将事件时间序列的复杂性通过多维张量表示和稀疏自编码器进行有效处理，解决了传统方法难以应对的非结构化和不规则数据挑战。其重要性在于提供了一个跨领域通用的解决方案，尤其在数据稀疏和结构不定的场景下具有显著的应用潜力。其灵活性、可扩展性和泛化能力是其主要亮点。"}}
{"id": "2507.11789", "title": "Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation", "authors": ["Alessandro Palma", "Sergei Rybakov", "Leon Hetzel", "Stephan Günnemann", "Fabian J. Theis"], "categories": ["cs.LG", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      31 pages, 14 figures", "url": "http://arxiv.org/abs/2507.11789v1", "summary": "Latent space interpolations are a powerful tool for navigating deep\ngenerative models in applied settings. An example is single-cell RNA\nsequencing, where existing methods model cellular state transitions as latent\nspace interpolations with variational autoencoders, often assuming linear\nshifts and Euclidean geometry. However, unless explicitly enforced, linear\ninterpolations in the latent space may not correspond to geodesic paths on the\ndata manifold, limiting methods that assume Euclidean geometry in the data\nrepresentations. We introduce FlatVI, a novel training framework that\nregularises the latent manifold of discrete-likelihood variational autoencoders\ntowards Euclidean geometry, specifically tailored for modelling single-cell\ncount data. By encouraging straight lines in the latent space to approximate\ngeodesic interpolations on the decoded single-cell manifold, FlatVI enhances\ncompatibility with downstream approaches that assume Euclidean latent geometry.\nExperiments on synthetic data support the theoretical soundness of our\napproach, while applications to time-resolved single-cell RNA sequencing data\ndemonstrate improved trajectory reconstruction and manifold interpolation.", "comment": "31 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.11789v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "在单细胞VAE中强制执行潜在欧几里得几何以实现流形插值", "tldr": "FlatVI是一种新的训练框架，它将单细胞VAE的潜在流形正则化为欧几里得几何，以改进数据流形上的测地线插值，从而增强与假设欧几里得潜在几何的下游方法的兼容性。", "motivation": "现有的单细胞RNA测序方法在潜在空间中对细胞状态转换进行建模时，通常假设线性平移和欧几里得几何。然而，除非明确强制执行，潜在空间中的线性插值可能不对应于数据流形上的测地线路径，这限制了假设数据表示中欧几里得几何的方法。", "method": "引入FlatVI，这是一种新颖的训练框架，它将离散似然变分自编码器（VAEs）的潜在流形正则化为欧几里得几何，专门用于建模单细胞计数数据。通过鼓励潜在空间中的直线近似解码单细胞流形上的测地线插值。", "result": "在合成数据上的实验支持了该方法的理论健全性；应用于时间分辨单细胞RNA测序数据时，展示了改进的轨迹重建和流形插值。", "conclusion": "FlatVI通过强制潜在空间中的欧几里得几何来提高单细胞VAE与假设欧几里得潜在几何的下游方法的兼容性，从而改进了流形插值和轨迹重建。", "translation": "潜在空间插值是导航深度生成模型在应用设置中的强大工具。一个例子是单细胞RNA测序，其中现有方法将细胞状态转换建模为带有变分自编码器的潜在空间插值，通常假设线性平移和欧几里得几何。然而，除非明确强制执行，潜在空间中的线性插值可能不对应于数据流形上的测地线路径，这限制了假设数据表示中欧几里得几何的方法。我们引入了FlatVI，这是一种新颖的训练框架，它将离散似然变分自编码器的潜在流形正则化为欧几里得几何，专门为建模单细胞计数数据而定制。通过鼓励潜在空间中的直线近似解码单细胞流形上的测地线插值，FlatVI增强了与假设欧几里得潜在几何的下游方法的兼容性。在合成数据上的实验支持了我们方法的理论健全性，而应用于时间分辨单细胞RNA测序数据则展示了改进的轨迹重建和流形插值。", "summary": "本文提出了FlatVI，一个针对单细胞RNA测序数据的新型训练框架。它通过正则化离散似然变分自编码器的潜在流形使其趋向欧几里得几何，以确保潜在空间中的线性插值能更好地近似数据流形上的测地线路径。这解决了现有方法在假设欧几里得几何时可能遇到的限制，并提高了与下游欧几里得假设方法的兼容性。实验证明FlatVI在理论上是健全的，并在实际单细胞数据上改进了轨迹重建和流形插值。", "keywords": "单细胞RNA测序, 变分自编码器, 欧几里得几何, 流形插值, 测地线", "comments": "FlatVI的创新之处在于明确地在单细胞VAEs的潜在空间中强制执行欧几里得几何，以解决现有方法中线性插值与数据流形测地线不一致的问题。这对于依赖潜在空间欧几里得假设的下游分析（如轨迹推断）具有重要意义。"}}
{"id": "2507.11919", "title": "STFT-based Time-Frequency Mode Decomposition: A Fast and Robust Method for Multicomponent Signal Analysis", "authors": ["Wei Zhou", "Wei-Jian Li", "Wei-Xin Ren"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11919v1", "summary": "The decomposition of complex, multicomponent, and non-stationary signals into\ntheir constituent modes is a fundamental yet significant challenge in science\nand engineering. Existing methods often struggle with a trade-off among\naccuracy, computational cost, and the need for prior information such as the\nnumber of modes. This paper introduces time-frequency mode decomposition\n(TFMD), a novel framework for the fast, robust, and adaptive decomposition of\nsuch signals. TFMD operates on the principle that modes form contiguous\nhigh-energy regions in the time-frequency domain. Its non-iterative pipeline\nreframes signal decomposition as an image segmentation task: a signal is\ntransformed into a spectrogram, which is then smoothed to enhance the\ncontinuity of these high-energy regions. A sequence of adaptive thresholding\nand connected-component labeling with size-based filtering is then employed to\nautomatically segment the spectrogram and generate a mask for each mode. The\nmodes are finally reconstructed via the inverse short-time Fourier transform.\nValidation on diverse synthetic signals demonstrates that TFMD accurately\ndetermines the number of modes and reconstructs them with high fidelity. Its\nperformance is particularly strong in high-noise conditions. A comparative\nanalysis confirms that TFMD provides robust, competitive performance across a\nwider variety of signal types, while a theoretical complexity analysis reveals\nits superior computational efficiency stemming from its non-iterative design.\nThe method's practical utility is further demonstrated by successfully\nextracting modal responses from a real-world footbridge vibration signal. TFMD\nprovides a computationally efficient and powerful paradigm for multicomponent\nsignal analysis, offering a compelling balance of accuracy, versatility, and\nefficiency for large-scale or time-sensitive applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11919v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于STFT的时频模态分解：一种用于多分量信号分析的快速鲁棒方法", "tldr": "本文提出了一种名为时频模态分解（TFMD）的新型框架，它通过将信号分解重构为图像分割任务，实现了对复杂多分量非平稳信号的快速、鲁棒和自适应分解。", "motivation": "将复杂、多分量、非平稳信号分解成其组成模态是科学和工程领域一个基本而重要的挑战。现有方法在准确性、计算成本以及对模态数量等先验信息的需求之间常常面临权衡。", "method": "TFMD基于模态在时频域中形成连续高能区域的原理。其非迭代流程将信号分解重新定义为图像分割任务：首先将信号转换为频谱图，然后对其进行平滑处理以增强高能区域的连续性。接着，采用一系列自适应阈值处理和基于大小过滤的连通分量标记来自动分割频谱图并为每个模态生成掩码。最后，通过逆短时傅里叶变换重建模态。", "result": "在多种合成信号上的验证表明，TFMD能够准确确定模态数量并高保真地重建它们，尤其在强噪声条件下表现出色。比较分析证实TFMD在更广泛的信号类型上提供了鲁棒且具有竞争力的性能。理论复杂性分析揭示了其非迭代设计带来的卓越计算效率。在真实世界人行天桥振动信号上成功提取模态响应进一步证明了其实用性。", "conclusion": "TFMD为多分量信号分析提供了一种计算高效且强大的范式，在准确性、多功能性和效率之间取得了引人注目的平衡，适用于大规模或时间敏感的应用。", "translation": "将复杂、多分量、非平稳信号分解成其组成模态是科学和工程领域一个基本而重要的挑战。现有方法在准确性、计算成本以及对模态数量等先验信息的需求之间常常面临权衡。本文介绍了一种时频模态分解（TFMD）的新型框架，用于此类信号的快速、鲁棒和自适应分解。TFMD基于模态在时频域中形成连续高能区域的原理。其非迭代流程将信号分解重新定义为图像分割任务：一个信号被转换为频谱图，然后对其进行平滑处理以增强这些高能区域的连续性。接着，采用一系列自适应阈值处理和基于大小过滤的连通分量标记来自动分割频谱图并为每个模态生成掩码。最后，通过逆短时傅里叶变换重建模态。在多种合成信号上的验证表明，TFMD能够准确确定模态数量并高保真地重建它们。其性能在强噪声条件下尤其突出。比较分析证实，TFMD在更广泛的信号类型上提供了鲁棒且具有竞争力的性能，而理论复杂性分析揭示了其非迭代设计带来的卓越计算效率。该方法在从真实世界人行天桥振动信号中成功提取模态响应方面进一步展示了其实用性。TFMD为多分量信号分析提供了一种计算高效且强大的范式，在准确性、多功能性和效率之间取得了引人注目的平衡，适用于大规模或时间敏感的应用。", "summary": "本文提出了一种基于短时傅里叶变换（STFT）的新型时频模态分解（TFMD）方法，旨在解决复杂多分量非平稳信号分解中现有方法面临的准确性、计算成本和先验信息需求之间的权衡问题。TFMD将信号分解视为图像分割任务：通过对信号频谱图进行平滑、自适应阈值和连通分量标记来识别并提取模态。该方法是非迭代的，因此计算效率高，并在合成信号和真实世界数据上表现出高精度和鲁棒性，尤其是在高噪声环境下。TFMD为多分量信号分析提供了一种高效、准确且通用的解决方案。", "keywords": "时频模态分解, 多分量信号分析, 图像分割, 非迭代, 短时傅里叶变换", "comments": "该论文创新性地将信号分解问题转化为图像分割任务，利用时频域中模态的连续性特性。其非迭代设计显著提升了计算效率，解决了现有方法在准确性与计算成本之间的固有矛盾，尤其适用于大规模或实时性要求高的应用。在强噪声条件下的优异表现也增加了其实用价值。"}}
{"id": "2507.12416", "title": "QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval", "authors": ["Jaehyun Kwak", "Ramahdani Muhammad Izaaz Inhar", "Se-Young Yun", "Sung-Ju Lee"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICML 2025", "url": "http://arxiv.org/abs/2507.12416v1", "summary": "Composed Image Retrieval (CIR) retrieves relevant images based on a reference\nimage and accompanying text describing desired modifications. However, existing\nCIR methods only focus on retrieving the target image and disregard the\nrelevance of other images. This limitation arises because most methods\nemploying contrastive learning-which treats the target image as positive and\nall other images in the batch as negatives-can inadvertently include false\nnegatives. This may result in retrieving irrelevant images, reducing user\nsatisfaction even when the target image is retrieved. To address this issue, we\npropose Query-Relevant Retrieval through Hard Negative Sampling (QuRe), which\noptimizes a reward model objective to reduce false negatives. Additionally, we\nintroduce a hard negative sampling strategy that selects images positioned\nbetween two steep drops in relevance scores following the target image, to\neffectively filter false negatives. In order to evaluate CIR models on their\nalignment with human satisfaction, we create Human-Preference FashionIQ\n(HP-FashionIQ), a new dataset that explicitly captures user preferences beyond\ntarget retrieval. Extensive experiments demonstrate that QuRe achieves\nstate-of-the-art performance on FashionIQ and CIRR datasets while exhibiting\nthe strongest alignment with human preferences on the HP-FashionIQ dataset. The\nsource code is available at https://github.com/jackwaky/QuRe.", "comment": "Accepted to ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.12416v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "QuRe：通过在组合图像检索中进行难负例采样实现查询相关检索", "tldr": "QuRe通过硬负例采样和奖励模型优化组合图像检索，解决现有方法中存在的假负例问题，提高了用户满意度和检索性能。", "motivation": "现有组合图像检索（CIR）方法只关注检索目标图像，忽略其他图像的相关性，且在对比学习中可能引入假负例，导致检索不相关图像，降低用户满意度。", "method": "本文提出了通过硬负例采样的查询相关检索（QuRe）方法，通过优化奖励模型目标来减少假负例。引入了一种硬负例采样策略，选择相关性得分在目标图像后两个陡降点之间的图像，以有效过滤假负例。同时，创建了Human-Preference FashionIQ（HP-FashionIQ）新数据集，用于评估CIR模型与人类满意度的一致性。", "result": "QuRe在FashionIQ和CIRR数据集上实现了最先进的性能，并在HP-FashionIQ数据集上表现出与人类偏好最强的一致性。", "conclusion": "QuRe通过有效处理假负例和更好地对齐人类偏好，显著提升了组合图像检索的性能和用户满意度。", "translation": "组合图像检索（CIR）根据参考图像和描述所需修改的附带文本来检索相关图像。然而，现有的CIR方法只关注检索目标图像，而忽视了其他图像的相关性。这种局限性产生于大多数采用对比学习——将目标图像视为正例，批次中所有其他图像视为负例——的方法可能会无意中包含假负例。这可能导致检索到不相关的图像，即使目标图像被检索到，也会降低用户满意度。为了解决这个问题，我们提出了通过硬负例采样的查询相关检索（QuRe），它优化了一个奖励模型目标以减少假负例。此外，我们引入了一种硬负例采样策略，选择位于目标图像后相关性得分的两个陡降点之间的图像，以有效过滤假负例。为了评估CIR模型与人类满意度的一致性，我们创建了Human-Preference FashionIQ（HP-FashionIQ），这是一个明确捕捉目标检索之外用户偏好的新数据集。广泛的实验表明，QuRe在FashionIQ和CIRR数据集上实现了最先进的性能，同时在HP-FashionIQ数据集上表现出与人类偏好最强的一致性。源代码可在https://github.com/jackwaky/QuRe获取。", "summary": "本文提出了一种名为 QuRe 的组合图像检索（CIR）方法，旨在解决现有方法中因假负例导致的检索不相关图像和用户满意度降低的问题。QuRe 通过优化奖励模型目标来减少假负例，并引入了一种硬负例采样策略，以有效过滤这些假负例。为更好地评估模型与人类满意度的一致性，作者还构建了 Human-Preference FashionIQ (HP-FashionIQ) 数据集。实验结果表明，QuRe 在多个标准数据集上达到了最先进的性能，并与人类偏好高度吻合。", "keywords": "组合图像检索, 硬负例采样, 查询相关检索, 奖励模型, 用户偏好", "comments": "QuRe的创新在于其针对组合图像检索中假负例问题的解决方案，特别是通过奖励模型优化和新颖的硬负例采样策略。此外，创建HP-FashionIQ数据集以更好地衡量与人类满意度的一致性，是评估和推动该领域发展的重要贡献。该方法不仅提高了检索准确性，也提升了用户体验。"}}
{"id": "2503.12335", "title": "GS-I$^{3}$: Gaussian Splatting for Surface Reconstruction from Illumination-Inconsistent Images", "authors": ["Tengfei Wang", "Xin Wang", "Yongmao Hou", "Zhaoning Zhang", "Yiwei Xu", "Zongqian Zhan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.12335v3", "summary": "Accurate geometric surface reconstruction, providing essential environmental\ninformation for navigation and manipulation tasks, is critical for enabling\nrobotic self-exploration and interaction. Recently, 3D Gaussian Splatting\n(3DGS) has gained significant attention in the field of surface reconstruction\ndue to its impressive geometric quality and computational efficiency. While\nrecent relevant advancements in novel view synthesis under inconsistent\nillumination using 3DGS have shown promise, the challenge of robust surface\nreconstruction under such conditions is still being explored. To address this\nchallenge, we propose a method called GS-3I. Specifically, to mitigate 3D\nGaussian optimization bias caused by underexposed regions in single-view\nimages, based on Convolutional Neural Network (CNN), a tone mapping correction\nframework is introduced. Furthermore, inconsistent lighting across multi-view\nimages, resulting from variations in camera settings and complex scene\nillumination, often leads to geometric constraint mismatches and deviations in\nthe reconstructed surface. To overcome this, we propose a normal compensation\nmechanism that integrates reference normals extracted from single-view image\nwith normals computed from multi-view observations to effectively constrain\ngeometric inconsistencies. Extensive experimental evaluations demonstrate that\nGS-3I can achieve robust and accurate surface reconstruction across complex\nillumination scenarios, highlighting its effectiveness and versatility in this\ncritical challenge. https://github.com/TFwang-9527/GS-3I", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.12335v3", "cate": "cs.CV", "date": "2025-03-16", "updated": "2025-07-16", "AI": {"title_translation": "GS-I$^{3}$: 基于高斯溅射的照度不一致图像表面重建", "tldr": "提出GS-3I方法，通过色调映射校正和法线补偿机制，实现了在光照不一致条件下鲁棒且准确的表面重建。", "motivation": "准确的几何表面重建对于机器人自主探索和交互至关重要。尽管3DGS在表面重建中表现出色，但在光照不一致条件下的鲁棒表面重建仍然是一个挑战。", "method": "本文提出GS-3I方法，旨在解决光照不一致图像下的表面重建问题。该方法包含两个主要组件：1. 基于卷积神经网络（CNN）的色调映射校正框架，用于减轻单视角图像中曝光不足区域导致的3D高斯优化偏差。2. 法线补偿机制，通过整合从单视角图像中提取的参考法线与从多视角观测中计算出的法线，以有效约束因多视角光照不一致引起的几何不匹配和偏差。", "result": "广泛的实验评估表明，GS-3I能够在复杂光照场景下实现鲁棒且准确的表面重建。", "conclusion": "GS-3I在解决复杂光照场景下鲁棒表面重建这一关键挑战中，展现出其有效性和多功能性。", "translation": "准确的几何表面重建，为导航和操作任务提供必要的环境信息，对于实现机器人自主探索和交互至关重要。最近，3D高斯溅射（3DGS）因其令人印象深刻的几何质量和计算效率，在表面重建领域获得了广泛关注。尽管最近在利用3DGS进行光照不一致条件下的新视图合成方面取得了相关进展，并展现出前景，但在这种条件下进行鲁棒表面重建的挑战仍在探索中。为了解决这一挑战，我们提出了一种名为GS-3I的方法。具体来说，为了减轻单视角图像中曝光不足区域导致的3D高斯优化偏差，我们引入了一个基于卷积神经网络（CNN）的色调映射校正框架。此外，由于相机设置和复杂场景光照的变化，多视角图像间不一致的光照常常导致几何约束不匹配和重建表面偏差。为了克服这一点，我们提出了一种法线补偿机制，该机制将从单视角图像中提取的参考法线与从多视角观测中计算出的法线相结合，以有效约束几何不一致性。广泛的实验评估表明，GS-3I能够在复杂光照场景下实现鲁棒且准确的表面重建，突显了其在这一关键挑战中的有效性和多功能性。", "summary": "本文提出了GS-3I方法，旨在解决光照不一致图像下的鲁棒表面重建问题。该方法引入了基于CNN的色调映射校正框架，以处理单视角图像中的曝光不足问题，并提出了法线补偿机制，通过结合单视角和多视角法线来解决多视角光照不一致导致的几何偏差。实验证明GS-3I在复杂光照条件下能够实现准确且鲁棒的表面重建。", "keywords": "3D高斯溅射, 表面重建, 光照不一致, 色调映射, 法线补偿", "comments": "该论文提出了一种创新的方法GS-3I，通过结合色调映射校正和法线补偿机制，有效地解决了3DGS在光照不一致图像下进行表面重建的挑战。其创新性在于针对光照变化带来的具体问题（曝光不足和几何不一致）提出了有针对性的解决方案，提高了重建的鲁棒性和准确性。"}}
{"id": "2507.11848", "title": "Interactive Hybrid Rice Breeding with Parametric Dual Projection", "authors": ["Changjian Chen", "Pengcheng Wang", "Fei Lyu", "Zhuo Tang", "Li Yang", "Long Wang", "Yong Cai", "Feng Yu", "Kenli Li"], "categories": ["cs.HC", "cs.AI", "q-bio.QM"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11848v1", "summary": "Hybrid rice breeding crossbreeds different rice lines and cultivates the\nresulting hybrids in fields to select those with desirable agronomic traits,\nsuch as higher yields. Recently, genomic selection has emerged as an efficient\nway for hybrid rice breeding. It predicts the traits of hybrids based on their\ngenes, which helps exclude many undesired hybrids, largely reducing the\nworkload of field cultivation. However, due to the limited accuracy of genomic\nprediction models, breeders still need to combine their experience with the\nmodels to identify regulatory genes that control traits and select hybrids,\nwhich remains a time-consuming process. To ease this process, in this paper, we\nproposed a visual analysis method to facilitate interactive hybrid rice\nbreeding. Regulatory gene identification and hybrid selection naturally\nensemble a dual-analysis task. Therefore, we developed a parametric dual\nprojection method with theoretical guarantees to facilitate interactive dual\nanalysis. Based on this dual projection method, we further developed a gene\nvisualization and a hybrid visualization to verify the identified regulatory\ngenes and hybrids. The effectiveness of our method is demonstrated through the\nquantitative evaluation of the parametric dual projection method, identified\nregulatory genes and desired hybrids in the case study, and positive feedback\nfrom breeders.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11848v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "交互式杂交水稻育种与参数化双重投影", "tldr": "本文提出了一种交互式可视化分析方法，通过参数化双重投影来辅助杂交水稻育种中的调控基因识别和杂交种选择，以提高效率。", "motivation": "杂交水稻育种中，基因组选择预测模型准确性有限，育种专家仍需结合经验识别调控基因和选择杂交种，这个过程耗时。", "method": "提出了一种可视化分析方法，旨在促进交互式杂交水稻育种。开发了一种具有理论保障的参数化双重投影方法，以促进交互式双重分析（调控基因识别和杂交种选择）。在此基础上，进一步开发了基因可视化和杂交种可视化。", "result": "通过参数化双重投影方法的定量评估、案例研究中识别的调控基因和所需杂交种，以及育种专家的积极反馈，证明了该方法的有效性。", "conclusion": "该可视化分析方法，特别是参数化双重投影，能够有效辅助杂交水稻育种中耗时的调控基因识别和杂交种选择过程，提高了育种效率。", "translation": "杂交水稻育种是通过杂交不同的水稻品系，并在田间种植所得杂交种，以选择具有所需农艺性状（如更高产量）的个体。最近，基因组选择已成为杂交水稻育种的一种高效方法。它根据杂交种的基因预测其性状，有助于排除许多不需要的杂交种，大大减少了田间种植的工作量。然而，由于基因组预测模型的准确性有限，育种专家仍然需要将他们的经验与模型相结合，以识别控制性状的调控基因并选择杂交种，这仍然是一个耗时的过程。为了简化这一过程，本文提出了一种可视化分析方法，以促进交互式杂交水稻育种。调控基因识别和杂交种选择自然地构成了一个双重分析任务。因此，我们开发了一种具有理论保障的参数化双重投影方法，以促进交互式双重分析。基于这种双重投影方法，我们进一步开发了基因可视化和杂交种可视化，以验证所识别的调控基因和杂交种。通过对参数化双重投影方法的定量评估、案例研究中识别的调控基因和所需杂交种，以及育种专家的积极反馈，证明了我们方法的有效性。", "summary": "本文提出了一种创新的交互式可视化分析方法，旨在解决杂交水稻育种中基因组预测模型准确性不足导致的人工经验耗时问题。核心是开发了一种具有理论保障的参数化双重投影方法，用于同时进行调控基因识别和杂交种选择的双重分析。此外，还设计了相应的基因和杂交种可视化工具。通过定量评估、案例研究和育种专家反馈，验证了该方法在提高育种效率方面的有效性。", "keywords": "杂交水稻育种, 基因组选择, 可视化分析, 参数化双重投影, 交互式育种", "comments": "这篇论文通过引入交互式可视化和参数化双重投影，有效地解决了基因组选择在杂交水稻育种中准确性不足导致的人工干预耗时问题。其创新点在于将调控基因识别和杂交种选择视为一个双重分析任务，并提出了一个有理论保障的通用框架。结合可视化工具，极大地提升了育种效率，具有重要的实际应用价值。"}}
{"id": "2507.12009", "title": "Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli", "authors": ["Florian David", "Michael Chan", "Elenor Morgenroth", "Patrik Vuilleumier", "Dimitri Van De Ville"], "categories": ["cs.CV", "cs.HC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted in International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) 2025", "url": "http://arxiv.org/abs/2507.12009v1", "summary": "We propose an end-to-end deep neural encoder-decoder model to encode and\ndecode brain activity in response to naturalistic stimuli using functional\nmagnetic resonance imaging (fMRI) data. Leveraging temporally correlated input\nfrom consecutive film frames, we employ temporal convolutional layers in our\narchitecture, which effectively allows to bridge the temporal resolution gap\nbetween natural movie stimuli and fMRI acquisitions. Our model predicts\nactivity of voxels in and around the visual cortex and performs reconstruction\nof corresponding visual inputs from neural activity. Finally, we investigate\nbrain regions contributing to visual decoding through saliency maps. We find\nthat the most contributing regions are the middle occipital area, the fusiform\narea, and the calcarine, respectively employed in shape perception, complex\nrecognition (in particular face perception), and basic visual features such as\nedges and contrasts. These functions being strongly solicited are in line with\nthe decoder's capability to reconstruct edges, faces, and contrasts. All in\nall, this suggests the possibility to probe our understanding of visual\nprocessing in films using as a proxy the behaviour of deep learning models such\nas the one proposed in this paper.", "comment": "Accepted in International Conference of the IEEE Engineering in\n  Medicine and Biology Society (EMBC) 2025", "pdf_url": "http://arxiv.org/pdf/2507.12009v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "深度神经编码器-解码器模型关联fMRI大脑活动与自然刺激", "tldr": "本文提出了一个端到端深度神经编码器-解码器模型，用于编码和解码fMRI数据中对自然刺激（电影帧）的大脑活动。该模型利用时间卷积层弥补了电影刺激和fMRI采集之间的时间分辨率差距，能够预测视觉皮层活动并从神经活动中重建视觉输入。研究发现，中枕叶、梭状回和距状沟等区域对视觉解码贡献最大，这与解码器重建边缘、面部和对比度的能力一致，表明可以通过深度学习模型探测电影中视觉处理的理解。", "motivation": "研究旨在利用功能性磁共振成像（fMRI）数据，建立一个端到端的深度神经网络模型，以编码和解码大脑对自然刺激（如电影）的活动，进而理解大脑如何处理这些复杂的视觉信息。", "method": "本文提出了一个端到端深度神经编码器-解码器模型。该模型利用时间卷积层处理连续电影帧的输入，以弥合自然电影刺激与fMRI采集之间的时间分辨率差距。模型能够预测视觉皮层内外体素的活动，并从神经活动中重建相应的视觉输入。此外，通过显著性图谱来研究对视觉解码有贡献的脑区。", "result": "模型能够预测视觉皮层内外体素的活动，并成功从神经活动中重建对应的视觉输入。通过显著性图谱分析，发现对视觉解码贡献最大的区域分别是中枕叶、梭状回和距状沟。这些区域分别负责形状感知、复杂识别（特别是面部感知）以及基本视觉特征（如边缘和对比度），这与解码器重建边缘、面部和对比度的能力高度一致。", "conclusion": "研究结果表明，本文提出的深度学习模型能够作为探究大脑在电影中视觉处理过程的有效工具。", "translation": "我们提出了一个端到端的深度神经编码器-解码器模型，用于编码和解码对自然刺激的大脑活动，使用功能性磁共振成像（fMRI）数据。利用来自连续电影帧的时间相关输入，我们在架构中采用了时间卷积层，这有效地弥合了自然电影刺激和fMRI采集之间的时间分辨率差距。我们的模型预测了视觉皮层内外体素的活动，并从神经活动中重建了相应的视觉输入。最后，我们通过显著性图谱研究了对视觉解码有贡献的脑区。我们发现贡献最大的区域分别是中枕叶、梭状回和距状沟，它们分别参与形状感知、复杂识别（特别是面部感知）以及基本视觉特征如边缘和对比度。这些功能被强烈调动，与解码器重建边缘、面部和对比度的能力一致。总而言之，这表明通过本文提出的深度学习模型的行为，可以探究我们对电影中视觉处理的理解。", "summary": "本文提出了一种端到端的深度神经编码器-解码器模型，旨在利用fMRI数据关联大脑活动与自然电影刺激。该模型采用时间卷积层以克服电影刺激与fMRI采集的时间分辨率差异，能够预测视觉皮层体素活动并从神经活动中重建视觉输入。研究发现，中枕叶、梭状回和距状沟是主要的贡献脑区，其功能与模型重建边缘、面部和对比度的能力相符。这表明该深度学习模型可作为理解大脑在观看电影时视觉处理机制的有效工具。", "keywords": "fMRI, 深度学习, 编码器-解码器, 视觉处理, 自然刺激", "comments": "该论文的创新点在于提出了一个端到端的深度神经编码器-解码器模型来直接关联fMRI脑活动与自然刺激，并通过时间卷积层有效解决了电影刺激与fMRI时间分辨率不匹配的问题。通过显著性图谱定位对视觉解码贡献的脑区，并将其与模型重建能力相结合，为理解大脑视觉处理提供了新的视角。该方法为利用深度学习模型作为代理来探究复杂认知过程（如视觉处理）提供了可能性，具有重要的研究价值。"}}
{"id": "2504.17791", "title": "LiDPM: Rethinking Point Diffusion for Lidar Scene Completion", "authors": ["Tetiana Martyniuk", "Gilles Puy", "Alexandre Boulch", "Renaud Marlet", "Raoul de Charette"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE IV 2025 (Oral); v2 - updated quantitative results based on the metrics (Voxel IoU) calculation code corrections", "url": "http://arxiv.org/abs/2504.17791v2", "summary": "Training diffusion models that work directly on lidar points at the scale of\noutdoor scenes is challenging due to the difficulty of generating fine-grained\ndetails from white noise over a broad field of view. The latest works\naddressing scene completion with diffusion models tackle this problem by\nreformulating the original DDPM as a local diffusion process. It contrasts with\nthe common practice of operating at the level of objects, where vanilla DDPMs\nare currently used. In this work, we close the gap between these two lines of\nwork. We identify approximations in the local diffusion formulation, show that\nthey are not required to operate at the scene level, and that a vanilla DDPM\nwith a well-chosen starting point is enough for completion. Finally, we\ndemonstrate that our method, LiDPM, leads to better results in scene completion\non SemanticKITTI. The project page is https://astra-vision.github.io/LiDPM .", "comment": "Accepted to IEEE IV 2025 (Oral); v2 - updated quantitative results\n  based on the metrics (Voxel IoU) calculation code corrections", "pdf_url": "http://arxiv.org/pdf/2504.17791v2", "cate": "cs.CV", "date": "2025-04-24", "updated": "2025-07-16", "AI": {"title_translation": "LiDPM：重新思考激光雷达场景补全的点扩散模型", "tldr": "LiDPM简化了激光雷达场景补全的扩散模型，证明标准DDPM在适当起点下足以完成任务，并在SemanticKITTI上取得更好效果。", "motivation": "训练直接作用于激光雷达点云的扩散模型以完成户外场景补全面临挑战，因为难以在大视场下从白噪声生成精细细节。现有方法通过局部扩散过程解决此问题，但与物体级别的通用DDPM实践不同。本文旨在弥合这两种方法之间的差距。", "method": "本文提出了LiDPM方法，通过识别局部扩散公式中的近似，并证明这些近似对于场景级别的操作并非必需。研究表明，一个带有精心选择起点的标准DDPM足以实现场景补全。", "result": "LiDPM方法在SemanticKITTI数据集上的场景补全任务中取得了更好的结果。", "conclusion": "局部扩散公式中的近似并非在场景级别操作所必需，一个带有精心选择起点的标准DDPM足以完成激光雷达场景补全任务。", "translation": "训练直接作用于户外场景规模激光雷达点的扩散模型具有挑战性，因为难以在大视场下从白噪声生成精细细节。最新通过扩散模型解决场景补全的工作通过将原始DDPM重新表述为局部扩散过程来解决这个问题。这与在对象级别操作的常见做法形成对比，在对象级别，香草DDPM目前正在使用。在这项工作中，我们弥合了这两类工作之间的差距。我们识别了局部扩散公式中的近似，表明它们在场景级别操作时并非必需，并且一个带有精心选择起点的香草DDPM足以完成补全。最后，我们证明了我们的方法LiDPM在SemanticKITTI上的场景补全中取得了更好的结果。项目页面是https://astra-vision.github.io/LiDPM。", "summary": "本文提出了LiDPM，一种用于激光雷达场景补全的新方法。针对当前扩散模型在处理大规模激光雷达点云时面临的细节生成挑战，LiDPM指出现有局部扩散方法中的近似并非必要。通过证明一个带有精心选择起点的标准DDPM足以进行场景级别的补全，LiDPM弥合了局部扩散与通用DDPM在对象级别应用之间的差距，并在SemanticKITTI数据集上展示了优越的场景补全性能。", "keywords": "激光雷达场景补全, 扩散模型, DDPM, 点云, LiDPM", "comments": "本文的创新之处在于挑战了现有激光雷达场景补全中扩散模型的局部扩散范式，并证明了更简单的标准DDPM在特定条件下也能有效工作，这可能简化未来该领域的研究和应用。通过识别并消除不必要的近似，该工作提供了一种更高效和直接的解决方案。"}}
{"id": "2507.12419", "title": "Mixture of Raytraced Experts", "authors": ["Andrea Perin", "Giacomo Lagomarsini", "Claudio Gallicchio", "Giuseppe Nuti"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preliminary version (pre-submission)", "url": "http://arxiv.org/abs/2507.12419v1", "summary": "We introduce a Mixture of Raytraced Experts, a stacked Mixture of Experts\n(MoE) architecture which can dynamically select sequences of experts, producing\ncomputational graphs of variable width and depth. Existing MoE architectures\ngenerally require a fixed amount of computation for a given sample. Our\napproach, in contrast, yields predictions with increasing accuracy as the\ncomputation cycles through the experts' sequence. We train our model by\niteratively sampling from a set of candidate experts, unfolding the sequence\nakin to how Recurrent Neural Networks are trained. Our method does not require\nload-balancing mechanisms, and preliminary experiments show a reduction in\ntraining epochs of 10\\% to 40\\% with a comparable/higher accuracy. These\nresults point to new research directions in the field of MoEs, allowing the\ndesign of potentially faster and more expressive models. The code is available\nat https://github.com/nutig/RayTracing", "comment": "Preliminary version (pre-submission)", "pdf_url": "http://arxiv.org/pdf/2507.12419v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "射线追踪专家混合模型", "tldr": "引入了一种新的MoE架构（Mixture of Raytraced Experts），可以动态选择专家序列，实现可变计算图，提高精度并减少训练时间。", "motivation": "现有MoE架构通常对给定样本需要固定的计算量，而本文方法能随计算循环增加精度。", "method": "提出Mixture of Raytraced Experts，一种堆叠MoE架构，能动态选择专家序列，生成可变宽度和深度的计算图。通过迭代采样候选专家并展开序列进行训练，类似于循环神经网络的训练。该方法不需要负载均衡机制。", "result": "初步实验显示训练周期减少10%至40%，同时保持或提高了准确性。", "conclusion": "这些结果为MoE领域指明了新的研究方向，有助于设计潜在更快、表达能力更强的模型。", "translation": "我们引入了一种射线追踪专家混合模型（Mixture of Raytraced Experts），这是一种堆叠的专家混合（MoE）架构，能够动态选择专家序列，生成宽度和深度可变的计算图。现有的MoE架构通常对给定样本需要固定的计算量。相比之下，我们的方法随着计算在专家序列中循环而产生越来越高的预测精度。我们通过从一组候选专家中迭代采样来训练我们的模型，展开序列的方式类似于循环神经网络的训练。我们的方法不需要负载均衡机制，初步实验表明训练周期减少了10%到40%，同时保持了相当或更高的准确性。这些结果指出了MoE领域的新研究方向，允许设计潜在更快、表达能力更强的模型。代码可在https://github.com/nutig/RayTracing获取。", "summary": "本文提出了一种名为“射线追踪专家混合模型”（Mixture of Raytraced Experts）的新型堆叠专家混合（MoE）架构。该模型能够动态选择专家序列，生成宽度和深度可变的计算图，从而在计算循环过程中逐步提高预测精度，解决了现有MoE架构计算量固定的问题。模型训练通过迭代采样和序列展开进行，且无需负载均衡。初步实验表明，该方法可将训练周期缩短10%至40%，同时保持或提升准确性，为MoE领域开辟了设计更快、更具表达力模型的新途径。", "keywords": "专家混合, 动态选择, 深度学习, 可变计算图, 射线追踪", "comments": "这篇论文创新性地将“射线追踪”的概念引入到MoE架构中，实现了专家序列的动态选择和可变计算图，克服了传统MoE固定计算量的限制。其无需负载均衡的特点和显著的训练加速效果，预示着MoE模型在效率和表达力方面有巨大的潜力。"}}
{"id": "2507.11882", "title": "Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language Models", "authors": ["Bo Zeng", "Chenyang Lyu", "Sinuo Liu", "Mingyan Zeng", "Minghao Wu", "Xuanfan Ni", "Tianqi Shi", "Yu Zhao", "Yefeng Liu", "Chenyu Zhu", "Ruizhe Li", "Jiahui Geng", "Qing Li", "Yu Tong", "Longyue Wang", "Weihua Luo", "Kaifu Zhang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025 Main Conference paper", "url": "http://arxiv.org/abs/2507.11882v1", "summary": "Instruction-following capability has become a major ability to be evaluated\nfor Large Language Models (LLMs). However, existing datasets, such as IFEval,\nare either predominantly monolingual and centered on English or simply machine\ntranslated to other languages, limiting their applicability in multilingual\ncontexts. In this paper, we present an carefully-curated extension of IFEval to\na localized multilingual version named Marco-Bench-MIF, covering 30 languages\nwith varying levels of localization. Our benchmark addresses linguistic\nconstraints (e.g., modifying capitalization requirements for Chinese) and\ncultural references (e.g., substituting region-specific company names in\nprompts) via a hybrid pipeline combining translation with verification. Through\ncomprehensive evaluation of 20+ LLMs on our Marco-Bench-MIF, we found that: (1)\n25-35% accuracy gap between high/low-resource languages, (2) model scales\nlargely impact performance by 45-60% yet persists script-specific challenges,\nand (3) machine-translated data underestimates accuracy by7-22% versus\nlocalized data. Our analysis identifies challenges in multilingual instruction\nfollowing, including keyword consistency preservation and compositional\nconstraint adherence across languages. Our Marco-Bench-MIF is available at\nhttps://github.com/AIDC-AI/Marco-Bench-MIF.", "comment": "ACL 2025 Main Conference paper", "pdf_url": "http://arxiv.org/pdf/2507.11882v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Marco-Bench-MIF：大型语言模型多语言指令遵循能力研究", "tldr": "本文介绍了Marco-Bench-MIF，一个用于评估大型语言模型多语言指令遵循能力的基准数据集，涵盖30种语言。研究发现高/低资源语言之间存在显著的准确性差距，模型规模对性能有影响，且机器翻译数据会低估准确性。", "motivation": "现有的指令遵循数据集主要以英语为中心或简单地进行机器翻译，这限制了它们在多语言环境中的适用性。因此，需要一个精心策划的、本地化的多语言基准来评估大型语言模型的多语言指令遵循能力。", "method": "本文提出了Marco-Bench-MIF，它是IFEval的一个本地化多语言扩展版本，涵盖30种语言，并具有不同程度的本地化。该基准通过结合翻译和验证的混合管道来解决语言和文化限制。研究团队对20多个大型语言模型在Marco-Bench-MIF上进行了全面评估。", "result": "评估结果显示：(1) 高/低资源语言之间存在25-35%的准确性差距；(2) 模型规模对性能有45-60%的显著影响，但脚本特有的挑战依然存在；(3) 机器翻译数据与本地化数据相比，准确性被低估了7-22%。分析还指出了多语言指令遵循中的挑战，包括关键词一致性保持和跨语言的组合约束遵守。", "conclusion": "本文引入了Marco-Bench-MIF，一个用于评估大型语言模型多语言指令遵循能力的新基准。通过对其进行评估，揭示了多语言指令遵循中的显著挑战和发现，例如不同语言间的性能差距以及纯机器翻译数据的局限性。", "translation": "指令遵循能力已成为评估大型语言模型（LLMs）的一项主要能力。然而，现有的数据集，例如IFEval，要么主要是单语言且以英语为中心，要么只是简单地机器翻译成其他语言，这限制了它们在多语言环境中的适用性。在本文中，我们提出了一个精心策划的IFEval扩展，名为Marco-Bench-MIF，它是一个本地化的多语言版本，涵盖30种不同本地化程度的语言。我们的基准通过结合翻译和验证的混合管道，解决了语言限制（例如，修改中文的大小写要求）和文化参考（例如，替换提示中特定地区的公司名称）。通过对我们Marco-Bench-MIF上20多个LLM的全面评估，我们发现：（1）高资源/低资源语言之间存在25-35%的准确性差距，（2）模型规模在很大程度上影响性能45-60%，但脚本特定的挑战依然存在，（3）机器翻译数据与本地化数据相比，准确性低估了7-22%。我们的分析确定了多语言指令遵循中的挑战，包括跨语言的关键词一致性保持和组合约束遵守。我们的Marco-Bench-MIF可在https://github.com/AIDC-AI/Marco-Bench-MIF获取。", "summary": "本文介绍了Marco-Bench-MIF，一个扩展IFEval至30种语言的新型本地化多语言指令遵循基准。该基准采用翻译与验证相结合的混合管道，以处理语言和文化细微差别。对20多个大型语言模型的评估揭示了高/低资源语言之间显著的准确性差距、模型规模的影响以及机器翻译数据对性能的低估，突显了多语言指令遵循中的关键挑战。", "keywords": "大型语言模型, 多语言, 指令遵循, 基准, 本地化", "comments": "这篇论文通过创建真正多语言和本地化的基准，解决了大型语言模型评估中的一个关键空白。关于不同语言之间性能差异以及机器翻译局限性的发现尤其有见地，强调了为稳健的大型语言模型开发精心策划的多语言数据集的必要性。"}}
{"id": "2309.10509", "title": "Polynomial-time Solver of Tridiagonal QUBO, QUDO and Tensor QUDO problems with Tensor Networks", "authors": ["Alejandro Mata Ali", "Iñigo Perez Delgado", "Marina Ristol Roura", "Aitor Moreno Fdez. de Leceta"], "categories": ["quant-ph", "cs.ET", "68Q12, 15A69, 90C27", "G.1.3; G.2.1"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      12 pages, 9 figures, extreme improvements, new algorithms, new comparisons, better computational complexity, code provided", "url": "http://arxiv.org/abs/2309.10509v4", "summary": "We present a quantum-inspired tensor network algorithm for solving\ntridiagonal Quadratic Unconstrained Binary Optimization (QUBO) problems and\nquadratic unconstrained discrete optimization (QUDO) problems. We also solve\nthe more general Tensor quadratic unconstrained discrete optimization (T-QUDO)\nproblems with one-neighbor interactions in a lineal chain. This method provides\nan exact and explicit equation for these problems. Our algorithms are based on\nthe simulation of a state that undergoes imaginary time evolution and a Half\npartial trace. In addition, we address the degenerate case and evaluate the\npolynomial complexity of the algorithm, also providing a parallelized version.\nWe implemented and tested them with other well-known classical algorithms and\nobserved an improvement in the quality of the results. The performance of the\nproposed algorithms is compared with the Google OR-TOOLS and dimod solvers,\nimproving their results.", "comment": "12 pages, 9 figures, extreme improvements, new algorithms, new\n  comparisons, better computational complexity, code provided", "pdf_url": "http://arxiv.org/pdf/2309.10509v4", "cate": "quant-ph", "date": "2023-09-19", "updated": "2025-07-15", "AI": {"title_translation": "基于张量网络的对角线QUBO、QUDO和张量QUDO问题的多项式时间求解器", "tldr": "开发了一种基于张量网络的量子启发式算法，用于在多项式时间内精确求解对角线QUBO、QUDO和T-QUDO问题，并在质量上优于现有经典算法。", "motivation": "解决三对角二次无约束二元优化（QUBO）问题、二次无约束离散优化（QUDO）问题以及更一般的张量二次无约束离散优化（T-QUDO）问题，并提供一种精确且明确的求解方法。", "method": "提出了一种量子启发式张量网络算法，该算法基于对经历虚时间演化和半部分迹的状态的模拟。该方法还处理简并情况，并评估了算法的多项式复杂度，同时提供了并行化版本。", "result": "该方法为这些问题提供了精确的显式方程。算法具有多项式复杂度。通过与Google OR-TOOLS和dimod等知名经典算法的比较，观察到所提出算法在结果质量上有所改进。", "conclusion": "基于张量网络的量子启发式算法能够有效且精确地解决三对角QUBO、QUDO和T-QUDO问题，并在性能上优于一些经典求解器。", "translation": "我们提出了一种量子启发式张量网络算法，用于求解三对角二次无约束二元优化（QUBO）问题和二次无约束离散优化（QUDO）问题。我们还解决了更一般的张量二次无约束离散优化（T-QUDO）问题，该问题具有线性链中的一个邻居相互作用。该方法为这些问题提供了精确且明确的方程。我们的算法基于对经历虚时间演化和半部分迹的状态的模拟。此外，我们还处理了简并情况，并评估了算法的多项式复杂度，同时提供了并行化版本。我们实现了它们并用其他知名经典算法进行了测试，观察到结果质量的提高。所提出算法的性能与Google OR-TOOLS和dimod求解器进行了比较，并改进了它们的结果。", "summary": "本文提出了一种量子启发式张量网络算法，用于在多项式时间内精确求解三对角QUBO、QUDO以及具有单邻居相互作用的T-QUDO问题。该算法基于虚时间演化和半部分迹，并能处理简并情况。实验结果表明，与Google OR-TOOLS和dimod等经典算法相比，该算法在结果质量上有所改进。", "keywords": "张量网络, QUBO, QUDO, T-QUDO, 量子启发式算法", "comments": "该论文提出了一种新颖的基于张量网络的量子启发式方法，能够精确且在多项式时间内求解一类特定的二次优化问题，包括QUBO、QUDO和T-QUDO。其创新点在于将张量网络应用于这些优化问题，并提供了精确解和并行化能力。与现有经典算法的性能对比显示出其优越性，这对于解决大规模优化问题具有潜在价值。"}}
{"id": "2507.11893", "title": "Spatial Frequency Modulation for Semantic Segmentation", "authors": ["Linwei Chen", "Ying Fu", "Lin Gu", "Dezhi Zheng", "Jifeng Dai"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accept by TPAMI 2025", "url": "http://arxiv.org/abs/2507.11893v1", "summary": "High spatial frequency information, including fine details like textures,\nsignificantly contributes to the accuracy of semantic segmentation. However,\naccording to the Nyquist-Shannon Sampling Theorem, high-frequency components\nare vulnerable to aliasing or distortion when propagating through downsampling\nlayers such as strided-convolution. Here, we propose a novel Spatial Frequency\nModulation (SFM) that modulates high-frequency features to a lower frequency\nbefore downsampling and then demodulates them back during upsampling.\nSpecifically, we implement modulation through adaptive resampling (ARS) and\ndesign a lightweight add-on that can densely sample the high-frequency areas to\nscale up the signal, thereby lowering its frequency in accordance with the\nFrequency Scaling Property. We also propose Multi-Scale Adaptive Upsampling\n(MSAU) to demodulate the modulated feature and recover high-frequency\ninformation through non-uniform upsampling This module further improves\nsegmentation by explicitly exploiting information interaction between densely\nand sparsely resampled areas at multiple scales. Both modules can seamlessly\nintegrate with various architectures, extending from convolutional neural\nnetworks to transformers. Feature visualization and analysis confirm that our\nmethod effectively alleviates aliasing while successfully retaining details\nafter demodulation. Finally, we validate the broad applicability and\neffectiveness of SFM by extending it to image classification, adversarial\nrobustness, instance segmentation, and panoptic segmentation tasks. The code is\navailable at\n\\href{https://github.com/Linwei-Chen/SFM}{https://github.com/Linwei-Chen/SFM}.", "comment": "Accept by TPAMI 2025", "pdf_url": "http://arxiv.org/pdf/2507.11893v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "空间频率调制用于语义分割", "tldr": "提出一种空间频率调制（SFM）方法，通过在下采样前调制高频特征并在上采样时解调来解决语义分割中高频信息的混叠问题。", "motivation": "高空间频率信息（如纹理）对语义分割精度至关重要，但通过下采样层（如步幅卷积）传播时容易出现混叠或失真，这限制了模型保留细节的能力。", "method": "提出空间频率调制（SFM）框架。在下采样前，通过自适应重采样（ARS）模块将高频特征调制到低频，该模块通过密集采样高频区域来放大信号并降低其频率。在上采样时，通过多尺度自适应上采样（MSAU）模块进行解调，该模块通过非均匀上采样恢复高频信息，并利用多尺度下采样和稀疏采样区域之间的信息交互。这两个模块可无缝集成到CNN和Transformer等多种架构中。", "result": "特征可视化和分析证实，该方法有效缓解了混叠问题，并在解调后成功保留了细节。SFM在图像分类、对抗鲁棒性、实例分割和全景分割任务中也表现出广泛的适用性和有效性。", "conclusion": "SFM通过在下采样前后对空间频率进行调制和解调，有效地解决了高频信息在深度学习模型中传播时的混叠和失真问题，从而提升了语义分割及其他视觉任务的性能和细节保留能力。", "translation": "高空间频率信息，包括纹理等精细细节，对语义分割的精度贡献显著。然而，根据奈奎斯特-香农采样定理，高频分量在通过下采样层（如步幅卷积）传播时容易受到混叠或失真的影响。为此，我们提出了一种新颖的空间频率调制（SFM）方法，在下采样前将高频特征调制到较低频率，然后在上采样时将其解调回来。具体来说，我们通过自适应重采样（ARS）实现调制，并设计了一个轻量级的附加模块，可以密集采样高频区域以放大信号，从而根据频率缩放特性降低其频率。我们还提出了多尺度自适应上采样（MSAU）来解调调制后的特征，并通过非均匀上采样恢复高频信息。该模块通过显式利用多尺度密集和稀疏重采样区域之间的信息交互，进一步提高了分割性能。这两个模块可以无缝集成到各种架构中，从卷积神经网络到Transformer。特征可视化和分析证实，我们的方法有效缓解了混叠问题，同时在解调后成功保留了细节。最后，我们通过将其扩展到图像分类、对抗鲁棒性、实例分割和全景分割任务，验证了SFM的广泛适用性和有效性。代码可在\\href{https://github.com/Linwei-Chen/SFM}{https://github.com/Linwei-Chen/SFM}获取。", "summary": "本论文提出一种名为空间频率调制（SFM）的新颖方法，旨在解决深度学习模型中高空间频率信息在下采样过程中易受混叠和失真影响的问题。SFM通过在下采样前利用自适应重采样（ARS）将高频特征调制到低频，并在上采样时通过多尺度自适应上采样（MSAU）将其解调以恢复细节。该方法可无缝集成到多种网络架构中，实验证明其有效缓解了混叠并成功保留了细节，并在语义分割、图像分类等多个视觉任务中展现出广泛的适用性和优越性。", "keywords": "空间频率调制, 语义分割, 混叠, 高频特征, 下采样", "comments": "这项工作通过引入空间频率调制（SFM）的概念，为深度学习模型中高频信息的有效处理提供了一个新颖且通用的框架。其创新点在于提出了一种在下采样前主动调制频率并在上采样时解调的机制，这直接解决了传统方法中高频信息丢失和混叠的关键痛点。该方法的通用性体现在其能够无缝集成到现有主流架构（CNNs和Transformers）并适用于多种视觉任务，这对于提升模型在细节敏感任务上的性能具有重要意义。"}}
{"id": "2507.12248", "title": "Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST", "authors": ["Anida Nezović", "Jalal Romano", "Nada Marić", "Medina Kapo", "Amila Akagić"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12248v1", "summary": "Deep learning has significantly advanced the field of medical image\nclassification, particularly with the adoption of Convolutional Neural Networks\n(CNNs). Various deep learning frameworks such as Keras, PyTorch and JAX offer\nunique advantages in model development and deployment. However, their\ncomparative performance in medical imaging tasks remains underexplored. This\nstudy presents a comprehensive analysis of CNN implementations across these\nframeworks, using the PathMNIST dataset as a benchmark. We evaluate training\nefficiency, classification accuracy and inference speed to assess their\nsuitability for real-world applications. Our findings highlight the trade-offs\nbetween computational speed and model accuracy, offering valuable insights for\nresearchers and practitioners in medical image analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12248v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Keras、PyTorch 和 JAX 在 PathMNIST 上 CNN 性能的比较分析", "tldr": "本研究比较了Keras、PyTorch 和 JAX 三种深度学习框架在PathMNIST数据集上CNN的性能，评估了训练效率、分类准确性和推理速度，并揭示了计算速度和模型准确性之间的权衡。", "motivation": "尽管深度学习在医学图像分类中取得了显著进展，但Keras、PyTorch和JAX等不同深度学习框架在医学成像任务中的比较性能尚未得到充分探索。", "method": "本研究对Keras、PyTorch和JAX框架中的CNN实现进行了全面分析，使用PathMNIST数据集作为基准，并评估了训练效率、分类准确性和推理速度。", "result": "研究结果突出了计算速度和模型准确性之间的权衡。", "conclusion": "本研究为医学图像分析领域的研究人员和从业者提供了关于深度学习框架适用性的宝贵见解。", "translation": "深度学习极大地推动了医学图像分类领域的发展，特别是卷积神经网络（CNNs）的应用。Keras、PyTorch 和 JAX 等各种深度学习框架在模型开发和部署方面具有独特的优势。然而，它们在医学成像任务中的比较性能仍未得到充分探索。本研究对这些框架中的 CNN 实现进行了全面分析，并使用 PathMNIST 数据集作为基准。我们评估了训练效率、分类准确性和推理速度，以评估它们在实际应用中的适用性。我们的研究结果突出了计算速度和模型准确性之间的权衡，为医学图像分析领域的研究人员和从业者提供了宝贵的见解。", "summary": "本研究旨在全面比较Keras、PyTorch和JAX三种深度学习框架中卷积神经网络（CNNs）在医学图像分类任务上的性能，特别是在PathMNIST数据集上。研究评估了训练效率、分类准确性和推理速度，发现计算速度和模型准确性之间存在权衡，为医学图像分析领域的从业者提供了实用的指导。", "keywords": "CNN, Keras, PyTorch, JAX, PathMNIST, 医学图像分类", "comments": "该论文通过系统地比较流行深度学习框架在医学图像分析这一特定应用领域的性能，填补了文献中的一个实际且重要的空白。尽管没有引入新颖的算法，但其经验分析为从业者根据性能权衡选择合适的工具提供了宝贵的指导，这对于实际部署至关重要。"}}
{"id": "2507.12029", "title": "Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery", "authors": ["Xinhang Wan", "Jiyuan Liu", "Qian Qu", "Suyuan Liu", "Chuyu Zhang", "Fangdi Wang", "Xinwang Liu", "En Zhu", "Kunlun He"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12029v1", "summary": "In this paper, we address the problem of novel class discovery (NCD), which\naims to cluster novel classes by leveraging knowledge from disjoint known\nclasses. While recent advances have made significant progress in this area,\nexisting NCD methods face two major limitations. First, they primarily focus on\nsingle-view data (e.g., images), overlooking the increasingly common multi-view\ndata, such as multi-omics datasets used in disease diagnosis. Second, their\nreliance on pseudo-labels to supervise novel class clustering often results in\nunstable performance, as pseudo-label quality is highly sensitive to factors\nsuch as data noise and feature dimensionality. To address these challenges, we\npropose a novel framework named Intra-view and Inter-view Correlation Guided\nMulti-view Novel Class Discovery (IICMVNCD), which is the first attempt to\nexplore NCD in multi-view setting so far. Specifically, at the intra-view\nlevel, leveraging the distributional similarity between known and novel\nclasses, we employ matrix factorization to decompose features into\nview-specific shared base matrices and factor matrices. The base matrices\ncapture distributional consistency among the two datasets, while the factor\nmatrices model pairwise relationships between samples. At the inter-view level,\nwe utilize view relationships among known classes to guide the clustering of\nnovel classes. This includes generating predicted labels through the weighted\nfusion of factor matrices and dynamically adjusting view weights of known\nclasses based on the supervision loss, which are then transferred to novel\nclass learning. Experimental results validate the effectiveness of our proposed\napproach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12029v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "视角内和视角间关联引导的多视图新类别发现", "tldr": "本文提出了一种名为IICMVNCD的新颖框架，用于多视图新类别发现，首次探索了该领域，并通过视角内和视角间关联指导，解决了现有单视图方法和伪标签不稳定性问题。", "motivation": "现有新类别发现（NCD）方法主要关注单视图数据，忽略了日益普遍的多视图数据（如多组学数据集），且其依赖伪标签进行监督导致性能不稳定，因为伪标签质量对数据噪声和特征维度高度敏感。", "method": "本文提出了一种名为视角内和视角间关联引导的多视图新类别发现（IICMVNCD）的新颖框架，这是首次尝试在多视图设置中探索NCD。具体而言，在视角内层面，利用已知和新类别之间的分布相似性，采用矩阵分解将特征分解为视图特定的共享基础矩阵和因子矩阵，其中基础矩阵捕获两个数据集之间的分布一致性，因子矩阵建模样本之间的成对关系。在视角间层面，利用已知类别之间的视图关系来指导新类别的聚类，包括通过因子矩阵的加权融合生成预测标签，并根据监督损失动态调整已知类别的视图权重，然后将其转移到新类别学习中。", "result": "实验结果验证了我们所提出方法的有效性。", "conclusion": "本文提出的IICMVNCD框架有效解决了多视图设置中新类别发现的挑战，与依赖不稳定伪标签的现有单视图方法相比，提供了一种更稳定和鲁棒的解决方案。", "translation": "在本文中，我们解决了新类别发现（NCD）问题，该问题旨在通过利用来自不相交已知类别的知识来聚类新类别。尽管最近的进展在该领域取得了显著进步，但现有的NCD方法面临两个主要限制。首先，它们主要关注单视图数据（例如图像），忽略了日益普遍的多视图数据，例如用于疾病诊断的多组学数据集。其次，它们依赖伪标签来监督新类别聚类，这通常导致性能不稳定，因为伪标签质量对数据噪声和特征维度等因素高度敏感。为了解决这些挑战，我们提出了一种名为视角内和视角间关联引导的多视图新类别发现（IICMVNCD）的新颖框架，这是迄今为止首次尝试在多视图设置中探索NCD。具体而言，在视角内层面，利用已知和新类别之间的分布相似性，我们采用矩阵分解将特征分解为视图特定的共享基础矩阵和因子矩阵。基础矩阵捕获两个数据集之间的分布一致性，而因子矩阵建模样本之间的成对关系。在视角间层面，我们利用已知类别之间的视图关系来指导新类别的聚类。这包括通过因子矩阵的加权融合生成预测标签，并根据监督损失动态调整已知类别的视图权重，然后将其转移到新类别学习中。实验结果验证了我们所提出方法的有效性。", "summary": "本文提出了IICMVNCD，一个用于多视图新类别发现（NCD）的新颖框架，这在该领域尚属首次尝试。它解决了现有NCD方法主要针对单视图数据且依赖不稳定伪标签的局限性。IICMVNCD在视角内和视角间两个层面进行操作：在视角内，它利用矩阵分解分解特征；在视角间，它利用已知类别间的视图关系来指导新类别聚类。实验结果证明了该方法的有效性。", "keywords": "新类别发现, 多视图学习, 矩阵分解, 伪标签, 数据融合", "comments": "本文的创新之处在于首次将新类别发现问题扩展到多视图数据设置，并提出了一个全面的框架IICMVNCD。它通过引入视角内和视角间关联指导，有效克服了现有方法在单视图限制和伪标签不稳定性方面的缺点，这对于处理复杂、多模态的现实世界数据（如多组学数据）具有重要意义。"}}
{"id": "2507.11687", "title": "MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization", "authors": ["Atharva Naik", "Lawanya Baghel", "Dhakshin Govindarajan", "Darsh Agrawal", "Daniel Fried", "Carolyn Rose"], "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11687v1", "summary": "Large Language Models, though successful in code generation, struggle with\ncode quality analysis because they are limited by static training data and\ncan't easily adapt to evolving best practices. We introduce MetaLint, a new\ninstruction-following framework that formulates code quality analysis as the\ntask of detecting and fixing problematic semantic code fragments or code idioms\nbased on high-level specifications. Unlike conventional approaches that train\nmodels on static, rule-based data, MetaLint employs instruction tuning on\nsynthetic linter-generated data to support easy-to-hard generalization,\nenabling models to adapt to novel or complex code patterns without retraining.\nTo evaluate this, we construct a benchmark of challenging idioms inspired by\nreal-world coding standards such as Python Enhancement Proposals (PEPs) and\nassess whether MetaLint-trained models reason adaptively or simply memorize.\nOur results show that MetaLint improves generalization to unseen PEP idioms,\nachieving a 70.37% F-score on idiom detection with the highest recall (70.43%)\namong all evaluated models. It also achieves 26.73% on localization,\ncompetitive for its 4B parameter size and comparable to larger state-of-the-art\nmodels like o3-mini, highlighting its potential for future-proof code quality\nanalysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11687v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "MetaLint：通过指令遵循和由易到难泛化实现可泛化的惯用代码质量分析", "tldr": "MetaLint是一个新的指令遵循框架，通过对合成的linter生成数据进行指令调整，实现代码质量分析的由易到难泛化，从而在不重新训练的情况下适应新的代码模式，并在代码质量分析任务中表现出色。", "motivation": "大型语言模型在代码生成方面表现出色，但在代码质量分析方面存在困难，因为它们受限于静态训练数据，难以适应不断发展的最佳实践。", "method": "MetaLint将代码质量分析表述为基于高级规范检测和修复问题语义代码片段或代码惯用法的任务。它采用指令调整（instruction tuning）方法，利用合成的linter生成数据，以支持由易到难的泛化，使模型无需重新训练即可适应新颖或复杂的代码模式。研究者构建了一个受真实世界编码标准（如PEP）启发的挑战性惯用法基准来评估MetaLint。", "result": "MetaLint在未见过的PEP惯用法上提高了泛化能力，在惯用法检测方面达到了70.37%的F-score，召回率最高（70.43%）。在定位方面也达到了26.73%的性能，与其4B参数规模相比具有竞争力，并与o3-mini等大型SOTA模型相当。", "conclusion": "MetaLint展示了在不重新训练的情况下适应新代码模式的潜力，并通过其优异的泛化能力和与大型SOTA模型相当的性能，为面向未来的代码质量分析提供了可能性。", "translation": "大型语言模型虽然在代码生成方面取得了成功，但在代码质量分析方面却举步维艰，因为它们受限于静态训练数据，并且难以适应不断发展的最佳实践。我们引入了MetaLint，一个全新的指令遵循框架，它将代码质量分析表述为根据高级规范检测和修复有问题的语义代码片段或代码惯用法的任务。与在静态、基于规则的数据上训练模型的传统方法不同，MetaLint采用对合成的linter生成数据进行指令调整，以支持由易到难的泛化，使模型无需重新训练即可适应新颖或复杂的代码模式。为了评估这一点，我们构建了一个受Python增强提案（PEP）等真实世界编码标准启发的挑战性惯用法基准，并评估MetaLint训练的模型是自适应推理还是简单记忆。我们的结果表明，MetaLint提高了对未见过的PEP惯用法的泛化能力，在惯用法检测方面达到了70.37%的F-score，在所有评估模型中召回率最高（70.43%）。它在定位方面也达到了26.73%的性能，与其4B参数规模相比具有竞争力，并且可与o3-mini等更大的最先进模型相媲美，突出了其在面向未来的代码质量分析方面的潜力。", "summary": "MetaLint是一个创新的指令遵循框架，旨在解决大型语言模型在代码质量分析中适应新代码模式的局限性。它通过对合成linter生成数据进行指令调整，实现了由易到难的泛化，使模型无需重新训练即可检测和修复代码惯用法。在PEP惯用法基准上的评估显示，MetaLint在检测方面表现出色，并在定位方面具有竞争力，证明了其在未来代码质量分析中的潜力。", "keywords": "代码质量分析, 指令遵循, 泛化, MetaLint, 代码惯用法", "comments": "MetaLint的创新之处在于其指令遵循框架和由易到难的泛化策略，这使得模型能够适应不断变化的代码最佳实践而无需重新训练，解决了传统LLM在代码质量分析中的核心痛点。其在未见过惯用法上的泛化能力是其重要性所在。"}}
{"id": "2402.11662", "title": "TDE-3: An improved prior for optical flow computation in spiking neural networks", "authors": ["Matthew Yedutenko", "Federico Paredes-Valles", "Lyes Khacef", "Guido C. H. E. De Croon"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.11662v2", "summary": "Motion detection is a primary task required for robotic systems to perceive\nand navigate in their environment. Proposed in the literature bioinspired\nneuromorphic Time-Difference Encoder (TDE-2) combines event-based sensors and\nprocessors with spiking neural networks to provide real-time and\nenergy-efficient motion detection through extracting temporal correlations\nbetween two points in space. However, on the algorithmic level, this design\nleads to loss of direction-selectivity of individual TDEs in textured\nenvironments. Here we propose an augmented 3-point TDE (TDE-3) with additional\ninhibitory input that makes TDE-3 direction-selectivity robust in textured\nenvironments. We developed a procedure to train the new TDE-3 using\nbackpropagation through time and surrogate gradients to linearly map input\nvelocities into an output spike count or an Inter-Spike Interval (ISI). Our\nwork is the first instance of training a spiking neuron to have a specific ISI.\nUsing synthetic data we compared training and inference with spike count and\nISI with respect to changes in stimuli dynamic range, spatial frequency, and\nlevel of noise. ISI turns out to be more robust towards variation in spatial\nfrequency, whereas the spike count is a more reliable training signal in the\npresence of noise. We performed the first in-depth quantitative investigation\nof optical flow coding with TDE and compared TDE-2 vs TDE-3 in terms of\nenergy-efficiency and coding precision. Results show that on the network level\nboth detectors show similar precision (20 degree angular error, 88% correlation\nwith ground truth). Yet, due to the more robust direction-selectivity of\nindividual TDEs, TDE-3 based network spike less and hence is more\nenergy-efficient. Reported precision is on par with model-based methods but the\nspike-based processing of the TDEs provides allows more energy-efficient\ninference with neuromorphic hardware.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.11662v2", "cate": "cs.NE", "date": "2024-02-18", "updated": "2025-07-16", "AI": {"title_translation": "TDE-3：一种改进的脉冲神经网络光流计算先验", "tldr": "本文提出了TDE-3，一种改进的时间差编码器，通过增加抑制输入解决了TDE-2在纹理环境中方向选择性不足的问题。TDE-3通过新颖的训练方法（包括首次训练特定ISI）在保持编码精度的同时显著提高了能量效率，使其更适用于神经形态硬件的光流计算。", "motivation": "现有的生物启发式神经形态时间差编码器（TDE-2）在纹理环境中存在个体TDE方向选择性丢失的问题，这限制了其在机器人运动检测中的应用，并降低了其在复杂场景下的性能。", "method": "提出了一个增强的3点TDE（TDE-3），增加了额外的抑制输入，使其在纹理环境中具有鲁棒的方向选择性。开发了一种使用时间反向传播和替代梯度训练新TDE-3的程序，以将输入速度线性映射到输出脉冲计数或脉冲间隔（ISI）。首次实现了训练脉冲神经元具有特定ISI。使用合成数据，比较了脉冲计数和ISI在不同刺激动态范围、空间频率和噪声水平下的训练和推理性能。对TDE的光流编码进行了深入的定量研究，并比较了TDE-2与TDE-3在能效和编码精度方面的表现。", "result": "ISI对空间频率变化更鲁棒，而脉冲计数在存在噪声时是更可靠的训练信号。在网络层面，TDE-2和TDE-3表现出相似的精度（20度角度误差，与真实值88%相关）。然而，由于TDE-3个体TDE的方向选择性更鲁棒，基于TDE-3的网络脉冲更少，因此更节能。报告的精度与基于模型的方法相当，但TDE的基于脉冲的处理允许神经形态硬件进行更节能的推理。", "conclusion": "TDE-3通过改进方向选择性，在保持与TDE-2相似精度的同时显著提高了能量效率，使其成为一种在神经形态硬件上进行光流计算的更优异且节能的解决方案，尤其是在纹理环境中。", "translation": "运动检测是机器人系统感知和导航环境所需的主要任务。文献中提出的生物启发式神经形态时间差编码器（TDE-2）结合了基于事件的传感器和处理器与脉冲神经网络，通过提取空间中两点之间的时间相关性来提供实时、节能的运动检测。然而，在算法层面，这种设计导致在纹理环境中个体TDE的方向选择性丢失。本文提出了一种增强的3点TDE（TDE-3），增加了额外的抑制输入，使得TDE-3在纹理环境中具有鲁棒的方向选择性。我们开发了一种使用时间反向传播和替代梯度训练新TDE-3的程序，以将输入速度线性映射到输出脉冲计数或脉冲间隔（ISI）。我们的工作是首次训练脉冲神经元具有特定ISI的实例。使用合成数据，我们比较了脉冲计数和ISI在刺激动态范围、空间频率和噪声水平变化下的训练和推理。结果表明，ISI对空间频率的变化更鲁棒，而脉冲计数在存在噪声时是更可靠的训练信号。我们首次对TDE的光流编码进行了深入的定量研究，并比较了TDE-2与TDE-3在能效和编码精度方面的表现。结果显示，在网络层面，两种检测器都表现出相似的精度（20度角度误差，与真实值88%相关）。然而，由于个体TDE更鲁棒的方向选择性，基于TDE-3的网络脉冲更少，因此更节能。报告的精度与基于模型的方法相当，但TDE的基于脉冲的处理使得神经形态硬件能够进行更节能的推理。", "summary": "本文提出了一种改进的神经形态时间差编码器TDE-3，旨在解决现有TDE-2在纹理环境中方向选择性不足的问题。TDE-3通过引入额外的抑制输入，增强了在复杂环境中的方向选择性鲁棒性。研究开发了一种新的训练方法，利用时间反向传播和替代梯度将输入速度映射到输出脉冲计数或脉冲间隔（ISI），并首次成功训练脉冲神经元产生特定ISI。实验结果表明，TDE-3在保持与TDE-2相似的光流编码精度的同时，通过减少网络脉冲数量，显著提高了能量效率。这使得TDE-3成为一种更适合在神经形态硬件上进行节能光流计算的有效方法。", "keywords": "光流计算, 脉冲神经网络, 时间差编码器, 神经形态硬件, 运动检测", "comments": "这项工作在生物启发式神经形态计算领域取得了重要进展。其创新之处在于TDE-3的设计，通过引入额外的抑制输入解决了传统TDE在纹理环境中方向选择性差的局限性，这对于实际机器人应用至关重要。更值得注意的是，该研究首次实现了训练脉冲神经元产生特定的脉冲间隔（ISI），这为脉冲神经网络的编码和训练开辟了新的途径。通过提高能效，TDE-3为未来低功耗、实时感知的神经形态硬件发展提供了有力的支持。"}}
{"id": "2504.15079", "title": "Generative Artificial Intelligence for Beamforming in Low-Altitude Economy", "authors": ["Geng Sun", "Jia Qi", "Chuang Zhang", "Xuejie Liu", "Jiacheng Wang", "Dusit Niyato", "Yuanwei Liu", "Dong In Kim"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.15079v2", "summary": "The growth of low-altitude economy (LAE) has driven a rising demand for\nefficient and secure communication. However, conventional beamforming\noptimization techniques struggle in the complex LAE environments. In this\ncontext, generative artificial intelligence (GenAI) methods provide a promising\nsolution. In this article, we first introduce the core concepts of LAE and the\nroles of beamforming in advanced communication technologies for LAE. We then\nexamine their interrelation, followed by an analysis of the limitations of\nconventional beamforming methods. Next, we provide an overview of how GenAI\nmethods enhance the process of beamforming, with a focus on its applications in\nLAE. Furthermore, we present a case study using a generative diffusion model\n(GDM)-based algorithm to enhance the performance of aerial collaborative\nbeamforming-enabled remote secure communications in LAE and simulation results\nverified the effectiveness of the proposed algorithms. Finally, promising\nresearch opportunities are identified.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.15079v2", "cate": "cs.NI", "date": "2025-04-21", "updated": "2025-07-16", "AI": {"title_translation": "低空经济中用于波束成形的生成式人工智能", "tldr": "本文探讨生成式AI如何解决低空经济中传统波束成形面临的挑战，并通过生成扩散模型案例验证了其在提升通信性能方面的有效性。", "motivation": "低空经济的增长对高效安全的通信提出需求，但传统波束成形优化技术在复杂的低空经济环境中表现不佳。", "method": "文章首先介绍了低空经济和波束成形的核心概念及其相互关系，分析了传统波束成形的局限性。随后概述了生成式AI如何增强波束成形，并重点关注其在低空经济中的应用。最后，通过一个基于生成扩散模型（GDM）的算法案例研究，验证了其在提升低空经济中空中协作波束成形远程安全通信性能方面的有效性。", "result": "仿真结果验证了所提出算法的有效性。", "conclusion": "文章识别了有前景的研究机会。", "translation": "低空经济（LAE）的增长推动了对高效安全通信日益增长的需求。然而，传统的波束成形优化技术在复杂的低空经济环境中面临挑战。在此背景下，生成式人工智能（GenAI）方法提供了一个有前景的解决方案。在本文中，我们首先介绍了低空经济的核心概念以及波束成形在低空经济先进通信技术中的作用。然后，我们探讨了它们之间的相互关系，并分析了传统波束成形方法的局限性。接下来，我们概述了生成式AI方法如何增强波束成形过程，重点关注其在低空经济中的应用。此外，我们提出了一个使用生成扩散模型（GDM）算法的案例研究，以增强低空经济中空中协作波束成形远程安全通信的性能，仿真结果验证了所提出算法的有效性。最后，识别了有前景的研究机会。", "summary": "本文探讨了生成式人工智能（GenAI）在低空经济（LAE）中波束成形应用的前景，旨在解决传统方法在复杂LAE环境中的局限性。文章介绍了LAE和波束成形的概念，分析了传统方法的不足，并详细阐述了GenAI如何改进波束成形。通过一个基于生成扩散模型（GDM）的案例研究，验证了GenAI算法在提升空中协作波束成形远程安全通信性能方面的有效性，并指出了未来的研究方向。", "keywords": "低空经济, 波束成形, 生成式人工智能, 生成扩散模型, 无线通信", "comments": "该论文创新性地将生成式AI引入低空经济中的波束成形领域，提出了一个有前景的解决方案，以应对传统技术在复杂环境下的挑战。其通过具体的GDM案例研究验证了方法的有效性，为未来低空通信技术的发展提供了新的思路。"}}
{"id": "2507.12070", "title": "Emergence of Quantised Representations Isolated to Anisotropic Functions", "authors": ["George Bird"], "categories": ["cs.LG", "I.5.1; F.1.1; I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      36 pages, 31 figures", "url": "http://arxiv.org/abs/2507.12070v1", "summary": "This paper describes a novel methodology for determining representational\nalignment, developed upon the existing Spotlight Resonance method. Using this,\nit is found that algebraic symmetries of network primitives are a strong\npredictor for task-agnostic structure in representations. Particularly, this\nnew tool is used to gain insight into how discrete representations can form and\narrange in autoencoder models, through an ablation study where only the\nactivation function is altered. Representations are found to tend to discretise\nwhen the activation functions are defined through a discrete algebraic\npermutation-equivariant symmetry. In contrast, they remain continuous under a\ncontinuous algebraic orthogonal-equivariant definition. These findings\ncorroborate the hypothesis that functional form choices can carry unintended\ninductive biases which produce task-independent artefactual structures in\nrepresentations, particularly that contemporary forms induce discretisation of\notherwise continuous structure -- a quantisation effect. Moreover, this\nsupports a general causal model for one mode in which discrete representations\nmay form, and could constitute a prerequisite for downstream interpretability\nphenomena, including grandmother neurons, discrete coding schemes, general\nlinear features and possibly Superposition. Hence, this tool and proposed\nmechanism for the influence of functional form on representations may provide\nseveral insights into emergent interpretability research. Finally, preliminary\nresults indicate that quantisation of representations appears to correlate with\na measurable increase in reconstruction error, reinforcing previous conjectures\nthat this collapse can be detrimental.", "comment": "36 pages, 31 figures", "pdf_url": "http://arxiv.org/pdf/2507.12070v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "各向异性函数中量化表示的出现", "tldr": "研究发现，激活函数的代数对称性会影响自动编码器中表示的离散化（量化）或连续性，离散化可能导致重建误差增加。", "motivation": "开发一种确定表示对齐的新方法；深入了解自动编码器模型中离散表示的形成和排列机制；验证函数形式选择是否会引入意想不到的归纳偏差，从而产生与任务无关的表示结构；探索离散表示形成的一种通用因果模型及其对可解释性现象的潜在影响。", "method": "开发了一种基于现有Spotlight Resonance方法的新型表示对齐确定方法；使用该工具对自动编码器模型进行消融研究，仅改变激活函数；通过分析激活函数的代数对称性来研究表示的结构。", "result": "网络原语的代数对称性是表示中任务无关结构的强预测因子；当激活函数通过离散代数置换等变对称定义时，表示倾向于离散化；当激活函数通过连续代数正交等变定义时，表示保持连续；初步结果表明，表示的量化与重建误差的显著增加相关。", "conclusion": "函数形式的选择会带来意想不到的归纳偏差，导致表示中出现与任务无关的人工结构，特别是当代形式会导致连续结构离散化，产生量化效应；研究支持了离散表示形成的一种通用因果模型，这可能是下游可解释性现象的先决条件；该工具和提出的函数形式对表示影响的机制为新兴的可解释性研究提供了见解；表示的量化可能与重建误差增加相关，这表明这种“崩溃”可能是有害的。", "translation": "这篇论文描述了一种确定表示对齐的新方法，该方法是在现有Spotlight Resonance方法的基础上开发的。利用这种方法，发现网络原语的代数对称性是表示中与任务无关结构的强预测因子。特别是，通过一项仅改变激活函数的消融研究，利用这个新工具深入了解了自动编码器模型中离散表示如何形成和排列。研究发现，当激活函数通过离散代数置换等变对称定义时，表示倾向于离散化。相反，在连续代数正交等变定义下，它们保持连续。这些发现证实了以下假设：函数形式的选择会带来意想不到的归纳偏差，从而在表示中产生与任务无关的人工结构，特别是当代形式会导致原本连续的结构离散化——一种量化效应。此外，这支持了离散表示可能形成的一种通用因果模型，并且可能构成下游可解释性现象（包括祖母细胞、离散编码方案、通用线性特征以及可能的叠加）的先决条件。因此，这个工具和提出的函数形式对表示影响的机制可能为新兴的可解释性研究提供若干见解。最后，初步结果表明，表示的量化似乎与重建误差的可测量增加相关，这强化了先前关于这种“崩溃”可能有害的推测。", "summary": "本文提出了一种新颖的表示对齐方法，并用其研究了自动编码器中表示的形成机制。研究发现，激活函数的代数对称性是表示结构的关键预测因素：离散对称性导致表示量化，而连续对称性则保持表示连续。这些结果表明，函数形式的选择会引入归纳偏差，导致与任务无关的量化效应，并且这种量化可能与重建误差的增加有关。该研究为理解离散表示的形成提供了见解，并对新兴的可解释性研究具有潜在意义。", "keywords": "量化表示, 激活函数, 归纳偏差, 自动编码器, 可解释性", "comments": "创新性：提出了一个新颖的表示对齐方法，并将其应用于揭示激活函数对表示结构（特别是量化）的影响，这在理解神经网络内部工作机制方面具有创新性。重要性：揭示了函数形式选择（如激活函数）引入的隐含归纳偏差如何影响表示的性质（连续性与离散性），这对于设计更可控、可解释的神经网络模型至关重要。同时，将量化效应与重建误差和下游可解释性现象（如祖母细胞）联系起来，为后续研究提供了新的方向。局限性/未来方向：结果目前是“初步的”，表明量化与重建误差的“相关性”，而非因果性。未来的工作可能需要更深入地探讨这种因果关系以及如何利用这些发现来设计避免有害量化的模型。"}}
{"id": "2111.09290", "title": "Matroid-Based TSP Rounding for Half-Integral Solutions", "authors": ["Anupam Gupta", "Euiwoong Lee", "Jason Li", "Marcin Mucha", "Heather Newman", "Sherry Sarkar"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2111.09290v2", "summary": "We show how to round any half-integral solution to the subtour-elimination\nrelaxation for the TSP, while losing a less-than-1.5 factor. Such a rounding\nalgorithm was recently given by Karlin, Klein, and Oveis Gharan based on\nsampling from max-entropy distributions. We build on an approach of Haddadan\nand Newman to show how sampling from the matroid intersection polytope, and a\nnew use of max-entropy sampling, can give better guarantees.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2111.09290v2", "cate": "cs.DS", "date": "2021-11-17", "updated": "2025-07-15", "AI": {"title_translation": "基于拟阵的TSP半整数解舍入", "tldr": "本文提出了一种基于拟阵交多面体和最大熵采样的新方法，用于将TSP半整数解舍入，实现了优于1.5的近似因子。", "motivation": "现有TSP半整数解舍入算法的近似因子可以被进一步改善。", "method": "借鉴Haddadan和Newman的方法，结合拟阵交多面体的采样和最大熵采样的新用法。", "result": "能够将TSP的半整数解舍入，近似因子损失小于1.5。", "conclusion": "通过结合拟阵交多面体和最大熵采样，可以获得更好的TSP半整数解舍入近似因子。", "translation": "我们展示了如何将TSP子回路消除松弛的任何半整数解进行舍入，同时损失小于1.5的因子。Karlin、Klein和Oveis Gharan最近基于从最大熵分布中采样给出了一种这样的舍入算法。我们借鉴Haddadan和Newman的方法，展示了如何从拟阵交多面体中采样，以及最大熵采样的新用法，可以提供更好的保证。", "summary": "本文提出了一种改进的旅行商问题（TSP）半整数解舍入算法。该算法基于Haddadan和Newman的方法，并结合了从拟阵交多面体中采样以及最大熵采样的新应用，旨在将TSP子回路消除松弛的半整数解舍入，并实现小于1.5的近似因子损失，优于现有方法。", "keywords": "旅行商问题, 半整数解, 舍入算法, 拟阵交多面体, 最大熵采样", "comments": "这篇论文通过引入拟阵交多面体的采样和最大熵采样的新应用，改进了旅行商问题（TSP）半整数解的舍入算法，实现了更小的近似因子损失，这在组合优化领域具有重要的理论意义。它在现有工作的基础上进行了创新，提升了近似算法的性能。"}}
{"id": "2503.22526", "title": "AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization", "authors": ["Martin Kišš", "Michal Hradiš", "Martina Dvořáková", "Václav Jiroušek", "Filip Kersch"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 2 tables, 7 figures; Accepted to GREC Workshop at ICDAR2025", "url": "http://arxiv.org/abs/2503.22526v3", "summary": "We introduce the AnnoPage Dataset, a novel collection of 7,550 pages from\nhistorical documents, primarily in Czech and German, spanning from 1485 to the\npresent, focusing on the late 19th and early 20th centuries. The dataset is\ndesigned to support research in document layout analysis and object detection.\nEach page is annotated with axis-aligned bounding boxes (AABB) representing\nelements of 25 categories of non-textual elements, such as images, maps,\ndecorative elements, or charts, following the Czech Methodology of image\ndocument processing. The annotations were created by expert librarians to\nensure accuracy and consistency. The dataset also incorporates pages from\nmultiple, mainly historical, document datasets to enhance variability and\nmaintain continuity. The dataset is divided into development and test subsets,\nwith the test set carefully selected to maintain the category distribution. We\nprovide baseline results using YOLO and DETR object detectors, offering a\nreference point for future research. The AnnoPage Dataset is publicly available\non Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth\nannotations in YOLO format.", "comment": "17 pages, 2 tables, 7 figures; Accepted to GREC Workshop at ICDAR2025", "pdf_url": "http://arxiv.org/pdf/2503.22526v3", "cate": "cs.CV", "date": "2025-03-28", "updated": "2025-07-16", "AI": {"title_translation": "AnnoPage数据集：文档中非文本元素的细粒度分类数据集", "tldr": "AnnoPage数据集是一个包含7,550页历史文档的图像数据集，专注于非文本元素的细粒度分类，并提供基线检测结果。", "motivation": "该数据集旨在支持文档版面分析和目标检测领域的研究。", "method": "AnnoPage数据集包含7,550页历史文档（主要为捷克语和德语，涵盖1485年至今，重点是19世纪末20世纪初）。每页都用轴对齐边界框（AABB）标注了25类非文本元素，如图像、地图、装饰元素或图表，遵循捷克图像文档处理方法。标注由专业图书管理员完成，以确保准确性和一致性。数据集还整合了来自多个（主要是历史）文档数据集的页面，以增强变异性。数据集分为开发和测试子集，测试集经过精心选择以保持类别分布。", "result": "该研究推出了AnnoPage数据集，并使用YOLO和DETR目标检测器提供了基线结果，为未来的研究提供了参考点。数据集及其标注已公开发布。", "conclusion": "AnnoPage数据集是一个新的、大规模的、经过专家标注的文档中非文本元素数据集，可用于文档版面分析和目标检测任务，为相关研究提供了宝贵的资源。", "translation": "我们推出了AnnoPage数据集，这是一个包含7,550页历史文档的新颖集合，主要使用捷克语和德语，时间跨度从1485年至今，重点是19世纪末和20世纪初。该数据集旨在支持文档版面分析和目标检测方面的研究。每页都用轴对齐边界框（AABB）标注了25类非文本元素，例如图像、地图、装饰元素或图表，遵循捷克图像文档处理方法。标注由专业图书管理员创建，以确保准确性和一致性。该数据集还包含来自多个（主要是历史）文档数据集的页面，以增强变异性并保持连续性。数据集分为开发和测试子集，测试集经过精心选择以保持类别分布。我们使用YOLO和DETR目标检测器提供了基线结果，为未来的研究提供了参考点。AnnoPage数据集及其YOLO格式的真值标注可在Zenodo（https://doi.org/10.5281/zenodo.12788419）上公开获取。", "summary": "AnnoPage数据集是一个新颖的、大规模的历史文档数据集，包含7,550页经过专家标注的文档。该数据集专注于文档中的非文本元素，并对其进行了细粒度的25类分类。它旨在支持文档版面分析和目标检测研究，并提供了使用YOLO和DETR的基线结果，已公开发布。", "keywords": "AnnoPage数据集, 非文本元素, 文档版面分析, 目标检测, 历史文档", "comments": "AnnoPage数据集的创新之处在于其对历史文档中非文本元素的细粒度分类（25个类别）和高质量的专家标注。这为文档版面分析和目标检测领域提供了一个独特且急需的资源，特别是对于处理历史文献的研究。提供基线结果和公共可用性进一步提升了其对未来研究的价值。"}}
{"id": "2507.03361", "title": "Scalable Differentially Private Sketches under Continual Observation", "authors": ["Rayne Holland"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      23 pages, 8 figures", "url": "http://arxiv.org/abs/2507.03361v2", "summary": "Sketches are a fundamental tool in data stream analytics. They are notable\nfor supporting both approximate frequency queries and heavy hitter detection\nwith bounded trade-offs for error and memory. Importantly, on streams that\ncontain sensitive information, sketches can be easily privatized with the\ninjection of a suitable amount of noise. This process is efficient in the\nsingle-release model, where the output is released only at the end of the\nstream. In this setting, it suffices to add noise to the sketch once.\n  In contrast, in the continual observation model, where the output is released\nat every time-step, noise needs to be added to the sketch before each release.\nThis creates an additional computational overhead. To address this, we\nintroduce Lazy Sketch, a novel differentially private sketching method, in the\ncontinual observation model, that employs lazy updates, perturbing and\nmodifying only a small portion of the sketch at each step. Compared to prior\nwork, we reduce the update complexity by a factor of $O(w)$, where $w$ is the\nwidth of the sketch. Experiments demonstrate that our method increases\nthroughput by up to 250x over prior work, making continual observation\ndifferential privacy practical for high-speed streaming applications.\n  In addition, for heavy hitter detection, we present a new sketch-based\nalgorithm that leverages lazy updates to achieve a per-update complexity of\n$O(d \\log T/w + \\log w)$, for sketches with dimension $d\\times w$ and streams\nof length $T$. This marks a significant improvement over prior approaches in\nthe streaming continual observation model, which require recomputing frequency\nestimates for every item in the input domain at each time step.", "comment": "23 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.03361v2", "cate": "cs.CR", "date": "2025-07-04", "updated": "2025-07-16", "AI": {"title_translation": "持续观察下可伸缩的差分隐私草图", "tldr": "本文提出了一种名为Lazy Sketch的新型差分隐私草图方法，用于持续观察模型下的数据流分析，显著提高了吞吐量并降低了计算复杂性，使差分隐私在高速流媒体应用中变得实用。", "motivation": "在持续观察模型中，为了实现差分隐私，需要在每个时间步向草图添加噪声，这会产生额外的计算开销，使得该方法在高速流媒体应用中不切实际。", "method": "本文引入了Lazy Sketch，这是一种新颖的差分隐私草图方法，在持续观察模型中采用惰性更新，在每个步骤中仅扰动和修改草图的一小部分。此外，针对重击手检测，提出了一种利用惰性更新的新型基于草图的算法。", "result": "与现有工作相比，Lazy Sketch将更新复杂性降低了O(w)（w是草图的宽度）。实验表明，该方法使吞吐量比现有工作提高了250倍。对于重击手检测，其每更新复杂性达到O(d log T/w + log w)，显著优于现有方法。", "conclusion": "Lazy Sketch通过显著降低计算开销和提高吞吐量，使持续观察下的差分隐私在高速流媒体应用中变得实用。", "translation": "草图是数据流分析中的一个基本工具。它们以支持近似频率查询和重击手检测而闻名，具有有界误差和内存权衡。重要的是，在包含敏感信息的流上，草图可以通过注入适量的噪声轻松实现隐私保护。这个过程在单次发布模型中是高效的，其中输出仅在流结束时发布。在这种设置下，只需向草图添加一次噪声即可。\n相比之下，在持续观察模型中，输出在每个时间步发布，因此在每次发布之前都需要向草图添加噪声。这会产生额外的计算开销。为了解决这个问题，我们引入了Lazy Sketch，这是一种在持续观察模型中新颖的差分隐私草图方法，它采用惰性更新，在每个步骤中仅扰动和修改草图的一小部分。与现有工作相比，我们将更新复杂性降低了O(w)的因子，其中w是草图的宽度。实验表明，我们的方法比现有工作提高了高达250倍的吞吐量，使持续观察差分隐私在高速流媒体应用中变得实用。\n此外，对于重击手检测，我们提出了一种新的基于草图的算法，该算法利用惰性更新来实现每更新复杂性为O(d log T/w + log w)，适用于维度为d×w的草图和长度为T的流。这标志着对流持续观察模型中现有方法的重大改进，现有方法需要在每个时间步重新计算输入域中每个项目的频率估计。", "summary": "本文介绍了Lazy Sketch，一种针对持续观察模型下数据流的新型差分隐私草图方法。与传统方法在每个时间步添加噪声不同，Lazy Sketch采用惰性更新机制，仅修改草图的一小部分，从而将更新复杂性降低了O(w)，并使吞吐量提高了高达250倍。这使得差分隐私在高速流媒体应用中的持续观察变得实用。此外，该方法还为重击手检测提供了一种改进的算法，进一步优化了性能。", "keywords": "差分隐私, 草图, 持续观察, 数据流, 惰性更新", "comments": "该论文的创新之处在于提出了“惰性更新”机制，有效解决了差分隐私在持续观察设置中产生的巨大计算开销。这使得此前不切实际的隐私保护数据分析方法在实时、高速数据流应用中变得可行，是隐私保护数据分析领域的一个重要实用进展。"}}
{"id": "2507.12301", "title": "Leveraging Bi-Directional Channel Reciprocity for Robust Ultra-Low-Rate Implicit CSI Feedback with Deep Learning", "authors": ["Zhenyu Liu", "Yi Ma", "Rahim Tafazolli", "Zhi Ding"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12301v1", "summary": "Deep learning-based implicit channel state information (CSI) feedback has\nbeen introduced to enhance spectral efficiency in massive MIMO systems.\nExisting methods often show performance degradation in ultra-low-rate scenarios\nand inadaptability across diverse environments. In this paper, we propose\nDual-ImRUNet, an efficient uplink-assisted deep implicit CSI feedback framework\nincorporating two novel plug-in preprocessing modules to achieve ultra-low\nfeedback rates while maintaining high environmental robustness. First, a novel\nbi-directional correlation enhancement module is proposed to strengthen the\ncorrelation between uplink and downlink CSI eigenvector matrices. This module\nprojects highly correlated uplink and downlink channel matrices into their\nrespective eigenspaces, effectively reducing redundancy for ultra-low-rate\nfeedback. Second, an innovative input format alignment module is designed to\nmaintain consistent data distributions at both encoder and decoder sides\nwithout extra transmission overhead, thereby enhancing robustness against\nenvironmental variations. Finally, we develop an efficient transformer-based\nimplicit CSI feedback network to exploit angular-delay domain sparsity and\nbi-directional correlation for ultra-low-rate CSI compression. Simulation\nresults demonstrate successful reduction of the feedback overhead by 85%\ncompared with the state-of-the-art method and robustness against unseen\nenvironments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12301v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "利用双向信道互易性实现基于深度学习的鲁棒超低速率隐式CSI反馈", "tldr": "本文提出Dual-ImRUNet，一个高效的上行链路辅助深度隐式CSI反馈框架，通过两个新颖的预处理模块，在实现超低反馈速率的同时保持高环境鲁棒性，相比现有技术将反馈开销降低85%。", "motivation": "现有的基于深度学习的隐式信道状态信息（CSI）反馈方法在超低速率场景下性能下降，并且对不同环境的适应性差。", "method": "本文提出了Dual-ImRUNet，一个高效的上行链路辅助深度隐式CSI反馈框架，包含两个新颖的插件预处理模块：\n1. 双向相关性增强模块：旨在增强上行链路和下行链路CSI特征向量矩阵之间的相关性，通过将高度相关的上行链路和下行链路信道矩阵投影到各自的特征空间，有效减少冗余。\n2. 输入格式对齐模块：用于在编码器和解码器端保持一致的数据分布，无需额外传输开销，从而增强对环境变化的鲁棒性。\n最后，开发了一个高效的基于Transformer的隐式CSI反馈网络，以利用角度-延迟域稀疏性和双向相关性进行超低速率CSI压缩。", "result": "仿真结果表明，与现有最先进的方法相比，反馈开销成功减少了85%，并且对未见过的环境具有鲁棒性。", "conclusion": "本文提出的Dual-ImRUNet框架通过创新的双向相关性增强和输入格式对齐模块，结合高效的Transformer网络，实现了超低速率的隐式CSI反馈，同时在不同环境中表现出卓越的鲁棒性。", "translation": "基于深度学习的隐式信道状态信息（CSI）反馈已被引入，以提高大规模MIMO系统的频谱效率。现有方法在超低速率场景中常常表现出性能下降，并且在不同环境中缺乏适应性。在本文中，我们提出了Dual-ImRUNet，一个高效的上行链路辅助深度隐式CSI反馈框架，它结合了两个新颖的插件预处理模块，以实现超低反馈速率，同时保持高环境鲁棒性。首先，提出了一个新的双向相关性增强模块，以加强上行链路和下行链路CSI特征向量矩阵之间的相关性。该模块将高度相关的上行链路和下行链路信道矩阵投影到各自的特征空间中，有效减少超低速率反馈的冗余。其次，设计了一个创新的输入格式对齐模块，以在编码器和解码器两侧保持一致的数据分布，而无需额外的传输开销，从而增强对环境变化的鲁棒性。最后，我们开发了一个高效的基于Transformer的隐式CSI反馈网络，以利用角度-延迟域稀疏性和双向相关性进行超低速率CSI压缩。仿真结果表明，与现有最先进的方法相比，反馈开销成功减少了85%，并且对未见过的环境具有鲁棒性。", "summary": "本文提出Dual-ImRUNet，一个基于深度学习的上行链路辅助隐式CSI反馈框架，旨在解决现有方法在超低速率和多变环境下的性能退化问题。该框架包含双向相关性增强模块和输入格式对齐模块，前者通过特征空间投影减少冗余，后者确保编码器和解码器数据分布一致性，从而提高鲁棒性。结合Transformer网络进行CSI压缩，实验证明Dual-ImRUNet能将反馈开销降低85%，并有效适应未知环境。", "keywords": "CSI反馈, 深度学习, 双向信道互易性, 超低速率, 大规模MIMO", "comments": "本文的创新点在于引入了双向相关性增强模块和输入格式对齐模块，有效地解决了超低速率CSI反馈中的冗余和环境鲁棒性问题。结合Transformer网络利用角度-延迟域稀疏性，进一步提升了压缩效率。该研究对于大规模MIMO系统中CSI反馈效率和鲁棒性的提升具有重要意义。"}}
{"id": "2507.12023", "title": "MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model", "authors": ["Xu Fan", "Zhihao Wang", "Yuetan Lin", "Yan Zhang", "Yang Xiang", "Hao Li"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12023v1", "summary": "Air pollutants pose a significant threat to the environment and human health,\nthus forecasting accurate pollutant concentrations is essential for pollution\nwarnings and policy-making. Existing studies predominantly focus on\nsingle-pollutant forecasting, neglecting the interactions among different\npollutants and their diverse spatial responses. To address the practical needs\nof forecasting multivariate air pollutants, we propose MultiVariate\nAutoRegressive air pollutants forecasting model (MVAR), which reduces the\ndependency on long-time-window inputs and boosts the data utilization\nefficiency. We also design the Multivariate Autoregressive Training Paradigm,\nenabling MVAR to achieve 120-hour long-term sequential forecasting.\nAdditionally, MVAR develops Meteorological Coupled Spatial Transformer block,\nenabling the flexible coupling of AI-based meteorological forecasts while\nlearning the interactions among pollutants and their diverse spatial responses.\nAs for the lack of standardized datasets in air pollutants forecasting, we\nconstruct a comprehensive dataset covering 6 major pollutants across 75 cities\nin North China from 2018 to 2023, including ERA5 reanalysis data and FuXi-2.0\nforecast data. Experimental results demonstrate that the proposed model\noutperforms state-of-the-art methods and validate the effectiveness of the\nproposed architecture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12023v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MVAR：多元自回归空气污染物预测模型", "tldr": "MVAR是一种用于多元空气污染物长期预测的模型，解决了现有单污染物预测的局限性，并构建了新的标准化数据集。", "motivation": "现有空气污染物预测研究主要关注单一污染物，忽略了不同污染物之间的相互作用及其多样化的空间响应，这无法满足实际中对多元空气污染物预测的需求。", "method": "本文提出了MVAR（多元自回归空气污染物预测模型），旨在减少对长时窗输入的依赖并提高数据利用效率。该模型设计了多元自回归训练范式，使其能够实现120小时的长期序列预测。MVAR还开发了气象耦合空间Transformer模块，以灵活耦合基于AI的气象预报，并学习污染物之间的相互作用及其多样化的空间响应。此外，针对空气污染物预测缺乏标准化数据集的问题，研究构建了一个全面的数据集，涵盖2018年至2023年华北地区75个城市的6种主要污染物，包括ERA5再分析数据和FuXi-2.0预测数据。", "result": "实验结果表明，所提出的MVAR模型优于现有最先进的方法，并且验证了所提出架构的有效性。", "conclusion": "MVAR模型通过其创新的架构和训练范式，成功解决了多元空气污染物长期预测的挑战，并在实际应用中展现出优越的性能，有效考虑了污染物间的相互作用和空间响应。", "translation": "空气污染物对环境和人类健康构成重大威胁，因此准确预测污染物浓度对于污染预警和政策制定至关重要。现有研究主要侧重于单一污染物预测，忽略了不同污染物之间的相互作用及其多样化的空间响应。为解决多元空气污染物预测的实际需求，我们提出了多元自回归空气污染物预测模型（MVAR），该模型减少了对长时窗输入的依赖，并提高了数据利用效率。我们还设计了多元自回归训练范式，使MVAR能够实现120小时的长期序列预测。此外，MVAR开发了气象耦合空间Transformer模块，能够灵活耦合基于AI的气象预报，同时学习污染物之间的相互作用及其多样化的空间响应。针对空气污染物预测中缺乏标准化数据集的问题，我们构建了一个全面的数据集，涵盖2018年至2023年华北地区75个城市的6种主要污染物，包括ERA5再分析数据和FuXi-2.0预测数据。实验结果表明，所提出的模型优于现有最先进的方法，并验证了所提出架构的有效性。", "summary": "本文提出了MVAR（多元自回归空气污染物预测模型），旨在解决现有研究在单一污染物预测上忽略污染物间相互作用及空间响应的局限。MVAR通过多元自回归训练范式实现了120小时的长期预测，并通过气象耦合空间Transformer模块灵活整合气象数据并捕捉污染物复杂交互。为弥补数据空白，研究构建了一个涵盖华北地区多城市、多污染物、长时间跨度的综合数据集。实验证明MVAR在性能上超越了现有先进方法，验证了其架构的有效性。", "keywords": "空气污染物预测, 多元自回归, 长期预测, 空间Transformer, 数据集", "comments": "这篇论文通过提出MVAR模型，有效解决了多元空气污染物长期预测的复杂问题，特别是在考虑污染物相互作用和空间响应方面具有创新性。构建新的综合数据集也填补了该领域标准化数据的空白，对后续研究具有重要贡献。模型的长期预测能力和与气象数据的灵活耦合是其亮点。"}}
{"id": "2506.05935", "title": "SurGSplat: Progressive Geometry-Constrained Gaussian Splatting for Surgical Scene Reconstruction", "authors": ["Yuchao Zheng", "Jianing Zhang", "Guochen Ning", "Hongen Liao"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.05935v2", "summary": "Intraoperative navigation relies heavily on precise 3D reconstruction to\nensure accuracy and safety during surgical procedures. However, endoscopic\nscenarios present unique challenges, including sparse features and inconsistent\nlighting, which render many existing Structure-from-Motion (SfM)-based methods\ninadequate and prone to reconstruction failure. To mitigate these constraints,\nwe propose SurGSplat, a novel paradigm designed to progressively refine 3D\nGaussian Splatting (3DGS) through the integration of geometric constraints. By\nenabling the detailed reconstruction of vascular structures and other critical\nfeatures, SurGSplat provides surgeons with enhanced visual clarity,\nfacilitating precise intraoperative decision-making. Experimental evaluations\ndemonstrate that SurGSplat achieves superior performance in both novel view\nsynthesis (NVS) and pose estimation accuracy, establishing it as a\nhigh-fidelity and efficient solution for surgical scene reconstruction. More\ninformation and results can be found on the page https://surgsplat.github.io/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.05935v2", "cate": "cs.GR", "date": "2025-06-06", "updated": "2025-07-16", "AI": {"title_translation": "SurGSplat：渐进式几何约束高斯泼溅用于手术场景重建", "tldr": "SurGSplat通过几何约束渐进式优化3D高斯泼溅，实现高精度手术场景重建，解决内窥镜手术场景中稀疏特征和光照不一致的问题。", "motivation": "术中导航依赖精确3D重建，但内窥镜场景的稀疏特征和不一致光照导致许多现有基于运动恢复结构（SfM）的方法不足且易导致重建失败。", "method": "提出SurGSplat，一种通过集成几何约束来渐进式优化3D高斯泼溅（3DGS）的新范式，旨在实现血管结构和其他关键特征的详细重建。", "result": "SurGSplat在新视角合成（NVS）和姿态估计精度方面均取得了卓越性能。", "conclusion": "SurGSplat是手术场景重建的高保真、高效解决方案，能为外科医生提供增强的视觉清晰度，促进精确术中决策。", "translation": "术中导航严重依赖精确的3D重建，以确保手术过程中的准确性和安全性。然而，内窥镜场景带来了独特的挑战，包括稀疏特征和不一致的光照，这使得许多现有的基于运动恢复结构（SfM）的方法不足且容易导致重建失败。为了缓解这些限制，我们提出了SurGSplat，这是一种新颖的范式，旨在通过集成几何约束来渐进式优化3D高斯泼溅（3DGS）。通过实现血管结构和其他关键特征的详细重建，SurGSplat为外科医生提供了增强的视觉清晰度，促进精确的术中决策。实验评估表明，SurGSplat在新视角合成（NVS）和姿态估计精度方面均取得了卓越的性能，使其成为手术场景重建的高保真、高效解决方案。更多信息和结果可在https://surgsplat.github.io/页面找到。", "summary": "SurGSplat提出了一种新颖的渐进式几何约束3D高斯泼溅方法，旨在解决内窥镜手术场景中稀疏特征和光照不一致导致的3D重建挑战。该方法通过详细重建血管结构等关键特征，显著提升了术中导航的视觉清晰度。实验证明，SurGSplat在NVS和姿态估计方面均表现出色，是一种高保真、高效的手术场景重建方案。", "keywords": "手术场景重建, 3D高斯泼溅, 几何约束, 术中导航, 新视角合成", "comments": "这篇论文通过将几何约束引入3D高斯泼溅，创新性地解决了内窥镜手术场景中传统SfM方法面临的挑战。其重要性在于，高精度的3D重建能显著提升术中导航的准确性和安全性，对临床实践具有直接价值。"}}
{"id": "2502.09724", "title": "Navigating the Social Welfare Frontier: Portfolios for Multi-objective Reinforcement Learning", "authors": ["Cheol Woo Kim", "Jai Moondra", "Shresth Verma", "Madeleine Pollack", "Lingkai Kong", "Milind Tambe", "Swati Gupta"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.09724v2", "summary": "In many real-world applications of reinforcement learning (RL), deployed\npolicies have varied impacts on different stakeholders, creating challenges in\nreaching consensus on how to effectively aggregate their preferences.\nGeneralized $p$-means form a widely used class of social welfare functions for\nthis purpose, with broad applications in fair resource allocation, AI\nalignment, and decision-making. This class includes well-known welfare\nfunctions such as Egalitarian, Nash, and Utilitarian welfare. However,\nselecting the appropriate social welfare function is challenging for\ndecision-makers, as the structure and outcomes of optimal policies can be\nhighly sensitive to the choice of $p$. To address this challenge, we study the\nconcept of an $\\alpha$-approximate portfolio in RL, a set of policies that are\napproximately optimal across the family of generalized $p$-means for all $p \\in\n[-\\infty, 1]$. We propose algorithms to compute such portfolios and provide\ntheoretical guarantees on the trade-offs among approximation factor, portfolio\nsize, and computational efficiency. Experimental results on synthetic and\nreal-world datasets demonstrate the effectiveness of our approach in\nsummarizing the policy space induced by varying $p$ values, empowering\ndecision-makers to navigate this landscape more effectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.09724v2", "cate": "cs.LG", "date": "2025-02-13", "updated": "2025-07-16", "AI": {"title_translation": "驾驭社会福利前沿：多目标强化学习的策略组合", "tldr": "本文研究在多目标强化学习中，由于社会福利函数（广义p-均值）对参数p的选择敏感，导致难以确定最优策略的问题。作者提出了一个$\\\\alpha$-近似策略组合的概念和算法，旨在为决策者提供一组在不同p值下近似最优的策略，并通过实验验证了其有效性。", "motivation": "在强化学习的许多实际应用中，部署的策略对不同利益相关者产生不同的影响，这导致在有效聚合他们的偏好方面存在挑战。广义p-均值作为一类广泛使用的社会福利函数，其最优策略的结构和结果对p的选择高度敏感，这使得决策者难以选择合适的社会福利函数。", "method": "本文研究了强化学习中$\\alpha$-近似策略组合的概念，即一组在所有$p \\in [-\\\\infty, 1]$的广义p-均值家族中近似最优的策略。作者提出了计算此类组合的算法，并提供了关于近似因子、组合大小和计算效率之间权衡的理论保证。", "result": "在合成数据集和真实世界数据集上的实验结果表明，该方法在总结由不同p值引起的策略空间方面是有效的，从而使决策者能够更有效地驾驭这一局面。", "conclusion": "通过引入$\\alpha$-近似策略组合及其计算算法，本文有效解决了多目标强化学习中社会福利函数选择的敏感性问题，赋能决策者更有效地探索和选择策略。", "translation": "在强化学习（RL）的许多实际应用中，部署的策略对不同利益相关者产生不同的影响，这在如何有效聚合他们的偏好方面带来了挑战。广义p-均值是为此目的广泛使用的一类社会福利函数，在公平资源分配、AI对齐和决策制定中具有广泛应用。这类函数包括著名的福利函数，如平均主义、纳什和功利主义福利。然而，选择合适的社会福利函数对决策者来说是一个挑战，因为最优策略的结构和结果可能对p的选择高度敏感。为了解决这一挑战，我们研究了RL中$\\alpha$-近似策略组合的概念，这是一组在所有$p \\in [-\\\\infty, 1]$的广义p-均值家族中近似最优的策略。我们提出了计算此类组合的算法，并提供了关于近似因子、组合大小和计算效率之间权衡的理论保证。在合成数据集和真实世界数据集上的实验结果表明，我们的方法在总结由不同p值引起的策略空间方面是有效的，从而使决策者能够更有效地驾驭这一局面。", "summary": "该研究旨在解决多目标强化学习中，社会福利函数（广义p-均值）对参数p敏感导致决策困难的问题。文章提出了$\\alpha$-近似策略组合的概念，即一组在不同广义p-均值下均近似最优的策略。作者开发了计算这些策略组合的算法，并提供了理论保证。实验结果表明，该方法能有效概括策略空间，帮助决策者更好地进行决策。", "keywords": "多目标强化学习, 社会福利函数, 策略组合, 广义p-均值, 决策制定", "comments": "本文的创新点在于提出了“$\\alpha$-近似策略组合”的概念，这提供了一种新颖的方式来应对多目标强化学习中社会福利函数选择的敏感性问题。通过提供一个策略集合而非单一最优策略，它极大地增强了决策者在复杂多目标环境中的灵活性和洞察力，具有重要的实际应用价值。"}}
{"id": "2507.11991", "title": "Robust Planning for Autonomous Vehicles with Diffusion-Based Failure Samplers", "authors": ["Juanran Wang", "Marc R. Schlichting", "Mykel J. Kochenderfer"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11991v1", "summary": "High-risk traffic zones such as intersections are a major cause of\ncollisions. This study leverages deep generative models to enhance the safety\nof autonomous vehicles in an intersection context. We train a 1000-step\ndenoising diffusion probabilistic model to generate collision-causing sensor\nnoise sequences for an autonomous vehicle navigating a four-way intersection\nbased on the current relative position and velocity of an intruder. Using the\ngenerative adversarial architecture, the 1000-step model is distilled into a\nsingle-step denoising diffusion model which demonstrates fast inference speed\nwhile maintaining similar sampling quality. We demonstrate one possible\napplication of the single-step model in building a robust planner for the\nautonomous vehicle. The planner uses the single-step model to efficiently\nsample potential failure cases based on the currently measured traffic state to\ninform its decision-making. Through simulation experiments, the robust planner\ndemonstrates significantly lower failure rate and delay rate compared with the\nbaseline Intelligent Driver Model controller.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11991v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "自动驾驶车辆基于扩散的故障采样器鲁棒规划", "tldr": "本研究利用精炼的扩散模型生成碰撞场景，以实现自动驾驶车辆的鲁棒规划，并在交叉路口表现出更高的安全性。", "motivation": "交叉路口等高风险交通区域是造成碰撞的主要原因，本研究旨在提高自动驾驶车辆在交叉路口环境中的安全性。", "method": "1. 训练一个1000步的去噪扩散概率模型（DDPM），根据入侵者的相对位置和速度，生成导致自动驾驶车辆在四向交叉路口发生碰撞的传感器噪声序列。2. 利用生成对抗架构，将1000步模型提炼成单步去噪扩散模型，以实现快速推理并保持采样质量。3. 将单步模型应用于鲁棒规划器，根据当前交通状态有效采样潜在故障情况，以指导决策。", "result": "单步模型在保持相似采样质量的同时，展示了快速的推理速度。与基线智能驾驶模型（IDM）控制器相比，鲁棒规划器在仿真实验中显示出显著降低的故障率和延迟率。", "conclusion": "所提出的鲁棒规划器利用精炼的扩散模型进行故障采样，显著提高了自动驾驶车辆在高风险交叉路口场景中的安全性和效率。", "translation": "诸如交叉路口等高风险交通区域是造成碰撞的主要原因。本研究利用深度生成模型来提高自动驾驶车辆在交叉路口环境中的安全性。我们训练了一个1000步的去噪扩散概率模型，根据入侵者的当前相对位置和速度，为在四向交叉路口行驶的自动驾驶车辆生成导致碰撞的传感器噪声序列。利用生成对抗架构，将1000步模型提炼成单步去噪扩散模型，该模型在保持相似采样质量的同时，展示了快速的推理速度。我们展示了单步模型在构建自动驾驶车辆鲁棒规划器方面的一种可能应用。该规划器使用单步模型根据当前测量的交通状态有效采样潜在的故障情况，以指导其决策。通过仿真实验，与基线智能驾驶模型控制器相比，鲁棒规划器显示出显著降低的故障率和延迟率。", "summary": "本论文旨在解决自动驾驶车辆在高风险交叉路口区域的安全性问题，提出了一种鲁棒规划方法。该方法利用一个1000步的去噪扩散概率模型生成导致碰撞的传感器噪声序列，随后将其提炼成一个更快的单步模型。这个单步扩散模型被集成到鲁棒规划器中，能够高效采样潜在的故障情况以指导决策。仿真结果表明，与基线控制器相比，该鲁棒规划器显著降低了故障率和延迟率。", "keywords": "自动驾驶车辆, 鲁棒规划, 扩散模型, 故障采样, 交叉路口", "comments": "本文的创新之处在于利用扩散模型，特别是经过精炼的单步版本，高效生成故障案例，以增强自动驾驶车辆规划的鲁棒性。这种方法提供了一种新颖途径，通过主动识别和缓解潜在碰撞风险，提高在交叉路口等复杂交通场景中的安全性。模型蒸馏过程对于满足实际应用的速度需求至关重要。"}}
{"id": "2412.19819", "title": "ChipAlign: Instruction Alignment in Large Language Models for Chip Design via Geodesic Interpolation", "authors": ["Chenhui Deng", "Yunsheng Bai", "Haoxing Ren"], "categories": ["cs.AR", "cs.AI"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      Accepted to DAC 2025", "url": "http://arxiv.org/abs/2412.19819v2", "summary": "Recent advancements in large language models (LLMs) have expanded their\napplication across various domains, including chip design, where domain-adapted\nchip models like ChipNeMo have emerged. However, these models often struggle\nwith instruction alignment, a crucial capability for LLMs that involves\nfollowing explicit human directives. This limitation impedes the practical\napplication of chip LLMs, including serving as assistant chatbots for hardware\ndesign engineers. In this work, we introduce ChipAlign, a novel approach that\nutilizes a training-free model merging strategy, combining the strengths of a\ngeneral instruction-aligned LLM with a chip-specific LLM. By considering the\nunderlying manifold in the weight space, ChipAlign employs geodesic\ninterpolation to effectively fuse the weights of input LLMs, producing a merged\nmodel that inherits strong instruction alignment and chip expertise from the\nrespective instruction and chip LLMs. Our results demonstrate that ChipAlign\nsignificantly enhances instruction-following capabilities of existing chip\nLLMs, achieving up to a 26.6% improvement on the IFEval benchmark, while\nmaintaining comparable expertise in the chip domain. This improvement in\ninstruction alignment also translates to notable gains in instruction-involved\nQA tasks, delivering performance enhancements of 3.9% on the OpenROAD QA\nbenchmark and 8.25% on production-level chip QA benchmarks, surpassing\nstate-of-the-art baselines.", "comment": "Accepted to DAC 2025", "pdf_url": "http://arxiv.org/pdf/2412.19819v2", "cate": "cs.AR", "date": "2024-12-15", "updated": "2025-07-15", "AI": {"title_translation": "ChipAlign：通过测地线插值实现芯片设计大型语言模型中的指令对齐", "tldr": "ChipAlign通过将通用指令对齐LLM与芯片专用LLM结合，利用测地线插值进行模型合并，显著提升了芯片LLM的指令遵循能力和问答性能。", "motivation": "现有的大型语言模型在芯片设计领域的应用中，面临指令对齐能力不足的问题，这阻碍了它们在实际应用中的部署，例如作为硬件设计工程师的助手聊天机器人。", "method": "引入了ChipAlign，这是一种无训练的模型合并策略，通过在权重空间中考虑底层流形，采用测地线插值来有效地融合通用指令对齐LLM和芯片专用LLM的权重，从而生成一个继承了强大指令对齐能力和芯片领域专业知识的合并模型。", "result": "ChipAlign显著增强了现有芯片LLM的指令遵循能力，在IFEval基准测试中实现了高达26.6%的改进，同时保持了可比的芯片领域专业知识。此外，在指令相关问答任务中，在OpenROAD QA基准测试中性能提升了3.9%，在生产级芯片QA基准测试中提升了8.25%，超越了现有基线。", "conclusion": "ChipAlign显著增强了现有芯片LLM的指令遵循能力，并在指令相关问答任务中表现出色，超越了现有基线。", "translation": "大型语言模型（LLMs）的最新进展已将其应用扩展到各个领域，包括芯片设计，其中出现了像ChipNeMo这样的领域适应性芯片模型。然而，这些模型通常在指令对齐方面遇到困难，这是LLMs的一项关键能力，涉及遵循明确的人类指令。这一限制阻碍了芯片LLMs的实际应用，包括作为硬件设计工程师的助手聊天机器人。在这项工作中，我们引入了ChipAlign，这是一种新颖的方法，它利用一种免训练的模型合并策略，结合了通用指令对齐LLM和芯片专用LLM的优势。通过考虑权重空间中的底层流形，ChipAlign采用测地线插值有效地融合了输入LLMs的权重，生成一个合并模型，该模型从各自的指令LLM和芯片LLM继承了强大的指令对齐能力和芯片专业知识。我们的结果表明，ChipAlign显著增强了现有芯片LLMs的指令遵循能力，在IFEval基准测试中实现了高达26.6%的改进，同时保持了可比的芯片领域专业知识。指令对齐的这种改进也转化为指令相关问答任务的显著收益，在OpenROAD QA基准测试中提供了3.9%的性能提升，在生产级芯片QA基准测试中提供了8.25%的性能提升，超越了最先进的基线。", "summary": "大型语言模型在芯片设计领域面临指令对齐的挑战，影响了其作为工程师助手的实际应用。为解决此问题，本文提出了ChipAlign，一种创新的无训练模型合并方法。ChipAlign通过测地线插值技术，将通用指令对齐LLM与芯片专用LLM的权重进行融合，从而使合并模型同时具备强大的指令遵循能力和芯片领域专业知识。实验结果显示，ChipAlign显著提升了现有芯片LLM的指令遵循能力（IFEval基准测试提升26.6%），并在指令相关问答任务中表现出色（OpenROAD QA提升3.9%，生产级芯片QA提升8.25%），超越了现有SOTA基线。", "keywords": "大型语言模型, 芯片设计, 指令对齐, 模型合并, 测地线插值", "comments": "本文的创新点在于提出了利用测地线插值进行无训练模型合并的策略，有效地将通用指令对齐能力与特定领域知识相结合。这对于提升芯片设计领域LLM的实用性具有重要意义，解决了现有模型在指令遵循方面的局限性。该方法为未来领域特定LLM的开发提供了一个新的思路。"}}
{"id": "2507.12082", "title": "Inductance Estimation for High-Power Multilayer Rectangle Planar Windings", "authors": ["Theofilos Papadopoulos", "Antonios Antonopoulos"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      7 pages, 7 figures, IEEE Journal of Emerging and Selected Topics in Industrial Electronics, 2025", "url": "http://arxiv.org/abs/2507.12082v1", "summary": "This paper proposes a simple and accurate monomial-like equation for\nestimating the inductance of Multilayer Rectangle-shaped Planar Windings\n(MLRPWs) for high-frequency, high-power applications. The equation consists of\nthe power product of the geometrical dimensions, raised at individual power\ncoefficients. The coefficients are generated via Multiple Linear Regression\n(MLR), based on a large set of approximately 6,000 simulated windings, with an\n80/20 training/evaluation sample ratio. The resulting mean error value is 0%,\nwith a standard deviation below 1.8%. The accuracy of the inductance estimation\nis confirmed on several experimental samples, with dimensions both within and\noutside the initial training dataset.", "comment": "7 pages, 7 figures, IEEE Journal of Emerging and Selected Topics in\n  Industrial Electronics, 2025", "pdf_url": "http://arxiv.org/pdf/2507.12082v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "大功率多层矩形平面绕组电感估算", "tldr": "本文提出了一种简单准确的单项式方程，用于估算高频、大功率应用中的多层矩形平面绕组的电感。该方程通过多元线性回归从6000个模拟绕组数据中生成系数，实现了0%的平均误差和低于1.8%的标准差，并得到了实验验证。", "motivation": "为了解决高频、大功率应用中多层矩形平面绕组的电感估算问题，本文旨在提出一个简单且准确的估算方程。", "method": "本文提出了一种单项式方程来估算电感。该方程由几何尺寸的幂乘积组成，各项具有独立的幂系数。这些系数是通过多元线性回归（MLR）从约6,000个模拟绕组的大型数据集中生成的，其中训练/评估样本比例为80/20。", "result": "该方法估算的平均误差值为0%，标准差低于1.8%。电感估算的准确性在几个实验样本上得到了证实，这些样本的尺寸既包括初始训练数据集内的，也包括其之外的。", "conclusion": "本文提出的单项式方程能够简单而准确地估算高频、大功率应用中多层矩形平面绕组的电感，且具有极低的误差。", "translation": "本文提出了一种简单准确的单项式方程，用于估算高频、大功率应用中的多层矩形平面绕组（MLRPWs）的电感。该方程由几何尺寸的幂乘积组成，具有独立的幂系数。这些系数是通过多元线性回归（MLR）生成的，基于大约6,000个模拟绕组的大型数据集，其中训练/评估样本比例为80/20。结果显示平均误差值为0%，标准差低于1.8%。电感估算的准确性在几个实验样本上得到了证实，这些样本的尺寸既包括初始训练数据集内的，也包括其之外的。", "summary": "本文提出了一种用于估算高频、大功率多层矩形平面绕组电感的单项式方程。该方程的系数通过对约6,000个模拟绕组数据进行多元线性回归获得，表现出0%的平均误差和低于1.8%的标准差。实验验证进一步证实了其在训练数据内外尺寸样本上的高精度。", "keywords": "电感估算, 多层平面绕组, 多元线性回归, 高频, 高功率", "comments": "该论文的创新之处在于提出了一个基于多元线性回归的简单单项式方程来精确估算多层矩形平面绕组的电感，尤其适用于高频、高功率应用。其重要性体现在为电源设计和优化提供了实用且高效的工具，显著降低了电感估算的复杂性和误差。通过大规模仿真数据训练和实验验证，提升了模型的可靠性和泛化能力。"}}
{"id": "2507.12428", "title": "Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models", "authors": ["Yik Siu Chan", "Zheng-Xin Yong", "Stephen H. Bach"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12428v1", "summary": "Open-weights reasoning language models generate long chains-of-thought (CoTs)\nbefore producing a final response, which improves performance but introduces\nadditional alignment risks, with harmful content often appearing in both the\nCoTs and the final outputs. In this work, we investigate if we can use CoTs to\npredict final response misalignment. We evaluate a range of monitoring\napproaches, including humans, highly-capable large language models, and text\nclassifiers, using either CoT text or activations. First, we find that a simple\nlinear probe trained on CoT activations can significantly outperform all\ntext-based methods in predicting whether a final response will be safe or\nunsafe. CoT texts are often unfaithful and can mislead humans and classifiers,\nwhile model latents (i.e., CoT activations) offer a more reliable predictive\nsignal. Second, the probe makes accurate predictions before reasoning\ncompletes, achieving strong performance even when applied to early CoT\nsegments. These findings generalize across model sizes, families, and safety\nbenchmarks, suggesting that lightweight probes could enable real-time safety\nmonitoring and early intervention during generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12428v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "我们能在模型思考完成前预测其对齐性吗？迈向监控未对齐的推理模型", "tldr": "本文研究了在大型语言模型完成思考前，如何通过分析其思维链（CoTs）来预测其输出是否会未对齐。研究发现，基于CoT激活的轻量级探针在预测对齐性方面显著优于基于文本的方法，并且能够实现早期、实时的安全监控。", "motivation": "开源推理语言模型生成的思维链（CoTs）虽然提高了性能，但也引入了额外的对齐风险，有害内容可能出现在CoTs和最终输出中。因此，本文旨在研究是否能利用CoTs来预测最终响应的未对齐性，以实现实时安全监控。", "method": "研究评估了一系列监控方法，包括人类、高能力大型语言模型和文本分类器，它们分别使用CoT文本或激活。核心方法是在CoT激活上训练一个简单的线性探针，并将其性能与所有基于文本的方法进行比较，以预测最终响应是否安全。此外，还测试了该探针在早期CoT片段上的预测能力。", "result": "1. 在预测最终响应是否安全方面，一个在CoT激活上训练的简单线性探针能显著优于所有基于文本的方法。\n2. CoT文本常常不忠实并可能误导人类和分类器，而模型潜在变量（即CoT激活）提供了更可靠的预测信号。\n3. 该探针在推理完成前就能做出准确预测，即使应用于早期的CoT片段也能获得强大的性能。\n4. 这些发现适用于不同的模型大小、家族和安全基准。", "conclusion": "通过在思维链（CoT）激活上训练轻量级探针，可以实现对未对齐推理模型的实时安全监控和早期干预，因为激活信号比CoT文本本身更能提供可靠的预测。", "translation": "开源推理语言模型在生成最终响应之前会生成长串思维链（CoTs），这虽然提高了性能，但也带来了额外的对齐风险，有害内容经常出现在CoTs和最终输出中。在这项工作中，我们研究是否可以使用CoTs来预测最终响应的未对齐性。我们评估了一系列监控方法，包括人类、高能力大型语言模型和文本分类器，使用CoT文本或激活。首先，我们发现一个在CoT激活上训练的简单线性探针在预测最终响应是否安全方面可以显著优于所有基于文本的方法。CoT文本通常不忠实，可能会误导人类和分类器，而模型潜在变量（即CoT激活）提供了更可靠的预测信号。其次，该探针在推理完成之前就能做出准确预测，即使应用于早期的CoT片段也能获得强大的性能。这些发现适用于不同的模型大小、家族和安全基准，表明轻量级探针可以在生成过程中实现实时安全监控和早期干预。", "summary": "本文探讨了如何在大型推理语言模型生成完整响应之前，通过分析其思维链（CoTs）来预测其对齐性。研究发现，在CoT激活上训练的简单线性探针在预测最终响应是否安全方面，显著优于基于文本的方法。这种探针不仅提供了更可靠的预测信号（因为CoT文本可能具有误导性），还能在推理过程早期就做出准确预测。这些发现普适于不同模型，表明轻量级探针有望实现生成过程中的实时安全监控和早期干预。", "keywords": "对齐预测, 思维链, 未对齐推理, 实时监控, 模型激活", "comments": "该论文的创新点在于，它提出并验证了利用模型内部的“激活”（即潜在变量）而非表面的思维链文本来检测模型未对齐行为的有效性，这比依赖文本的方法更为可靠。这一发现为解决大型语言模型部署中的关键安全挑战提供了实用的途径，特别是在实现实时安全监控和早期干预方面具有重要意义。其结果在不同模型和基准上的泛化性进一步增强了其实用价值和潜在影响。"}}
{"id": "2503.12955", "title": "HIS-GPT: Towards 3D Human-In-Scene Multimodal Understanding", "authors": ["Jiahe Zhao", "Ruibing Hou", "Zejie Tian", "Hong Chang", "Shiguang Shan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2503.12955v2", "summary": "We propose a new task to benchmark human-in-scene understanding for embodied\nagents: Human-In-Scene Question Answering (HIS-QA). Given a human motion within\na 3D scene, HIS-QA requires the agent to comprehend human states and behaviors,\nreason about its surrounding environment, and answer human-related questions\nwithin the scene. To support this new task, we present HIS-Bench, a multimodal\nbenchmark that systematically evaluates HIS understanding across a broad\nspectrum, from basic perception to commonsense reasoning and planning. Our\nevaluation of various vision-language models on HIS-Bench reveals significant\nlimitations in their ability to handle HIS-QA tasks. To this end, we propose\nHIS-GPT, the first foundation model for HIS understanding. HIS-GPT integrates\n3D scene context and human motion dynamics into large language models while\nincorporating specialized mechanisms to capture human-scene interactions.\nExtensive experiments demonstrate that HIS-GPT sets a new state-of-the-art on\nHIS-QA tasks. We hope this work inspires future research on human behavior\nanalysis in 3D scenes, advancing embodied AI and world models. The codes and\ndata: https://github.com/ZJHTerry18/HumanInScene.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.12955v2", "cate": "cs.CV", "date": "2025-03-17", "updated": "2025-07-16", "AI": {"title_translation": "HIS-GPT：迈向3D场景中人类多模态理解", "tldr": "本文提出了一个新的任务HIS-QA和基准HIS-Bench，用于评估具身智能体对3D场景中人类的理解能力。为解决现有模型在该任务上的局限性，作者提出了HIS-GPT，一个结合3D场景和人类运动的开创性基础模型，并在HIS-QA任务上达到了SOTA性能。", "motivation": "为了基准化具身智能体在3D场景中人类行为的理解能力，并解决现有视觉-语言模型在处理人类-场景问答（HIS-QA）任务时的显著局限性。", "method": "本文提出了一个新的任务：场景中人类问答（HIS-QA），并构建了多模态基准数据集HIS-Bench来系统性评估HIS理解能力。为此，作者提出了HIS-GPT，这是首个用于HIS理解的基础模型，它将3D场景上下文和人类运动动态整合到大型语言模型中，并包含捕获人类-场景交互的专门机制。", "result": "广泛的实验表明，HIS-GPT在HIS-QA任务上达到了新的最先进水平（state-of-the-art）。", "conclusion": "这项工作有望启发未来在3D场景中人类行为分析的研究，从而推动具身AI和世界模型的发展。", "translation": "我们提出了一个新任务来基准化具身智能体在场景中人类的理解能力：场景中人类问答（HIS-QA）。给定3D场景中的人类动作，HIS-QA要求智能体理解人类状态和行为，推理其周围环境，并回答场景中与人类相关的问题。为了支持这项新任务，我们提出了HIS-Bench，一个多模态基准，系统地评估HIS理解，范围从基本感知到常识推理和规划。我们对HIS-Bench上各种视觉-语言模型的评估揭示了它们在处理HIS-QA任务方面的显著局限性。为此，我们提出了HIS-GPT，这是首个用于HIS理解的基础模型。HIS-GPT将3D场景上下文和人类运动动态整合到大型语言模型中，同时结合了专门机制来捕捉人类-场景交互。广泛的实验表明，HIS-GPT在HIS-QA任务上达到了新的最先进水平。我们希望这项工作能激发未来在3D场景中人类行为分析方面的研究，从而推动具身AI和世界模型的发展。代码和数据：https://github.com/ZJHTerry18/HumanInScene。", "summary": "本文引入了“场景中人类问答（HIS-QA）”这一新任务，旨在评估具身智能体对3D场景中人类行为的理解能力。为支持该任务，作者构建了多模态基准HIS-Bench，并发现现有视觉-语言模型在该任务上存在不足。为此，论文提出了HIS-GPT，一个创新的基础模型，它将3D场景信息和人类运动动态融入大型语言模型，并专注于捕获人-场景交互。实验证明HIS-GPT在HIS-QA任务上表现出色，达到了最先进水平，有望推动具身AI和3D场景中人类行为分析的研究。", "keywords": "人类-场景理解, 多模态, 3D场景, 具身AI, HIS-GPT", "comments": "本文的主要创新在于提出了一个全新的任务HIS-QA和配套的基准HIS-Bench，这对于推动具身智能体在复杂3D环境中理解人类行为至关重要。此外，HIS-GPT作为首个专门用于HIS理解的基础模型，通过有效整合3D场景上下文和人类运动动态，并结合了人-场景交互机制，显著提升了该领域的性能。这项工作为未来具身AI和世界模型的发展奠定了基础。"}}
{"id": "2507.12207", "title": "BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution", "authors": ["Subin Lin", "Chuanbo Hua"], "categories": ["cs.AI", "cs.NE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      ICML 2025 CO-Build Workshop Poster", "url": "http://arxiv.org/abs/2507.12207v1", "summary": "Accurate building energy forecasting is essential, yet traditional heuristics\noften lack precision, while advanced models can be opaque and struggle with\ngeneralization by neglecting physical principles. This paper introduces\nBuildEvo, a novel framework that uses Large Language Models (LLMs) to\nautomatically design effective and interpretable energy prediction heuristics.\nWithin an evolutionary process, BuildEvo guides LLMs to construct and enhance\nheuristics by systematically incorporating physical insights from building\ncharacteristics and operational data (e.g., from the Building Data Genome\nProject 2). Evaluations show BuildEvo achieves state-of-the-art performance on\nbenchmarks, offering improved generalization and transparent prediction logic.\nThis work advances the automated design of robust, physically grounded\nheuristics, promoting trustworthy models for complex energy systems.", "comment": "ICML 2025 CO-Build Workshop Poster", "pdf_url": "http://arxiv.org/pdf/2507.12207v1", "cate": "cs.AI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "BuildEvo：通过LLM驱动的进化设计建筑能耗预测启发式算法", "tldr": "BuildEvo利用大型语言模型（LLMs）通过进化过程自动设计和改进建筑能耗预测启发式算法，实现了最先进的性能和更好的泛化能力。", "motivation": "传统的建筑能耗预测启发式算法精度不足，而先进模型则不透明且由于忽视物理原理而泛化能力差。因此，需要设计有效且可解释的能耗预测启发式算法。", "method": "本文引入了BuildEvo框架，该框架在一个进化过程中利用大型语言模型（LLMs）自动设计和增强能耗预测启发式算法。它通过系统地整合来自建筑特性和运行数据（如Building Data Genome Project 2）的物理见解来指导LLMs构建和改进启发式算法。", "result": "BuildEvo在基准测试中取得了最先进的性能，并提供了改进的泛化能力和透明的预测逻辑。", "conclusion": "这项工作推动了鲁棒的、基于物理的启发式算法的自动化设计，为复杂的能源系统推广了值得信赖的模型。", "translation": "准确的建筑能耗预测至关重要，然而传统的启发式算法往往缺乏精度，而先进模型可能不透明且由于忽视物理原理而难以泛化。本文引入了BuildEvo，一个新颖的框架，它使用大型语言模型（LLMs）自动设计有效且可解释的能耗预测启发式算法。在一个进化过程中，BuildEvo通过系统地整合来自建筑特性和运行数据（例如，来自Building Data Genome Project 2）的物理见解来指导LLMs构建和增强启发式算法。评估表明，BuildEvo在基准测试中取得了最先进的性能，提供了改进的泛化能力和透明的预测逻辑。这项工作推动了鲁棒的、基于物理的启发式算法的自动化设计，促进了复杂能源系统值得信赖的模型。", "summary": "BuildEvo是一个利用大型语言模型（LLMs）在进化框架内自动设计和优化建筑能耗预测启发式算法的新方法。它通过整合物理洞察力来提高预测的准确性、可解释性和泛化能力。实验证明，BuildEvo在能耗预测方面达到了最先进的水平，为能源系统提供了更可靠和透明的模型。", "keywords": "建筑能耗预测, 大型语言模型, 启发式算法, 进化算法, 物理见解", "comments": "该论文的创新之处在于将LLMs与进化算法结合，用于自动设计具有物理基础的、可解释的能耗预测启发式算法，解决了传统方法精度低或可解释性差的问题。其重要性在于提升了建筑能耗预测的可靠性和透明度，有助于推广值得信赖的能源管理模型。"}}
{"id": "2507.11683", "title": "PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training", "authors": ["Seth Ockerman", "Amal Gueroudji", "Tanwi Mallick", "Yixuan He", "Line Pouchard", "Robert Ross", "Shivaram Venkataraman"], "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      To be published in the 2025 International Conference for High Performance Computing, Networking, Storage, and Analysis", "url": "http://arxiv.org/abs/2507.11683v1", "summary": "Spatiotemporal graph neural networks (ST-GNNs) are powerful tools for\nmodeling spatial and temporal data dependencies. However, their applications\nhave been limited primarily to small-scale datasets because of memory\nconstraints. While distributed training offers a solution, current frameworks\nlack support for spatiotemporal models and overlook the properties of\nspatiotemporal data. Informed by a scaling study on a large-scale workload, we\npresent PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorch\nGeometric Temporal that integrates distributed data parallel training and two\nnovel strategies: index-batching and distributed-index-batching. Our index\ntechniques exploit spatiotemporal structure to construct snapshots dynamically\nat runtime, significantly reducing memory overhead, while\ndistributed-index-batching extends this approach by enabling scalable\nprocessing across multiple GPUs. Our techniques enable the first-ever training\nof an ST-GNN on the entire PeMS dataset without graph partitioning, reducing\npeak memory usage by up to 89\\% and achieving up to a 13.1x speedup over\nstandard DDP with 128 GPUs.", "comment": "To be published in the 2025 International Conference for High\n  Performance Computing, Networking, Storage, and Analysis", "pdf_url": "http://arxiv.org/pdf/2507.11683v1", "cate": "cs.DC", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "PGT-I：面向时空图神经网络的内存高效分布式训练扩展", "tldr": "PGT-I通过引入索引批处理和分布式索引批处理，显著降低了时空图神经网络的内存消耗，并实现了大规模数据集上的高效分布式训练。", "motivation": "时空图神经网络（ST-GNNs）在建模时空数据依赖方面功能强大，但由于内存限制，其应用主要限于小规模数据集。当前的分布式训练框架缺乏对时空模型的支持，并忽视了时空数据的特性。", "method": "本文提出了PyTorch Geometric Temporal Index (PGT-I)，它是PyTorch Geometric Temporal的一个扩展，集成了分布式数据并行训练和两种新颖的策略：索引批处理（index-batching）和分布式索引批处理（distributed-index-batching）。这些索引技术利用时空结构在运行时动态构建快照，显著减少内存开销，并通过分布式索引批处理实现多GPU上的可扩展处理。", "result": "PGT-I首次在不进行图分区的情况下，在整个PeMS数据集上训练了ST-GNN，将峰值内存使用量减少了高达89%，并且在使用128个GPU时，比标准DDP（分布式数据并行）加速了13.1倍。", "conclusion": "PGT-I通过内存高效的分布式训练，成功解决了大规模时空图神经网络的内存瓶颈问题，使其能够应用于更大的数据集。", "translation": "时空图神经网络（ST-GNNs）是建模时空数据依赖关系的强大工具。然而，由于内存限制，它们的应用主要限于小规模数据集。尽管分布式训练提供了一种解决方案，但当前的框架缺乏对时空模型的支持，并且忽视了时空数据的特性。通过对大规模工作负载进行扩展研究，我们提出了PyTorch Geometric Temporal Index (PGT-I)，它是PyTorch Geometric Temporal的一个扩展，集成了分布式数据并行训练和两种新颖的策略：索引批处理和分布式索引批处理。我们的索引技术利用时空结构在运行时动态构建快照，显著减少了内存开销，而分布式索引批处理通过在多个GPU上实现可扩展处理来扩展这种方法。我们的技术首次实现在不进行图分区的情况下，在整个PeMS数据集上训练ST-GNN，将峰值内存使用量减少了高达89%，并在使用128个GPU时，比标准DDP加速了13.1倍。", "summary": "该论文提出了PGT-I，一个PyTorch Geometric Temporal的扩展，旨在解决时空图神经网络（ST-GNNs）在处理大规模数据集时的内存限制问题。PGT-I集成了分布式数据并行训练，并引入了两种新颖的索引技术：索引批处理和分布式索引批处理。这些技术通过动态构建时空快照来显著减少内存开销，并支持多GPU的可扩展处理。实验证明，PGT-I首次在整个PeMS数据集上成功训练了ST-GNN，实现了显著的内存使用量减少（高达89%）和训练速度提升（高达13.1倍）。", "keywords": "时空图神经网络, 分布式训练, 内存效率, PyTorch Geometric Temporal, PGT-I", "comments": "PGT-I的创新点在于其提出的索引批处理和分布式索引批处理技术，这些技术巧妙地利用了时空数据结构来优化内存使用和并行处理。这对于推动ST-GNN在实际大规模应用中的落地具有重要意义，解决了长期困扰该领域的内存瓶颈问题。"}}
{"id": "2507.12000", "title": "DSSD: Efficient Edge-Device Deployment and Collaborative Inference via Distributed Split Speculative Decoding", "authors": ["Jiahong Ning", "Ce Zheng", "Tingting Yang"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2507.12000v1", "summary": "Large language models (LLMs) have transformed natural language processing but\nface critical deployment challenges in device-edge systems due to resource\nlimitations and communication overhead. To address these issues, collaborative\nframeworks have emerged that combine small language models (SLMs) on devices\nwith LLMs at the edge, using speculative decoding (SD) to improve efficiency.\nHowever, existing solutions often trade inference accuracy for latency or\nsuffer from high uplink transmission costs when verifying candidate tokens. In\nthis paper, we propose Distributed Split Speculative Decoding (DSSD), a novel\narchitecture that not only preserves the SLM-LLM split but also partitions the\nverification phase between the device and edge. In this way, DSSD replaces the\nuplink transmission of multiple vocabulary distributions with a single downlink\ntransmission, significantly reducing communication latency while maintaining\ninference quality. Experiments show that our solution outperforms current\nmethods, and codes are at:\nhttps://github.com/JasonNing96/DSSD-Efficient-Edge-Computing", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.12000v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "DSSD：通过分布式分拆推测解码实现高效边缘设备部署和协同推理", "tldr": "DSSD是一种新的分布式推测解码架构，用于在设备-边缘系统中高效部署LLM，通过分拆验证阶段和减少通信延迟来保持推理质量。", "motivation": "大型语言模型（LLMs）在设备-边缘系统中面临资源限制和通信开销的部署挑战。现有协同框架（SLM-LLM结合推测解码）在提高效率时，常以牺牲推理精度为代价，或在验证候选词时产生高上行传输成本。", "method": "本文提出了分布式分拆推测解码（DSSD）架构。DSSD不仅保留了SLM-LLM的分拆，还将验证阶段在设备和边缘之间进行分区。通过这种方式，DSSD用一次下行传输取代了多次词汇分布的上行传输，显著降低了通信延迟。", "result": "实验表明，DSSD优于现有方法，显著降低了通信延迟，同时保持了推理质量。", "conclusion": "DSSD通过优化验证阶段的传输方式，有效解决了LLM在LLM在设备-边缘系统中的部署挑战，实现了高效且高质量的协同推理。", "translation": "大型语言模型（LLMs）已经改变了自然语言处理，但在设备-边缘系统中面临关键的部署挑战，原因在于资源限制和通信开销。为了解决这些问题，出现了协同框架，它们将设备上的小型语言模型（SLMs）与边缘的LLMs结合起来，利用推测解码（SD）来提高效率。然而，现有解决方案在验证候选词时，往往以推理精度换取延迟，或者遭受高昂的上行传输成本。在本文中，我们提出了分布式分拆推测解码（DSSD），这是一种新颖的架构，它不仅保留了SLM-LLM的分拆，而且还在设备和边缘之间划分了验证阶段。通过这种方式，DSSD用一次下行传输取代了多次词汇分布的上行传输，显著降低了通信延迟，同时保持了推理质量。实验表明，我们的解决方案优于现有方法，代码可在：https://github.com/JasonNing96/DSSD-Efficient-Edge-Computing 获取。", "summary": "本文提出了分布式分拆推测解码（DSSD），这是一种旨在解决大型语言模型在资源受限的设备-边缘系统中的部署挑战的新架构。DSSD通过在设备和边缘之间分区推测解码的验证阶段，并用单次下行传输替代多次上行传输，从而显著降低了通信延迟，同时保持了推理质量。实验结果表明，DSSD在效率和性能方面均优于现有协同推理方法。", "keywords": "分布式分拆推测解码, 大型语言模型, 边缘计算, 协同推理, 通信延迟", "comments": "DSSD的创新之处在于其对推测解码验证阶段的巧妙分区，将多词汇分布的上行传输替换为单次下行传输，从而显著降低了通信延迟，这对于资源受限的边缘设备部署至关重要。该方法在保证推理质量的同时提高了效率，为LLM在边缘计算环境中的实际应用提供了有前景的解决方案。"}}
{"id": "2507.12435", "title": "Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks", "authors": ["Yi Li", "David Mccoy", "Nolan Gunter", "Kaitlyn Lee", "Alejandro Schuler", "Mark van der Laan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12435v1", "summary": "Modern deep neural networks are powerful predictive tools yet often lack\nvalid inference for causal parameters, such as treatment effects or entire\nsurvival curves. While frameworks like Double Machine Learning (DML) and\nTargeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits,\nexisting neural implementations either rely on \"targeted losses\" that do not\nguarantee solving the efficient influence function equation or computationally\nexpensive post-hoc \"fluctuations\" for multi-parameter settings. We propose\nTargeted Deep Architectures (TDA), a new framework that embeds TMLE directly\ninto the network's parameter space with no restrictions on the backbone\narchitecture. Specifically, TDA partitions model parameters - freezing all but\na small \"targeting\" subset - and iteratively updates them along a targeting\ngradient, derived from projecting the influence functions onto the span of the\ngradients of the loss with respect to weights. This procedure yields plug-in\nestimates that remove first-order bias and produce asymptotically valid\nconfidence intervals. Crucially, TDA easily extends to multi-dimensional causal\nestimands (e.g., entire survival curves) by merging separate targeting\ngradients into a single universal targeting update. Theoretically, TDA inherits\nclassical TMLE properties, including double robustness and semiparametric\nefficiency. Empirically, on the benchmark IHDP dataset (average treatment\neffects) and simulated survival data with informative censoring, TDA reduces\nbias and improves coverage relative to both standard neural-network estimators\nand prior post-hoc approaches. In doing so, TDA establishes a direct, scalable\npathway toward rigorous causal inference within modern deep architectures for\ncomplex multi-parameter targets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12435v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "目标深度架构：一个基于TMLE的神经网络中鲁棒因果推断框架", "tldr": "本文提出了目标深度架构（TDA），这是一个将目标最大似然估计（TMLE）直接嵌入神经网络参数空间的新框架，旨在解决现有深度学习模型在因果参数推断中缺乏有效性的问题。TDA通过迭代更新一小部分“目标”参数来减少偏差并提供渐近有效的置信区间，并能扩展到多维因果估计量，在基准数据集上表现出更好的偏差和覆盖率。", "motivation": "现代深度神经网络虽然是强大的预测工具，但通常缺乏对因果参数（如治疗效果或整个生存曲线）的有效推断。现有的去偏方法（如DML和TMLE的神经网络实现）存在问题，例如“目标损失”无法保证解决有效影响函数方程，或者多参数设置下计算成本高昂的后验“波动”操作。", "method": "我们提出了目标深度架构（TDA），它将TMLE直接嵌入到网络的参数空间中，对骨干架构没有限制。具体来说，TDA将模型参数分区——冻结大部分参数，只留下一个小的“目标”子集——并沿着目标梯度迭代更新它们。该目标梯度是通过将影响函数投影到损失相对于权重的梯度张成的空间中获得的。该过程生成了消除一阶偏差并产生渐近有效置信区间的即插即用估计。TDA通过将单独的目标梯度合并到一个通用的目标更新中，可以轻松扩展到多维因果估计量。", "result": "在基准IHDP数据集（平均治疗效果）和具有信息性审查的模拟生存数据上，TDA相对于标准神经网络估计器和先前的后验方法，显著减少了偏差并提高了覆盖率。", "conclusion": "TDA为现代深度架构中复杂多参数目标的严谨因果推断建立了一条直接、可扩展的途径。它继承了经典TMLE的特性，包括双重鲁棒性和半参数效率。", "translation": "现代深度神经网络是强大的预测工具，但通常缺乏对因果参数（如治疗效果或整个生存曲线）的有效推断。虽然双重机器学习（DML）和目标最大似然估计（TMLE）等框架可以消除机器学习拟合的偏差，但现有的神经网络实现要么依赖于不能保证解决有效影响函数方程的“目标损失”，要么依赖于多参数设置下计算成本高昂的后验“波动”。我们提出了目标深度架构（TDA），这是一个将TMLE直接嵌入网络参数空间的新框架，对骨干架构没有限制。具体来说，TDA将模型参数分区——冻结所有参数，只留下一个小的“目标”子集——并沿着目标梯度迭代更新它们，该梯度源自将影响函数投影到损失相对于权重的梯度所张成的空间。此过程产生即插即用估计，可消除一阶偏差并产生渐近有效的置信区间。至关重要的是，TDA通过将单独的目标梯度合并到一个通用的目标更新中，可以轻松扩展到多维因果估计量（例如，整个生存曲线）。理论上，TDA继承了经典TMLE的特性，包括双重鲁棒性和半参数效率。在基准IHDP数据集（平均治疗效果）和具有信息性审查的模拟生存数据上，TDA相对于标准神经网络估计器和先前的后验方法，显著减少了偏差并提高了覆盖率。通过这样做，TDA为现代深度架构中复杂多参数目标的严谨因果推断建立了一条直接、可扩展的途径。", "summary": "本文提出了一种名为目标深度架构（TDA）的新框架，旨在解决现代深度神经网络在因果推断方面（如治疗效果或生存曲线）的不足。与现有方法（如DML和TMLE的神经网络实现）的局限性（例如“目标损失”的有效性问题或高计算成本的后验波动）不同，TDA将目标最大似然估计（TMLE）直接嵌入到神经网络的参数空间中。该方法通过迭代更新一小部分“目标”参数来消除偏差并产生渐近有效的置信区间，并且能够轻松扩展到多维因果估计量。TDA在理论上继承了TMLE的双重鲁棒性和半参数效率等特性。经验证明，在IHDP数据集和模拟生存数据上，TDA相对于传统神经网络估计器和现有后验方法，显著降低了偏差并提高了覆盖率。TDA为在现代深度架构中进行复杂多参数目标的严谨因果推断提供了一条直接且可扩展的路径。", "keywords": "因果推断, 深度学习, 目标最大似然估计, 神经网络, 偏差减少", "comments": "该论文的创新点在于将目标最大似然估计（TMLE）直接嵌入到深度神经网络的参数空间中，而非依赖于外部的后处理或修改损失函数。这种“内嵌式”设计使得TDA能够更好地融合深度学习的预测能力与因果推断的严谨性。其重要性在于为复杂的、多参数的因果估计问题（如整个生存曲线）提供了可扩展且鲁棒的解决方案，填补了现有深度学习因果推断方法的空白。该方法在理论上具有双重鲁棒性和半参数效率，并在实践中展现出优越的偏差减少和覆盖率提升。"}}
{"id": "2507.11942", "title": "DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression", "authors": ["Yi Zhao", "Zuchao Li", "Hai Zhao", "Baoyuan Qi", "Guoming Liu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025", "url": "http://arxiv.org/abs/2507.11942v1", "summary": "Task-agnostic prompt compression leverages the redundancy in natural language\nto reduce computational overhead and enhance information density within\nprompts, especially in long-context scenarios. Existing methods predominantly\nrely on information entropy as the metric to compress lexical units, aiming to\nachieve minimal information loss. However, these approaches overlook two\ncritical aspects: (i) the importance of attention-critical tokens at the\nalgorithmic level, and (ii) shifts in information entropy during the\ncompression process. Motivated by these challenges, we propose a dynamic\nattention-aware approach for task-agnostic prompt compression (DAC). This\napproach effectively integrates entropy and attention information, dynamically\nsensing entropy shifts during compression to achieve fine-grained prompt\ncompression. Extensive experiments across various domains, including LongBench,\nGSM8K, and BBH, show that DAC consistently yields robust and substantial\nimprovements across a diverse range of tasks and LLMs, offering compelling\nevidence of its efficacy.", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2507.11942v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "DAC：一种用于任务无关提示压缩的动态注意力感知方法", "tldr": "DAC是一种动态注意力感知方法，它结合了熵和注意力信息，以实现细粒度的任务无关提示压缩，并在各种任务和LLM上表现出显著改进。", "motivation": "现有任务无关提示压缩方法主要依赖信息熵来压缩词汇单元，但忽略了算法层面注意力关键令牌的重要性以及压缩过程中信息熵的变化。", "method": "我们提出了DAC（动态注意力感知方法），它有效整合了熵和注意力信息，并在压缩过程中动态感知熵的变化，以实现细粒度的提示压缩。", "result": "在LongBench、GSM8K和BBH等各种领域的广泛实验表明，DAC在各种任务和大型语言模型上持续产生稳健而显著的改进，证明了其有效性。", "conclusion": "DAC通过结合熵和注意力信息，能够有效地进行任务无关的提示压缩，并在多个基准测试中展现出卓越的性能。", "translation": "任务无关提示压缩利用自然语言中的冗余来减少计算开销并增强提示中的信息密度，尤其是在长上下文场景中。现有方法主要依赖信息熵作为度量标准来压缩词汇单元，旨在实现最小信息损失。然而，这些方法忽略了两个关键方面：（i）算法层面注意力关键令牌的重要性，以及（ii）压缩过程中信息熵的变化。受这些挑战的启发，我们提出了一种用于任务无关提示压缩的动态注意力感知方法（DAC）。该方法有效地整合了熵和注意力信息，在压缩过程中动态感知熵的变化，以实现细粒度的提示压缩。在LongBench、GSM8K和BBH等各种领域的广泛实验表明，DAC在各种任务和大型语言模型上持续产生稳健而显著的改进，提供了其有效性的有力证据。", "summary": "该论文提出了一种名为DAC的动态注意力感知方法，用于任务无关提示压缩。该方法旨在解决现有压缩方法忽略注意力关键令牌和信息熵动态变化的问题。DAC通过整合熵和注意力信息，并动态感知压缩过程中的熵变化，实现了细粒度的提示压缩。实验结果表明，DAC在多个基准测试和大型语言模型上均表现出显著且稳健的性能提升。", "keywords": "提示压缩, 任务无关, 动态注意力, 信息熵, 大型语言模型", "comments": "DAC的创新之处在于其动态整合了信息熵和注意力信息，解决了现有提示压缩方法在处理长上下文和保持关键信息方面的局限性。这种方法对于提高大型语言模型的效率和性能具有重要意义。"}}
{"id": "2507.11639", "title": "Deep Generative Methods and Tire Architecture Design", "authors": ["Fouad Oubari", "Raphael Meunier", "Rodrigue Décatoire", "Mathilde Mougeot"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11639v1", "summary": "As deep generative models proliferate across the AI landscape, industrial\npractitioners still face critical yet unanswered questions about which deep\ngenerative models best suit complex manufacturing design tasks. This work\naddresses this question through a complete study of five representative models\n(Variational Autoencoder, Generative Adversarial Network, multimodal\nVariational Autoencoder, Denoising Diffusion Probabilistic Model, and\nMultinomial Diffusion Model) on industrial tire architecture generation. Our\nevaluation spans three key industrial scenarios: (i) unconditional generation\nof complete multi-component designs, (ii) component-conditioned generation\n(reconstructing architectures from partial observations), and (iii)\ndimension-constrained generation (creating designs that satisfy specific\ndimensional requirements). To enable discrete diffusion models to handle\nconditional scenarios, we introduce categorical inpainting, a mask-aware\nreverse diffusion process that preserves known labels without requiring\nadditional training. Our evaluation employs geometry-aware metrics specifically\ncalibrated for industrial requirements, quantifying spatial coherence,\ncomponent interaction, structural connectivity, and perceptual fidelity. Our\nfindings reveal that diffusion models achieve the strongest overall\nperformance; a masking-trained VAE nonetheless outperforms the multimodal\nvariant MMVAE\\textsuperscript{+} on nearly all component-conditioned metrics,\nand within the diffusion family MDM leads in-distribution whereas DDPM\ngeneralises better to out-of-distribution dimensional constraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11639v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "深度生成方法与轮胎结构设计", "tldr": "本文全面评估了五种深度生成模型在工业轮胎结构设计中的表现，发现扩散模型整体性能最佳，并引入了分类修复技术以支持条件生成。", "motivation": "解决工业实践中关于哪种深度生成模型最适合复杂制造设计任务的关键问题。", "method": "本文对五种代表性深度生成模型（变分自编码器V AE、生成对抗网络GAN、多模态变分自编码器MMVAE、去噪扩散概率模型DDPM和多项式扩散模型MDM）在工业轮胎结构生成任务上进行了全面研究。评估涵盖无条件生成、组件条件生成和尺寸约束生成三种关键工业场景。为使离散扩散模型能处理条件场景，引入了无需额外训练的分类修复（categorical inpainting）技术。评估采用专门为工业需求校准的几何感知度量标准。", "result": "研究发现，扩散模型实现了最强的整体性能；一个经过掩码训练的VAE在几乎所有组件条件指标上都优于多模态变体MMVAE+；在扩散模型家族内部，MDM在分布内表现领先，而DDPM对分布外尺寸约束的泛化能力更好。", "conclusion": "扩散模型在工业轮胎结构设计任务中表现出强大的潜力，但在不同的工业场景和具体需求下，各种深度生成模型各有优势，需要根据具体情况进行选择。", "translation": "随着深度生成模型在人工智能领域的大量涌现，工业实践者仍然面临着关于哪种深度生成模型最适合复杂制造设计任务的关键但尚未解决的问题。这项工作通过对工业轮胎结构生成中五种代表性模型（变分自编码器、生成对抗网络、多模态变分自编码器、去噪扩散概率模型和多项式扩散模型）的完整研究来解决这个问题。我们的评估涵盖了三个关键的工业场景：(i) 完整多组件设计的无条件生成，(ii) 组件条件生成（从部分观测重建结构），以及 (iii) 尺寸约束生成（创建满足特定尺寸要求的设计）。为了使离散扩散模型能够处理条件场景，我们引入了分类修复，这是一种掩码感知的反向扩散过程，可以在不进行额外训练的情况下保留已知标签。我们的评估采用了专门为工业需求校准的几何感知度量，量化了空间连贯性、组件交互、结构连通性和感知保真度。我们的发现表明，扩散模型实现了最强的整体性能；然而，经过掩码训练的VAE在几乎所有组件条件指标上都优于多模态变体MMVAE+，并且在扩散模型家族中，MDM在分布内领先，而DDPM对分布外尺寸约束的泛化能力更好。", "summary": "本文针对工业制造设计中深度生成模型的选择难题，全面评估了五种主流模型（VAE、GAN、MMVAE、DDPM、MDM）在工业轮胎结构生成任务中的表现。研究涵盖无条件、组件条件和尺寸约束三种生成场景，并引入了分类修复技术以增强离散扩散模型的条件生成能力。结果表明，扩散模型整体性能最佳，但不同模型在特定条件下各有优势，例如掩码训练的VAE在组件条件生成上表现突出，而MDM和DDPM在扩散模型家族中分别在分布内和分布外泛化能力上有所侧重。", "keywords": "深度生成模型, 轮胎结构设计, 扩散模型, 条件生成, 工业应用", "comments": "该研究通过对多种深度生成模型在实际工业轮胎设计任务中的系统评估，为工业界提供了宝贵的指导，特别是在复杂制造设计中的模型选择。引入分类修复技术以支持离散扩散模型的条件生成是其创新点，提升了扩散模型在实际应用中的灵活性。该研究强调了在不同工业场景下模型性能的差异，具有重要的实践意义。"}}
{"id": "2507.12414", "title": "AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models", "authors": ["Santosh Vasa", "Aditi Ramadwar", "Jnana Rama Krishna Darabattula", "Md Zafar Anwar", "Stanislaw Antol", "Andrei Vatavu", "Thomas Monninger", "Sihao Ding"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12414v1", "summary": "Training of autonomous driving systems requires extensive datasets with\nprecise annotations to attain robust performance. Human annotations suffer from\nimperfections, and multiple iterations are often needed to produce high-quality\ndatasets. However, manually reviewing large datasets is laborious and\nexpensive. In this paper, we introduce AutoVDC (Automated Vision Data Cleaning)\nframework and investigate the utilization of Vision-Language Models (VLMs) to\nautomatically identify erroneous annotations in vision datasets, thereby\nenabling users to eliminate these errors and enhance data quality. We validate\nour approach using the KITTI and nuImages datasets, which contain object\ndetection benchmarks for autonomous driving. To test the effectiveness of\nAutoVDC, we create dataset variants with intentionally injected erroneous\nannotations and observe the error detection rate of our approach. Additionally,\nwe compare the detection rates using different VLMs and explore the impact of\nVLM fine-tuning on our pipeline. The results demonstrate our method's high\nperformance in error detection and data cleaning experiments, indicating its\npotential to significantly improve the reliability and accuracy of large-scale\nproduction datasets in autonomous driving.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12414v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "AutoVDC：使用视觉-语言模型进行自动化视觉数据清洗", "tldr": "提出AutoVDC框架，利用视觉-语言模型自动检测自动驾驶视觉数据中的错误标注，以提高数据质量。", "motivation": "自动驾驶系统训练需要大量精确标注的数据集，但人工标注存在缺陷，且手动审查大型数据集既费力又昂贵。", "method": "引入AutoVDC框架，利用视觉-语言模型（VLMs）自动识别视觉数据集中的错误标注。通过在KITTI和nuImages数据集上注入错误进行验证，并比较不同VLM和VLM微调的影响。", "result": "实验结果表明该方法在错误检测和数据清洗实验中表现出高性能，错误检测率高。", "conclusion": "AutoVDC方法有潜力显著提高自动驾驶大规模生产数据集的可靠性和准确性。", "translation": "自动驾驶系统的训练需要大量的精确标注数据集才能获得鲁棒的性能。人工标注存在缺陷，通常需要多次迭代才能生成高质量的数据集。然而，手动审查大型数据集既费力又昂贵。在本文中，我们介绍了AutoVDC（自动化视觉数据清洗）框架，并研究了利用视觉-语言模型（VLMs）自动识别视觉数据集中错误标注的方法，从而使用户能够消除这些错误并提高数据质量。我们使用包含自动驾驶目标检测基准的KITTI和nuImages数据集验证了我们的方法。为了测试AutoVDC的有效性，我们创建了故意注入错误标注的数据集变体，并观察了我们方法的错误检测率。此外，我们比较了使用不同VLM的检测率，并探讨了VLM微调对我们管道的影响。结果表明，我们的方法在错误检测和数据清洗实验中表现出高性能，表明其有潜力显著提高自动驾驶中大规模生产数据集的可靠性和准确性。", "summary": "本文提出了AutoVDC框架，旨在解决自动驾驶视觉数据集中人工标注错误的问题。该框架利用视觉-语言模型（VLMs）自动化识别数据集中的错误标注，从而提高数据质量。通过在KITTI和nuImages数据集上进行实验，并注入人工错误进行验证，结果显示AutoVDC在错误检测和数据清洗方面表现出色，有望显著提升大规模自动驾驶数据集的可靠性和准确性。", "keywords": "自动驾驶, 数据清洗, 视觉-语言模型, 错误检测, 数据质量", "comments": "该论文提出了一种创新的方法，利用视觉-语言模型来自动化数据清洗过程，解决了自动驾驶领域高质量数据集获取的痛点。其重要性在于能够降低人工审查成本，提高数据标注效率和准确性，对于依赖大规模标注数据的AI系统训练具有实际应用价值。"}}
{"id": "2505.00512", "title": "InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method", "authors": ["Nguyen Hoang Khoi Tran", "Julie Stephany Berrio", "Mao Shan", "Zhenxing Ming", "Stewart Worrall"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00512v3", "summary": "Online localization of road intersections is beneficial for autonomous\nvehicle localization, mapping and motion planning. Intersections offer strong\nlandmarks for correcting vehicle pose estimation, anchoring new sensor data in\nup-to-date maps, and guiding vehicle routing in road network graphs. Despite\nthis importance, intersection localization has not been widely studied, with\nexisting methods either ignoring the rich semantic information already computed\nonboard or relying on scarce, hand-labeled intersection datasets. To close this\ngap, we present a novel LiDAR-based method for online vehicle-centric\nintersection localization. We detect the intersection candidates in a bird's\neye view (BEV) representation formed by concatenating a sequence of semantic\nroad scans. We then refine these candidates by analyzing the intersecting road\nbranches and adjusting the intersection center point in a least-squares\nformulation. For evaluation, we introduce an automated pipeline that pairs\nlocalized intersection points with OpenStreetMap (OSM) intersection nodes using\nprecise GNSS/INS ground-truth poses. Experiments on the SemanticKITTI dataset\nshow that our method outperforms the latest learning-based baseline in accuracy\nand reliability. Sensitivity tests demonstrate the method's robustness to\nchallenging segmentation errors, highlighting its applicability in the real\nworld.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00512v3", "cate": "cs.CV", "date": "2025-05-01", "updated": "2025-07-16", "AI": {"title_translation": "InterLoc：基于LiDAR的交叉路口定位，结合道路分割与自动化评估方法", "tldr": "InterLoc提出了一种基于LiDAR和道路语义分割的在线交叉路口定位新方法，并通过自动化评估流程，在SemanticKITTI数据集上表现出优于现有基线的准确性和鲁棒性。", "motivation": "在线定位道路交叉路口对自动驾驶车辆的定位、建图和运动规划至关重要，因为它们提供了强大的地标。然而，现有方法要么忽视丰富的语义信息，要么依赖稀缺的手动标注数据集，未能充分研究交叉路口定位。", "method": "本文提出了一种新颖的基于LiDAR的在线以车辆为中心的交叉路口定位方法。该方法通过拼接一系列语义道路扫描形成的鸟瞰图（BEV）表示来检测交叉路口候选区域。随后，通过分析相交的道路分支并采用最小二乘公式调整交叉路口中心点来细化这些候选区域。为评估该方法，引入了一个自动化流程，该流程利用精确的GNSS/INS真值姿态将定位的交叉路口点与OpenStreetMap（OSM）交叉路口节点进行配对。", "result": "在SemanticKITTI数据集上的实验结果表明，我们的方法在准确性和可靠性方面均优于最新的基于学习的基线。敏感性测试进一步证明了该方法对具有挑战性的分割错误具有鲁棒性，突出了其在实际应用中的可行性。", "conclusion": "本研究提出的InterLoc方法在交叉路口定位方面表现出卓越的准确性和鲁棒性，克服了现有方法的局限性，并有望在自动驾驶领域提供可靠的感知支持。", "translation": "在线定位道路交叉路口有助于自动驾驶车辆的定位、建图和运动规划。交叉路口提供了强大的地标，用于纠正车辆姿态估计、在最新地图中锚定新的传感器数据以及在道路网络图中引导车辆路线。尽管其重要性，交叉路口定位尚未得到广泛研究，现有方法要么忽略了已在车载上计算的丰富语义信息，要么依赖稀缺的手动标注交叉路口数据集。为了弥补这一空白，我们提出了一种新颖的基于LiDAR的在线以车辆为中心的交叉路口定位方法。我们通过拼接一系列语义道路扫描形成的鸟瞰图（BEV）表示来检测交叉路口候选区域。然后，通过分析相交的道路分支并使用最小二乘公式调整交叉路口中心点来细化这些候选区域。为了评估，我们引入了一个自动化管道，该管道使用精确的GNSS/INS地面真值姿态将定位的交叉路口点与OpenStreetMap（OSM）交叉路口节点配对。在SemanticKITTI数据集上的实验表明，我们的方法在准确性和可靠性方面优于最新的基于学习的基线。敏感性测试表明该方法对挑战性的分割错误具有鲁棒性，突出了其在实际世界中的适用性。", "summary": "本文提出了一种名为InterLoc的LiDAR-based在线交叉路口定位新方法，旨在解决现有方案未能充分利用语义信息或依赖稀疏标注数据的不足。该方法首先在语义道路扫描形成的鸟瞰图中识别交叉路口候选区域，随后通过分析道路分支并采用最小二乘法精确调整中心点。为验证其性能，研究引入了一套自动化评估流程，将定位结果与OpenStreetMap数据及高精度真值进行比对。实验结果显示，InterLoc在SemanticKITTI数据集上展现出优越的准确性和可靠性，并对分割错误具有较强的鲁棒性，证明了其在实际自动驾驶应用中的潜力。", "keywords": "LiDAR, 交叉路口定位, 道路分割, 自动驾驶, 语义地图", "comments": "该论文的创新点在于提出了一种新颖的基于LiDAR和道路语义分割的交叉路口定位方法，并引入了自动化的评估流程，有效解决了传统方法对人工标注数据集依赖和语义信息利用不足的问题。其在提高自动驾驶车辆定位精度和鲁棒性方面具有重要意义。特别是对分割错误的鲁棒性测试，进一步验证了其在复杂真实环境中的实用价值。"}}
{"id": "2507.12283", "title": "FADE: Adversarial Concept Erasure in Flow Models", "authors": ["Zixuan Fu", "Yan Ren", "Finn Carter", "Chenyue Wang", "Ze Niu", "Dacheng Yu", "Emily Davis", "Bo Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Camera Ready", "url": "http://arxiv.org/abs/2507.12283v1", "summary": "Diffusion models have demonstrated remarkable image generation capabilities,\nbut also pose risks in privacy and fairness by memorizing sensitive concepts or\nperpetuating biases. We propose a novel \\textbf{concept erasure} method for\ntext-to-image diffusion models, designed to remove specified concepts (e.g., a\nprivate individual or a harmful stereotype) from the model's generative\nrepertoire. Our method, termed \\textbf{FADE} (Fair Adversarial Diffusion\nErasure), combines a trajectory-aware fine-tuning strategy with an adversarial\nobjective to ensure the concept is reliably removed while preserving overall\nmodel fidelity. Theoretically, we prove a formal guarantee that our approach\nminimizes the mutual information between the erased concept and the model's\noutputs, ensuring privacy and fairness. Empirically, we evaluate FADE on Stable\nDiffusion and FLUX, using benchmarks from prior work (e.g., object, celebrity,\nexplicit content, and style erasure tasks from MACE). FADE achieves\nstate-of-the-art concept removal performance, surpassing recent baselines like\nESD, UCE, MACE, and ANT in terms of removal efficacy and image quality.\nNotably, FADE improves the harmonic mean of concept removal and fidelity by\n5--10\\% over the best prior method. We also conduct an ablation study to\nvalidate each component of FADE, confirming that our adversarial and\ntrajectory-preserving objectives each contribute to its superior performance.\nOur work sets a new standard for safe and fair generative modeling by\nunlearning specified concepts without retraining from scratch.", "comment": "Camera Ready", "pdf_url": "http://arxiv.org/pdf/2507.12283v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "FADE：流模型中的对抗性概念擦除", "tldr": "FADE是一种新的概念擦除方法，用于从文本到图像的扩散模型中删除敏感概念，同时保持模型保真度，并实现了最先进的性能。", "motivation": "扩散模型在图像生成方面表现出色，但也存在通过记忆敏感概念或延续偏见而导致隐私和公平性风险的问题。", "method": "提出了一种名为FADE（Fair Adversarial Diffusion Erasure）的新型概念擦除方法。该方法结合了轨迹感知微调策略和对抗性目标，以确保概念被可靠删除，同时保持整体模型保真度。理论上，该方法最小化了被擦除概念与模型输出之间的互信息。", "result": "FADE在Stable Diffusion和FLUX上进行了评估，并在概念删除性能上达到了最先进水平，超越了ESD、UCE、MACE和ANT等现有基线。FADE在概念删除和保真度的调和平均值上比现有最佳方法提高了5-10%。消融研究证实了对抗性和轨迹保持目标对性能的贡献。", "conclusion": "该工作通过在不从头开始重新训练的情况下“遗忘”特定概念，为安全和公平的生成建模设定了新标准。", "translation": "扩散模型展现了卓越的图像生成能力，但也通过记忆敏感概念或延续偏见而带来隐私和公平性风险。我们提出了一种针对文本到图像扩散模型的新颖的**概念擦除**方法，旨在从模型的生成能力中移除指定概念（例如，私人个体或有害刻板印象）。我们的方法名为**FADE**（Fair Adversarial Diffusion Erasure），它结合了轨迹感知微调策略和对抗性目标，以确保概念被可靠地移除，同时保持整体模型保真度。在理论上，我们证明了我们的方法能最小化被擦除概念与模型输出之间的互信息，从而保证了隐私和公平性。在实证方面，我们使用先前工作的基准（例如，来自MACE的物体、名人、露骨内容和风格擦除任务）在Stable Diffusion和FLUX上评估了FADE。FADE在概念移除性能上达到了最先进水平，在移除效率和图像质量方面超越了ESD、UCE、MACE和ANT等近期基线。值得注意的是，FADE在概念移除和保真度的调和平均值上比现有最佳方法提高了5-10%。我们还进行了一项消融研究，以验证FADE的每个组件，证实了我们的对抗性和轨迹保持目标都对其卓越性能有所贡献。我们的工作通过在不从头开始重新训练的情况下“遗忘”指定概念，为安全和公平的生成建模设定了新标准。", "summary": "本文提出FADE，一种针对文本到图像扩散模型的新型概念擦除方法，旨在消除模型生成能力中的特定敏感概念（如私人个体或有害刻板印象）。FADE结合了轨迹感知微调策略和对抗性目标，以确保概念可靠移除并保持模型保真度。该方法在理论上证明了其能最小化被擦除概念与模型输出之间的互信息，从而保障隐私和公平性。实验结果表明，FADE在Stable Diffusion和FLUX上实现了最先进的概念删除性能，在移除效果和图像质量方面超越了现有基线，并在概念删除和保真度调和平均值上提升了5-10%。", "keywords": "概念擦除, 扩散模型, 对抗性学习, 隐私, 公平性", "comments": "FADE的创新点在于其结合了轨迹感知微调策略和对抗性目标来可靠地擦除概念，并在理论上提供了互信息最小化的保证。其重要性在于为解决扩散模型中的隐私和公平性风险提供了一种有效且高效的解决方案，避免了从头训练的成本。"}}
{"id": "2504.15110", "title": "Kolmogorov-Arnold Networks: Approximation and Learning Guarantees for Functions and their Derivatives", "authors": ["Anastasis Kratsios", "Bum Jun Kim", "Takashi Furuya"], "categories": ["cs.LG", "cs.NA", "cs.NE", "math.FA", "math.NA", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.15110v2", "summary": "Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold\nNetworks (KANs) have recently emerged as an improved backbone for most deep\nlearning frameworks, promising more adaptivity than their multilayer perception\n(MLP) predecessor by allowing for trainable spline-based activation functions.\nIn this paper, we probe the theoretical foundations of the KAN architecture by\nshowing that it can optimally approximate any Besov function in\n$B^{s}_{p,q}(\\mathcal{X})$ on a bounded open, or even fractal, domain\n$\\mathcal{X}$ in $\\mathbb{R}^d$ at the optimal approximation rate with respect\nto any weaker Besov norm $B^{\\alpha}_{p,q}(\\mathcal{X})$; where $\\alpha < s$.\nWe complement our approximation guarantee with a dimension-free estimate on the\nsample complexity of a residual KAN model when learning a function of Besov\nregularity from $N$ i.i.d. noiseless samples. Our KAN architecture incorporates\ncontemporary deep learning wisdom by leveraging residual/skip connections\nbetween layers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.15110v2", "cate": "cs.LG", "date": "2025-04-21", "updated": "2025-07-15", "AI": {"title_translation": "柯尔莫哥洛夫-阿诺德网络：函数及其导数的逼近和学习保证", "tldr": "KANs在理论上被证明能够最优地逼近Besov函数，并且在学习时具有与维度无关的样本复杂度，优于MLP。", "motivation": "柯尔莫哥洛夫-阿诺德网络（KANs）作为多层感知机（MLP）的改进骨干出现，通过可训练的基于样条的激活函数，有望提供更强的适应性。本文旨在探究KAN架构的理论基础。", "method": "本文通过理论分析KAN架构，证明了其能够最优地逼近Besov函数，并对残差KAN模型在学习Besov正则函数时的样本复杂度提供了与维度无关的估计。", "result": "KANs能够在有界开放甚至分形域上，以相对于任何较弱的Besov范数的最优逼近率，最优地逼近任何Besov函数。同时，对残差KAN模型从无噪声样本中学习Besov正则函数时的样本复杂度给出了与维度无关的估计。", "conclusion": "KANs在函数逼近和学习方面具有强大的理论保证，显示出其作为一种优越深度学习架构的潜力。", "translation": "受柯尔莫哥洛夫-阿诺德叠加定理的启发，柯尔莫哥洛夫-阿诺德网络（KANs）最近已成为大多数深度学习框架的改进骨干，通过允许可训练的基于样条的激活函数，承诺比其多层感知机（MLP）前身具有更强的适应性。在本文中，我们通过证明KAN架构可以在有界开放甚至分形域 $\\mathcal{X}$ in $\\mathbb{R}^d$ 上以相对于任何较弱的Besov范数 $B^{\\alpha}_{p,q}(\\mathcal{X})$ 的最优逼近率，最优地逼近任何Besov函数 $B^{s}_{p,q}(\\mathcal{X})$ 来探究其理论基础；其中 $\\alpha < s$。我们通过对残差KAN模型在从 $N$ 个i.i.d.无噪声样本学习Besov正则函数时的样本复杂度进行无维度估计，来补充我们的逼近保证。我们的KAN架构通过利用层之间的残差/跳跃连接，融入了当代深度学习的智慧。", "summary": "本文从理论上研究了柯尔莫哥洛夫-阿诺德网络（KANs），这是一种受柯尔莫哥洛夫-阿诺德叠加定理启发的深度学习新架构，它使用可训练的基于样条的激活函数，以提高相对于MLP的适应性。作者证明了KANs可以在各种域上以最优速率最优地逼近Besov函数。此外，他们还为残差KAN模型学习Besov正则函数的样本复杂度提供了与维度无关的估计，该模型融入了跳跃连接等现代深度学习技术。", "keywords": "柯尔莫哥洛夫-阿诺德网络, 逼近理论, Besov函数, 样本复杂度, 深度学习", "comments": "这篇论文为KANs（一种有前景的传统MLP替代方案）提供了重要的理论基础。它展示了KANs对Besov函数的最优逼近率和与维度无关的样本复杂度估计，突出了其强大的理论优势。残差连接的整合表明了对实际深度学习进展的关注。其创新之处在于利用柯尔莫哥洛夫-阿诺德叠加定理与可训练样条相结合，为网络设计提供了一种新颖的方法。"}}
{"id": "2507.11903", "title": "Unveiling the Visual Rhetoric of Persuasive Cartography: A Case Study of the Design of Octopus Maps", "authors": ["Daocheng Lin", "Yifan Wang", "Yutong Yang", "Xingyu Lan"], "categories": ["cs.HC", "cs.MM"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11903v1", "summary": "When designed deliberately, data visualizations can become powerful\npersuasive tools, influencing viewers' opinions, values, and actions. While\nresearchers have begun studying this issue (e.g., to evaluate the effects of\npersuasive visualization), we argue that a fundamental mechanism of persuasion\nresides in rhetorical construction, a perspective inadequately addressed in\ncurrent visualization research. To fill this gap, we present a focused analysis\nof octopus maps, a visual genre that has maintained persuasive power across\ncenturies and achieved significant social impact. Employing rhetorical schema\ntheory, we collected and analyzed 90 octopus maps spanning from the 19th\ncentury to contemporary times. We closely examined how octopus maps implement\ntheir persuasive intents and constructed a design space that reveals how visual\nmetaphors are strategically constructed and what common rhetorical strategies\nare applied to components such as maps, octopus imagery, and text. Through the\nabove analysis, we also uncover a set of interesting findings. For instance,\ncontrary to the common perception that octopus maps are primarily a historical\nphenomenon, our research shows that they remain a lively design convention in\ntoday's digital age. Additionally, while most octopus maps stem from Western\ndiscourse that views the octopus as an evil symbol, some designs offer\nalternative interpretations, highlighting the dynamic nature of rhetoric across\ndifferent sociocultural settings. Lastly, drawing from the lessons provided by\noctopus maps, we discuss the associated ethical concerns of persuasive\nvisualization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11903v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "揭示说服性制图的视觉修辞：以章鱼地图设计为例", "tldr": "本研究通过分析章鱼地图，揭示了数据可视化中修辞构建的说服机制，并探讨了其设计策略和伦理问题。", "motivation": "当前可视化研究未能充分探讨说服的根本机制——修辞构建，而数据可视化作为强大的说服工具，其潜在影响需要深入理解。本研究旨在填补这一空白。", "method": "采用修辞图式理论，收集并分析了90张从19世纪至今的章鱼地图。研究人员深入考察了章鱼地图如何实现其说服意图，并构建了一个设计空间，揭示了视觉隐喻的策略性构建方式以及地图、章鱼图像和文本等组成部分中常用的修辞策略。", "result": "研究发现，章鱼地图在当今数字时代仍是一种活跃的设计惯例，并非仅仅是历史现象。此外，尽管大多数章鱼地图源于西方将章鱼视为邪恶象征的论述，但一些设计提供了不同的解读，突显了修辞在不同社会文化背景下的动态性。", "conclusion": "通过对章鱼地图的分析，本研究揭示了说服性数据可视化的设计机制，并讨论了与之相关的伦理问题。", "translation": "当经过精心设计时，数据可视化可以成为强大的说服工具，影响观众的观点、价值观和行为。尽管研究人员已经开始研究这个问题（例如，评估说服性可视化的效果），但我们认为说服的根本机制在于修辞构建，这一观点在当前的可视化研究中尚未得到充分解决。为了填补这一空白，我们对章鱼地图进行了重点分析，这是一种在几个世纪以来一直保持说服力并取得了重大社会影响的视觉类型。我们运用修辞图式理论，收集并分析了90张从19世纪至今的章鱼地图。我们仔细研究了章鱼地图如何实现其说服意图，并构建了一个设计空间，揭示了视觉隐喻是如何策略性构建的，以及地图、章鱼图像和文本等组成部分中应用了哪些常见的修辞策略。通过上述分析，我们还发现了一系列有趣的发现。例如，与章鱼地图主要是一种历史现象的普遍看法相反，我们的研究表明它们在当今数字时代仍然是一种活跃的设计惯例。此外，尽管大多数章鱼地图源于将章鱼视为邪恶象征的西方论述，但一些设计提供了替代解释，突出了修辞在不同社会文化背景下的动态性。最后，借鉴章鱼地图提供的经验教训，我们讨论了说服性可视化相关的伦理问题。", "summary": "本研究旨在弥补当前可视化研究在修辞构建说服机制方面的不足。论文以章鱼地图为案例，运用修辞图式理论，分析了90张章鱼地图的设计，构建了一个设计空间来揭示其视觉修辞策略。研究发现，章鱼地图在数字时代依然活跃，并且其修辞表达具有跨文化动态性。最后，论文讨论了说服性可视化的伦理问题。", "keywords": "说服性制图, 章鱼地图, 视觉修辞, 修辞图式理论, 数据可视化", "comments": "本研究创新性地将修辞学理论应用于数据可视化领域，特别是通过章鱼地图这一独特且历史悠久的视觉类型进行深入案例分析，揭示了视觉修辞在说服中的关键作用。其构建的设计空间有助于理解说服性可视化的设计原理。此外，研究还提出了对说服性可视化伦理问题的讨论，具有重要的现实意义。"}}
{"id": "2507.11661", "title": "Partitioner Guided Modal Learning Framework", "authors": ["Guimin Hu", "Yi Xin", "Lijie Hu", "Zhihong Zhu", "Hasti Seifi"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      acm multimedia 2025", "url": "http://arxiv.org/abs/2507.11661v1", "summary": "Multimodal learning benefits from multiple modal information, and each\nlearned modal representations can be divided into uni-modal that can be learned\nfrom uni-modal training and paired-modal features that can be learned from\ncross-modal interaction. Building on this perspective, we propose a\npartitioner-guided modal learning framework, PgM, which consists of the modal\npartitioner, uni-modal learner, paired-modal learner, and uni-paired modal\ndecoder. Modal partitioner segments the learned modal representation into\nuni-modal and paired-modal features. Modal learner incorporates two dedicated\ncomponents for uni-modal and paired-modal learning. Uni-paired modal decoder\nreconstructs modal representation based on uni-modal and paired-modal features.\nPgM offers three key benefits: 1) thorough learning of uni-modal and\npaired-modal features, 2) flexible distribution adjustment for uni-modal and\npaired-modal representations to suit diverse downstream tasks, and 3) different\nlearning rates across modalities and partitions. Extensive experiments\ndemonstrate the effectiveness of PgM across four multimodal tasks and further\nhighlight its transferability to existing models. Additionally, we visualize\nthe distribution of uni-modal and paired-modal features across modalities and\ntasks, offering insights into their respective contributions.", "comment": "acm multimedia 2025", "pdf_url": "http://arxiv.org/pdf/2507.11661v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "分区器引导的模态学习框架", "tldr": "本文提出了PgM，一个分区器引导的模态学习框架，它将多模态特征分为单模态和配对模态部分，以实现更彻底的学习、灵活的分布调整和不同的学习率。", "motivation": "多模态学习受益于多种模态信息，并且每种学到的模态表示都可以分为单模态特征（从单模态训练中学习）和配对模态特征（从跨模态交互中学习）。本文旨在改进这些不同特征的学习。", "method": "本文提出了一个分区器引导的模态学习框架（PgM），它由模态分区器、单模态学习器、配对模态学习器和单配对模态解码器组成。模态分区器负责将学到的模态表示分割成单模态和配对模态特征。模态学习器包含两个专门用于单模态和配对模态学习的组件。单配对模态解码器则基于单模态和配对模态特征重建模态表示。PgM的优势在于能够彻底学习单模态和配对模态特征，灵活调整其分布以适应下游任务，并允许跨模态和分区采用不同的学习率。", "result": "广泛的实验证明了PgM在四种多模态任务上的有效性，并进一步强调了其对现有模型的可迁移性。此外，通过可视化单模态和配对模态特征在不同模态和任务中的分布，为它们的各自贡献提供了见解。", "conclusion": "本文提出了PgM，一个用于多模态学习的框架，它能有效地学习和管理单模态和配对模态特征，并在各种任务中展现出有效性和可迁移性。", "translation": "多模态学习受益于多种模态信息，并且每个学到的模态表示可以分为可以从单模态训练中学到的单模态特征和可以从跨模态交互中学到的配对模态特征。基于这一观点，我们提出了一个分区器引导的模态学习框架PgM，它由模态分区器、单模态学习器、配对模态学习器和单配对模态解码器组成。模态分区器将学到的模态表示分割成单模态和配对模态特征。模态学习器包含两个专门用于单模态和配对模态学习的组件。单配对模态解码器根据单模态和配对模态特征重建模态表示。PgM提供三个主要优势：1）彻底学习单模态和配对模态特征，2）为单模态和配对模态表示提供灵活的分布调整以适应不同的下游任务，以及3）跨模态和分区采用不同的学习率。大量的实验证明了PgM在四种多模态任务上的有效性，并进一步强调了其对现有模型的可迁移性。此外，我们可视化了单模态和配对模态特征在不同模态和任务中的分布，为它们的各自贡献提供了见解。", "summary": "本文介绍了一种名为PgM的新型分区器引导模态学习框架，旨在通过明确分离和学习单模态与配对模态特征来增强多模态学习。PgM由模态分区器、单模态学习器、配对模态学习器和单配对模态解码器组成。其主要优势包括全面的特征学习、适用于不同任务的灵活特征分布调整以及不同的学习率。在四种多模态任务上的实验结果证实了PgM的有效性及其对现有模型的可迁移性，同时通过可视化提供了对特征贡献的深入见解。", "keywords": "多模态学习, 特征分区, 单模态特征, 配对模态特征, 深度学习", "comments": "该论文的创新之处在于在一个统一的框架内明确地划分和管理单模态和配对模态特征，从而实现更彻底的学习和对各种任务的灵活适应。其对现有模型的 demonstrated transferability 也是一个显著的优势。"}}
{"id": "2507.12060", "title": "InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing", "authors": ["Kun-Hsiang Lin", "Yu-Wen Tseng", "Kang-Yang Huang", "Jhih-Ciang Wu", "Wen-Huang Cheng"], "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by MM'25", "url": "http://arxiv.org/abs/2507.12060v1", "summary": "Face anti-spoofing (FAS) aims to construct a robust system that can withstand\ndiverse attacks. While recent efforts have concentrated mainly on cross-domain\ngeneralization, two significant challenges persist: limited semantic\nunderstanding of attack types and training redundancy across domains. We\naddress the first by integrating vision-language models (VLMs) to enhance the\nperception of visual input. For the second challenge, we employ a meta-domain\nstrategy to learn a unified model that generalizes well across multiple\ndomains. Our proposed InstructFLIP is a novel instruction-tuned framework that\nleverages VLMs to enhance generalization via textual guidance trained solely on\na single domain. At its core, InstructFLIP explicitly decouples instructions\ninto content and style components, where content-based instructions focus on\nthe essential semantics of spoofing, and style-based instructions consider\nvariations related to the environment and camera characteristics. Extensive\nexperiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA\nmodels in accuracy and substantially reducing training redundancy across\ndiverse domains in FAS. Project website is available at\nhttps://kunkunlin1221.github.io/InstructFLIP.", "comment": "Accepted by MM'25", "pdf_url": "http://arxiv.org/pdf/2507.12060v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "InstructFLIP：探索用于人脸防伪的统一视觉-语言模型", "tldr": "InstructFLIP通过指令微调的视觉-语言模型，解决了人脸防伪中的语义理解不足和跨域训练冗余问题，实现了更好的泛化性能。", "motivation": "当前人脸防伪（FAS）系统面临两大挑战：攻击类型语义理解有限和跨域训练冗余。", "method": "本文提出了InstructFLIP，一个新颖的指令微调框架。它利用视觉-语言模型（VLMs）通过文本指导增强泛化能力，仅在单一域上训练。核心是将指令明确解耦为内容（关注欺骗的本质语义）和风格（考虑环境和相机特性相关的变化）组件，并采用元域策略学习统一模型以实现多域泛化。", "result": "InstructFLIP在人脸防伪任务中，准确性超越了SOTA模型，并显著减少了跨域训练冗余。", "conclusion": "InstructFLIP通过整合视觉-语言模型并采用指令解耦和元域策略，有效提升了人脸防伪系统的泛化能力，并降低了跨域训练的复杂度。", "translation": "人脸防伪（FAS）旨在构建一个能够抵御各种攻击的鲁棒系统。尽管最近的工作主要集中在跨域泛化，但仍然存在两个重大挑战：攻击类型语义理解有限和跨域训练冗余。我们通过整合视觉-语言模型（VLMs）来增强视觉输入的感知，从而解决第一个挑战。对于第二个挑战，我们采用元域策略来学习一个在多个域中泛化良好的统一模型。我们提出的InstructFLIP是一个新颖的指令微调框架，它利用VLMs通过文本指导来增强泛化能力，仅在单一域上进行训练。其核心是，InstructFLIP明确地将指令解耦为内容和风格组件，其中基于内容的指令侧重于欺骗的基本语义，而基于风格的指令则考虑与环境和相机特性相关的变化。大量的实验证明了InstructFLIP的有效性，它在准确性方面超越了SOTA模型，并大大减少了人脸防伪中跨域训练的冗余。项目网站：https://kunkunlin1221.github.io/InstructFLIP", "summary": "本文提出了InstructFLIP，一个创新的指令微调框架，旨在解决人脸防伪（FAS）中攻击类型语义理解不足和跨域训练冗余的问题。该框架通过整合视觉-语言模型（VLMs），并将指令解耦为内容和风格两部分，从而在仅单一域训练的情况下实现对多域的良好泛化。实验结果表明，InstructFLIP在准确性上超越了现有最佳模型，并显著降低了训练冗余。", "keywords": "人脸防伪, 视觉-语言模型, 指令微调, 跨域泛化, 训练冗余", "comments": "该论文的创新点在于将视觉-语言模型引入人脸防伪领域，并通过指令解耦（内容与风格）的方式提升了模型的语义理解能力和跨域泛化性。这种方法有效解决了传统FAS模型在语义理解和训练冗余方面的痛点，对于构建更鲁棒、更高效的防伪系统具有重要意义。"}}
{"id": "2402.13357", "title": "Minimizing Tardy Processing Time on a Single Machine in Near-Linear Time", "authors": ["Nick Fischer", "Leo Wennmann"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      17 pages. This is the TheoretiCS journal version", "url": "http://arxiv.org/abs/2402.13357v3", "summary": "In this work we revisit the elementary scheduling problem $1||\\sum p_j U_j$.\nThe goal is to select, among $n$ jobs with processing times and due dates, a\nsubset of jobs with maximum total processing time that can be scheduled in\nsequence without violating their due dates. This problem is NP-hard, but a\nclassical algorithm by Lawler and Moore from the 60s solves this problem in\npseudo-polynomial time $O(nP)$, where $P$ is the total processing time of all\njobs. With the aim to develop best-possible pseudo-polynomial-time algorithms,\na recent wave of results has improved Lawler and Moore's algorithm for $1||\\sum\np_j U_j$: First to time $\\tilde O(P^{7/4})$ [Bringmann, Fischer, Hermelin,\nShabtay, Wellnitz; ICALP'20], then to time $\\tilde O(P^{5/3})$ [Klein, Polak,\nRohwedder; SODA'23], and finally to time $\\tilde O(P^{7/5})$ [Schieber,\nSitaraman; WADS'23]. It remained an exciting open question whether these works\ncan be improved further.\n  In this work we develop an algorithm in near-linear time $\\tilde O(P)$ for\nthe $1||\\sum p_j U_j$ problem. This running time not only significantly\nimproves upon the previous results, but also matches conditional lower bounds\nbased on the Strong Exponential Time Hypothesis or the Set Cover Hypothesis and\nis therefore likely optimal (up to subpolynomial factors). Our new algorithm\nalso extends to the case of $m$ machines in time $\\tilde O(P^m)$. In contrast\nto the previous improvements, we take a different, more direct approach\ninspired by the recent reductions from Modular Subset Sum to dynamic string\nproblems. We thereby arrive at a satisfyingly simple algorithm.", "comment": "17 pages. This is the TheoretiCS journal version", "pdf_url": "http://arxiv.org/pdf/2402.13357v3", "cate": "cs.DS", "date": "2024-02-20", "updated": "2025-07-16", "AI": {"title_translation": "单机近线性时间最小化延迟处理时间", "tldr": "本文为调度问题$1||\n∑ p_j U_j$开发了一种近线性时间$\tilde O(P)$算法，显著优于现有结果，并可能达到最优。", "motivation": "调度问题$1||\n∑ p_j U_j$是一个NP-hard问题，尽管已有伪多项式时间算法，但仍存在进一步优化的开放性问题。本文旨在显著改进现有算法，并探索开发最佳可能的伪多项式时间算法。", "method": "本文采用了一种不同于以往的、更直接的方法。该方法受到最近从模子集和问题到动态字符串问题归约的启发，从而得到了一个令人满意的简单算法。", "result": "本文开发的算法在近线性时间$\tilde O(P)$内解决了$1||\n∑ p_j U_j$问题。这一运行时间显著优于之前的$\tilde O(P^{7/4})$、$\tilde O(P^{5/3})$和$\tilde O(P^{7/5})$等结果。它还与基于强指数时间假设或集合覆盖假设的条件下限相匹配，因此可能是最优的。此外，该算法可扩展到$m$台机器的情况，运行时间为$\tilde O(P^m)$。", "conclusion": "本文成功开发了一种针对$1||\n∑ p_j U_j$调度问题的近线性时间算法，该算法显著改善了现有结果并可能达到最优，是该领域的一个重要突破。", "translation": "在这项工作中，我们重新审视了基本的调度问题$1||\n∑ p_j U_j$。目标是在具有处理时间和截止日期的$n$个作业中，选择一个具有最大总处理时间的作业子集，这些作业可以按顺序调度而不会违反其截止日期。这个问题是NP-hard的，但Lawler和Moore在60年代提出的一种经典算法在伪多项式时间$O(nP)$内解决了这个问题，其中$P$是所有作业的总处理时间。为了开发最佳的伪多项式时间算法，最近的一波结果改进了Lawler和Moore针对$1||\n∑ p_j U_j$的算法：首先是时间$\tilde O(P^{7/4})$ [Bringmann, Fischer, Hermelin, Shabtay, Wellnitz; ICALP'20]，然后是时间$\tilde O(P^{5/3})$ [Klein, Polak, Rohwedder; SODA'23]，最后是时间$\tilde O(P^{7/5})$ [Schieber, Sitaraman; WADS'23]。这些工作是否能进一步改进仍然是一个令人兴奋的开放问题。\n在这项工作中，我们为$1||\n∑ p_j U_j$问题开发了一种近线性时间$\tilde O(P)$的算法。这一运行时间不仅显著改进了之前的结果，而且与基于强指数时间假设或集合覆盖假设的条件性下限相匹配，因此很可能是最优的（直至次多项式因子）。我们的新算法也扩展到$m$台机器的情况，时间为$\tilde O(P^m)$。与之前的改进不同，我们采取了一种不同的、更直接的方法，灵感来源于最近从模子集和问题到动态字符串问题的归约。因此，我们得到了一个令人满意的简单算法。", "summary": "本文重新审视了基本的调度问题$1||\n∑ p_j U_j$，目标是在给定处理时间和截止日期的$n$个作业中选择一个具有最大总处理时间的子集，以便按顺序调度且不违反截止日期。该问题是NP-hard的，但现有算法已在伪多项式时间内得到改进。本文提出了一种在近线性时间$\tilde O(P)$内解决该问题的新算法，该算法显著优于现有结果，并且与条件下限相匹配，因此可能是最优的。新算法还可扩展到$m$台机器的情况，运行时间为$\tilde O(P^m)$。与以往的改进不同，本文采取了一种受模子集和问题到动态字符串问题归约启发的新颖直接方法，从而得到了一个简洁的算法。", "keywords": "调度, 近线性时间, NP-hard, 伪多项式, 最优算法", "comments": "本文通过为$1||\n∑ p_j U_j$调度问题提供一个近线性时间算法，实现了显著的突破。其创新之处在于采用了受模子集和问题启发的新颖直接方法，从而得到了一个简洁且高效的算法。该结果不仅大幅超越了之前的所有改进，而且达到了理论上的最优性（考虑到条件限制），这使其成为调度算法领域的一个里程碑式贡献。"}}
{"id": "2504.00584", "title": "Semantic Adapter for Universal Text Embeddings: Diagnosing and Mitigating Negation Blindness to Enhance Universality", "authors": ["Hongliu Cao"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted in ECAI 2025 main track", "url": "http://arxiv.org/abs/2504.00584v2", "summary": "Negation plays an important role in various natural language processing tasks\nsuch as Natural Language Inference and Sentiment Analysis tasks. Numerous prior\nstudies have found that contextual text embedding models such as BERT, ELMO,\nRoBERTa or XLNet face challenges in accurately understanding negation. Recent\nadvancements in universal text embeddings have demonstrated superior\nperformance over contextual text embeddings in various tasks. However, due to\nthe bias in popular evaluation benchmarks, the negation awareness capacity of\nthese models remains unclear. To bridge the gap in existing literature, an\nin-depth analysis is initiated in this work to study the negation awareness of\ncutting-edge universal text embedding models. Our findings reveal a significant\nlack of negation awareness in these models, often interpreting negated text\npairs as semantically similar. To efficiently deal with the conflict that\ndifferent tasks need different trade-offs between topic and negation\ninformation among other semantic information, a data-efficient and\ncomputational-efficient embedding re-weighting method is proposed without\nmodifying the parameters of text embedding models. The proposed solution is\nable to improve text embedding models' negation awareness significantly on both\nsimple negation understanding task and complex negation understanding task.\nFurthermore, the proposed solution can also significantly improve the negation\nawareness of Large Language Model based task-specific high dimensional\nuniversal text embeddings.", "comment": "Accepted in ECAI 2025 main track", "pdf_url": "http://arxiv.org/pdf/2504.00584v2", "cate": "cs.CL", "date": "2025-04-01", "updated": "2025-07-16", "AI": {"title_translation": "通用文本嵌入的语义适配器：诊断和缓解否定盲点以增强通用性", "tldr": "研究发现通用文本嵌入模型对否定理解存在盲点，提出一种高效的嵌入重加权方法显著提升其否定感知能力。", "motivation": "现有通用文本嵌入模型在理解否定方面存在显著不足，经常将否定文本对解释为语义相似。此外，流行评估基准未能充分揭示这些模型的否定感知能力。", "method": "提出了一种数据高效且计算高效的嵌入重加权方法，该方法无需修改文本嵌入模型的参数，旨在处理不同任务对主题和否定信息之间不同权衡的需求。", "result": "所提出的解决方案显著提高了文本嵌入模型在简单和复杂否定理解任务上的否定感知能力。此外，它也能显著提高基于大型语言模型的特定任务高维通用文本嵌入的否定感知能力。", "conclusion": "通过提出的语义适配器（嵌入重加权方法），可以有效诊断并缓解通用文本嵌入模型（包括基于LLM的模型）的否定盲点，从而增强其在处理否定信息时的通用性。", "translation": "否定在自然语言处理的各种任务中扮演着重要角色，例如自然语言推理和情感分析任务。许多先前的研究发现，BERT、ELMO、RoBERTa或XLNet等上下文文本嵌入模型在准确理解否定方面面临挑战。通用文本嵌入的最新进展在各种任务中表现出优于上下文文本嵌入的性能。然而，由于流行评估基准中的偏差，这些模型的否定感知能力仍不清楚。为了弥补现有文献中的空白，这项工作深入分析了尖端通用文本嵌入模型的否定感知能力。我们的发现揭示了这些模型在否定感知方面存在显著不足，经常将否定文本对解释为语义相似。为了有效处理不同任务需要在主题和否定信息之间进行不同权衡的冲突，提出了一种数据高效、计算高效的嵌入重加权方法，而无需修改文本嵌入模型的参数。所提出的解决方案能够显著提高文本嵌入模型在简单否定理解任务和复杂否定理解任务上的否定感知能力。此外，所提出的解决方案还可以显著提高基于大型语言模型的特定任务高维通用文本嵌入的否定感知能力。", "summary": "本文深入分析了尖端通用文本嵌入模型在理解否定时的不足，发现它们常将否定文本对误判为语义相似。为解决此问题，作者提出了一种数据和计算高效的嵌入重加权方法，无需修改模型参数。实验证明，该方法能显著提升文本嵌入模型，包括基于大型语言模型的通用文本嵌入，在简单和复杂否定理解任务上的否定感知能力，从而增强其通用性。", "keywords": "否定理解, 通用文本嵌入, 语义适配器, 嵌入重加权, 大型语言模型", "comments": "本文识别并解决了通用文本嵌入模型在否定理解方面的关键局限性，特别是在当前大型语言模型（LLM）盛行的背景下，其提出的无需修改模型参数的轻量级重加权方法具有很强的实用价值和创新性。它弥补了现有评估基准的不足，并为提升模型在细微语义理解方面的鲁棒性提供了新思路。"}}
{"id": "2507.10786", "title": "\"Is it always watching? Is it always listening?\" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots", "authors": ["Henry Bell", "Jabari Kwesi", "Hiba Laabadli", "Pardis Emami-Naeini"], "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.ET", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10786v2", "summary": "Equipped with artificial intelligence (AI) and advanced sensing capabilities,\nsocial robots are gaining interest among consumers in the United States. These\nrobots seem like a natural evolution of traditional smart home devices.\nHowever, their extensive data collection capabilities, anthropomorphic\nfeatures, and capacity to interact with their environment make social robots a\nmore significant security and privacy threat. Increased risks include data\nlinkage, unauthorized data sharing, and the physical safety of users and their\nhomes. It is critical to investigate U.S. users' security and privacy needs and\nconcerns to guide the design of social robots while these devices are still in\nthe early stages of commercialization in the U.S. market. Through 19\nsemi-structured interviews, we identified significant security and privacy\nconcerns, highlighting the need for transparency, usability, and robust privacy\ncontrols to support adoption. For educational applications, participants\nworried most about misinformation, and in medical use cases, they worried about\nthe reliability of these devices. Participants were also concerned with the\ndata inference that social robots could enable. We found that participants\nexpect tangible privacy controls, indicators of data collection, and\ncontext-appropriate functionality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10786v2", "cate": "cs.CY", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "“它总是在监视吗？它总是在倾听吗？” 探索家庭社交机器人相关的语境隐私和安全问题", "tldr": "研究美国消费者对家用社交机器人的隐私和安全担忧，强调设计中需考虑透明度、可用性和隐私控制。", "motivation": "社交机器人作为智能家居设备的自然演变，其广泛的数据收集能力、拟人化特征和与环境互动的能力带来了重大的安全和隐私威胁。因此，在这些设备商业化早期阶段，调查美国用户的安全和隐私需求和担忧至关重要，以指导其设计。", "method": "通过19次半结构化访谈。", "result": "识别出显著的安全和隐私担忧，强调了透明度、可用性和强大的隐私控制对支持采用的重要性。受访者最担心教育应用中的错误信息和医疗用例中的设备可靠性。受访者还关注社交机器人可能导致的数据推断。研究发现受访者期望有形的隐私控制、数据收集指示器和符合情境的功能。", "conclusion": "社交机器人的设计需要整合透明度、可用性和强大的隐私控制，以解决用户对其数据收集、隐私和安全方面的担忧，从而促进其采用。", "translation": "配备人工智能(AI)和先进传感能力的社交机器人正引起美国消费者的兴趣。这些机器人似乎是传统智能家居设备的自然演变。然而，它们广泛的数据收集能力、拟人化特征以及与环境互动的能力使社交机器人成为更重大的安全和隐私威胁。增加的风险包括数据关联、未经授权的数据共享以及用户及其家庭的物理安全。在这些设备仍处于美国市场商业化的早期阶段时，调查美国用户的安全和隐私需求和担忧对于指导社交机器人的设计至关重要。通过19次半结构化访谈，我们识别出了显著的安全和隐私担忧，强调了透明度、可用性和强大的隐私控制对支持采用的需求。对于教育应用，参与者最担心错误信息，而在医疗用例中，他们担心这些设备的可靠性。参与者还关注社交机器人可能导致的数据推断。我们发现参与者期望有形的隐私控制、数据收集指示器和符合情境的功能。", "summary": "这项研究调查了美国消费者对家用社交机器人日益增长的隐私和安全担忧，这些机器人因其数据收集能力和拟人化特征而构成潜在威胁。通过19次半结构化访谈，研究发现用户对数据关联、未经授权共享和物理安全表示担忧，并期望设备具有透明度、可用性和强大的隐私控制。研究还特别提到了教育和医疗应用中的具体担忧，并强调了数据推断问题。", "keywords": "社交机器人, 隐私, 安全, 数据收集, 用户担忧", "comments": "这项研究在社交机器人商业化早期就关注用户隐私和安全问题，具有前瞻性。其通过访谈识别用户担忧，并提出透明度、可用性和隐私控制的需求，为未来社交机器人的设计提供了重要的用户中心视角。"}}
{"id": "2507.11807", "title": "CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels", "authors": ["Ruofan Hu", "Dongyu Zhang", "Huayi Zhang", "Elke Rundensteiner"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      KDD 2025, 12 pages, 7 figures", "url": "http://arxiv.org/abs/2507.11807v1", "summary": "Learning with noisy labels (LNL) is essential for training deep neural\nnetworks with imperfect data. Meta-learning approaches have achieved success by\nusing a clean unbiased labeled set to train a robust model. However, this\napproach heavily depends on the availability of a clean labeled meta-dataset,\nwhich is difficult to obtain in practice. In this work, we thus tackle the\nchallenge of meta-learning for noisy label scenarios without relying on a clean\nlabeled dataset. Our approach leverages the data itself while bypassing the\nneed for labels. Building on the insight that clean samples effectively\npreserve the consistency of related data structures across the last hidden and\nthe final layer, whereas noisy samples disrupt this consistency, we design the\nCross-layer Information Divergence-based Meta Update Strategy (CLID-MU).\nCLID-MU leverages the alignment of data structures across these diverse feature\nspaces to evaluate model performance and use this alignment to guide training.\nExperiments on benchmark datasets with varying amounts of labels under both\nsynthetic and real-world noise demonstrate that CLID-MU outperforms\nstate-of-the-art methods. The code is released at\nhttps://github.com/ruofanhu/CLID-MU.", "comment": "KDD 2025, 12 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.11807v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "CLID-MU：基于跨层信息散度的元更新策略，用于噪声标签学习", "tldr": "CLID-MU在没有干净元数据集的情况下，利用数据自身的跨层信息一致性来处理噪声标签学习，并在实验中优于现有方法。", "motivation": "现有的噪声标签学习元学习方法严重依赖于难以获取的干净标记元数据集，因此需要一种不依赖干净标签数据集的新方法。", "method": "本文提出了CLID-MU（基于跨层信息散度的元更新策略）。该方法不依赖干净标签，而是利用数据自身。其核心思想是利用干净样本在最后一层隐藏层和最终层之间保持数据结构一致性，而噪声样本会破坏这种一致性。CLID-MU通过评估这些不同特征空间中数据结构的对齐来指导模型训练。", "result": "在具有不同数量标签的基准数据集上，无论是合成噪声还是真实噪声，CLID-MU都优于最先进的方法。", "conclusion": "CLID-MU在不依赖干净标签元数据集的情况下，有效解决了噪声标签学习中的元学习挑战，并在各项实验中表现出优于现有方法的性能。", "translation": "学习带有噪声标签（LNL）对于使用不完美数据训练深度神经网络至关重要。元学习方法通过使用干净的无偏标记集来训练鲁棒模型取得了成功。然而，这种方法严重依赖于干净标记元数据集的可用性，这在实践中很难获得。因此，在这项工作中，我们解决了在不依赖干净标记数据集的情况下，为噪声标签场景进行元学习的挑战。我们的方法利用数据本身，同时绕过了对标签的需求。基于干净样本能有效保持最后一层隐藏层和最终层之间相关数据结构的一致性，而噪声样本会破坏这种一致性的洞察，我们设计了基于跨层信息散度的元更新策略（CLID-MU）。CLID-MU利用这些不同特征空间中数据结构的对齐来评估模型性能，并使用这种对齐来指导训练。在具有不同数量标签的基准数据集上，在合成噪声和真实世界噪声下进行的实验表明，CLID-MU优于最先进的方法。代码已在https://github.com/ruofanhu/CLID-MU 发布。", "summary": "本文提出了CLID-MU，一种用于噪声标签学习的元更新策略，旨在解决现有元学习方法对干净元数据集的依赖。CLID-MU利用数据在最后一层隐藏层和最终层之间的数据结构一致性来区分干净和噪声样本，并以此指导模型训练。实验证明，CLID-MU在合成和真实噪声环境下均优于现有先进方法，无需干净的元数据集。", "keywords": "噪声标签学习, 元学习, 跨层信息散度, 深度神经网络, 数据一致性", "comments": "CLID-MU的创新点在于，它在不依赖昂贵的干净元数据集的情况下，利用数据自身的内在结构一致性来识别和处理噪声，这为噪声标签学习提供了一条新颖且实用的路径。其通过跨层信息散度来评估模型性能并指导训练的思路值得关注。"}}
{"id": "2507.12094", "title": "Measuring Informativeness Gap of (Mis)Calibrated Predictors", "authors": ["Yiding Feng", "Wei Tang"], "categories": ["cs.LG", "cs.GT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12094v1", "summary": "In many applications, decision-makers must choose between multiple predictive\nmodels that may all be miscalibrated. Which model (i.e., predictor) is more\n\"useful\" in downstream decision tasks? To answer this, our first contribution\nintroduces the notion of the informativeness gap between any two predictors,\ndefined as the maximum normalized payoff advantage one predictor offers over\nthe other across all decision-making tasks. Our framework strictly generalizes\nseveral existing notions: it subsumes U-Calibration [KLST-23] and Calibration\nDecision Loss [HW-24], which compare a miscalibrated predictor to its\ncalibrated counterpart, and it recovers Blackwell informativeness [Bla-51,\nBla-53] as a special case when both predictors are perfectly calibrated. Our\nsecond contribution is a dual characterization of the informativeness gap,\nwhich gives rise to a natural informativeness measure that can be viewed as a\nrelaxed variant of the earth mover's distance (EMD) between two prediction\ndistributions. We show that this measure satisfies natural desiderata: it is\ncomplete and sound, and it can be estimated sample-efficiently in the\nprediction-only access setting. Along the way, we also obtain novel\ncombinatorial structural results when applying this measure to perfectly\ncalibrated predictors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12094v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "测量（误）校准预测器的信息量差距", "tldr": "本文引入了“信息量差距”的概念，用以比较（误）校准预测器在下游决策任务中的有用性，并提出了一个概括现有概念的新度量。", "motivation": "在许多应用中，决策者需要在多个可能存在校准偏差的预测模型之间进行选择，因此需要确定哪个模型在下游决策任务中更“有用”。", "method": "本文首先引入了任意两个预测器之间“信息量差距”的概念，定义为一个预测器在所有决策任务中相对于另一个预测器所能提供的最大标准化收益优势。其次，提出了信息量差距的双重刻画，从而得到一种自然的信息量度量，可视为两种预测分布之间地球移动距离（EMD）的一种宽松变体。", "result": "该框架严格概括了U-校准和校准决策损失等现有概念，并在两个预测器都完美校准时恢复了Blackwell信息量。所提出的度量满足完备性和可靠性等自然需求，并且可以在仅有预测访问的设置下进行样本高效估计。此外，当将此度量应用于完美校准的预测器时，还获得了新颖的组合结构结果。", "conclusion": "本文提出了一种新颖的框架和度量，用于量化和比较预测器（特别是存在校准偏差的预测器）的有用性，该框架具有强大的理论性质和实际可估计性。", "translation": "在许多应用中，决策者必须在多个可能都存在校准偏差的预测模型之间进行选择。在下游决策任务中，哪个模型（即预测器）更“有用”？为了回答这个问题，我们的第一个贡献引入了任意两个预测器之间信息量差距的概念，其定义为一个预测器在所有决策任务中相对于另一个预测器所能提供的最大标准化收益优势。我们的框架严格地概括了几个现有概念：它包含了U-校准[KLST-23]和校准决策损失[HW-24]（它们将一个校准偏差的预测器与其校准后的对应物进行比较），并且当两个预测器都完美校准时，它能恢复Blackwell信息量[Bla-51, Bla-53]作为特例。我们的第二个贡献是信息量差距的双重刻画，这产生了一种自然的信息量度量，可以看作是两种预测分布之间地球移动距离（EMD）的一种宽松变体。我们证明了该度量满足自然的需求：它是完备和可靠的，并且可以在仅有预测访问的设置下进行样本高效估计。在此过程中，当将此度量应用于完美校准的预测器时，我们还获得了新颖的组合结构结果。", "summary": "本文引入了“信息量差距”的概念，以量化和比较任意两个预测模型（尤其是存在校准偏差的模型）在下游决策任务中的有用性。该框架严格概括了U-校准和校准决策损失等现有概念，并能恢复Blackwell信息量。此外，本文还提供了信息量差距的双重刻画，从而提出了一种类似于宽松地球移动距离（EMD）的新型信息量度量，并证明其具有完备性、可靠性，且能够在仅有预测访问的设置下进行样本高效估计。", "keywords": "信息量差距, 校准偏差预测器, 决策任务, 地球移动距离, 模型比较", "comments": "该论文解决了在存在校准偏差时，如何超越单纯的准确性来比较模型这一关键的实际问题。它对现有概念的推广以及引入新的类EMD度量具有创新性。其在实际中可高效估计的特性也是一个重要的优势。"}}
{"id": "2506.13212", "title": "Volumetric Functional Maps", "authors": ["Filippo Maggioli", "Simone Melzi", "Marco Livesu"], "categories": ["cs.GR", "cs.CG", "68U05", "I.3"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.13212v2", "summary": "The computation of volumetric correspondences between 3D shapes is a\nprominent tool for medical and industrial applications. In this work, we pave\nthe way for spectral volume mapping, extending for the first time the\nfunctional maps framework from the surface to the volumetric setting. We show\nthat the eigenfunctions of the volumetric Laplace operator define a functional\nspace that is suitable for high-quality signal transfer. We also experiment\nwith various techniques that edit this functional space, porting them to volume\ndomains. We validate our method on novel volumetric datasets and on\ntetrahedralizations of well established surface datasets, also showcasing\npractical applications involving both discrete and continuous signal mapping,\nfor segmentation transfer, mesh connectivity transfer and solid texturing. Last\nbut not least, we show that considering the volumetric spectrum greatly\nimproves the accuracy for classical shape matching tasks among surfaces,\nconsistently outperforming existing surface-only spectral methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.13212v2", "cate": "cs.GR", "date": "2025-06-16", "updated": "2025-07-15", "AI": {"title_translation": "体功能映射", "tldr": "本文首次将功能映射框架从表面扩展到体数据，提出了体功能映射方法，并展示了其在信号传输、分割、网格连接和纹理映射等应用中的优越性，尤其在表面匹配任务中显著优于现有方法。", "motivation": "3D形状之间的体对应计算是医疗和工业应用中的重要工具。现有功能映射框架主要针对表面数据，缺乏针对体数据的有效方法。", "method": "本文首次将功能映射框架从表面扩展到体数据，提出了体功能映射。研究表明，体拉普拉斯算子的特征函数定义了一个适合高质量信号传输的功能空间。同时，实验了多种编辑此功能空间的技术，并将其移植到体域。", "result": "该方法在新的体数据集和现有表面数据集的四面体化上得到了验证。展示了涉及离散和连续信号映射的实际应用，包括分割传输、网格连接传输和实体纹理映射。结果表明，考虑体谱显著提高了经典形状匹配任务的准确性，并持续优于现有的仅基于表面的谱方法。", "conclusion": "本文成功将功能映射框架扩展到体数据，提出了体功能映射，并证明了其在高质量信号传输和形状匹配任务中的优越性，尤其在表面匹配方面超越了现有方法。", "translation": "体功能映射\n\n3D形状之间的体对应计算是医疗和工业应用中的重要工具。在这项工作中，我们为谱体映射铺平了道路，首次将功能映射框架从表面扩展到体设置。我们证明了体拉普拉斯算子的特征函数定义了一个适合高质量信号传输的功能空间。我们还尝试了多种编辑此功能空间的技术，并将其移植到体域。我们在新的体数据集和现有表面数据集的四面体化上验证了我们的方法，并展示了涉及离散和连续信号映射的实际应用，用于分割传输、网格连接传输和实体纹理映射。最后但同样重要的是，我们表明，考虑体谱极大地提高了表面之间经典形状匹配任务的准确性，持续优于现有的仅基于表面的谱方法。", "summary": "本文首次将功能映射框架从表面扩展到体数据，提出了体功能映射。通过利用体拉普拉斯算子的特征函数定义的功能空间，实现了高质量的信号传输。该方法在体数据集和四面体化表面数据集上进行了验证，并展示了在分割传输、网格连接传输和实体纹理映射等方面的应用。研究表明，体谱的应用显著提升了形状匹配的准确性，超越了现有的表面谱方法。", "keywords": "体功能映射, 体对应, 拉普拉斯算子, 信号传输, 形状匹配", "comments": "这项工作创新性地将功能映射框架从传统的表面扩展到体数据，填补了该领域的空白。其贡献在于证明了体拉普拉斯算子特征函数在体域信号传输的有效性，并展示了其在多种实际应用中的潜力，特别是提高了经典形状匹配任务的准确性，超越了现有方法，具有重要的理论和实践意义。"}}
{"id": "2502.12937", "title": "Tuning Algorithmic and Architectural Hyperparameters in Graph-Based Semi-Supervised Learning with Provable Guarantees", "authors": ["Ally Yalei Du", "Eric Huang", "Dravyansh Sharma"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      31 pages (12 pages main body), 2 figures. UAI 2025", "url": "http://arxiv.org/abs/2502.12937v2", "summary": "Graph-based semi-supervised learning is a powerful paradigm in machine\nlearning for modeling and exploiting the underlying graph structure that\ncaptures the relationship between labeled and unlabeled data. A large number of\nclassical as well as modern deep learning based algorithms have been proposed\nfor this problem, often having tunable hyperparameters. We initiate a formal\nstudy of tuning algorithm hyperparameters from parameterized algorithm families\nfor this problem. We obtain novel $O(\\log n)$ pseudo-dimension upper bounds for\nhyperparameter selection in three classical label propagation-based algorithm\nfamilies, where $n$ is the number of nodes, implying bounds on the amount of\ndata needed for learning provably good parameters. We further provide matching\n$\\Omega(\\log n)$ pseudo-dimension lower bounds, thus asymptotically\ncharacterizing the learning-theoretic complexity of the parameter tuning\nproblem. We extend our study to selecting architectural hyperparameters in\nmodern graph neural networks. We bound the Rademacher complexity for tuning the\nself-loop weighting in recently proposed Simplified Graph Convolution (SGC)\nnetworks. We further propose a tunable architecture that interpolates graph\nconvolutional neural networks (GCN) and graph attention networks (GAT) in every\nlayer, and provide Rademacher complexity bounds for tuning the interpolation\ncoefficient.", "comment": "31 pages (12 pages main body), 2 figures. UAI 2025", "pdf_url": "http://arxiv.org/pdf/2502.12937v2", "cate": "cs.LG", "date": "2025-02-18", "updated": "2025-07-16", "AI": {"title_translation": "图半监督学习中可证明保证的算法和架构超参数调优", "tldr": "本文对图半监督学习中的算法和架构超参数调优进行了形式化研究，为经典算法和现代图神经网络提供了可证明的保证，包括伪维度和Rademacher复杂度界限。", "motivation": "图半监督学习中的经典算法和现代深度学习算法通常具有可调超参数。现有研究缺乏对这些超参数调优的正式研究和可证明的保证。", "method": "研究了参数化算法族中算法超参数的调优问题。为三种经典标签传播算法家族的超参数选择获得了伪维度上界和下界。将研究扩展到现代图神经网络中的架构超参数选择，具体包括：为简化图卷积（SGC）网络中自环加权调优提供了Rademacher复杂度界限；提出了一个在每层插值图卷积神经网络（GCN）和图注意力网络（GAT）的可调架构，并为其插值系数的调优提供了Rademacher复杂度界限。", "result": "获得了三种经典标签传播算法家族的超参数选择的$O(\\log n)$伪维度上界，以及匹配的$\\Omega(\\log n)$伪维度下界，从而渐近地刻画了参数调优问题的学习理论复杂性。为简化图卷积（SGC）网络中自环加权的调优提供了Rademacher复杂度界限。为提出的GCN和GAT插值架构中的插值系数调优提供了Rademacher复杂度界限。", "conclusion": "本文对图半监督学习中的超参数调优进行了形式化研究，为经典方法和现代图神经网络架构提供了学习理论复杂性表征和可证明的保证（伪维度和Rademacher复杂度界限），并提出了一种新颖的插值架构。", "translation": "图半监督学习是机器学习中一种强大的范式，用于建模和利用捕获标记和未标记数据之间关系的底层图结构。针对这个问题，已经提出了大量的经典算法以及基于现代深度学习的算法，这些算法通常具有可调超参数。我们启动了对该问题中参数化算法族的算法超参数调优的正式研究。我们为三种经典标签传播算法家族的超参数选择获得了新颖的$O(\\log n)$伪维度上界，其中$n$是节点数量，这意味着学习可证明的良好参数所需数据量的界限。我们进一步提供了匹配的$\\Omega(\\log n)$伪维度下界，从而渐近地刻画了参数调优问题的学习理论复杂性。我们将研究扩展到现代图神经网络中的架构超参数选择。我们为最近提出的简化图卷积（SGC）网络中自环加权的调优提供了Rademacher复杂度界限。我们进一步提出了一种在每层插值图卷积神经网络（GCN）和图注意力网络（GAT）的可调架构，并为调优插值系数提供了Rademacher复杂度界限。", "summary": "本文对图半监督学习（GSSL）中的超参数调优进行了深入的理论研究，涵盖了算法和架构层面。研究为经典标签传播算法的超参数选择提供了严谨的伪维度上界和匹配的下界，从而量化了其学习理论复杂性。此外，工作扩展到现代图神经网络（GNNs），为简化图卷积（SGC）网络的自环加权调优和一种新提出的GCN与GAT插值架构的插值系数调优提供了Rademacher复杂度界限。这些发现为GSSL中的超参数选择提供了重要的可证明保证。", "keywords": "图半监督学习, 超参数调优, 伪维度, Rademacher复杂度, 图神经网络", "comments": "本文的创新之处在于首次对图半监督学习中的超参数调优进行了系统的学习理论分析，并提供了严格的伪维度和Rademacher复杂度界限，这对于理解和指导超参数选择具有重要意义。它不仅涵盖了传统的图算法，还扩展到了现代图神经网络，特别是提出了GCN和GAT的插值架构，展现了其理论和实践价值。"}}
{"id": "2507.11689", "title": "REST in Pieces: RESTful Design Rule Violations in Student-Built Web Apps", "authors": ["Sergio Di Meglio", "Valeria Pontillo", "Luigi Libero Lucio Starace"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Manuscript accepted for the 51st Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA)", "url": "http://arxiv.org/abs/2507.11689v1", "summary": "In Computer Science Bachelor's programs, software quality is often\nunderemphasized due to limited time and a focus on foundational skills, leaving\nmany students unprepared for industry expectations. To better understand the\ntypical quality of student code and inform both education and hiring practices,\nwe analyze 40 full-stack web applications developed in a third-year Web\nTechnologies course. Using an automated static analysis pipeline, we assess\nadherence to REST API design rules. Results reveal frequent violations of\nfoundational conventions, such as missing hyphens in endpoint paths (98%),\nincorrect pluralization (88%), and misuse of HTTP methods (83%). These findings\nhighlight the need for more focused instruction on API design and support the\nadoption of automated tools to improve code quality in student projects.", "comment": "Manuscript accepted for the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA)", "pdf_url": "http://arxiv.org/pdf/2507.11689v1", "cate": "cs.SE", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "REST 残片：学生构建的 Web 应用中的 RESTful 设计规则违规", "tldr": "一项对学生构建的 Web 应用的分析发现，它们普遍存在 RESTful API 设计规则违规，例如缺少连字符、错误的复数形式和 HTTP 方法误用，这表明需要加强教学和工具支持。", "motivation": "计算机科学学士课程中，软件质量常因时间有限和侧重基础技能而被忽视，导致许多学生未能达到行业期望。为了更好地了解学生代码的典型质量，并为教育和招聘实践提供信息，本研究进行了分析。", "method": "本研究分析了在三年级 Web 技术课程中开发的 40 个全栈 Web 应用程序。研究人员使用自动化静态分析管道来评估其对 REST API 设计规则的遵守情况。", "result": "结果显示，学生项目普遍违反了基础约定，例如端点路径中缺少连字符（98%）、复数形式不正确（88%）和 HTTP 方法误用（83%）。", "conclusion": "这些发现强调了需要更专注于 API 设计的教学，并支持采用自动化工具来提高学生项目的代码质量。", "translation": "在计算机科学学士课程中，软件质量常因时间有限和侧重基础技能而被忽视，导致许多学生未能达到行业期望。为了更好地了解学生代码的典型质量，并为教育和招聘实践提供信息，我们分析了在三年级 Web 技术课程中开发的 40 个全栈 Web 应用程序。我们使用自动化静态分析管道来评估其对 REST API 设计规则的遵守情况。结果显示，学生项目普遍违反了基础约定，例如端点路径中缺少连字符（98%）、复数形式不正确（88%）和 HTTP 方法误用（83%）。这些发现强调了需要更专注于 API 设计的教学，并支持采用自动化工具来提高学生项目的代码质量。", "summary": "本研究旨在评估计算机科学专业学生构建的 Web 应用程序的软件质量，特别是在 REST API 设计规则的遵守方面。通过对 40 个学生全栈 Web 应用进行自动化静态分析，发现存在高频率的 RESTful 设计规则违规，包括路径命名、复数使用和 HTTP 方法的误用。研究结果强调了在计算机科学教育中加强 API 设计教学以及推广自动化代码质量工具的必要性。", "keywords": "REST API 设计, 学生项目, 代码质量, 静态分析, Web 应用", "comments": "本文通过对真实学生项目的分析，揭示了当前计算机科学教育在软件质量，特别是 REST API 设计方面可能存在的不足。其创新之处在于使用了自动化静态分析方法对大量学生代码进行了系统性评估。研究结果对教育者和行业实践者都有重要启示，指出了改进课程设置和引入自动化工具以提升学生代码质量的明确方向。"}}
{"id": "2507.12356", "title": "Exploring Gender Bias in Alzheimer's Disease Detection: Insights from Mandarin and Greek Speech Perception", "authors": ["Liu He", "Yuanchao Li", "Rui Feng", "XinRan Han", "Yin-Long Liu", "Yuwei Yang", "Zude Zhu", "Jiahong Yuan"], "categories": ["cs.CL", "cs.HC", "cs.SD"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages, 5 figures, conference or other essential info", "url": "http://arxiv.org/abs/2507.12356v1", "summary": "Gender bias has been widely observed in speech perception tasks, influenced\nby the fundamental voicing differences between genders. This study reveals a\ngender bias in the perception of Alzheimer's Disease (AD) speech. In a\nperception experiment involving 16 Chinese listeners evaluating both Chinese\nand Greek speech, we identified that male speech was more frequently identified\nas AD, with this bias being particularly pronounced in Chinese speech. Acoustic\nanalysis showed that shimmer values in male speech were significantly\nassociated with AD perception, while speech portion exhibited a significant\nnegative correlation with AD identification. Although language did not have a\nsignificant impact on AD perception, our findings underscore the critical role\nof gender bias in AD speech perception. This work highlights the necessity of\naddressing gender bias when developing AD detection models and calls for\nfurther research to validate model performance across different linguistic\ncontexts.", "comment": "12 pages, 5 figures, conference or other essential info", "pdf_url": "http://arxiv.org/pdf/2507.12356v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "探索阿尔茨海默病检测中的性别偏见：来自普通话和希腊语语音感知的见解", "tldr": "本研究发现阿尔茨海默病（AD）语音感知中存在性别偏见，男性语音更常被识别为AD，尤其是在中文语音中。这强调了在开发AD检测模型时解决性别偏见的必要性。", "motivation": "性别偏见在语音感知任务中普遍存在，受性别之间基本发音差异的影响。本研究旨在揭示阿尔茨海默病（AD）语音感知中是否存在性别偏见。", "method": "通过一项感知实验，16名中国听众评估中文和希腊语语音。同时进行了声学分析。", "result": "男性语音更频繁地被识别为AD，这种偏见在中文语音中尤为明显。声学分析显示，男性语音中的颤音值与AD感知显著相关，而语音部分与AD识别呈显著负相关。语言对AD感知没有显著影响。", "conclusion": "本研究结果强调了性别偏见在AD语音感知中的关键作用，并指出在开发AD检测模型时必须解决性别偏见。", "translation": "性别偏见在语音感知任务中已被广泛观察到，并受到性别之间基本发音差异的影响。本研究揭示了阿尔茨海默病（AD）语音感知中的性别偏见。在一项涉及16名中国听众评估中文和希腊语语音的感知实验中，我们发现男性语音更频繁地被识别为AD，这种偏见在中文语音中尤为明显。声学分析显示，男性语音中的颤音值与AD感知显著相关，而语音部分与AD识别呈显著负相关。尽管语言对AD感知没有显著影响，但我们的发现强调了性别偏见在AD语音感知中的关键作用。这项工作突出强调了在开发AD检测模型时解决性别偏见的必要性，并呼吁进一步研究以验证模型在不同语言环境下的性能。", "summary": "本研究探讨了阿尔茨海默病（AD）语音感知中的性别偏见。通过一项涉及16名中国听众对中文和希腊语语音的感知实验，发现男性语音更容易被识别为AD，尤其是在中文语音中。声学分析表明，男性语音的颤音值与AD感知显著相关。研究强调了性别偏见在AD语音感知中的重要性，并指出在开发AD检测模型时应考虑并解决这一偏见。", "keywords": "性别偏见, 阿尔茨海默病, 语音感知, 颤音, 语言", "comments": "这项研究揭示了AD语音感知中一个重要的、以前可能被忽视的性别偏见问题，这对于开发更公平、更准确的AD检测模型具有重要意义。其创新之处在于将性别偏见分析引入AD语音检测领域，并指出跨语言验证的必要性。"}}
{"id": "2507.12026", "title": "3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering", "authors": ["Rongtao Xu", "Han Gao", "Mingming Yu", "Dong An", "Shunpeng Chen", "Changwei Wang", "Li Guo", "Xiaodan Liang", "Shibiao Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IROS 2025", "url": "http://arxiv.org/abs/2507.12026v1", "summary": "With the growing need for diverse and scalable data in indoor scene tasks,\nsuch as question answering and dense captioning, we propose 3D-MoRe, a novel\nparadigm designed to generate large-scale 3D-language datasets by leveraging\nthe strengths of foundational models. The framework integrates key components,\nincluding multi-modal embedding, cross-modal interaction, and a language model\ndecoder, to process natural language instructions and 3D scene data. This\napproach facilitates enhanced reasoning and response generation in complex 3D\nenvironments. Using the ScanNet 3D scene dataset, along with text annotations\nfrom ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairs\nand 73,000 object descriptions across 1,513 scenes. We also employ various data\naugmentation techniques and implement semantic filtering to ensure high-quality\ndata. Experiments on ScanQA demonstrate that 3D-MoRe significantly outperforms\nstate-of-the-art baselines, with the CIDEr score improving by 2.15\\%.\nSimilarly, on ScanRefer, our approach achieves a notable increase in CIDEr@0.5\nby 1.84\\%, highlighting its effectiveness in both tasks. Our code and generated\ndatasets will be publicly released to benefit the community, and both can be\naccessed on the https://3D-MoRe.github.io.", "comment": "Accepted by IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.12026v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "3D-MoRe：具身问答中的统一模态-上下文推理", "tldr": "3D-MoRe利用基础模型生成大规模3D语言数据集，并通过统一模态-上下文推理显著提升了3D具身问答和指代任务的性能。", "motivation": "室内场景任务（如问答和密集字幕）对多样化和可扩展数据的需求日益增长。", "method": "本文提出了3D-MoRe框架，旨在利用基础模型生成大规模3D语言数据集。该框架整合了多模态嵌入、跨模态交互和语言模型解码器，以处理自然语言指令和3D场景数据，从而促进增强推理和响应生成。该方法还采用了数据增强技术和语义过滤以确保数据质量。", "result": "3D-MoRe利用ScanNet、ScanQA和ScanRefer数据集，生成了62,000个问答对和73,000个对象描述。在ScanQA上的实验表明，CIDEr分数提高了2.15%；在ScanRefer上，CIDEr@0.5提高了1.84%，显著优于现有基线。", "conclusion": "3D-MoRe在生成高质量大规模3D语言数据集方面表现出显著有效性，并在具身问答和指代任务中显著提升了性能。", "translation": "随着室内场景任务（如问答和密集字幕）对多样化和可扩展数据的需求日益增长，我们提出了3D-MoRe，一个旨在利用基础模型的优势生成大规模3D语言数据集的新范式。该框架集成了关键组件，包括多模态嵌入、跨模态交互和语言模型解码器，以处理自然语言指令和3D场景数据。这种方法有助于增强复杂3D环境中的推理和响应生成。通过使用ScanNet 3D场景数据集以及来自ScanQA和ScanRefer的文本注释，3D-MoRe在1,513个场景中生成了62,000个问答对和73,000个对象描述。我们还采用了各种数据增强技术并实施语义过滤以确保高质量数据。在ScanQA上的实验表明，3D-MoRe显著优于最先进的基线，CIDEr分数提高了2.15%。同样，在ScanRefer上，我们的方法在CIDEr@0.5方面实现了1.84%的显著增长，突出了其在两项任务中的有效性。我们的代码和生成的数据集将公开发布以造福社区，两者都可以在https://3D-MoRe.github.io上访问。", "summary": "本文提出了3D-MoRe，一个利用基础模型生成大规模3D语言数据集的新范式，旨在解决室内场景任务中数据多样性和可扩展性的需求。该框架通过整合多模态嵌入、跨模态交互和语言模型解码器，增强了复杂3D环境中的推理和响应生成。实验结果表明，3D-MoRe在ScanQA和ScanRefer任务上均显著超越了现有基线，提升了性能，并生成了大量高质量的问答对和对象描述数据。", "keywords": "3D-MoRe, 具身问答, 3D语言数据集, 模态推理, 基础模型", "comments": "这项工作通过利用基础模型来生成大规模、高质量的3D语言数据集，为具身问答和相关任务提供了重要的数据基础，解决了数据稀缺的挑战。其统一模态-上下文推理方法以及在多个任务上的显著性能提升，显示了其创新性和实用价值。数据集的公开将极大地促进社区研究。"}}
{"id": "2507.12451", "title": "S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling", "authors": ["Suman Adhya", "Debarshi Kumar Sanyal"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted as a long paper for ACL 2025 main conference", "url": "http://arxiv.org/abs/2507.12451v1", "summary": "Modeling latent representations in a hyperspherical space has proven\neffective for capturing directional similarities in high-dimensional text data,\nbenefiting topic modeling. Variational autoencoder-based neural topic models\n(VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode hyperspherical\nstructure. However, VAE-NTMs often suffer from posterior collapse, where the KL\ndivergence term in the objective function highly diminishes, leading to\nineffective latent representations. To mitigate this issue while modeling\nhyperspherical structure in the latent space, we propose the Spherical Sliced\nWasserstein Autoencoder for Topic Modeling (S2WTM). S2WTM employs a prior\ndistribution supported on the unit hypersphere and leverages the Spherical\nSliced-Wasserstein distance to align the aggregated posterior distribution with\nthe prior. Experimental results demonstrate that S2WTM outperforms\nstate-of-the-art topic models, generating more coherent and diverse topics\nwhile improving performance on downstream tasks.", "comment": "Accepted as a long paper for ACL 2025 main conference", "pdf_url": "http://arxiv.org/pdf/2507.12451v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "S2WTM：用于主题建模的球形切片Wasserstein自编码器", "tldr": "S2WTM通过利用球形切片Wasserstein距离来解决变分自编码器神经主题模型（VAE-NTM）中的后验崩溃问题，从而在超球形空间中生成更连贯和多样的主题。", "motivation": "在超球形空间中建模潜在表示已被证明对捕获高维文本数据中的方向相似性有效，有利于主题建模。然而，基于变分自编码器的神经主题模型（VAE-NTM）常受后验崩溃问题困扰，导致潜在表示无效。", "method": "本文提出了S2WTM（用于主题建模的球形切片Wasserstein自编码器）。S2WTM采用一个支持在单位超球体上的先验分布，并利用球形切片Wasserstein距离来对齐聚合后验分布与先验分布。", "result": "实验结果表明，S2WTM优于最先进的主题模型，能够生成更连贯和多样的主题，同时提高了下游任务的性能。", "conclusion": "S2WTM有效缓解了VAE-NTM中的后验崩溃问题，并通过在超球形空间中利用球形切片Wasserstein距离，显著提升了主题建模的性能和主题质量。", "translation": "在超球形空间中建模潜在表示已被证明对捕获高维文本数据中的方向相似性有效，有利于主题建模。基于变分自编码器的神经主题模型（VAE-NTM）通常采用von Mises-Fisher先验来编码超球形结构。然而，VAE-NTM常受后验崩溃问题困扰，即目标函数中的KL散度项高度减小，导致潜在表示无效。为了在潜在空间中建模超球形结构的同时缓解这个问题，我们提出了用于主题建模的球形切片Wasserstein自编码器（S2WTM）。S2WTM采用一个支持在单位超球体上的先验分布，并利用球形切片Wasserstein距离来对齐聚合后验分布与先验分布。实验结果表明，S2WTM优于最先进的主题模型，能够生成更连贯和多样的主题，同时提高了下游任务的性能。", "summary": "本文提出S2WTM，一种基于球形切片Wasserstein自编码器的主题模型，旨在解决传统变分自编码器神经主题模型（VAE-NTM）在超球形空间中进行主题建模时常出现的后验崩溃问题。S2WTM通过在单位超球体上使用特定先验分布，并利用球形切片Wasserstein距离来确保聚合后验分布与先验分布对齐。实验证明，S2WTM在生成更连贯和多样的主题方面优于现有模型，并提升了下游任务的表现。", "keywords": "主题建模, 变分自编码器, Wasserstein距离, 超球形空间, 后验崩溃", "comments": "本文的创新点在于引入了球形切片Wasserstein距离来解决超球形变分自编码器在主题建模中的后验崩溃问题。这种方法不仅保持了超球形表示的优势，还通过有效的距离度量改善了模型性能，对于提升神经主题模型的效果具有重要意义。"}}
{"id": "2503.13026", "title": "HiMTok: Learning Hierarchical Mask Tokens for Image Segmentation with Large Multimodal Model", "authors": ["Tao Wang", "Changxu Cheng", "Lingfeng Wang", "Senda Chen", "Wuyue Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025; the code is at this https URL", "url": "http://arxiv.org/abs/2503.13026v2", "summary": "The remarkable performance of large multimodal models (LMMs) has attracted\nsignificant interest from the image segmentation community. To align with the\nnext-token-prediction paradigm, current LMM-driven segmentation methods either\nuse object boundary points to represent masks or introduce special segmentation\ntokens, whose hidden states are decoded by a segmentation model requiring the\noriginal image as input. However, these approaches often suffer from inadequate\nmask representation and complex architectures, limiting the potential of LMMs.\nIn this work, we propose the Hierarchical Mask Tokenizer (HiMTok), which\nrepresents segmentation masks with up to 32 tokens and eliminates the need for\nthe original image during mask de-tokenization. HiMTok allows for compact and\ncoarse-to-fine mask representations, aligning well with the LLM\nnext-token-prediction paradigm and facilitating the direct acquisition of\nsegmentation capabilities. We develop a 3-stage training recipe for progressive\nlearning of segmentation and visual capabilities, featuring a hierarchical mask\nloss for effective coarse-to-fine learning. Additionally, we enable\nbidirectional information flow, allowing conversion between bounding boxes and\nmask tokens to fully leverage multi-task training potential. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\nacross various segmentation tasks,while also enhancing visual grounding and\nmaintaining overall visual understanding.", "comment": "Accepted by ICCV 2025; the code is at\n  https://github.com/yayafengzi/LMM-HiMTok", "pdf_url": "http://arxiv.org/pdf/2503.13026v2", "cate": "cs.CV", "date": "2025-03-17", "updated": "2025-07-16", "AI": {"title_translation": "HiMTok：学习分层掩码令牌用于大型多模态模型的图像分割", "tldr": "HiMTok是一种新的方法，通过分层掩码令牌在大型多模态模型中实现高效的图像分割，无需原始图像输入，并达到SOTA性能。", "motivation": "当前由大型多模态模型（LMMs）驱动的图像分割方法，为了适应下一令牌预测范式，通常使用目标边界点表示掩码或引入特殊分割令牌，这些令牌的隐藏状态需要通过一个需要原始图像作为输入的分割模型解码。然而，这些方法常面临掩码表示不足和架构复杂的问题，限制了LMMs的潜力。", "method": "本文提出了分层掩码令牌器（HiMTok），它使用多达32个令牌表示分割掩码，并在掩码去令牌化过程中无需原始图像。HiMTok实现了紧凑且从粗到细的掩码表示，很好地与LLM的下一令牌预测范式对齐，并促进了分割能力的直接获取。我们开发了一个三阶段训练方案，用于逐步学习分割和视觉能力，其特点是采用分层掩码损失以实现有效的从粗到细学习。此外，我们还实现了双向信息流，允许在边界框和掩码令牌之间进行转换，以充分利用多任务训练潜力。", "result": "我们的方法在各种分割任务中实现了最先进的性能，同时增强了视觉基础并保持了整体视觉理解能力。", "conclusion": "HiMTok通过提供卓越的掩码表示和架构，有效解决了当前LMM驱动的分割方法的局限性，从而在各种分割任务中实现了最先进的性能，并增强了视觉理解。", "translation": "大型多模态模型（LMMs）的卓越性能引起了图像分割界的广泛关注。为了与下一令牌预测范式对齐，当前由LMM驱动的分割方法要么使用目标边界点来表示掩码，要么引入特殊的分割令牌，其隐藏状态需要通过一个需要原始图像作为输入的分割模型进行解码。然而，这些方法常常存在掩码表示不足和架构复杂的问题，限制了LMMs的潜力。在这项工作中，我们提出了分层掩码令牌器（HiMTok），它使用多达32个令牌表示分割掩码，并在掩码去令牌化过程中无需原始图像。HiMTok允许紧凑且从粗到细的掩码表示，与LLM的下一令牌预测范式良好对齐，并促进了分割能力的直接获取。我们开发了一个三阶段训练方案，用于逐步学习分割和视觉能力，其特点是采用分层掩码损失以实现有效的从粗到细学习。此外，我们还实现了双向信息流，允许在边界框和掩码令牌之间进行转换，以充分利用多任务训练潜力。广泛的实验表明，我们的方法在各种分割任务中实现了最先进的性能，同时增强了视觉基础并保持了整体视觉理解。", "summary": "当前大型多模态模型（LMM）驱动的图像分割方法面临掩码表示不足和架构复杂的问题。本文提出了HiMTok，一种分层掩码令牌器，它使用多达32个令牌表示分割掩码，并在解码时无需原始图像。HiMTok实现了紧凑且从粗到细的掩码表示，与下一令牌预测范式良好对齐。通过一个包含分层掩码损失的三阶段训练方案和双向信息流，HiMTok能够有效学习。广泛实验证明，HiMTok在多种分割任务中达到了最先进的性能，并提升了视觉基础和整体视觉理解能力。", "keywords": "大型多模态模型, 图像分割, 分层掩码令牌, HiMTok, 下一令牌预测", "comments": "本文的创新点在于提出了HiMTok，通过分层掩码令牌实现了更紧凑和粗到细的掩码表示，并且在去令牌化过程中无需原始图像，这显著简化了模型架构并提高了效率。其三阶段训练策略和双向信息流设计也有效地利用了多任务训练潜力，推动了LMM在图像分割领域的应用，为未来的研究提供了新的方向。"}}
{"id": "2507.11549", "title": "An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search", "authors": ["Wendong Mao", "Mingfan Zhao", "Jianfeng Guan", "Qiwei Dong", "Zhongfeng Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11549v1", "summary": "Deformable Attention Transformers (DAT) have shown remarkable performance in\ncomputer vision tasks by adaptively focusing on informative image regions.\nHowever, their data-dependent sampling mechanism introduces irregular memory\naccess patterns, posing significant challenges for efficient hardware\ndeployment. Existing acceleration methods either incur high hardware overhead\nor compromise model accuracy. To address these issues, this paper proposes a\nhardware-friendly optimization framework for DAT. First, a neural architecture\nsearch (NAS)-based method with a new slicing strategy is proposed to\nautomatically divide the input feature into uniform patches during the\ninference process, avoiding memory conflicts without modifying model\narchitecture. The method explores the optimal slice configuration by jointly\noptimizing hardware cost and inference accuracy. Secondly, an FPGA-based\nverification system is designed to test the performance of this framework on\nedge-side hardware. Algorithm experiments on the ImageNet-1K dataset\ndemonstrate that our hardware-friendly framework can maintain have only 0.2%\naccuracy drop compared to the baseline DAT. Hardware experiments on Xilinx FPGA\nshow the proposed method reduces DRAM access times to 18% compared with\nexisting DAT acceleration methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11549v1", "cate": "cs.CV", "date": "2025-07-13", "updated": "2025-07-13", "AI": {"title_translation": "具有神经架构搜索的可变形Transformer的内存高效框架", "tldr": "提出了一种基于NAS的内存高效框架，通过切片策略优化可变形Transformer在硬件上的部署，显著减少DRAM访问并保持高精度。", "motivation": "可变形注意力Transformer (DAT) 在计算机视觉任务中表现出色，但其数据依赖的采样机制导致不规则内存访问模式，阻碍了高效硬件部署。现有加速方法存在高硬件开销或精度损失问题。", "method": "1. 提出一种基于神经架构搜索 (NAS) 的新切片策略，在推理过程中自动将输入特征划分为均匀块，避免内存冲突且不修改模型架构，同时优化硬件成本和推理精度。 2. 设计了一个基于FPGA的验证系统，用于在边缘侧硬件上测试该框架的性能。", "result": "在ImageNet-1K数据集上的算法实验表明，与基线DAT相比，该框架仅有0.2%的精度下降。在Xilinx FPGA上的硬件实验表明，所提出的方法将DRAM访问次数降低到现有DAT加速方法的18%。", "conclusion": "该研究成功开发了一个内存高效且硬件友好的可变形Transformer优化框架，显著降低了硬件部署的内存访问开销，同时保持了高模型精度。", "translation": "可变形注意力Transformer（DAT）通过自适应地聚焦于信息丰富的图像区域，在计算机视觉任务中表现出卓越的性能。然而，它们的数据依赖采样机制引入了不规则的内存访问模式，对高效硬件部署提出了重大挑战。现有的加速方法要么导致高硬件开销，要么牺牲模型精度。为了解决这些问题，本文提出了一种适用于DAT的硬件友好优化框架。首先，提出了一种基于神经架构搜索（NAS）的新切片策略，用于在推理过程中自动将输入特征划分为均匀块，从而在不修改模型架构的情况下避免内存冲突。该方法通过联合优化硬件成本和推理精度来探索最佳切片配置。其次，设计了一个基于FPGA的验证系统，用于在边缘侧硬件上测试该框架的性能。在ImageNet-1K数据集上的算法实验表明，与基线DAT相比，我们硬件友好的框架仅有0.2%的精度下降。在Xilinx FPGA上的硬件实验表明，所提出的方法将DRAM访问次数减少到现有DAT加速方法的18%。", "summary": "本文针对可变形注意力Transformer (DAT) 在硬件部署中面临的不规则内存访问问题，提出了一种内存高效且硬件友好的优化框架。该框架结合了神经架构搜索 (NAS) 和创新的切片策略，能够在推理时自动划分输入特征以避免内存冲突，同时不改变原始模型架构。通过联合优化硬件成本和推理精度，该方法在ImageNet-1K数据集上仅导致0.2%的精度损失，并在FPGA上将DRAM访问次数显著降低至现有加速方法的18%，从而有效解决了DAT的部署挑战。", "keywords": "可变形Transformer, 内存高效, 神经架构搜索, 硬件部署, FPGA", "comments": "这篇论文通过引入神经架构搜索和创新的切片策略来优化可变形Transformer的内存效率和硬件部署，具有显著的创新性。它有效解决了DAT在边缘设备上部署的实际挑战，平衡了性能和资源消耗，对于推动计算机视觉模型在实际应用中的落地具有重要意义。"}}
{"id": "2507.11900", "title": "CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos", "authors": ["Wei Sun", "Linhan Cao", "Kang Fu", "Dandan Zhu", "Jun Jia", "Menghan Hu", "Xiongkuo Min", "Guangtao Zhai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      CompressedVQA-HDR won first place in the FR track of the Generalizable HDR & SDR Video Quality Measurement Grand Challenge at IEEE ICME 2025", "url": "http://arxiv.org/abs/2507.11900v1", "summary": "Video compression is a standard procedure applied to all videos to minimize\nstorage and transmission demands while preserving visual quality as much as\npossible. Therefore, evaluating the visual quality of compressed videos is\ncrucial for guiding the practical usage and further development of video\ncompression algorithms. Although numerous compressed video quality assessment\n(VQA) methods have been proposed, they often lack the generalization capability\nneeded to handle the increasing diversity of video types, particularly high\ndynamic range (HDR) content. In this paper, we introduce CompressedVQA-HDR, an\neffective VQA framework designed to address the challenges of HDR video quality\nassessment. Specifically, we adopt the Swin Transformer and SigLip 2 as the\nbackbone networks for the proposed full-reference (FR) and no-reference (NR)\nVQA models, respectively. For the FR model, we compute deep structural and\ntextural similarities between reference and distorted frames using\nintermediate-layer features extracted from the Swin Transformer as its\nquality-aware feature representation. For the NR model, we extract the global\nmean of the final-layer feature maps from SigLip 2 as its quality-aware\nrepresentation. To mitigate the issue of limited HDR training data, we\npre-train the FR model on a large-scale standard dynamic range (SDR) VQA\ndataset and fine-tune it on the HDRSDR-VQA dataset. For the NR model, we employ\nan iterative mixed-dataset training strategy across multiple compressed VQA\ndatasets, followed by fine-tuning on the HDRSDR-VQA dataset. Experimental\nresults show that our models achieve state-of-the-art performance compared to\nexisting FR and NR VQA models. Moreover, CompressedVQA-HDR-FR won first place\nin the FR track of the Generalizable HDR & SDR Video Quality Measurement Grand\nChallenge at IEEE ICME 2025. The code is available at\nhttps://github.com/sunwei925/CompressedVQA-HDR.", "comment": "CompressedVQA-HDR won first place in the FR track of the\n  Generalizable HDR & SDR Video Quality Measurement Grand Challenge at IEEE\n  ICME 2025", "pdf_url": "http://arxiv.org/pdf/2507.11900v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "CompressedVQA-HDR：压缩高动态范围视频的通用全参考和无参考质量评估模型", "tldr": "提出了CompressedVQA-HDR，一个针对压缩高动态范围（HDR）视频的新型视频质量评估（VQA）框架，其全参考（FR）和无参考（NR）模型均达到了最先进的性能，并在IEEE ICME 2025的挑战赛中获得第一名。", "motivation": "视频压缩是减少存储和传输需求同时尽可能保持视觉质量的标准程序，因此评估压缩视频的视觉质量对于指导视频压缩算法的实际应用和进一步发展至关重要。尽管已经提出了许多压缩视频质量评估（VQA）方法，但它们通常缺乏处理日益多样化的视频类型（特别是高动态范围（HDR）内容）所需的泛化能力。", "method": "本文提出了一个名为CompressedVQA-HDR的有效VQA框架，旨在解决HDR视频质量评估的挑战。具体来说，我们分别采用Swin Transformer和SigLip 2作为所提出的全参考（FR）和无参考（NR）VQA模型的骨干网络。对于FR模型，我们使用从Swin Transformer中提取的中间层特征作为其质量感知特征表示，计算参考帧和失真帧之间的深度结构和纹理相似性。为了缓解HDR训练数据有限的问题，我们将FR模型在一个大规模标准动态范围（SDR）VQA数据集上进行预训练，并在HDRSDR-VQA数据集上进行微调。对于NR模型，我们从SigLip 2中提取最终层特征图的全局均值作为其质量感知表示。我们采用了一种跨多个压缩VQA数据集的迭代混合数据集训练策略，随后在HDRSDR-VQA数据集上进行微调。", "result": "实验结果表明，我们的模型与现有FR和NR VQA模型相比，达到了最先进的性能。此外，CompressedVQA-HDR-FR在IEEE ICME 2025的通用HDR和SDR视频质量测量大挑战赛的FR赛道中获得了第一名。", "conclusion": "所提出的CompressedVQA-HDR框架有效解决了HDR视频质量评估的挑战，其全参考和无参考模型均表现出强大的泛化能力和最先进的性能。", "translation": "视频压缩是应用于所有视频的标准程序，旨在最大限度地减少存储和传输需求，同时尽可能保持视觉质量。因此，评估压缩视频的视觉质量对于指导视频压缩算法的实际应用和进一步发展至关重要。尽管已经提出了许多压缩视频质量评估（VQA）方法，但它们通常缺乏处理日益多样化的视频类型（特别是高动态范围（HDR）内容）所需的泛化能力。在本文中，我们引入了CompressedVQA-HDR，一个旨在解决HDR视频质量评估挑战的有效VQA框架。具体来说，我们分别采用Swin Transformer和SigLip 2作为所提出的全参考（FR）和无参考（NR）VQA模型的骨干网络。对于FR模型，我们使用从Swin Transformer中提取的中间层特征作为其质量感知特征表示，计算参考帧和失真帧之间的深度结构和纹理相似性。对于NR模型，我们从SigLip 2中提取最终层特征图的全局均值作为其质量感知表示。为了缓解HDR训练数据有限的问题，我们将FR模型在一个大规模标准动态范围（SDR）VQA数据集上进行预训练，并在HDRSDR-VQA数据集上进行微调。对于NR模型，我们采用了一种跨多个压缩VQA数据集的迭代混合数据集训练策略，随后在HDRSDR-VQA数据集上进行微调。实验结果表明，我们的模型与现有FR和NR VQA模型相比，达到了最先进的性能。此外，CompressedVQA-HDR-FR在IEEE ICME 2025的通用HDR和SDR视频质量测量大挑战赛的FR赛道中获得了第一名。代码可在https://github.com/sunwei925/CompressedVQA-HDR获取。", "summary": "CompressedVQA-HDR是一个针对压缩HDR视频质量评估的有效框架。它采用Swin Transformer和SigLip 2作为全参考（FR）和无参考（NR）模型的骨干网络，并通过特定的特征提取和训练策略（包括跨SDR和HDR数据集的预训练和微调）解决了HDR训练数据有限的问题。实验结果表明，该模型在FR和NR VQA方面均达到了最先进的性能，其FR模型还在IEEE ICME 2025的挑战赛中获得第一名，证明了其在HDR视频质量评估中的通用性和有效性。", "keywords": "视频质量评估, 高动态范围, 全参考, 无参考, 深度学习", "comments": "该论文解决了HDR内容视频质量评估中存在的关键泛化能力不足问题。其创新之处在于将成熟的视觉Transformer（Swin、SigLip 2）作为骨干网络，并结合了特定的预训练和在混合数据集上的微调策略，尤其是在处理有限的HDR数据方面。在大型挑战赛中获得第一名进一步验证了其在实际应用中的有效性。"}}
{"id": "2507.12163", "title": "Integrated Switched Capacitor Array and Synchronous Charge Extraction with Adaptive Hybrid MPPT for Piezoelectric Harvesters", "authors": ["Pramit Karmakar", "Siddharth B", "Chinmay Murlidhar Kadnur Rao"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12163v1", "summary": "Energy Harvesting technologies will play a fundamental role in the\ndevelopment of the next generation of electronic systems as well as in\nadvancing the development of sustainable infrastructure. One of the critical\nchallenges in EH is utilizing ambient vibrations to harvest energy. Piezo\nEnergy Harvesting, which uses ambient vibrations, is a promising technology in\nenergy harvesting and a self-powered technology. However, it suffers from\nseveral practical challenges. Some of these challenges include narrow\nbandwidth, non-linearity, and impedance mismatch, among others. This paper\npresents a novel, simulated Piezo Energy Harvesting (PEH) framework that\naddresses some of these challenges. The proposed model is designed to be\nadaptive and effective against the inherent non-linearity of PEH. This detailed\nmodel covers a non-linear piezo, Synchronous Electric Charge Extraction (SECE),\nHybrid Maximum Power Point Tracking (MPPT) and a Switched Capacitor Array\n(SCA). The SECE extracts the maximum charge accumulated on the piezo every time\nthe piezo reaches the mechanical extremum. The Bouc-Wen model has been used to\nestablish nonlinearity in the system. The hybrid MPPT exhibits significant\nimprovement over conventional P&O, while the SCA-tuned system demonstrates\nresilience against variable frequency input.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12163v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "用于压电能量收集器的集成开关电容阵列和自适应混合MPPT同步电荷提取", "tldr": "本文提出了一个集成了开关电容阵列和自适应混合MPPT同步电荷提取的压电能量收集框架，以解决压电能量收集器中的非线性、窄带宽和阻抗失配等挑战。", "motivation": "能量收集技术在下一代电子系统和可持续基础设施发展中扮演关键角色。利用环境振动进行能量收集面临挑战，尤其是压电能量收集（PEH）存在窄带宽、非线性和阻抗失配等实际问题。", "method": "本文提出了一个新颖的、模拟的压电能量收集（PEH）框架，旨在解决PEH固有的非线性问题。该详细模型包括非线性压电元件、同步电荷提取（SECE）、混合最大功率点跟踪（MPPT）和一个开关电容阵列（SCA）。SECE在压电元件每次达到机械极值时提取最大累积电荷，并使用Bouc-Wen模型建立系统非线性。", "result": "混合MPPT比传统P&O表现出显著改进，而SCA调谐系统则展示了对可变频率输入的弹性。", "conclusion": "该研究提出的集成开关电容阵列和自适应混合MPPT同步电荷提取框架，有效解决了压电能量收集器中存在的非线性、窄带宽和阻抗失配等关键挑战，提升了能量收集效率和系统鲁棒性。", "translation": "能量收集技术将在下一代电子系统以及可持续基础设施的发展中发挥基础性作用。能量收集中的一个关键挑战是利用环境振动来收集能量。压电能量收集利用环境振动，是一种很有前景的能量收集技术和自供电技术。然而，它面临着一些实际挑战。其中一些挑战包括窄带宽、非线性和阻抗失配等。本文提出了一个新颖的、模拟的压电能量收集（PEH）框架，解决了其中一些挑战。所提出的模型被设计为适应性强，并能有效应对PEH固有的非线性。这个详细模型涵盖了非线性压电元件、同步电荷提取（SECE）、混合最大功率点跟踪（MPPT）和一个开关电容阵列（SCA）。SECE在压电元件每次达到机械极值时提取压电元件上累积的最大电荷。Bouc-Wen模型已被用于建立系统中的非线性。混合MPPT比传统的P&O表现出显著改进，而SCA调谐系统则展示了对可变频率输入的弹性。", "summary": "本文提出了一个新颖的模拟压电能量收集（PEH）框架，旨在解决PEH面临的窄带宽、非线性和阻抗失配等挑战。该框架集成了非线性压电模型、同步电荷提取（SECE）、混合最大功率点跟踪（MPPT）和开关电容阵列（SCA）。研究结果表明，所提出的混合MPPT相比传统方法有显著改进，并且SCA调谐系统对变频输入表现出良好的适应性。", "keywords": "压电能量收集, MPPT, 开关电容阵列, 同步电荷提取, 非线性", "comments": "该论文提出了一种集成的压电能量收集框架，通过结合SECE、混合MPPT和SCA，有效地解决了压电能量收集器面临的非线性、窄带宽和变频输入等核心挑战，具有较强的创新性。其提出的自适应混合MPPT和SCA在提升系统效率和鲁棒性方面表现出色。"}}
{"id": "2507.12453", "title": "Cost-aware Stopping for Bayesian Optimization", "authors": ["Qian Xie", "Linda Cai", "Alexander Terenin", "Peter I. Frazier", "Ziv Scully"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12453v1", "summary": "In automated machine learning, scientific discovery, and other applications\nof Bayesian optimization, deciding when to stop evaluating expensive black-box\nfunctions is an important practical consideration. While several adaptive\nstopping rules have been proposed, in the cost-aware setting they lack\nguarantees ensuring they stop before incurring excessive function evaluation\ncosts. We propose a cost-aware stopping rule for Bayesian optimization that\nadapts to varying evaluation costs and is free of heuristic tuning. Our rule is\ngrounded in a theoretical connection to state-of-the-art cost-aware acquisition\nfunctions, namely the Pandora's Box Gittins Index (PBGI) and log expected\nimprovement per cost. We prove a theoretical guarantee bounding the expected\ncumulative evaluation cost incurred by our stopping rule when paired with these\ntwo acquisition functions. In experiments on synthetic and empirical tasks,\nincluding hyperparameter optimization and neural architecture size search, we\nshow that combining our stopping rule with the PBGI acquisition function\nconsistently matches or outperforms other acquisition-function--stopping-rule\npairs in terms of cost-adjusted simple regret, a metric capturing trade-offs\nbetween solution quality and cumulative evaluation cost.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12453v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "贝叶斯优化中的成本感知停止策略", "tldr": "本文提出了一种新的成本感知停止规则，用于贝叶斯优化，该规则适应不同的评估成本，并提供理论保证，在实验中表现优异。", "motivation": "在自动化机器学习和科学发现等贝叶斯优化应用中，决定何时停止评估昂贵的黑盒函数是一个重要的实际考虑。现有的自适应停止规则在成本感知设置中缺乏保证，无法确保在产生过高函数评估成本之前停止。", "method": "我们提出了一种用于贝叶斯优化的成本感知停止规则，该规则能够适应不同的评估成本，并且无需启发式调优。我们的规则基于与最先进的成本感知采集函数（即潘多拉魔盒吉丁斯指数（PBGI）和每成本对数预期改进）的理论联系。", "result": "在合成任务和经验任务（包括超参数优化和神经网络架构大小搜索）的实验中，我们表明，将我们的停止规则与PBGI采集函数结合使用，在成本调整的简单遗憾（一个捕获解决方案质量和累积评估成本之间权衡的指标）方面，始终与或优于其他采集函数-停止规则对。", "conclusion": "本文提出的成本感知停止规则在贝叶斯优化中是有效的，特别是在与PBGI采集函数结合使用时，能够更好地平衡解决方案质量和评估成本。", "translation": "在自动化机器学习、科学发现和贝叶斯优化的其他应用中，决定何时停止评估昂贵的黑盒函数是一个重要的实际考虑。虽然已经提出了几种自适应停止规则，但在成本感知设置中，它们缺乏保证，无法确保在产生过高函数评估成本之前停止。我们提出了一种用于贝叶斯优化的成本感知停止规则，该规则能够适应不同的评估成本，并且无需启发式调优。我们的规则基于与最先进的成本感知采集函数（即潘多拉魔盒吉丁斯指数（PBGI）和每成本对数预期改进）的理论联系。我们证明了当我们的停止规则与这两种采集函数配对时，其预期的累积评估成本受到限制。在合成任务和经验任务（包括超参数优化和神经网络架构大小搜索）的实验中，我们表明，将我们的停止规则与PBGI采集函数结合使用，在成本调整的简单遗憾（一个捕获解决方案质量和累积评估成本之间权衡的指标）方面，始终与或优于其他采集函数-停止规则对。", "summary": "本文提出了一种新的贝叶斯优化成本感知停止规则，旨在解决现有方法在控制昂贵函数评估成本方面的不足。该规则基于与潘多拉魔盒吉丁斯指数（PBGI）和每成本对数预期改进等先进采集函数的理论联系，并提供了预期累积评估成本的理论上限保证。实验结果表明，该停止规则与PBGI结合使用时，在平衡解决方案质量和评估成本方面，表现优于或媲美其他方法。", "keywords": "贝叶斯优化, 停止规则, 成本感知, 黑盒优化, PBGI", "comments": "这篇论文的创新点在于提出了一个有理论保证的成本感知停止规则，解决了贝叶斯优化中实际应用的关键问题，即如何有效控制昂贵函数评估的成本。其与现有先进采集函数的结合以及在各种任务上的实验验证，增强了其实用性和重要性。"}}
{"id": "2507.11972", "title": "Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker", "authors": ["Yuhong Zhang", "Jialu Li", "Shilai Yang", "Yuchen Xu", "Gert Cauwenberghs", "Tzyy-Ping Jung"], "categories": ["cs.CL", "q-bio.NC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11972v1", "summary": "Reading comprehension is a fundamental skill in human cognitive development.\nWith the advancement of Large Language Models (LLMs), there is a growing need\nto compare how humans and LLMs understand language across different contexts\nand apply this understanding to functional tasks such as inference, emotion\ninterpretation, and information retrieval. Our previous work used LLMs and\nhuman biomarkers to study the reading comprehension process. The results showed\nthat the biomarkers corresponding to words with high and low relevance to the\ninference target, as labeled by the LLMs, exhibited distinct patterns,\nparticularly when validated using eye-tracking data. However, focusing solely\non individual words limited the depth of understanding, which made the\nconclusions somewhat simplistic despite their potential significance. This\nstudy used an LLM-based AI agent to group words from a reading passage into\nnodes and edges, forming a graph-based text representation based on semantic\nmeaning and question-oriented prompts. We then compare the distribution of eye\nfixations on important nodes and edges. Our findings indicate that LLMs exhibit\nhigh consistency in language understanding at the level of graph topological\nstructure. These results build on our previous findings and offer insights into\neffective human-AI co-learning strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11972v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "使用大型语言模型和眼动追踪生物标记的阅读理解分析图表示", "tldr": "本研究利用大型语言模型（LLMs）将文本构建成图表示，并结合眼动追踪生物标记分析阅读理解。研究发现LLMs在图拓扑结构层面的语言理解与人类表现出高度一致性，为有效的人机协同学习策略提供了见解。", "motivation": "随着大型语言模型（LLMs）的进步，有必要比较人类和LLMs如何理解语言。之前的研究虽然发现LLMs标记的词汇相关性与眼动追踪生物标记存在不同模式，但仅关注单个词汇限制了理解深度，导致结论过于简化。本研究旨在通过图表示法获得对阅读理解更深层次的理解，以克服这一局限。", "method": "本研究使用基于LLM的AI智能体，根据语义意义和面向问题的提示，将阅读段落中的词汇分组为节点和边，从而形成图表示的文本结构。随后，比较了人类在重要节点和边上的眼动注视分布。", "result": "研究发现，大型语言模型在图拓扑结构层面的语言理解表现出高度一致性。", "conclusion": "这些结果建立在以往发现的基础上，并为有效的人机协同学习策略提供了见解。", "translation": "阅读理解是人类认知发展中的一项基本技能。随着大型语言模型（LLMs）的进步，越来越需要比较人类和LLMs如何在不同语境中理解语言，并将这种理解应用于推理、情感解释和信息检索等功能性任务。我们之前的工作利用LLMs和人类生物标记来研究阅读理解过程。结果显示，LLMs标记的与推理目标高度相关和低度相关的词汇所对应的生物标记表现出不同的模式，尤其是在使用眼动追踪数据验证时。然而，仅仅关注单个词汇限制了理解的深度，尽管其具有潜在意义，但结论有些简单。本研究使用基于LLM的AI智能体将阅读段落中的词汇分组为节点和边，基于语义意义和面向问题的提示形成图表示。然后，我们比较了重要节点和边上的眼动注视分布。我们的发现表明，LLMs在图拓扑结构层面的语言理解表现出高度一致性。这些结果建立在我们之前的发现之上，并为有效的人机协同学习策略提供了见解。", "summary": "本研究通过结合大型语言模型（LLMs）和眼动追踪数据，深入分析阅读理解。为克服以往仅关注单个词汇的局限，研究提出了一种创新方法：利用LLM驱动的AI智能体将文本转化为基于语义和问题导向的图表示（包含节点和边）。通过比较人类在这些图结构上眼动注视的分布，研究发现LLMs在图拓扑结构层面的语言理解表现出高度一致性。这些发现不仅深化了对阅读理解过程的理解，也为未来人机协同学习策略的开发提供了宝贵见解。", "keywords": "阅读理解, 大型语言模型, 眼动追踪, 图表示, 人机协同学习", "comments": "这篇论文提出了一种创新的方法来分析阅读理解，通过将文本从单个词汇层面提升到图表示层面，并巧妙地利用LLM进行语义结构化。眼动追踪数据的引入为人类行为提供了可靠的生物标记，增强了研究的验证性。发现LLMs在结构层面与人类语言理解的高度一致性，对于开发更有效的人机协作系统具有重要意义，尤其是在教育和信息处理领域。它成功解决了以往研究的局限性，提供了更深层次、更全面的理解。"}}
{"id": "2507.12007", "title": "Predictable Drifts in Collective Cultural Attention: Evidence from Nation-Level Library Takeout Data", "authors": ["Anders Weile Larsen", "Vedran Sekara"], "categories": ["cs.SI", "cs.CY"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12007v1", "summary": "Predicting changes in consumer attention for cultural products, such as\nbooks, movies, and songs, is notoriously difficult. Past research on predicting\nthe popularity of individual products suggests the existence of intrinsic\nprediction limits. However, little is known about the limits for predicting\ncollective attention across cultural products. Here, we analyze four years of\nnationwide library loan data for approximately 2 million individuals,\ncomprising over 100 million loans of more than 660,000 unique books. We find\nthat culture, as measured by popularity distributions of loaned books, drifts\ncontinually from month to month at a near-constant rate, leading to a growing\ndivergence over time, and that drifts vary between different book genres. By\nlinking book loans to registry data, we investigate the influence of age, sex,\neducational level, and geographical area on cultural drift, finding\nheterogeneous effects from the different demographic groups. Our findings have\nimportant implications for market forecasting and developing robust recommender\nsystems, highlighting the need to account for specific drift dynamics for\ndifferent types of items and demographic groups.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12007v1", "cate": "cs.SI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "集体文化注意力的可预测漂移：来自国家级图书馆外借数据的证据", "tldr": "通过分析全国图书馆借阅数据，研究发现集体文化注意力持续漂移，且漂移速度随时间增长而发散，并受书籍类型和人口统计学因素影响。这对于市场预测和推荐系统具有重要意义。", "motivation": "预测文化产品（如书籍、电影、歌曲）的消费者注意力变化非常困难。过去对个体产品流行度的研究表明存在内在的预测限制，但对文化产品集体注意力的预测限制知之甚少。", "method": "研究分析了四年间约200万个人的全国图书馆借阅数据，包括超过1亿次借阅和66万多本独特的书籍。通过将书籍借阅数据与登记数据关联，调查了年龄、性别、教育水平和地理区域对文化漂移的影响。", "result": "研究发现，以借阅书籍流行度分布衡量的文化，每月以接近恒定的速度持续漂移，导致随时间推移而不断增长的差异。漂移在不同书籍类型之间存在差异。通过关联人口统计数据，发现年龄、性别、教育水平和地理区域等不同人口群体对文化漂移有异质性影响。", "conclusion": "研究结果对市场预测和开发健壮的推荐系统具有重要意义，强调需要考虑不同类型项目和人口群体的特定漂移动态。", "translation": "预测文化产品（如书籍、电影和歌曲）的消费者注意力变化是出了名的困难。过去关于预测个体产品流行度的研究表明存在内在的预测限制。然而，对于预测跨文化产品的集体注意力的限制知之甚少。在此，我们分析了四年间约200万个人的全国图书馆借阅数据，包括超过1亿次借阅和66万多本独特的书籍。我们发现，以借阅书籍流行度分布衡量的文化，每月以接近恒定的速度持续漂移，导致随时间推移而不断增长的差异，并且漂移在不同书籍类型之间存在差异。通过将书籍借阅与登记数据关联，我们调查了年龄、性别、教育水平和地理区域对文化漂移的影响，发现不同人口群体具有异质性效应。我们的发现对市场预测和开发健壮的推荐系统具有重要意义，强调需要考虑不同类型项目和人口群体的特定漂移动态。", "summary": "本研究分析了大规模全国图书馆借阅数据，揭示了集体文化注意力存在可预测的持续漂移现象。研究发现，文化注意力每月以恒定速度漂移，导致随时间推移而发散，且漂移模式因书籍类型和人口统计学特征（如年龄、性别、教育水平、地理区域）而异。这些发现为市场预测和推荐系统设计提供了重要启示，强调了考虑特定漂移动态的重要性。", "keywords": "文化注意力, 集体漂移, 图书馆数据, 预测, 推荐系统", "comments": "该论文通过利用大规模的真实世界图书馆借阅数据，创新性地研究了集体文化注意力的动态漂移。其重要性在于揭示了文化注意力的可预测性及其受多种因素影响的异质性，这对于市场趋势预测和个性化推荐系统优化具有直接的应用价值。数据的规模和对人口统计学因素的考量是其亮点。"}}
{"id": "2507.08677", "title": "Qualitative Assessment of Low Power Wide Area Network Protocols and their Security Aspect", "authors": ["Wesley dos Reis Bezerra", "Lais Machado Bezerra", "Carlos Becker Westphall"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08677v2", "summary": "There are currently many communication options in the Internet of Things,\neven in particular areas such as constrained and battery-powered devices, such\nas Low Power Wide Area Networks. Understanding the differences and\ncharacteristics of each option is a challenge, even for professionals and\nresearchers in the field. To meet this need, this work analyses the qualitative\ncharacteristics of Low Power Wide Area Network protocols and the challenges and\nopportunities of using constrained devices for sparse networks based on\nlong-life batteries. For this study, a bibliographic survey of the literature\nwas carried out as an analysis of three protocols (LoRaWAN, NB-IoT, and\nSigfox), and a detailing of the first one. As a result, there is a discussion\nabout the chosen network protocol and its use in IoT solutions with sparse\nsensors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08677v2", "cate": "cs.NI", "date": "2025-07-11", "updated": "2025-07-15", "AI": {"title_translation": "低功耗广域网协议及其安全方面的定性评估", "tldr": "本文对低功耗广域网协议（LoRaWAN、NB-IoT、Sigfox）的定性特征及其在受限设备中使用的挑战与机遇进行了文献综述和分析。", "motivation": "物联网中通信选项众多，特别是受限和电池供电设备（如低功耗广域网），理解它们的差异和特性对专业人士和研究人员来说是一个挑战，因此需要对这些协议进行分析。", "method": "进行了一项文献调查，分析了三种低功耗广域网协议（LoRaWAN、NB-IoT和Sigfox），并对LoRaWAN进行了详细阐述。", "result": "讨论了所选网络协议及其在稀疏传感器物联网解决方案中的应用。", "conclusion": "Not mentioned in abstract", "translation": "物联网中目前有许多通信选项，即使在受限和电池供电设备等特定领域也是如此，例如低功耗广域网。理解每种选项的差异和特性是一项挑战，即使对于该领域的专业人士和研究人员也是如此。为了满足这一需求，本工作分析了低功耗广域网协议的定性特征，以及在基于长寿命电池的稀疏网络中使用受限设备的挑战和机遇。本研究通过文献调研的方式，分析了三种协议（LoRaWAN、NB-IoT和Sigfox），并详细阐述了第一种协议。结果是对所选网络协议及其在稀疏传感器物联网解决方案中的使用进行了讨论。", "summary": "本文旨在解决物联网中低功耗广域网（LPWAN）协议选择的复杂性问题。通过对LoRaWAN、NB-IoT和Sigfox三种主要LPWAN协议进行文献综述和定性分析，并详细介绍了LoRaWAN，研究探讨了这些协议在受限设备和稀疏网络中的应用挑战与机遇，最终讨论了所选协议在物联网解决方案中的适用性。", "keywords": "低功耗广域网, 物联网, LoRaWAN, NB-IoT, Sigfox, 定性评估", "comments": "这篇论文通过对现有LPWAN协议的定性评估和文献综述，为理解这些复杂协议提供了有价值的见解，尤其关注了它们在受限IoT设备中的应用。其贡献在于对LoRaWAN等特定协议的深入探讨，有助于研究人员和专业人士更好地选择和部署适用于稀疏传感器网络的解决方案。"}}
{"id": "2507.12010", "title": "Enhancing Situational Awareness in ISAC Networks via Drone Swarms: A Real-World Channel Sounding Data Set", "authors": ["Julia Beuster", "Carsten Andrich", "Sebastian Giehl", "Marc Miranda", "Lorenz Mohr", "Dieter Novotny", "Tom Kaufmann", "Christian Schneider", "Reiner Thomä"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12010v1", "summary": "With the upcoming capabilities of integrated sensing and communication (ISAC)\nand the incorporation of user equipment (UE) like unmanned aerial vehicles\n(UAVs) in 6G mobile networks, there is a significant opportunity to enhance\nsituational awareness through multi-static radar sensing in meshed ISAC\nnetworks. This paper presents a real-world channel sounding data set acquired\nusing a testbed with synchronized, distributed ground-based sensor nodes and\nflying sensor nodes within a swarm of up to four drones. The conducted\nmeasurement campaign is designed to sense the bi-static reflectivity of objects\nsuch as parking cars, vertical take-off and landing (VTOL) aircraft, and small\ndrones in multi-path environments. We detail the rationale behind the selection\nof the included scenarios and the configuration of the participating nodesand\npresent exemplary results to demonstrate the potential of using collaborating\ndrone swarms for multi-static radar tracking and localization in air-to-air\n(A2A) and air-to-ground (A2G) scenarios. The data sets are publicly available\nto support the development and validation of future ISAC algorithms in\nreal-world environments rather than relying solely on simulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12010v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "通过无人机蜂群增强ISAC网络态势感知：一个真实世界信道探测数据集", "tldr": "该论文提供了一个使用无人机蜂群在ISAC网络中进行多基地雷达传感的真实世界信道探测数据集，旨在增强态势感知，并验证了其在空对空和空对地场景中跟踪和定位的潜力。", "motivation": "随着集成传感与通信（ISAC）能力的到来以及无人机（UAV）等用户设备在6G移动网络中的整合，通过网状ISAC网络中的多基地雷达传感来增强态势感知存在巨大机遇。现有的研究可能主要依赖仿真，缺乏真实世界数据。", "method": "本研究提出了一个真实世界信道探测数据集，该数据集通过一个测试平台获得，该平台包含同步的分布式地面传感器节点和多达四个无人机蜂群中的飞行传感器节点。测量活动旨在探测多径环境中停车、垂直起降（VTOL）飞机和小型无人机等物体的双基地反射率。论文详细说明了场景选择和节点配置的原理。", "result": "论文展示了示例结果，以证明利用协作无人机蜂群在空对空（A2A）和空对地（A2G）场景中进行多基地雷达跟踪和定位的潜力。所收集的数据集已公开，以支持未来ISAC算法在真实世界环境中的开发和验证，而不是仅仅依赖仿真。", "conclusion": "通过利用无人机蜂群和提供的真实世界信道探测数据集，可以有效增强ISAC网络中的态势感知能力，并支持ISAC算法在实际环境中的开发和验证。", "translation": "随着集成传感与通信（ISAC）能力的到来以及无人机（UAV）等用户设备在6G移动网络中的整合，通过网状ISAC网络中的多基地雷达传感来增强态势感知存在巨大机遇。本文提出了一个真实世界信道探测数据集，该数据集通过一个测试平台获得，该平台包含同步的分布式地面传感器节点和多达四个无人机蜂群中的飞行传感器节点。所进行的测量活动旨在探测多径环境中停车、垂直起降（VTOL）飞机和小型无人机等物体的双基地反射率。我们详细说明了所包含场景选择的原理和参与节点的配置，并展示了示例结果，以证明利用协作无人机蜂群在空对空（A2A）和空对地（A2G）场景中进行多基地雷达跟踪和定位的潜力。该数据集已公开，以支持未来ISAC算法在真实世界环境中的开发和验证，而不是仅仅依赖仿真。", "summary": "本论文关注于通过无人机蜂群在集成传感与通信（ISAC）网络中增强态势感知。研究通过一个包含地面和飞行传感器节点的测试平台，收集了一个真实的信道探测数据集，用于测量多径环境中各种物体的双基地反射率。论文展示了该数据在空对空和空对地场景中，利用无人机蜂群进行多基地雷达跟踪和定位的潜力，并公开了数据集以促进未来ISAC算法的开发和验证。", "keywords": "ISAC网络, 无人机蜂群, 信道探测, 态势感知, 多基地雷达", "comments": "该论文的创新之处在于提供了首个利用无人机蜂群进行ISAC网络中态势感知的真实世界信道探测数据集。这对于推动ISAC技术从仿真走向实际应用具有重要意义，尤其是在6G网络背景下。数据集的公开性将极大地促进相关算法的开发和验证。其局限性可能在于测试场景的规模和多样性，以及蜂群规模的限制。"}}
{"id": "2507.12292", "title": "Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation", "authors": ["Antonio Finocchiaro", "Giovanni Maria Farinella", "Antonino Furnari"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages, 4 figures, In International Conference on Image Analysis and Processing", "url": "http://arxiv.org/abs/2507.12292v1", "summary": "Calisthenics skill classification is the computer vision task of inferring\nthe skill performed by an athlete from images, enabling automatic performance\nassessment and personalized analytics. Traditional methods for calisthenics\nskill recognition are based on pose estimation methods to determine the\nposition of skeletal data from images, which is later fed to a classification\nalgorithm to infer the performed skill. Despite the progress in human pose\nestimation algorithms, they still involve high computational costs, long\ninference times, and complex setups, which limit the applicability of such\napproaches in real-time applications or mobile devices. This work proposes a\ndirect approach to calisthenics skill recognition, which leverages depth\nestimation and athlete patch retrieval to avoid the computationally expensive\nhuman pose estimation module. Using Depth Anything V2 for depth estimation and\nYOLOv10 for athlete localization, we segment the subject from the background\nrather than relying on traditional pose estimation techniques. This strategy\nincreases efficiency, reduces inference time, and improves classification\naccuracy. Our approach significantly outperforms skeleton-based methods,\nachieving 38.3x faster inference with RGB image patches and improved\nclassification accuracy with depth patches (0.837 vs. 0.815). Beyond these\nperformance gains, the modular design of our pipeline allows for flexible\nreplacement of components, enabling future enhancements and adaptation to\nreal-world applications.", "comment": "13 pages, 4 figures, In International Conference on Image Analysis\n  and Processing", "pdf_url": "http://arxiv.org/pdf/2507.12292v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "通过前景实例选择和深度估计实现高效的健美操技能分类", "tldr": "该论文提出了一种新的健美操技能分类方法，通过深度估计和运动员前景补丁检索来避免计算成本高昂的姿态估计，相比传统基于骨骼的方法，实现了显著更快的推理速度和更高的准确性。", "motivation": "传统的健美操技能识别方法依赖于人体姿态估计，但其计算成本高、推理时间长且设置复杂，限制了它们在实时应用或移动设备中的适用性。", "method": "本文提出了一种直接的健美操技能识别方法。该方法利用Depth Anything V2进行深度估计，并使用YOLOv10进行运动员定位，从而将前景主体从背景中分割出来，以避免使用计算成本高昂的人体姿态估计模块。", "result": "该方法显著优于基于骨骼的方法，使用RGB图像补丁实现了38.3倍的推理速度提升，并且使用深度补丁提高了分类精度（0.837 对比 0.815）。", "conclusion": "通过直接利用深度和前景信息，该方法为健美操技能分类提供了一个更高效和准确的解决方案，优于传统的基于姿态估计的方法。其模块化设计也利于未来的增强和实际应用的适应性。", "translation": "健美操技能分类是一项计算机视觉任务，旨在从图像中推断运动员所执行的技能，从而实现自动性能评估和个性化分析。传统的健美操技能识别方法基于姿态估计方法，从图像中确定骨骼数据的位置，然后将其输入分类算法以推断所执行的技能。尽管人体姿态估计算法取得了进展，但它们仍然涉及高计算成本、长的推理时间和复杂的设置，这限制了此类方法在实时应用或移动设备中的适用性。这项工作提出了一种直接的健美操技能识别方法，该方法利用深度估计和运动员补丁检索来避免计算成本高昂的人体姿态估计模块。我们使用Depth Anything V2进行深度估计，并使用YOLOv10进行运动员定位，从而将主体从背景中分割出来，而不是依赖传统的姿态估计技术。这种策略提高了效率，缩短了推理时间，并提高了分类精度。我们的方法显著优于基于骨骼的方法，使用RGB图像补丁实现了38.3倍的推理速度提升，并使用深度补丁提高了分类精度（0.837 对比 0.815）。除了这些性能提升之外，我们管道的模块化设计允许灵活更换组件，从而实现未来的增强和对实际应用的适应。", "summary": "本文介绍了一种高效的计算机视觉方法，用于健美操技能分类，该方法避开了传统计算密集型的人体姿态估计。所提出的方法利用Depth Anything V2进行深度估计和YOLOv10进行运动员定位，以分割前景运动员。与基于骨骼的技术相比，这种直接方法显著缩短了推理时间（使用RGB补丁快38.3倍）并提高了分类精度（使用深度补丁为0.837 对比 0.815），由于其效率和模块化设计，为实时和移动应用提供了更实用的解决方案。", "keywords": "健美操技能分类, 深度估计, 前景实例选择, YOLOv10, 高效计算机视觉", "comments": "该创新的核心在于完全绕过了计算成本高昂的人体姿态估计，直接利用深度估计和前景实例选择。这种直接方法在速度和准确性方面提供了显著的性能提升，使其非常适用于实时和资源受限的环境，如移动设备。模块化设计也是一个亮点，确保了适应性和未来的可扩展性。"}}
{"id": "2507.10678", "title": "A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks", "authors": ["Cutter Dawes", "Simon Segert", "Kamesh Krishnamurthy", "Jonathan D. Cohen"], "categories": ["cs.LG", "cs.AI", "cs.NE", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      22 pages, 6 figures; typos corrected", "url": "http://arxiv.org/abs/2507.10678v2", "summary": "A major challenge in the use of neural networks both for modeling human\ncognitive function and for artificial intelligence is the design of systems\nwith the capacity to efficiently learn functions that support radical\ngeneralization. At the roots of this is the capacity to discover and implement\nsymmetry functions. In this paper, we investigate a paradigmatic example of\nradical generalization through the use of symmetry: base addition. We present a\ngroup theoretic analysis of base addition, a fundamental and defining\ncharacteristic of which is the carry function -- the transfer of the remainder,\nwhen a sum exceeds the base modulus, to the next significant place. Our\nanalysis exposes a range of alternative carry functions for a given base, and\nwe introduce quantitative measures to characterize these. We then exploit\ndifferences in carry functions to probe the inductive biases of neural networks\nin symmetry learning, by training neural networks to carry out base addition\nusing different carries, and comparing efficacy and rate of learning as a\nfunction of their structure. We find that even simple neural networks can\nachieve radical generalization with the right input format and carry function,\nand that learnability is closely correlated with carry function structure. We\nthen discuss the relevance this has for cognitive science and machine learning.", "comment": "22 pages, 6 figures; typos corrected", "pdf_url": "http://arxiv.org/pdf/2507.10678v2", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "基于基数加法对称性的群论分析及其神经网络可学习性", "tldr": "本文通过群论分析基数加法中的对称性，并探究神经网络在不同进位函数下的学习能力，发现正确的输入格式和进位函数能使简单网络实现激进泛化，且可学习性与进位函数结构密切相关。", "motivation": "神经网络在建模人类认知功能和人工智能应用中面临的一个主要挑战是设计能够有效学习支持激进泛化功能的系统，其核心在于发现和实现对称函数。本文旨在通过基数加法这一典型例子来探究激进泛化和对称性学习。", "method": "研究通过群论分析了基数加法，揭示了给定基数下的多种替代进位函数，并引入量化指标来表征它们。然后，通过训练神经网络使用不同的进位函数进行基数加法，并比较其学习效率和速率与结构的关系，来探究神经网络在对称性学习中的归纳偏置。", "result": "研究发现，即使是简单的神经网络，在正确的输入格式和进位函数下也能实现激进泛化，并且学习能力与进位函数的结构密切相关。", "conclusion": "神经网络学习能力与进位函数结构密切相关，这对于认知科学和机器学习领域具有重要意义。", "translation": "神经网络在建模人类认知功能和人工智能中面临的一个主要挑战是设计能够有效学习支持激进泛化功能的系统。其核心在于发现和实现对称函数的能力。本文通过利用对称性实现激进泛化的一个典型例子——基数加法——进行研究。我们对基数加法进行了群论分析，其一个基本且决定性的特征是进位函数——当和超过基数模时，将余数转移到下一个有效位。我们的分析揭示了给定基数下的一系列替代进位函数，并且我们引入了量化度量来表征这些函数。然后，我们通过训练神经网络使用不同的进位函数执行基数加法，并比较其学习效率和速率与结构的关系，从而利用进位函数的差异来探究神经网络在对称性学习中的归纳偏置。我们发现，即使是简单的神经网络，在正确的输入格式和进位函数下也能实现激进泛化，并且学习能力与进位函数结构密切相关。随后，我们讨论了这与认知科学和机器学习的相关性。", "summary": "本文通过对基数加法进行群论分析，揭示了其内在对称性及多种进位函数。研究利用这些进位函数的差异，训练神经网络执行基数加法，以探究其在对称性学习中的归纳偏置。结果表明，简单神经网络在合适的输入格式和进位函数下，能够实现激进泛化，且学习能力与进位函数结构紧密相关。该发现对认知科学和机器学习领域具有重要意义。", "keywords": "激进泛化, 神经网络, 基数加法, 对称性, 进位函数", "comments": "本文通过将抽象的激进泛化问题具体化为基数加法中的对称性学习，提供了一个新颖的研究视角。其创新点在于结合群论分析来量化和表征不同的进位函数，并系统地探究了这些函数对神经网络学习能力的影响。研究结果强调了输入表示和内在结构（如进位函数）对神经网络泛化能力的关键作用，为设计更高效、更具泛化能力的AI系统提供了理论洞察。该工作对理解神经网络如何学习和泛化对称性具有重要意义。"}}
{"id": "2507.10578", "title": "When and Where do Data Poisons Attack Textual Inversion?", "authors": ["Jeremy Styborski", "Mingzhi Lyu", "Jiayou Lu", "Nupur Kapur", "Adams Kong"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.10578v2", "summary": "Poisoning attacks pose significant challenges to the robustness of diffusion\nmodels (DMs). In this paper, we systematically analyze when and where poisoning\nattacks textual inversion (TI), a widely used personalization technique for\nDMs. We first introduce Semantic Sensitivity Maps, a novel method for\nvisualizing the influence of poisoning on text embeddings. Second, we identify\nand experimentally verify that DMs exhibit non-uniform learning behavior across\ntimesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias\nand inject adversarial signals predominantly at lower timesteps. Lastly, we\nobserve that adversarial signals distract learning away from relevant concept\nregions within training data, corrupting the TI process. Based on these\ninsights, we propose Safe-Zone Training (SZT), a novel defense mechanism\ncomprised of 3 key components: (1) JPEG compression to weaken high-frequency\npoison signals, (2) restriction to high timesteps during TI training to avoid\nadversarial signals at lower timesteps, and (3) loss masking to constrain\nlearning to relevant regions. Extensive experiments across multiple poisoning\nmethods demonstrate that SZT greatly enhances the robustness of TI against all\npoisoning attacks, improving generative quality beyond prior published\ndefenses. Code: www.github.com/JStyborski/Diff_Lab Data:\nwww.github.com/JStyborski/NC10", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.10578v2", "cate": "cs.CR", "date": "2025-07-11", "updated": "2025-07-16", "AI": {"title_translation": "数据毒药何时何地攻击文本反演？", "tldr": "本文系统分析了数据投毒何时何地攻击扩散模型中的文本反演技术，并提出了一个名为Safe-Zone Training (SZT)的新型防御机制，该机制显著增强了文本反演对抗所有投毒攻击的鲁棒性。", "motivation": "投毒攻击对扩散模型（DMs）的鲁棒性构成了重大挑战。本文旨在系统分析投毒攻击何时何地影响文本反演（TI）这一广泛使用的扩散模型个性化技术。", "method": "1. 引入语义敏感性图（Semantic Sensitivity Maps）来可视化投毒对文本嵌入的影响。2. 识别并实验验证扩散模型在时间步长上表现出非均匀学习行为，主要集中在低噪声样本上，投毒攻击继承了这种偏见并在较低时间步长注入对抗性信号。3. 观察到对抗性信号将学习从训练数据中相关概念区域分散开，从而破坏了TI过程。4. 基于这些见解，提出了安全区训练（Safe-Zone Training, SZT），一种包含三个关键组件的新型防御机制：(1) JPEG压缩以削弱高频毒药信号；(2) 在TI训练期间限制在高时间步长以避免较低时间步长的对抗性信号；(3) 损失掩码以将学习限制在相关区域。", "result": "SZT显著增强了文本反演（TI）对抗所有投毒攻击的鲁棒性，并且在生成质量上超越了先前发表的防御方法。", "conclusion": "SZT是一种有效且创新的防御机制，能够显著提高文本反演在面对多种投毒攻击时的鲁棒性和生成质量。", "translation": "投毒攻击对扩散模型（DMs）的鲁棒性构成了重大挑战。在本文中，我们系统分析了投毒攻击何时何地攻击文本反演（TI），这是一种广泛使用的扩散模型个性化技术。我们首先引入了语义敏感性图，这是一种可视化投毒对文本嵌入影响的新颖方法。其次，我们识别并实验验证了扩散模型在时间步长上表现出非均匀学习行为，主要集中在低噪声样本上。投毒攻击继承了这种偏见，并主要在较低时间步长注入对抗性信号。最后，我们观察到对抗性信号将学习从训练数据中相关概念区域分散开，从而破坏了TI过程。基于这些见解，我们提出了安全区训练（SZT），一种包含3个关键组件的新型防御机制：(1) JPEG压缩以削弱高频毒药信号；(2) 在TI训练期间限制在高时间步长以避免较低时间步长的对抗性信号；(3) 损失掩码以将学习限制在相关区域。针对多种投毒方法的广泛实验表明，SZT极大地增强了TI对抗所有投毒攻击的鲁棒性，并在生成质量上超越了先前发表的防御方法。", "summary": "本文深入探究了数据投毒攻击对扩散模型中文本反演（TI）技术的影响时机与位置。研究发现，扩散模型在不同时间步长学习行为不均，投毒攻击主要在低时间步长注入对抗信号，并使模型偏离关键概念区域。为应对此问题，作者提出了一种名为Safe-Zone Training (SZT)的新型防御机制，通过JPEG压缩、高时间步长训练限制和损失掩码来增强TI的鲁棒性。实验证明，SZT能有效提升TI对抗多种投毒攻击的性能和生成质量。", "keywords": "数据投毒, 文本反演, 扩散模型, 鲁棒性, 安全区训练", "comments": "本文通过系统分析投毒攻击在文本反演中的作用机制，揭示了扩散模型学习行为的非均匀性及其对投毒攻击的影响，提供了深入的洞察。提出的SZT防御机制结合了多种策略，针对性地解决了投毒攻击的弱点，其创新性在于对攻击时机和位置的精确定位，并提出了相应的防御措施。该研究对于提升扩散模型的鲁棒性和安全性具有重要意义。"}}
{"id": "2507.11115", "title": "Finding Order-Preserving Subgraphs", "authors": ["Haruya Imamura", "Yasuaki Kobayashi", "Yota Otachi", "Toshiki Saitoh", "Keita Sato", "Asahi Takaoka", "Ryo Yoshinaka", "Tom C. van der Zanden"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11115v2", "summary": "(Induced) Subgraph Isomorphism and Maximum Common (Induced) Subgraph are\nfundamental problems in graph pattern matching and similarity computation. In\ngraphs derived from time-series data or protein structures, a natural total\nordering of vertices often arises from their underlying structure, such as\ntemporal sequences or amino acid sequences. This motivates the study of problem\nvariants that respect this inherent ordering. This paper addresses Ordered\n(Induced) Subgraph Isomorphism (O(I)SI) and its generalization, Maximum Common\nOrdered (Induced) Subgraph (MCO(I)S), which seek to find subgraph isomorphisms\nthat preserve the vertex orderings of two given ordered graphs. Our main\ncontributions are threefold: (1) We prove that these problems remain\nNP-complete even when restricted to small graph classes, such as trees of depth\n2 and threshold graphs. (2) We establish a gap in computational complexity\nbetween OSI and OISI on certain graph classes. For instance, OSI is\npolynomial-time solvable for interval graphs with their interval orderings,\nwhereas OISI remains NP-complete under the same setting. (3) We demonstrate\nthat the tractability of these problems can depend on the vertex ordering. For\nexample, while OISI is NP-complete on threshold graphs, its generalization,\nMCOIS, can be solved in polynomial time if the specific vertex orderings that\ncharacterize the threshold graphs are provided.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11115v2", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "寻找保序子图", "tldr": "本文研究了有序子图同构和最大公共有序子图问题，证明了其在多种图类上的NP完全性，揭示了不同问题变体之间的计算复杂性差异，并指出可处理性取决于顶点排序。", "motivation": "在时间序列数据或蛋白质结构中，顶点常因其底层结构（如时间序列或氨基酸序列）而具有自然的整体排序。这促使研究尊重这种固有排序的问题变体。", "method": "本文定义并分析了有序（诱导）子图同构（O(I)SI）及其泛化问题——最大公共有序（诱导）子图（MCO(I)S）的计算复杂性。研究方法包括证明这些问题在特定图类上的NP完全性，以及识别在某些条件下可多项式时间求解的实例。", "result": "1. 即使限制在小图类（如深度为2的树和阈值图），这些问题仍是NP完全的。2. 在某些图类上，OSI和OISI之间存在计算复杂性差距，例如，OSI对于具有区间排序的区间图是多项式时间可解的，而OISI在相同设置下仍是NP完全的。3. 这些问题的可处理性可能取决于顶点排序，例如，OISI在阈值图上是NP完全的，但如果提供了表征阈值图的特定顶点排序，其泛化MCOIS可以在多项式时间内解决。", "conclusion": "有序（诱导）子图同构和最大公共有序（诱导）子图问题通常是计算困难的（NP完全），但其可处理性在很大程度上取决于具体的图类、是否为诱导子图以及顶点排序的特性。", "translation": "（诱导）子图同构和最大公共（诱导）子图是图模式匹配和相似性计算中的基本问题。在源自时间序列数据或蛋白质结构的图中，顶点通常因其底层结构（如时间序列或氨基酸序列）而具有自然的整体排序。这促使研究尊重这种固有排序的问题变体。本文探讨了有序（诱导）子图同构（O(I)SI）及其泛化——最大公共有序（诱导）子图（MCO(I)S），这些问题旨在寻找保留两个给定有序图顶点排序的子图同构。我们的主要贡献有三方面：（1）我们证明了即使限制在小图类（如深度为2的树和阈值图），这些问题仍是NP完全的。（2）我们建立了OSI和OISI在某些图类上的计算复杂性差距。例如，OSI对于具有区间排序的区间图是多项式时间可解的，而OISI在相同设置下仍是NP完全的。（3）我们证明了这些问题的可处理性可能取决于顶点排序。例如，虽然OISI在阈值图上是NP完全的，但如果提供了表征阈值图的特定顶点排序，其泛化MCOIS可以在多项式时间内解决。", "summary": "本文引入并研究了有序（诱导）子图同构（O(I)SI）和最大公共有序（诱导）子图（MCO(I)S）问题，这些问题旨在解决实际图数据中顶点存在固有排序的子图匹配挑战。研究发现，即使在简单图类中，这些问题也常常是NP完全的。论文揭示了不同有序子图问题变体之间的计算复杂性差异，并指出问题的可处理性可能显著依赖于具体的顶点排序方式。", "keywords": "有序子图同构, 最大公共子图, 计算复杂性, 顶点排序", "comments": "该论文通过引入顶点排序，对经典的图模式匹配问题进行了重要且新颖的变体研究，这对于处理时间序列和蛋白质结构等具有内在顺序的真实世界数据具有重要意义。其贡献在于明确了这些有序问题的计算复杂性边界，并识别了在何种条件下问题变得可处理或保持不可处理，为相关领域提供了坚实的理论基础。"}}
{"id": "2504.19982", "title": "TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons", "authors": ["Emre Can Acikgoz", "Carl Guo", "Suvodip Dey", "Akul Datta", "Takyoung Kim", "Gokhan Tur", "Dilek Hakkani-Tür"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.19982v2", "summary": "Task-oriented dialogue (TOD) systems are experiencing a revolution driven by\nLarge Language Models (LLMs), yet the evaluation methodologies for these\nsystems remain insufficient for their growing sophistication. While traditional\nautomatic metrics effectively assessed earlier modular systems, they focus\nsolely on the dialogue level and cannot detect critical intermediate errors\nthat can arise during user-agent interactions. In this paper, we introduce\nTD-EVAL (Turn and Dialogue-level Evaluation), a two-step evaluation framework\nthat unifies fine-grained turn-level analysis with holistic dialogue-level\ncomparisons. At turn level, we evaluate each response along three TOD-specific\ndimensions: conversation cohesion, backend knowledge consistency, and policy\ncompliance. Meanwhile, we design TOD Agent Arena that uses pairwise comparisons\nto provide a measure of dialogue-level quality. Through experiments on MultiWOZ\n2.4 and {\\tau}-Bench, we demonstrate that TD-EVAL effectively identifies the\nconversational errors that conventional metrics miss. Furthermore, TD-EVAL\nexhibits better alignment with human judgments than traditional and LLM-based\nmetrics. These findings demonstrate that TD-EVAL introduces a new paradigm for\nTOD system evaluation, efficiently assessing both turn and system levels with a\nplug-and-play framework for future research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.19982v2", "cate": "cs.CL", "date": "2025-04-28", "updated": "2025-07-16", "AI": {"title_translation": "TD-EVAL：通过结合轮级精度与对话级比较来重新审视面向任务的对话评估", "tldr": "TD-EVAL是一个新的面向任务对话系统评估框架，它结合了细粒度的轮级分析和整体对话级比较，能更有效地识别传统指标遗漏的错误，并与人类判断更一致。", "motivation": "当前的面向任务对话（TOD）系统评估方法不足以应对其日益增长的复杂性，传统自动指标仅关注对话级别，无法检测用户与代理交互过程中可能出现的关键中间错误。", "method": "论文提出了TD-EVAL（轮和对话级评估），一个两步评估框架。在轮级，它从对话连贯性、后端知识一致性和策略合规性三个维度评估每个响应。同时，设计了TOD Agent Arena，使用成对比较来衡量对话级质量。", "result": "实验表明，TD-EVAL能有效识别传统指标遗漏的对话错误。此外，TD-EVAL与人类判断的对齐程度优于传统和基于LLM的指标。", "conclusion": "TD-EVAL为面向任务对话系统评估引入了一种新范式，它能够高效地评估轮级和系统级，并提供一个即插即用的框架供未来研究使用。", "translation": "面向任务的对话（TOD）系统在大型语言模型（LLMs）的推动下正经历一场革命，然而，这些系统的评估方法对于其日益增长的复杂性来说仍然不足。传统的自动指标虽然能有效评估早期的模块化系统，但它们仅关注对话级别，无法检测用户与代理交互过程中可能出现的关键中间错误。在本文中，我们引入了TD-EVAL（轮和对话级评估），这是一个两步评估框架，它将细粒度的轮级分析与整体对话级比较相结合。在轮级，我们从三个TOD特定维度评估每个响应：对话连贯性、后端知识一致性和策略合规性。同时，我们设计了TOD Agent Arena，它使用成对比较来提供对话级质量的衡量。通过在MultiWOZ 2.4和τ-Bench上的实验，我们证明了TD-EVAL能有效识别传统指标遗漏的对话错误。此外，TD-EVAL与人类判断的对齐程度优于传统和基于LLM的指标。这些发现表明，TD-EVAL为TOD系统评估引入了一种新范式，能够高效地评估轮级和系统级，并提供一个即插即用的框架供未来研究使用。", "summary": "本文针对大型语言模型驱动的面向任务对话（TOD）系统评估方法不足的问题，提出了TD-EVAL框架。该框架结合了细粒度的轮级分析（评估对话连贯性、后端知识一致性和策略合规性）与整体对话级比较（通过TOD Agent Arena进行成对比较）。实验证明，TD-EVAL能有效发现传统指标遗漏的对话错误，并与人类判断表现出更好的一致性，为TOD系统评估提供了一个新的、高效且可插拔的范式。", "keywords": "面向任务对话, 评估, TD-EVAL, 轮级分析, 对话级比较", "comments": "TD-EVAL的创新之处在于其两步评估框架，将传统的对话级评估与细粒度的轮级分析相结合，弥补了现有评估方法无法检测中间错误的不足。这一方法对于日益复杂的LLM驱动的TOD系统尤为重要，因为它能更全面、准确地反映系统性能，并与人类判断高度对齐，为未来的TOD系统评估和改进提供了坚实的基础。"}}
{"id": "2502.14198", "title": "Antenna Position and Beamforming Optimization for Movable Antenna Enabled ISAC: Optimal Solutions and Efficient Algorithms", "authors": ["Lebin Chen", "Ming-Min Zhao", "Min-Jian Zhao", "Rui Zhang"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages, 8 figures", "url": "http://arxiv.org/abs/2502.14198v2", "summary": "In this paper, we propose an integrated sensing and communication (ISAC)\nsystem enabled by movable antennas (MAs), which can dynamically adjust antenna\npositions to enhance both sensing and communication performance for future\nwireless networks. To characterize the benefits of MA-enabled ISAC systems, we\nfirst derive the Cram\\'er-Rao bound (CRB) for angle estimation error, which is\nthen minimized for optimizing the antenna position vector (APV) and beamforming\ndesign, subject to a pre-defined signal-to-noise ratio (SNR) constraint to\nensure the communication performance. In particular, for the case with receive\nMAs only, we provide a closed-form optimal antenna position solution, and show\nthat employing MAs over conventional fixed-position antennas (FPAs) can achieve\na sensing performance gain upper-bounded by 4.77 dB. On the other hand, for the\ncase with transmit MAs only, we develop a boundary traversal breadth-first\nsearch (BT-BFS) algorithm to obtain the global optimal solution in the\nline-of-sight (LoS) channel scenario, along with a lower-complexity boundary\ntraversal depth-first search (BT-DFS) algorithm to find a local optimal\nsolution efficiently. While in the scenario with non-LoS (NLoS) channels, a\nmajorization-minimization (MM) based Rosen's gradient projection (RGP)\nalgorithm with an efficient initialization method is proposed to obtain\nstationary solutions for the considered problem, which can be extended to the\ngeneral case with both transmit and receive MAs. Extensive numerical results\nare presented to verify the effectiveness of the proposed algorithms, and\ndemonstrate the superiority of the considered MA-enabled ISAC system over\nconventional ISAC systems with FPAs in terms of sensing and communication\nperformance trade-off.", "comment": "16 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2502.14198v2", "cate": "cs.IT", "date": "2025-02-20", "updated": "2025-07-16", "AI": {"title_translation": "可移动天线赋能的ISAC系统中的天线位置和波束成形优化：最优解和高效算法", "tldr": "研究了可移动天线（MA）赋能的集成传感与通信（ISAC）系统中的天线位置和波束成形优化，以提升传感和通信性能，并提出了相应的最优解和高效算法。", "motivation": "为了提升未来无线网络的传感和通信性能，本文提出了一种由可移动天线（MAs）赋能的集成传感与通信（ISAC）系统，旨在通过动态调整天线位置来克服传统固定位置天线（FPAs）的局限性，从而增强双重性能。", "method": "本文首先推导了角度估计误差的Cramér-Rao下界（CRB），并在此基础上，在预定义的信噪比（SNR）约束下，最小化CRB以协同优化天线位置向量（APV）和波束成形设计。具体地，对于仅有接收MA的情况，提供了闭合形式的最优天线位置解。对于仅有发射MA的视距（LoS）信道，开发了边界遍历广度优先搜索（BT-BFS）算法以获得全局最优解，以及复杂度较低的边界遍历深度优先搜索（BT-DFS）算法以高效找到局部最优解。在非视距（NLoS）信道下，提出了一种基于主化最小化（MM）的Rosen梯度投影（RGP）算法，并结合高效初始化方法来获得平稳解，该方法可扩展至同时具有发射和接收MAs的通用情况。", "result": "研究结果表明，在仅有接收MA的情况下，相对于传统固定位置天线（FPAs），可实现高达4.77 dB的传感性能增益上限。所提出的BT-BFS算法在LoS信道下能够获得全局最优解，而BT-DFS算法能高效找到局部最优解。MM-RGP算法在NLoS信道下获得了平稳解。大量的数值结果验证了所提出算法的有效性，并证明了MA赋能的ISAC系统在传感和通信性能权衡方面明显优于传统的FPA赋能的ISAC系统。", "conclusion": "本研究成功地提出了可移动天线赋能的ISAC系统中的天线位置和波束成形优化方案，并针对不同场景（包括不同MA配置和信道条件）开发了高效的优化算法。结果表明，所提出的系统能够显著提升传感和通信性能，并优于传统的固定位置天线系统，为未来无线网络提供了新的性能提升途径。", "translation": "在本文中，我们提出了一种由可移动天线（MAs）赋能的集成传感与通信（ISAC）系统，该系统可以动态调整天线位置，以增强未来无线网络的传感和通信性能。为了表征MA赋能的ISAC系统的优势，我们首先推导了角度估计误差的Cramér-Rao下界（CRB），然后将其最小化以优化天线位置向量（APV）和波束成形设计，同时受限于预定义的信噪比（SNR）约束以确保通信性能。特别是，对于仅有接收MA的情况，我们提供了闭合形式的最优天线位置解，并表明相对于传统固定位置天线（FPAs），采用MA可以实现高达4.77 dB的传感性能增益上限。另一方面，对于仅有发射MA的情况，我们开发了一种边界遍历广度优先搜索（BT-BFS）算法以在视距（LoS）信道场景中获得全局最优解，同时还提出了一个复杂度较低的边界遍历深度优先搜索（BT-DFS）算法以高效地找到局部最优解。而在非视距（NLoS）信道场景中，提出了一种基于主化最小化（MM）的Rosen梯度投影（RGP）算法，并结合高效初始化方法，以获得所考虑问题的平稳解，该算法可以扩展到同时具有发射和接收MA的通用情况。大量的数值结果验证了所提出算法的有效性，并证明了所考虑的MA赋能的ISAC系统在传感和通信性能权衡方面优于传统的FPA赋能的ISAC系统。", "summary": "本文提出了一种基于可移动天线（MA）的集成传感与通信（ISAC）系统，通过优化天线位置和波束成形来提升传感和通信性能。研究推导了角度估计误差的CRB并进行最小化，同时满足通信SNR约束。针对不同MA配置和信道条件（如仅接收MA、仅发射MA的LoS/NLoS场景），提出了闭合形式解、BT-BFS/BT-DFS算法以及MM-RGP算法。数值结果验证了这些算法的有效性以及MA赋能ISAC系统相对于传统固定位置天线系统的显著性能优势。", "keywords": "可移动天线, 集成传感与通信, 天线位置优化, 波束成形, Cramér-Rao下界", "comments": "这篇论文的创新点在于将可移动天线引入到ISAC系统中，通过动态调整天线位置来协同优化传感和通信性能，这为未来无线网络提供了新的自由度。论文不仅进行了严谨的理论分析（CRB推导），还针对不同实际场景（LoS/NLoS，仅Tx/Rx MA）设计了多种高效优化算法，并给出了具体的性能增益（如4.77 dB）。这表明了其在理论和实践上的重要性，为MA赋能的ISAC系统设计提供了坚实的基础和有效的解决方案。"}}
{"id": "2507.11886", "title": "A Composite Alignment-Aware Framework for Myocardial Lesion Segmentation in Multi-sequence CMR Images", "authors": ["Yifan Gao", "Shaohao Rui", "Haoyang Su", "Jinyi Xiang", "Lianming Wu", "Xiaosong Wang"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      MICCAI 2025", "url": "http://arxiv.org/abs/2507.11886v1", "summary": "Accurate segmentation of myocardial lesions from multi-sequence cardiac\nmagnetic resonance imaging is essential for cardiac disease diagnosis and\ntreatment planning. However, achieving optimal feature correspondence is\nchallenging due to intensity variations across modalities and spatial\nmisalignment caused by inconsistent slice acquisition protocols. We propose\nCAA-Seg, a composite alignment-aware framework that addresses these challenges\nthrough a two-stage approach. First, we introduce a selective slice alignment\nmethod that dynamically identifies and aligns anatomically corresponding slice\npairs while excluding mismatched sections, ensuring reliable spatial\ncorrespondence between sequences. Second, we develop a hierarchical alignment\nnetwork that processes multi-sequence features at different semantic levels,\ni.e., local deformation correction modules address geometric variations in\nlow-level features, while global semantic fusion blocks enable semantic fusion\nat high levels where intensity discrepancies diminish. We validate our method\non a large-scale dataset comprising 397 patients. Experimental results show\nthat our proposed CAA-Seg achieves superior performance on most evaluation\nmetrics, with particularly strong results in myocardial infarction\nsegmentation, representing a substantial 5.54% improvement over\nstate-of-the-art approaches. The code is available at\nhttps://github.com/yifangao112/CAA-Seg.", "comment": "MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.11886v1", "cate": "eess.IV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "多序列CMR图像中心肌病变分割的复合对齐感知框架", "tldr": "提出CAA-Seg框架，通过选择性切片对齐和分层对齐网络，解决多序列CMR图像中心肌病变分割中的特征对应和空间错位问题，并取得了SOTA性能提升。", "motivation": "准确分割多序列心脏磁共振成像（CMR）中的心肌病变对于心脏疾病诊断和治疗规划至关重要。然而，由于模态间的强度变化和不一致的切片采集协议导致的空间错位，实现最佳特征对应具有挑战性。", "method": "本文提出了CAA-Seg，一个复合对齐感知框架，通过两阶段方法解决挑战。首先，引入选择性切片对齐方法，动态识别并对齐解剖学上对应的切片对，同时排除不匹配的部分，确保序列间可靠的空间对应。其次，开发分层对齐网络，在不同语义级别处理多序列特征，即局部形变校正模块处理低级特征中的几何变化，而全局语义融合块在高层实现语义融合，此时强度差异减小。", "result": "在包含397名患者的大规模数据集上验证了该方法。实验结果表明，CAA-Seg在大多数评估指标上表现优异，尤其在心肌梗死分割方面表现突出，比现有最先进方法提高了5.54%。", "conclusion": "CAA-Seg框架通过其两阶段对齐策略，有效解决了多序列CMR图像中心肌病变分割的挑战，并在大规模数据集上取得了显著优于现有技术的性能，尤其在心肌梗死分割中表现突出。", "translation": "从多序列心脏磁共振成像中准确分割心肌病变对于心脏疾病的诊断和治疗规划至关重要。然而，由于模态间的强度变化和不一致的切片采集协议导致的空间错位，实现最佳特征对应具有挑战性。我们提出了CAA-Seg，一个复合对齐感知框架，通过两阶段方法解决了这些挑战。首先，我们引入了一种选择性切片对齐方法，该方法动态识别并对齐解剖学上对应的切片对，同时排除不匹配的部分，确保序列间可靠的空间对应。其次，我们开发了一个分层对齐网络，在不同的语义级别处理多序列特征，即局部形变校正模块处理低级特征中的几何变化，而全局语义融合块在高层实现语义融合，此时强度差异减小。我们在包含397名患者的大规模数据集上验证了我们的方法。实验结果表明，我们提出的CAA-Seg在大多数评估指标上取得了优异的性能，尤其在心肌梗死分割方面表现强劲，比最先进的方法提高了5.54%。代码可在https://github.com/yifangao112/CAA-Seg获取。", "summary": "本文提出了CAA-Seg，一个用于多序列CMR图像中心肌病变分割的复合对齐感知框架。针对多模态强度变化和空间错位问题，该框架采用两阶段方法：首先通过选择性切片对齐确保空间对应，然后利用分层对齐网络在不同语义级别处理特征。在大规模数据集上的实验表明，CAA-Seg在心肌病变分割（特别是心肌梗死分割）方面显著优于现有技术，性能提升达5.54%。", "keywords": "心肌病变分割, 多序列CMR, 图像对齐, 深度学习, 心肌梗死", "comments": "该研究创新性地结合了选择性切片对齐和分层特征处理，有效解决了多序列医学图像中常见的空间错位和强度差异问题。其在心肌梗死分割上的显著性能提升，表明该框架在临床诊断和治疗规划中具有重要应用潜力。大规模数据集的验证增加了结果的可靠性。"}}
{"id": "2507.12067", "title": "Robust Route Planning for Sidewalk Delivery Robots", "authors": ["Xing Tong", "Michele D. Simoni"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12067v1", "summary": "Sidewalk delivery robots are a promising solution for urban freight\ndistribution, reducing congestion compared to trucks and providing a safer,\nhigher-capacity alternative to drones. However, unreliable travel times on\nsidewalks due to pedestrian density, obstacles, and varying infrastructure\nconditions can significantly affect their efficiency. This study addresses the\nrobust route planning problem for sidewalk robots, explicitly accounting for\ntravel time uncertainty due to varying sidewalk conditions. Optimization is\nintegrated with simulation to reproduce the effect of obstacles and pedestrian\nflows and generate realistic travel times. The study investigates three\ndifferent approaches to derive uncertainty sets, including budgeted,\nellipsoidal, and support vector clustering (SVC)-based methods, along with a\ndistributionally robust method to solve the shortest path (SP) problem. A\nrealistic case study reproducing pedestrian patterns in Stockholm's city center\nis used to evaluate the efficiency of robust routing across various robot\ndesigns and environmental conditions. The results show that, when compared to a\nconventional SP, robust routing significantly enhances operational reliability\nunder variable sidewalk conditions. The Ellipsoidal and DRSP approaches\noutperform the other methods, yielding the most efficient paths in terms of\naverage and worst-case delay. Sensitivity analyses reveal that robust\napproaches consistently outperform the conventional SP, particularly for\nsidewalk delivery robots that are wider, slower, and have more conservative\nnavigation behaviors. These benefits are even more pronounced in adverse\nweather conditions and high pedestrian congestion scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12067v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "人行道配送机器人的鲁棒路径规划", "tldr": "本研究提出并评估了人行道配送机器人的鲁棒路径规划方法，以应对不确定的出行时间，结果表明鲁棒路由显著提高了在可变人行道条件下的运行可靠性。", "motivation": "人行道配送机器人是城市货运配送的有前景的解决方案，但由于行人密度、障碍物和基础设施条件变化导致出行时间不可靠，严重影响其效率。本研究旨在解决人行道机器人的鲁棒路径规划问题，明确考虑出行时间的不确定性。", "method": "研究将优化与仿真相结合，以重现障碍物和行人流的影响并生成真实的出行时间。研究探讨了三种不确定性集合的推导方法（预算、椭球和支持向量聚类），以及一种求解最短路径问题的分布鲁棒方法。使用斯德哥尔摩市中心的行人模式案例研究进行评估。", "result": "与传统最短路径相比，鲁棒路由显著增强了在可变人行道条件下的运行可靠性。椭球法和DRSP方法优于其他方法，在平均和最坏情况延迟方面产生了最有效的路径。敏感性分析表明，鲁棒方法始终优于传统最短路径，特别是对于更宽、更慢、导航行为更保守的机器人，在恶劣天气和高行人拥堵情况下效益更明显。", "conclusion": "鲁棒路径规划对于人行道配送机器人至关重要，能够显著提高其在不确定环境下的运行可靠性和效率，尤其是在挑战性条件下。", "translation": "人行道配送机器人是城市货运配送的一种有前景的解决方案，与卡车相比可减少拥堵，并为无人机提供更安全、更高容量的替代方案。然而，由于行人密度、障碍物和基础设施条件变化导致人行道上的出行时间不可靠，可能会显著影响其效率。本研究解决了人行道机器人的鲁棒路径规划问题，明确考虑了因人行道条件变化引起的出行时间不确定性。研究将优化与仿真相结合，以再现障碍物和行人流的影响并生成真实的出行时间。研究调查了三种不同的不确定性集合推导方法，包括预算、椭球和基于支持向量聚类（SVC）的方法，以及一种求解最短路径（SP）问题的分布鲁棒方法。通过一个再现斯德哥尔摩市中心行人模式的真实案例研究，评估了在各种机器人设计和环境条件下鲁棒路由的效率。结果表明，与传统SP相比，鲁棒路由在可变人行道条件下显著增强了运行可靠性。椭球法和DRSP方法优于其他方法，在平均和最坏情况延迟方面产生了最有效的路径。敏感性分析表明，鲁棒方法始终优于传统SP，特别是对于更宽、更慢、导航行为更保守的人行道配送机器人。这些优势在恶劣天气条件和高行人拥堵情景中更为显著。", "summary": "本研究提出并评估了人行道配送机器人的鲁棒路径规划方法，以应对因行人密度、障碍物和基础设施变化导致的出行时间不确定性。通过将优化与仿真结合，并探索预算、椭球和SVC等不确定性集合推导方法以及分布鲁棒最短路径（DRSP）方法，研究表明鲁棒路由显著提高了机器人在可变人行道条件下的运行可靠性。特别地，椭球法和DRSP方法在平均和最坏情况延迟方面表现最优。敏感性分析进一步证实，鲁棒方法对于较宽、较慢、行为保守的机器人，以及在恶劣天气和高拥堵环境下，其优势更为明显。", "keywords": "鲁棒路径规划, 人行道配送机器人, 出行时间不确定性, 分布鲁棒最短路径, 城市物流", "comments": "这项研究创新性地将优化与仿真结合，以解决人行道配送机器人出行时间的不确定性问题，并提出了多种鲁棒路径规划方法。其重要性在于能够显著提升城市配送机器人的实际运行可靠性和效率，特别是在复杂的城市环境中。研究结果对于未来城市物流和机器人导航系统的设计具有重要指导意义。"}}
{"id": "2506.05566", "title": "ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation", "authors": ["Chenhui Deng", "Yun-Da Tsai", "Guan-Ting Liu", "Zhongzhi Yu", "Haoxing Ren"], "categories": ["cs.AR", "cs.AI"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      Accepted to MLCAD 2025", "url": "http://arxiv.org/abs/2506.05566v2", "summary": "Recent advances in large language models (LLMs) have enabled near-human\nperformance on software coding benchmarks, but their effectiveness in RTL code\ngeneration remains limited due to the scarcity of high-quality training data.\nWhile prior efforts have fine-tuned LLMs for RTL tasks, they do not\nfundamentally overcome the data bottleneck and lack support for test-time\nscaling due to their non-reasoning nature. In this work, we introduce ScaleRTL,\nthe first reasoning LLM for RTL coding that scales up both high-quality\nreasoning data and test-time compute. Specifically, we curate a diverse set of\nlong chain-of-thought reasoning traces averaging 56K tokens each, resulting in\na dataset of 3.5B tokens that captures rich RTL knowledge. Fine-tuning a\ngeneral-purpose reasoning model on this corpus yields ScaleRTL that is capable\nof deep RTL reasoning. Subsequently, we further enhance the performance of\nScaleRTL through a novel test-time scaling strategy that extends the reasoning\nprocess via iteratively reflecting on and self-correcting previous reasoning\nsteps. Experimental results show that ScaleRTL achieves state-of-the-art\nperformance on VerilogEval and RTLLM, outperforming 18 competitive baselines by\nup to 18.4% on VerilogEval and 12.7% on RTLLM.", "comment": "Accepted to MLCAD 2025", "pdf_url": "http://arxiv.org/pdf/2506.05566v2", "cate": "cs.AR", "date": "2025-06-05", "updated": "2025-07-15", "AI": {"title_translation": "ScaleRTL: 利用推理数据和测试时计算扩展LLM以实现精确的RTL代码生成", "tldr": "ScaleRTL是一个用于RTL代码生成的推理LLM，通过高质量的推理数据和创新的测试时自校正策略，显著提升了RTL代码生成性能，在VerilogEval和RTLLM上实现了最先进的结果。", "motivation": "现有大型语言模型（LLMs）在软件编码基准测试中表现接近人类水平，但在RTL代码生成方面效果有限，主要原因是高质量训练数据稀缺。之前的努力未能从根本上解决数据瓶颈，且缺乏对测试时扩展的支持。", "method": "本研究引入了ScaleRTL，这是一个用于RTL编码的推理LLM。它通过以下方式实现：1. 策划多样化的长链式思考推理轨迹（平均56K tokens），形成一个包含3.5B tokens的数据集，捕捉丰富的RTL知识。2. 在此语料库上微调一个通用推理模型，使其具备深度RTL推理能力。3. 通过一种新颖的测试时扩展策略进一步增强性能，该策略通过迭代反思和自我纠正之前的推理步骤来扩展推理过程。", "result": "ScaleRTL在VerilogEval和RTLLM上取得了最先进的性能，在VerilogEval上超越18个竞争基线高达18.4%，在RTLLM上超越12.7%。", "conclusion": "ScaleRTL通过结合高质量的推理数据和创新的测试时计算扩展策略，成功克服了RTL代码生成中LLM的局限性，显著提升了性能，证明了推理能力和数据规模对复杂编码任务的重要性。", "translation": "大型语言模型（LLMs）的最新进展使得在软件编码基准测试中实现了接近人类的性能，但由于高质量训练数据的稀缺性，它们在RTL代码生成方面的有效性仍然有限。虽然之前的努力已经针对RTL任务对LLMs进行了微调，但它们未能从根本上克服数据瓶颈，并且由于其非推理性质而缺乏对测试时扩展的支持。在这项工作中，我们引入了ScaleRTL，这是第一个用于RTL编码的推理LLM，它同时扩展了高质量推理数据和测试时计算。具体来说，我们策划了一组多样化的长链式思考推理轨迹，平均每条56K token，从而形成了一个包含3.5B token的数据集，捕捉了丰富的RTL知识。在此语料库上微调一个通用推理模型产生了ScaleRTL，使其能够进行深度RTL推理。随后，我们通过一种新颖的测试时扩展策略进一步增强了ScaleRTL的性能，该策略通过迭代反思和自我纠正之前的推理步骤来扩展推理过程。实验结果表明，ScaleRTL在VerilogEval和RTLLM上取得了最先进的性能，在VerilogEval上超越了18个竞争基线高达18.4%，在RTLLM上超越了12.7%。", "summary": "ScaleRTL是一个用于RTL代码生成的推理型大型语言模型。针对RTL代码生成中LLM面临的数据稀缺和测试时扩展不足问题，ScaleRTL通过构建一个包含3.5B tokens的高质量链式思考推理数据集进行模型微调。此外，它引入了一种创新的测试时自校正推理策略。实验证明，ScaleRTL在VerilogEval和RTLLM基准测试上均达到了最先进的性能，显著优于现有模型。", "keywords": "RTL代码生成, 大型语言模型, 推理数据, 测试时计算, 自校正", "comments": "ScaleRTL的创新之处在于其双重扩展策略：一是通过大规模高质量的链式思考推理数据克服了RTL领域的数据瓶颈；二是通过独特的测试时自校正机制进一步提升了模型的推理和生成能力。这为LLM在专业领域（如硬件描述语言）的应用提供了新的范式，突破了传统微调的局限性，强调了推理数据和动态推理过程的重要性。"}}
{"id": "2505.09092", "title": "OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions", "authors": ["Yuhang Wang", "Abdulaziz Alhuraish", "Shengming Yuan", "Hao Zhou"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.09092v2", "summary": "Lane Keeping Assist (LKA) is widely adopted in modern vehicles, yet its\nreal-world performance remains underexplored due to proprietary systems and\nlimited data access. This paper presents OpenLKA, the first open, large-scale\ndataset for LKA evaluation and improvement. It includes 400 hours of driving\ndata from 62 production vehicle models, collected through extensive road\ntesting in Tampa, Florida and global contributions from the Comma.ai driving\ncommunity. The dataset spans a wide range of challenging scenarios, including\ncomplex road geometries, degraded lane markings, adverse weather, lighting\nconditions and surrounding traffic. The dataset is multimodal, comprising: i)\nfull CAN bus streams, decoded using custom reverse-engineered DBC files to\nextract key LKA events (e.g., system disengagements, lane detection failures);\nii) synchronized high-resolution dash-cam video; iii) real-time outputs from\nOpenpilot, providing accurate estimates of road curvature and lane positioning;\niv) enhanced scene annotations generated by Vision Language Models, describing\nlane visibility, pavement quality, weather, lighting, and traffic conditions.\nBy integrating vehicle-internal signals with high-fidelity perception and rich\nsemantic context, OpenLKA provides a comprehensive platform for benchmarking\nthe real-world performance of production LKA systems, identifying\nsafety-critical operational scenarios, and assessing the readiness of current\nroad infrastructure for autonomous driving. The dataset is publicly available\nat: https://github.com/OpenLKA/OpenLKA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.09092v2", "cate": "cs.CV", "date": "2025-05-14", "updated": "2025-07-16", "AI": {"title_translation": "OpenLKA：一个来自近期车型在真实驾驶条件下车道保持辅助的开放数据集", "tldr": "OpenLKA是一个大型开放数据集，用于评估和改进真实世界中车道保持辅助系统（LKA）的性能，包含多模态数据和挑战性场景。", "motivation": "由于专有系统和有限的数据访问，现有车道保持辅助（LKA）系统的真实世界性能尚未得到充分探索。", "method": "本文介绍了OpenLKA，一个开放、大规模的LKA评估和改进数据集。它包含了来自62款生产车型的400小时驾驶数据，这些数据通过在佛罗里达州坦帕市的广泛道路测试以及Comma.ai驾驶社区的全球贡献收集而来。数据集是多模态的，包括完整的CAN总线流（解码LKA事件）、同步高分辨率行车记录仪视频、Openpilot的实时输出（提供道路曲率和车道定位估计），以及由视觉语言模型生成的增强场景注释（描述车道可见性、路面质量、天气、光照和交通状况）。", "result": "发布了OpenLKA数据集，这是第一个开放、大规模的用于LKA评估和改进的数据集。", "conclusion": "OpenLKA通过整合车辆内部信号、高保真感知和丰富的语义上下文，提供了一个全面的平台，用于基准测试生产LKA系统的真实世界性能，识别安全关键的操作场景，并评估当前道路基础设施对自动驾驶的准备情况。", "translation": "车道保持辅助系统（LKA）在现代车辆中被广泛采用，但由于专有系统和有限的数据访问，其真实世界性能尚未得到充分探索。本文介绍了OpenLKA，这是第一个用于LKA评估和改进的开放、大规模数据集。它包含了来自62款生产车型的400小时驾驶数据，这些数据通过在佛罗里达州坦帕市的广泛道路测试以及Comma.ai驾驶社区的全球贡献收集而来。该数据集涵盖了各种具有挑战性的场景，包括复杂的道路几何形状、退化的车道标记、恶劣天气、光照条件和周围交通。该数据集是多模态的，包括：i) 完整的CAN总线流，使用自定义逆向工程的DBC文件解码以提取关键LKA事件（例如，系统脱离、车道检测失败）；ii) 同步的高分辨率行车记录仪视频；iii) Openpilot的实时输出，提供准确的道路曲率和车道定位估计；iv) 由视觉语言模型生成的增强场景注释，描述车道可见性、路面质量、天气、光照和交通状况。通过将车辆内部信号与高保真感知和丰富的语义上下文相结合，OpenLKA提供了一个全面的平台，用于基准测试生产LKA系统的真实世界性能，识别安全关键的操作场景，并评估当前道路基础设施对自动驾驶的准备情况。该数据集可在以下网址公开获取：https://github.com/OpenLKA/OpenLKA。", "summary": "本文推出了OpenLKA，一个用于评估和改进车道保持辅助（LKA）系统在真实世界中性能的开放、大规模多模态数据集。该数据集包含来自62款车型400小时的驾驶数据，覆盖复杂道路、恶劣天气和光照等挑战性场景，并整合了CAN总线数据、视频、Openpilot输出和VLMs生成的场景注释。OpenLKA旨在为LKA系统基准测试、安全关键场景识别及自动驾驶基础设施评估提供全面平台。", "keywords": "车道保持辅助, 开放数据集, 真实世界驾驶, 多模态数据, 自动驾驶", "comments": "OpenLKA通过提供大规模、多模态、真实世界的数据集，填补了LKA系统性能评估领域的数据空白。其数据来源多样性（多种车型、复杂场景）和数据类型丰富性（CAN总线、视频、Openpilot、VLMs注释）使其成为研究LKA系统鲁棒性和安全性、以及推动自动驾驶技术发展的重要资源。"}}
{"id": "2507.12461", "title": "Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis", "authors": ["Trong-Thang Pham", "Anh Nguyen", "Zhigang Deng", "Carol C. Wu", "Hien Van Nguyen", "Ngan Le"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACM MM 2025", "url": "http://arxiv.org/abs/2507.12461v1", "summary": "Radiologists rely on eye movements to navigate and interpret medical images.\nA trained radiologist possesses knowledge about the potential diseases that may\nbe present in the images and, when searching, follows a mental checklist to\nlocate them using their gaze. This is a key observation, yet existing models\nfail to capture the underlying intent behind each fixation. In this paper, we\nintroduce a deep learning-based approach, RadGazeIntent, designed to model this\nbehavior: having an intention to find something and actively searching for it.\nOur transformer-based architecture processes both the temporal and spatial\ndimensions of gaze data, transforming fine-grained fixation features into\ncoarse, meaningful representations of diagnostic intent to interpret\nradiologists' goals. To capture the nuances of radiologists' varied\nintention-driven behaviors, we process existing medical eye-tracking datasets\nto create three intention-labeled subsets: RadSeq (Systematic Sequential\nSearch), RadExplore (Uncertainty-driven Exploration), and RadHybrid (Hybrid\nPattern). Experimental results demonstrate RadGazeIntent's ability to predict\nwhich findings radiologists are examining at specific moments, outperforming\nbaseline methods across all intention-labeled datasets.", "comment": "ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.12461v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "从胸部X光诊断中的眼球运动解读放射科医生的意图", "tldr": "本文提出了一种名为RadGazeIntent的深度学习模型，用于从胸部X光诊断中的眼球运动解读放射科医生的诊断意图，该模型优于基线方法。", "motivation": "现有模型未能捕捉到放射科医生每次注视背后的潜在意图，尽管放射科医生在搜索疾病时会遵循心理清单，这是一个关键的观察。", "method": "本文提出了一种基于深度学习的方法RadGazeIntent，它采用基于Transformer的架构来处理凝视数据的时间和空间维度，将细粒度的注视特征转化为粗略、有意义的诊断意图表示。为了捕捉放射科医生多样化的意图驱动行为，作者处理了现有的医学眼动追踪数据集，创建了三个意图标记子集：RadSeq、RadExplore和RadHybrid。", "result": "RadGazeIntent能够预测放射科医生在特定时刻正在检查哪些发现，并且在所有意图标记数据集上均优于基线方法。", "conclusion": "该模型成功地从眼球运动中解读了放射科医生的诊断意图，并优于现有基线方法。", "translation": "放射科医生依靠眼球运动来导航和解读医学图像。一位训练有素的放射科医生对图像中可能存在的潜在疾病拥有知识，并在搜索时遵循心理清单，通过他们的凝视来定位它们。这是一个关键的观察，但现有模型未能捕捉到每次注视背后的潜在意图。在本文中，我们介绍了一种基于深度学习的方法RadGazeIntent，旨在模拟这种行为：即有目的地寻找某物并积极搜索。我们基于Transformer的架构处理凝视数据的时间和空间维度，将细粒度的注视特征转化为粗略、有意义的诊断意图表示，以解读放射科医生的目标。为了捕捉放射科医生各种意图驱动行为的细微差别，我们处理现有的医学眼动追踪数据集，创建了三个意图标记子集：RadSeq（系统顺序搜索）、RadExplore（不确定性驱动探索）和RadHybrid（混合模式）。实验结果表明，RadGazeIntent能够预测放射科医生在特定时刻正在检查哪些发现，在所有意图标记数据集上均优于基线方法。", "summary": "本文提出了一种新颖的深度学习模型RadGazeIntent，该模型利用基于Transformer的架构，从放射科医生在胸部X光诊断过程中的眼球运动中解读其诊断意图。鉴于现有模型未能捕捉注视背后的意图，RadGazeIntent处理时间和空间上的凝视数据，将细粒度特征转化为有意义的诊断意图表示。作者从现有眼动追踪数据中创建了三个意图标记数据集（RadSeq、RadExplore、RadHybrid）。实验表明，RadGazeIntent成功预测了放射科医生的检查目标，并优于基线方法。", "keywords": "眼球运动, 放射科医生意图, 深度学习, 胸部X光诊断, 凝视数据", "comments": "本文的创新之处在于明确地建模和解读放射科医生眼球运动背后的“意图”，这比单纯的眼动追踪更进了一步。这有助于更好地理解诊断过程，并可能辅助培训或AI辅助诊断。创建意图标记数据集也是一项有价值的贡献。"}}
{"id": "2502.16075", "title": "Implicit Bias of Gradient Descent for Non-Homogeneous Deep Networks", "authors": ["Yuhang Cai", "Kangjie Zhou", "Jingfeng Wu", "Song Mei", "Michael Lindsey", "Peter L. Bartlett"], "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      79 pages, appeared in Proceedings of the 42nd International Conference on Machine Learning, Vancouver, Canada", "url": "http://arxiv.org/abs/2502.16075v2", "summary": "We establish the asymptotic implicit bias of gradient descent (GD) for\ngeneric non-homogeneous deep networks under exponential loss. Specifically, we\ncharacterize three key properties of GD iterates starting from a sufficiently\nsmall empirical risk, where the threshold is determined by a measure of the\nnetwork's non-homogeneity. First, we show that a normalized margin induced by\nthe GD iterates increases nearly monotonically. Second, we prove that while the\nnorm of the GD iterates diverges to infinity, the iterates themselves converge\nin direction. Finally, we establish that this directional limit satisfies the\nKarush-Kuhn-Tucker (KKT) conditions of a margin maximization problem. Prior\nworks on implicit bias have focused exclusively on homogeneous networks; in\ncontrast, our results apply to a broad class of non-homogeneous networks\nsatisfying a mild near-homogeneity condition. In particular, our results apply\nto networks with residual connections and non-homogeneous activation functions,\nthereby resolving an open problem posed by Ji and Telgarsky (2020).", "comment": "79 pages, appeared in Proceedings of the 42nd International\n  Conference on Machine Learning, Vancouver, Canada", "pdf_url": "http://arxiv.org/pdf/2502.16075v2", "cate": "cs.LG", "date": "2025-02-22", "updated": "2025-07-15", "AI": {"title_translation": "梯度下降在非齐次深度网络中的隐式偏差", "tldr": "本文建立了指数损失下梯度下降在非齐次深度网络中的渐近隐式偏差，证明了其迭代器的方向收敛到边际最大化问题的KKT条件解，解决了齐次网络之外的开放问题。", "motivation": "先前关于隐式偏差的研究主要集中在齐次网络，本文旨在将这一理论扩展到更广泛的非齐次深度网络，并解决Ji和Telgarsky (2020)提出的开放问题。", "method": "本文通过表征从足够小的经验风险开始的梯度下降迭代器的三个关键特性，建立了在指数损失下，通用非齐次深度网络的梯度下降的渐近隐式偏差。", "result": "1. 梯度下降迭代器引起的归一化边际几乎单调增加。\n2. 梯度下降迭代器的范数发散到无穷大，但迭代器本身在方向上收敛。\n3. 这个方向极限满足边际最大化问题的Karush-Kuhn-Tucker (KKT) 条件。", "conclusion": "本文成功地将梯度下降的隐式偏差理论扩展到了一大类满足轻微近齐次条件的非齐次网络，包括带有残差连接和非齐次激活函数的网络，解决了现有研究的局限性。", "translation": "我们建立了在指数损失下，通用非齐次深度网络的梯度下降（GD）的渐近隐式偏差。具体来说，我们表征了从足够小的经验风险开始的GD迭代器的三个关键特性，其中阈值由网络非齐次性的一种度量决定。首先，我们表明GD迭代器引起的归一化边际几乎单调增加。其次，我们证明虽然GD迭代器的范数发散到无穷大，但迭代器本身在方向上收敛。最后，我们确定这个方向极限满足边际最大化问题的Karush-Kuhn-Tucker (KKT) 条件。先前关于隐式偏差的工作只专注于齐次网络；相比之下，我们的结果适用于满足轻微近齐次条件的一大类非齐次网络。特别是，我们的结果适用于带有残差连接和非齐次激活函数的网络，从而解决了Ji和Telgarsky (2020)提出的一个开放问题。", "summary": "本文研究了梯度下降在通用非齐次深度网络（包括带有残差连接和非齐次激活函数的网络）下的渐近隐式偏差。作者证明了在指数损失下，GD迭代器会产生一个几乎单调增加的归一化边际，并且虽然其范数发散，但方向会收敛到一个满足边际最大化KKT条件的极限。这项工作扩展了现有关于齐次网络的隐式偏差理论，并解决了非齐次网络领域的开放问题。", "keywords": "梯度下降, 隐式偏差, 非齐次网络, 深度学习, 边际最大化", "comments": "本文的创新之处在于将梯度下降的隐式偏差理论从传统的齐次网络扩展到了更具普适性的非齐次网络，解决了该领域的一个重要开放问题。其结果对于理解深度学习优化算法的泛化能力具有重要意义，尤其是在实践中广泛使用的非齐次网络结构。"}}
{"id": "2507.12215", "title": "Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning", "authors": ["Yuhao Chen", "Shuochen Liu", "Yuanjie Lyu", "Chao Zhang", "Jiayao Shi", "Tong Xu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      10 pages, 7 figures", "url": "http://arxiv.org/abs/2507.12215v1", "summary": "Game playing has long served as a fundamental benchmark for evaluating\nArtificial General Intelligence (AGI). While Large Language Models (LLMs) have\ndemonstrated impressive capabilities in general reasoning, their effectiveness\nin spatial strategic reasoning, which is critical for complex and fully\nobservable board games, remains insufficiently explored. In this work, we adopt\nChinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate\nrules and spatial complexity. To advance LLMs' strategic competence in such\nenvironments, we propose a training framework tailored to Xiangqi, built upon a\nlarge-scale dataset of five million board-move pairs enhanced with expert\nannotations and engine evaluations. Building on this foundation, we introduce\nXiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning\nfor legal move prediction to capture basic spatial rules, (2) incorporating\nstrategic annotations to improve decision-making, and (3) applying\nreinforcement learning via Group Relative Policy Optimization (GRPO) with\nmulti-dimensional reward signals to enhance reasoning stability. Our\nExperimental results indicate that, despite their size and power,\ngeneral-purpose LLMs struggle to achieve satisfactory performance in these\ntasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an\n18% rise in move legality and a 22% boost in analysis accuracy. Our results\npoint to a promising path for creating general strategic intelligence in\nspatially complex areas.", "comment": "10 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.12215v1", "cate": "cs.AI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Xiangqi-R1：通过强化学习增强LLM在中国象棋中的空间战略推理能力", "tldr": "Xiangqi-R1是一个7B参数模型，通过多阶段训练（包括强化学习）显著提升了LLM在中国象棋空间战略推理上的表现。", "motivation": "游戏对弈长期以来是评估通用人工智能（AGI）的基本基准。尽管大型语言模型（LLM）在通用推理方面表现出色，但它们在空间战略推理方面的有效性尚未得到充分探索，而这对于复杂的、完全可观察的棋盘游戏至关重要。", "method": "我们以中国象棋（Xiangqi）作为测试平台，并提出了一个为象棋量身定制的训练框架。该框架基于一个包含五百万棋盘-走法对的大规模数据集，并辅以专家标注和引擎评估。在此基础上，我们引入了Xiangqi-R1，一个7B参数模型，采用多阶段训练：1) 微调以预测合法走法，捕捉基本空间规则；2) 整合战略标注以改进决策；3) 通过带有多维度奖励信号的群组相对策略优化（GRPO）应用强化学习，以增强推理稳定性。", "result": "实验结果表明，尽管通用LLM规模庞大且能力强大，但在这些任务中难以达到令人满意的表现。与通用LLM相比，Xiangqi-R1在走法合法性方面提升了18%，在分析准确性方面提升了22%。", "conclusion": "我们的结果指明了一条在空间复杂领域创建通用战略智能的充满希望的道路。", "translation": "游戏对弈长期以来是评估通用人工智能（AGI）的基本基准。尽管大型语言模型（LLM）在通用推理方面表现出色，但它们在空间战略推理方面的有效性尚未得到充分探索，而这对于复杂的、完全可观察的棋盘游戏至关重要。在这项工作中，我们采用中国象棋（Xiangqi）作为具有挑战性和丰富的测试平台，因为它具有复杂的规则和空间复杂性。为了提高LLM在此类环境中的战略能力，我们提出了一个为象棋量身定制的训练框架，该框架建立在一个包含五百万棋盘-走法对的大规模数据集之上，并辅以专家标注和引擎评估。在此基础上，我们引入了Xiangqi-R1，一个7B参数模型，采用多阶段训练：1) 微调以预测合法走法，捕捉基本空间规则；2) 整合战略标注以改进决策；3) 通过带有多维度奖励信号的群组相对策略优化（GRPO）应用强化学习，以增强推理稳定性。我们的实验结果表明，尽管通用LLM规模庞大且能力强大，但在这些任务中难以达到令人满意的表现。与通用LLM相比，Xiangqi-R1在走法合法性方面提升了18%，在分析准确性方面提升了22%。我们的结果指明了一条在空间复杂领域创建通用战略智能的充满希望的道路。", "summary": "本研究旨在提升大型语言模型（LLMs）在复杂棋盘游戏（如中国象棋）中的空间战略推理能力。作者提出了Xiangqi-R1，一个7B参数模型，通过一个结合大规模数据集、专家标注、引擎评估以及多阶段训练（包括强化学习）的框架进行训练。实验结果显示，Xiangqi-R1在走法合法性和分析准确性上显著优于通用LLMs，表明其在空间复杂领域通用战略智能方面具有潜力。", "keywords": "大型语言模型, 空间战略推理, 中国象棋, 强化学习, Xiangqi-R1", "comments": "该论文通过将强化学习应用于LLM，并针对中国象棋这一复杂的空间战略游戏进行定制化训练，为提升LLM在特定领域（尤其是空间推理）的能力提供了创新途径。其多阶段训练方法，特别是结合了GRPO的强化学习阶段，是其重要创新点。研究结果表明，通过专业化训练，LLM能够克服通用性不足的问题，在特定复杂任务上取得显著进步，这对于未来AGI的发展具有重要意义。"}}
{"id": "2507.11830", "title": "Arctic Inference with Shift Parallelism: Fast and Efficient Open Source Inference System for Enterprise AI", "authors": ["Samyam Rajbhandari", "Mert Hidayetoglu", "Aurick Qiao", "Ye Wang", "Juncheng Yang", "Jeff Rasley", "Michael Wyatt", "Yuxiong He"], "categories": ["cs.DC", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11830v1", "summary": "Inference is now the dominant AI workload, yet existing systems force\ntrade-offs between latency, throughput, and cost. Arctic Inference, an\nopen-source vLLM plugin from Snowflake AI Research, introduces Shift\nParallelism, a dynamic parallelism strategy that adapts to real-world traffic\nwhile integrating speculative decoding, SwiftKV compute reduction, and\noptimized embedding inference. It achieves up to 3.4 times faster request\ncompletion, 1.75 times faster generation, and 1.6M tokens/sec per GPU for\nembeddings, outperforming both latency- and throughput-optimized deployments.\nAlready powering Snowflake Cortex AI, Arctic Inference delivers\nstate-of-the-art, cost-effective inference for enterprise AI and is now\navailable to the community.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11830v1", "cate": "cs.DC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Arctic 推理与移位并行：企业级AI的快速高效开源推理系统", "tldr": "Arctic Inference 是一个开源的AI推理系统，通过引入移位并行（Shift Parallelism）和其他优化技术，显著提高了企业级AI推理的速度和效率，解决了现有系统在延迟、吞吐量和成本之间的权衡问题。", "motivation": "推理是当前主要的AI工作负载，但现有系统在延迟、吞吐量和成本之间存在权衡，无法同时满足所有需求。", "method": "Arctic Inference 是一个来自Snowflake AI Research的开源vLLM插件，它引入了移位并行（Shift Parallelism）这一动态并行策略，该策略能适应实际流量，并集成了推测解码（speculative decoding）、SwiftKV 计算 S-KV（SwiftKV compute reduction）以及优化的嵌入推理（optimized embedding inference）。", "result": "该系统实现了高达3.4倍的请求完成速度提升，1.75倍的生成速度提升，以及每GPU每秒1.6M token的嵌入处理速度，性能优于现有针对延迟和吞吐量优化的部署。", "conclusion": "Arctic Inference 为企业级AI提供了最先进、高成本效益的推理解决方案，目前已在Snowflake Cortex AI中投入使用，并已向社区开源。", "translation": "推理现在是主要的AI工作负载，然而现有系统在延迟、吞吐量和成本之间被迫进行权衡。Arctic Inference 是Snowflake AI Research的一个开源vLLM插件，它引入了移位并行（Shift Parallelism），这是一种动态并行策略，能够适应真实世界的流量，同时集成了推测解码、SwiftKV 计算优化和优化的嵌入推理。它实现了高达3.4倍的请求完成速度、1.75倍的生成速度以及每GPU每秒1.6M token的嵌入处理速度，性能优于针对延迟和吞吐量优化的部署。Arctic Inference 已为Snowflake Cortex AI提供支持，为企业级AI提供了最先进、高成本效益的推理，现在已向社区开放。", "summary": "Arctic Inference是Snowflake AI Research开发的一个开源vLLM插件，通过引入动态移位并行策略并整合推测解码、SwiftKV计算优化和优化的嵌入推理，旨在解决当前AI推理系统在延迟、吞吐量和成本上的权衡问题。该系统在请求完成速度、生成速度和嵌入吞吐量方面均表现出色，为企业级AI提供了先进且高成本效益的推理能力，目前已应用于Snowflake Cortex AI并已开源。", "keywords": "推理系统, 移位并行, 企业级AI, 开源, 性能优化", "comments": "本文的创新点在于提出了“移位并行”这一动态并行策略，并将其与推测解码、SwiftKV等多种优化技术相结合，以适应实际流量并提升推理效率。其作为开源项目并已在实际企业级AI产品中得到应用，凸显了其实用价值和对AI推理领域的重要性。"}}
{"id": "2507.12064", "title": "StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features", "authors": ["Jeremi K. Ochab", "Mateusz Matias", "Tymoteusz Boba", "Tomasz Walkowiak"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12064v1", "summary": "This submission to the binary AI detection task is based on a modular\nstylometric pipeline, where: public spaCy models are used for text\npreprocessing (including tokenisation, named entity recognition, dependency\nparsing, part-of-speech tagging, and morphology annotation) and extracting\nseveral thousand features (frequencies of n-grams of the above linguistic\nannotations); light-gradient boosting machines are used as the classifier. We\ncollect a large corpus of more than 500 000 machine-generated texts for the\nclassifier's training. We explore several parameter options to increase the\nclassifier's capacity and take advantage of that training set. Our approach\nfollows the non-neural, computationally inexpensive but explainable approach\nfound effective previously.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12064v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "StylOch在PAN竞赛中：基于频率的文体学特征的梯度提升树", "tldr": "该论文提交了一项基于模块化文体学管道的二元AI文本检测方法，该方法使用spaCy进行文本预处理和特征提取（频率化的n-gram），并采用轻量级梯度提升机作为分类器，训练于一个包含50多万机器生成文本的大型语料库。", "motivation": "该研究旨在参与二元AI文本检测任务。", "method": "该方法基于一个模块化的文体学管道。它使用公共spaCy模型进行文本预处理，包括分词、命名实体识别、依存句法分析、词性标注和形态学标注。从这些语言学标注中提取数千个特征，主要是n-gram的频率。分类器采用轻量级梯度提升机。研究人员收集了一个包含超过50万机器生成文本的大型语料库用于训练。此外，他们探索了多种参数选项以提高分类器容量并充分利用训练集。该方法遵循了非神经网络、计算成本低但可解释且此前已被证明有效的方法。", "result": "未在摘要中提及", "conclusion": "未在摘要中提及", "translation": "本提交是针对二元AI检测任务的，其基础是一个模块化的文体学管道，其中：公共spaCy模型用于文本预处理（包括分词、命名实体识别、依存句法分析、词性标注和形态学标注）和提取数千个特征（上述语言学标注的n-gram频率）；轻量级梯度提升机用作分类器。我们收集了一个包含超过50万机器生成文本的大型语料库用于分类器的训练。我们探索了多种参数选项以提高分类器的容量并利用该训练集。我们的方法遵循了先前被证明有效的非神经网络、计算成本低但可解释的方法。", "summary": "本论文提出了一种用于二元AI文本检测的模块化文体学方法。该方法利用spaCy模型进行全面的文本预处理（如分词、NER、POS标注等）和基于n-gram频率的特征提取。分类器采用轻量级梯度提升机，并在一个包含50多万机器生成文本的大型语料库上进行训练。该研究还探索了参数优化以提升模型性能，并强调其非神经网络、计算效率高和可解释的特点。", "keywords": "文体学, AI检测, 梯度提升树, n-gram, spaCy", "comments": "该论文提出了一种基于传统机器学习方法（梯度提升树）和丰富的文体学特征（通过spaCy提取的n-gram频率）的AI文本检测方案，这与当前主流的深度学习方法形成对比。其强调的“计算成本低但可解释”是其创新性和重要性所在，尤其是在需要模型透明度和资源受限的场景中。然而，摘要中未提及具体的实验结果或性能指标，这限制了对其有效性的初步评估。"}}
{"id": "2507.11768", "title": "LLMs are Bayesian, in Expectation, not in Realization", "authors": ["Leon Chlon", "Sarah Rashidi", "Zein Khamis", "MarcAntonio M. Awada"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11768v1", "summary": "Large language models demonstrate remarkable in-context learning\ncapabilities, adapting to new tasks without parameter updates. While this\nphenomenon has been successfully modeled as implicit Bayesian inference, recent\nempirical findings reveal a fundamental contradiction: transformers\nsystematically violate the martingale property, a cornerstone requirement of\nBayesian updating on exchangeable data. This violation challenges the\ntheoretical foundations underlying uncertainty quantification in critical\napplications.\n  Our theoretical analysis establishes four key results: (1) positional\nencodings induce martingale violations of order $\\Theta(\\log n / n)$; (2)\ntransformers achieve information-theoretic optimality with excess risk\n$O(n^{-1/2})$ in expectation over orderings; (3) the implicit posterior\nrepresentation converges to the true Bayesian posterior in the space of\nsufficient statistics; and (4) we derive the optimal chain-of-thought length as\n$k^* = \\Theta(\\sqrt{n}\\log(1/\\varepsilon))$ with explicit constants, providing\na principled approach to reduce inference costs while maintaining performance.\nEmpirical validation on GPT-3 confirms predictions (1)-(3), with transformers\nreaching 99\\% of theoretical entropy limits within 20 examples. Our framework\nprovides practical methods for extracting calibrated uncertainty estimates from\nposition-aware architectures and optimizing computational efficiency in\ndeployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11768v1", "cate": "stat.ML", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "大型语言模型是贝叶斯式的，在期望上而非在实现上", "tldr": "大型语言模型（LLMs）的上下文学习虽被建模为隐式贝叶斯推理，但Transformer模型系统性地违反了马尔可夫性质。本文通过理论分析揭示了位置编码是原因，并证明了LLMs在期望上仍能实现信息论最优性和后验收敛，同时提出了优化计算效率的实用方法。", "motivation": "大型语言模型（LLMs）的上下文学习能力虽然被成功建模为隐式贝叶斯推理，但最近的经验发现揭示，Transformer模型系统性地违反了马尔可夫性质，这挑战了在关键应用中不确定性量化的理论基础。", "method": "本文通过理论分析建立了四个关键结果，并使用GPT-3进行了实证验证，以确认这些理论预测。", "result": "1. 位置编码导致阶数为$\\\\Theta(\\\\log n / n)$的马尔可夫性质违反。2. Transformer在期望排序上以$O(n^{-1/2})$的超额风险实现了信息论最优性。3. 隐式后验表示收敛到充分统计量空间中的真实贝叶斯后验。4. 推导出最优思维链长度为$k^* = \\\\Theta(\\\\sqrt{n}\\\\log(1/\\\\varepsilon))$。实验在GPT-3上证实了前三个预测，Transformer在20个示例内达到理论熵限制的99%。", "conclusion": "该框架提供了从位置感知架构中提取校准不确定性估计和优化部署计算效率的实用方法。", "translation": "大型语言模型展示了卓越的上下文学习能力，无需参数更新即可适应新任务。尽管这种现象已成功地建模为隐式贝叶斯推理，但最近的经验发现揭示了一个根本性矛盾：Transformer系统性地违反了马尔可夫性质，这是可交换数据上贝叶斯更新的基石要求。这种违反挑战了关键应用中不确定性量化的理论基础。\n我们的理论分析建立了四个关键结果：（1）位置编码导致阶数为$\\\\Theta(\\\\log n / n)$的马尔可夫性质违反；（2）Transformer在期望排序上以$O(n^{-1/2})$的超额风险实现了信息论最优性；（3）隐式后验表示收敛到充分统计量空间中的真实贝叶斯后验；（4）我们推导出最优思维链长度为$k^* = \\\\Theta(\\\\sqrt{n}\\\\log(1/\\\\varepsilon))$，提供了在保持性能的同时降低推理成本的原则性方法。GPT-3上的实证验证证实了预测（1）-（3），Transformer在20个示例内达到了理论熵限制的99%。我们的框架提供了从位置感知架构中提取校准不确定性估计和优化部署计算效率的实用方法。", "summary": "本文探讨了大型语言模型（LLMs）的上下文学习能力，尽管其被建模为隐式贝叶斯推理，但Transformer模型却系统性地违反了马尔可夫性质。研究通过理论分析揭示了位置编码是导致违反的原因，并证明了Transformer在信息论上具有最优性，其隐式后验收敛于真实贝叶斯后验。此外，论文还推导了最优思维链长度，以平衡性能与计算成本。GPT-3上的实证验证支持了理论预测，表明LLMs在实践中能有效逼近理论极限。该研究为从LLMs中提取校准不确定性估计和优化计算效率提供了实用框架。", "keywords": "大型语言模型, 贝叶斯推理, 上下文学习, 马尔可夫性质, 位置编码", "comments": "这篇论文深入探讨了LLMs上下文学习的理论基础，指出了其在贝叶斯推理模型中的局限性（马尔可夫性质的违反），并提供了严谨的理论分析和实证支持。其创新之处在于揭示了位置编码与这种违反的关系，并提出了优化思维链长度的实用方法，对于理解LLMs的不确定性量化和提高部署效率具有重要意义。"}}
{"id": "2505.05470", "title": "Flow-GRPO: Training Flow Matching Models via Online RL", "authors": ["Jie Liu", "Gongye Liu", "Jiajun Liang", "Yangguang Li", "Jiaheng Liu", "Xintao Wang", "Pengfei Wan", "Di Zhang", "Wanli Ouyang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Code: this https URL", "url": "http://arxiv.org/abs/2505.05470v4", "summary": "We propose Flow-GRPO, the first method integrating online reinforcement\nlearning (RL) into flow matching models. Our approach uses two key strategies:\n(1) an ODE-to-SDE conversion that transforms a deterministic Ordinary\nDifferential Equation (ODE) into an equivalent Stochastic Differential Equation\n(SDE) that matches the original model's marginal distribution at all timesteps,\nenabling statistical sampling for RL exploration; and (2) a Denoising Reduction\nstrategy that reduces training denoising steps while retaining the original\ninference timestep number, significantly improving sampling efficiency without\nperformance degradation. Empirically, Flow-GRPO is effective across multiple\ntext-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly\nperfect object counts, spatial relations, and fine-grained attributes, boosting\nGenEval accuracy from 63% to 95%. In visual text rendering, its accuracy\nimproves from 59% to 92%, significantly enhancing text generation. Flow-GRPO\nalso achieves substantial gains in human preference alignment. Notably, very\nlittle reward hacking occurred, meaning rewards did not increase at the cost of\nappreciable image quality or diversity degradation.", "comment": "Code: https://github.com/yifan123/flow_grpo", "pdf_url": "http://arxiv.org/pdf/2505.05470v4", "cate": "cs.CV", "date": "2025-05-08", "updated": "2025-07-16", "AI": {"title_translation": "Flow-GRPO：通过在线强化学习训练流匹配模型", "tldr": "Flow-GRPO首次将在线强化学习集成到流匹配模型中，通过ODE-SDE转换和去噪减少策略，显著提升了文本到图像生成和视觉文本渲染在准确性、效率和人类偏好对齐方面的表现，且没有出现明显的奖励作弊。", "motivation": "论文的目标是提出一种将在线强化学习整合到流匹配模型中的新方法，以提升这些模型在文本到图像生成等任务中的性能和效率。", "method": "论文提出了Flow-GRPO，这是首个将在线强化学习（RL）整合到流匹配模型中的方法。它包含两个关键策略：1. ODE-to-SDE 转换：将确定性常微分方程（ODE）转换为等效的随机微分方程（SDE），该SDE在所有时间步长上都与原始模型的边际分布匹配，从而为RL探索提供统计采样。2. 去噪减少策略：在保持原始推理时间步数不变的情况下，减少训练去噪步骤，显著提高采样效率而不会降低性能。", "result": "Flow-GRPO在多个文本到图像任务中表现出有效性。在复杂构图任务中，经过RL调整的SD3.5在对象计数、空间关系和细粒度属性方面表现近乎完美，将GenEval准确率从63%提升到95%。在视觉文本渲染方面，准确率从59%提高到92%，显著增强了文本生成能力。Flow-GRPO在人类偏好对齐方面也取得了显著进展。值得注意的是，奖励作弊（即奖励增加但图像质量或多样性下降）现象很少发生。", "conclusion": "Flow-GRPO成功地将在线强化学习整合到流匹配模型中，通过其创新的转换和去噪策略，显著提升了文本到图像生成任务的准确性、效率和人类偏好对齐，且有效避免了奖励作弊问题。", "translation": "我们提出了Flow-GRPO，这是首个将在线强化学习（RL）整合到流匹配模型中的方法。我们的方法采用了两个关键策略：（1）ODE到SDE的转换，将确定性常微分方程（ODE）转换为等效的随机微分方程（SDE），该SDE在所有时间步长上都与原始模型的边际分布匹配，从而为RL探索提供统计采样；（2）去噪减少策略，在保留原始推理时间步数的同时减少训练去噪步骤，显著提高采样效率而不会降低性能。经验表明，Flow-GRPO在多个文本到图像任务中均有效。对于复杂构图，RL调整后的SD3.5生成了几乎完美的物体计数、空间关系和细粒度属性，将GenEval准确率从63%提高到95%。在视觉文本渲染中，其准确率从59%提高到92%，显著增强了文本生成。Flow-GRPO在人类偏好对齐方面也取得了显著提升。值得注意的是，很少发生奖励作弊，这意味着奖励的增加并未以图像质量或多样性明显下降为代价。", "summary": "Flow-GRPO是一种新颖的方法，首次将在线强化学习引入流匹配模型。它通过将确定性ODE转换为等效的SDE以支持RL探索，并采用去噪减少策略提升采样效率。实验证明，Flow-GRPO在文本到图像生成任务中表现出色，显著提高了复杂构图和视觉文本渲染的准确性（GenEval准确率从63%提升至95%，视觉文本渲染准确率从59%提升至92%），并增强了人类偏好对齐，同时有效避免了奖励作弊问题。", "keywords": "流匹配模型, 在线强化学习, 文本到图像生成, ODE-SDE转换, 采样效率", "comments": "这篇论文的创新点在于首次将在线强化学习与流匹配模型相结合，为生成模型带来了新的优化范式。其提出的ODE-to-SDE转换策略巧妙地解决了RL探索的采样问题，而去噪减少策略则显著提升了训练效率。在实际应用中，Flow-GRPO在文本到图像生成方面取得了显著的性能提升，尤其是在处理复杂构图和文本渲染时的准确性，以及在人类偏好对齐方面的表现，都显示出其重要性。此外，论文提到很少发生奖励作弊，这表明该方法在优化性能的同时，能较好地保持生成内容的质量和多样性，这是一个非常重要的优势。"}}
{"id": "2507.11645", "title": "Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation", "authors": ["Ahmed Salah", "David Yevick"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 11 figures", "url": "http://arxiv.org/abs/2507.11645v1", "summary": "Grokking refers to delayed generalization in which the increase in test\naccuracy of a neural network occurs appreciably after the improvement in\ntraining accuracy This paper introduces several practical metrics including\nvariance under dropout, robustness, embedding similarity, and sparsity\nmeasures, that can forecast grokking behavior. Specifically, the resilience of\nneural networks to noise during inference is estimated from a Dropout\nRobustness Curve (DRC) obtained from the variation of the accuracy with the\ndropout rate as the model transitions from memorization to generalization. The\nvariance of the test accuracy under stochastic dropout across training\ncheckpoints further exhibits a local maximum during the grokking. Additionally,\nthe percentage of inactive neurons decreases during generalization, while the\nembeddings tend to a bimodal distribution independent of initialization that\ncorrelates with the observed cosine similarity patterns and dataset symmetries.\nThese metrics additionally provide valuable insight into the origin and\nbehaviour of grokking.", "comment": "15 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.11645v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "追踪Grokking之路：嵌入、Dropout和网络激活", "tldr": "论文引入了多种指标来预测和理解神经网络中的“Grokking”现象。", "motivation": "理解和预测神经网络中“Grokking”（延迟泛化）行为。", "method": "引入了多种实用指标，包括Dropout下的方差、鲁棒性、嵌入相似性和稀疏性度量。具体方法包括通过Dropout鲁棒性曲线（DRC）估计网络对噪声的弹性，分析训练检查点下随机Dropout的测试准确度方差，以及观察非活跃神经元比例和嵌入分布。", "result": "引入的指标能够预测Grokking行为。在Grokking期间，随机Dropout下测试准确度的方差出现局部最大值。泛化过程中，非活跃神经元的百分比下降。嵌入倾向于双峰分布，且与余弦相似性模式和数据集对称性相关。", "conclusion": "这些指标为Grokking的起源和行为提供了宝贵的见解。", "translation": "Grokking指的是延迟泛化，即神经网络的测试准确率在训练准确率提高之后才显著增加。本文引入了几种实用的指标，包括Dropout下的方差、鲁棒性、嵌入相似性和稀疏性度量，它们可以预测Grokking行为。具体来说，神经网络在推理过程中对噪声的弹性通过Dropout鲁棒性曲线（DRC）进行估计，该曲线通过模型从记忆到泛化过渡时准确率随Dropout率的变化获得。此外，在Grokking期间，训练检查点上随机Dropout下测试准确率的方差进一步表现出局部最大值。另外，在泛化过程中，非活跃神经元的百分比会下降，而嵌入倾向于独立于初始化的双峰分布，这与观察到的余弦相似性模式和数据集对称性相关。这些指标还为Grokking的起源和行为提供了宝贵的见解。", "summary": "本文探讨了神经网络中“Grokking”这一延迟泛化现象。为预测和理解Grokking行为，论文引入了多种实用指标，包括Dropout方差、鲁棒性、嵌入相似性和稀疏性度量。主要发现包括：Grokking期间测试准确度方差出现局部最大值，泛化时非活跃神经元比例下降，以及嵌入呈现双峰分布，这些为Grokking的机制提供了深入见解。", "keywords": "Grokking, 神经网络, 泛化, Dropout, 嵌入", "comments": "这篇论文引入了新颖的指标，为理解“Grokking”现象提供了更深入的视角，这对于训练鲁棒的神经网络至关重要。其对Dropout鲁棒性曲线（DRC）和嵌入分布等实用可测量指标的关注，为研究人员提供了一个有价值的诊断工具。"}}
{"id": "2403.09567", "title": "Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models", "authors": ["Laura Fernández-Becerra", "Miguel Ángel González-Santamarta", "Ángel Manuel Guerrero-Higueras", "Francisco Javier Rodríguez-Lera", "Vicente Matellán Olivera"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.09567v4", "summary": "The deployment of autonomous agents in environments involving human\ninteraction has increasingly raised security concerns. Consequently,\nunderstanding the circumstances behind an event becomes critical, requiring the\ndevelopment of capabilities to justify their behaviors to non-expert users.\nSuch explanations are essential in enhancing trustworthiness and safety, acting\nas a preventive measure against failures, errors, and misunderstandings.\nAdditionally, they contribute to improving communication, bridging the gap\nbetween the agent and the user, thereby improving the effectiveness of their\ninteractions. This work presents an accountability and explainability\narchitecture implemented for ROS-based mobile robots. The proposed solution\nconsists of two main components. Firstly, a black box-like element to provide\naccountability, featuring anti-tampering properties achieved through blockchain\ntechnology. Secondly, a component in charge of generating natural language\nexplanations by harnessing the capabilities of Large Language Models (LLMs)\nover the data contained within the previously mentioned black box. The study\nevaluates the performance of our solution in three different scenarios, each\ninvolving autonomous agent navigation functionalities. This evaluation includes\na thorough examination of accountability and explainability metrics,\ndemonstrating the effectiveness of our approach in using accountable data from\nrobot actions to obtain coherent, accurate and understandable explanations,\neven when facing challenges inherent in the use of autonomous agents in\nreal-world scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.09567v4", "cate": "cs.RO", "date": "2024-03-14", "updated": "2025-07-15", "AI": {"title_translation": "增强自主代理的信任：通过区块链和大型语言模型实现问责制和可解释性的架构", "tldr": "提出了一种结合区块链和LLM的架构，用于提高自主代理的问责制和可解释性，以增强信任。", "motivation": "自主代理在人机交互环境中的部署日益引发安全担忧，需要开发能够向非专业用户解释其行为的能力，以增强信任、安全性并改进沟通。", "method": "提出了一种针对基于ROS的移动机器人的问责制和可解释性架构。该方案包含两个主要组件：一个利用区块链技术实现防篡改特性的“黑盒”组件，提供问责制；一个利用大型语言模型（LLMs）根据“黑盒”中的数据生成自然语言解释的组件。", "result": "该研究在三个涉及自主代理导航功能的场景中评估了所提出解决方案的性能。评估包括对问责制和可解释性指标的全面检查，证明了该方法在利用机器人行动的可追溯数据来获得连贯、准确和可理解的解释方面的有效性，即使在面对现实世界自主代理使用固有的挑战时也是如此。", "conclusion": "该架构能够有效提高自主代理的问责制和可解释性，通过结合区块链的防篡改特性和LLM的解释生成能力，从而增强用户信任和安全。", "translation": "自主代理在涉及人类交互的环境中的部署日益引起安全担忧。因此，理解事件背后的情况变得至关重要，这需要开发能够向非专业用户解释其行为的能力。此类解释对于增强信任和安全性至关重要，可作为预防故障、错误和误解的措施。此外，它们有助于改善沟通，弥合代理与用户之间的鸿沟，从而提高其交互的有效性。\n这项工作提出了一种为基于ROS的移动机器人实现的问责制和可解释性架构。所提出的解决方案由两个主要组件组成。首先，一个类似黑盒的组件提供问责制，通过区块链技术实现防篡改特性。其次，一个负责通过利用大型语言模型（LLMs）对先前所述黑盒中包含的数据生成自然语言解释的组件。\n该研究在三种不同的场景中评估了我们解决方案的性能，每种场景都涉及自主代理导航功能。这项评估包括对问责制和可解释性指标的全面检查，证明了我们的方法在利用机器人行动的可追溯数据来获得连贯、准确和可理解的解释方面的有效性，即使在面对现实世界中自主代理使用固有的挑战时也是如此。", "summary": "这项工作提出了一种创新的架构，旨在通过结合区块链技术提供防篡改的问责制，并利用大型语言模型生成自然语言解释，从而增强自主代理的信任和安全性。该架构针对ROS移动机器人实现，并在涉及导航的实际场景中进行了评估，结果表明其能有效提供准确且可理解的解释，即使面对复杂挑战。", "keywords": "自主代理, 问责制, 可解释性, 区块链, 大型语言模型", "comments": "这篇论文的创新点在于将区块链的防篡改特性与大型语言模型的可解释性生成能力相结合，为自主代理提供了一个全面的问责和解释框架。这种结合有效解决了自主代理在实际应用中面临的信任和安全挑战，特别是在机器人领域。其重要性在于为未来自主系统在关键应用中的部署提供了新的思路和技术支持，有助于提高公众对AI系统的接受度。"}}
{"id": "2507.12127", "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks", "authors": ["Ngoc Duy Pham", "Thusitha Dayaratne", "Viet Vo", "Shangqi Lai", "Sharif Abuadbba", "Hajime Suzuki", "Xingliang Yuan", "Carsten Rudolph"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12127v1", "summary": "Advancements in wireless and mobile technologies, including 5G advanced and\nthe envisioned 6G, are driving exponential growth in wireless devices. However,\nthis rapid expansion exacerbates spectrum scarcity, posing a critical\nchallenge. Dynamic spectrum allocation (DSA)--which relies on sensing and\ndynamically sharing spectrum--has emerged as an essential solution to address\nthis issue. While machine learning (ML) models hold significant potential for\nimproving spectrum sensing, their adoption in centralized ML-based DSA systems\nis limited by privacy concerns, bandwidth constraints, and regulatory\nchallenges. To overcome these limitations, distributed ML-based approaches such\nas Federated Learning (FL) offer promising alternatives. This work addresses\ntwo key challenges in FL-based spectrum sensing (FLSS). First, the scarcity of\nlabeled data for training FL models in practical spectrum sensing scenarios is\ntackled with a semi-supervised FL approach, combined with energy detection,\nenabling model training on unlabeled datasets. Second, we examine the security\nvulnerabilities of FLSS, focusing on the impact of data poisoning attacks. Our\nanalysis highlights the shortcomings of existing majority-based defenses in\ncountering such attacks. To address these vulnerabilities, we propose a novel\ndefense mechanism inspired by vaccination, which effectively mitigates data\npoisoning attacks without relying on majority-based assumptions. Extensive\nexperiments on both synthetic and real-world datasets validate our solutions,\ndemonstrating that FLSS can achieve near-perfect accuracy on unlabeled datasets\nand maintain Byzantine robustness against both targeted and untargeted data\npoisoning attacks, even when a significant proportion of participants are\nmalicious.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12127v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "蜂窝网络中无需良性多数的自适应鲁棒联邦频谱感知", "tldr": "本文提出了一种自适应且鲁棒的联邦学习方法，用于频谱感知，能够处理未标记数据，并在不依赖良性多数的情况下防御数据投毒攻击。", "motivation": "无线设备数量的指数增长导致频谱稀缺性加剧，动态频谱分配（DSA）成为关键解决方案。然而，集中式机器学习（ML）在DSA中的应用受隐私、带宽和监管限制。联邦学习（FL）虽有前景，但在FLSS中面临两大挑战：训练FL模型所需的标记数据稀缺性，以及数据投毒攻击带来的安全漏洞，现有基于多数的防御机制不足以应对。", "method": "为解决标记数据稀缺问题，本文采用半监督FL方法，结合能量检测，使模型能在未标记数据集上训练。为应对数据投毒攻击，提出了一种受疫苗接种启发的全新防御机制，该机制无需依赖基于多数的假设。", "result": "在未标记数据集上，FLSS能实现近乎完美的准确性。同时，即使在大量恶意参与者存在的情况下，它也能对目标和非目标数据投毒攻击保持拜占庭鲁棒性。", "conclusion": "本文提出的解决方案有效解决了FLSS中的标记数据稀缺性和数据投毒攻击问题，使其能够在实际场景中实现高精度和强大的鲁棒性。", "translation": "无线和移动技术（包括5G Advanced和设想的6G）的进步正在推动无线设备的指数级增长。然而，这种快速扩张加剧了频谱稀缺性，构成了一个严峻的挑战。动态频谱分配（DSA）——依赖于感知和动态共享频谱——已成为解决此问题的基本方案。尽管机器学习（ML）模型在改善频谱感知方面具有巨大潜力，但由于隐私问题、带宽限制和监管挑战，它们在集中式基于ML的DSA系统中的应用受到限制。为了克服这些限制，联邦学习（FL）等分布式基于ML的方法提供了有前景的替代方案。本工作解决了基于FL的频谱感知（FLSS）中的两个关键挑战。首先，针对实际频谱感知场景中用于训练FL模型的标记数据稀缺问题，采用了一种半监督FL方法，结合能量检测，从而能够在无标记数据集上进行模型训练。其次，我们研究了FLSS的安全漏洞，重点关注数据投毒攻击的影响。我们的分析强调了现有基于多数的防御机制在对抗此类攻击方面的不足。为了解决这些漏洞，我们提出了一种受疫苗接种启发的全新防御机制，该机制无需依赖基于多数的假设即可有效减轻数据投毒攻击。在合成和真实世界数据集上进行的广泛实验验证了我们的解决方案，证明FLSS可以在无标记数据集上实现近乎完美的准确性，并保持对目标和非目标数据投毒攻击的拜占庭鲁棒性，即使在很大一部分参与者是恶意的情况下。", "summary": "本文旨在解决联邦学习（FL）在频谱感知（FLSS）中的两大挑战：标记数据稀缺和数据投毒攻击。针对数据稀缺问题，提出了一种结合能量检测的半监督FL方法，以利用未标记数据进行训练。针对数据投毒攻击，开发了一种新颖的、受疫苗接种启发的防御机制，该机制不依赖于多数假设。实验结果表明，该方案在未标记数据集上能达到高精度，并对各类数据投毒攻击表现出强大的鲁棒性。", "keywords": "联邦学习, 频谱感知, 数据投毒, 半监督学习, 鲁棒性", "comments": "该论文的创新之处在于同时解决了FLSS的两个关键实际问题：数据稀缺性和对高级数据投毒攻击的鲁棒安全性，特别是提出了一个独立于多数假设的新型防御机制。这显著提升了联邦学习在动态频谱分配中的实用性和可信度。"}}
{"id": "2507.12336", "title": "Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors", "authors": ["Subin Jeon", "In Cho", "Junyoung Hong", "Seon Joo Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12336v1", "summary": "This paper introduces KeyDiff3D, a framework for unsupervised monocular 3D\nkeypoints estimation that accurately predicts 3D keypoints from a single image.\nWhile previous methods rely on manual annotations or calibrated multi-view\nimages, both of which are expensive to collect, our method enables monocular 3D\nkeypoints estimation using only a collection of single-view images. To achieve\nthis, we leverage powerful geometric priors embedded in a pretrained multi-view\ndiffusion model. In our framework, this model generates multi-view images from\na single image, serving as a supervision signal to provide 3D geometric cues to\nour model. We also use the diffusion model as a powerful 2D multi-view feature\nextractor and construct 3D feature volumes from its intermediate\nrepresentations. This transforms implicit 3D priors learned by the diffusion\nmodel into explicit 3D features. Beyond accurate keypoints estimation, we\nfurther introduce a pipeline that enables manipulation of 3D objects generated\nby the diffusion model. Experimental results on diverse aspects and datasets,\nincluding Human3.6M, Stanford Dogs, and several in-the-wild and out-of-domain\ndatasets, highlight the effectiveness of our method in terms of accuracy,\ngeneralization, and its ability to enable manipulation of 3D objects generated\nby the diffusion model from a single image.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12336v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于多视角扩散先验的无监督单目3D关键点发现", "tldr": "KeyDiff3D是一种新的无监督单目3D关键点估计框架，它利用预训练的多视角扩散模型生成多视角图像作为监督信号，并提取2D多视角特征构建3D特征体，从而实现了高精度、泛化性强的3D关键点估计，并支持3D对象操作。", "motivation": "传统单目3D关键点估计方法依赖昂贵的手动标注或校准过的多视角图像，而KeyDiff3D旨在解决这些数据收集成本高的问题，实现仅使用单视角图像集合进行无监督的单目3D关键点估计。", "method": "KeyDiff3D框架利用预训练的多视角扩散模型。该模型从单张图像生成多视角图像，作为监督信号为模型提供3D几何线索。此外，扩散模型还被用作强大的2D多视角特征提取器，并从其中间表示构建3D特征体，将隐式3D先验转化为显式3D特征。", "result": "实验结果表明，KeyDiff3D在Human3.6M、Stanford Dogs以及多个野外和域外数据集上表现出高精度、良好的泛化能力，并且能够实现扩散模型生成的3D对象的操控。", "conclusion": "KeyDiff3D成功地引入了一种利用多视角扩散先验进行无监督单目3D关键点估计的新框架，解决了传统方法的标注成本问题，并在准确性、泛化性及3D对象操作方面展现了显著的有效性。", "translation": "本文介绍KeyDiff3D，一个用于无监督单目3D关键点估计的框架，能够从单张图像准确预测3D关键点。虽然以前的方法依赖于手动标注或校准过的多视角图像，这两种方法收集成本都很高，但我们的方法仅使用单视角图像集合就能实现单目3D关键点估计。为了实现这一点，我们利用了预训练的多视角扩散模型中嵌入的强大几何先验。在我们的框架中，该模型从单张图像生成多视角图像，作为监督信号为我们的模型提供3D几何线索。我们还将扩散模型用作强大的2D多视角特征提取器，并从其中间表示构建3D特征体。这会将扩散模型学习到的隐式3D先验转化为显式3D特征。除了准确的关键点估计，我们还引入了一个能够操纵扩散模型生成的3D对象的流程。在包括Human3.6M、Stanford Dogs以及多个野外和域外数据集在内的不同方面和数据集上的实验结果，突出了我们方法在准确性、泛化能力方面的有效性，以及其从单张图像实现扩散模型生成的3D对象操纵的能力。", "summary": "KeyDiff3D是一个创新的无监督单目3D关键点估计框架。它通过利用预训练的多视角扩散模型，从单视角图像生成多视角数据作为监督信号，并提取3D特征，从而克服了传统方法对昂贵标注数据的依赖。该方法实现了高精度的3D关键点估计，展现了优秀的泛化能力，并支持对扩散模型生成3D对象的操控。", "keywords": "无监督学习, 3D关键点估计, 扩散模型, 单目视觉, 几何先验", "comments": "KeyDiff3D的创新之处在于其无需手动标注或校准多视角图像，仅通过利用预训练的多视角扩散模型作为几何先验和特征提取器，实现了无监督的单目3D关键点估计。这种方法显著降低了数据收集成本，并展现了扩散模型在高级视觉任务中的强大潜力。其能够将隐式3D先验转化为显式3D特征的机制，以及对3D对象操作的支持，增加了其实用性和重要性。"}}
{"id": "2507.11981", "title": "Simplifications are Absolutists: How Simplified Language Reduces Word Sense Awareness in LLM-Generated Definitions", "authors": ["Lukas Ellinger", "Miriam Anschütz", "Georg Groh"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by RANLP 2025", "url": "http://arxiv.org/abs/2507.11981v1", "summary": "Large Language Models (LLMs) can provide accurate word definitions and\nexplanations for any context. However, the scope of the definition changes for\ndifferent target groups, like children or language learners. This is especially\nrelevant for homonyms, words with multiple meanings, where oversimplification\nmight risk information loss by omitting key senses, potentially misleading\nusers who trust LLM outputs. We investigate how simplification impacts homonym\ndefinition quality across three target groups: Normal, Simple, and ELI5. Using\ntwo novel evaluation datasets spanning multiple languages, we test DeepSeek v3,\nLlama 4 Maverick, Qwen3-30B A3B, GPT-4o mini, and Llama 3.1 8B via LLM-as-Judge\nand human annotations. Our results show that simplification drastically\ndegrades definition completeness by neglecting polysemy, increasing the risk of\nmisunderstanding. Fine-tuning Llama 3.1 8B with Direct Preference Optimization\nsubstantially improves homonym response quality across all prompt types. These\nfindings highlight the need to balance simplicity and completeness in\neducational NLP to ensure reliable, context-aware definitions for all learners.", "comment": "Accepted by RANLP 2025", "pdf_url": "http://arxiv.org/pdf/2507.11981v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "简化是绝对主义者：简化语言如何降低大型语言模型生成定义中的词义意识", "tldr": "简化语言会显著降低大型语言模型在生成词义定义时对多义词的词义意识，导致信息丢失和误解风险增加。", "motivation": "大型语言模型在为不同目标群体（如儿童或语言学习者）提供词义定义时，存在过度简化多义词（同音异义词）定义，从而丢失关键信息并可能误导用户的风险。本研究旨在调查简化对同音异义词定义质量的影响。", "method": "研究调查了简化对多义词定义质量的影响，涵盖“正常”、“简化”和“ELI5”三种目标群体。研究使用了两个新颖的多语言评估数据集，并测试了DeepSeek v3、Llama 4 Maverick、Qwen3-30B A3B、GPT-4o mini和Llama 3.1 8B等模型。评估方法包括“LLM-as-Judge”和人工标注。此外，研究还通过直接偏好优化（DPO）对Llama 3.1 8B进行了微调。", "result": "结果显示，简化会显著降低定义的完整性，因为它忽略了多义性，从而增加了误解的风险。通过直接偏好优化（DPO）对Llama 3.1 8B进行微调，显著改善了所有提示类型下的同音异义词响应质量。", "conclusion": "研究结果强调，在教育NLP领域，需要在简化性和完整性之间取得平衡，以确保为所有学习者提供可靠且上下文感知的定义。", "translation": "大型语言模型（LLMs）可以为任何上下文提供准确的词义定义和解释。然而，定义的范围会因不同的目标群体（如儿童或语言学习者）而异。这对于同音异义词（具有多个含义的词语）尤为重要，因为过度简化可能会通过省略关键词义而导致信息丢失，从而可能误导信任LLM输出的用户。我们调查了简化如何影响三种目标群体（正常、简化和ELI5）的同音异义词定义质量。我们使用两个新颖的跨多种语言的评估数据集，通过“LLM-as-Judge”和人工标注测试了DeepSeek v3、Llama 4 Maverick、Qwen3-30B A3B、GPT-4o mini和Llama 3.1 8B。我们的结果表明，简化会通过忽视多义性而大大降低定义的完整性，增加误解的风险。通过直接偏好优化（DPO）对Llama 3.1 8B进行微调，显著改善了所有提示类型下的同音异义词响应质量。这些发现强调了在教育NLP中平衡简洁性和完整性的必要性，以确保为所有学习者提供可靠、上下文感知的定义。", "summary": "本研究探讨了简化语言如何影响大型语言模型生成的多义词定义质量。结果表明，为适应不同目标群体而进行的过度简化会导致定义完整性下降，因为它常常忽略词语的多种含义，从而增加用户误解的风险。研究通过对多个主流LLM进行评估，并发现通过直接偏好优化对模型进行微调可以显著改善多义词的定义质量。论文强调了在教育NLP中，需要在定义内容的简洁性和完整性之间取得平衡，以确保提供准确且上下文感知的词义解释。", "keywords": "大型语言模型, 词义消歧, 简化语言, 多义词, 定义质量", "comments": "这篇论文揭示了LLM在教育应用中一个重要的潜在陷阱：过度简化可能适得其反。其创新之处在于通过实验验证了简化语言对LLM词义意识的负面影响，并提出了通过DPO微调来改善这一问题。这对于开发面向教育或特定用户群体的LLM应用具有重要指导意义，强调了在追求易读性的同时，不能牺牲信息的准确性和完整性。"}}
{"id": "2507.11911", "title": "AFPM: Alignment-based Frame Patch Modeling for Cross-Dataset EEG Decoding", "authors": ["Xiaoqing Chen", "Siyang Li", "Dongrui Wu"], "categories": ["cs.HC", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11911v1", "summary": "Electroencephalogram (EEG) decoding models for brain-computer interfaces\n(BCIs) struggle with cross-dataset learning and generalization due to channel\nlayout inconsistencies, non-stationary signal distributions, and limited\nneurophysiological prior integration. To address these issues, we propose a\nplug-and-play Alignment-Based Frame-Patch Modeling (AFPM) framework, which has\ntwo main components: 1) Spatial Alignment, which selects task-relevant channels\nbased on brain-region priors, aligns EEG distributions across domains, and\nremaps the selected channels to a unified layout; and, 2) Frame-Patch Encoding,\nwhich models multi-dataset signals into unified spatiotemporal patches for EEG\ndecoding. Compared to 17 state-of-the-art approaches that need dataset-specific\ntuning, the proposed calibration-free AFPM achieves performance gains of up to\n4.40% on motor imagery and 3.58% on event-related potential tasks. To our\nknowledge, this is the first calibration-free cross-dataset EEG decoding\nframework, substantially enhancing the practicalness of BCIs in real-world\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11911v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "AFPM：基于对齐的帧块建模用于跨数据集脑电图解码", "tldr": "AFPM是一个免校准的跨数据集脑电图解码框架，通过空间对齐和帧块编码解决了现有模型在跨数据集学习和泛化方面的挑战，显著提升了脑机接口的实用性。", "motivation": "当前的脑电图（EEG）解码模型在跨数据集学习和泛化方面存在困难，原因包括通道布局不一致、非稳态信号分布以及神经生理学先验知识整合不足。", "method": "本文提出了一个即插即用的基于对齐的帧块建模（AFPM）框架，包含两个主要组件：1）空间对齐：根据脑区先验选择任务相关通道，对齐跨域脑电图分布，并将选定通道重新映射到统一布局；2）帧块编码：将多数据集信号建模为统一的时空块用于脑电图解码。", "result": "与17种需要特定数据集调优的最新方法相比，所提出的免校准AFPM在运动想象任务上实现了高达4.40%的性能提升，在事件相关电位任务上实现了3.58%的性能提升。", "conclusion": "AFPM是首个免校准的跨数据集脑电图解码框架，显著增强了脑机接口在实际应用中的实用性。", "translation": "脑电图（EEG）解码模型在脑机接口（BCIs）中，由于通道布局不一致、非稳态信号分布和有限的神经生理学先验知识整合，在跨数据集学习和泛化方面面临挑战。为了解决这些问题，我们提出了一个即插即用的基于对齐的帧块建模（AFPM）框架，它有两个主要组件：1）空间对齐，根据脑区先验选择任务相关通道，对齐跨域脑电图分布，并将选定通道重新映射到统一布局；2）帧块编码，将多数据集信号建模为统一的时空块用于脑电图解码。与17种需要特定数据集调优的最新方法相比，所提出的免校准AFPM在运动想象任务上实现了高达4.40%的性能提升，在事件相关电位任务上实现了3.58%的性能提升。据我们所知，这是第一个免校准的跨数据集脑电图解码框架，大大增强了脑机接口在实际应用中的实用性。", "summary": "本文提出了一种名为AFPM（基于对齐的帧块建模）的即插即用框架，旨在解决脑电图（EEG）解码模型在跨数据集学习和泛化方面的挑战。AFPM通过空间对齐技术统一不同数据集的通道布局和信号分布，并通过帧块编码将多数据集信号转化为统一的时空块。实验结果表明，与现有方法相比，AFPM在运动想象和事件相关电位任务上均取得了显著的性能提升，且无需校准，极大地提高了脑机接口在实际应用中的实用性。", "keywords": "脑电图解码, 跨数据集学习, 免校准, 空间对齐, 帧块建模", "comments": "AFPM框架的创新之处在于其“免校准”的特性和“即插即用”的设计，这对于脑机接口的实际部署具有里程碑意义。通过空间对齐和帧块编码，它有效地解决了跨数据集EEG解码中的核心挑战，即通道不一致性和信号分布差异。其性能提升也证明了该方法的有效性，为BCI的普及化提供了新的思路。"}}
{"id": "2507.11692", "title": "Galaxy image simplification using Generative AI", "authors": ["Sai Teja Erukude", "Lior Shamir"], "categories": ["astro-ph.GA", "astro-ph.IM", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Astrophysics of Galaxies (astro-ph.GA)", "pdf_link": null, "comments": "Comments:      Astronomy and Computing, accepted", "url": "http://arxiv.org/abs/2507.11692v1", "summary": "Modern digital sky surveys have been acquiring images of billions of\ngalaxies. While these images often provide sufficient details to analyze the\nshape of the galaxies, accurate analysis of such high volumes of images\nrequires effective automation. Current solutions often rely on machine learning\nannotation of the galaxy images based on a set of pre-defined classes. Here we\nintroduce a new approach to galaxy image analysis that is based on generative\nAI. The method simplifies the galaxy images and automatically converts them\ninto a ``skeletonized\" form. The simplified images allow accurate measurements\nof the galaxy shapes and analysis that is not limited to a certain pre-defined\nset of classes. We demonstrate the method by applying it to galaxy images\nacquired by the DESI Legacy Survey. The code and data are publicly available.\nThe method was applied to 125,000 DESI Legacy Survey images, and the catalog of\nthe simplified images is publicly available.", "comment": "Astronomy and Computing, accepted", "pdf_url": "http://arxiv.org/pdf/2507.11692v1", "cate": "astro-ph.GA", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "星系图像生成式AI简化", "tldr": "使用生成式AI简化星系图像，将其骨架化，实现对星系形状的精确测量和更灵活的分析。", "motivation": "现代数字巡天获取了数十亿星系图像，但高精度分析这些大量图像需要有效自动化。现有解决方案常依赖于预定义类别的机器学习标注，这限制了分析，因此需要一种新的方法。", "method": "本文提出一种基于生成式AI的新方法，用于简化星系图像并自动将其转换为“骨架化”形式。", "result": "简化后的图像允许对星系形状进行精确测量，且分析不受预定义类别的限制。该方法已应用于DESI遗产巡天获取的125,000张星系图像，并公开了代码和简化图像目录。", "conclusion": "通过生成式AI简化星系图像，可以实现更精确、更灵活的星系形状分析，并且克服了传统方法对预定义类别的依赖。", "translation": "现代数字巡天已获取了数十亿张星系图像。尽管这些图像通常提供足够的细节来分析星系的形状，但对如此大量图像进行准确分析需要有效的自动化。当前的解决方案通常依赖于基于一组预定义类别的星系图像机器学习标注。在此，我们介绍了一种基于生成式AI的星系图像分析新方法。该方法简化了星系图像，并自动将其转换为“骨架化”形式。简化的图像允许对星系形状进行精确测量，并且分析不受限于某个预定义类别集。我们通过将其应用于DESI遗产巡天获取的星系图像来演示该方法。代码和数据均已公开。该方法已应用于125,000张DESI遗产巡天图像，并且简化图像的目录已公开。", "summary": "本文提出一种利用生成式AI简化星系图像的新方法，将高细节的星系图像转化为“骨架化”形式。这种简化过程旨在克服现有机器学习标注方法对预定义类别的依赖，从而实现对星系形状更精确、更不受限制的测量和分析。该方法已成功应用于DESI遗产巡天的125,000张星系图像，并公开了代码和简化图像目录。", "keywords": "星系图像简化, 生成式AI, 星系形状分析, 骨架化, 数字巡天", "comments": "这篇论文的创新点在于将生成式AI应用于星系图像的简化和骨架化，这提供了一种新的、更灵活的分析星系形状的方法，突破了传统基于预定义分类的限制。其重要性在于能够处理天文大数据，并可能提高星系形态学分析的精度和自动化程度。公开代码和数据也增强了其可复现性和影响力。"}}
{"id": "2507.12049", "title": "MoViAD: Modular Visual Anomaly Detection", "authors": ["Manuel Barusco", "Francesco Borsatti", "Arianna Stropeni", "Davide Dalle Pezze", "Gian Antonio Susto"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12049v1", "summary": "VAD is a critical field in machine learning focused on identifying deviations\nfrom normal patterns in images, often challenged by the scarcity of anomalous\ndata and the need for unsupervised training. To accelerate research and\ndeployment in this domain, we introduce MoViAD, a comprehensive and highly\nmodular library designed to provide fast and easy access to state-of-the-art\nVAD models, trainers, datasets, and VAD utilities. MoViAD supports a wide array\nof scenarios, including continual, semi-supervised, few-shots, noisy, and many\nmore. In addition, it addresses practical deployment challenges through\ndedicated Edge and IoT settings, offering optimized models and backbones, along\nwith quantization and compression utilities for efficient on-device execution\nand distributed inference. MoViAD integrates a selection of backbones, robust\nevaluation VAD metrics (pixel-level and image-level) and useful profiling tools\nfor efficiency analysis. The library is designed for fast, effortless\ndeployment, enabling machine learning engineers to easily use it for their\nspecific setup with custom models, datasets, and backbones. At the same time,\nit offers the flexibility and extensibility researchers need to develop and\nexperiment with new methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12049v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MoViAD：模块化视觉异常检测", "tldr": "MoViAD是一个全面的模块化库，旨在加速视觉异常检测（VAD）领域的研究和部署，提供先进的模型、训练器、数据集和实用工具，并支持多种场景和边缘部署。", "motivation": "视觉异常检测（VAD）领域面临异常数据稀缺和需要无监督训练的挑战，为了加速该领域的研究和部署，需要一个综合性的解决方案。", "method": "本文介绍了MoViAD，一个全面且高度模块化的库，它提供对最先进的VAD模型、训练器、数据集和VAD实用工具的快速便捷访问。MoViAD支持多种场景，包括持续学习、半监督、少样本、噪声数据等，并通过提供优化的模型、骨干网络、量化和压缩工具来解决边缘和物联网环境中的实际部署挑战。", "result": "MoViAD集成了多种骨干网络、鲁棒的VAD评估指标（像素级和图像级）以及用于效率分析的实用分析工具。它旨在实现快速、轻松的部署，使机器学习工程师能够轻松将其用于自定义模型、数据集和骨干网络，同时为研究人员提供了开发和实验新方法所需的灵活性和可扩展性。", "conclusion": "MoViAD旨在通过提供一个全面、模块化且易于部署的库，加速视觉异常检测领域的研究和实际应用，同时兼顾了研究人员的灵活性和可扩展性需求。", "translation": "视觉异常检测（VAD）是机器学习中的一个关键领域，专注于识别图像中与正常模式的偏差，通常面临异常数据稀缺和需要无监督训练的挑战。为了加速该领域的研究和部署，我们引入了MoViAD，一个全面且高度模块化的库，旨在提供对最先进的VAD模型、训练器、数据集和VAD实用工具的快速便捷访问。MoViAD支持多种场景，包括持续学习、半监督学习、少样本学习、噪声数据等。此外，它通过专门的边缘和物联网设置解决了实际部署挑战，提供优化的模型和骨干网络，以及用于高效设备端执行和分布式推理的量化和压缩工具。MoViAD集成了多种骨干网络、鲁棒的VAD评估指标（像素级和图像级）以及用于效率分析的实用分析工具。该库旨在实现快速、轻松的部署，使机器学习工程师能够轻松将其用于其特定设置，包括自定义模型、数据集和骨干网络。同时，它也为研究人员提供了开发和实验新方法所需的灵活性和可扩展性。", "summary": "MoViAD是一个为视觉异常检测（VAD）领域设计的全面且模块化的库，旨在克服数据稀缺和无监督训练等挑战，加速研究和部署。它提供了先进的VAD模型、训练器、数据集和实用工具，支持多种场景（如持续学习、少样本）并优化了边缘和物联网部署。该库集成了骨干网络、评估指标和分析工具，旨在实现快速、便捷的部署，同时为研究人员提供高度的灵活性和可扩展性。", "keywords": "视觉异常检测, 模块化库, 机器学习, 部署, MoViAD", "comments": "MoViAD的创新之处在于其高度模块化的设计和对多种VAD场景的全面支持，尤其是在解决边缘和IoT部署挑战方面的实用性。这对于加速VAD领域的实际应用和研究具有重要意义，因为它降低了门槛并提供了强大的工具集。"}}
{"id": "2507.11256", "title": "Fully Dynamic Euclidean k-Means", "authors": ["Sayan Bhattacharya", "Martín Costa", "Ermiya Farokhnejad", "Shaofeng H. -C. Jiang", "Yaonan Jin", "Jianing Lou"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11256v2", "summary": "We consider the fundamental Euclidean $k$-means clustering problem in a\ndynamic setting, where the input $X \\subseteq \\mathbb{R}^d$ evolves over time\nvia a sequence of point insertions/deletions. We have to explicitly maintain a\nsolution (a set of $k$ centers) $S \\subseteq \\mathbb{R}^d$ throughout these\nupdates, while minimizing the approximation ratio, the update time (time taken\nto handle a point insertion/deletion) and the recourse (number of changes made\nto the solution $S$) of the algorithm.\n  We present a dynamic algorithm for this problem with\n$\\text{poly}(1/\\epsilon)$-approximation ratio, $\\tilde{O}(k^{\\epsilon})$ update\ntime and $\\tilde{O}(1)$ recourse. In the general regime, where the dimension\n$d$ cannot be assumed to be a fixed constant, our algorithm has almost optimal\nguarantees across all these three parameters. Indeed, improving our update time\nor approximation ratio would imply beating the state-of-the-art static\nalgorithm for this problem (which is widely believed to be the best possible),\nand the recourse of any dynamic algorithm must be $\\Omega(1)$.\n  We obtain our result by building on top of the recent work of [Bhattacharya,\nCosta, Farokhnejad; STOC'25], which gave a near-optimal dynamic algorithm for\n$k$-means in general metric spaces (as opposed to in the Euclidean setting).\nAlong the way, we design several novel geometric data structures that are of\nindependent interest. Specifically, one of our main contributions is designing\nthe first consistent hashing scheme [Czumaj, Jiang, Krauthgamer, Vesel\\'y,\nYang; FOCS'22] that achieves $\\tilde O(n^\\epsilon)$ running time per point\nevaluation with competitive parameters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11256v2", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "全动态欧几里得k-均值", "tldr": "本文提出了一个针对动态欧几里得k-均值聚类问题的算法，该算法在逼近比、更新时间和恢复能力方面几乎达到最优，并且引入了几种新的几何数据结构。", "motivation": "在动态环境下考虑基本的欧几里得k-均值聚类问题，其中输入数据通过点插入/删除序列随时间演变。需要在这些更新过程中显式维护一个解决方案（k个中心），同时最小化算法的逼近比、更新时间（处理点插入/删除所需时间）和恢复能力（对解决方案S进行的更改次数）。", "method": "本文在[Bhattacharya, Costa, Farokhnejad; STOC'25]最近的工作基础上构建，该工作为一般度量空间中的k-均值提供了接近最优的动态算法。在此过程中，设计了几种新的几何数据结构，其中一个主要贡献是设计了第一个一致性哈希方案，该方案实现了每次点评估的$\tilde O(n^\\epsilon)$运行时间，并具有竞争性参数。", "result": "提出了一个动态算法，其逼近比为$\text{poly}(1/\\epsilon)$，更新时间为$\tilde{O}(k^{\\epsilon})$，恢复能力为$\tilde{O}(1)$。在维度d不被假定为固定常数的一般情况下，该算法在所有这三个参数上都具有几乎最优的保证。改进更新时间或逼近比将意味着超越当前最先进的静态算法，并且任何动态算法的恢复能力必须为$\\\\Omega(1)$。", "conclusion": "本文提出的动态欧几里得k-均值聚类算法在逼近比、更新时间和恢复能力方面达到了几乎最优的性能，并且通过引入新的几何数据结构（包括第一个具有竞争参数的一致性哈希方案）为该领域做出了重要贡献，其性能甚至挑战了现有静态算法的极限。", "translation": "我们考虑动态设置中的基本欧几里得k-均值聚类问题，其中输入$X \\subseteq \\mathbb{R}^d$通过一系列点插入/删除随时间演变。我们必须在这些更新过程中显式维护一个解决方案（k个中心）$S \\subseteq \\mathbb{R}^d$，同时最小化算法的逼近比、更新时间（处理点插入/删除所需时间）和恢复能力（对解决方案$S$进行的更改次数）。\n我们为该问题提出了一种动态算法，其逼近比为$\text{poly}(1/\\epsilon)$，更新时间为$\tilde{O}(k^{\\epsilon})$，恢复能力为$\tilde{O}(1)$。在维度$d$不能假定为固定常数的一般情况下，我们的算法在这三个参数上都具有几乎最优的保证。事实上，改进我们的更新时间或逼近比将意味着超越该问题最先进的静态算法（这被广泛认为是最佳的），并且任何动态算法的恢复能力必须是$\\\\Omega(1)$。\n我们通过在[Bhattacharya, Costa, Farokhnejad; STOC'25]的最新工作基础上构建来获得我们的结果，该工作为一般度量空间（而不是欧几里得设置）中的k-均值提供了接近最优的动态算法。在此过程中，我们设计了几种独立兴趣的新型几何数据结构。具体而言，我们的主要贡献之一是设计了第一个一致性哈希方案[Czumaj, Jiang, Krauthgamer, Vesel\\'y, Yang; FOCS'22]，该方案以竞争性参数实现了每次点评估的$\tilde O(n^\\epsilon)$运行时间。", "summary": "本文研究了动态欧几里得k-均值聚类问题，其中数据点随时间插入或删除。文章提出了一个动态算法，在逼近比、更新时间和恢复能力方面实现了几乎最优的性能，其逼近比为$\text{poly}(1/\\epsilon)$，更新时间为$\tilde{O}(k^{\\epsilon})$，恢复能力为$\tilde{O}(1)$。该算法在通用维度设置下表现出色，其性能甚至可以挑战现有静态算法的极限。研究成果建立在最近关于度量空间k-均值的工作之上，并引入了多项创新几何数据结构，包括一种高效的一致性哈希方案。", "keywords": "动态k-均值, 欧几里得空间, 聚类, 动态算法, 几何数据结构", "comments": "本文在动态k-均值聚类领域取得了显著进展，尤其是在欧几里得空间中。其创新性在于将现有度量空间k-均值算法扩展到欧几里得环境，并设计了多个新颖的几何数据结构，其中一致性哈希方案具有独立的研究价值。该算法在更新时间、逼近比和恢复能力方面达到了接近理论最优的界限，表明其在实际应用中的高效性。其结果甚至超越了某些静态算法的性能，这强调了其重要性。"}}
{"id": "2507.12015", "title": "EME-TTS: Unlocking the Emphasis and Emotion Link in Speech Synthesis", "authors": ["Haoxun Li", "Leyuan Qu", "Jiaxi Hu", "Taihao Li"], "categories": ["cs.SD"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted by INTERSPEECH 2025", "url": "http://arxiv.org/abs/2507.12015v1", "summary": "In recent years, emotional Text-to-Speech (TTS) synthesis and\nemphasis-controllable speech synthesis have advanced significantly. However,\ntheir interaction remains underexplored. We propose Emphasis Meets Emotion TTS\n(EME-TTS), a novel framework designed to address two key research questions:\n(1) how to effectively utilize emphasis to enhance the expressiveness of\nemotional speech, and (2) how to maintain the perceptual clarity and stability\nof target emphasis across different emotions. EME-TTS employs weakly supervised\nlearning with emphasis pseudo-labels and variance-based emphasis features.\nAdditionally, the proposed Emphasis Perception Enhancement (EPE) block enhances\nthe interaction between emotional signals and emphasis positions. Experimental\nresults show that EME-TTS, when combined with large language models for\nemphasis position prediction, enables more natural emotional speech synthesis\nwhile preserving stable and distinguishable target emphasis across emotions.\nSynthesized samples are available on-line.", "comment": "Accepted by INTERSPEECH 2025", "pdf_url": "http://arxiv.org/pdf/2507.12015v1", "cate": "cs.SD", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "EME-TTS：解锁语音合成中的重音与情感关联", "tldr": "EME-TTS是一个新框架，通过弱监督学习和EPE模块，解决了情感语音合成中重音与情感的交互问题，实现了更自然且重音清晰的合成语音。", "motivation": "现有的情感文本到语音（TTS）合成和重音可控语音合成技术进步显著，但它们之间的相互作用仍未得到充分探索。本文旨在解决如何有效利用重音增强情感语音的表现力，以及如何在不同情感下保持目标重音的感知清晰度和稳定性这两个关键问题。", "method": "提出了Emphasis Meets Emotion TTS (EME-TTS)框架。该框架采用弱监督学习，结合重音伪标签和基于方差的重音特征。此外，引入了Emphasis Perception Enhancement (EPE)模块，以增强情感信号和重音位置之间的交互。", "result": "实验结果表明，EME-TTS与大型语言模型结合进行重音位置预测时，能够实现更自然的情感语音合成，同时在不同情感下保持稳定且可区分的目标重音。", "conclusion": "EME-TTS成功地解决了情感语音合成中重音与情感的交互问题，提升了合成语音的自然度和重音清晰度。", "translation": "近年来，情感文本到语音（TTS）合成和重音可控语音合成取得了显著进展。然而，它们之间的相互作用仍未得到充分探索。我们提出了强调与情感结合的TTS（EME-TTS），这是一个旨在解决两个关键研究问题的新颖框架：（1）如何有效利用重音来增强情感语音的表现力，以及（2）如何在不同情感下保持目标重音的感知清晰度和稳定性。EME-TTS采用弱监督学习，结合重音伪标签和基于方差的重音特征。此外，所提出的重音感知增强（EPE）模块增强了情感信号和重音位置之间的交互。实验结果表明，EME-TTS与大型语言模型结合进行重音位置预测时，能够实现更自然的情感语音合成，同时在不同情感下保持稳定且可区分的目标重音。合成样本可在网上获取。", "summary": "EME-TTS是一个旨在解决情感与重音交互问题的语音合成框架。它利用弱监督学习和重音伪标签，并引入重音感知增强（EPE）模块来加强情感信号与重音位置的互动。实验证明，EME-TTS能生成更自然的情感语音，并在不同情感下保持重音的稳定性和清晰度。", "keywords": "语音合成, 情感TTS, 重音控制, 弱监督学习, EPE模块", "comments": "EME-TTS的创新点在于首次深入探讨并解决了情感语音合成中重音与情感的交互问题。通过弱监督学习和EPE模块的设计，它提供了一种有效的方法来提升合成语音的自然度和表现力，尤其是在保持重音清晰度方面具有重要意义。与大型语言模型结合使用也体现了其前瞻性。"}}
{"id": "2507.11898", "title": "Extremal Testing for Network Software using LLMs", "authors": ["Rathin Singha", "Harry Qian", "Srinath Saikrishnan", "Tracy Zhao", "Ryan Beckett", "Siva Kesava Reddy Kakarla", "George Varghese"], "categories": ["cs.SE", "cs.NI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11898v1", "summary": "Physicists often manually consider extreme cases when testing a theory. In\nthis paper, we show how to automate extremal testing of network software using\nLLMs in two steps: first, ask the LLM to generate input constraints (e.g., DNS\nname length limits); then ask the LLM to generate tests that violate the\nconstraints. We demonstrate how easy this process is by generating extremal\ntests for HTTP, BGP and DNS implementations, each of which uncovered new bugs.\nWe show how this methodology extends to centralized network software such as\nshortest path algorithms, and how LLMs can generate filtering code to reject\nextremal input. We propose using agentic AI to further automate extremal\ntesting. LLM-generated extremal testing goes beyond an old technique in\nsoftware testing called Boundary Value Analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11898v1", "cate": "cs.SE", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "使用大型语言模型对网络软件进行极端测试", "tldr": "本文展示了如何利用大型语言模型（LLMs）自动化网络软件的极端测试，通过让LLM生成输入约束并进一步生成违反这些约束的测试用例，成功发现了新错误。", "motivation": "物理学家通常手动考虑极端情况来测试理论。本文旨在自动化网络软件的极端测试过程。", "method": "该方法分两步：首先，要求大型语言模型（LLM）生成输入约束（例如，DNS名称长度限制）；然后，要求LLM生成违反这些约束的测试。作者通过为HTTP、BGP和DNS实现生成极端测试来演示此过程。该方法还扩展到集中式网络软件（如最短路径算法），并且LLM可以生成过滤代码来拒绝极端输入。", "result": "通过该方法，成功为HTTP、BGP和DNS实现生成了极端测试，每个都发现了新的bug。该方法可扩展到集中式网络软件，并且LLM能够生成过滤代码以拒绝极端输入。", "conclusion": "LLM生成的极端测试是一种有效的方法，能够超越传统的边界值分析技术，并且能够发现新的软件缺陷。未来可以利用代理AI进一步自动化极端测试。", "translation": "物理学家在测试理论时通常会手动考虑极端情况。在本文中，我们展示了如何使用大型语言模型（LLM）分两步自动化网络软件的极端测试：首先，要求LLM生成输入约束（例如，DNS名称长度限制）；然后要求LLM生成违反这些约束的测试。我们通过为HTTP、BGP和DNS实现生成极端测试来证明这个过程的简易性，每个测试都发现了新的错误。我们展示了这种方法如何扩展到集中式网络软件，例如最短路径算法，以及LLM如何生成过滤代码来拒绝极端输入。我们建议使用代理AI进一步自动化极端测试。LLM生成的极端测试超越了软件测试中一种名为边界值分析的旧技术。", "summary": "本文提出了一种利用大型语言模型（LLMs）自动化网络软件极端测试的新方法。该方法分为两步：首先让LLM生成输入约束，然后生成违反这些约束的测试用例。研究人员通过对HTTP、BGP和DNS的实现进行测试，成功发现了新错误，并证明了该方法对集中式网络软件的适用性以及LLM生成过滤代码的能力。该方法超越了传统的边界值分析技术，并建议未来可结合代理AI进一步提升自动化水平。", "keywords": "极端测试, 网络软件, 大型语言模型, 自动化测试, 软件测试", "comments": "本文的创新之处在于利用大型语言模型（LLMs）自动化了网络软件的极端测试，这是一种新颖且高效的测试方法。它不仅简化了传统上需要手动进行的极端情况考虑过程，而且通过实际案例（HTTP, BGP, DNS）证明了其在发现新bug方面的有效性。此外，该方法超越了传统的边界值分析，展现了LLM在复杂软件测试领域的巨大潜力。未来的代理AI集成将进一步提升其自动化程度和应用范围。"}}
{"id": "2507.11818", "title": "SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling", "authors": ["Andrei Rekesh", "Miruna Cretu", "Dmytro Shevchuk", "Vignesh Ram Somnath", "Pietro Liò", "Robert A. Batey", "Mike Tyers", "Michał Koziarski", "Cheng-Hao Liu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11818v1", "summary": "Ensuring synthesizability in generative small molecule design remains a major\nchallenge. While recent developments in synthesizable molecule generation have\ndemonstrated promising results, these efforts have been largely confined to 2D\nmolecular graph representations, limiting the ability to perform geometry-based\nconditional generation. In this work, we present SynCoGen (Synthesizable\nCo-Generation), a single framework that combines simultaneous masked graph\ndiffusion and flow matching for synthesizable 3D molecule generation. SynCoGen\nsamples from the joint distribution of molecular building blocks, chemical\nreactions, and atomic coordinates. To train the model, we curated SynSpace, a\ndataset containing over 600K synthesis-aware building block graphs and 3.3M\nconformers. SynCoGen achieves state-of-the-art performance in unconditional\nsmall molecule graph and conformer generation, and the model delivers\ncompetitive performance in zero-shot molecular linker design for protein ligand\ngeneration in drug discovery. Overall, this multimodal formulation represents a\nfoundation for future applications enabled by non-autoregressive molecular\ngeneration, including analog expansion, lead optimization, and direct structure\nconditioning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11818v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "SynCoGen：通过联合反应和坐标建模实现可合成三维分子生成", "tldr": "SynCoGen是一个新框架，结合掩码图扩散和流匹配，用于生成可合成的三维分子，并在小分子图和构象生成方面取得了最先进的性能。", "motivation": "现有可合成分子生成方法主要局限于二维分子图表示，限制了几何条件生成的能力，而确保生成小分子的可合成性仍是一个重大挑战。", "method": "SynCoGen是一个单一框架，结合了同时掩码图扩散和流匹配，用于可合成三维分子生成。它从分子构建块、化学反应和原子坐标的联合分布中采样。为此，作者还整理了一个名为SynSpace的数据集，包含超过60万个合成感知构建块图和330万个构象异构体。", "result": "SynCoGen在无条件小分子图和构象生成方面取得了最先进的性能，并在药物发现中用于蛋白质配体生成的零样本分子连接器设计方面表现出竞争力。", "conclusion": "这种多模态公式为未来非自回归分子生成所支持的应用（包括类似物扩展、先导优化和直接结构条件化）奠定了基础。", "translation": "确保生成的小分子设计具有可合成性仍然是一个重大挑战。尽管最近在可合成分子生成方面取得了有前景的进展，但这些努力主要局限于二维分子图表示，这限制了几何条件生成的能力。在这项工作中，我们提出了SynCoGen（可合成协同生成），这是一个单一框架，结合了同时掩码图扩散和流匹配，用于可合成三维分子生成。SynCoGen从分子构建块、化学反应和原子坐标的联合分布中采样。为了训练模型，我们整理了SynSpace数据集，其中包含超过60万个合成感知构建块图和330万个构象异构体。SynCoGen在无条件小分子图和构象异构体生成方面取得了最先进的性能，并且该模型在药物发现中用于蛋白质配体生成的零样本分子连接器设计方面表现出竞争力。总的来说，这种多模态公式为未来非自回归分子生成所支持的应用（包括类似物扩展、先导优化和直接结构条件化）奠定了基础。", "summary": "SynCoGen是一个新颖的框架，旨在解决现有可合成分子生成方法仅限于2D表示的局限性。它通过结合掩码图扩散和流匹配，实现了可合成三维分子的联合反应和坐标建模生成。为了训练模型，研究人员构建了SynSpace数据集。SynCoGen在无条件小分子图和构象生成上达到了最先进的性能，并在零样本分子连接器设计方面表现出色，为未来的药物发现应用奠定了基础。", "keywords": "三维分子生成, 可合成性, 图扩散, 流匹配, 药物发现", "comments": "SynCoGen的创新之处在于其将3D分子生成与可合成性相结合，并通过联合建模反应和坐标来解决2D表示的限制。其多模态方法和新数据集SynSpace的构建对于推动药物发现领域的分子设计具有重要意义。"}}
{"id": "2507.12187", "title": "Learning, fast and slow: a two-fold algorithm for data-based model adaptation", "authors": ["Laura Boca de Giuli", "Alessio La Bella", "Riccardo Scattolini"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12187v1", "summary": "This article addresses the challenge of adapting data-based models over time.\nWe propose a novel two-fold modelling architecture designed to correct\nplant-model mismatch caused by two types of uncertainty. Out-of-domain\nuncertainty arises when the system operates under conditions not represented in\nthe initial training dataset, while in-domain uncertainty results from\nreal-world variability and flaws in the model structure or training process. To\nhandle out-of-domain uncertainty, a slow learning component, inspired by the\nhuman brain's slow thinking process, learns system dynamics under unexplored\noperating conditions, and it is activated only when a monitoring strategy deems\nit necessary. This component consists of an ensemble of models, featuring (i) a\ncombination rule that weights individual models based on the statistical\nproximity between their training data and the current operating condition, and\n(ii) a monitoring algorithm based on statistical control charts that supervises\nthe ensemble's reliability and triggers the offline training and integration of\na new model when a new operating condition is detected. To address in-domain\nuncertainty, a fast learning component, inspired by the human brain's fast\nthinking process, continuously compensates in real time for the mismatch of the\nslow learning model. This component is implemented as a Gaussian process (GP)\nmodel, trained online at each iteration using recent data while discarding\nolder samples. The proposed methodology is tested on a benchmark energy system\nreferenced in the literature, demonstrating that the combined use of slow and\nfast learning components improves model accuracy compared to standard\nadaptation approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12187v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "快慢学习：一种用于数据驱动模型自适应的双重算法", "tldr": "本文提出了一种受人脑快慢思维启发的新型双重建模架构，用于校正数据驱动模型随时间推移引起的模型-实际系统失配，通过结合慢速学习（处理域外不确定性）和快速学习（处理域内不确定性），显著提高了模型精度。", "motivation": "本文旨在解决数据驱动模型随时间推移的自适应挑战，特别是由于域外不确定性（系统在初始训练数据未涵盖的条件下运行）和域内不确定性（现实世界变异性或模型结构/训练过程缺陷）引起的实际系统与模型之间的失配问题。", "method": "本研究提出了一种双重建模架构。慢速学习组件（受人脑慢速思维启发）用于处理域外不确定性，它包含一个模型集成，其组合规则根据训练数据与当前操作条件的统计接近度加权个体模型，并使用基于统计控制图的监控算法在检测到新操作条件时触发离线训练和新模型集成。快速学习组件（受人脑快速思维启发）用于处理域内不确定性，它作为高斯过程（GP）模型实现，使用最新数据在线训练并丢弃旧样本，实时补偿慢速学习模型的失配。", "result": "该方法在一个文献中引用的基准能源系统上进行了测试，结果表明，结合使用慢速和快速学习组件比标准自适应方法提高了模型精度。", "conclusion": "结合慢速和快速学习组件的策略能够有效提高数据驱动模型的自适应能力和精度，尤其是在应对不同类型的不确定性时表现出优越性。", "translation": "本文解决了数据驱动模型随时间自适应的挑战。我们提出了一种新颖的双重建模架构，旨在纠正由两种类型不确定性引起的实际系统与模型之间的失配。当系统在初始训练数据中未表示的条件下运行时，会出现域外不确定性；而域内不确定性则源于现实世界的变异性以及模型结构或训练过程中的缺陷。为了处理域外不确定性，一个受人脑慢速思维过程启发的慢速学习组件，学习未探索操作条件下的系统动力学，并且仅当监控策略认为必要时才激活。该组件包含一个模型集成，其特点是：(i) 一种组合规则，根据其训练数据与当前操作条件之间的统计接近度来加权单个模型；(ii) 一种基于统计控制图的监控算法，用于监督集成的可靠性，并在检测到新的操作条件时触发新模型的离线训练和集成。为了解决域内不确定性，一个受人脑快速思维过程启发的快速学习组件，持续实时补偿慢速学习模型的失配。该组件实现为一个高斯过程（GP）模型，在每次迭代中使用最新数据进行在线训练，同时丢弃较旧的样本。所提出的方法在一个文献中引用的基准能源系统上进行了测试，结果表明，结合使用慢速和快速学习组件比标准自适应方法提高了模型精度。", "summary": "本文提出了一种受人脑快慢思维过程启发的双重建模算法，旨在解决数据驱动模型在长期运行中面临的两种不确定性：域外不确定性（新操作条件）和域内不确定性（模型结构或数据变异性）。慢速学习组件通过一个模型集成和监控策略处理域外不确定性，在必要时触发新模型训练；快速学习组件则通过在线训练的高斯过程模型实时补偿域内不确定性。在基准能源系统上的测试表明，该快慢结合的方法显著提升了模型精度，优于传统自适应方法。", "keywords": "模型自适应, 快慢学习, 域外不确定性, 域内不确定性, 高斯过程", "comments": "该论文的创新之处在于其受人脑思维过程启发的双重学习架构，将慢速、全局适应与快速、局部补偿相结合，有效应对了数据驱动模型在动态环境下的复杂挑战。这种将不同时间尺度学习策略结合的方法，为模型自适应领域提供了新的思路，尤其是在处理不同来源不确定性方面具有重要意义。"}}
{"id": "2011.10672", "title": "Artificial Intelligence Governance for Businesses", "authors": ["Johannes Schneider", "Rene Abraham", "Christian Meske", "Jan vom Brocke"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2011.10672v3", "summary": "Artificial Intelligence (AI) governance regulates the exercise of authority\nand control over the management of AI. It aims at leveraging AI through\neffective use of data and minimization of AI-related cost and risk. While\ntopics such as AI governance and AI ethics are thoroughly discussed on a\ntheoretical, philosophical, societal and regulatory level, there is limited\nwork on AI governance targeted to companies and corporations. This work views\nAI products as systems, where key functionality is delivered by machine\nlearning (ML) models leveraging (training) data. We derive a conceptual\nframework by synthesizing literature on AI and related fields such as ML. Our\nframework decomposes AI governance into governance of data, (ML) models and\n(AI) systems along four dimensions. It relates to existing IT and data\ngovernance frameworks and practices. It can be adopted by practitioners and\nacademics alike. For practitioners the synthesis of mainly research papers, but\nalso practitioner publications and publications of regulatory bodies provides a\nvaluable starting point to implement AI governance, while for academics the\npaper highlights a number of areas of AI governance that deserve more\nattention.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2011.10672v3", "cate": "cs.AI", "date": "2020-11-20", "updated": "2025-07-16", "AI": {"title_translation": "商业人工智能治理", "tldr": "本文提出了一个针对企业的人工智能治理概念框架，通过综合现有文献，将AI治理分解为数据、模型和系统治理，以填补企业级AI治理研究的空白。", "motivation": "尽管AI治理在理论、哲学、社会和监管层面已有充分讨论，但针对企业和公司的人工智能治理研究工作有限。", "method": "通过综合人工智能和机器学习等相关领域的文献，推导出一个概念框架。该框架将人工智能产品视为系统，其核心功能由利用训练数据的机器学习模型提供。", "result": "提出了一个将AI治理分解为数据、(ML)模型和(AI)系统治理的四维度概念框架。该框架与现有的IT和数据治理框架及实践相关联。", "conclusion": "该框架为实践者实施AI治理提供了宝贵的起点，并为学术界指出了AI治理中值得更多关注的领域。", "translation": "人工智能（AI）治理规范了对AI管理的权力行使和控制。它旨在通过有效利用数据和最小化AI相关成本和风险来发挥AI的优势。虽然AI治理和AI伦理等话题在理论、哲学、社会和监管层面已得到充分讨论，但针对公司和企业的人工智能治理工作有限。这项工作将AI产品视为系统，其关键功能由利用（训练）数据的机器学习（ML）模型提供。我们通过综合AI和ML等相关领域的文献，推导出了一个概念框架。我们的框架将AI治理分解为数据、（ML）模型和（AI）系统的治理，并从四个维度进行。它与现有的IT和数据治理框架及实践相关。它可供实践者和学者采用。对于实践者而言，这项主要综合了研究论文、实践者出版物以及监管机构出版物的工作，为实施AI治理提供了一个有价值的起点；而对于学者而言，本文则强调了AI治理中一些值得更多关注的领域。", "summary": "本文针对企业和公司在人工智能治理方面研究不足的现状，提出了一个概念框架。该框架通过综合人工智能和机器学习领域的文献而得，将人工智能治理分解为数据、机器学习模型和人工智能系统在四个维度上的治理。它与现有IT和数据治理框架相关联，旨在帮助企业有效利用AI并降低风险，同时为学术研究提供了新的方向。", "keywords": "人工智能治理, 企业, 概念框架, 数据治理, 模型治理", "comments": "本文填补了企业级AI治理研究的空白，提出一个实用的概念框架，对于指导企业实施AI治理具有重要意义。其通过文献综合的方法构建框架，并明确了对实践者和学者的价值，结构清晰。"}}
{"id": "2505.23836", "title": "Large Language Models Often Know When They Are Being Evaluated", "authors": ["Joe Needham", "Giles Edkins", "Govind Pimpale", "Henning Bartsch", "Marius Hobbhahn"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.23836v3", "summary": "If AI models can detect when they are being evaluated, the effectiveness of\nevaluations might be compromised. For example, models could have systematically\ndifferent behavior during evaluations, leading to less reliable benchmarks for\ndeployment and governance decisions. We investigate whether frontier language\nmodels can accurately classify transcripts based on whether they originate from\nevaluations or real-world deployment, a capability we call evaluation\nawareness. To achieve this, we construct a diverse benchmark of 1,000 prompts\nand transcripts from 61 distinct datasets. These span public benchmarks (e.g.,\nMMLU, SWEBench), real-world deployment interactions, and agent trajectories\nfrom scaffolding frameworks (e.g., web-browsing agents). Frontier models\nclearly demonstrate above-random evaluation awareness (Gemini-2.5-Pro reaches\nan AUC of $0.83$), but do not yet surpass our simple human baseline (AUC of\n$0.92$). Furthermore, both AI models and humans are better at identifying\nevaluations in agentic settings compared to chat settings. Additionally, we\ntest whether models can identify the purpose of the evaluation. Under\nmultiple-choice and open-ended questioning, AI models far outperform random\nchance in identifying what an evaluation is testing for. Our results indicate\nthat frontier models already exhibit a substantial, though not yet superhuman,\nlevel of evaluation-awareness. We recommend tracking this capability in future\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.23836v3", "cate": "cs.CL", "date": "2025-05-28", "updated": "2025-07-16", "AI": {"title_translation": "大型语言模型通常知道自己何时被评估", "tldr": "大型语言模型（LLMs）能够检测自己何时正在被评估，这可能影响评估的有效性。研究发现前沿LLMs具有显著的评估意识，但尚未超越人类基线。", "motivation": "如果AI模型能够检测到自己何时被评估，可能会导致其在评估期间表现出系统性差异行为，从而降低基准测试的可靠性，进而影响部署和治理决策的有效性。", "method": "研究构建了一个包含来自61个不同数据集的1,000个提示和对话记录的基准，涵盖了公共基准测试（如MMLU, SWEBench）、真实世界部署交互以及来自代理框架（如网络浏览代理）的代理轨迹。研究人员调查了前沿语言模型是否能准确地将对话记录分类为来自评估或真实世界部署，并测试了模型识别评估目的的能力。", "result": "前沿模型表现出明显高于随机水平的评估意识（Gemini-2.5-Pro的AUC达到0.83），但尚未超越简单的人类基线（AUC为0.92）。AI模型和人类在代理设置中识别评估的能力优于聊天设置。AI模型在多项选择和开放式问题中识别评估目的的能力远超随机。", "conclusion": "前沿模型已经表现出显著的评估意识，尽管尚未达到超人水平。建议在未来的模型中持续追踪这种能力，因为它可能影响评估的有效性。", "translation": "如果AI模型能够检测到自己何时正在被评估，评估的有效性可能会受到影响。例如，模型在评估期间可能会表现出系统性差异行为，导致部署和治理决策的基准测试可靠性降低。我们调查了前沿语言模型是否能够根据对话记录是否源自评估或真实世界部署进行准确分类，我们称之为评估意识。为了实现这一点，我们构建了一个包含来自61个不同数据集的1000个提示和对话记录的多样化基准。这些数据集涵盖了公共基准测试（例如MMLU、SWEBench）、真实世界部署交互以及来自脚手架框架（例如网络浏览代理）的代理轨迹。前沿模型清楚地展示了高于随机水平的评估意识（Gemini-2.5-Pro的AUC达到了0.83），但尚未超越我们简单的人类基线（AUC为0.92）。此外，无论是AI模型还是人类，在代理设置中识别评估的能力都优于聊天设置。此外，我们测试了模型是否能够识别评估的目的。在多项选择题和开放式问题中，AI模型在识别评估测试内容方面远远优于随机猜测。我们的结果表明，前沿模型已经表现出相当大的、尽管尚未达到超人水平的评估意识。我们建议在未来的模型中追踪这种能力。", "summary": "本研究调查了大型语言模型（LLMs）是否具有“评估意识”，即它们能否识别出自己何时正在被评估。通过构建一个包含来自多样化数据集的1000个提示和对话记录的基准，研究发现前沿LLMs（如Gemini-2.5-Pro）表现出显著高于随机水平的评估意识（AUC 0.83），尽管尚未超越人类基线（AUC 0.92）。研究还发现，模型和人类在代理设置中识别评估的能力更强，且模型能远超随机地识别评估目的。结果表明，当前LLMs已具备相当程度的评估意识，这提示未来模型开发需关注并追踪此能力，以确保评估的可靠性。", "keywords": "大型语言模型, 评估意识, 基准测试, 模型行为, AI安全", "comments": "这项研究揭示了前沿大型语言模型的一个重要且令人担忧的能力——“评估意识”。其创新之处在于首次系统性地构建基准来量化这一能力，并将其与人类表现进行对比。研究的重要性在于，如果模型能够感知到评估环境，其在基准测试中的表现可能无法真实反映其在实际部署中的行为，从而影响AI治理和安全决策。这提出了对现有评估方法有效性的挑战，并强调了开发更鲁棒、难以被模型察觉的评估策略的必要性。未来研究应探索如何设计“评估盲”的测试方法。"}}
{"id": "2507.11550", "title": "Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction", "authors": ["Hyeonseok Jin", "Geonmin Kim", "Kyungbaek Kim"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2507.11550v1", "summary": "Spatio-temporal traffic prediction plays a key role in intelligent\ntransportation systems by enabling accurate prediction in complex urban areas.\nAlthough not only accuracy but also efficiency for scalability is important,\nsome previous methods struggle to capture heterogeneity such as varying traffic\npatterns across regions and time periods. Moreover, Graph Neural Networks\n(GNNs), which are the mainstream of traffic prediction, not only require\npredefined adjacency matrix, but also limit scalability to large-scale data\ncontaining many nodes due to their inherent complexity. To overcome these\nlimitations, we propose Deformable Dynamic Convolution Network (DDCN) for\naccurate yet efficient traffic prediction. Traditional Convolutional Neural\nNetworks (CNNs) are limited in modeling non-Euclidean spatial structures and\nspatio-temporal heterogeneity, DDCN overcomes these challenges by dynamically\napplying deformable filters based on offset. Specifically, DDCN decomposes\ntransformer-style CNN to encoder-decoder structure, and applies proposed\napproaches to the spatial and spatio-temporal attention blocks of the encoder\nto emphasize important features. The decoder, composed of feed-forward module,\ncomplements the output of the encoder. This novel structure make DDCN can\nperform accurate yet efficient traffic prediction. In comprehensive experiments\non four real-world datasets, DDCN achieves competitive performance, emphasizing\nthe potential and effectiveness of CNN-based approaches for spatio-temporal\ntraffic prediction.", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2507.11550v1", "cate": "cs.CV", "date": "2025-07-13", "updated": "2025-07-13", "AI": {"title_translation": "用于准确高效时空交通预测的可变形动态卷积", "tldr": "本文提出了一种名为可变形动态卷积网络（DDCN）的新型CNN模型，用于解决传统方法在时空交通预测中存在的准确性、效率和可扩展性问题。", "motivation": "当前的时空交通预测方法在捕捉区域和时间段内变化的交通模式等异质性方面存在不足，同时，主流的图神经网络（GNNs）需要预定义邻接矩阵，且在大规模数据上存在可扩展性限制。为了在保证准确性的同时提高效率和可扩展性，本文提出了新的方法。", "method": "本文提出了可变形动态卷积网络（DDCN）。DDCN通过基于偏移量动态应用可变形滤波器，克服了传统卷积神经网络（CNNs）在建模非欧几里得空间结构和时空异质性方面的局限。具体来说，DDCN将Transformer风格的CNN分解为编码器-解码器结构，并将提出的方法应用于编码器的空间和时空注意力块，以强调重要特征。解码器由前馈模块组成，补充编码器的输出。", "result": "在四个真实世界数据集上的综合实验表明，DDCN取得了具有竞争力的性能。", "conclusion": "DDCN在时空交通预测方面表现出准确性和效率，强调了基于CNN的方法在该领域的潜力和有效性。", "translation": "时空交通预测通过在复杂的城市区域实现准确预测，在智能交通系统中发挥着关键作用。尽管准确性和可扩展性效率都很重要，但一些先前的方法难以捕捉区域和时间段内变化的交通模式等异质性。此外，图神经网络（GNNs）作为交通预测的主流，不仅需要预定义的邻接矩阵，而且由于其固有的复杂性，限制了对包含许多节点的大规模数据的可扩展性。为了克服这些限制，我们提出了可变形动态卷积网络（DDCN），用于准确而高效的交通预测。传统的卷积神经网络（CNNs）在建模非欧几里得空间结构和时空异质性方面存在局限性，DDCN通过基于偏移量动态应用可变形滤波器来克服这些挑战。具体来说，DDCN将Transformer风格的CNN分解为编码器-解码器结构，并将提出的方法应用于编码器的空间和时空注意力块，以强调重要特征。由前馈模块组成的解码器补充了编码器的输出。这种新颖的结构使DDCN能够进行准确而高效的交通预测。在四个真实世界数据集上的综合实验中，DDCN取得了具有竞争力的性能，强调了基于CNN的方法在时空交通预测方面的潜力和有效性。", "summary": "本文提出了一种名为可变形动态卷积网络（DDCN）的新型CNN模型，旨在解决传统时空交通预测方法在准确性、效率和可扩展性方面的不足。DDCN通过动态应用可变形滤波器来处理空间结构和时空异质性，并采用编码器-解码器结构来增强特征学习。实验结果表明，DDCN在多个真实世界数据集上实现了有竞争力的性能，证明了CNN在时空交通预测中的潜力。", "keywords": "时空交通预测, 可变形动态卷积, 卷积神经网络, 交通流预测, 深度学习", "comments": "该论文提出了一种新颖的CNN架构，通过引入可变形动态卷积来克服传统CNN在处理非欧几里得空间结构和时空异质性方面的局限性。其创新之处在于将Transformer风格的CNN分解为编码器-解码器，并利用可变形滤波器来增强特征提取，从而在保证准确性的同时提高了效率和可扩展性，这对于大规模交通预测系统具有重要意义。"}}
{"id": "2507.12370", "title": "Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate", "authors": ["Ana Davila", "Jacinto Colan", "Yasuhisa Hasegawa"], "categories": ["cs.CL", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at the 2025 SICE Festival with Annual Conference (SICE FES)", "url": "http://arxiv.org/abs/2507.12370v1", "summary": "Large Language Models (LLMs) have demonstrated significant capabilities in\nunderstanding and generating human language, contributing to more natural\ninteractions with complex systems. However, they face challenges such as\nambiguity in user requests processed by LLMs. To address these challenges, this\npaper introduces and evaluates a multi-agent debate framework designed to\nenhance detection and resolution capabilities beyond single models. The\nframework consists of three LLM architectures (Llama3-8B, Gemma2-9B, and\nMistral-7B variants) and a dataset with diverse ambiguities. The debate\nframework markedly enhanced the performance of Llama3-8B and Mistral-7B\nvariants over their individual baselines, with Mistral-7B-led debates achieving\na notable 76.7% success rate and proving particularly effective for complex\nambiguities and efficient consensus. While acknowledging varying model\nresponses to collaborative strategies, these findings underscore the debate\nframework's value as a targeted method for augmenting LLM capabilities. This\nwork offers important insights for developing more robust and adaptive language\nunderstanding systems by showing how structured debates can lead to improved\nclarity in interactive systems.", "comment": "Accepted at the 2025 SICE Festival with Annual Conference (SICE FES)", "pdf_url": "http://arxiv.org/pdf/2507.12370v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "超越单一模型：通过辩论增强LLM对请求歧义的检测", "tldr": "本文提出并评估了一个多智能体辩论框架，用于增强LLM对用户请求中歧义的检测和解决能力，实验表明其显著提升了LLM的表现，尤其对复杂歧义有效。", "motivation": "尽管大型语言模型（LLMs）在理解和生成人类语言方面表现出色，但它们在处理用户请求中的歧义时面临挑战。", "method": "本文引入并评估了一个多智能体辩论框架，旨在增强LLM检测和解决歧义的能力，超越单一模型。该框架包含三种LLM架构（Llama3-8B, Gemma2-9B, Mistral-7B变体）和一个包含多样化歧义的数据集。", "result": "辩论框架显著提升了Llama3-8B和Mistral-7B变体相对于其单独基线的性能。其中，以Mistral-7B为主导的辩论达到了76.7%的成功率，并且在处理复杂歧义和高效达成共识方面表现尤为出色。", "conclusion": "研究结果强调了辩论框架作为一种增强LLM能力的有针对性方法的价值。通过展示结构化辩论如何提高交互系统中的清晰度，这项工作为开发更健壮和自适应的语言理解系统提供了重要见解。", "translation": "大型语言模型（LLMs）在理解和生成人类语言方面展现出显著能力，有助于与复杂系统进行更自然的交互。然而，它们面临着诸如LLMs处理的用户请求中的歧义等挑战。为了解决这些挑战，本文引入并评估了一个多智能体辩论框架，旨在增强超越单一模型的检测和解决能力。该框架由三种LLM架构（Llama3-8B、Gemma2-9B和Mistral-7B变体）以及一个包含多样化歧义的数据集组成。该辩论框架显著提升了Llama3-8B和Mistral-7B变体相对于其单独基线的性能，其中Mistral-7B主导的辩论达到了76.7%的显著成功率，并被证明对复杂歧义和高效共识特别有效。尽管承认不同模型对协作策略的反应各异，但这些发现强调了辩论框架作为一种增强LLM能力的有针对性方法的价值。这项工作通过展示结构化辩论如何提高交互系统中的清晰度，为开发更健壮和自适应的语言理解系统提供了重要见解。", "summary": "本文提出并评估了一个多智能体辩论框架，以解决大型语言模型（LLMs）在处理用户请求中歧义的挑战。该框架利用Llama3-8B、Gemma2-9B和Mistral-7B等多种LLM变体进行辩论，并使用包含多样化歧义的数据集进行测试。结果显示，该辩论框架显著提升了LLMs（特别是Llama3-8B和Mistral-7B）检测和解决歧义的能力，其中Mistral-7B主导的辩论表现最佳，成功率达76.7%，尤其对复杂歧义有效。研究强调了该框架对于构建更健壮、自适应语言理解系统的重要性。", "keywords": "大型语言模型, 歧义检测, 多智能体系统, 辩论框架, 自然语言理解", "comments": "本文的创新之处在于引入了多智能体辩论框架来解决LLM处理用户请求中歧义的问题，这超越了传统单一模型的局限。通过模拟人类辩论过程，该方法有效提升了LLM的歧义检测和解决能力，尤其是在复杂场景下表现突出。这为未来开发更具鲁棒性和适应性的语言理解系统提供了新思路。"}}
{"id": "2507.12132", "title": "DoRF: Doppler Radiance Fields for Robust Human Activity Recognition Using Wi-Fi", "authors": ["Navid Hasanzadeh", "Shahrokh Valaee"], "categories": ["eess.SP", "cs.CV"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12132v1", "summary": "Wi-Fi Channel State Information (CSI) has gained increasing interest for\nremote sensing applications. Recent studies show that Doppler velocity\nprojections extracted from CSI can enable human activity recognition (HAR) that\nis robust to environmental changes and generalizes to new users. However,\ndespite these advances, generalizability still remains insufficient for\npractical deployment. Inspired by neural radiance fields (NeRF), which learn a\nvolumetric representation of a 3D scene from 2D images, this work proposes a\nnovel approach to reconstruct an informative 3D latent motion representation\nfrom one-dimensional Doppler velocity projections extracted from Wi-Fi CSI. The\nresulting latent representation is then used to construct a uniform Doppler\nradiance field (DoRF) of the motion, providing a comprehensive view of the\nperformed activity and improving the robustness to environmental variability.\nThe results show that the proposed approach noticeably enhances the\ngeneralization accuracy of Wi-Fi-based HAR, highlighting the strong potential\nof DoRFs for practical sensing applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12132v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "DoRF：用于Wi-Fi鲁棒人体活动识别的多普勒辐射场", "tldr": "本文提出DoRF，一种基于Wi-Fi CSI多普勒速度投影来构建多普勒辐射场的方法，显著提高了Wi-Fi人体活动识别的泛化能力。", "motivation": "尽管Wi-Fi CSI在人体活动识别（HAR）方面取得了进展，但其泛化能力对于实际部署仍然不足。", "method": "受神经辐射场（NeRF）启发，本文提出一种新方法，从Wi-Fi CSI提取的一维多普勒速度投影中重建信息丰富的3D潜在运动表示。然后，利用该潜在表示构建运动的统一多普勒辐射场（DoRF）。", "result": "结果表明，所提出的方法显著提高了基于Wi-Fi的HAR的泛化精度。", "conclusion": "DoRF在基于Wi-Fi的人体活动识别中表现出强大的潜力，显著增强了泛化能力，使其适用于实际传感应用。", "translation": "Wi-Fi信道状态信息（CSI）在远程传感应用中引起了越来越多的关注。最近的研究表明，从CSI中提取的多普勒速度投影可以实现对环境变化具有鲁棒性并能泛化到新用户的人体活动识别（HAR）。然而，尽管取得了这些进展，泛化能力对于实际部署仍然不足。受神经辐射场（NeRF）的启发，该研究提出了一种新颖的方法，从从Wi-Fi CSI中提取的一维多普勒速度投影中重建信息丰富的3D潜在运动表示。然后，利用由此产生的潜在表示构建运动的统一多普勒辐射场（DoRF），从而提供对所执行活动的全面视图，并提高对环境变异性的鲁棒性。结果表明，所提出的方法显著增强了基于Wi-Fi的HAR的泛化精度，突出了DoRF在实际传感应用中的巨大潜力。", "summary": "本文提出DoRF（多普勒辐射场），一种受NeRF启发的Wi-Fi人体活动识别新方法。该方法从Wi-Fi CSI的多普勒速度投影中重建3D潜在运动表示，并构建多普勒辐射场，以提高对环境变化的鲁棒性和泛化能力。实验结果表明，DoRF显著提升了Wi-Fi HAR的泛化精度。", "keywords": "Wi-Fi传感, 人体活动识别, 多普勒辐射场, CSI, 泛化能力", "comments": "该论文的创新点在于将神经辐射场的概念引入到Wi-Fi传感领域，通过构建多普勒辐射场来解决Wi-Fi人体活动识别中泛化能力不足的问题。这种将3D表示应用于一维多普勒数据的方法具有很强的开创性，并有望推动Wi-Fi传感技术在实际应用中的部署。"}}
{"id": "2507.11780", "title": "Inference on Optimal Policy Values and Other Irregular Functionals via Smoothing", "authors": ["Justin Whitehouse", "Morgane Austern", "Vasilis Syrgkanis"], "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "Subjects:       Econometrics (econ.EM)", "pdf_link": null, "comments": "Comments:      40 pages, 2 figures", "url": "http://arxiv.org/abs/2507.11780v1", "summary": "Constructing confidence intervals for the value of an optimal treatment\npolicy is an important problem in causal inference. Insight into the optimal\npolicy value can guide the development of reward-maximizing, individualized\ntreatment regimes. However, because the functional that defines the optimal\nvalue is non-differentiable, standard semi-parametric approaches for performing\ninference fail to be directly applicable. Existing approaches for handling this\nnon-differentiability fall roughly into two camps. In one camp are estimators\nbased on constructing smooth approximations of the optimal value. These\napproaches are computationally lightweight, but typically place unrealistic\nparametric assumptions on outcome regressions. In another camp are approaches\nthat directly de-bias the non-smooth objective. These approaches don't place\nparametric assumptions on nuisance functions, but they either require the\ncomputation of intractably-many nuisance estimates, assume unrealistic\n$L^\\infty$ nuisance convergence rates, or make strong margin assumptions that\nprohibit non-response to a treatment. In this paper, we revisit the problem of\nconstructing smooth approximations of non-differentiable functionals. By\ncarefully controlling first-order bias and second-order remainders, we show\nthat a softmax smoothing-based estimator can be used to estimate parameters\nthat are specified as a maximum of scores involving nuisance components. In\nparticular, this includes the value of the optimal treatment policy as a\nspecial case. Our estimator obtains $\\sqrt{n}$ convergence rates, avoids\nparametric restrictions/unrealistic margin assumptions, and is often\nstatistically efficient.", "comment": "40 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.11780v1", "cate": "econ.EM", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "通过平滑对最优策略值及其他不规则泛函的推断", "tldr": "本文提出了一种基于softmax平滑的估计器，用于最优策略值和其他不规则泛函的推断，实现了根号n收敛速度并避免了强假设。", "motivation": "在因果推断中，为最优治疗策略值构建置信区间是一个重要问题。然而，定义最优值的泛函是不可微分的，导致标准半参数方法无法直接应用。现有方法要么施加不切实际的参数假设，要么存在计算量大、收敛速度假设不切实际或边缘假设过强等局限性。", "method": "本文重新审视了不可微分泛函的平滑近似问题，提出了一种基于softmax平滑的估计器。通过仔细控制一阶偏差和二阶余项，该估计器可用于估计定义为涉及冗余分量的分数最大值的参数，其中最优治疗策略值是特例。", "result": "我们的估计器获得了$\\\\sqrt{n}$收敛速度，避免了参数限制和不切实际的边缘假设，并且通常在统计上是高效的。", "conclusion": "本文通过精心应用softmax平滑，成功开发了一种对最优策略值及类似不规则泛函进行推断的鲁棒且高效的方法，克服了以往方法的局限性。", "translation": "构建最优治疗策略值的置信区间是因果推断中的一个重要问题。对最优策略值的深入了解可以指导奖励最大化、个体化治疗方案的开发。然而，由于定义最优值的泛函是不可微分的，标准的半参数推断方法无法直接适用。处理这种不可微分性的现有方法大致分为两类。一类是基于构建最优值平滑近似的估计器。这些方法计算量小，但通常对结果回归施加不切实际的参数假设。另一类是直接对非平滑目标进行去偏的方法。这些方法不对冗余函数施加参数假设，但它们要么需要计算难以处理的冗余估计，要么假设不切实际的$L^\\\\infty$冗余收敛速度，要么做出强边缘假设，从而禁止对治疗无反应。在本文中，我们重新审视了构建不可微分泛函平滑近似的问题。通过仔细控制一阶偏差和二阶余项，我们表明基于softmax平滑的估计器可用于估计指定为涉及冗余分量的分数最大值的参数。特别是，这包括最优治疗策略值作为特例。我们的估计器获得了$\\\\sqrt{n}$收敛速度，避免了参数限制/不切实际的边缘假设，并且通常在统计上是高效的。", "summary": "本文解决了因果推断中为最优治疗策略值构建置信区间的挑战，该问题因其定义泛函的不可微分性而复杂化。现有方法要么需要强参数假设，要么存在计算/理论局限性。作者提出了一种新颖的基于softmax平滑的估计器，通过仔细控制偏差，能够估计指定为分数最大值的参数，包括最优策略值。这种新估计器实现了根号n收敛速度，避免了限制性假设，并且通常在统计上是高效的，为不规则泛函的推断提供了一个鲁棒的解决方案。", "keywords": "最优策略值, 因果推断, 平滑, 不可微分泛函, Softmax估计器", "comments": "本文通过提供一种对最优策略值进行推断的鲁棒方法，在因果推断领域取得了显著进展，该方法避免了以往基于平滑方法中常见的不切实际假设，以及去偏方法中的计算负担或强理论假设。在softmax平滑方法中对偏差和余项的仔细控制是其主要创新点。"}}
{"id": "2504.07618", "title": "CTSR: Cartesian tensor-based sparse regression for data-driven discovery of high-dimensional invariant governing equations", "authors": ["Boqian Zhang", "Juanmian Lei", "Guoyou Sun", "Shuaibing Ding", "Jian Guo"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.07618v2", "summary": "Accurate and concise governing equations are crucial for understanding system\ndynamics. Recently, data-driven methods such as sparse regression have been\nemployed to automatically uncover governing equations from data, representing a\nsignificant shift from traditional first-principles modeling. However, most\nexisting methods focus on scalar equations, limiting their applicability to\nsimple, low-dimensional scenarios, and failing to ensure rotation and\nreflection invariance without incurring significant computational cost or\nrequiring additional prior knowledge. This paper proposes a Cartesian\ntensor-based sparse regression (CTSR) technique to accurately and efficiently\nuncover complex, high-dimensional governing equations while ensuring\ninvariance. Evaluations on two two-dimensional (2D) and two three-dimensional\n(3D) test cases demonstrate that the proposed method achieves superior accuracy\nand efficiency compared to the conventional technique.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.07618v2", "cate": "cs.LG", "date": "2025-04-10", "updated": "2025-07-16", "AI": {"title_translation": "CTSR：基于笛卡尔张量的稀疏回归用于高维不变控制方程的数据驱动发现", "tldr": "CTSR提出了一种基于笛卡尔张量的稀疏回归方法，用于从数据中准确高效地发现高维不变控制方程，克服了现有方法在处理复杂、高维系统和确保不变性方面的局限性。", "motivation": "现有数据驱动的稀疏回归方法在发现控制方程时，主要集中于标量方程，限制了其在简单、低维场景的应用，并且在不显著增加计算成本或额外先验知识的情况下，难以确保旋转和反射不变性。", "method": "本文提出了一种基于笛卡尔张量的稀疏回归（CTSR）技术，旨在准确高效地发现复杂、高维的控制方程，同时确保不变性。", "result": "通过在两个二维（2D）和两个三维（3D）测试案例上的评估表明，所提出的CTSR方法与传统技术相比，实现了更高的准确性和效率。", "conclusion": "CTSR方法能够准确高效地从数据中发现复杂、高维的控制方程，并有效确保方程的旋转和反射不变性，优于现有方法。", "translation": "准确简洁的控制方程对于理解系统动力学至关重要。最近，稀疏回归等数据驱动方法已被用于从数据中自动发现控制方程，这代表了传统第一性原理建模的重大转变。然而，大多数现有方法侧重于标量方程，限制了其在简单、低维场景中的适用性，并且在不产生显著计算成本或需要额外先验知识的情况下，未能确保旋转和反射不变性。本文提出了一种基于笛卡尔张量的稀疏回归（CTSR）技术，以准确高效地发现复杂、高维的控制方程，同时确保不变性。在两个二维（2D）和两个三维（3D）测试案例上的评估表明，所提出的方法与传统技术相比，实现了卓越的准确性和效率。", "summary": "本文提出了一种名为CTSR（基于笛卡尔张量的稀疏回归）的数据驱动方法，旨在解决现有稀疏回归技术在发现高维、复杂系统控制方程时，因主要关注标量方程而导致的适用性受限以及难以确保旋转和反射不变性的问题。CTSR通过引入笛卡尔张量，实现了在确保不变性的同时，准确高效地从数据中发现高维控制方程。实验结果表明，该方法在二维和三维测试案例中均优于传统技术，展现出更高的准确性和效率。", "keywords": "笛卡尔张量, 稀疏回归, 控制方程, 数据驱动, 不变性", "comments": "CTSR的创新之处在于将笛卡尔张量引入稀疏回归，从而有效地解决了传统数据驱动方法在发现高维物理方程时面临的“不变性”和“计算效率”两大挑战。这对于从复杂数据中自动提取物理定律具有重要意义，尤其是在流体力学、材料科学等需要处理张量量场的领域。"}}
{"id": "2507.12063", "title": "Contrastive Cascade Graph Learning for Classifying Real and Synthetic Information Diffusion Patterns", "authors": ["Naoki Shibao", "Sho Tsugawa"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12063v1", "summary": "A wide variety of information is disseminated through social media, and\ncontent that spreads at scale can have tangible effects on the real world. To\ncurb the spread of harmful content and promote the dissemination of reliable\ninformation, research on cascade graph mining has attracted increasing\nattention. A promising approach in this area is Contrastive Cascade Graph\nLearning (CCGL). One important task in cascade graph mining is cascade\nclassification, which involves categorizing cascade graphs based on their\nstructural characteristics. Although CCGL is expected to be effective for this\ntask, its performance has not yet been thoroughly evaluated. This study aims to\ninvestigate the effectiveness of CCGL for cascade classification. Our findings\ndemonstrate the strong performance of CCGL in capturing platform- and\nmodel-specific structural patterns in cascade graphs, highlighting its\npotential for a range of downstream information diffusion analysis tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12063v1", "cate": "cs.SI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "对比级联图学习用于分类真实和合成信息扩散模式", "tldr": "本研究评估了对比级联图学习（CCGL）在级联分类任务中的有效性，发现其在识别信息扩散模式方面表现出色。", "motivation": "社交媒体上的信息传播对现实世界有重大影响，研究级联图挖掘对于遏制有害内容和促进可靠信息传播至关重要。对比级联图学习（CCGL）是一个有前景的方法，但在级联分类任务中的性能尚未得到充分评估。", "method": "本研究旨在调查对比级联图学习（CCGL）在级联分类任务中的有效性。", "result": "研究结果表明，CCGL在捕获级联图中平台和模型特定的结构模式方面表现出强大的性能。", "conclusion": "CCGL在级联分类方面表现出色，突出了其在各种下游信息扩散分析任务中的潜力。", "translation": "大量信息通过社交媒体传播，大规模传播的内容可能对现实世界产生切实影响。为了遏制有害内容的传播并促进可靠信息的传播，级联图挖掘的研究引起了越来越多的关注。对比级联图学习（CCGL）是该领域一个有前景的方法。级联图挖掘中的一个重要任务是级联分类，它涉及根据级联图的结构特征对其进行分类。尽管CCGL有望对这项任务有效，但其性能尚未得到彻底评估。本研究旨在调查CCGL在级联分类方面的有效性。我们的发现证明了CCGL在捕获级联图中平台和模型特定结构模式方面的强大性能，突出了其在各种下游信息扩散分析任务中的潜力。", "summary": "本研究评估了对比级联图学习（CCGL）在信息扩散模式级联分类任务中的有效性。研究发现，CCGL在识别平台和模型特定的级联图结构模式方面表现出强大的性能，这表明其在未来的信息扩散分析任务中具有巨大潜力。", "keywords": "对比级联图学习, 级联分类, 信息扩散, 社交媒体, 图学习", "comments": "该论文通过评估对比级联图学习（CCGL）在级联分类中的表现，填补了现有研究的空白。其重要性在于验证了一个有前景的方法在区分真实和合成信息扩散模式方面的有效性，为遏制有害信息传播提供了潜在工具。"}}
{"id": "2507.11910", "title": "SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring", "authors": ["Kaustav Chanda", "Aayush Atul Verma", "Arpitsinh Vaghela", "Yezhou Yang", "Bharatesh Chakravarthi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at the 28th IEEE International Conference on Intelligent Transportation Systems (ITSC 2025)", "url": "http://arxiv.org/abs/2507.11910v1", "summary": "Event-based sensors have emerged as a promising solution for addressing\nchallenging conditions in pedestrian and traffic monitoring systems. Their\nlow-latency and high dynamic range allow for improved response time in\nsafety-critical situations caused by distracted walking or other unusual\nmovements. However, the availability of data covering such scenarios remains\nlimited. To address this gap, we present SEPose -- a comprehensive synthetic\nevent-based human pose estimation dataset for fixed pedestrian perception\ngenerated using dynamic vision sensors in the CARLA simulator. With nearly 350K\nannotated pedestrians with body pose keypoints from the perspective of fixed\ntraffic cameras, SEPose is a comprehensive synthetic multi-person pose\nestimation dataset that spans busy and light crowds and traffic across diverse\nlighting and weather conditions in 4-way intersections in urban, suburban, and\nrural environments. We train existing state-of-the-art models such as RVT and\nYOLOv8 on our dataset and evaluate them on real event-based data to demonstrate\nthe sim-to-real generalization capabilities of the proposed dataset.", "comment": "Accepted at the 28th IEEE International Conference on Intelligent\n  Transportation Systems (ITSC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.11910v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "SEPose：一个用于行人监测的合成事件相机人体姿态估计数据集", "tldr": "SEPose是一个用于行人监测的合成事件相机人体姿态估计数据集，旨在解决数据稀缺问题并展示了其模拟到现实的泛化能力。", "motivation": "事件相机在行人及交通监控系统中具有低延迟和高动态范围的优势，但相关数据稀缺，限制了其应用。本研究旨在解决这一数据鸿沟。", "method": "提出SEPose数据集，一个在CARLA模拟器中利用动态视觉传感器生成的综合性合成事件相机人体姿态估计数据集。该数据集包含近35万个带有人体姿态关键点的行人标注，覆盖了不同光照、天气和交通条件下的城市场景。研究者使用SEPose训练了RVT和YOLOv8等现有最先进模型。", "result": "训练后的模型在真实事件相机数据上进行了评估，结果表明所提出的数据集具有良好的模拟到现实的泛化能力。", "conclusion": "SEPose数据集有效解决了事件相机人体姿态估计在行人监控领域的数据稀缺问题，并展现了强大的模拟到现实的泛化能力。", "translation": "事件相机传感器已成为解决行人与交通监控系统中挑战性条件的一种有前景的解决方案。它们的低延迟和高动态范围特性，可以在由分心行走或其他异常动作引起的安全关键情况中提高响应时间。然而，涵盖此类场景的数据可用性仍然有限。为了弥补这一空白，我们提出了SEPose——一个用于固定行人感知的综合性合成事件相机人体姿态估计数据集，该数据集使用CARLA模拟器中的动态视觉传感器生成。SEPose包含近35万个从固定交通摄像头视角标注的人体姿态关键点行人，是一个综合性的合成多人姿态估计数据集，涵盖了城市、郊区和乡村环境中四向交叉路口在不同光照和天气条件下的繁忙和稀疏人群及交通情况。我们使用我们的数据集训练了RVT和YOLOv8等现有的最先进模型，并在真实事件相机数据上进行评估，以证明所提出数据集的模拟到现实泛化能力。", "summary": "本文介绍了SEPose，一个利用CARLA模拟器生成的、大规模的合成事件相机人体姿态估计数据集。该数据集旨在解决事件相机在行人监控领域的数据稀缺问题，提供了近35万个在各种条件下标注的行人数据。通过使用SEPose训练RVT和YOLOv8等先进模型，并在真实事件相机数据上验证其模拟到现实的泛化能力，证明了该数据集的有效性。", "keywords": "事件相机传感器, 人体姿态估计, 合成数据集, 行人监测, 模拟到现实", "comments": "该研究的创新之处在于创建了一个大规模的合成事件相机数据集（SEPose），以解决事件相机在行人监控领域面临的关键数据稀缺问题，这对于安全关键应用至关重要。展示其模拟到现实的泛化能力是一项重要贡献，验证了该数据集在实际部署事件相机姿态估计模型方面的实用价值。"}}
{"id": "2507.12237", "title": "Constructed Realities? Technical and Contextual Anomalies in a High-Profile Image", "authors": ["Matthias Wjst"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      32 pages, 8 figures, 36 references", "url": "http://arxiv.org/abs/2507.12237v1", "summary": "This study offers a forensic assessment of a widely circulated photograph\nfeaturing Prince Andrew, Virginia Giuffre, and Ghislaine Maxwell - an image\nthat has played a pivotal role in public discourse and legal narratives.\nThrough analysis of multiple published versions, several inconsistencies are\nidentified, including irregularities in lighting, posture, and physical\ninteraction, which are more consistent with digital compositing than with an\nunaltered snapshot. While the absence of the original negative and a verifiable\naudit trail precludes definitive conclusions, the technical and contextual\nanomalies suggest that the image may have been deliberately constructed.\nNevertheless, without additional evidence, the photograph remains an unresolved\nbut symbolically charged fragment within a complex story of abuse, memory, and\ncontested truth.", "comment": "32 pages, 8 figures, 36 references", "pdf_url": "http://arxiv.org/pdf/2507.12237v1", "cate": "eess.IV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "构建的现实？一张高知名度图片中的技术和背景异常", "tldr": "该研究对一张备受关注的安德鲁王子照片进行了法证分析，发现技术和背景异常，表明该图片可能经过数字合成。", "motivation": "该研究旨在对一张在公共讨论和法律叙事中发挥关键作用的、广为流传的照片进行法证评估，以探究其真实性。", "method": "通过分析多份已发布的照片版本，识别了光线、姿势和物理互动方面的不一致性。", "result": "发现多处不一致，包括光线、姿势和物理互动方面的异常，这些异常更符合数字合成而非未经修改的快照。", "conclusion": "尽管缺乏原始底片和可验证的审计追踪，无法得出明确结论，但技术和背景异常表明该图片可能经过蓄意构建。该照片仍是复杂故事中未解决但具有象征意义的一部分。", "translation": "这项研究对一张广为流传的、以安德鲁王子、弗吉尼亚·朱弗雷和吉斯莱恩·麦克斯韦为主角的照片进行了法证评估，该照片在公众讨论和法律叙事中发挥了关键作用。通过对多个已发布版本的分析，识别出了一些不一致之处，包括光线、姿势和身体互动方面的异常，这些异常更符合数字合成而非未经修改的快照。虽然缺乏原始底片和可验证的审计追踪排除了明确的结论，但技术和背景异常表明该图像可能经过蓄意构建。然而，在没有额外证据的情况下，这张照片在一个关于虐待、记忆和有争议真相的复杂故事中，仍然是一个悬而未决但具有象征意义的片段。", "summary": "本研究对一张在公共和法律领域具有重要影响力的安德鲁王子照片进行法证分析。通过比对不同版本，研究者发现照片存在光线、姿势和互动方面的异常，这些迹象暗示照片可能经过数字合成。尽管缺乏原始证据，无法下定论，但这些技术和背景异常强烈指向图片被刻意构建的可能性，使其成为一个复杂叙事中悬而未决的象征性部分。", "keywords": "法证分析, 数字合成, 图像真实性, 技术异常, 公众讨论", "comments": "该研究创新性地将法证分析应用于高知名度照片，揭示了数字图像在法律和公共领域中真实性验证的复杂性。其重要性在于提醒公众和司法系统对数字证据进行批判性审查，并突出了原始数据和审计追踪在验证数字内容中的关键作用。"}}
{"id": "2507.12344", "title": "Improving Lightweight Weed Detection via Knowledge Distillation", "authors": ["Ahmet Oğuz Saltık", "Max Voigt", "Sourav Modak", "Mike Beckworth", "Anthony Stein"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12344v1", "summary": "Weed detection is a critical component of precision agriculture, facilitating\ntargeted herbicide application and reducing environmental impact. However,\ndeploying accurate object detection models on resource-limited platforms\nremains challenging, particularly when differentiating visually similar weed\nspecies commonly encountered in plant phenotyping applications. In this work,\nwe investigate Channel-wise Knowledge Distillation (CWD) and Masked Generative\nDistillation (MGD) to enhance the performance of lightweight models for\nreal-time smart spraying systems. Utilizing YOLO11x as the teacher model and\nYOLO11n as both reference and student, both CWD and MGD effectively transfer\nknowledge from the teacher to the student model. Our experiments, conducted on\na real-world dataset comprising sugar beet crops and four weed types (Cirsium,\nConvolvulus, Fallopia, and Echinochloa), consistently show increased AP50\nacross all classes. The distilled CWD student model achieves a notable\nimprovement of 2.5% and MGD achieves 1.9% in mAP50 over the baseline without\nincreasing model complexity. Additionally, we validate real-time deployment\nfeasibility by evaluating the student YOLO11n model on Jetson Orin Nano and\nRaspberry Pi 5 embedded devices, performing five independent runs to evaluate\nperformance stability across random seeds. These findings confirm CWD and MGD\nas an effective, efficient, and practical approach for improving deep\nlearning-based weed detection accuracy in precision agriculture and plant\nphenotyping scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12344v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "通过知识蒸馏改进轻量级杂草检测", "tldr": "本研究利用通道级知识蒸馏（CWD）和掩码生成蒸馏（MGD）技术，显著提升了轻量级模型（YOLO11n）在资源受限平台上进行杂草检测的准确性，并验证了其在精准农业中实时部署的可行性。", "motivation": "在资源受限平台上部署准确的目标检测模型仍然具有挑战性，尤其是在区分视觉上相似的杂草物种时。这限制了精准农业中杂草检测的广泛应用。", "method": "本研究调查了通道级知识蒸馏（CWD）和掩码生成蒸馏（MGD）两种方法，以提高轻量级模型在实时智能喷洒系统中的性能。实验中，YOLO11x被用作教师模型，YOLO11n作为参考和学生模型。研究在一个包含甜菜作物和四种杂草的真实世界数据集上进行了实验，并评估了模型在Jetson Orin Nano和Raspberry Pi 5嵌入式设备上的实时部署可行性。", "result": "实验结果持续显示所有类别的AP50均有所提高。经过蒸馏的CWD学生模型在mAP50上比基线提高了2.5%，MGD提高了1.9%，且未增加模型复杂度。此外，研究验证了YOLO11n学生模型在嵌入式设备上的实时部署可行性。", "conclusion": "这些发现证实CWD和MGD是提高精准农业和植物表型分析中基于深度学习的杂草检测准确性的一种有效、高效且实用的方法。", "translation": "杂草检测是精准农业的关键组成部分，有助于靶向施用除草剂并减少对环境的影响。然而，在资源有限的平台上部署准确的目标检测模型仍然具有挑战性，特别是在区分植物表型应用中常见的视觉相似杂草物种时。在这项工作中，我们研究了通道级知识蒸馏（CWD）和掩码生成蒸馏（MGD），以提高轻量级模型在实时智能喷洒系统中的性能。利用YOLO11x作为教师模型，YOLO11n作为参考和学生模型，CWD和MGD都有效地将知识从教师模型转移到学生模型。我们的实验在一个包含甜菜作物和四种杂草类型（Cirsium、Convolvulus、Fallopia和Echinochloa）的真实世界数据集上进行，结果持续显示所有类别的AP50均有所提高。经过蒸馏的CWD学生模型在mAP50上比基线显著提高了2.5%，MGD提高了1.9%，且未增加模型复杂度。此外，我们通过在Jetson Orin Nano和Raspberry Pi 5嵌入式设备上评估学生YOLO11n模型，验证了实时部署的可行性，并进行了五次独立运行以评估随机种子下的性能稳定性。这些发现证实CWD和MGD是提高精准农业和植物表型分析中基于深度学习的杂草检测准确性的一种有效、高效且实用的方法。", "summary": "本研究旨在解决在资源受限平台上部署准确的轻量级杂草检测模型所面临的挑战。研究探索了通道级知识蒸馏（CWD）和掩码生成蒸馏（MGD）两种方法，通过将YOLO11x教师模型的知识转移到YOLO11n学生模型，显著提升了其在真实世界杂草数据集上的检测性能。实验结果表明，CWD和MGD分别使mAP50提高了2.5%和1.9%，且未增加模型复杂度。此外，研究还在嵌入式设备上验证了模型的实时部署能力，证实了知识蒸馏在精准农业中提高杂草检测效率和实用性的潜力。", "keywords": "杂草检测, 知识蒸馏, 轻量级模型, 精准农业, YOLO", "comments": "该论文的创新点在于将知识蒸馏技术应用于轻量级模型在精准农业杂草检测领域的性能提升。其重要性体现在为资源受限的智能农业设备提供了高效且准确的解决方案，有助于减少除草剂使用和环境影响。通过在实际硬件上验证实时部署可行性，进一步增强了其应用价值。研究结果表明知识蒸馏是一种非常有前景的策略，可以弥补轻量级模型在准确性上的不足。"}}
{"id": "2505.07530", "title": "FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images", "authors": ["Raul Ismayilov", "Dzemila Sero", "Luuk Spreeuwers"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.07530v3", "summary": "Synthetic face datasets are increasingly used to overcome the limitations of\nreal-world biometric data, including privacy concerns, demographic imbalance,\nand high collection costs. However, many existing methods lack fine-grained\ncontrol over identity attributes and fail to produce paired,\nidentity-consistent images under structured capture conditions. We introduce\nFLUXSynID, a framework for generating high-resolution synthetic face datasets\nalong with a dataset of 14,889 synthetic identities. We generate synthetic\nfaces with user-defined identity attribute distributions, offering both\ndocument-style and trusted live capture images. The dataset generated using the\nFLUXSynID framework shows improved alignment with real-world identity\ndistributions and greater inter-class diversity compared to prior work. Our\nwork is publicly released to support biometric research, including face\nrecognition and morphing attack detection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.07530v3", "cate": "cs.CV", "date": "2025-05-12", "updated": "2025-07-16", "AI": {"title_translation": "FLUXSynID：一种基于证件照和实时图像的身份控制合成人脸生成框架", "tldr": "FLUXSynID是一个用于生成高分辨率合成人脸数据集的框架，能提供身份控制的证件照和实时图像，解决了现有方法缺乏精细控制和一致性问题，并提高了与真实世界分布的对齐度及多样性。", "motivation": "现有的真实世界生物识别数据存在隐私、人口不平衡和收集成本高等局限性，导致合成人脸数据集被广泛使用。然而，许多现有方法缺乏对身份属性的精细控制，并且无法在结构化捕获条件下生成成对、身份一致的图像。", "method": "本文提出了FLUXSynID框架，用于生成高分辨率合成人脸数据集，并附带了14,889个合成身份的数据集。该框架能够根据用户定义的身份属性分布生成合成人脸，并提供证件照风格和可信的实时捕获图像。", "result": "使用FLUXSynID框架生成的数据集与真实世界身份分布的对齐度更高，并且与现有工作相比，具有更大的类间多样性。", "conclusion": "FLUXSynID框架及其生成的数据集被公开发布，以支持包括人脸识别和形变攻击检测在内的生物识别研究。", "translation": "合成人脸数据集正越来越多地用于克服真实世界生物识别数据的局限性，包括隐私问题、人口统计学不平衡和高收集成本。然而，许多现有方法缺乏对身份属性的精细控制，并且无法在结构化捕获条件下生成成对、身份一致的图像。我们引入了FLUXSynID，这是一个用于生成高分辨率合成人脸数据集的框架，并附带了14,889个合成身份的数据集。我们能够根据用户定义的身份属性分布生成合成人脸，提供证件照风格和可信的实时捕获图像。与现有工作相比，使用FLUXSynID框架生成的数据集显示出与真实世界身份分布的更好对齐，以及更大的类间多样性。我们的工作已公开发布，以支持生物识别研究，包括人脸识别和形变攻击检测。", "summary": "FLUXSynID是一个旨在解决现有合成人脸生成方法在身份控制和图像一致性方面不足的框架。它能够生成高分辨率的合成人脸数据集，包含14,889个合成身份，并支持用户定义属性分布，提供证件照和实时捕获两种风格的图像。该框架生成的数据集在与真实世界身份分布的对齐度及类间多样性上均优于现有方法，并已公开以支持生物识别领域的研究。", "keywords": "合成人脸生成, 身份控制, 生物识别, 证件照, 实时图像", "comments": "FLUXSynID的创新之处在于其提供了对合成人脸身份属性的精细控制，并能生成在结构化捕获条件下身份一致的配对图像（证件照和实时图像），这对于生物识别研究，特别是人脸识别和形变攻击检测具有重要意义。数据集的公开性也极大地促进了相关领域的研究进展。"}}
{"id": "2312.12216", "title": "Sharing is CAIRing: Characterizing Principles and Assessing Properties of Universal Privacy Evaluation for Synthetic Tabular Data", "authors": ["Tobias Hyrup", "Anton Danholt Lautrup", "Arthur Zimek", "Peter Schneider-Kamp"], "categories": ["cs.LG", "cs.CR", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2312.12216v2", "summary": "Data sharing is a necessity for innovative progress in many domains,\nespecially in healthcare. However, the ability to share data is hindered by\nregulations protecting the privacy of natural persons. Synthetic tabular data\nprovide a promising solution to address data sharing difficulties but does not\ninherently guarantee privacy. Still, there is a lack of agreement on\nappropriate methods for assessing the privacy-preserving capabilities of\nsynthetic data, making it difficult to compare results across studies. To the\nbest of our knowledge, this is the first work to identify properties that\nconstitute good universal privacy evaluation metrics for synthetic tabular\ndata. The goal of universally applicable metrics is to enable comparability\nacross studies and to allow non-technical stakeholders to understand how\nprivacy is protected. We identify four principles for the assessment of\nmetrics: Comparability, Applicability, Interpretability, and Representativeness\n(CAIR). To quantify and rank the degree to which evaluation metrics conform to\nthe CAIR principles, we design a rubric using a scale of 1-4. Each of the four\nproperties is scored on four parameters, yielding 16 total dimensions. We study\nthe applicability and usefulness of the CAIR principles and rubric by assessing\na selection of metrics popular in other studies. The results provide granular\ninsights into the strengths and weaknesses of existing metrics that not only\nrank the metrics but highlight areas of potential improvements. We expect that\nthe CAIR principles will foster agreement among researchers and organizations\non which universal privacy evaluation metrics are appropriate for synthetic\ntabular data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2312.12216v2", "cate": "cs.LG", "date": "2023-12-19", "updated": "2025-07-16", "AI": {"title_translation": "共享即关怀：表征通用隐私评估原则并评估合成表格数据属性", "tldr": "本文提出了CAIR原则和评估标准，用于统一评估合成表格数据的隐私保护能力，以促进跨研究的比较和非技术利益相关者的理解。", "motivation": "在许多领域（尤其是医疗保健）中，数据共享对于创新进步至关重要，但受限于隐私法规。合成表格数据提供了一种解决方案，但其隐私性并非固有保证。目前，对于评估合成数据隐私保护能力的适当方法缺乏共识，导致研究结果难以比较。", "method": "本文首次提出了构成合成表格数据良好通用隐私评估指标的四个原则：可比性（Comparability）、适用性（Applicability）、可解释性（Interpretability）和代表性（Representativeness），统称为CAIR。为了量化和评估现有评估指标与CAIR原则的符合程度，本文设计了一个1-4分的评估标准（rubric），每个属性在四个参数上评分，共16个维度。研究通过评估现有流行指标来验证CAIR原则和评估标准的适用性和有效性。", "result": "评估结果提供了对现有指标优缺点的细致洞察，不仅对指标进行了排名，还指出了潜在的改进领域。", "conclusion": "CAIR原则有望促进研究人员和组织之间就何种通用隐私评估指标适用于合成表格数据达成共识。", "translation": "数据共享是许多领域（尤其是医疗保健）创新进步的必要条件。然而，数据共享的能力受到保护自然人隐私的法规的阻碍。合成表格数据提供了一个有前景的解决方案来解决数据共享的困难，但其本身并不能保证隐私。尽管如此，对于评估合成数据隐私保护能力的适当方法仍然缺乏共识，这使得跨研究结果的比较变得困难。据我们所知，这是首次识别构成合成表格数据良好通用隐私评估指标的属性的工作。通用适用指标的目标是实现跨研究的可比性，并允许非技术利益相关者理解隐私是如何被保护的。我们为指标评估确定了四个原则：可比性（Comparability）、适用性（Applicability）、可解释性（Interpretability）和代表性（Representativeness）（CAIR）。为了量化和评估评估指标符合CAIR原则的程度，我们设计了一个使用1-4分制的评估标准。四个属性中的每一个都在四个参数上评分，总共产生16个维度。我们通过评估其他研究中流行的一些指标来研究CAIR原则和评估标准的适用性和有用性。结果提供了对现有指标优缺点的细致洞察，不仅对指标进行了排名，还突出了潜在的改进领域。我们期望CAIR原则将促进研究人员和组织之间就哪些通用隐私评估指标适用于合成表格数据达成共识。", "summary": "本研究旨在解决合成表格数据隐私评估方法缺乏共识的问题，提出了第一个用于通用隐私评估指标的CAIR（可比性、适用性、可解释性、代表性）四大原则。为量化评估指标对这些原则的符合程度，设计了一个16维度的评分标准。通过评估现有流行指标，本研究提供了对它们优缺点的深入分析，并期望CAIR原则能促进合成表格数据隐私评估标准的统一。", "keywords": "合成数据, 隐私评估, CAIR原则, 表格数据, 数据共享", "comments": "本文的创新之处在于首次系统性地提出了评估合成表格数据隐私保护能力的通用原则（CAIR）和量化评估标准。这对于解决当前领域内评估方法不统一、结果难以比较的痛点具有重要意义。通过提供一个标准化的框架，它有望加速合成数据在隐私保护下的应用和研究进展，并降低非技术人员理解隐私保护的门槛。"}}
{"id": "2503.09174", "title": "Deterministic and Statistical Analysis of the DoF of Continuous Linear Arrays in the Near Field", "authors": ["Athanasios G. Kanatas", "Harris K. Armeniakos", "Harpreet S. Dhillon", "Marco Di Renzo"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages, Submitted to IEEE journal for possible publication", "url": "http://arxiv.org/abs/2503.09174v2", "summary": "This paper examines the number of communication modes, that is, the degrees\nof freedom (DoF) in a wireless line-of-sight channel comprising a small\ncontinuous linear intelligent antenna array in the near field of a large one.\nThe framework allows for any orientations between the arrays and any positions\nin a two-dimensional space assuming that the transmitting array is placed at\nthe origin. Therefore, apart from the length of the two continuous arrays, four\nkey parameters determine the DoF and are hence considered in the analysis: the\nCartesian coordinates of the center of the receiving array and two angles that\nmodel the rotation of each array around its center. The paper starts with the\ncalculation of the deterministic DoF for a generic geometric setting, which\nextends beyond the widely studied paraxial case. Subsequently, a stochastic\ngeometry framework is proposed to study the statistical DoF, as a first step\ntowards the investigation of the system-level performance in near field\nnetworks. Numerical results applied to millimeter wave networks reveal the\nlarge number of DoF provided by near-field communications and unveil key\nsystem-level insights. A comparison of the proposed method with the singular\nvalue decomposition-based method is illustrated to validate the model.", "comment": "16 pages, Submitted to IEEE journal for possible publication", "pdf_url": "http://arxiv.org/pdf/2503.09174v2", "cate": "cs.IT", "date": "2025-03-12", "updated": "2025-07-16", "AI": {"title_translation": "近场连续线性阵列自由度的确定性与统计分析", "tldr": "本文分析了近场无线信道中连续线性天线阵列的自由度（DoF），采用确定性和统计方法，揭示了高自由度并为毫米波网络提供了系统级见解。", "motivation": "本文旨在研究由小型连续线性智能天线阵列与大型阵列在近场组成的无线视距信道中的通信模式数量（即自由度，DoF）。这是迈向研究近场网络系统级性能的第一步。", "method": "本文首先计算了通用几何设置下的确定性自由度，该设置超越了广泛研究的近轴情况。随后，提出了一个随机几何框架来研究统计自由度。通过将所提出的方法与基于奇异值分解的方法进行比较，验证了该模型。", "result": "应用于毫米波网络的数值结果表明，近场通信提供了大量的自由度，并揭示了关键的系统级见解。", "conclusion": "近场通信提供了大量的自由度，这对系统级性能至关重要，尤其是在毫米波网络中。本文提出的确定性与统计分析框架有效地对此进行了建模。", "translation": "本文研究了由一个小型连续线性智能天线阵列在一个大型阵列的近场组成的无线视距信道中的通信模式数量，即自由度（DoF）。该框架允许阵列之间有任何方向，以及在二维空间中的任何位置，假设发射阵列位于原点。因此，除了两个连续阵列的长度之外，四个关键参数决定了自由度，并因此被纳入分析：接收阵列中心的笛卡尔坐标和模拟每个阵列围绕其中心旋转的两个角度。本文首先计算了通用几何设置下的确定性自由度，这超出了广泛研究的近轴情况。随后，提出了一个随机几何框架来研究统计自由度，作为研究近场网络系统级性能的第一步。应用于毫米波网络的数值结果揭示了近场通信提供的巨大自由度，并揭示了关键的系统级见解。通过将所提出的方法与基于奇异值分解的方法进行比较，验证了该模型。", "summary": "本文研究了近场无线视距信道中连续线性天线阵列的自由度（DoF）。该研究建立了一个考虑阵列长度、位置和方向的框架。论文首先推导了通用几何配置下的确定性自由度，然后引入了用于统计自由度分析的随机几何框架。数值结果，特别是针对毫米波网络的应用，证明了近场通信的显著自由度潜力，并提供了宝贵的系统级见解。通过与基于奇异值分解的方法进行比较，验证了所提出方法的有效性。", "keywords": "近场, 自由度, 连续线性阵列, 毫米波, 随机几何", "comments": "本文的创新之处在于将自由度分析扩展到更通用的近场设置，超越了近轴情况，并结合了确定性与统计方法。其对连续阵列和毫米波网络系统级见解的关注对于推动未来无线通信系统至关重要。与SVD方法的比较验证增加了其可信度。"}}
{"id": "2507.10158", "title": "MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping", "authors": ["Obaidullah Zaland", "Erik Elmroth", "Monowar Bhuyan"], "categories": ["cs.LG", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The work is accepted for presentation at IEEE SMC 2025", "url": "http://arxiv.org/abs/2507.10158v2", "summary": "Federated Learning (FL) is a promising machine learning paradigm that enables\nparticipating devices to train privacy-preserved and collaborative models. FL\nhas proven its benefits for robotic manipulation tasks. However, grasping tasks\nlack exploration in such settings where robots train a global model without\nmoving data and ensuring data privacy. The main challenge is that each robot\nlearns from data that is nonindependent and identically distributed (non-IID)\nand of low quantity. This exhibits performance degradation, particularly in\nrobotic grasping. Thus, in this work, we propose MTF-Grasp, a multi-tier FL\napproach for robotic grasping, acknowledging the unique challenges posed by the\nnon-IID data distribution across robots, including quantitative skewness.\nMTF-Grasp harnesses data quality and quantity across robots to select a set of\n\"top-level\" robots with better data distribution and higher sample count. It\nthen utilizes top-level robots to train initial seed models and distribute them\nto the remaining \"low-level\" robots, reducing the risk of model performance\ndegradation in low-level robots. Our approach outperforms the conventional FL\nsetup by up to 8% on the quantity-skewed Cornell and Jacquard grasping\ndatasets.", "comment": "The work is accepted for presentation at IEEE SMC 2025", "pdf_url": "http://arxiv.org/pdf/2507.10158v2", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "MTF-Grasp: 一种用于机器人抓取的多层联邦学习方法", "tldr": "MTF-Grasp提出了一种多层联邦学习方法，通过利用数据质量和数量来选择“顶层”机器人训练初始模型，以解决机器人抓取中联邦学习的非IID数据挑战，并在性能上优于传统联邦学习设置。", "motivation": "联邦学习在机器人操作任务中显示出其优势，但机器人抓取任务在此设置中缺乏探索，尤其是在数据非独立同分布（non-IID）且数量低的情况下，这会导致模型性能下降。", "method": "本研究提出了MTF-Grasp，一种用于机器人抓取的多层联邦学习方法。它利用机器人之间的数据质量和数量，选择一组具有更好数据分布和更高样本数量的“顶层”机器人。然后，这些顶层机器人用于训练初始种子模型，并将其分发给其余的“底层”机器人，从而降低底层机器人模型性能下降的风险。", "result": "MTF-Grasp在数量偏斜的Cornell和Jacquard抓取数据集上的表现优于传统的联邦学习设置高达8%。", "conclusion": "MTF-Grasp方法通过解决非IID数据分布带来的独特挑战，在机器人抓取任务中显著提升了联邦学习的性能，优于传统联邦学习设置。", "translation": "联邦学习（FL）是一种很有前景的机器学习范式，它使参与设备能够训练隐私保护和协作模型。联邦学习已被证明对机器人操作任务有益。然而，在这种设置下，机器人抓取任务缺乏探索，即机器人无需移动数据即可训练全局模型并确保数据隐私。主要挑战在于每个机器人从非独立同分布（non-IID）且数据量低的数据中学习。这会导致性能下降，尤其是在机器人抓取中。因此，在这项工作中，我们提出了MTF-Grasp，一种用于机器人抓取的多层联邦学习方法，它认识到机器人之间非IID数据分布（包括数量偏斜）带来的独特挑战。MTF-Grasp利用机器人之间的数据质量和数量来选择一组具有更好数据分布和更高样本数量的“顶层”机器人。然后，它利用顶层机器人训练初始种子模型，并将其分发给其余的“底层”机器人，从而降低底层机器人模型性能下降的风险。我们的方法在数量偏斜的Cornell和Jacquard抓取数据集上的表现优于传统的联邦学习设置高达8%。", "summary": "本文提出MTF-Grasp，一种针对机器人抓取任务的多层联邦学习方法，以解决联邦学习中由非独立同分布（non-IID）数据导致的性能下降问题。该方法通过识别并利用拥有高质量和高数量数据的“顶层”机器人来训练初始模型，并将这些模型分发给“底层”机器人，从而有效降低模型性能退化风险。实验结果表明，MTF-Grasp在Cornell和Jacquard抓取数据集上的性能比传统联邦学习设置提高了8%。", "keywords": "联邦学习, 机器人抓取, 非IID数据, 多层学习, MTF-Grasp", "comments": "MTF-Grasp的创新之处在于其多层联邦学习架构，特别是在处理机器人抓取任务中常见的非IID数据分布问题。通过区分“顶层”和“底层”机器人并利用数据质量和数量进行模型初始化和分发，有效缓解了传统联邦学习在数据异构性下的性能瓶颈，对隐私保护下的分布式机器人学习具有重要意义。"}}
{"id": "2507.11484", "title": "Multipass Linear Sketches for Geometric LP-Type Problems", "authors": ["N. Efe Çekirge", "William Gay", "David P. Woodruff"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      To Appear in APPROX 2025, 45 pages; Updated author information in v2", "url": "http://arxiv.org/abs/2507.11484v2", "summary": "LP-type problems such as the Minimum Enclosing Ball (MEB), Linear Support\nVector Machine (SVM), Linear Programming (LP), and Semidefinite Programming\n(SDP) are fundamental combinatorial optimization problems, with many important\napplications in machine learning applications such as classification,\nbioinformatics, and noisy learning. We study LP-type problems in several\nstreaming and distributed big data models, giving $\\varepsilon$-approximation\nlinear sketching algorithms with a focus on the high accuracy regime with low\ndimensionality $d$, that is, when ${d < (1/\\varepsilon)^{0.999}}$. Our main\nresult is an $O(ds)$ pass algorithm with $O(s( \\sqrt{d}/\\varepsilon)^{3d/s})\n\\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$ space complexity in words, for\nany parameter $s \\in [1, d \\log (1/\\varepsilon)]$, to solve\n$\\varepsilon$-approximate LP-type problems of $O(d)$ combinatorial and VC\ndimension. Notably, by taking $s = d \\log (1/\\varepsilon)$, we achieve space\ncomplexity polynomial in $d$ and polylogarithmic in $1/\\varepsilon$, presenting\nexponential improvements in $1/\\varepsilon$ over current algorithms. We\ncomplement our results by showing lower bounds of $(1/\\varepsilon)^{\\Omega(d)}$\nfor any $1$-pass algorithm solving the $(1 + \\varepsilon)$-approximation MEB\nand linear SVM problems, further motivating our multi-pass approach.", "comment": "To Appear in APPROX 2025, 45 pages; Updated author information in v2", "pdf_url": "http://arxiv.org/pdf/2507.11484v2", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "几何LP型问题的多趟线性草图算法", "tldr": "本文研究了在流式和分布式大数据模型下解决LP型问题的ε-近似线性草图算法，特别是在低维度高精度场景下，提出了一种在1/ε方面呈指数级改进的多趟算法，并证明了单趟算法的下界，从而支持多趟方法的优势。", "motivation": "LP型问题（如最小包围球、线性支持向量机、线性规划和半定规划）是基础组合优化问题，在机器学习（如分类、生物信息学和噪声学习）中有许多重要应用。在流式和分布式大数据模型下解决这些问题是一个挑战，尤其是在需要高精度且维度较低的情况下。", "method": "本文研究了LP型问题在几种流式和分布式大数据模型下的ε-近似线性草图算法。主要方法是提出了一种O(ds)趟算法，其空间复杂度为$O(s( \\sqrt{d}/\\varepsilon)^{3d/s}) \\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$，用于解决O(d)组合和VC维度的ε-近似LP型问题。通过设置参数s，可以实现不同的空间-趟数权衡。", "result": "本文的主要结果是提出了一种针对O(d)组合和VC维度的ε-近似LP型问题的O(ds)趟算法，其空间复杂度为$O(s( \\sqrt{d}/\\varepsilon)^{3d/s}) \\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$。当$s = d \\log (1/\\varepsilon)$时，空间复杂度在d上是多项式，在1/ε上是多对数，这比现有算法在1/ε方面有指数级改进。此外，还证明了任何解决(1 + ε)-近似MEB和线性SVM问题的1趟算法的下界为$(1/\\varepsilon)^{\\Omega(d)}$。", "conclusion": "本文提出的多趟线性草图算法在低维度高精度场景下，能够以显著优于现有算法的空间复杂度（尤其是在1/ε方面达到指数级改进）解决LP型问题。通过证明单趟算法的下界，进一步强调了多趟方法的必要性和优势。", "translation": "LP型问题，如最小包围球（MEB）、线性支持向量机（SVM）、线性规划（LP）和半定规划（SDP），是基础组合优化问题，在机器学习应用（如分类、生物信息学和噪声学习）中具有许多重要应用。我们研究了在几种流式和分布式大数据模型中的LP型问题，给出了ε-近似线性草图算法，重点关注低维度d下的高精度范围，即当${d < (1/\\varepsilon)^{0.999}}$时。我们的主要结果是一种O(ds)趟算法，其空间复杂度为$O(s( \\sqrt{d}/\\varepsilon)^{3d/s}) \\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$字，适用于任何参数$s \\in [1, d \\log (1/\\varepsilon)]$，用于解决O(d)组合和VC维度的ε-近似LP型问题。值得注意的是，通过取$s = d \\log (1/\\varepsilon)$，我们实现了在d上是多项式，在1/ε上是多对数的空间复杂度，这比现有算法在1/ε方面有指数级改进。我们通过展示解决(1 + ε)-近似MEB和线性SVM问题的任何1趟算法的下界为$(1/\\varepsilon)^{\\Omega(d)}$来补充我们的结果，进一步激励了我们的多趟方法。", "summary": "本文针对流式和分布式大数据模型中的LP型问题，特别是在低维度高精度要求下，提出了一种新颖的ε-近似多趟线性草图算法。该算法在1/ε方面实现了指数级的空间复杂度改进，并且通过理论下界证明了多趟方法的优越性，克服了单趟算法的局限性。", "keywords": "LP型问题, 线性草图, 多趟算法, 大数据, 近似算法", "comments": "本文的创新点在于提出了在多趟模型下解决LP型问题的线性草图算法，特别是在高精度、低维度场景下实现了对1/ε的指数级空间复杂度改进。这种改进对于处理大数据流中的优化问题具有重要意义。此外，通过理论下界证明了单趟算法的局限性，从而有力地支持了其多趟方法的必要性和有效性。"}}
{"id": "2507.12004", "title": "Improving Data and Parameter Efficiency of Neural Language Models Using Representation Analysis", "authors": ["Josip Jukić"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12004v1", "summary": "This thesis addresses challenges related to data and parameter efficiency in\nneural language models, with a focus on representation analysis and the\nintroduction of new optimization techniques. The first part examines the\nproperties and dynamics of language representations within neural models,\nemphasizing their significance in enhancing robustness and generalization. It\nproposes innovative approaches based on representation smoothness, including\nregularization strategies that utilize Jacobian and Hessian matrices to\nstabilize training and mitigate sensitivity to input perturbations. The second\npart focuses on methods to significantly enhance data and parameter efficiency\nby integrating active learning strategies with parameter-efficient fine-tuning,\nguided by insights from representation smoothness analysis. It presents\nsmoothness-informed early-stopping techniques designed to eliminate the need\nfor labeled validation sets and proposes innovative combinations of active\nlearning and parameter-efficient fine-tuning to reduce labeling efforts and\ncomputational resources. Extensive experimental evaluations across various NLP\ntasks demonstrate that these combined approaches substantially outperform\ntraditional methods in terms of performance, stability, and efficiency. The\nthird part explores weak supervision techniques enhanced by in-context learning\nto effectively utilize unlabeled data, further reducing dependence on extensive\nlabeling. It shows that using in-context learning as a mechanism for weak\nsupervision enables models to better generalize from limited labeled data by\nleveraging unlabeled examples more effectively during training. Comprehensive\nempirical evaluations confirm significant gains in model accuracy,\nadaptability, and robustness, especially in low-resource settings and dynamic\ndata environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12004v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "利用表征分析提高神经语言模型的数据和参数效率", "tldr": "本论文通过表征分析和新的优化技术，提高了神经语言模型的数据和参数效率，尤其是在低资源和动态数据环境中。", "motivation": "本论文旨在解决神经语言模型中数据和参数效率相关的挑战。", "method": "本论文分为三个部分：\n1. 探讨语言表征的属性和动态，提出基于表征平滑度（利用雅可比和海森矩阵进行正则化）的创新方法，以增强鲁棒性和泛化能力。\n2. 结合主动学习策略与参数高效微调，并由表征平滑度分析指导，引入平滑度感知的早停技术以消除对验证集的需求，并创新性地结合主动学习和参数高效微调以减少标注工作和计算资源。\n3. 探索通过上下文学习增强的弱监督技术，以有效利用未标注数据，进一步减少对大量标注的依赖。", "result": "实验评估表明，所提出的组合方法在性能、稳定性和效率方面显著优于传统方法。特别是在低资源设置和动态数据环境中，模型准确性、适应性和鲁棒性获得了显著提升。", "conclusion": "通过对表征分析、主动学习与参数高效微调的结合、以及弱监督与上下文学习的探索，本研究成功提高了神经语言模型的数据和参数效率、鲁棒性、泛化能力和准确性，尤其适用于资源受限和动态环境。", "translation": "本论文旨在解决神经语言模型中与数据和参数效率相关的挑战，重点关注表征分析和新优化技术的引入。第一部分探讨了神经模型中语言表征的特性和动态，强调其在增强鲁棒性和泛化能力方面的重要性。它提出了基于表征平滑度的创新方法，包括利用雅可比和海森矩阵的正则化策略，以稳定训练并减轻对输入扰动的敏感性。第二部分侧重于通过将主动学习策略与参数高效微调相结合来显著提高数据和参数效率，并由表征平滑度分析提供指导。它提出了平滑度感知的早停技术，旨在消除对标记验证集的需要，并提出了主动学习和参数高效微调的创新组合，以减少标记工作和计算资源。在各种NLP任务中进行的大量实验评估表明，这些组合方法在性能、稳定性方面显著优于传统方法。第三部分探讨了通过上下文学习增强的弱监督技术，以有效利用未标记数据，进一步减少对大量标记的依赖。它表明，将上下文学习作为弱监督机制，使模型能够通过在训练期间更有效地利用未标记示例，更好地从有限的标记数据中进行泛化。全面的实证评估证实了模型准确性、适应性和鲁棒性的显著提升，尤其是在低资源设置和动态数据环境中。", "summary": "本论文通过表征分析，提升了神经语言模型的数据和参数效率。研究分为三部分：首先，通过表征平滑度（利用雅可比和海森矩阵）进行正则化以增强模型鲁棒性；其次，结合主动学习与参数高效微调，并引入平滑度感知的早停技术，以减少数据标注和计算资源；最后，利用上下文学习增强弱监督，有效利用未标注数据。实验证明，这些方法在性能、稳定性、效率、准确性、适应性和鲁棒性方面均显著优于传统方法，尤其适用于低资源和动态数据环境。", "keywords": "神经语言模型, 数据效率, 参数效率, 表征分析, 主动学习, 弱监督", "comments": "本论文的创新点在于将表征分析深入应用于提升神经语言模型的数据和参数效率。通过引入表征平滑度概念及其在正则化、早停和主动学习中的应用，以及结合上下文学习进行弱监督，形成了一套全面的优化策略。这对于解决当前大型语言模型面临的资源消耗和数据依赖问题具有重要意义，特别是在低资源场景下，其提出的无验证集早停和减少标注努力的方法具有很高的实用价值。"}}
{"id": "2507.12093", "title": "Tree-SLAM: semantic object SLAM for efficient mapping of individual trees in orchards", "authors": ["David Rapado-Rincon", "Gert Kootstra"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Paper submitted to Smart Agricultural Technology", "url": "http://arxiv.org/abs/2507.12093v1", "summary": "Accurate mapping of individual trees is an important component for precision\nagriculture in orchards, as it allows autonomous robots to perform tasks like\ntargeted operations or individual tree monitoring. However, creating these maps\nis challenging because GPS signals are often unreliable under dense tree\ncanopies. Furthermore, standard Simultaneous Localization and Mapping (SLAM)\napproaches struggle in orchards because the repetitive appearance of trees can\nconfuse the system, leading to mapping errors. To address this, we introduce\nTree-SLAM, a semantic SLAM approach tailored for creating maps of individual\ntrees in orchards. Utilizing RGB-D images, our method detects tree trunks with\nan instance segmentation model, estimates their location and re-identifies them\nusing a cascade-graph-based data association algorithm. These re-identified\ntrunks serve as landmarks in a factor graph framework that integrates noisy GPS\nsignals, odometry, and trunk observations. The system produces maps of\nindividual trees with a geo-localization error as low as 18 cm, which is less\nthan 20\\% of the planting distance. The proposed method was validated on\ndiverse datasets from apple and pear orchards across different seasons,\ndemonstrating high mapping accuracy and robustness in scenarios with unreliable\nGPS signals.", "comment": "Paper submitted to Smart Agricultural Technology", "pdf_url": "http://arxiv.org/pdf/2507.12093v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Tree-SLAM：用于果园中单棵树高效测绘的语义目标SLAM", "tldr": "Tree-SLAM是一种语义SLAM方法，利用RGB-D图像和树干检测来精确绘制果园中单棵树的地图，即使在GPS信号不可靠的情况下也能实现高精度。", "motivation": "在果园中进行单棵树精确测绘面临挑战：GPS信号在茂密树冠下不可靠，且标准SLAM方法因树木重复外观而容易混淆，导致测绘错误。", "method": "Tree-SLAM利用RGB-D图像，通过实例分割模型检测树干，并使用基于级联图的数据关联算法估计并重新识别其位置。这些重新识别的树干作为地标，整合到包含噪声GPS信号、里程计和树干观测的因子图框架中。", "result": "该系统生成的单棵树地图的地理定位误差低至18厘米，小于种植距离的20%。该方法在不同季节的苹果和梨园数据集上进行了验证，在GPS信号不可靠的场景中展示了高测绘精度和鲁棒性。", "conclusion": "Tree-SLAM成功解决了果园中单棵树精确测绘的挑战，即使在GPS信号差的环境下也能提供高精度和鲁棒性的地图，为精准农业中的自动化操作提供了重要工具。", "translation": "果园中单棵树的精确测绘是精准农业的重要组成部分，它使自主机器人能够执行有针对性的操作或单棵树监测等任务。然而，创建这些地图具有挑战性，因为GPS信号在茂密树冠下通常不可靠。此外，标准的同时定位与地图构建（SLAM）方法在果园中也面临困难，因为树木重复出现的外观会混淆系统，导致测绘错误。为了解决这个问题，我们引入了Tree-SLAM，一种专为创建果园中单棵树地图而定制的语义SLAM方法。我们的方法利用RGB-D图像，通过实例分割模型检测树干，估计它们的位置并使用基于级联图的数据关联算法重新识别它们。这些重新识别的树干在因子图框架中作为地标，该框架集成了噪声GPS信号、里程计和树干观测。该系统生成的单棵树地图的地理定位误差低至18厘米，小于种植距离的20%。所提出的方法在来自苹果和梨园的不同季节的各种数据集上进行了验证，在GPS信号不可靠的场景中展示了高测绘精度和鲁棒性。", "summary": "Tree-SLAM是一种针对果园单棵树测绘的语义SLAM方法，旨在解决传统方法在树冠下GPS信号不可靠和树木重复外观导致的测绘误差问题。它利用RGB-D图像和实例分割检测树干作为语义地标，并通过级联图数据关联和因子图框架融合GPS、里程计和树干观测。实验证明，该方法在各种果园环境下，即使GPS信号较差，也能实现18厘米的地理定位误差，展现出高精度和鲁棒性。", "keywords": "Tree-SLAM, 语义SLAM, 精准农业, 果园测绘, 树干检测", "comments": "Tree-SLAM的创新之处在于将语义信息（树干）引入SLAM系统，有效解决了果园环境特有的重复纹理问题和GPS受限问题。其基于因子图的融合框架提高了定位和建图的精度和鲁棒性，对精准农业中的自动化操作具有重要意义。"}}
{"id": "2507.07044", "title": "Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics", "authors": ["Mehrdad Morsali", "Chengwei Zhou", "Deniz Najafi", "Sreetama Sarkar", "Pietro Mercati", "Navid Khoshavi", "Peter Beerel", "Mahdi Nikdast", "Gourav Datta", "Shaahin Angizi"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07044v2", "summary": "Vision Transformers (ViTs) have emerged as a powerful architecture for\ncomputer vision tasks due to their ability to model long-range dependencies and\nglobal contextual relationships. However, their substantial compute and memory\ndemands hinder efficient deployment in scenarios with strict energy and\nbandwidth limitations. In this work, we propose OptoViT, the first near-sensor,\nregion-aware ViT accelerator leveraging silicon photonics (SiPh) for real-time\nand energy-efficient vision processing. Opto-ViT features a hybrid\nelectronic-photonic architecture, where the optical core handles\ncompute-intensive matrix multiplications using Vertical-Cavity Surface-Emitting\nLasers (VCSELs) and Microring Resonators (MRs), while nonlinear functions and\nnormalization are executed electronically. To reduce redundant computation and\npatch processing, we introduce a lightweight Mask Generation Network (MGNet)\nthat identifies regions of interest in the current frame and prunes irrelevant\npatches before ViT encoding. We further co-optimize the ViT backbone using\nquantization-aware training and matrix decomposition tailored for photonic\nconstraints. Experiments across device fabrication, circuit and architecture\nco-design, to classification, detection, and video tasks demonstrate that\nOptoViT achieves 100.4 KFPS/W with up to 84% energy savings with less than 1.6%\naccuracy loss, while enabling scalable and efficient ViT deployment at the\nedge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07044v2", "cate": "cs.AR", "date": "2025-07-09", "updated": "2025-07-16", "AI": {"title_translation": "Opto-ViT：一种基于硅光子学的近传感器区域感知视觉Transformer加速器架构设计", "tldr": "OptoViT是一种利用硅光子学实现的近传感器ViT加速器，通过区域感知和混合架构显著提高能效并降低计算冗余。", "motivation": "视觉Transformer（ViTs）计算和内存需求巨大，阻碍了其在能量和带宽受限场景中的高效部署。", "method": "提出Opto-ViT，首个近传感器、区域感知ViT加速器，利用硅光子学实现实时和高能效视觉处理。采用混合电子-光子架构，光学核心使用VCSEL和MR处理计算密集型矩阵乘法，电子部分执行非线性函数和归一化。引入轻量级Mask Generation Network（MGNet）识别感兴趣区域并剪枝不相关补丁。通过量化感知训练和为光子约束定制的矩阵分解共同优化ViT主干网络。", "result": "OptoViT在分类、检测和视频任务中实现了100.4 KFPS/W的性能，能耗节省高达84%，精度损失小于1.6%。", "conclusion": "OptoViT实现了ViT在边缘设备上的可扩展和高效部署，显著提高了能效并降低了计算冗余。", "translation": "视觉Transformer（ViT）因其建模长距离依赖和全局上下文关系的能力，已成为计算机视觉任务的强大架构。然而，其大量的计算和内存需求阻碍了在能量和带宽严格受限场景中的高效部署。在这项工作中，我们提出了OptoViT，这是首个利用硅光子学（SiPh）实现实时和高能效视觉处理的近传感器、区域感知ViT加速器。Opto-ViT具有混合电子-光子架构，其中光学核心使用垂直腔面发射激光器（VCSEL）和微环谐振器（MR）处理计算密集型矩阵乘法，而非线性函数和归一化则通过电子方式执行。为了减少冗余计算和补丁处理，我们引入了一个轻量级掩码生成网络（MGNet），用于识别当前帧中的感兴趣区域，并在ViT编码之前剪枝不相关的补丁。我们通过量化感知训练和为光子约束定制的矩阵分解进一步共同优化了ViT骨干网络。跨设备制造、电路和架构协同设计、到分类、检测和视频任务的实验表明，OptoViT在精度损失小于1.6%的情况下，实现了100.4 KFPS/W的性能，并节省了高达84%的能耗，同时支持ViT在边缘设备上的可扩展和高效部署。", "summary": "本文提出了OptoViT，一个利用硅光子技术实现的高能效近传感器视觉Transformer加速器。它采用混合电子-光子架构，通过光学核心处理矩阵乘法，并引入轻量级Mask Generation Network识别感兴趣区域以减少冗余计算。OptoViT还通过量化感知训练和矩阵分解进行优化，实验证明其在多种视觉任务中能显著提高能效并降低功耗，同时保持高精度，为边缘ViT部署提供了高效解决方案。", "keywords": "视觉Transformer, 硅光子学, 加速器, 边缘计算, 区域感知", "comments": "这项工作在ViT加速器领域具有显著创新性，首次将硅光子技术应用于近传感器、区域感知的ViT加速，有效解决了ViT在边缘部署中的能耗和带宽瓶颈。其混合架构和轻量级MGNet的设计思路非常巧妙，为未来光计算与传统电子计算的结合提供了新的范例。"}}
{"id": "2507.12075", "title": "BOOKCOREF: Coreference Resolution at Book Scale", "authors": ["Giuliano Martinelli", "Tommaso Bonomo", "Pere-Lluís Huguet Cabot", "Roberto Navigli"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025 Main Conference. 19 pages", "url": "http://arxiv.org/abs/2507.12075v1", "summary": "Coreference Resolution systems are typically evaluated on benchmarks\ncontaining small- to medium-scale documents. When it comes to evaluating long\ntexts, however, existing benchmarks, such as LitBank, remain limited in length\nand do not adequately assess system capabilities at the book scale, i.e., when\nco-referring mentions span hundreds of thousands of tokens. To fill this gap,\nwe first put forward a novel automatic pipeline that produces high-quality\nCoreference Resolution annotations on full narrative texts. Then, we adopt this\npipeline to create the first book-scale coreference benchmark, BOOKCOREF, with\nan average document length of more than 200,000 tokens. We carry out a series\nof experiments showing the robustness of our automatic procedure and\ndemonstrating the value of our resource, which enables current long-document\ncoreference systems to gain up to +20 CoNLL-F1 points when evaluated on full\nbooks. Moreover, we report on the new challenges introduced by this\nunprecedented book-scale setting, highlighting that current models fail to\ndeliver the same performance they achieve on smaller documents. We release our\ndata and code to encourage research and development of new book-scale\nCoreference Resolution systems at https://github.com/sapienzanlp/bookcoref.", "comment": "Accepted to ACL 2025 Main Conference. 19 pages", "pdf_url": "http://arxiv.org/pdf/2507.12075v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "BOOKCOREF：书籍规模指代消解", "tldr": "现有指代消解系统在处理长文本（书籍规模）时评估受限，本文提出了一个自动标注流程，并创建了首个书籍规模指代消解基准数据集BOOKCOREF，展示了现有模型在书籍规模上的性能下降和该资源的价值。", "motivation": "现有指代消解系统在评估长文本（如书籍）时的基准数据集长度有限，无法充分评估系统在书籍规模（数十万词元）下的能力。", "method": "1. 提出了一个新颖的自动管道，用于在完整的叙事文本上生成高质量的指代消解标注。2. 采用该管道创建了首个书籍规模指代消解基准数据集BOOKCOREF，平均文档长度超过20万词元。3. 进行了一系列实验以展示自动流程的鲁棒性并证明资源的价值。", "result": "1. 自动标注流程具有鲁棒性。2. 该资源（BOOKCOREF）使现有的长文档指代消解系统在对完整书籍进行评估时，CoNLL-F1分数可提高高达+20点。3. 揭示了书籍规模设置带来的新挑战，即当前模型在处理书籍规模文本时无法达到在较小文档上的相同性能。", "conclusion": "当前的指代消解模型在书籍规模的文本上表现不佳，这突显了开发新的、更适合长文本的指代消解系统的必要性。", "translation": "指代消解系统通常在包含小到中等规模文档的基准数据集上进行评估。然而，在评估长文本时，现有基准数据集，例如 LitBank，长度仍然有限，无法充分评估系统在书籍规模（即指代提及跨越数十万词元）下的能力。为了填补这一空白，我们首先提出了一个新颖的自动管道，该管道可以在完整的叙事文本上生成高质量的指代消解标注。然后，我们采用此管道创建了第一个书籍规模的指代消解基准数据集 BOOKCOREF，其平均文档长度超过 200,000 个词元。我们进行了一系列实验，展示了我们自动程序的鲁棒性，并证明了我们资源的价值，该资源使当前的长文档指代消解系统在对完整书籍进行评估时，CoNLL-F1 分数可提高高达 +20 点。此外，我们报告了这种前所未有的书籍规模设置所带来的新挑战，强调当前模型未能达到它们在较小文档上所实现的相同性能。我们发布了我们的数据和代码以鼓励在 https://github.com/sapienzanlp/bookcoref 上进行新的书籍规模指代消解系统的研究和开发。", "summary": "本文针对现有指代消解系统在处理长文本（书籍规模）时评估受限的问题，提出了一个新颖的自动标注管道，并基于此创建了首个书籍规模指代消解基准数据集BOOKCOREF。该数据集平均文档长度超20万词元，实验证明了其标注流程的鲁棒性，并揭示了现有模型在书籍规模上性能显著下降的挑战，同时表明该资源能帮助现有系统提升性能，推动了书籍规模指代消解的研究。", "keywords": "指代消解, 书籍规模, 基准数据集, 长文本, 自动标注", "comments": "这项工作通过创建首个书籍规模的指代消解基准数据集BOOKCOREF，填补了现有评估基准在处理长文本方面的空白。其创新的自动标注管道为生成高质量长文本标注提供了可行方案，并明确指出了现有模型在处理超长文本时的性能瓶颈，对推动指代消解领域向更实际、更复杂的应用场景发展具有重要意义。"}}
{"id": "2410.01349", "title": "Life, uh, Finds a Way: Hyperadaptability by Behavioral Search", "authors": ["Alex Baranski", "Jun Tani"], "categories": ["cs.AI", "cs.NE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      39 pages, 9 figures", "url": "http://arxiv.org/abs/2410.01349v2", "summary": "Living beings are able to solve a wide variety of problems that they\nencounter rarely or only once. Without the benefit of extensive and repeated\nexperience with these problems, they can solve them in an ad-hoc manner. We\ncall this capacity to always find a solution to a physically solvable problem\n$hyperadaptability$. To explain how hyperadaptability can be achieved, we\npropose a theory that frames behavior as the physical manifestation of a\nself-modifying search procedure. Rather than exploring randomly, our system\nachieves robust problem-solving by dynamically ordering an infinite set of\ncontinuous behaviors according to simplicity and effectiveness. Behaviors are\nsampled from paths over cognitive graphs, their order determined by a tight\nbehavior-execution/graph-modification feedback loop. We implement cognitive\ngraphs using Hebbian-learning and a novel harmonic neural representation\nsupporting flexible information storage. We validate our approach through\nsimulation experiments showing rapid achievement of highly-robust navigation\nability in complex mazes, as well as high reward on difficult extensions of\nclassic reinforcement learning problems. This framework offers a new\ntheoretical model for developmental learning and paves the way for robots that\ncan autonomously master complex skills and handle exceptional circumstances.", "comment": "39 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2410.01349v2", "cate": "cs.AI", "date": "2024-10-02", "updated": "2025-07-16", "AI": {"title_translation": "生命，呃，总能找到出路：通过行为搜索实现超适应性", "tldr": "本文提出并解释了生物体在没有广泛经验的情况下解决新问题的能力，即“超适应性”，通过一种将行为视为自我修改搜索过程的理论，并用模拟实验验证了其在导航和强化学习任务中的有效性。", "motivation": "生物体能够解决很少或只遇到一次的各种问题，即“超适应性”，即使没有大量重复经验也能以一种临时的方式解决。本文的动机是解释这种超适应性是如何实现的。", "method": "本文提出了一种理论，将行为视为自我修改搜索过程的物理表现。该系统通过根据简单性和有效性动态排序无限的连续行为来实现鲁棒的问题解决。行为从认知图上的路径中采样，其顺序由紧密的行为执行/图修改反馈循环决定。认知图通过赫布学习和一种支持灵活信息存储的新型谐波神经表示实现。", "result": "通过模拟实验验证了该方法，结果显示在复杂迷宫中能够快速获得高度鲁棒的导航能力，并在经典强化学习问题的困难扩展上获得了高回报。", "conclusion": "该框架为发展学习提供了一个新的理论模型，并为机器人自主掌握复杂技能和处理特殊情况铺平了道路。", "translation": "生物能够解决他们很少或只遇到一次的各种问题。在没有大量重复经验的情况下，他们能够以一种临时的方式解决这些问题。我们将这种总是能找到物理上可解问题的解决方案的能力称为“超适应性”。为了解释超适应性如何实现，我们提出了一种理论，将行为视为一种自我修改的搜索过程的物理表现。我们的系统不是随机探索，而是通过根据简单性和有效性动态排序无限的连续行为来达到鲁棒的问题解决能力。行为是从认知图上的路径中采样的，它们的顺序由紧密的行为执行/图修改反馈循环决定。我们使用赫布学习和一种支持灵活信息存储的新型谐波神经表示来实现认知图。我们通过模拟实验验证了我们的方法，这些实验表明在复杂迷宫中能够快速获得高度鲁棒的导航能力，以及在经典强化学习问题的困难扩展上获得高回报。这个框架为发展学习提供了一个新的理论模型，并为机器人自主掌握复杂技能和处理特殊情况铺平了道路。", "summary": "本文引入了“超适应性”的概念，即生物体在没有广泛经验的情况下解决新颖或罕见问题的能力。为了解释这一点，作者提出了一种理论，将行为视为一种自我修改的搜索过程。他们的系统利用认知图动态排序连续行为，并通过紧密的反馈循环和结合赫布学习的新型谐波神经表示来实现。模拟实验证明了该模型在鲁棒导航和解决复杂强化学习任务方面的有效性，这为发展学习和更先进的机器人技术提供了新的理论模型。", "keywords": "超适应性, 行为搜索, 认知图, 发展学习, 机器人技术", "comments": "该论文引入了“超适应性”这一新颖概念，并提出了一种基于自我修改行为搜索和认知图的受生物学启发的计算模型。其创新之处在于将行为构建为一种动态搜索过程，这有望显著推动发展学习理论，并促进能够处理不可预见情况的更具适应性的AI和机器人技术的发展。"}}
{"id": "2507.12299", "title": "Modal Analysis of Multimode Waveguides Based on Large Step Size AdaMax from Far-Field Amplitudes", "authors": ["Jingtong Li", "Dongting Huang", "Minhui Xiong", "Mingzhi Li"], "categories": ["physics.comp-ph", "cs.SD", "physics.optics"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12299v1", "summary": "Optimizing multimode waveguide performance depends on modal analysis;\nhowever, current approaches focus predominantly on modal power distribution\nand, limited by experimental hardware and conditions, exhibit low accuracy,\npoor adaptability, and high computational cost. In this work, under a\npower-normalization constraint, we employ the AdaMax optimizer with a\nlarge-step-size strategy to perform modal analysis of multimode waveguides from\nfar-field amplitude measurements. Our method retrieves both the modal power\ndistribution and the modal relative-phase distribution, and we elucidate how\ntwin-image ambiguity limits the capability to analyze modal relative-phase\ndistributions. Experimental results demonstrate that the proposed method\nperforms well for both rectangular and circular waveguides, maintaining high\naccuracy and robustness under noise with signal-to-noise ratios (SNRs) ranging\nfrom 20 to 120 dB, and achieving substantial improvements in accuracy and\ncomputational cost over comparable methods. This method provides a novel\nsolution for modal analysis with broad application potential.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12299v1", "cate": "physics.comp-ph", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于大步长AdaMax从远场振幅进行多模波导模态分析", "tldr": "本文提出了一种使用大步长AdaMax优化器从远场振幅测量中对多模波导进行模态分析的新方法，该方法在准确性和计算成本方面优于现有方法，并能同时获取模态功率和相对相位分布。", "motivation": "当前的多模波导模态分析方法主要关注模态功率分布，并且受限于实验硬件和条件，存在精度低、适应性差和计算成本高的问题。", "method": "在功率归一化约束下，采用大步长AdaMax优化器，从远场振幅测量数据对多模波导进行模态分析。该方法能够同时获取模态功率分布和模态相对相位分布。", "result": "实验结果表明，所提出的方法对矩形和圆形波导均表现良好，在20至120 dB的信噪比范围内仍保持高精度和鲁棒性，并且与同类方法相比，在精度和计算成本上都有显著提升。同时，阐明了双像模糊如何限制模态相对相位分布的分析能力。", "conclusion": "该方法为模态分析提供了一种新颖的解决方案，具有广阔的应用潜力。", "translation": "优化多模波导性能依赖于模态分析；然而，当前的方法主要关注模态功率分布，并且受限于实验硬件和条件，表现出低精度、差适应性和高计算成本。在这项工作中，在功率归一化约束下，我们采用大步长AdaMax优化器从远场振幅测量中对多模波导进行模态分析。我们的方法可以同时获取模态功率分布和模态相对相位分布，并且我们阐明了双像模糊如何限制分析模态相对相位分布的能力。实验结果表明，所提出的方法对矩形和圆形波导都表现良好，在20到120 dB的信噪比（SNR）范围内，在噪声下保持高精度和鲁棒性，并且在精度和计算成本上比同类方法有显著提高。该方法为模态分析提供了一种具有广泛应用潜力的新颖解决方案。", "summary": "本文提出了一种基于大步长AdaMax优化器，从远场振幅测量数据对多模波导进行模态分析的新方法。该方法在功率归一化约束下，不仅能够准确获取模态功率分布，还能同时获得模态相对相位分布。实验证明，该方法对不同形状的波导均适用，在噪声环境下表现出高精度和鲁棒性，并在精度和计算效率上显著优于现有方法。研究还揭示了双像模糊对模态相对相位分析的限制。", "keywords": "多模波导, 模态分析, AdaMax, 远场振幅, 模态相对相位", "comments": "该论文通过引入大步长AdaMax优化器，创新性地解决了现有模模态分析方法精度低、成本高的问题。其重要性在于能够同时获取模态功率和相对相位分布，这对于多模波导的全面性能评估至关重要。此外，论文还深入探讨了双像模糊这一限制因素，这对于未来研究具有指导意义。"}}
{"id": "2507.11543", "title": "A Review of Generative AI in Computer Science Education: Challenges and Opportunities in Accuracy, Authenticity, and Assessment", "authors": ["Iman Reihanian", "Yunfei Hou", "Yu Chen", "Yifei Zheng"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at The 2024 International Conference on Computational Science and Computational Intelligence (CSCI), Research Track on Education. To appear in Springer Lecture Notes in Computer Science (LNCS) proceedings, expected July 2025", "url": "http://arxiv.org/abs/2507.11543v1", "summary": "This paper surveys the use of Generative AI tools, such as ChatGPT and\nClaude, in computer science education, focusing on key aspects of accuracy,\nauthenticity, and assessment. Through a literature review, we highlight both\nthe challenges and opportunities these AI tools present. While Generative AI\nimproves efficiency and supports creative student work, it raises concerns such\nas AI hallucinations, error propagation, bias, and blurred lines between\nAI-assisted and student-authored content. Human oversight is crucial for\naddressing these concerns. Existing literature recommends adopting hybrid\nassessment models that combine AI with human evaluation, developing bias\ndetection frameworks, and promoting AI literacy for both students and\neducators. Our findings suggest that the successful integration of AI requires\na balanced approach, considering ethical, pedagogical, and technical factors.\nFuture research may explore enhancing AI accuracy, preserving academic\nintegrity, and developing adaptive models that balance creativity with\nprecision.", "comment": "Accepted for presentation at The 2024 International Conference on\n  Computational Science and Computational Intelligence (CSCI), Research Track\n  on Education. To appear in Springer Lecture Notes in Computer Science (LNCS)\n  proceedings, expected July 2025", "pdf_url": "http://arxiv.org/pdf/2507.11543v1", "cate": "cs.CY", "date": "2025-06-17", "updated": "2025-06-17", "AI": {"title_translation": "生成式人工智能在计算机科学教育中的应用综述：准确性、真实性和评估方面的挑战与机遇", "tldr": "本文综述了生成式人工智能在计算机科学教育中的应用，重点讨论了准确性、真实性和评估方面的挑战与机遇，并强调了人工监督和平衡整合的重要性。", "motivation": "本文旨在调查生成式人工智能工具在计算机科学教育中的应用，并重点阐述这些人工智能工具所带来的挑战和机遇，尤其关注准确性、真实性和评估方面。", "method": "文献综述。", "result": "生成式人工智能能够提高效率并支持学生的创造性工作，但也引发了人工智能幻觉、错误传播、偏见以及人工智能辅助内容与学生原创内容界限模糊等问题。人工监督对于解决这些问题至关重要。现有文献建议采用结合人工智能和人工评估的混合评估模型、开发偏见检测框架以及促进学生和教育工作者的人工智能素养。", "conclusion": "人工智能在教育领域的成功整合需要一种平衡的方法，需综合考虑伦理、教学和技术因素。未来的研究应侧重于提高人工智能的准确性、维护学术诚信以及开发平衡创造性与精确性的自适应模型。", "translation": "本文综述了ChatGPT和Claude等生成式人工智能工具在计算机科学教育中的应用，重点关注准确性、真实性和评估等关键方面。通过文献综述，我们强调了这些人工智能工具带来的挑战和机遇。尽管生成式人工智能提高了效率并支持学生的创造性工作，但它也引发了担忧，例如人工智能幻觉、错误传播、偏见以及人工智能辅助内容与学生原创内容之间界限模糊。人工监督对于解决这些问题至关重要。现有文献建议采用结合人工智能和人工评估的混合评估模型，开发偏见检测框架，并促进学生和教育工作者的人工智能素养。我们的研究结果表明，成功整合人工智能需要一种平衡的方法，考虑伦理、教学和技术因素。未来的研究可以探索提高人工智能准确性、维护学术诚信以及开发平衡创造性与精确性的自适应模型。", "summary": "本文综述了生成式人工智能工具在计算机科学教育中的应用，探讨了其对准确性、真实性和评估的影响。文章指出了生成式人工智能在提高效率和支持创造性方面的优势，同时也提出了人工智能幻觉、偏见和内容归属模糊等挑战。研究强调了人工监督的重要性，并推荐采用混合评估模型、开发偏见检测框架和提升人工智能素养。结论指出，成功整合人工智能需平衡伦理、教学和技术因素，并建议未来研究关注提高准确性和维护学术诚信。", "keywords": "生成式人工智能, 计算机科学教育, 教育中的人工智能, 评估, 人工智能素养", "comments": "这篇论文对生成式人工智能在教育领域的应用进行了及时且相关的概述，探讨了随着这些技术日益普及而出现的关键问题。其优势在于同时识别了机遇和挑战，并为整合提供了实用的建议。强调人工监督和采取平衡方法对于应对伦理和教学的复杂性至关重要。"}}
{"id": "2507.11899", "title": "Performance Assessment of Load Balancing Methods in Cloud Computing: Analysis of Round Robin, Equally Spread, and Throttled Strategies Using Cloud Analyst", "authors": ["Saeid Aghasoleymani Najafabadi"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11899v1", "summary": "Load balancing plays a pivotal role in cloud computing, ensuring that\nresources are optimally allocated to maintain high service quality and\noperational efficiency. As workloads in cloud environments become increasingly\ndynamic and unpredictable, load balancing strategies are evolving from\ntraditional static methods to more adaptive and intelligent approaches. In this\nstudy, the Cloud Analyst simulation tool was used to evaluate the performance\nof different load balancing algorithms under various scenarios, including both\ncentralized and distributed resource setups. The results highlight that while\nthe Round Robin algorithm yields slightly better processing times within a\nsingle data center, Equally Spread and Throttled techniques perform\ncompetitively, especially when network latency is considered. More importantly,\nwhen resources are distributed across multiple data centers, response times are\nsignificantly reduced, emphasizing the value of proximity and efficient load\ndistribution. In these distributed environments, Equally Spread and Throttled\nalgorithms not only maintain quick response times but also contribute to lower\noperational costs. These findings demonstrate the necessity of strategic\nresource placement and proactive infrastructure planning to balance performance\nand cost. Adopting intelligent, dynamic load balancing and resource management\npractices can help organizations meet evolving cloud demands, optimize costs,\nand maintain a competitive advantage. Continuous evaluation and integration of\nemerging technologies are crucial for sustaining effective and scalable cloud\noperations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11899v1", "cate": "cs.DC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "云计算中负载均衡方法的性能评估：使用 Cloud Analyst 分析轮询、均等分配和限制策略", "tldr": "本研究使用 Cloud Analyst 评估了云计算中不同负载均衡算法（轮询、均等分配、限制）的性能，发现分布式资源设置能显著降低响应时间，且均等分配和限制算法在分布式环境中表现更优，并能降低成本。", "motivation": "随着云计算环境中工作负载的动态性和不可预测性增加，负载均衡策略正从传统静态方法向更具适应性和智能的方法演进，因此需要评估不同负载均衡算法的性能。", "method": "本研究使用 Cloud Analyst 仿真工具，在集中式和分布式资源设置等不同场景下评估了不同负载均衡算法（轮询、均等分配、限制）的性能。", "result": "在单个数据中心内，轮询算法的处理时间略优；考虑网络延迟时，均等分配和限制技术表现具有竞争力；当资源分布在多个数据中心时，响应时间显著缩短；在分布式环境中，均等分配和限制算法不仅保持快速响应时间，还有助于降低运营成本。", "conclusion": "战略性的资源部署和积极的基础设施规划对于平衡性能和成本至关重要。采用智能、动态的负载均衡和资源管理实践有助于应对云需求、优化成本并保持竞争优势。持续评估和整合新兴技术对于维持有效和可扩展的云操作至关重要。", "translation": "负载均衡在云计算中扮演着关键角色，它确保资源得到优化分配，以维持高质量的服务和操作效率。随着云环境中的工作负载变得越来越动态和不可预测，负载均衡策略正从传统的静态方法演变为更具适应性和智能的方法。在本研究中，使用 Cloud Analyst 仿真工具评估了在各种场景（包括集中式和分布式资源设置）下不同负载均衡算法的性能。结果表明，虽然轮询算法在单个数据中心内产生了略好的处理时间，但均等分配和限制技术表现出竞争力，尤其是在考虑网络延迟时。更重要的是，当资源分布在多个数据中心时，响应时间显著缩短，这强调了邻近性和高效负载分配的价值。在这些分布式环境中，均等分配和限制算法不仅保持了快速响应时间，还有助于降低运营成本。这些发现表明，战略性资源部署和积极的基础设施规划对于平衡性能和成本是必要的。采用智能、动态的负载均衡和资源管理实践可以帮助组织满足不断变化的云需求，优化成本，并保持竞争优势。持续评估和整合新兴技术对于维持有效和可扩展的云操作至关重要。", "summary": "本研究利用 Cloud Analyst 仿真工具，评估了云计算中轮询、均等分配和限制等负载均衡策略在集中式和分布式环境下的性能。研究发现，在单个数据中心内，轮询算法处理时间略优；而在考虑网络延迟和分布式资源部署时，均等分配和限制算法表现更佳，能显著降低响应时间并优化运营成本。这强调了战略性资源部署和动态负载均衡在平衡性能与成本方面的重要性。", "keywords": "负载均衡, 云计算, Cloud Analyst, 轮询, 均等分配, 限制", "comments": "这篇论文通过仿真工具 Cloud Analyst 对云计算中常见的负载均衡策略进行了性能评估，特别关注了分布式环境下的表现。其创新点在于强调了分布式资源部署在降低响应时间和运营成本方面的优势，并指出均等分配和限制算法在这些场景下的优越性。这对于云服务提供商和企业进行基础设施规划和资源管理具有重要的指导意义。"}}
{"id": "2507.12133", "title": "HyDRA: A Hybrid Dual-Mode Network for Closed- and Open-Set RFFI with Optimized VMD", "authors": ["Hanwen Liu", "Yuhe Huang", "Yifeng Gong", "Yanjie Zhai", "Jiaxuan Lu"], "categories": ["cs.LG", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12133v1", "summary": "Device recognition is vital for security in wireless communication systems,\nparticularly for applications like access control. Radio Frequency Fingerprint\nIdentification (RFFI) offers a non-cryptographic solution by exploiting\nhardware-induced signal distortions. This paper proposes HyDRA, a Hybrid\nDual-mode RF Architecture that integrates an optimized Variational Mode\nDecomposition (VMD) with a novel architecture based on the fusion of\nConvolutional Neural Networks (CNNs), Transformers, and Mamba components,\ndesigned to support both closed-set and open-set classification tasks. The\noptimized VMD enhances preprocessing efficiency and classification accuracy by\nfixing center frequencies and using closed-form solutions. HyDRA employs the\nTransformer Dynamic Sequence Encoder (TDSE) for global dependency modeling and\nthe Mamba Linear Flow Encoder (MLFE) for linear-complexity processing, adapting\nto varying conditions. Evaluation on public datasets demonstrates\nstate-of-the-art (SOTA) accuracy in closed-set scenarios and robust performance\nin our proposed open-set classification method, effectively identifying\nunauthorized devices. Deployed on NVIDIA Jetson Xavier NX, HyDRA achieves\nmillisecond-level inference speed with low power consumption, providing a\npractical solution for real-time wireless authentication in real-world\nenvironments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12133v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "HyDRA：一种用于闭集和开集RFFI的混合双模网络，采用优化VMD", "tldr": "HyDRA是一种结合了优化VMD、CNN、Transformer和Mamba的混合双模网络，用于闭集和开集射频指纹识别(RFFI)，实现了高精度、实时推理和低功耗。", "motivation": "无线通信系统中的设备识别对于安全至关重要，特别是访问控制。射频指纹识别(RFFI)通过利用硬件引起的信号失真提供了一种非加密解决方案。", "method": "本文提出了HyDRA（Hybrid Dual-mode RF Architecture），它集成了优化的变分模态分解（VMD）和一种基于卷积神经网络（CNNs）、Transformer和Mamba组件融合的新型架构，旨在支持闭集和开集分类任务。优化的VMD通过固定中心频率和使用闭式解来提高预处理效率和分类精度。HyDRA利用Transformer动态序列编码器（TDSE）进行全局依赖建模，并利用Mamba线性流编码器（MLFE）进行线性复杂度处理。", "result": "在公共数据集上，HyDRA在闭集场景中表现出最先进（SOTA）的精度，并在所提出的开集分类方法中表现出鲁棒的性能，有效识别未经授权的设备。部署在NVIDIA Jetson Xavier NX上，HyDRA实现了毫秒级的推理速度和低功耗。", "conclusion": "HyDRA为实时无线认证提供了一个实用的解决方案，能够有效识别授权和未经授权的设备，具有高精度、快速推理和低功耗的特点。", "translation": "设备识别对于无线通信系统的安全至关重要，特别是对于访问控制等应用。射频指纹识别（RFFI）通过利用硬件引起的信号失真提供了一种非加密解决方案。本文提出了HyDRA，一种混合双模射频架构，它集成了优化的变分模态分解（VMD）和一种基于卷积神经网络（CNNs）、Transformer和Mamba组件融合的新型架构，旨在支持闭集和开集分类任务。优化的VMD通过固定中心频率和使用闭式解来提高预处理效率和分类精度。HyDRA利用Transformer动态序列编码器（TDSE）进行全局依赖建模，并利用Mamba线性流编码器（MLFE）进行线性复杂度处理，以适应不同的条件。在公共数据集上的评估表明，在闭集场景中达到了最先进（SOTA）的精度，并在我们提出的开集分类方法中表现出鲁棒的性能，有效识别未经授权的设备。部署在NVIDIA Jetson Xavier NX上，HyDRA实现了毫秒级的推理速度和低功耗，为现实世界环境中的实时无线认证提供了一个实用的解决方案。", "summary": "HyDRA是一种新颖的混合双模网络，结合了优化VMD、CNN、Transformer和Mamba，专为闭集和开集射频指纹识别(RFFI)设计。该网络通过优化VMD提升预处理效率，并通过融合多种深度学习组件处理全局依赖和实现线性复杂度处理。实验证明，HyDRA在闭集RFFI中达到SOTA精度，并在开集场景中表现出鲁棒性，同时在嵌入式平台上实现毫秒级推理速度和低功耗，为实时无线认证提供了实用方案。", "keywords": "射频指纹识别, 混合网络, 变分模态分解, 闭集分类, 开集分类", "comments": "HyDRA的创新之处在于其混合双模架构，将优化的VMD与CNN、Transformer和Mamba等不同组件融合，以同时支持闭集和开集RFFI任务，这在实际应用中非常重要。其在嵌入式设备上的高效部署能力也增强了其实用性。"}}
{"id": "2507.11806", "title": "MOFSimBench: Evaluating Universal Machine Learning Interatomic Potentials In Metal--Organic Framework Molecular Modeling", "authors": ["Hendrik Kraß", "Ju Huang", "Seyed Mohamad Moosavi"], "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "Subjects:       Materials Science (cond-mat.mtrl-sci)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11806v1", "summary": "Universal machine learning interatomic potentials (uMLIPs) have emerged as\npowerful tools for accelerating atomistic simulations, offering scalable and\nefficient modeling with accuracy close to quantum calculations. However, their\nreliability and effectiveness in practical, real-world applications remain an\nopen question. Metal-organic frameworks (MOFs) and related nanoporous materials\nare highly porous crystals with critical relevance in carbon capture, energy\nstorage, and catalysis applications. Modeling nanoporous materials presents\ndistinct challenges for uMLIPs due to their diverse chemistry, structural\ncomplexity, including porosity and coordination bonds, and the absence from\nexisting training datasets. Here, we introduce MOFSimBench, a benchmark to\nevaluate uMLIPs on key materials modeling tasks for nanoporous materials,\nincluding structural optimization, molecular dynamics (MD) stability, the\nprediction of bulk properties, such as bulk modulus and heat capacity, and\nguest-host interactions. Evaluating over 20 models from various architectures\non a chemically and structurally diverse materials set, we find that\ntop-performing uMLIPs consistently outperform classical force fields and\nfine-tuned machine learning potentials across all tasks, demonstrating their\nreadiness for deployment in nanoporous materials modeling. Our analysis\nhighlights that data quality, particularly the diversity of training sets and\ninclusion of out-of-equilibrium conformations, plays a more critical role than\nmodel architecture in determining performance across all evaluated uMLIPs. We\nrelease our modular and extendable benchmarking framework at\nhttps://github.com/AI4ChemS/mofsim-bench, providing an open resource to guide\nthe adoption for nanoporous materials modeling and further development of\nuMLIPs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11806v1", "cate": "cond-mat.mtrl-sci", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MOFSimBench：评估金属有机框架分子建模中的通用机器学习原子间势", "tldr": "MOFSimBench基准测试发现，在纳米多孔材料建模中，通用机器学习原子间势（uMLIPs）表现优于传统方法，且数据质量比模型架构更重要。", "motivation": "通用机器学习原子间势（uMLIPs）在加速原子模拟方面展现出潜力，但其在金属有机框架（MOFs）等纳米多孔材料实际应用中的可靠性和有效性仍未确定，尤其考虑到MOFs的复杂化学性质和结构以及现有训练数据集中缺乏相关信息。", "method": "研究引入了MOFSimBench，一个用于评估uMLIPs在纳米多孔材料关键建模任务（包括结构优化、分子动力学稳定性、体性质预测和客体-主体相互作用）上的基准。该基准测试评估了来自不同架构的20多个模型，并使用了化学和结构多样化的材料集。", "result": "评估结果显示，顶级的uMLIPs在所有任务中均持续优于经典力场和微调的机器学习势。分析还强调，数据质量（特别是训练集的多样性和包含非平衡构象）在决定uMLIPs性能方面比模型架构更关键。MOFSimBench框架已开源。", "conclusion": "通用机器学习原子间势已准备好部署于纳米多孔材料建模中，并且数据质量而非模型架构是决定其性能的关键因素。MOFSimBench的发布为纳米多孔材料建模提供了开放资源，并指导uMLIPs的进一步开发。", "translation": "通用机器学习原子间势（uMLIPs）已成为加速原子模拟的强大工具，可提供可扩展、高效且接近量子计算精度的建模。然而，它们在实际应用中的可靠性和有效性仍是一个悬而未决的问题。金属有机框架（MOFs）及相关纳米多孔材料是高度多孔的晶体，在碳捕获、能量存储和催化应用中具有关键意义。由于其多样的化学性质、结构复杂性（包括孔隙率和配位键）以及现有训练数据集中缺乏相关信息，对纳米多孔材料进行建模对uMLIPs提出了独特的挑战。在此，我们介绍了MOFSimBench，这是一个用于评估uMLIPs在纳米多孔材料关键材料建模任务上的基准，包括结构优化、分子动力学（MD）稳定性、体性质预测（如体积模量和热容）以及客体-主体相互作用。通过评估来自不同架构的20多个模型，并在化学和结构多样化的材料集上进行测试，我们发现表现最佳的uMLIPs在所有任务中均持续优于经典力场和微调的机器学习势，这表明它们已准备好部署于纳米多孔材料建模中。我们的分析强调，数据质量，特别是训练集的多样性和包含非平衡构象，在决定所有被评估uMLIPs的性能方面，比模型架构扮演着更关键的角色。我们发布了我们的模块化和可扩展的基准测试框架，网址为https://github.com/AI4ChemS/mofsim-bench，为纳米多孔材料建模的采用和uMLIPs的进一步开发提供了开放资源。", "summary": "本研究推出了MOFSimBench，一个专门用于评估通用机器学习原子间势（uMLIPs）在金属有机框架（MOFs）等纳米多孔材料建模中性能的基准测试平台。通过对20多个uMLIP模型在结构优化、分子动力学稳定性、体性质预测和客体-主体相互作用等任务上的评估，结果表明顶级的uMLIPs表现优于传统方法。研究强调，数据质量，特别是训练集的多样性和包含非平衡构象，对uMLIPs的性能至关重要。MOFSimBench的开源旨在推动纳米多孔材料建模领域uMLIPs的应用和发展。", "keywords": "通用机器学习原子间势, 金属有机框架, 基准测试, 数据质量, 纳米多孔材料", "comments": "该论文通过引入MOFSimBench基准测试，填补了通用机器学习原子间势在复杂纳米多孔材料（如MOFs）应用中可靠性评估的空白。其创新之处在于提供了系统性的评估框架，并明确指出数据质量而非模型架构是决定uMLIPs性能的关键因素，这为未来的模型开发提供了重要指导。其开源的基准框架将极大地促进该领域的研究进展和实际应用。"}}
{"id": "2506.00713", "title": "AKReF: An argumentative knowledge representation framework for structured argumentation", "authors": ["Debarati Bhattacharjee", "Ashish Anand"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      20 pages, 7 figures, 2 tables", "url": "http://arxiv.org/abs/2506.00713v3", "summary": "This paper presents a framework to convert argumentative texts into argument\nknowledge graphs (AKG). The proposed argumentative knowledge representation\nframework (AKReF) extends the theoretical foundation and enables the AKG to\nprovide a graphical view of the argumentative structure that is easier to\nunderstand. Starting with basic annotations of argumentative components (ACs)\nand argumentative relations (ARs), we enrich the information by constructing a\nknowledge base (KB) graph with metadata attributes for nodes. Next, we apply\nmodus ponens on premises and inference rules from the KB to form arguments.\nFrom these arguments, we create an AKG. The nodes and edges of the AKG have\nattributes capturing key argumentative features such as the type of premise\n(e.g., axiom, ordinary premise, assumption), the type of inference rule (e.g.,\nstrict, defeasible), preference order over defeasible rules, markers (e.g.,\n\"therefore\", \"however\"), and the type of attack (e.g., undercut, rebuttal,\nundermining). We identify inference rules by locating a specific set of\nmarkers, called inference markers (IM). This, in turn, makes it possible to\nidentify undercut attacks previously undetectable in existing datasets. AKG\nprepares the ground for reasoning tasks, including checking the coherence of\narguments and identifying opportunities for revision. For this, it is essential\nto find indirect relations, many of which are implicit. Our proposed AKG\nformat, with annotated inference rules and modus ponens, helps reasoning models\nlearn the implicit, indirect relations that require inference over arguments\nand their interconnections. We use an essay from the AAEC dataset to illustrate\nthe framework. We further show its application in complex analyses such as\nextracting a conflict-free set and a maximal set of admissible arguments.", "comment": "20 pages, 7 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2506.00713v3", "cate": "cs.CL", "date": "2025-05-31", "updated": "2025-07-15", "AI": {"title_translation": "AKReF：一个用于结构化论证的论证知识表示框架", "tldr": "AKReF是一个将论证文本转换为论证知识图（AKG）的框架，通过丰富信息并识别推理规则和攻击类型，旨在提供更易理解的论证结构视图，并支持推理任务。", "motivation": "该研究旨在提出一个框架，能够将论证文本转换为论证知识图（AKG），以提供一个更易理解的论证结构图形视图，并为推理任务（如论证一致性检查和修订机会识别）奠定基础。", "method": "该框架（AKReF）首先对论证组件（ACs）和论证关系（ARs）进行基本标注，然后通过构建带有节点元数据属性的知识库（KB）图来丰富信息。接着，它将KB中的前提和推理规则应用于演绎推理（modus ponens）以形成论证。从这些论证中，创建论证知识图（AKG），其节点和边包含论证特征属性。通过定位推理标记（IM）来识别推理规则，从而识别出以前无法检测到的攻击类型。", "result": "所提出的AKReF框架能够将论证文本转换为论证知识图（AKG），提供易于理解的论证结构图形视图。AKG的节点和边捕获了关键的论证特征，例如前提类型、推理规则类型、可驳回规则的偏好顺序、标记和攻击类型。通过识别推理标记，能够识别以前在现有数据集中无法检测到的反驳攻击。AKG为推理任务（包括检查论证一致性和识别修订机会）奠定了基础，并且其格式有助于推理模型学习需要对论证及其相互连接进行推理的隐式、间接关系。该框架已通过AAEC数据集中的一篇文章进行了说明，并展示了其在提取无冲突集和最大可接受论证集等复杂分析中的应用。", "conclusion": "AKReF框架成功地将论证文本转化为结构化的论证知识图（AKG），通过丰富论证特征和识别推理规则，显著提高了论证结构的可理解性，并为复杂的论证推理任务（包括识别隐式关系和检测新型攻击）提供了基础。", "translation": "本文提出了一个将论证文本转换为论证知识图（AKG）的框架。所提出的论证知识表示框架（AKReF）扩展了理论基础，并使AKG能够提供一个更易于理解的论证结构图形视图。从论证组件（ACs）和论证关系（ARs）的基本标注开始，我们通过构建一个带有节点元数据属性的知识库（KB）图来丰富信息。接下来，我们对KB中的前提和推理规则应用演绎推理（modus ponens）来形成论证。从这些论证中，我们创建了一个AKG。AKG的节点和边具有捕获关键论证特征的属性，例如前提类型（例如，公理、普通前提、假设）、推理规则类型（例如，严格、可驳回）、可驳回规则的偏好顺序、标记（例如，“因此”、“然而”）以及攻击类型（例如，削弱、反驳、破坏）。我们通过定位一组特定的标记，称为推理标记（IM），来识别推理规则。这反过来使得识别以前在现有数据集中无法检测到的削弱攻击成为可能。AKG为推理任务奠定了基础，包括检查论证的一致性和识别修订的机会。为此，找到间接关系至关重要，其中许多是隐含的。我们提出的AKG格式，通过标注推理规则和演绎推理，有助于推理模型学习需要对论证及其相互连接进行推理的隐式、间接关系。我们使用AAEC数据集中的一篇文章来阐释该框架。我们进一步展示了其在复杂分析中的应用，例如提取无冲突集和最大可接受论证集。", "summary": "AKReF是一个新颖的论证知识表示框架，旨在将论证文本转换为结构化的论证知识图（AKG）。该框架通过标注论证组件和关系，并构建包含元数据属性的知识库来丰富信息。它利用演绎推理和识别推理规则（通过推理标记）来形成论证和AKG，AKG的节点和边捕获了详细的论证特征和攻击类型。AKReF使得识别此前难以检测的攻击成为可能，并为论证一致性检查和修订等推理任务奠定了基础，尤其有助于学习论证中隐含的间接关系。该框架已通过实例验证，并展示了其在复杂论证分析中的潜力。", "keywords": "论证知识图, 知识表示, 结构化论证, 推理规则, 论证分析", "comments": "AKReF框架的创新之处在于其将论证文本转化为结构化知识图的能力，并通过丰富的元数据属性和对推理规则的识别，提供了比现有方法更细致和可理解的论证表示。特别值得注意的是，通过引入“推理标记”来识别推理规则，这使得发现以前未被检测到的攻击类型成为可能，为论证分析带来了新的视角。该框架为论证推理任务（如一致性检查和隐式关系学习）奠定了坚实基础，具有重要的理论和应用价值。"}}
{"id": "2507.11649", "title": "ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs", "authors": ["Daniel Commey", "Benjamin Appiah", "Griffith S. Klogo", "Garth V. Crosby"], "categories": ["cs.LG", "cs.DC", "cs.NI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11649v1", "summary": "Federated Learning (FL) enables collaborative model training on decentralized\ndata without exposing raw data. However, the evaluation phase in FL may leak\nsensitive information through shared performance metrics. In this paper, we\npropose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to\nenable privacy-preserving and verifiable evaluation for FL. Instead of\nrevealing raw loss values, clients generate a succinct proof asserting that\ntheir local loss is below a predefined threshold. Our approach is implemented\nwithout reliance on external APIs, using self-contained modules for federated\nlearning simulation, ZKP circuit design, and experimental evaluation on both\nthe MNIST and Human Activity Recognition (HAR) datasets. We focus on a\nthreshold-based proof for a simple Convolutional Neural Network (CNN) model\n(for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate\nthe approach in terms of computational overhead, communication cost, and\nverifiability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11649v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "ZKP-FedEval：使用零知识证明的可验证和隐私保护联邦评估", "tldr": "ZKP-FedEval提出了一种利用零知识证明的联邦学习评估协议，在不泄露原始损失值的情况下，实现隐私保护和可验证的评估。", "motivation": "联邦学习的评估阶段可能通过共享性能指标泄露敏感信息。", "method": "本文提出了一种新的协议，将零知识证明（ZKPs）融入联邦学习的评估阶段，以实现隐私保护和可验证性。客户端不再直接揭示原始损失值，而是生成一个简洁的证明，断言其本地损失低于预定义的阈值。该方法不依赖外部API，使用自包含模块进行联邦学习模拟、ZKP电路设计，并在MNIST和人类活动识别（HAR）数据集上进行了实验评估。", "result": "该方法针对简单的卷积神经网络（CNN）模型（用于MNIST）和多层感知器（MLP）模型（用于HAR）的基于阈值的证明进行了评估，并分析了计算开销、通信成本和可验证性。", "conclusion": "本文成功提出并评估了一种利用零知识证明实现联邦学习中隐私保护和可验证评估的新协议，通过证明损失值低于阈值而非直接公开损失值，有效解决了评估阶段的信息泄露问题。", "translation": "联邦学习（FL）能够在不暴露原始数据的情况下，在去中心化数据上进行协作模型训练。然而，FL中的评估阶段可能会通过共享性能指标泄露敏感信息。在本文中，我们提出了一种新的协议，该协议结合了零知识证明（ZKPs），以实现FL的隐私保护和可验证评估。客户端无需揭示原始损失值，而是生成一个简洁的证明，断言其本地损失低于预定义的阈值。我们的方法不依赖外部API实现，使用自包含模块进行联邦学习模拟、ZKP电路设计以及在MNIST和人类活动识别（HAR）数据集上的实验评估。我们专注于简单卷积神经网络（CNN）模型（用于MNIST）和多层感知器（MLP）模型（用于HAR）的基于阈值的证明，并从计算开销、通信成本和可验证性方面评估了该方法。", "summary": "本文提出了一种名为ZKP-FedEval的新协议，旨在解决联邦学习评估阶段潜在的敏感信息泄露问题。通过整合零知识证明（ZKPs），该协议允许客户端在不暴露原始损失值的情况下，生成证明其本地损失低于预设阈值的简洁凭证，从而实现隐私保护和可验证的联邦评估。研究在MNIST和HAR数据集上对CNN和MLP模型进行了实验，评估了该方法的计算开销、通信成本和可验证性。", "keywords": "联邦学习, 零知识证明, 隐私保护, 模型评估, 可验证性", "comments": "该论文的创新点在于将零知识证明应用于联邦学习的评估阶段，特别是通过证明损失值低于阈值来保护隐私，而非传统地共享性能指标。这种方法有效解决了联邦学习中评估阶段的数据隐私泄露风险，具有重要的实践意义。其自包含的实现方式也表明了该方案的独立性和潜在的易部署性。"}}
{"id": "2409.15590", "title": "MapEx: Indoor Structure Exploration with Probabilistic Information Gain from Global Map Predictions", "authors": ["Cherie Ho", "Seungchan Kim", "Brady Moon", "Aditya Parandekar", "Narek Harutyunyan", "Chen Wang", "Katia Sycara", "Graeme Best", "Sebastian Scherer"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2409.15590v3", "summary": "Exploration is a critical challenge in robotics, centered on understanding\nunknown environments. In this work, we focus on robots exploring structured\nindoor environments which are often predictable and composed of repeating\npatterns. Most existing approaches, such as conventional frontier approaches,\nhave difficulty leveraging the predictability and explore with simple\nheuristics such as `closest first'. Recent works use deep learning techniques\nto predict unknown regions of the map, using these predictions for information\ngain calculation. However, these approaches are often sensitive to the\npredicted map quality or do not reason over sensor coverage. To overcome these\nissues, our key insight is to jointly reason over what the robot can observe\nand its uncertainty to calculate probabilistic information gain. We introduce\nMapEx, a new exploration framework that uses predicted maps to form\nprobabilistic sensor model for information gain estimation. MapEx generates\nmultiple predicted maps based on observed information, and takes into\nconsideration both the computed variances of predicted maps and estimated\nvisible area to estimate the information gain of a given viewpoint. Experiments\non the real-world KTH dataset showed on average 12.4% improvement than\nrepresentative map-prediction based exploration and 25.4% improvement than\nnearest frontier approach. Website: mapex-explorer.github.io", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2409.15590v3", "cate": "cs.RO", "date": "2024-09-23", "updated": "2025-07-16", "AI": {"title_translation": "MapEx：基于全局地图预测的概率信息增益的室内结构探索", "tldr": "MapEx通过结合机器人可观测性及其不确定性来计算概率信息增益，提高了室内环境探索效率，优于现有方法。", "motivation": "机器人探索未知环境是关键挑战。现有方法（如传统边界探索）难以利用结构化室内环境的可预测性，且基于深度学习的地图预测方法对预测质量敏感或不考虑传感器覆盖范围。", "method": "提出MapEx框架，利用预测地图构建概率传感器模型来估计信息增益。MapEx生成多个预测地图，并考虑预测地图的计算方差和估计可见区域来估算给定视点的信息增益。核心思想是联合考虑机器人能观察到的内容及其不确定性。", "result": "在真实世界的KTH数据集上，MapEx比基于地图预测的代表性探索方法平均提升12.4%，比最近边界方法平均提升25.4%。", "conclusion": "MapEx通过新颖的概率信息增益计算方法，显著提高了机器人对结构化室内环境的探索效率。", "translation": "探索是机器人学中的一个关键挑战，其核心在于理解未知环境。在这项工作中，我们专注于机器人探索结构化的室内环境，这些环境通常是可预测的并由重复模式组成。大多数现有方法，例如传统的边界探索方法，难以利用这种可预测性，并且仅使用“最近优先”等简单启发式方法进行探索。最近的工作使用深度学习技术来预测地图的未知区域，并利用这些预测来计算信息增益。然而，这些方法通常对预测地图的质量敏感，或者不考虑传感器覆盖范围。为了克服这些问题，我们的关键见解是共同推理机器人能够观察到的内容及其不确定性，以计算概率信息增益。我们引入了MapEx，一个使用预测地图形成概率传感器模型以进行信息增益估计的新探索框架。MapEx根据观测信息生成多个预测地图，并同时考虑预测地图的计算方差和估计可见区域来估计给定视点的信息增益。在真实世界的KTH数据集上的实验表明，MapEx比代表性的基于地图预测的探索方法平均提高了12.4%，比最近边界方法平均提高了25.4%。网站：mapex-explorer.github.io", "summary": "MapEx是一个用于机器人探索结构化室内环境的新框架。它解决了现有探索方法未能有效利用环境可预测性或对地图预测质量敏感的问题。MapEx的核心在于联合考虑机器人可观测性及其不确定性，通过生成多个预测地图并评估其方差和估计可见区域来计算概率信息增益，从而更有效地指导探索。实验证明，MapEx在探索效率上显著优于传统及基于地图预测的方法。", "keywords": "机器人探索, 概率信息增益, 地图预测, 室内环境, 传感器覆盖", "comments": "MapEx的创新点在于其概率信息增益的计算方式，它综合考虑了预测地图的不确定性和传感器的覆盖范围，这为机器人探索提供了一种更鲁棒和有效的方法。它克服了现有方法对单一预测结果的过度依赖，并实现了显著的性能提升。"}}
{"id": "2507.12062", "title": "MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning", "authors": ["Hongxu Ma", "Guanshuo Wang", "Fufu Yu", "Qiong Jia", "Shouhong Ding"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM'25", "url": "http://arxiv.org/abs/2507.12062v1", "summary": "Video Moment Retrieval (MR) and Highlight Detection (HD) aim to pinpoint\nspecific moments and assess clip-wise relevance based on the text query. While\nDETR-based joint frameworks have made significant strides, there remains\nuntapped potential in harnessing the intricate relationships between temporal\nmotion and spatial semantics within video content. In this paper, we propose\nthe Motion-Semantics DETR (MS-DETR), a framework that captures rich\nmotion-semantics features through unified learning for MR/HD tasks. The encoder\nfirst explicitly models disentangled intra-modal correlations within motion and\nsemantics dimensions, guided by the given text queries. Subsequently, the\ndecoder utilizes the task-wise correlation across temporal motion and spatial\nsemantics dimensions to enable precise query-guided localization for MR and\nrefined highlight boundary delineation for HD. Furthermore, we observe the\ninherent sparsity dilemma within the motion and semantics dimensions of MR/HD\ndatasets. To address this issue, we enrich the corpus from both dimensions by\ngeneration strategies and propose contrastive denoising learning to ensure the\nabove components learn robustly and effectively. Extensive experiments on four\nMR/HD benchmarks demonstrate that our method outperforms existing\nstate-of-the-art models by a margin. Our code is available at\nhttps://github.com/snailma0229/MS-DETR.git.", "comment": "Accepted by ACM MM'25", "pdf_url": "http://arxiv.org/pdf/2507.12062v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MS-DETR：通过联合运动-语义学习实现有效的视频精彩片段检索和高光检测", "tldr": "MS-DETR是一个新的框架，通过统一学习运动-语义特征来改进视频精彩片段检索和高光检测，解决了现有DETR模型未能充分利用时空关系的问题，并在多个基准测试中超越了现有SOTA模型。", "motivation": "现有的基于DETR的联合框架在视频精彩片段检索（MR）和高光检测（HD）任务中，未能充分利用视频内容中时间运动和空间语义之间复杂的内在关系。数据集中的运动和语义维度存在固有的稀疏性困境，影响模型的鲁棒性和有效性。", "method": "本文提出了运动-语义DETR（MS-DETR）框架，通过统一学习捕获丰富的运动-语义特征。编码器首先在文本查询的引导下，明确建模运动和语义维度内解耦的模态内关联。随后，解码器利用跨时间运动和空间语义维度上的任务感知关联，实现精确的查询引导定位（MR）和精细的高光边界描绘（HD）。此外，为了解决MR/HD数据集中运动和语义维度固有的稀疏性问题，通过生成策略丰富语料库，并提出了对比去噪学习以确保组件的鲁棒有效学习。", "result": "在四个MR/HD基准测试中，MS-DETR方法显著优于现有最先进的模型。", "conclusion": "MS-DETR通过创新的运动-语义联合学习和对比去噪策略，有效地解决了视频精彩片段检索和高光检测中的挑战，显著提升了模型性能，证明了充分利用时空运动-语义关系的有效性。", "translation": "视频精彩片段检索（MR）和高光检测（HD）旨在根据文本查询精确定位特定时刻并评估片段相关性。尽管基于DETR的联合框架取得了显著进展，但在利用视频内容中时间运动和空间语义之间复杂的内在关系方面仍有未开发的潜力。在本文中，我们提出了运动-语义DETR（MS-DETR），一个通过统一学习捕获丰富运动-语义特征的框架，用于MR/HD任务。编码器首先在给定文本查询的引导下，明确建模运动和语义维度内解耦的模态内关联。随后，解码器利用跨时间运动和空间语义维度上的任务感知关联，以实现MR的精确查询引导定位和HD的精细高光边界描绘。此外，我们观察到MR/HD数据集中运动和语义维度内固有的稀疏性困境。为了解决这个问题，我们通过生成策略从两个维度丰富语料库，并提出了对比去噪学习，以确保上述组件能够稳健有效地学习。在四个MR/HD基准测试上的大量实验表明，我们的方法显著优于现有最先进的模型。我们的代码可在https://github.com/snailma0229/MS-DETR.git获取。", "summary": "MS-DETR是一种新型的视频精彩片段检索（MR）和高光检测（HD）框架，旨在通过统一学习充分利用视频中时间运动和空间语义之间的复杂关系。该框架的编码器在文本查询引导下建模解耦的模态内关联，而解码器则利用任务感知关联进行精确的查询引导定位和高光边界描绘。为应对数据稀疏性，MS-DETR通过生成策略丰富语料库并引入对比去噪学习。实验结果表明，MS-DETR在多个MR/HD基准测试上超越了现有最先进的模型。", "keywords": "视频精彩片段检索, 高光检测, 运动-语义学习, DETR, 对比去噪学习", "comments": "MS-DETR的创新之处在于其对视频中运动和语义特征的联合统一学习，并通过解耦建模和任务感知关联来充分利用这些信息。它还创造性地通过生成策略和对比去噪学习来解决数据稀疏性问题，这对于提高模型在真实世界数据上的鲁棒性和泛化能力至关重要。该方法在多个基准测试中取得的显著性能提升，证明了其有效性和在该领域的领先地位。"}}
{"id": "2507.12382", "title": "Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation", "authors": ["Kaiwen Huang", "Yi Zhou", "Huazhu Fu", "Yizhe Zhang", "Chen Gong", "Tao Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages; 2 figures; Have been accepted by MICCAI 2025", "url": "http://arxiv.org/abs/2507.12382v1", "summary": "Semi-supervised medical image segmentation is a crucial technique for\nalleviating the high cost of data annotation. When labeled data is limited,\ntextual information can provide additional context to enhance visual semantic\nunderstanding. However, research exploring the use of textual data to enhance\nvisual semantic embeddings in 3D medical imaging tasks remains scarce. In this\npaper, we propose a novel text-driven multiplanar visual interaction framework\nfor semi-supervised medical image segmentation (termed Text-SemiSeg), which\nconsists of three main modules: Text-enhanced Multiplanar Representation (TMR),\nCategory-aware Semantic Alignment (CSA), and Dynamic Cognitive Augmentation\n(DCA). Specifically, TMR facilitates text-visual interaction through planar\nmapping, thereby enhancing the category awareness of visual features. CSA\nperforms cross-modal semantic alignment between the text features with\nintroduced learnable variables and the intermediate layer of visual features.\nDCA reduces the distribution discrepancy between labeled and unlabeled data\nthrough their interaction, thus improving the model's robustness. Finally,\nexperiments on three public datasets demonstrate that our model effectively\nenhances visual features with textual information and outperforms other\nmethods. Our code is available at https://github.com/taozh2017/Text-SemiSeg.", "comment": "10 pages; 2 figures; Have been accepted by MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.12382v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "文本驱动的多平面视觉交互半监督医学图像分割", "tldr": "提出了一种文本驱动的多平面视觉交互框架（Text-SemiSeg），用于半监督医学图像分割，通过文本增强视觉特征，并在三个公共数据集上表现优异。", "motivation": "半监督医学图像分割是减轻数据标注高成本的关键技术。当标记数据有限时，文本信息可以提供额外上下文以增强视觉语义理解。然而，探索使用文本数据增强3D医学图像任务中视觉语义嵌入的研究仍然稀缺。", "method": "本文提出了一种新颖的文本驱动多平面视觉交互框架Text-SemiSeg，用于半监督医学图像分割。该框架包含三个主要模块：文本增强多平面表示（TMR）通过平面映射促进文本-视觉交互并增强视觉特征的类别感知；类别感知语义对齐（CSA）在文本特征与视觉特征的中间层之间执行跨模态语义对齐；动态认知增强（DCA）通过标记和未标记数据之间的交互减少分布差异，提高模型鲁棒性。", "result": "在三个公共数据集上的实验表明，所提出的模型有效利用文本信息增强了视觉特征，并且性能优于其他现有方法。", "conclusion": "Text-SemiSeg框架通过创新性地结合文本信息，显著提升了半监督医学图像分割的性能，尤其在标记数据有限的情况下，为缓解高昂的数据标注成本提供了有效途径。", "translation": "半监督医学图像分割是减轻数据标注高成本的关键技术。当标记数据有限时，文本信息可以提供额外的上下文来增强视觉语义理解。然而，探索使用文本数据增强3D医学成像任务中视觉语义嵌入的研究仍然稀缺。在本文中，我们提出了一种新颖的文本驱动多平面视觉交互框架，用于半监督医学图像分割（称为Text-SemiSeg），该框架由三个主要模块组成：文本增强多平面表示（TMR）、类别感知语义对齐（CSA）和动态认知增强（DCA）。具体来说，TMR通过平面映射促进文本-视觉交互，从而增强视觉特征的类别感知。CSA在文本特征（引入可学习变量）与视觉特征的中间层之间执行跨模态语义对齐。DCA通过标记和未标记数据之间的交互减少它们之间的分布差异，从而提高模型的鲁棒性。最后，在三个公共数据集上的实验表明，我们的模型有效利用文本信息增强了视觉特征，并优于其他方法。我们的代码可在https://github.com/taozh2017/Text-SemiSeg获取。", "summary": "本文提出了一种名为Text-SemiSeg的文本驱动多平面视觉交互框架，旨在解决标记数据有限情况下的半监督医学图像分割问题。该框架通过文本增强多平面表示（TMR）促进文本与视觉交互，类别感知语义对齐（CSA）实现跨模态对齐，以及动态认知增强（DCA）减少数据分布差异，从而有效利用文本信息提升视觉特征，并在多个公共数据集上展现出优越的性能。", "keywords": "医学图像分割, 半监督学习, 文本驱动, 多平面交互, 跨模态学习", "comments": "该论文的创新点在于首次探索并成功地将文本信息引入到3D医学图像的半监督分割任务中，通过多平面视觉交互和跨模态语义对齐显著增强了视觉特征的语义理解能力，为缓解医学图像标注成本高昂的问题提供了一条新颖且有效的途径。"}}
{"id": "2505.14635", "title": "Bridging Predictive Coding and MDL: A Two-Part Code Framework for Deep Learning", "authors": ["Benjamin Prada", "Shion Matsumoto", "Abdul Malik Zekri", "Ankur Mali"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      24 pages, 2 figures", "url": "http://arxiv.org/abs/2505.14635v2", "summary": "We present the first theoretical framework that connects predictive coding\n(PC), a biologically inspired local learning rule, with the minimum description\nlength (MDL) principle in deep networks. We prove that layerwise PC performs\nblock-coordinate descent on the MDL two-part code objective, thereby jointly\nminimizing empirical risk and model complexity. Using Hoeffding's inequality\nand a prefix-code prior, we derive a novel generalization bound of the form\n$R(\\theta) \\le \\hat{R}(\\theta) + \\frac{L(\\theta)}{N}$, capturing the tradeoff\nbetween fit and compression. We further prove that each PC sweep monotonically\ndecreases the empirical two-part codelength, yielding tighter high-probability\nrisk bounds than unconstrained gradient descent. Finally, we show that repeated\nPC updates converge to a block-coordinate stationary point, providing an\napproximate MDL-optimal solution. To our knowledge, this is the first result\noffering formal generalization and convergence guarantees for PC-trained deep\nmodels, positioning PC as a theoretically grounded and biologically plausible\nalternative to backpropagation.", "comment": "24 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2505.14635v2", "cate": "cs.LG", "date": "2025-05-20", "updated": "2025-07-16", "AI": {"title_translation": "连接预测编码与MDL：深度学习的两部分编码框架", "tldr": "本文提出了一个将预测编码（PC）与最小描述长度（MDL）原理在深度网络中连接起来的理论框架，证明了PC在MDL目标上的优化能力，并提供了泛化和收敛性保证，表明PC是反向传播的一种理论上可靠且生物学上合理的替代方案。", "motivation": "该研究旨在建立预测编码（PC）与最小描述长度（MDL）原理之间的理论联系，为深度学习中的生物启发式局部学习规则提供形式化的泛化和收敛性保证，从而将PC定位为反向传播的一种理论上可靠且生物学上合理的替代方案。", "method": "本文提出了一个理论框架，证明了层级预测编码（PC）在最小描述长度（MDL）两部分编码目标上执行块坐标下降，从而联合最小化经验风险和模型复杂度。通过霍夫丁不等式和前缀码先验，推导了一个新的泛化界限。此外，还证明了每次PC扫描单调地减少经验两部分码长，并证明重复的PC更新收敛到块坐标平稳点。", "result": "研究证明，层级预测编码（PC）在最小描述长度（（MDL）两部分编码目标上执行块坐标下降，同时最小化经验风险和模型复杂度。推导出了一个形式为 $R(\theta) \\le \\hat{R}(\theta) + \\frac{L(\\theta)}{N}$ 的新型泛化界限。进一步证明了每次PC扫描单调地减少经验两部分码长，从而产生比无约束梯度下降更紧密的高概率风险界限。最后，结果显示重复的PC更新收敛到块坐标平稳点，提供了近似MDL最优解。", "conclusion": "本文首次为PC训练的深度模型提供了形式化的泛化和收敛性保证，将预测编码（PC）定位为一种理论上可靠且生物学上可行的反向传播替代方案。", "translation": "我们提出了第一个理论框架，将预测编码（PC）——一种受生物学启发的局部学习规则，与深度网络中的最小描述长度（MDL）原理联系起来。我们证明了层级PC在MDL两部分编码目标上执行块坐标下降，从而联合最小化经验风险和模型复杂度。利用霍夫丁不等式和前缀码先验，我们推导出了一个形式为 $R(\theta) \\le \\hat{R}(\theta) + \\frac{L(\\theta)}{N}$ 的新型泛化界限，捕捉了拟合与压缩之间的权衡。我们进一步证明，每次PC扫描单调地减少经验两部分码长，从而产生比无约束梯度下降更紧密的高概率风险界限。最后，我们表明重复的PC更新收敛到块坐标平稳点，提供了一个近似MDL最优解。据我们所知，这是第一个为PC训练的深度模型提供形式化泛化和收敛性保证的结果，将PC定位为反向传播的一种理论上可靠且生物学上合理的替代方案。", "summary": "本文提出了一个将预测编码（PC）与最小描述长度（MDL）原理相结合的理论框架，证明了层级PC通过块坐标下降优化MDL两部分编码目标，从而同时最小化经验风险和模型复杂度。研究推导了一个新的泛化界限，并证明了PC更新能单调减少经验码长，提供比传统梯度下降更紧密的风险界限。此外，还证明了PC更新会收敛到近似MDL最优解。这项工作首次为PC训练的深度模型提供了形式化的泛化和收敛性保证，确立了PC作为反向传播的理论上和生物学上可行的替代方案。", "keywords": "预测编码, 最小描述长度, 深度学习, 泛化, 收敛性", "comments": "本文的创新之处在于首次在理论上建立了预测编码（PC）与最小描述长度（MDL）原理之间的联系，并为PC训练的深度模型提供了严格的泛化和收敛性保证。这对于理解PC的优化机制及其在深度学习中的应用具有重要意义，同时也为探索生物启发式学习算法提供了坚实的理论基础，挑战了反向传播在深度学习中主导地位。"}}
{"id": "2507.11960", "title": "d-DQIVAR: Data-centric Visual Analytics and Reasoning for Data Quality Improvement", "authors": ["Hyein Hong", "Sangbong Yoo", "SeokHwan Choi", "Jisue Kim", "Seongbum Seo", "Haneol Cho", "Chansoo Kim", "Yun Jang"], "categories": ["cs.HC", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11960v1", "summary": "Approaches to enhancing data quality (DQ) are classified into two main\ncategories: data- and process-driven. However, prior research has predominantly\nutilized batch data preprocessing within the data-driven framework, which often\nproves insufficient for optimizing machine learning (ML) model performance and\nfrequently leads to distortions in data characteristics. Existing studies have\nprimarily focused on data preprocessing rather than genuine data quality\nimprovement (DQI). In this paper, we introduce d-DQIVAR, a novel visual\nanalytics system designed to facilitate DQI strategies aimed at improving ML\nmodel performance. Our system integrates visual analytics techniques that\nleverage both data-driven and process-driven approaches. Data-driven techniques\ntackle DQ issues such as imputation, outlier detection, deletion, format\nstandardization, removal of duplicate records, and feature selection.\nProcess-driven strategies encompass evaluating DQ and DQI procedures by\nconsidering DQ dimensions and ML model performance and applying the\nKolmogorov-Smirnov test. We illustrate how our system empowers users to harness\nexpert and domain knowledge effectively within a practical workflow through\ncase studies, evaluations, and user studies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11960v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "d-DQIVAR：以数据为中心的视觉分析与推理，用于数据质量改进", "tldr": "d-DQIVAR是一个新颖的视觉分析系统，通过结合数据驱动和过程驱动方法，旨在改进数据质量以提升机器学习模型性能。", "motivation": "现有数据质量增强方法主要依赖批处理数据预处理，这不足以优化机器学习模型性能，常导致数据特性失真，且多关注数据预处理而非真正的数据质量改进。", "method": "本文引入d-DQIVAR视觉分析系统，该系统整合了数据驱动（处理数据插补、异常值检测、删除、格式标准化、重复记录移除、特征选择等数据质量问题）和过程驱动（通过考虑数据质量维度、机器学习模型性能并应用Kolmogorov-Smirnov检验来评估数据质量和数据质量改进程序）的视觉分析技术。", "result": "通过案例研究、评估和用户研究，展示了系统如何赋能用户在实际工作流程中有效利用专家和领域知识。", "conclusion": "该系统能够有效帮助用户在实际工作流程中利用专家和领域知识，通过数据质量改进来提升机器学习模型的性能。", "translation": "数据质量（DQ）增强方法主要分为两大类：数据驱动和过程驱动。然而，先前的研究主要在数据驱动框架内利用批处理数据预处理，这通常不足以优化机器学习（ML）模型性能，并且经常导致数据特性失真。现有研究主要集中在数据预处理而非真正的数据质量改进（DQI）。在本文中，我们引入了d-DQIVAR，一个新颖的视觉分析系统，旨在促进旨在提高ML模型性能的DQI策略。我们的系统集成了利用数据驱动和过程驱动方法的视觉分析技术。数据驱动技术处理DQ问题，如插补、异常值检测、删除、格式标准化、重复记录移除和特征选择。过程驱动策略包括通过考虑DQ维度和ML模型性能以及应用Kolmogorov-Smirnov检验来评估DQ和DQI程序。我们通过案例研究、评估和用户研究，说明了我们的系统如何使​​用户能够在实际工作流程中有效利用专家和领域知识。", "summary": "本文提出d-DQIVAR，一个创新的视觉分析系统，旨在通过结合数据驱动和过程驱动方法来改进数据质量，从而提升机器学习模型的性能。该系统解决了现有批处理预处理方法在优化ML性能方面的不足和数据失真问题，并专注于真正的数据质量改进。d-DQIVAR集成了多种数据处理技术和评估策略，并通过案例研究、评估和用户研究验证了其在实际应用中赋能用户利用领域知识的能力。", "keywords": "数据质量改进, 视觉分析, 机器学习性能, 数据驱动, 过程驱动", "comments": "该论文的创新点在于其提出的d-DQIVAR系统将数据驱动和过程驱动的视觉分析技术有机结合，专注于实现真正的数据质量改进以优化机器学习模型性能，而非仅仅停留在数据预处理层面。这对于提高ML模型的可靠性和准确性具有重要意义。通过整合多种数据质量处理技术和评估方法，并辅以专家知识的利用，该系统提供了一个全面的解决方案。"}}
{"id": "2507.11694", "title": "ExpliCIT-QA: Explainable Code-Based Image Table Question Answering", "authors": ["Maximiliano Hormazábal Lagos", "Álvaro Bueno Sáez", "Pedro Alonso Doval", "Jorge Alcalde Vesteiro", "Héctor Cerezo-Costas"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This work has been accepted for presentation at the 24nd Portuguese Conference on Artificial Intelligence (EPIA 2025) and will be published in the proceedings by Springer in the Lecture Notes in Computer Science (LNCS) series. Please cite the published version when available", "url": "http://arxiv.org/abs/2507.11694v1", "summary": "We present ExpliCIT-QA, a system that extends our previous MRT approach for\ntabular question answering into a multimodal pipeline capable of handling\ncomplex table images and providing explainable answers. ExpliCIT-QA follows a\nmodular design, consisting of: (1) Multimodal Table Understanding, which uses a\nChain-of-Thought approach to extract and transform content from table images;\n(2) Language-based Reasoning, where a step-by-step explanation in natural\nlanguage is generated to solve the problem; (3) Automatic Code Generation,\nwhere Python/Pandas scripts are created based on the reasoning steps, with\nfeedback for handling errors; (4) Code Execution to compute the final answer;\nand (5) Natural Language Explanation that describes how the answer was\ncomputed. The system is built for transparency and auditability: all\nintermediate outputs, parsed tables, reasoning steps, generated code, and final\nanswers are available for inspection. This strategy works towards closing the\nexplainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on\nthe TableVQA-Bench benchmark, comparing it with existing baselines. We\ndemonstrated improvements in interpretability and transparency, which open the\ndoor for applications in sensitive domains like finance and healthcare where\nauditing results are critical.", "comment": "This work has been accepted for presentation at the 24nd Portuguese\n  Conference on Artificial Intelligence (EPIA 2025) and will be published in\n  the proceedings by Springer in the Lecture Notes in Computer Science (LNCS)\n  series. Please cite the published version when available", "pdf_url": "http://arxiv.org/pdf/2507.11694v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "ExpliCIT-QA：可解释的基于代码的图像表格问答", "tldr": "ExpliCIT-QA是一个多模态系统，它扩展了之前的表格问答方法，能够处理复杂的表格图像并提供可解释的答案，通过链式思考、语言推理、代码生成和执行来提高透明度和可审计性。", "motivation": "该研究的动机是弥合端到端TableVQA系统中的可解释性差距，并为金融和医疗等敏感领域提供可审计的结果。", "method": "ExpliCIT-QA采用模块化设计，包括：1) 多模态表格理解，使用链式思考从表格图像中提取和转换内容；2) 基于语言的推理，生成自然语言的逐步解释；3) 自动代码生成，根据推理步骤创建Python/Pandas脚本并处理错误；4) 代码执行以计算最终答案；5) 自然语言解释，描述答案的计算方式。所有中间输出、解析后的表格、推理步骤、生成的代码和最终答案都可供检查，以实现透明度和可审计性。", "result": "ExpliCIT-QA在TableVQA-Bench基准测试上进行了评估，与现有基线进行了比较，并展示了在可解释性和透明度方面的改进。", "conclusion": "该系统在可解释性和透明度方面的改进，为金融和医疗等结果审计至关重要的敏感领域应用打开了大门。", "translation": "我们提出了ExpliCIT-QA，一个将我们之前用于表格问答的MRT方法扩展为多模态管道的系统，能够处理复杂的表格图像并提供可解释的答案。ExpliCIT-QA遵循模块化设计，包括：(1) 多模态表格理解，它使用链式思考方法从表格图像中提取和转换内容；(2) 基于语言的推理，生成自然语言的逐步解释来解决问题；(3) 自动代码生成，根据推理步骤创建Python/Pandas脚本，并提供错误处理反馈；(4) 代码执行以计算最终答案；以及 (5) 自然语言解释，描述答案是如何计算的。该系统旨在提高透明度和可审计性：所有中间输出、解析后的表格、推理步骤、生成的代码和最终答案都可供检查。该策略旨在弥合端到端TableVQA系统中的可解释性差距。我们在TableVQA-Bench基准测试上评估了ExpliCIT-QA，并与现有基线进行了比较。我们展示了在可解释性和透明度方面的改进，这为金融和医疗等结果审计至关重要的敏感领域的应用打开了大门。", "summary": "ExpliCIT-QA是一个创新的多模态系统，旨在通过结合链式思考、语言推理和代码生成与执行来解决图像表格问答中的可解释性问题。它扩展了现有的MRT方法，能够处理复杂的表格图像并提供透明、可审计的答案。该系统在TableVQA-Bench上表现出改进，特别是在可解释性和透明度方面，使其适用于需要高可信度的敏感领域。", "keywords": "图像表格问答, 可解释性AI, 多模态理解, 代码生成, 表格VQA", "comments": "该论文的关键创新在于其模块化、可解释的设计，通过提供中间步骤（如链式思考、自然语言推理和可执行代码）来增强透明度和可审计性。这对于将AI系统应用于金融和医疗等高风险领域至关重要，因为这些领域需要结果的可信度和可追溯性。通过结合多模态理解和代码生成，它有效地弥合了传统端到端系统中的“黑箱”问题。"}}
{"id": "2507.12259", "title": "Neural Co-state Regulator: A Data-Driven Paradigm for Real-time Optimal Control with Input Constraints", "authors": ["Lihan Lian", "Yuxin Tong", "Uduak Inyang-Udoh"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12259v1", "summary": "We propose a novel unsupervised learning framework for solving nonlinear\noptimal control problems (OCPs) with input constraints in real-time. In this\nframework, a neural network (NN) learns to predict the optimal co-state\ntrajectory that minimizes the control Hamiltonian for a given system, at any\nsystem's state, based on the Pontryagin's Minimum Principle (PMP).\nSpecifically, the NN is trained to find the norm-optimal co-state solution that\nsimultaneously satisfies the nonlinear system dynamics and minimizes a\nquadratic regulation cost. The control input is then extracted from the\npredicted optimal co-state trajectory by solving a quadratic program (QP) to\nsatisfy input constraints and optimality conditions. We coin the term neural\nco-state regulator (NCR) to describe the combination of the co-state NN and\ncontrol input QP solver. To demonstrate the effectiveness of the NCR, we\ncompare its feedback control performance with that of an expert nonlinear model\npredictive control (MPC) solver on a unicycle model. Because the NCR's training\ndoes not rely on expert nonlinear control solvers which are often suboptimal,\nthe NCR is able to produce solutions that outperform the nonlinear MPC solver\nin terms of convergence error and input trajectory smoothness even for system\nconditions that are outside its original training domain. At the same time, the\nNCR offers two orders of magnitude less computational time than the nonlinear\nMPC.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12259v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "神经协态调节器：一种用于实时带输入约束最优控制的数据驱动范式", "tldr": "提出了一种基于无监督学习的神经协态调节器（NCR），用于实时解决带输入约束的非线性最优控制问题，性能优于传统MPC且计算效率更高。", "motivation": "解决实时非线性最优控制问题（OCPs）中的输入约束挑战，并克服传统方法的计算效率和对专家求解器依赖的局限性。", "method": "提出神经协态调节器（NCR）。它是一个无监督学习框架，其中神经网络（NN）根据Pontryagin最小原理（PMP）学习预测最优协态轨迹，以最小化控制哈密顿量。NN训练目标是找到同时满足非线性系统动力学并最小化二次调节成本的范数最优协态解。控制输入通过求解二次规划（QP）从预测的协态轨迹中提取，以满足输入约束和最优性条件。", "result": "NCR在收敛误差和输入轨迹平滑度方面优于非线性MPC求解器，即使在训练域之外的系统条件下也是如此。NCR的计算时间比非线性MPC少两个数量级。NCR的训练不依赖于通常次优的专家非线性控制求解器。", "conclusion": "神经协态调节器（NCR）提供了一种有效且高效的实时最优控制方法，能够处理输入约束，并在性能和计算效率上超越了传统的非线性MPC。", "translation": "我们提出了一种新颖的无监督学习框架，用于实时解决带输入约束的非线性最优控制问题（OCPs）。在该框架中，神经网络（NN）根据庞特里亚金最小化原理（PMP），学习预测在任何给定系统状态下使控制哈密顿量最小化的最优协态轨迹。具体来说，NN被训练以找到同时满足非线性系统动力学并最小化二次调节成本的范数最优协态解。然后，通过求解二次规划（QP）从预测的最优协态轨迹中提取控制输入，以满足输入约束和最优性条件。我们将协态NN和控制输入QP求解器的组合称为神经协态调节器（NCR）。为了证明NCR的有效性，我们将其反馈控制性能与专家非线性模型预测控制（MPC）求解器在独轮车模型上进行了比较。由于NCR的训练不依赖于通常次优的专家非线性控制求解器，因此即使在超出其原始训练域的系统条件下，NCR也能生成在收敛误差和输入轨迹平滑度方面优于非线性MPC求解器的解决方案。同时，NCR的计算时间比非线性MPC少两个数量级。", "summary": "本文提出了一种名为神经协态调节器（NCR）的无监督学习框架，用于实时解决带输入约束的非线性最优控制问题。NCR利用神经网络预测最优协态轨迹，并结合二次规划求解器提取满足约束的控制输入。实验表明，NCR在收敛误差、输入轨迹平滑度和计算效率方面均显著优于传统非线性模型预测控制（MPC），且其训练不依赖于专家求解器，展现出良好的泛化能力。", "keywords": "实时最优控制, 神经协态调节器, 无监督学习, 输入约束, 庞特里亚金最小原理", "comments": "这项工作提出了一个创新的数据驱动范式，将深度学习与经典最优控制理论（PMP）相结合，解决了实时带约束最优控制的挑战。其核心创新在于利用神经网络学习协态，从而避免了传统MPC的在线优化计算负担，显著提升了计算效率。无监督学习的特性也减少了对大量高质量专家数据的依赖。在性能上超越传统MPC，并在训练域外展现泛化能力，是其重要亮点。这为未来复杂系统的实时最优控制提供了一个有潜力的方向。"}}
{"id": "2412.18375", "title": "Many Objective Problems Where Crossover is Provably Essential", "authors": ["Andre Opris"], "categories": ["cs.NE", "cs.AI", "cs.DS", "68Q25, 68Q87, 68T20, 68W20, 68W40, 68W50", "F.2.2; G.3; I.2.8"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      Conference version appeared at AAAI 2025, submitted to artificial intelligence", "url": "http://arxiv.org/abs/2412.18375v2", "summary": "This article addresses theory in evolutionary many-objective optimization and\nfocuses on the role of crossover operators. The advantages of using crossover\nare hardly understood and rigorous runtime analyses with crossover are lagging\nfar behind its use in practice, specifically in the case of more than two\nobjectives. We present two many-objective problems $RR_{\\text{RO}}$ and\n$uRR_{\\text{RO}}$ together with a theoretical runtime analysis of the GSEMO and\nthe widely used NSGA-III algorithm to demonstrate that one point crossover on\n$RR_{\\text{RO}}$, as well as uniform crossover on $uRR_{\\text{RO}}$, can yield\nan exponential speedup in the runtime. In particular, when the number of\nobjectives is constant, this algorithms can find the Pareto set of both\nproblems in expected polynomial time when using crossover while without\ncrossover they require exponential time to even find a single Pareto-optimal\npoint. For both problems, we also demonstrate a significant performance gap in\ncertain superconstant parameter regimes for the number of objectives. To the\nbest of our knowledge, this is one of the first rigorous runtime analysis in\nmany-objective optimization which demonstrates an exponential performance gap\nwhen using crossover for more than two objectives. Additionally, it is the\nfirst runtime analysis involving crossover in many-objective optimization where\nthe number of objectives is not necessarily constant.", "comment": "Conference version appeared at AAAI 2025, submitted to artificial\n  intelligence", "pdf_url": "http://arxiv.org/pdf/2412.18375v2", "cate": "cs.NE", "date": "2024-12-24", "updated": "2025-07-15", "AI": {"title_translation": "交叉算子在多目标问题中被证明是必不可少的", "tldr": "本文通过理论运行时分析，证明在某些多目标优化问题中，使用交叉算子可以带来指数级的运行时加速，尤其是在目标数量超过两个时。", "motivation": "进化式多目标优化中，交叉算子的优势尚不明确，且涉及交叉算子的严格运行时分析远落后于其实际应用，特别是在目标数量超过两个的情况下。", "method": "提出了两个多目标问题$RR_{\\text{RO}}$和$uRR_{\\text{RO}}$。对GSEMO和NSGA-III算法进行了理论运行时分析，分别在$RR_{\\text{RO}}$上使用单点交叉和在$uRR_{\\text{RO}}$上使用均匀交叉。", "result": "当目标数量恒定时，使用交叉算子的算法在预期多项式时间内找到两个问题的Pareto集，而没有交叉算子则需要指数时间才能找到一个Pareto最优解。对于两个问题，在目标数量为某些超常数参数区域时，也展示了显著的性能差距。", "conclusion": "这是首次在多目标优化中，针对目标数量超过两个的情况，进行了严谨的运行时分析，并证明了使用交叉算子可以带来指数级的性能提升。同时，这也是首次针对目标数量不一定是常数的多目标优化中的交叉算子进行运行时分析。", "translation": "本文探讨了进化式多目标优化理论，并重点关注交叉算子的作用。使用交叉算子的优势尚不明确，且涉及交叉算子的严格运行时分析远落后于其实际应用，特别是在目标数量超过两个的情况下。我们提出了两个多目标问题$RR_{\\text{RO}}$和$uRR_{\\text{RO}}$，并对GSEMO和广泛使用的NSGA-III算法进行了理论运行时分析，以证明在$RR_{\\text{RO}}$上使用单点交叉，以及在$uRR_{\\text{RO}}$上使用均匀交叉，可以带来运行时上的指数级加速。特别是，当目标数量恒定时，这些算法在使用交叉算子时，可以在预期多项式时间内找到这两个问题的Pareto集，而没有交叉算子时，它们甚至需要指数时间才能找到一个Pareto最优解。对于这两个问题，我们还在目标数量的某些超常数参数区域内展示了显著的性能差距。据我们所知，这是多目标优化中首次进行的严谨运行时分析之一，证明了当目标数量超过两个时使用交叉算子会产生指数级性能差距。此外，这是首次涉及交叉算子的多目标优化运行时分析，其中目标数量不一定是常数。", "summary": "该研究深入探讨了进化式多目标优化中交叉算子的关键作用，指出其理论优势和严格运行时分析的不足。论文提出了两个新的多目标问题$RR_{\\text{RO}}$和$uRR_{\\text{RO}}$，并对GSEMO和NSGA-III算法进行了理论运行时分析。结果表明，在这些问题上，使用特定的交叉算子（单点交叉或均匀交叉）可以使算法在预期多项式时间内找到Pareto集，而没有交叉算子则需要指数时间。研究还揭示了在目标数量为超常数参数时，交叉算子带来的显著性能提升，填补了多目标优化领域在交叉算子理论分析方面的空白，特别是针对目标数量不恒定的情况。", "keywords": "多目标优化, 交叉算子, 运行时分析, GSEMO, NSGA-III", "comments": "这篇论文的创新之处在于首次提供了多目标优化中交叉算子带来指数级性能提升的严格运行时分析，特别是在目标数量超过两个或不为常数的情况下。这对于理解进化算法的效率边界和指导实际应用中的算子选择具有重要意义，有助于弥补理论与实践之间的差距。"}}
{"id": "2505.11493", "title": "GIE-Bench: Towards Grounded Evaluation for Text-Guided Image Editing", "authors": ["Yusu Qian", "Jiasen Lu", "Tsu-Jui Fu", "Xinze Wang", "Chen Chen", "Yinfei Yang", "Wenze Hu", "Zhe Gan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2505.11493v2", "summary": "Editing images using natural language instructions has become a natural and\nexpressive way to modify visual content; yet, evaluating the performance of\nsuch models remains challenging. Existing evaluation approaches often rely on\nimage-text similarity metrics like CLIP, which lack precision. In this work, we\nintroduce a new benchmark designed to evaluate text-guided image editing models\nin a more grounded manner, along two critical dimensions: (i) functional\ncorrectness, assessed via automatically generated multiple-choice questions\nthat verify whether the intended change was successfully applied; and (ii)\nimage content preservation, which ensures that non-targeted regions of the\nimage remain visually consistent using an object-aware masking technique and\npreservation scoring. The benchmark includes over 1000 high-quality editing\nexamples across 20 diverse content categories, each annotated with detailed\nediting instructions, evaluation questions, and spatial object masks. We\nconduct a large-scale study comparing GPT-Image-1, the latest flagship in the\ntext-guided image editing space, against several state-of-the-art editing\nmodels, and validate our automatic metrics against human ratings. Results show\nthat GPT-Image-1 leads in instruction-following accuracy, but often\nover-modifies irrelevant image regions, highlighting a key trade-off in the\ncurrent model behavior. GIE-Bench provides a scalable, reproducible framework\nfor advancing more accurate evaluation of text-guided image editing.", "comment": "Project page: https://sueqian6.github.io/GIE-Bench-web/", "pdf_url": "http://arxiv.org/pdf/2505.11493v2", "cate": "cs.CV", "date": "2025-05-16", "updated": "2025-07-16", "AI": {"title_translation": "GIE-Bench：迈向文本引导图像编辑的扎实评估", "tldr": "本文提出了GIE-Bench，一个用于文本引导图像编辑模型评估的新基准，它通过功能正确性和图像内容保留两个维度进行更扎实的评估，并揭示了当前模型行为中的关键权衡。", "motivation": "现有的文本引导图像编辑模型评估方法通常依赖于图像-文本相似性指标（如CLIP），但这些方法缺乏精确性，使得评估模型性能具有挑战性。", "method": "本文引入了一个名为GIE-Bench的新基准，旨在从两个关键维度更扎实地评估文本引导图像编辑模型：(i) 功能正确性，通过自动生成的多项选择题来验证预期的更改是否成功应用；(ii) 图像内容保留，通过对象感知掩蔽技术和保留评分确保图像的非目标区域在视觉上保持一致。该基准包含1000多个高质量的编辑示例，涵盖20个不同的内容类别，每个示例都标注了详细的编辑指令、评估问题和空间对象掩码。", "result": "大规模研究比较了GPT-Image-1与几种最先进的编辑模型，并验证了自动度量与人类评分的一致性。结果显示，GPT-Image-1在指令遵循准确性方面领先，但经常过度修改不相关的图像区域，这突出了当前模型行为中的一个关键权衡。", "conclusion": "GIE-Bench提供了一个可扩展、可复现的框架，用于推进文本引导图像编辑的更准确评估。", "translation": "使用自然语言指令编辑图像已成为修改视觉内容的一种自然而富有表现力的方式；然而，评估此类模型的性能仍然具有挑战性。现有的评估方法通常依赖于图像-文本相似性指标，如CLIP，但其缺乏精确性。在这项工作中，我们引入了一个新的基准，旨在以更扎实的方式评估文本引导图像编辑模型，该基准从两个关键维度进行评估：(i) 功能正确性，通过自动生成的多项选择题来验证预期的更改是否成功应用；以及 (ii) 图像内容保留，它使用对象感知掩蔽技术和保留评分来确保图像的非目标区域在视觉上保持一致。该基准包括20个不同内容类别的1000多个高质量编辑示例，每个示例都标注了详细的编辑指令、评估问题和空间对象掩码。我们进行了一项大规模研究，比较了文本引导图像编辑领域的最新旗舰GPT-Image-1与几种最先进的编辑模型，并根据人类评分验证了我们的自动度量。结果显示，GPT-Image-1在指令遵循准确性方面领先，但经常过度修改不相关的图像区域，这突出显示了当前模型行为中的一个关键权衡。GIE-Bench为推进文本引导图像编辑的更准确评估提供了一个可扩展、可复现的框架。", "summary": "本文介绍了GIE-Bench，一个用于评估文本引导图像编辑模型的新基准。该基准通过两个核心维度——功能正确性（使用自动多项选择题）和图像内容保留（通过对象感知掩蔽）——来提供更精确和扎实的评估。GIE-Bench包含1000多个带详细标注的编辑示例。研究使用该基准评估了GPT-Image-1及其他SOTA模型，发现GPT-Image-1在指令遵循上表现突出，但存在过度修改非目标区域的问题，揭示了当前模型性能的权衡。GIE-Bench旨在提供一个可扩展、可复现的框架，以促进文本引导图像编辑评估的进步。", "keywords": "文本引导图像编辑, 图像评估, GIE-Bench, 功能正确性, 内容保留", "comments": "GIE-Bench的创新之处在于其双维度评估方法，特别是引入了功能正确性的自动问答和对象感知的图像内容保留评估，这比单纯依赖图像-文本相似性指标更加精细和“扎实”。该基准提供了高质量、详细标注的数据集，对推进文本引导图像编辑模型的评估和发展具有重要意义。它也揭示了当前先进模型（如GPT-Image-1）在指令遵循与内容保留之间的权衡，为未来的研究指明了方向。"}}
{"id": "2507.11976", "title": "A Task Taxonomy for Conformance Checking", "authors": ["Jana-Rebecca Rehse", "Michael Grohs", "Finn Klessascheck", "Lisa-Marie Klein", "Tatiana von Landesberger", "Luise Pufahl"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Preprint submitted to Information Systems", "url": "http://arxiv.org/abs/2507.11976v1", "summary": "Conformance checking is a sub-discipline of process mining, which compares\nobserved process traces with a process model to analyze whether the process\nexecution conforms with or deviates from the process design. Organizations can\nleverage this analysis, for example to check whether their processes comply\nwith internal or external regulations or to identify potential improvements.\nGaining these insights requires suitable visualizations, which make complex\nresults accessible and actionable. So far, however, the development of\nconformance checking visualizations has largely been left to tool vendors. As a\nresult, current tools offer a wide variety of visual representations for\nconformance checking, but the analytical purposes they serve often remain\nunclear. However, without a systematic understanding of these purposes, it is\ndifficult to evaluate the visualizations' usefulness. Such an evaluation hence\nrequires a deeper understanding of conformance checking as an analysis domain.\nTo this end, we propose a task taxonomy, which categorizes the tasks that can\noccur when conducting conformance checking analyses. This taxonomy supports\nresearchers in determining the purpose of visualizations, specifying relevant\nconformance checking tasks in terms of their goal, means, constraint type, data\ncharacteristics, data target, and data cardinality. Combining concepts from\nprocess mining and visual analytics, we address researchers from both\ndisciplines to enable and support closer collaborations.", "comment": "Preprint submitted to Information Systems", "pdf_url": "http://arxiv.org/pdf/2507.11976v1", "cate": "cs.SE", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "一种一致性检查的任务分类法", "tldr": "现有的一致性检查可视化工具目的不清，难以评估。本文提出了一种任务分类法，用于系统地理解一致性检查任务，从而支持可视化工具的评估与开发。", "motivation": "现有一致性检查可视化工具种类繁多，但其分析目的不明确，导致难以评估其有用性。需要对一致性检查作为分析领域有更深入的理解。", "method": "提出了一种任务分类法（task taxonomy），用于对执行一致性检查分析时可能出现的任务进行分类。", "result": "该分类法支持研究人员确定可视化的目的，并根据目标、方法、约束类型、数据特征、数据目标和数据基数来指定相关的一致性检查任务。它结合了过程挖掘和视觉分析的概念，旨在促进这两个学科研究人员之间的合作。", "conclusion": "该任务分类法提供了一个系统框架，以更好地理解和评估一致性检查可视化工具，并促进跨学科合作。", "translation": "一致性检查是过程挖掘的一个子学科，它将观察到的过程轨迹与过程模型进行比较，以分析过程执行是否符合或偏离过程设计。组织可以利用这种分析，例如检查其过程是否符合内部或外部规定，或识别潜在的改进。获得这些见解需要合适的可视化，使复杂的结果易于理解和操作。然而，到目前为止，一致性检查可视化的开发在很大程度上留给了工具供应商。结果是，目前的工具提供各种各样的一致性检查视觉表示，但它们所服务的分析目的往往不明确。然而，如果没有对这些目的的系统理解，就很难评估可视化的有用性。因此，这种评估需要对一致性检查作为分析领域有更深入的理解。为此，我们提出了一种任务分类法，它对执行一致性检查分析时可能出现的任务进行分类。这种分类法支持研究人员确定可视化的目的，根据其目标、方法、约束类型、数据特征、数据目标和数据基数来指定相关的一致性检查任务。结合过程挖掘和视觉分析的概念，我们面向这两个学科的研究人员，以实现和支持更紧密的合作。", "summary": "本文提出了一种针对一致性检查的任务分类法，旨在解决现有可视化工具分析目的不明确导致难以评估其有用性的问题。该分类法通过对一致性检查任务进行系统分类，并明确其目标、方法、约束类型、数据特征等维度，帮助研究人员理解和指定可视化的目的，从而促进过程挖掘和视觉分析领域的合作，提升一致性检查工具的开发和评估。", "keywords": "一致性检查, 任务分类法, 过程挖掘, 可视化, 视觉分析", "comments": "这篇论文通过提出一个任务分类法，为一致性检查领域提供了一个急需的系统化框架。其创新之处在于将过程挖掘和视觉分析结合，为理解和评估复杂的可视化工具提供了一个统一的视角。这对于提升一致性检查工具的可用性和有效性具有重要意义，因为它将开发重点从单纯的视觉表现转向其背后的分析目的，有助于指导未来工具的设计。"}}
{"id": "2507.11836", "title": "HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction", "authors": ["Jian Gao", "Jianshe Wu", "JingYi Ding"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11836v1", "summary": "Dynamic link prediction in continuous-time dynamic graphs is a fundamental\ntask for modeling evolving complex systems. Existing node-centric and\nevent-centric methods focus on individual interactions or atomic states,\nfailing to capture the structural cohesion of composite hyper-events, groups of\ncausally related events. To address this, we propose HyperEvent, a framework\nreframing dynamic link prediction as hyper-event recognition. Central to\nHyperEvent is the dynamic construction of an association sequence using event\ncorrelation vectors. These vectors quantify pairwise dependencies between the\nquery event and relevant historical events, thereby characterizing the\nstructural cohesion of a potential hyper-event. The framework predicts the\noccurrence of the query event by evaluating whether it collectively forms a\nvalid hyper-event with these historical events. Notably, HyperEvent outperforms\nstate-of-the-art methods on 4 out of 5 datasets in the official leaderboard.\nFor scalability, we further introduce an efficient parallel training algorithm\nthat segments large event streams to enable concurrent training. Experiments\nvalidate HyperEvent's superior accuracy and efficiency on large-scale graphs.\nAmong which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank\nover state-of-the-art baseline on the large-scale Flight dataset while\nutilizing only 10.17% of the training time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11836v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "HyperEvent：学习大规模动态链接预测的内聚事件", "tldr": "HyperEvent是一个新的框架，通过识别内聚的“超事件”来改进大规模动态图中的动态链接预测，解决了现有方法未能捕捉复合事件结构内聚性的问题，并在准确性和效率上超越了现有技术。", "motivation": "现有的节点中心和事件中心方法在连续时间动态图的动态链接预测中，未能捕捉复合超事件（即因果相关事件组）的结构内聚性，而这种能力对于建模演化复杂系统至关重要。", "method": "HyperEvent框架将动态链接预测重新定义为超事件识别。其核心是动态构建一个使用事件相关向量的关联序列，这些向量量化查询事件与相关历史事件之间的成对依赖关系，从而表征潜在超事件的结构内聚性。该框架通过评估查询事件是否与这些历史事件共同形成一个有效的超事件来预测其发生。此外，为实现可扩展性，还引入了一种高效的并行训练算法，该算法通过分段大型事件流来实现并发训练。", "result": "HyperEvent在官方排行榜的5个数据集中有4个超越了最先进的方法。在大型Flight数据集上，HyperEvent在平均倒数排名（MRR）上比最先进的基线提高了6.95%，同时仅使用了10.17%的训练时间。实验验证了HyperEvent在大规模图上的卓越准确性和效率。", "conclusion": "HyperEvent框架通过将动态链接预测重构为超事件识别，并引入事件相关向量来捕捉结构内聚性，结合高效的并行训练算法，显著提高了大规模动态图上动态链接预测的准确性和效率，有效解决了现有方法在处理复杂事件关联方面的局限性。", "translation": "动态图中连续时间动态链接预测是建模演化复杂系统的一项基本任务。现有的以节点为中心和以事件为中心的方法侧重于个体交互或原子状态，未能捕捉复合超事件（即因果相关事件组）的结构内聚性。为了解决这个问题，我们提出了HyperEvent，一个将动态链接预测重构为超事件识别的框架。HyperEvent的核心是利用事件相关向量动态构建关联序列。这些向量量化了查询事件与相关历史事件之间的成对依赖关系，从而表征了潜在超事件的结构内聚性。该框架通过评估查询事件是否与这些历史事件共同形成一个有效的超事件来预测其发生。值得注意的是，HyperEvent在官方排行榜的5个数据集中有4个超越了最先进的方法。为了可扩展性，我们进一步引入了一种高效的并行训练算法，该算法将大型事件流分段以实现并发训练。实验验证了HyperEvent在大规模图上的卓越准确性和效率。其中，HyperEvent在大型Flight数据集上比最先进的基线在平均倒数排名上提高了6.95%，同时仅使用了10.17%的训练时间。", "summary": "本文提出了HyperEvent框架，旨在通过识别具有结构内聚性的复合“超事件”来改进大规模动态图中的动态链接预测。该方法通过构建事件相关向量的关联序列来捕捉事件间的依赖关系和内聚性，并引入并行训练算法以提高效率。实验证明，HyperEvent在多个数据集上优于现有SOTA方法，特别是在大规模图上展现出显著的准确性提升和训练时间缩减。", "keywords": "动态链接预测, 超事件, 结构内聚性, 事件相关向量, 大规模图", "comments": "HyperEvent的创新之处在于将动态链接预测重新定义为“超事件识别”，关注事件的结构内聚性而非孤立的交互，这弥补了现有方法在处理复杂事件关联方面的不足。其引入事件相关向量和并行训练算法，不仅提升了预测准确性，还显著改善了在大规模图上的可扩展性和效率，具有重要的实际应用价值。"}}
{"id": "2507.12146", "title": "A Practical Analysis: Understanding Phase Noise Modelling in Time and Frequency Domain for Phase-Locked Loops", "authors": ["Carl Collmann", "Bitan Banerjee", "Ahmad Nimr", "Gerhard Fettweis"], "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      14 Pages", "url": "http://arxiv.org/abs/2507.12146v1", "summary": "In MIMO systems, the presence of phase noise is a significant factor that can\ndegrade performance. For MIMO testbeds build from SDR devices, phase noise\ncannot be ignored, particular in applications that require phase\nsynchronization. This is especially relevant in MIMO systems that employ\ndigital beamforming, where precise phase alignment is crucial. Accordingly,\naccurate phase noise modelling of SDR devices is essential. However, the\ninformation provided in data sheets for different SDR models varies widely and\nis often insufficient for comprehensive characterization of their phase noise\nperformance. While numerical simulations of PLL phase noise behavior are\ndocumented in the literature, there is a lack of extensive measurements\nsupported by appropriate system modelling. In this work, we present a practical\nphase noise modeling methodology applied to an SDR from the USRP X310 series.\nBased on measurement data, we derive estimates of key PLL performance\nindicators such as cycle-to-cycle jitter, oscillator constants, and PLL\nbandwidth. Furthermore, we propose a parametric model for the phase noise PSD\nof the PLL circuit and provide corresponding parameter estimates. This model\ncan be used for further investigation into the impact of phase noise on MIMO\nsystem performance implemented by similar SDR devices.", "comment": "14 Pages", "pdf_url": "http://arxiv.org/pdf/2507.12146v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "实用分析：理解锁相环中时域和频域的相位噪声建模", "tldr": "相位噪声会降低MIMO/SDR系统性能，现有数据不足。本文提出了一种基于测量的SDR（USRP X310）实用相位噪声建模方法，推导了PLL指标，并提出了一个参数化PSD模型，以供未来分析。", "motivation": "在MIMO系统中，相位噪声是导致性能下降的重要因素，尤其是在基于SDR设备的MIMO测试平台中，需要精确的相位同步。现有SDR数据手册提供的相位噪声信息不足，且文献中缺乏由广泛测量支持的系统建模。", "method": "本文提出了一种实用的相位噪声建模方法，并将其应用于USRP X310系列SDR。该方法基于测量数据，推导了关键PLL性能指标，如逐周期抖动、振荡器常数和PLL带宽。此外，还提出了PLL电路相位噪声PSD的参数模型，并提供了相应的参数估计。", "result": "成功推导了USRP X310 SDR的关键PLL性能指标（逐周期抖动、振荡器常数、PLL带宽），并提出了一个用于PLL电路相位噪声PSD的参数模型，提供了相应的参数估计。", "conclusion": "所提出的模型可用于进一步研究相位噪声对使用类似SDR设备实现的MIMO系统性能的影响。", "translation": "在MIMO系统中，相位噪声的存在是可能降低性能的重要因素。对于由SDR设备构建的MIMO测试平台，相位噪声不容忽视，特别是在需要相位同步的应用中。这在采用数字波束成形的MIMO系统中尤为重要，其中精确的相位对齐至关重要。因此，对SDR设备进行精确的相位噪声建模至关重要。然而，不同SDR型号数据手册中提供的信息差异很大，并且通常不足以全面表征其相位噪声性能。尽管文献中记录了PLL相位噪声行为的数值模拟，但缺乏由适当系统建模支持的广泛测量。在这项工作中，我们提出了一种应用于USRP X310系列SDR的实用相位噪声建模方法。基于测量数据，我们推导出关键PLL性能指标的估计值，例如逐周期抖动、振荡器常数和PLL带宽。此外，我们提出了PLL电路相位噪声PSD的参数模型，并提供了相应的参数估计。该模型可用于进一步研究相位噪声对由类似SDR设备实现的MIMO系统性能的影响。", "summary": "本文针对MIMO系统中SDR设备相位噪声建模不足的问题，提出了一种实用的相位噪声建模方法。通过对USRP X310 SDR的测量数据进行分析，该研究推导了关键锁相环性能指标，并提出了一个相位噪声功率谱密度参数模型，旨在为评估相位噪声对MIMO系统性能的影响提供工具。", "keywords": "相位噪声, MIMO系统, SDR, 锁相环, 建模", "comments": "这篇论文解决了MIMO系统中使用SDR设备时相位噪声建模的关键实际问题。其创新点在于结合了实际测量数据来推导PLL性能指标并提出参数模型，弥补了现有文献中缺乏广泛测量支持的系统建模的不足。这对于需要高精度相位同步的数字波束成形MIMO系统具有重要意义。"}}
{"id": "2410.15460", "title": "Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training", "authors": ["Shahrad Mohammadzadeh", "Juan David Guerra", "Marco Bonizzato", "Reihaneh Rabbany", "Golnoosh Farnadi"], "categories": ["cs.AI", "cs.CL", "math.SP"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025, accepted to Safe Generative AI Workshop @ NeurIPS 2024. Camera-ready version for ACL 2025 (to appear). Submitted July 2025", "url": "http://arxiv.org/abs/2410.15460v4", "summary": "As large language models (LLMs) become increasingly prevalent, concerns about\ntheir reliability, particularly due to hallucinations - factually inaccurate or\nirrelevant outputs - have grown. Our research investigates the relationship\nbetween the uncertainty in training dynamics and the emergence of\nhallucinations. Using models from the Pythia suite and several hallucination\ndetection metrics, we analyze hallucination trends and identify significant\nvariance during training. To address this, we propose \\textbf{Sensitivity\nDropout (SenD)}, a novel training protocol designed to reduce hallucination\nvariance during training by deterministically dropping embedding indices with\nsignificant variability. In addition, we develop an unsupervised hallucination\ndetection metric, Efficient EigenScore (EES), which approximates the\ntraditional EigenScore in 2x speed. This metric is integrated into our training\nprotocol, allowing SenD to be both computationally scalable and effective at\nreducing hallucination variance. SenD improves test-time reliability of Pythia\nand Meta's Llama models by up to 17\\% and enhances factual accuracy in\nWikipedia, Medical, Legal, and Coding domains without affecting downstream task\nperformance.", "comment": "Accepted to ACL 2025, accepted to Safe Generative AI Workshop @\n  NeurIPS 2024. Camera-ready version for ACL 2025 (to appear). Submitted July\n  2025", "pdf_url": "http://arxiv.org/pdf/2410.15460v4", "cate": "cs.AI", "date": "2024-10-20", "updated": "2025-07-16", "AI": {"title_translation": "幻觉排毒：大型语言模型训练中的敏感性丢弃 (SenD)", "tldr": "本文提出了一种名为敏感性丢弃 (SenD) 的新型训练协议，通过在训练期间确定性地丢弃具有显著可变性的嵌入索引来减少大型语言模型 (LLM) 的幻觉方差，同时开发了一种名为高效特征分数 (EES) 的无监督幻觉检测指标，以提高可扩展性。SenD 显著提高了LLM的可靠性和事实准确性。", "motivation": "随着大型语言模型 (LLM) 的日益普及，其可靠性问题，特别是由于幻觉（事实不准确或不相关输出）引起的担忧日益增长。本研究旨在调查训练动态中的不确定性与幻觉出现之间的关系，并解决训练过程中幻觉方差大的问题。", "method": "本研究提出了一种名为敏感性丢弃 (SenD) 的新型训练协议，旨在通过确定性地丢弃具有显著可变性的嵌入索引来减少训练期间的幻觉方差。此外，研究还开发了一种无监督幻觉检测指标——高效特征分数 (EES)，其速度是传统特征分数的两倍，并将其集成到SenD训练协议中，以确保计算的可扩展性和有效性。", "result": "SenD 将 Pythia 和 Meta 的 Llama 模型的测试时可靠性提高了高达 17%，并在不影响下游任务性能的情况下，提高了维基百科、医学、法律和编码领域的事实准确性。", "conclusion": "本文提出的敏感性丢弃 (SenD) 训练协议，结合高效特征分数 (EES) 检测指标，能够有效减少大型语言模型训练中的幻觉方差，显著提高模型的可靠性和事实准确性，且不影响下游任务表现。", "translation": "随着大型语言模型（LLM）的日益普及，人们对其可靠性的担忧也随之增加，特别是由于幻觉——即事实不准确或不相关的输出——所引起的问题。我们的研究调查了训练动态中的不确定性与幻觉出现之间的关系。我们使用 Pythia 模型套件和几种幻觉检测指标，分析了幻觉趋势并识别出训练期间的显著方差。为了解决这个问题，我们提出了**敏感性丢弃（SenD）**，这是一种新颖的训练协议，旨在通过确定性地丢弃具有显著可变性的嵌入索引来减少训练期间的幻觉方差。此外，我们开发了一种无监督幻觉检测指标——高效特征分数（EES），其近似于传统特征分数，速度提高了一倍。该指标被整合到我们的训练协议中，使得 SenD 在计算上既可扩展又有效地减少幻觉方差。SenD 将 Pythia 和 Meta 的 Llama 模型的测试时可靠性提高了高达 17%，并在不影响下游任务性能的情况下，提高了维基百科、医学、法律和编码领域的事实准确性。", "summary": "本文提出了一种名为敏感性丢弃 (SenD) 的新型训练协议，旨在解决大型语言模型 (LLM) 训练过程中出现的幻觉问题。研究发现训练动态中的不确定性与幻觉密切相关，并观察到训练期间幻觉存在显著方差。SenD 通过确定性地丢弃高变异性嵌入索引来减少这种方差。为提高效率，论文还开发了加速两倍的无监督幻觉检测指标高效特征分数 (EES)，并将其集成到 SenD 中。实验结果表明，SenD 将 Pythia 和 Llama 模型的可靠性提高了高达 17%，并在多个领域显著提升了事实准确性，同时不影响下游任务性能。", "keywords": "幻觉, 大型语言模型, 敏感性丢弃, 训练协议, 事实准确性", "comments": "该论文通过引入敏感性丢弃 (SenD) 训练协议和高效特征分数 (EES) 检测指标，为解决大型语言模型中的幻觉问题提供了一个新颖且有效的方案。其创新之处在于将训练动态中的不确定性与幻觉联系起来，并通过确定性丢弃高变异性嵌入索引来直接干预。EES 的开发进一步提升了方法的实用性和可扩展性。这项工作对于提高LLM的可靠性和事实准确性具有重要意义，尤其是在需要高准确性的领域。"}}
{"id": "2507.12039", "title": "A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans", "authors": ["Anca Dinu", "Andra-Maria Florescu", "Alina Resceanu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at KES 2025. To appear in Procedia Computer Science (Elsevier)", "url": "http://arxiv.org/abs/2507.12039v1", "summary": "The following paper introduces a general linguistic creativity test for\nhumans and Large Language Models (LLMs). The test consists of various tasks\naimed at assessing their ability to generate new original words and phrases\nbased on word formation processes (derivation and compounding) and on\nmetaphorical language use. We administered the test to 24 humans and to an\nequal number of LLMs, and we automatically evaluated their answers using OCSAI\ntool for three criteria: Originality, Elaboration, and Flexibility. The results\nshow that LLMs not only outperformed humans in all the assessed criteria, but\ndid better in six out of the eight test tasks. We then computed the uniqueness\nof the individual answers, which showed some minor differences between humans\nand LLMs. Finally, we performed a short manual analysis of the dataset, which\nrevealed that humans are more inclined towards E(extending)-creativity, while\nLLMs favor F(ixed)-creativity.", "comment": "Accepted for presentation at KES 2025. To appear in Procedia Computer\n  Science (Elsevier)", "pdf_url": "http://arxiv.org/pdf/2507.12039v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "评估大型语言模型和人类语言创造力的比较方法", "tldr": "本研究引入了一项通用语言创造力测试，结果显示大型语言模型在多项评估标准和任务中表现优于人类，但在创造力类型上存在差异。", "motivation": "本研究旨在引入一种通用的语言创造力测试，以评估人类和大型语言模型（LLMs）生成新颖原创词汇和短语的能力。", "method": "研究设计了一项包含多种任务的语言创造力测试，旨在评估基于词语形成过程（派生和复合）和隐喻语言使用能力的创造力。该测试对24名人类和等量的LLMs进行了施测。答案使用OCSAI工具根据原创性、精细性和灵活性三个标准进行自动评估。研究还计算了个体答案的独特性，并进行了简短的手工分析。", "result": "结果显示，LLMs不仅在所有评估标准上均优于人类，而且在八项测试任务中的六项表现更好。个体答案的独特性显示人类和LLMs之间存在一些微小差异。手动分析揭示人类更倾向于E（扩展）型创造力，而LLMs偏向F（固定）型创造力。", "conclusion": "本研究的结论是，大型语言模型在语言创造力测试中的表现普遍优于人类，尽管在创造力的具体类型上存在偏好差异。", "translation": "本文介绍了一种针对人类和大型语言模型（LLM）的通用语言创造力测试。该测试包含各种任务，旨在评估它们基于词语形成过程（派生和复合）和隐喻语言使用生成新颖原创词汇和短语的能力。我们对24名人类和等量的大型语言模型进行了测试，并使用OCSAI工具根据原创性、精细性和灵活性三个标准自动评估了它们的答案。结果显示，大型语言模型不仅在所有评估标准上均优于人类，而且在八项测试任务中的六项中表现更好。随后，我们计算了单个答案的独特性，这显示了人类和大型语言模型之间的一些微小差异。最后，我们对数据集进行了简短的手动分析，揭示了人类更倾向于E（扩展）型创造力，而大型语言模型则倾向于F（固定）型创造力。", "summary": "本研究提出了一种通用的语言创造力测试，用于比较人类和大型语言模型（LLMs）的语言创造力。该测试包含词语形成和隐喻使用任务，并对24名人类和LLMs进行施测。结果显示，LLMs在原创性、精细性和灵活性等多个评估标准以及多数测试任务中均表现优于人类。尽管在答案独特性上存在细微差异，但手动分析发现人类倾向于E-创造力，而LLMs倾向于F-创造力。", "keywords": "语言创造力, 大型语言模型, 人类, 比较研究, OCSAI", "comments": "该论文通过设计一套新颖的语言创造力测试，为量化评估大型语言模型与人类的创造力提供了有价值的比较视角。其创新之处在于结合了自动评估工具OCSAI，并引入了对不同创造力类型的区分（E-creativity vs. F-creativity），这对于理解LLMs的认知机制及其与人类认知的异同具有重要意义。研究结果挑战了传统观点，即人类在创造力方面具有绝对优势，并为未来深入研究LLMs的创造性潜力奠定了基础。然而，测试的范围和OCSAI工具的局限性可能仍需进一步探讨。"}}
{"id": "2507.11554", "title": "Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models", "authors": ["Zejian Li", "Yize Li", "Chenye Meng", "Zhongni Liu", "Yang Ling", "Shengyuan Zhang", "Guang Yang", "Changyuan Yang", "Zhiyuan Yang", "Lingyun Sun"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11554v1", "summary": "Recent advancements in diffusion models (DMs) have been propelled by\nalignment methods that post-train models to better conform to human\npreferences. However, these approaches typically require computation-intensive\ntraining of a base model and a reward model, which not only incurs substantial\ncomputational overhead but may also compromise model accuracy and training\nefficiency. To address these limitations, we propose Inversion-DPO, a novel\nalignment framework that circumvents reward modeling by reformulating Direct\nPreference Optimization (DPO) with DDIM inversion for DMs. Our method conducts\nintractable posterior sampling in Diffusion-DPO with the deterministic\ninversion from winning and losing samples to noise and thus derive a new\npost-training paradigm. This paradigm eliminates the need for auxiliary reward\nmodels or inaccurate appromixation, significantly enhancing both precision and\nefficiency of training. We apply Inversion-DPO to a basic task of text-to-image\ngeneration and a challenging task of compositional image generation. Extensive\nexperiments show substantial performance improvements achieved by Inversion-DPO\ncompared to existing post-training methods and highlight the ability of the\ntrained generative models to generate high-fidelity compositionally coherent\nimages. For the post-training of compostitional image geneation, we curate a\npaired dataset consisting of 11,140 images with complex structural annotations\nand comprehensive scores, designed to enhance the compositional capabilities of\ngenerative models. Inversion-DPO explores a new avenue for efficient,\nhigh-precision alignment in diffusion models, advancing their applicability to\ncomplex realistic generation tasks. Our code is available at\nhttps://github.com/MIGHTYEZ/Inversion-DPO", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11554v1", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "Inversion-DPO：扩散模型的精确高效后训练", "tldr": "Inversion-DPO提出了一种新的扩散模型对齐框架，通过结合DDIM反演和DPO，避免了奖励模型，显著提高了后训练的精度和效率。", "motivation": "现有的扩散模型对齐方法通常需要计算密集型的基础模型和奖励模型训练，导致计算开销大，并可能损害模型精度和训练效率。", "method": "我们提出了Inversion-DPO，一个通过将直接偏好优化（DPO）与DDIM反演结合来规避奖励建模的新型对齐框架。该方法通过将胜利和失败样本确定性反演到噪声，进行扩散-DPO中难以处理的后验采样，从而推导出一种新的后训练范式，消除了对辅助奖励模型或不精确近似的需求。", "result": "Inversion-DPO在文本到图像生成和组合图像生成任务中都取得了显著的性能提升，与现有后训练方法相比表现出优越性。训练后的生成模型能够生成高保真、组合连贯的图像。此外，为组合图像生成后训练，我们策划了一个包含11,140张具有复杂结构注释和综合分数的配对数据集。", "conclusion": "Inversion-DPO为扩散模型中高效、高精度的对齐探索了一条新途径，提升了其在复杂现实生成任务中的适用性。", "translation": "扩散模型（DMs）的最新进展得益于通过后训练模型以更好地符合人类偏好的对齐方法。然而，这些方法通常需要计算密集型的基础模型和奖励模型训练，这不仅带来了巨大的计算开销，还可能损害模型精度和训练效率。为了解决这些限制，我们提出了Inversion-DPO，一种新颖的对齐框架，它通过将直接偏好优化（DPO）与扩散模型的DDIM反演相结合来规避奖励建模。我们的方法通过将胜利和失败样本的确定性反演到噪声来执行扩散-DPO中难以处理的后验采样，从而推导出一种新的后训练范式。这种范式消除了对辅助奖励模型或不精确近似的需求，显著提高了训练的精度和效率。我们将Inversion-DPO应用于文本到图像生成的基本任务和组合图像生成的挑战性任务。广泛的实验表明，与现有后训练方法相比，Inversion-DPO取得了显著的性能提升，并突出了训练后的生成模型生成高保真、组合连贯图像的能力。为了进行组合图像生成的后训练，我们策划了一个包含11,140张具有复杂结构注释和综合分数的配对数据集，旨在增强生成模型的组合能力。Inversion-DPO为扩散模型中高效、高精度的对齐探索了一条新途径，提升了其在复杂现实生成任务中的适用性。我们的代码可在https://github.com/MIGHTYEZ/Inversion-DPO获取。", "summary": "本文提出了Inversion-DPO，一种用于扩散模型后训练的新型对齐框架。该方法通过将DPO与DDIM反演结合，避免了传统方法中对计算密集型奖励模型的依赖，从而显著提高了训练的精度和效率。Inversion-DPO通过对胜利和失败样本进行确定性反演来执行后验采样，并已在文本到图像和组合图像生成任务中验证了其优越性，能够生成高保真、组合连贯的图像。为支持研究，作者还创建了一个新的组合图像生成数据集。", "keywords": "扩散模型, 后训练, 对齐, DPO, DDIM反演", "comments": "Inversion-DPO的创新点在于其巧妙地将DDIM反演融入到DPO框架中，从而完全绕过了传统对齐方法中对奖励模型的依赖，这在计算效率和精度上都带来了显著优势。它为扩散模型的后训练提供了一个更轻量级且高效的范式，对于推动扩散模型在复杂实际应用中的落地具有重要意义。特别是其在组合图像生成任务上的表现，以及为此专门构建的新数据集，都展现了其在解决特定挑战性问题上的潜力。"}}
{"id": "2507.10024", "title": "Qualitative Study for LLM-assisted Design Study Process: Strategies, Challenges, and Roles", "authors": ["Shaolun Ruan", "Rui Sheng", "Xiaolin Wen", "Jiachen Wang", "Tianyi Zhang", "Yong Wang", "Tim Dwyer", "Jiannan Li"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10024v2", "summary": "Design studies aim to create visualization solutions for real-world problems\nof different application domains. Recently, the emergence of large language\nmodels (LLMs) has introduced new opportunities to enhance the design study\nprocess, providing capabilities such as creative problem-solving, data\nhandling, and insightful analysis. However, despite their growing popularity,\nthere remains a lack of systematic understanding of how LLMs can effectively\nassist researchers in visualization-specific design studies. In this paper, we\nconducted a multi-stage qualitative study to fill this gap, involving 30 design\nstudy researchers from diverse backgrounds and expertise levels. Through\nin-depth interviews and carefully-designed questionnaires, we investigated\nstrategies for utilizing LLMs, the challenges encountered, and the practices\nused to overcome them. We further compiled and summarized the roles that LLMs\ncan play across different stages of the design study process. Our findings\nhighlight practical implications to inform visualization practitioners, and\nprovide a framework for leveraging LLMs to enhance the design study process in\nvisualization research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10024v2", "cate": "cs.HC", "date": "2025-07-14", "updated": "2025-07-16", "AI": {"title_translation": "LLM辅助设计研究过程的定性研究：策略、挑战与角色", "tldr": "本文通过一项针对30位研究人员的定性研究，探讨了大型语言模型（LLMs）如何辅助可视化设计研究，识别了其使用策略、面临的挑战以及LLMs所能扮演的角色。", "motivation": "尽管大型语言模型（LLMs）为设计研究带来了新的机遇，但在可视化领域，目前仍缺乏对LLMs如何有效辅助研究人员进行设计研究的系统性理解。", "method": "本研究采用多阶段定性研究方法，对象为30位来自不同背景和专业水平的设计研究人员。研究通过深度访谈和精心设计的问卷进行。", "result": "研究调查了利用LLMs的策略、遇到的挑战以及克服这些挑战的实践。此外，还汇编并总结了LLMs在设计研究过程不同阶段可以扮演的角色。研究结果为可视化实践者提供了实际指导，并为利用LLMs增强可视化设计研究提供了一个框架。", "conclusion": "本研究的发现为可视化实践者提供了实际指导，并为在可视化研究中利用LLMs增强设计研究过程提供了一个框架。", "translation": "设计研究旨在为不同应用领域的现实世界问题创建可视化解决方案。近期，大型语言模型（LLMs）的出现为增强设计研究过程带来了新的机遇，提供了诸如创造性问题解决、数据处理和深入分析等能力。然而，尽管它们日益普及，但对于LLMs如何有效辅助研究人员进行可视化特定设计研究，仍然缺乏系统性的理解。在本文中，我们进行了一项多阶段定性研究以填补这一空白，研究对象包括30位来自不同背景和专业水平的设计研究研究人员。通过深入访谈和精心设计的问卷，我们调查了利用LLMs的策略、遇到的挑战以及克服这些挑战的实践。我们进一步汇编并总结了LLMs在设计研究过程不同阶段可以扮演的角色。我们的研究结果突出了对可视化实践者的实际指导意义，并为利用LLMs增强可视化研究中的设计研究过程提供了一个框架。", "summary": "本研究旨在弥补大型语言模型（LLMs）如何辅助可视化特定设计研究的理解空白。通过一项针对30位设计研究人员的多阶段定性研究，包括深度访谈和问卷调查，本文探讨了利用LLMs的策略、遇到的挑战以及克服这些挑战的方法。研究还总结了LLMs在设计研究过程中可以扮演的角色。研究结果为可视化实践者提供了实用指导，并为在可视化研究中利用LLMs提供了一个增强设计研究过程的框架。", "keywords": "LLMs, 设计研究, 可视化, 定性研究, 策略", "comments": "该论文及时地探讨了大型语言模型在可视化设计研究中的应用，具有重要的现实意义。通过定性研究方法，它深入分析了LLMs辅助设计过程的策略、挑战和角色，为实践者提供了宝贵的洞察和框架，有助于推动LLM在人机交互和可视化领域的应用。"}}
{"id": "2507.12427", "title": "Unit-Based Histopathology Tissue Segmentation via Multi-Level Feature Representation", "authors": ["Ashkan Shakarami", "Azade Farshad", "Yousef Yeganeh", "Lorenzo Nicole", "Peter Schuffler", "Stefano Ghidoni", "Nassir Navab"], "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      12 pages, 6 figures", "url": "http://arxiv.org/abs/2507.12427v1", "summary": "We propose UTS, a unit-based tissue segmentation framework for histopathology\nthat classifies each fixed-size 32 * 32 tile, rather than each pixel, as the\nsegmentation unit. This approach reduces annotation effort and improves\ncomputational efficiency without compromising accuracy. To implement this\napproach, we introduce a Multi-Level Vision Transformer (L-ViT), which benefits\nthe multi-level feature representation to capture both fine-grained morphology\nand global tissue context. Trained to segment breast tissue into three\ncategories (infiltrating tumor, non-neoplastic stroma, and fat), UTS supports\nclinically relevant tasks such as tumor-stroma quantification and surgical\nmargin assessment. Evaluated on 386,371 tiles from 459 H&E-stained regions, it\noutperforms U-Net variants and transformer-based baselines. Code and Dataset\nwill be available at GitHub.", "comment": "12 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.12427v1", "cate": "eess.IV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于单元的多级特征表示的组织病理学组织分割", "tldr": "UTS是一种用于组织病理学图像的基于单元的组织分割框架，它使用多级Vision Transformer，在保持准确性的同时减少了标注工作并提高了计算效率，并且在乳腺组织分割任务上优于现有方法。", "motivation": "现有的组织病理学图像分割方法可能面临标注工作量大和计算效率低的问题，同时需要有效捕获细粒度形态和全局组织上下文以支持临床任务。", "method": "本文提出了一种名为UTS的基于单元的组织分割框架。该框架将每个固定大小的32x32像素图块作为分割单元，而不是每个像素。为实现此方法，引入了多级Vision Transformer (L-ViT) 来捕获多级特征表示，包括细粒度形态和全局组织上下文。该模型被训练用于将乳腺组织分割为浸润性肿瘤、非肿瘤性间质和脂肪三类。", "result": "UTS在从459个H&E染色区域提取的386,371个图块上进行了评估。实验结果显示，UTS在性能上优于U-Net变体和基于Transformer的基线方法。", "conclusion": "UTS通过采用基于单元的分割和多级特征表示，在组织病理学图像分割中实现了高效且准确的性能，并支持重要的临床任务。", "translation": "我们提出了UTS，一个用于组织病理学的基于单元的组织分割框架，它将每个固定大小的32 * 32瓦片（而不是每个像素）分类为分割单元。这种方法在不损害准确性的前提下，减少了标注工作量并提高了计算效率。为了实现这种方法，我们引入了一种多级视觉Transformer (L-ViT)，它受益于多级特征表示，以捕获细粒度形态和全局组织上下文。UTS被训练用于将乳腺组织分割为三类（浸润性肿瘤、非肿瘤性间质和脂肪），支持肿瘤-间质量化和手术切缘评估等临床相关任务。在来自459个H&E染色区域的386,371个瓦片上进行评估，它优于U-Net变体和基于Transformer的基线方法。代码和数据集将在GitHub上提供。", "summary": "本文提出了一种名为UTS的基于单元的组织病理学组织分割框架。该框架以32x32的图块为分割单元，并通过引入多级Vision Transformer (L-ViT) 来有效捕获细粒度形态和全局上下文特征。UTS在乳腺组织分割任务（分为浸润性肿瘤、非肿瘤性间质和脂肪）上进行了评估，结果显示其在减少标注工作量、提高计算效率的同时，性能优于U-Net变体和基于Transformer的基线方法，并支持临床相关应用。", "keywords": "组织病理学, 组织分割, Vision Transformer, 多级特征, 乳腺癌", "comments": "该论文的创新之处在于提出了基于图块的分割单元和多级Vision Transformer (L-ViT)相结合的方法，有效解决了传统像素级分割在计算效率和标注成本上的挑战。其在临床相关任务上的应用潜力以及优于现有方法的性能，表明了其重要性。"}}
{"id": "2507.11842", "title": "CosmoFlow: Scale-Aware Representation Learning for Cosmology with Flow Matching", "authors": ["Sidharth Kannan", "Tian Qiu", "Carolina Cuesta-Lazaro", "Haewon Jeong"], "categories": ["astro-ph.CO", "cs.LG"], "primary_category": "Subjects:       Cosmology and Nongalactic Astrophysics (astro-ph.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11842v1", "summary": "Generative machine learning models have been demonstrated to be able to learn\nlow dimensional representations of data that preserve information required for\ndownstream tasks. In this work, we demonstrate that flow matching based\ngenerative models can learn compact, semantically rich latent representations\nof field level cold dark matter (CDM) simulation data without supervision. Our\nmodel, CosmoFlow, learns representations 32x smaller than the raw field data,\nusable for field level reconstruction, synthetic data generation, and parameter\ninference. Our model also learns interpretable representations, in which\ndifferent latent channels correspond to features at different cosmological\nscales.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11842v1", "cate": "astro-ph.CO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "CosmoFlow：基于流匹配的宇宙学尺度感知表示学习", "tldr": "CosmoFlow是一种基于流匹配的生成模型，能够为宇宙学冷暗物质模拟数据学习紧凑、语义丰富且尺度可解释的潜在表示，其大小是原始数据的1/32，可用于数据重建、生成和参数推断。", "motivation": "现有的生成机器学习模型能够学习保留下游任务所需信息的低维数据表示。本文旨在探索基于流匹配的生成模型是否也能为宇宙学冷暗物质模拟数据学习紧凑、语义丰富的潜在表示。", "method": "本文提出CosmoFlow模型，该模型是一种基于流匹配的生成模型，用于无监督地学习场级别冷暗物质（CDM）模拟数据的潜在表示。", "result": "CosmoFlow模型学习到的表示比原始场数据小32倍，可用于场级别重建、合成数据生成和参数推断。此外，该模型还学习到可解释的表示，其中不同的潜在通道对应于不同宇宙学尺度的特征。", "conclusion": "基于流匹配的生成模型（CosmoFlow）能够成功地为宇宙学冷暗物质模拟数据学习到紧凑、语义丰富且尺度可解释的潜在表示，这些表示在多种下游任务中具有实用价值。", "translation": "生成式机器学习模型已被证明能够学习数据的低维表示，这些表示保留了下游任务所需的信息。在这项工作中，我们证明了基于流匹配的生成模型可以无监督地学习场级别冷暗物质（CDM）模拟数据的紧凑、语义丰富的潜在表示。我们的模型CosmoFlow学习到的表示比原始场数据小32倍，可用于场级别重建、合成数据生成和参数推断。我们的模型还学习到可解释的表示，其中不同的潜在通道对应于不同宇宙学尺度的特征。", "summary": "CosmoFlow是一种基于流匹配的生成模型，专为宇宙学冷暗物质模拟数据设计。它能够在无监督的情况下学习到比原始数据小32倍的紧凑、语义丰富的潜在表示。这些表示不仅可用于数据重建、合成数据生成和参数推断，还具有可解释性，其潜在通道对应着不同的宇宙学尺度特征。", "keywords": "流匹配, 宇宙学, 表示学习, 冷暗物质, 生成模型", "comments": "该研究的创新点在于将流匹配生成模型应用于宇宙学数据，并成功实现了尺度感知和可解释的潜在表示学习。其将数据压缩32倍的能力显著提升了数据处理效率，并为宇宙学研究提供了新的工具，尤其是在数据重建、生成和参数推断方面。可解释性是其重要优势，有助于科学家理解模型学到的特征与物理尺度的对应关系。"}}
{"id": "2507.11646", "title": "State-based approach to the numerical solution of Dirichlet boundary optimal control problems for the Laplace equation", "authors": ["Ulrich Langer", "Richard Löscher", "Olaf Steinbach", "Huidong Yang"], "categories": ["math.NA", "cs.NA", "math.OC", "49J20, 49K20, 65K10, 65N30, 65N22"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11646v1", "summary": "We investigate the Dirichlet boundary control of the Laplace equation,\nconsidering the control in $H^{1/2}(\\partial \\Omega)$, which is the natural\nspace for Dirichlet data when the state belongs to $H^1(\\Omega)$. The cost of\nthe control is measured in the $H^{1/2}(\\partial \\Omega)$ norm that also plays\nthe role of the regularization term. We discuss regularization and finite\nelement error estimates enabling us to derive an optimal relation between the\nfinite element mesh size $h$ and the regularization parameter $\\varrho$,\nbalancing the energy cost for the control and the accuracy of the approximation\nof the desired state. This relationship is also crucial in designing efficient\nsolvers. We also discuss additional box constraints imposed on the control and\nthe state. Our theoretical findings are complemented by numerical examples,\nincluding one example with box constraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11646v1", "cate": "math.NA", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "基于状态的方法求解拉普拉斯方程的狄利克雷边界最优控制问题", "tldr": "本文研究了拉普拉斯方程的狄利克雷边界控制问题，重点在于推导有限元网格尺寸与正则化参数之间的最优关系，以实现高效的数值求解，并考虑了盒约束。", "motivation": "调查拉普拉斯方程的狄利克雷边界控制，并推导有限元网格尺寸与正则化参数之间的最优关系，以实现高效且准确的数值解。", "method": "本文采用基于状态的方法，将控制置于$H^{1/2}(\\partial \\Omega)$空间中，并在此范数下衡量控制成本作为正则化项。研究讨论了正则化和有限元误差估计，推导了网格尺寸与正则化参数之间的最优关系。此外，还讨论了对控制和状态施加的盒约束。理论结果通过数值例子得到验证。", "result": "研究推导了有限元网格尺寸$h$与正则化参数$\\varrho$之间的最优关系，该关系能够平衡控制的能量成本和所需状态近似的准确性。这种关系对于设计高效求解器至关重要。理论发现得到了数值例子的补充，其中包括一个带有盒约束的例子。", "conclusion": "本文成功研究了拉普拉斯方程的狄利克雷边界控制问题，并建立了有限元网格尺寸与正则化参数之间的最优关系，这对高效数值求解器至关重要。", "translation": "我们研究了拉普拉斯方程的狄利克雷边界控制，考虑在$H^{1/2}(\\partial \\Omega)$空间中的控制，当状态属于$H^1(\\Omega)$时，这是狄利克雷数据的自然空间。控制的成本以$H^{1/2}(\\partial \\Omega)$范数衡量，该范数也起到正则化项的作用。我们讨论了正则化和有限元误差估计，使我们能够推导出有限元网格尺寸$h$与正则化参数$\\varrho$之间的最优关系，以平衡控制的能量成本和所需状态近似的准确性。这种关系对于设计高效求解器也至关重要。我们还讨论了对控制和状态施加的额外盒约束。我们的理论发现通过数值例子得到了补充，其中包括一个带有盒约束的例子。", "summary": "本文研究了拉普拉斯方程的狄利克雷边界最优控制问题，重点关注在$H^{1/2}(\\partial \\Omega)$空间中的控制。论文详细阐述了如何使用$H^{1/2}(\\partial \\Omega)$范数来衡量控制成本并作为正则化项。一个关键贡献是推导了有限元网格尺寸与正则化参数之间的最优关系，这对于平衡控制能量成本和近似精度，以及设计高效求解器至关重要。研究还讨论并纳入了对控制和状态的额外盒约束，并通过数值例子验证了理论发现。", "keywords": "狄利克雷边界控制, 拉普拉斯方程, 最优控制, 有限元, 正则化", "comments": "该论文解决了偏微分方程最优控制中的一个基本问题。其对网格尺寸和正则化参数之间最优关系的关注尤其具有创新性，因为它直接影响了数值求解器的计算效率和准确性。对盒约束的考虑增加了实际相关性。"}}
{"id": "2507.12108", "title": "Multimodal Coordinated Online Behavior: Trade-offs and Strategies", "authors": ["Lorenzo Mannocci", "Stefano Cresci", "Matteo Magnani", "Anna Monreale", "Maurizio Tesconi"], "categories": ["cs.SI", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12108v1", "summary": "Coordinated online behavior, which spans from beneficial collective actions\nto harmful manipulation such as disinformation campaigns, has become a key\nfocus in digital ecosystem analysis. Traditional methods often rely on\nmonomodal approaches, focusing on single types of interactions like co-retweets\nor co-hashtags, or consider multiple modalities independently of each other.\nHowever, these approaches may overlook the complex dynamics inherent in\nmultimodal coordination. This study compares different ways of operationalizing\nthe detection of multimodal coordinated behavior. It examines the trade-off\nbetween weakly and strongly integrated multimodal models, highlighting the\nbalance between capturing broader coordination patterns and identifying tightly\ncoordinated behavior. By comparing monomodal and multimodal approaches, we\nassess the unique contributions of different data modalities and explore how\nvarying implementations of multimodality impact detection outcomes. Our\nfindings reveal that not all the modalities provide distinct insights, but that\nwith a multimodal approach we can get a more comprehensive understanding of\ncoordination dynamics. This work enhances the ability to detect and analyze\ncoordinated online behavior, offering new perspectives for safeguarding the\nintegrity of digital platforms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12108v1", "cate": "cs.SI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "多模态协同在线行为：权衡与策略", "tldr": "本研究比较了检测多模态协同在线行为的不同方法，探讨了弱整合与强整合多模态模型之间的权衡，并发现多模态方法能更全面地理解协同动态，有助于保护数字平台完整性。", "motivation": "传统的单模态方法或独立考虑多模态的方法在检测在线协同行为时可能忽略其固有的复杂动态，无法全面理解从有益集体行动到有害虚假信息宣传等多种形式的协同行为。", "method": "本研究通过比较不同的操作化方法来检测多模态协同行为，并考察了弱整合与强整合多模态模型之间的权衡。此外，还比较了单模态和多模态方法，评估了不同数据模态的独特贡献，并探讨了多模态的不同实现方式如何影响检测结果。", "result": "研究发现并非所有模态都能提供独特的见解，但通过多模态方法可以更全面地理解协同动态。", "conclusion": "这项工作增强了检测和分析协同在线行为的能力，为维护数字平台完整性提供了新视角。", "translation": "协同在线行为，从有益的集体行动到有害的操纵（如虚假信息宣传），已成为数字生态系统分析的关键焦点。传统方法通常依赖于单模态方法，侧重于单一类型的交互，例如共同转发或共同话题标签，或独立考虑多种模态。然而，这些方法可能会忽略多模态协同中固有的复杂动态。本研究比较了操作化检测多模态协同行为的不同方式。它考察了弱整合和强整合多模态模型之间的权衡，强调了捕捉更广泛协同模式与识别紧密协同行为之间的平衡。通过比较单模态和多模态方法，我们评估了不同数据模态的独特贡献，并探讨了多模态的不同实现方式如何影响检测结果。我们的发现表明，并非所有模态都提供独特的见解，但通过多模态方法，我们可以更全面地理解协同动态。这项工作增强了检测和分析协同在线行为的能力，为维护数字平台完整性提供了新视角。", "summary": "本研究旨在解决传统方法在检测复杂多模态协同在线行为时的局限性。通过比较单模态和多模态方法，并深入分析弱整合与强整合多模态模型之间的权衡，研究发现多模态方法能够提供更全面的协同动态理解，尽管并非所有模态都提供独特见解。这项工作为提升在线协同行为的检测与分析能力，进而维护数字平台完整性提供了新视角。", "keywords": "多模态协同, 在线行为, 虚假信息, 数字平台, 权衡", "comments": "该论文的创新之处在于其首次系统性地比较了不同多模态模型在检测协同在线行为方面的权衡，并强调了多模态方法在提供更全面理解方面的优势。这对于数字平台的内容治理和安全维护具有重要意义，有助于识别和应对虚假信息等有害行为。"}}
{"id": "2507.11931", "title": "Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark", "authors": ["Jingqian Wu", "Peiqi Duan", "Zongqiang Wang", "Changwei Wang", "Boxin Shi", "Edmund Y. Lam"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11931v1", "summary": "In low-light environments, conventional cameras often struggle to capture\nclear multi-view images of objects due to dynamic range limitations and motion\nblur caused by long exposure. Event cameras, with their high-dynamic range and\nhigh-speed properties, have the potential to mitigate these issues.\nAdditionally, 3D Gaussian Splatting (GS) enables radiance field reconstruction,\nfacilitating bright frame synthesis from multiple viewpoints in low-light\nconditions. However, naively using an event-assisted 3D GS approach still faced\nchallenges because, in low light, events are noisy, frames lack quality, and\nthe color tone may be inconsistent. To address these issues, we propose\nDark-EvGS, the first event-assisted 3D GS framework that enables the\nreconstruction of bright frames from arbitrary viewpoints along the camera\ntrajectory. Triplet-level supervision is proposed to gain holistic knowledge,\ngranular details, and sharp scene rendering. The color tone matching block is\nproposed to guarantee the color consistency of the rendered frames.\nFurthermore, we introduce the first real-captured dataset for the event-guided\nbright frame synthesis task via 3D GS-based radiance field reconstruction.\nExperiments demonstrate that our method achieves better results than existing\nmethods, conquering radiance field reconstruction under challenging low-light\nconditions. The code and sample data are included in the supplementary\nmaterial.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11931v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "Dark-EvGS：事件相机作为黑暗中辐射场的“眼睛”", "tldr": "Dark-EvGS提出了一种事件相机辅助的3D高斯泼溅框架，用于在低光环境下重建清晰的辐射场并合成亮帧，解决了传统方法在黑暗中噪声大、图像质量差和颜色不一致的问题。", "motivation": "在低光环境下，传统相机受限于动态范围和长时间曝光引起的运动模糊，难以捕捉清晰的多视角图像。虽然事件相机和3D高斯泼溅（GS）有潜力缓解这些问题，但简单地结合它们仍面临挑战，因为在低光下事件噪声大，帧质量差，且颜色不一致。", "method": "我们提出了Dark-EvGS，这是首个事件相机辅助的3D GS框架。它引入了三重级别监督来获取整体知识、细粒度细节和清晰场景渲染，并设计了颜色色调匹配模块以确保渲染帧的颜色一致性。此外，我们还构建了首个用于事件引导亮帧合成的真实捕获数据集。", "result": "实验证明，我们的方法在具有挑战性的低光条件下，比现有方法取得了更好的辐射场重建结果。", "conclusion": "Dark-EvGS成功解决了低光环境下事件相机辅助3D高斯泼溅的挑战，首次实现了从事件数据在黑暗中高质量的辐射场重建和亮帧合成。", "translation": "在低光环境下，传统相机由于动态范围限制和长时间曝光引起的运动模糊，往往难以捕获清晰的物体多视角图像。事件相机凭借其高动态范围和高速特性，有潜力缓解这些问题。此外，3D高斯泼溅（GS）能够重建辐射场，从而在低光条件下从多个视点合成亮帧。然而，简单地使用事件辅助的3D GS方法仍然面临挑战，因为在低光下，事件噪声大，帧质量差，并且颜色色调可能不一致。为了解决这些问题，我们提出了Dark-EvGS，这是第一个事件辅助的3D GS框架，它能够沿着相机轨迹从任意视点重建亮帧。我们提出了三重级别监督来获取整体知识、细粒度细节和清晰的场景渲染。同时，提出了颜色色调匹配模块来保证渲染帧的颜色一致性。此外，我们引入了第一个通过基于3D GS的辐射场重建来完成事件引导亮帧合成任务的真实捕获数据集。实验表明，我们的方法比现有方法取得了更好的结果，克服了在挑战性低光条件下的辐射场重建难题。代码和示例数据包含在补充材料中。", "summary": "Dark-EvGS是一个创新的事件相机辅助3D高斯泼溅框架，旨在解决低光环境下辐射场重建和亮帧合成的挑战。它通过引入三重级别监督和颜色色调匹配模块，有效处理了低光下事件噪声、帧质量差和颜色不一致的问题。该研究还发布了首个用于此任务的真实数据集，实验证明其在低光条件下的性能优于现有方法。", "keywords": "事件相机, 3D高斯泼溅, 低光成像, 辐射场重建, 亮帧合成", "comments": "Dark-EvGS的创新之处在于将事件相机的高动态范围特性与3D高斯泼溅相结合，并针对低光环境下的特定挑战（如噪声、颜色不一致）提出了有效的解决方案。三重级别监督和颜色色调匹配模块是其核心贡献。此外，构建真实捕获数据集也为该领域的研究提供了宝贵的资源，具有重要的实践意义。"}}
{"id": "2507.12117", "title": "Quantum Machine Learning in Multi-Qubit Phase-Space Part I: Foundations", "authors": ["Timothy Heightman", "Edward Jiang", "Ruth Mora-Soto", "Maciej Lewenstein", "Marcin Płodzień"], "categories": ["quant-ph", "cs.AI", "math-ph", "math.MP"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12117v1", "summary": "Quantum machine learning (QML) seeks to exploit the intrinsic properties of\nquantum mechanical systems, including superposition, coherence, and quantum\nentanglement for classical data processing. However, due to the exponential\ngrowth of the Hilbert space, QML faces practical limits in classical\nsimulations with the state-vector representation of quantum system. On the\nother hand, phase-space methods offer an alternative by encoding quantum states\nas quasi-probability functions. Building on prior work in qubit phase-space and\nthe Stratonovich-Weyl (SW) correspondence, we construct a closed, composable\ndynamical formalism for one- and many-qubit systems in phase-space. This\nformalism replaces the operator algebra of the Pauli group with function\ndynamics on symplectic manifolds, and recasts the curse of dimensionality in\nterms of harmonic support on a domain that scales linearly with the number of\nqubits. It opens a new route for QML based on variational modelling over\nphase-space.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12117v1", "cate": "quant-ph", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "量子多比特相空间机器学习 第一部分：基础", "tldr": "本文构建了一种新的多比特量子系统相空间动力学形式，通过将维度诅咒转化为线性缩放的谐波支持，为量子机器学习提供了新的途径。", "motivation": "经典的量子机器学习模拟因希尔伯特空间的指数增长而面临实际限制，即所谓的“维度诅咒”。", "method": "作者基于量子比特相空间和Stratonovich-Weyl (SW) 对应关系，构建了一个用于单比特和多比特系统的封闭、可组合的相空间动力学形式。该形式用辛流形上的函数动力学取代了泡利群的算子代数。", "result": "该形式将维度诅咒转化为域上与量子比特数量线性相关的谐波支持，有效解决了维度扩展问题。", "conclusion": "这种新的相空间形式为基于变分建模的量子机器学习开辟了一条新途径。", "translation": "量子机器学习（QML）旨在利用量子力学系统的内在特性，包括叠加、相干性和量子纠缠，进行经典数据处理。然而，由于希尔伯特空间的指数增长，QML在用量子系统的态矢量表示进行经典模拟时面临实际限制。另一方面，相空间方法通过将量子态编码为准概率函数提供了另一种选择。基于先前在量子比特相空间和Stratonovich-Weyl (SW) 对应关系方面的工作，我们构建了一个用于单比特和多比特系统在相空间中封闭、可组合的动力学形式。该形式用辛流形上的函数动力学取代了泡利群的算子代数，并将维度诅咒转化为域上与量子比特数量线性相关的谐波支持。这为基于相空间变分建模的QML开辟了一条新途径。", "summary": "本文针对量子机器学习在经典模拟中因希尔伯特空间指数增长而面临的维度限制问题，提出了一种新的解决方案。研究人员基于量子比特相空间和Stratonovich-Weyl对应关系，构建了一个适用于单比特和多比特系统的封闭且可组合的相空间动力学形式。该形式用辛流形上的函数动力学替代了传统的算子代数，并成功地将维度诅咒问题转化为一个与量子比特数量呈线性关系的谐波支持问题。这项工作为基于相空间变分建模的量子机器学习开辟了新的研究方向。", "keywords": "量子机器学习, 相空间, 维度诅咒, Stratonovich-Weyl对应, 多比特系统", "comments": "这篇论文通过引入相空间方法来解决量子机器学习中经典的“维度诅咒”问题，具有创新性。它将指数级的复杂性转化为线性级的缩放，为QML的实际应用奠定了新的理论基础。这种将算子代数转化为函数动力学的方法，为处理多比特量子系统提供了新的视角和工具。"}}
{"id": "2507.12396", "title": "OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments", "authors": ["Hayat Ullah", "Abbas Khan", "Arslan Munir", "Hari Kalva"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages", "url": "http://arxiv.org/abs/2507.12396v1", "summary": "Realistic human surveillance datasets are crucial for training and evaluating\ncomputer vision models under real-world conditions, facilitating the\ndevelopment of robust algorithms for human and human-interacting object\ndetection in complex environments. These datasets need to offer diverse and\nchallenging data to enable a comprehensive assessment of model performance and\nthe creation of more reliable surveillance systems for public safety. To this\nend, we present two visual object detection benchmarks named OD-VIRAT Large and\nOD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance\nimagery. The video sequences in both benchmarks cover 10 different scenes of\nhuman surveillance recorded from significant height and distance. The proposed\nbenchmarks offer rich annotations of bounding boxes and categories, where\nOD-VIRAT Large has 8.7 million annotated instances in 599,996 images and\nOD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also\nfocuses on benchmarking state-of-the-art object detection architectures,\nincluding RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object\ndetection-specific variant of VIRAT dataset. To the best of our knowledge, it\nis the first work to examine the performance of these recently published\nstate-of-the-art object detection architectures on realistic surveillance\nimagery under challenging conditions such as complex backgrounds, occluded\nobjects, and small-scale objects. The proposed benchmarking and experimental\nsettings will help in providing insights concerning the performance of selected\nobject detection models and set the base for developing more efficient and\nrobust object detection architectures.", "comment": "14 pages", "pdf_url": "http://arxiv.org/pdf/2507.12396v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "OD-VIRAT：一个用于现实监控环境中目标检测的大规模基准", "tldr": "本文提出了OD-VIRAT，一个用于现实监控环境中目标检测的大规模基准数据集，包含OD-VIRAT Large和OD-VIRAT Tiny两个版本，并在此基准上评估了最先进的目标检测模型。", "motivation": "现实的人类监控数据集对于在真实世界条件下训练和评估计算机视觉模型至关重要，它有助于在复杂环境中开发用于人类和人机交互目标检测的鲁棒算法。这些数据集需要提供多样化和具有挑战性的数据，以实现对模型性能的全面评估，并为公共安全创建更可靠的监控系统。", "method": "本文提出了两个名为OD-VIRAT Large和OD-VIRAT Tiny的视觉目标检测基准。这些基准的视频序列涵盖了从高处和远距离记录的10种不同的人类监控场景，并提供了丰富的边界框和类别标注。OD-VIRAT Large包含599,996张图像中的870万个标注实例，OD-VIRAT Tiny包含19,860张图像中的288,901个标注实例。此外，本文还在此特定于目标检测的VIRAT数据集变体上，对包括RETMDET、YOLOX、RetinaNet、DETR和Deformable-DETR在内的最先进目标检测架构进行了基准测试。", "result": "本文创建了两个大规模的现实监控环境目标检测基准数据集OD-VIRAT Large和OD-VIRAT Tiny，并首次在具有复杂背景、遮挡物体和小尺度物体等挑战性条件下，对最先进的目标检测架构在现实监控图像上的性能进行了检验。具体的模型性能数据未在摘要中提及。", "conclusion": "所提出的基准测试和实验设置将有助于提供关于所选目标检测模型性能的见解，并为开发更高效和鲁棒的目标检测架构奠定基础。", "translation": "现实的人类监控数据集对于在真实世界条件下训练和评估计算机视觉模型至关重要，它有助于在复杂环境中开发用于人类和人机交互目标检测的鲁棒算法。这些数据集需要提供多样化和具有挑战性的数据，以实现对模型性能的全面评估，并为公共安全创建更可靠的监控系统。为此，我们提出了两个名为OD-VIRAT Large和OD-VIRAT Tiny的视觉目标检测基准，旨在推进监控图像中的视觉理解任务。这两个基准中的视频序列涵盖了从显著高度和距离记录的10种不同人类监控场景。所提出的基准提供了丰富的边界框和类别标注，其中OD-VIRAT Large在599,996张图像中包含870万个标注实例，OD-VIRAT Tiny在19,860张图像中包含288,901个标注实例。这项工作还专注于在此特定于目标检测的VIRAT数据集变体上，对包括RETMDET、YOLOX、RetinaNet、DETR和Deformable-DETR在内的最先进目标检测架构进行基准测试。据我们所知，这是首次在复杂背景、遮挡物体和小尺度物体等挑战性条件下，检验这些最新发布的最先进目标检测架构在现实监控图像上的性能。所提出的基准测试和实验设置将有助于提供关于所选目标检测模型性能的见解，并为开发更高效和鲁棒的目标检测架构奠定基础。", "summary": "本文介绍了OD-VIRAT，一个用于现实监控环境中目标检测的大规模基准数据集，旨在促进复杂监控场景下的视觉理解任务。该基准包含OD-VIRAT Large和OD-VIRAT Tiny两个版本，提供了丰富的人类和人机交互目标标注，涵盖了多样的场景和挑战性条件。研究人员在此基准上评估了多种最先进的目标检测模型，旨在为未来开发更鲁棒高效的算法提供基础和见解。", "keywords": "目标检测, 监控环境, 大规模数据集, 基准测试, 计算机视觉", "comments": "本文的主要创新在于构建了一个大规模且具有挑战性的现实监控环境目标检测基准数据集OD-VIRAT，填补了现有数据集在真实世界复杂条件下的不足。通过对SOTA模型进行基准测试，该工作为评估和开发更鲁棒的目标检测算法提供了宝贵资源，对公共安全领域的计算机视觉应用具有重要意义。"}}
{"id": "2506.03194", "title": "HueManity: Probing Fine-Grained Visual Perception in MLLMs", "authors": ["Rynaa Grover", "Jayant Sravan Tamarapalli", "Sahiti Yerramilli", "Nilay Pande"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.03194v2", "summary": "Multimodal Large Language Models (MLLMs) excel at high-level visual\nreasoning, but their performance on nuanced perceptual tasks remains\nsurprisingly limited. We present HueManity, a benchmark designed to assess\nvisual perception in MLLMs. The dataset comprises 83,850 images featuring\ntwo-character alphanumeric strings embedded in Ishihara test style dot\npatterns, challenging models on precise pattern recognition. Our evaluation of\nnine state-of-the-art MLLMs on HueManity demonstrates a significant performance\ndeficit compared to human and traditional computer vision baselines. The\nbest-performing MLLM achieved a 33.6% accuracy on the numeric `easy' task and a\nstriking 3% on the alphanumeric `hard' task. In contrast, human participants\nachieved near-perfect scores (100% and 95.6%), and a fine-tuned ResNet50 model\nreached accuracies of 96.5% and 94.5%. These results highlight a critical gap\nin the visual capabilities of current MLLMs. Our analysis further explores\npotential architectural and training-paradigm factors contributing to this\nperceptual gap in MLLMs. We open-source HueManity dataset and code to foster\nfurther research in improving perceptual robustness of MLLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.03194v2", "cate": "cs.CV", "date": "2025-05-31", "updated": "2025-07-16", "AI": {"title_translation": "HueManity：探究多模态大语言模型中的细粒度视觉感知", "tldr": "MLLMs在细粒度视觉感知任务上表现不佳，HueManity基准测试显示其远逊于人类和传统CV模型。", "motivation": "尽管多模态大语言模型（MLLM）在高级视觉推理方面表现出色，但在细微的感知任务上性能却出人意料地有限。因此，需要一个专门的基准来评估和揭示MLLM在细粒度视觉感知方面的不足。", "method": "提出了名为HueManity的基准测试，该数据集包含83,850张图像，这些图像中包含嵌入在石原氏色盲测试风格点阵中的双字符字母数字字符串，旨在挑战模型的精确模式识别能力。研究评估了九个最先进的MLLM，并将其性能与人类参与者和经过微调的ResNet50模型进行了比较。", "result": "评估结果显示，与人类和传统计算机视觉基准相比，MLLM的性能存在显著缺陷。表现最好的MLLM在数字“简单”任务上准确率为33.6%，在字母数字“困难”任务上仅为3%。相比之下，人类参与者取得了接近完美的得分（100%和95.6%），而一个经过微调的ResNet50模型则达到了96.5%和94.5%的准确率。", "conclusion": "当前的多模态大语言模型在细粒度视觉感知方面存在关键性缺陷，远不及人类和专门的计算机视觉模型。这表明未来研究需要重点关注提高MLLM的感知鲁棒性。", "translation": "多模态大语言模型（MLLM）在高级视觉推理方面表现出色，但它们在细微感知任务上的性能却出人意料地有限。我们提出了HueManity，一个旨在评估MLLM视觉感知的基准。该数据集包含83,850张图像，这些图像中包含嵌入在石原氏色盲测试风格点阵中的双字符字母数字字符串，对模型的精确模式识别能力提出了挑战。我们对九个最先进的MLLM在HueManity上的评估表明，与人类和传统计算机视觉基准相比，其性能存在显著缺陷。表现最好的MLLM在数字“简单”任务上实现了33.6%的准确率，在字母数字“困难”任务上则惊人地达到了3%。相比之下，人类参与者取得了接近完美的得分（100%和95.6%），而一个经过微调的ResNet50模型达到了96.5%和94.5%的准确率。这些结果突显了当前MLLM视觉能力上的一个关键差距。我们的分析进一步探讨了导致MLLM这种感知差距的潜在架构和训练范式因素。我们开源了HueManity数据集和代码，以促进在提高MLLM感知鲁棒性方面的进一步研究。", "summary": "本文介绍了HueManity，一个用于评估多模态大语言模型（MLLM）细粒度视觉感知的基准。通过包含石原氏色盲测试风格图像的数据集，研究发现当前最先进的MLLM在精确模式识别任务上表现远逊于人类和传统计算机视觉模型，揭示了MLLM在视觉感知能力上的显著缺陷。论文还探讨了导致这种感知差距的潜在因素，并开源了数据集和代码以促进相关研究，旨在提高MLLM的感知鲁棒性。", "keywords": "多模态大语言模型, 视觉感知, 基准测试, HueManity, 精确模式识别", "comments": "这篇论文通过引入一个新颖的、针对细粒度视觉感知的基准测试（HueManity），揭示了当前多模态大语言模型（MLLM）的一个重要局限性。其创新之处在于使用类似石原氏色盲测试的图像来挑战模型，有效暴露了MLLM在处理细微视觉信息方面的不足。这项工作对于推动MLLM在更广泛、更复杂的视觉任务上的发展具有重要意义，促使研究人员关注并解决其感知鲁棒性问题。"}}
{"id": "2403.15740", "title": "Protecting Copyrighted Material with Unique Identifiers in Large Language Model Training", "authors": ["Shuai Zhao", "Linchao Zhu", "Ruijie Quan", "Yi Yang"], "categories": ["cs.CL", "cs.CR", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      A technical report, work mainly done in the early of 2024", "url": "http://arxiv.org/abs/2403.15740v3", "summary": "A primary concern regarding training large language models (LLMs) is whether\nthey abuse copyrighted online text. With the increasing training data scale and\nthe prevalence of LLMs in daily lives, two problems arise: \\textbf{1)} false\npositive membership inference results misled by similar examples; \\textbf{2)}\nmembership inference methods are usually too complex for end users to\nunderstand and use. To address these issues, we propose an alternative\n\\textit{insert-and-detect} methodology, advocating that web users and content\nplatforms employ \\textbf{\\textit{unique identifiers}} for reliable and\nindependent membership inference. Users and platforms can create their\nidentifiers, embed them in copyrighted text, and independently detect them in\nfuture LLMs. As an initial demonstration, we introduce \\textit{\\textbf{ghost\nsentences}} and a user-friendly last-$k$ words test, allowing end users to chat\nwith LLMs for membership inference. Ghost sentences consist primarily of unique\npassphrases of random natural words, which can come with customized elements to\nbypass possible filter rules. The last-$k$ words test requires a significant\nrepetition time of ghost sentences~($\\ge10$). For cases with fewer repetitions,\nwe designed an extra perplexity test, as LLMs exhibit high perplexity when\nencountering unnatural passphrases. We also conduct a comprehensive study on\nthe memorization and membership inference of ghost sentences, examining factors\nsuch as training data scales, model sizes, repetition times, insertion\npositions, wordlist of passphrases, alignment, \\textit{etc}. Our study shows\nthe possibility of applying ghost sentences in real scenarios and provides\ninstructions for the potential application.", "comment": "A technical report, work mainly done in the early of 2024", "pdf_url": "http://arxiv.org/pdf/2403.15740v3", "cate": "cs.CL", "date": "2024-03-23", "updated": "2025-07-16", "AI": {"title_translation": "大型语言模型训练中通过唯一标识符保护版权材料", "tldr": "提出一种“插入-检测”方法，通过在版权文本中嵌入唯一标识符（如“幽灵句子”）来帮助用户独立检测LLM是否滥用其版权内容，解决现有成员推断方法的复杂性和假阳性问题。", "motivation": "主要关注大型语言模型（LLM）是否滥用受版权保护的在线文本。现有问题包括：1) 相似示例误导导致的成员推断假阳性结果；2) 成员推断方法对终端用户而言过于复杂，难以理解和使用。", "method": "提出“插入-检测”方法，倡导网络用户和内容平台采用唯一标识符进行可靠和独立的成员推断。用户和平台可以创建标识符，嵌入到版权文本中，并在未来的LLM中独立检测。初步演示引入“幽灵句子”（ghost sentences）和用户友好的“最后k个词测试”（last-k words test），允许终端用户与LLM聊天进行成员推断。幽灵句子主要由随机自然词汇的独特密码短语组成，可定制以绕过过滤规则。“最后k个词测试”需要幽灵句子重复次数较多（≥10）。对于重复次数较少的情况，设计了额外的“困惑度测试”（perplexity test）。进行了关于幽灵句子的记忆和成员推断的综合研究，检查了训练数据规模、模型大小、重复次数、插入位置、密码短语词表、对齐等因素。", "result": "研究表明幽灵句子在实际场景中应用的可能性，并为潜在应用提供了指导。", "conclusion": "研究表明幽灵句子在实际场景中应用的可能性，并为潜在应用提供了指导。", "translation": "关于训练大型语言模型（LLM）的一个主要问题是它们是否滥用受版权保护的在线文本。随着训练数据规模的增加和LLM在日常生活中日益普及，出现了两个问题：1) 相似示例误导导致的成员推断假阳性结果；2) 成员推断方法通常对终端用户来说过于复杂，难以理解和使用。为了解决这些问题，我们提出了一种替代的“插入-检测”方法，提倡网络用户和内容平台采用“唯一标识符”进行可靠和独立的成员推断。用户和平台可以创建他们的标识符，将其嵌入到受版权保护的文本中，并在未来的LLM中独立检测它们。作为初步演示，我们引入了“幽灵句子”和用户友好的“最后k个词测试”，允许终端用户与LLM聊天进行成员推断。幽灵句子主要由随机自然词汇的独特密码短语组成，可以带有定制元素以绕过可能的过滤规则。最后k个词测试需要幽灵句子有显著的重复次数（≥10）。对于重复次数较少的情况，我们设计了一个额外的困惑度测试，因为LLM在遇到不自然的密码短语时会表现出高困惑度。我们还对幽灵句子的记忆和成员推断进行了综合研究，检查了训练数据规模、模型大小、重复次数、插入位置、密码短语词表、对齐等因素。我们的研究表明了在实际场景中应用幽灵句子的可能性，并为潜在应用提供了指导。", "summary": "这篇论文提出了一种名为“插入-检测”的新方法，旨在解决大型语言模型（LLM）训练中版权滥用检测的难题。针对现有成员推断方法存在的假阳性高和用户使用复杂的问题，作者建议内容创作者在受版权保护的文本中嵌入“唯一标识符”（如“幽灵句子”）。这些标识符可以在未来的LLM中被独立检测，从而判断其是否使用了受版权保护的内容。论文介绍了基于“幽灵句子”和“最后k个词测试”的用户友好型检测方案，并为低重复率场景设计了“困惑度测试”。综合研究表明了该方法在实际应用中的可行性。", "keywords": "版权保护, 大型语言模型, 唯一标识符, 成员推断, 幽灵句子", "comments": "该论文提出了一种新颖且实用的版权保护方法，通过“插入-检测”范式，将版权检测的主动权交还给内容创作者。其创新点在于引入“幽灵句子”作为唯一标识符，并设计了用户友好的检测机制，有效降低了成员推断的复杂性并减少了假阳性。这对于解决LLM训练数据版权归属问题具有重要意义，尤其是在大规模数据时代，为内容创作者提供了新的保护工具。"}}
{"id": "1909.10455", "title": "Geometry, Computation, and Optimality in Stochastic Optimization", "authors": ["Chen Cheng", "Daniel Levy", "John C. Duchi"], "categories": ["math.OC", "cs.IT", "cs.LG", "math.IT", "stat.ML"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      47 pages. An earlier version of this paper, entitled \"Necessary and Sufficient Geometries for Gradient Methods,\" appeared at NeurIPS 2019 ( arXiv:1909.10455v2 )", "url": "http://arxiv.org/abs/1909.10455v4", "summary": "We study computational and statistical consequences of problem geometry in\nstochastic and online optimization. By focusing on constraint set and gradient\ngeometry, we characterize the problem families for which stochastic- and\nadaptive-gradient methods are (minimax) optimal and, conversely, when nonlinear\nupdates -- such as those mirror descent employs -- are necessary for optimal\nconvergence. When the constraint set is quadratically convex, diagonally\npre-conditioned stochastic gradient methods are minimax optimal. We provide\nquantitative converses showing that the ``distance'' of the underlying\nconstraints from quadratic convexity determines the sub-optimality of\nsubgradient methods. These results apply, for example, to any $\\ell_p$-ball for\n$p < 2$, and the computation/accuracy tradeoffs they demonstrate exhibit a\nstriking analogy to those in Gaussian sequence models.", "comment": "47 pages. An earlier version of this paper, entitled \"Necessary and\n  Sufficient Geometries for Gradient Methods,\" appeared at NeurIPS 2019\n  (arXiv:1909.10455v2)", "pdf_url": "http://arxiv.org/pdf/1909.10455v4", "cate": "math.OC", "date": "2019-09-23", "updated": "2025-07-16", "AI": {"title_translation": "随机优化中的几何、计算和最优性", "tldr": "本文研究了随机优化中问题几何对计算和统计结果的影响，并确定了不同梯度方法的最优性条件。", "motivation": "研究问题几何在随机和在线优化中的计算和统计影响，并确定不同梯度方法何时能达到最优收敛，以及何时需要非线性更新。", "method": "通过关注约束集和梯度几何，论文表征了随机梯度和自适应梯度方法在哪些问题族中是（minimax）最优的，以及何时需要非线性更新（如镜像下降）才能实现最优收敛。", "result": "当约束集是二次凸时，对角预处理的随机梯度方法是minimax最优的。研究量化了基础约束与二次凸性之间的“距离”如何决定次梯度方法的次优性。这些结果适用于例如任何 $p < 2$ 的 $\\ell_p$ 球，并且计算/精度权衡展示了与高斯序列模型中惊人的类比。", "conclusion": "问题几何对随机优化算法的性能和最优性至关重要。二次凸性是随机梯度方法达到最优的关键条件，而与二次凸性的偏离则会导致次优性。研究强调了根据问题几何选择或设计优化算法的重要性。", "translation": "我们研究了随机和在线优化中问题几何的计算和统计结果。通过关注约束集和梯度几何，我们刻画了随机梯度和自适应梯度方法在哪些问题族中是（minimax）最优的，反之，何时需要非线性更新——例如镜像下降所采用的——才能实现最优收敛。当约束集是二次凸时，对角预处理的随机梯度方法是minimax最优的。我们提供了量化的反向结果，表明基础约束与二次凸性之间的“距离”决定了次梯度方法的次优性。这些结果例如适用于任何 $p < 2$ 的 $\\ell_p$ 球，并且它们所展示的计算/精度权衡与高斯序列模型中的权衡表现出惊人的类比。", "summary": "本文探讨了随机和在线优化中问题几何对算法性能的影响。研究揭示了当约束集为二次凸时，对角预处理的随机梯度方法是minimax最优的，并量化了约束集与二次凸性偏离程度对次梯度方法次优性的影响。研究还指出，对于某些问题族，非线性更新是实现最优收敛的必要条件。这些发现为理解和设计高效的随机优化算法提供了几何视角，并揭示了与高斯序列模型的类比。", "keywords": "随机优化, 问题几何, 梯度方法, 最优性, 二次凸性", "comments": "这篇论文的创新点在于系统地分析了问题几何（特别是约束集和梯度几何）对随机优化算法最优性的影响。它不仅指出了二次凸性作为对角预处理随机梯度方法达到最优的关键条件，还定量地阐明了偏离二次凸性如何导致次优性。这种深入的几何分析为理解不同优化算法的适用范围和性能限制提供了深刻的理论见解，并建立了与高斯序列模型的有趣类比，具有重要的理论和实践价值。"}}
{"id": "2507.12142", "title": "RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization", "authors": ["Vladimir Bogachev", "Vladimir Aletov", "Alexander Molozhavenko", "Denis Bobkov", "Vera Soboleva", "Aibek Alanov", "Maxim Rakhuba"], "categories": ["cs.LG", "cs.CL", "cs.NA", "math.DG", "math.NA", "68T07, 65F55, 53Z50"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12142v1", "summary": "Low-Rank Adaptation (LoRA) has become a widely adopted standard for\nparameter-efficient fine-tuning of large language models (LLMs), significantly\nreducing memory and computational demands. However, challenges remain,\nincluding finding optimal initialization strategies or mitigating\noverparametrization in low-rank matrix factorization. In this work, we propose\na novel approach that addresses both of the challenges simultaneously within a\nunified framework. Our method treats a set of fixed-rank LoRA matrices as a\nsmooth manifold. Considering adapters as elements on this manifold removes\noverparametrization, while determining the direction of the fastest loss\ndecrease along the manifold provides initialization. Special care is taken to\nobtain numerically stable and computationally efficient implementation of our\nmethod, using best practices from numerical linear algebra and Riemannian\noptimization. Experimental results on LLM and diffusion model architectures\ndemonstrate that RiemannLoRA consistently improves both convergence speed and\nfinal performance over standard LoRA and its state-of-the-art modifications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12142v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "RiemannLoRA：一种用于无歧义LoRA优化的统一黎曼框架", "tldr": "RiemannLoRA提出了一种统一的黎曼框架，通过将LoRA矩阵视为平滑流形来解决LoRA优化中的初始化和过参数化问题，从而在LLM和扩散模型上显著提高了收敛速度和最终性能。", "motivation": "低秩适应（LoRA）在LLM参数高效微调中广泛应用，但仍面临寻找最优初始化策略和缓解低秩矩阵分解中过参数化等挑战。", "method": "本文提出了一种新颖的方法，将一组固定秩的LoRA矩阵视为一个平滑流形。将适配器视为此流形上的元素可以消除过参数化，同时确定沿流形损失最快下降的方向提供了初始化。该方法利用数值线性代数和黎曼优化中的最佳实践，以实现数值稳定和计算高效的实现。", "result": "在LLM和扩散模型架构上的实验结果表明，RiemannLoRA始终优于标准LoRA及其最先进的修改，在收敛速度和最终性能方面都有所提高。", "conclusion": "RiemannLoRA通过提供一个统一的黎曼框架，有效地解决了LoRA优化中的关键挑战，实现了更优的性能和更快的收敛。", "translation": "低秩适应（LoRA）已成为大型语言模型（LLM）参数高效微调的广泛采用标准，显著降低了内存和计算需求。然而，挑战依然存在，包括寻找最优初始化策略或缓解低秩矩阵分解中的过参数化。在这项工作中，我们提出了一种新颖的方法，在一个统一的框架内同时解决这两个挑战。我们的方法将一组固定秩的LoRA矩阵视为一个平滑流形。将适配器视为此流形上的元素消除了过参数化，同时确定沿流形损失最快下降的方向提供了初始化。我们特别注意使用数值线性代数和黎曼优化中的最佳实践，以获得数值稳定且计算高效的方法实现。在LLM和扩散模型架构上的实验结果表明，RiemannLoRA始终优于标准LoRA及其最先进的修改，在收敛速度和最终性能方面都有所提高。", "summary": "RiemannLoRA提出了一种统一的黎曼框架，用于优化低秩适应（LoRA）。该方法通过将固定秩的LoRA矩阵视为一个平滑流形，同时解决了LoRA优化中的初始化和过参数化问题。通过黎曼优化，该框架能够确定损失下降最快的方向进行初始化，并消除过参数化。实验证明，RiemannLoRA在LLM和扩散模型上均能显著提升收敛速度和最终性能，优于现有LoRA方法。", "keywords": "LoRA, 黎曼优化, 参数高效微调, 大语言模型, 过参数化", "comments": "该论文的创新之处在于提出了一个统一的黎曼框架来解决LoRA优化中的两个关键且相互关联的挑战：初始化和过参数化。通过将LoRA矩阵视为流形上的元素，它提供了一种几何视角来处理这些问题，这在LoRA优化领域是新颖的。这种方法不仅理论严谨，而且在实践中也展现出显著的性能提升，对于参数高效微调具有重要意义。"}}
{"id": "2411.14995", "title": "Learning Lifted STRIPS Models from Action Traces Alone: A Simple, General, and Scalable Solution", "authors": ["Jonas Gösgens", "Niklas Jansen", "Hector Geffner"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      accepted at ICAPS 2025", "url": "http://arxiv.org/abs/2411.14995v3", "summary": "Learning STRIPS action models from action traces alone is a challenging\nproblem as it involves learning the domain predicates as well. In this work, a\nnovel approach is introduced which, like the well-known LOCM systems, is\nscalable, but like SAT approaches, is sound and complete. Furthermore, the\napproach is general and imposes no restrictions on the hidden domain or the\nnumber or arity of the predicates. The new learning method is based on an\n\\emph{efficient, novel test} that checks whether the assumption that a\npredicate is affected by a set of action patterns, namely, actions with\nspecific argument positions, is consistent with the traces. The predicates and\naction patterns that pass the test provide the basis for the learned domain\nthat is then easily completed with preconditions and static predicates. The new\nmethod is studied theoretically and experimentally. For the latter, the method\nis evaluated on traces and graphs obtained from standard classical domains like\nthe 8-puzzle, which involve hundreds of thousands of states and transitions.\nThe learned representations are then verified on larger instances.", "comment": "accepted at ICAPS 2025", "pdf_url": "http://arxiv.org/pdf/2411.14995v3", "cate": "cs.AI", "date": "2024-11-22", "updated": "2025-07-16", "AI": {"title_translation": "仅从动作轨迹中学习提升的STRIPS模型：一个简单、通用且可扩展的解决方案", "tldr": "该论文提出了一种新颖、可扩展、完备且健全的方法，用于仅从动作轨迹中学习STRIPS动作模型，包括领域谓词，并在经典领域中进行了评估。", "motivation": "仅从动作轨迹中学习STRIPS动作模型是一个具有挑战性的问题，因为它还涉及到学习领域谓词。", "method": "该研究引入了一种新颖的方法，该方法像LOCM系统一样具有可扩展性，但像SAT方法一样是完备且健全的。该方法具有通用性，对隐藏域或谓词的数量或元数没有限制。新的学习方法基于一个高效、新颖的测试，该测试检查谓词受一组动作模式影响的假设是否与轨迹一致。通过测试的谓词和动作模式为学习到的域提供了基础，然后用前置条件和静态谓词进行完善。", "result": "该方法在理论上和实验上都进行了研究。实验中，该方法在从8-puzzle等标准经典领域获得的轨迹和图上进行了评估，这些领域涉及数十万个状态和转换。学习到的表示在更大的实例上进行了验证。", "conclusion": "该论文介绍了一种新颖、通用、可扩展、完备且健全的方法，用于仅从动作轨迹中学习STRIPS模型，并在经典领域中证明了其有效性。", "translation": "仅从动作轨迹中学习STRIPS动作模型是一个具有挑战性的问题，因为它还涉及到学习领域谓词。在这项工作中，引入了一种新颖的方法，该方法像著名的LOCM系统一样具有可扩展性，但像SAT方法一样，是完备且健全的。此外，该方法是通用的，对隐藏域或谓词的数量或元数没有限制。新的学习方法基于一种高效、新颖的测试，该测试检查谓词受一组动作模式（即具有特定参数位置的动作）影响的假设是否与轨迹一致。通过测试的谓词和动作模式为学习到的域提供了基础，然后可以轻松地用前置条件和静态谓词来完善。新方法在理论上和实验上都进行了研究。在实验方面，该方法在从8-puzzle等标准经典领域获得的轨迹和图上进行了评估，这些领域涉及数十万个状态和转换。然后，学习到的表示在更大的实例上进行了验证。", "summary": "该论文提出了一种新颖、通用、可扩展、完备且健全的方法，用于仅从动作轨迹中学习提升的STRIPS动作模型，包括领域谓词。它采用一种高效的测试来识别一致的谓词和动作模式，这些构成了学习域的基础。该方法经过理论分析，并在8-puzzle等大型经典领域中进行了实验验证。", "keywords": "STRIPS模型, 动作轨迹, 谓词学习, 模型学习, 可扩展性", "comments": "该论文在仅从有限数据（动作轨迹）中学习STRIPS模型方面取得了重要进展，解决了同时学习领域谓词的挑战性问题。其主要创新在于实现了可扩展性（如LOCM）同时保持了完备性和健全性（如SAT方法），并且对领域或谓词没有限制，具有通用性。文中提出的“高效、新颖的测试”是其方法论的核心，使其成为解决AI规划中复杂问题的鲁棒解决方案。"}}
{"id": "2506.10972", "title": "Predictable Scale: Part II, Farseer: A Refined Scaling Law in Large Language Models", "authors": ["Houyi Li", "Wenzhen Zheng", "Qiufeng Wang", "Zhenyu Ding", "Haoying Wang", "Zili Wang", "Shijie Xuyang", "Ning Ding", "Shuigeng Zhou", "Xiangyu Zhang", "Daxin Jiang"], "categories": ["cs.LG", "cs.AI", "I.2"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      34", "url": "http://arxiv.org/abs/2506.10972v3", "summary": "Training Large Language Models (LLMs) is prohibitively expensive, creating a\ncritical scaling gap where insights from small-scale experiments often fail to\ntransfer to resource-intensive production systems, thereby hindering efficient\ninnovation. To bridge this, we introduce Farseer, a novel and refined scaling\nlaw offering enhanced predictive accuracy across scales. By systematically\nconstructing a model loss surface $L(N,D)$, Farseer achieves a significantly\nbetter fit to empirical data than prior laws (e.g., Chinchilla's law). Our\nmethodology yields accurate, robust, and highly generalizable predictions,\ndemonstrating excellent extrapolation capabilities, improving upon Chinchilla's\nlaw by reducing extrapolation error by 433\\%. This allows for the reliable\nevaluation of competing training strategies across all $(N,D)$ settings,\nenabling conclusions from small-scale ablation studies to be confidently\nextrapolated to predict large-scale performance. Furthermore, Farseer provides\nnew insights into optimal compute allocation, better reflecting the nuanced\ndemands of modern LLM training. To validate our approach, we trained an\nextensive suite of approximately 1,000 LLMs across diverse scales and\nconfigurations, consuming roughly 3 million NVIDIA H100 GPU hours. We are\ncomprehensively open-sourcing all models, data, results, and logs at\nhttps://github.com/Farseer-Scaling-Law/Farseer to foster further research.", "comment": "34", "pdf_url": "http://arxiv.org/pdf/2506.10972v3", "cate": "cs.LG", "date": "2025-06-12", "updated": "2025-07-16", "AI": {"title_translation": "可预测的规模：第二部分，Farseer：大型语言模型中改进的缩放定律", "tldr": "Farseer是一种新的、更精确的LLM缩放定律，可显著提高预测精度并减少外推误差，从而实现从小规模实验到大规模部署的可靠预测，并优化计算分配。", "motivation": "训练大型语言模型（LLM）成本高昂，且小规模实验的洞察力难以推广到资源密集型生产系统，导致效率低下并阻碍创新。", "method": "引入并构建了Farseer，一种新的、改进的缩放定律，通过系统地构建模型损失曲面L(N,D)来实现。通过训练大约1000个不同规模和配置的LLM，消耗约300万NVIDIA H100 GPU小时来验证其方法。", "result": "Farseer比先前的定律（如Chinchilla定律）能更好地拟合经验数据，并将外推误差减少了433%。它能提供准确、鲁棒、高度泛化的预测，并为最佳计算分配提供新见解。", "conclusion": "Farseer能够可靠地评估所有(N,D)设置下的竞争训练策略，使得小规模消融研究的结论能够自信地外推以预测大规模性能，并更好地反映现代LLM训练的细微需求，从而优化计算分配。", "translation": "训练大型语言模型（LLM）的成本高得令人望而却步，造成了一个关键的规模差距，即小规模实验的洞察力往往无法转移到资源密集型生产系统，从而阻碍了高效创新。为了弥合这一差距，我们引入了Farseer，这是一种新颖且经过改进的缩放定律，可提高跨尺度的预测精度。通过系统地构建模型损失曲面L(N,D)，Farseer比先前的定律（例如Chinchilla定律）能更好地拟合经验数据。我们的方法产生了准确、鲁棒且高度泛化的预测，展示了出色的外推能力，通过将外推误差减少433%来改进Chinchilla定律。这使得能够可靠地评估所有(N,D)设置下的竞争训练策略，从而使小规模消融研究的结论能够自信地外推以预测大规模性能。此外，Farseer为最佳计算分配提供了新见解，更好地反映了现代LLM训练的细微需求。为了验证我们的方法，我们训练了大约1000个不同规模和配置的LLM，消耗了大约300万NVIDIA H100 GPU小时。我们正在全面开源所有模型、数据、结果和日志，网址为https://github.com/Farseer-Scaling-Law/Farseer，以促进进一步研究。", "summary": "本文提出了Farseer，一种针对大型语言模型（LLM）的改进型缩放定律，旨在解决小规模实验结果难以推广到大规模生产的“缩放鸿沟”问题。Farseer通过系统构建模型损失曲面L(N,D)，显著提高了预测精度和外推能力，将现有缩放定律（如Chinchilla定律）的外推误差减少了433%。这使得研究人员能够从小规模实验中可靠地预测大规模LLM的性能，并优化计算资源分配。该研究通过训练约1000个LLM并消耗大量GPU小时进行了验证，并承诺开源所有相关数据和模型，以促进进一步研究。", "keywords": "大型语言模型, 缩放定律, Farseer, 预测精度, 计算分配", "comments": "本文的创新之处在于提出了Farseer这一新的缩放定律，显著提高了LLM性能预测的准确性和外推能力，特别是将外推误差大幅降低了433%。这对于优化LLM训练成本、加速创新和指导资源分配具有重要意义。通过大规模实验验证（训练约1000个LLM并消耗300万GPU小时）并开源数据，也体现了其研究的严谨性和对社区的贡献。"}}
{"id": "2507.12148", "title": "Leveraging Sidewalk Robots for Walkability-Related Analyses", "authors": ["Xing Tong", "Michele D. Simoni", "Kaj Munhoz Arfvidsson", "Jonas Mårtensson"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12148v1", "summary": "Walkability is a key component of sustainable urban development, while\ncollecting detailed data on its related features remains challenging due to the\nhigh costs and limited scalability of traditional methods. Sidewalk delivery\nrobots, increasingly deployed in urban environments, offer a promising solution\nto these limitations. This paper explores how these robots can serve as mobile\ndata collection platforms, capturing sidewalk-level features related to\nwalkability in a scalable, automated, and real-time manner. A sensor-equipped\nrobot was deployed on a sidewalk network at KTH in Stockholm, completing 101\ntrips covering 900 segments. From the collected data, different typologies of\nfeatures are derived, including robot trip characteristics (e.g., speed,\nduration), sidewalk conditions (e.g., width, surface unevenness), and sidewalk\nutilization (e.g., pedestrian density). Their walkability-related implications\nwere investigated with a series of analyses. The results demonstrate that\npedestrian movement patterns are strongly influenced by sidewalk\ncharacteristics, with higher density, reduced width, and surface irregularity\nassociated with slower and more variable trajectories. Notably, robot speed\nclosely mirrors pedestrian behavior, highlighting its potential as a proxy for\nassessing pedestrian dynamics. The proposed framework enables continuous\nmonitoring of sidewalk conditions and pedestrian behavior, contributing to the\ndevelopment of more walkable, inclusive, and responsive urban environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12148v1", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "利用人行道机器人进行步行友好性相关分析", "tldr": "该研究探讨了如何利用配备传感器的人行道机器人作为移动数据收集平台，以可扩展、自动化和实时的方式收集步行友好性特征数据，并分析了这些数据对行人行为的影响。", "motivation": "传统方法收集详细的步行友好性相关数据成本高昂且可扩展性有限，这阻碍了可持续城市发展中步行友好性的关键作用。", "method": "研究部署了一台配备传感器的机器人在斯德哥尔摩KTH的人行道网络上，完成了101次行程，覆盖900个路段。从收集到的数据中，推导出了不同类型的特征，包括机器人行程特征（如速度、持续时间）、人行道状况（如宽度、路面不平整度）和人行道利用率（如行人密度），并对它们与步行友好性相关的含义进行了一系列分析。", "result": "结果表明，行人移动模式受人行道特征的强烈影响，较高的密度、较窄的宽度和不规则的路面与较慢且变化更大的轨迹相关。值得注意的是，机器人速度与行人行为密切相关，突显了其作为评估行人动态代理的潜力。", "conclusion": "所提出的框架能够持续监测人行道状况和行人行为，有助于发展更具步行友好性、包容性和响应性的城市环境。", "translation": "步行友好性是可持续城市发展的关键组成部分，然而，由于传统方法成本高昂且可扩展性有限，收集其相关特征的详细数据仍然具有挑战性。人行道送货机器人越来越多地部署在城市环境中，为克服这些限制提供了有前景的解决方案。本文探讨了这些机器人如何作为移动数据收集平台，以可扩展、自动化和实时的方式捕获与步行友好性相关的人行道层面特征。一台配备传感器的机器人在斯德哥尔摩KTH的人行道网络上进行了部署，完成了101次行程，覆盖了900个路段。从收集到的数据中，推导出了不同类型的特征，包括机器人行程特征（例如速度、持续时间）、人行道状况（例如宽度、路面不平整度）和人行道利用率（例如行人密度）。通过一系列分析，研究了它们与步行友好性相关的含义。结果表明，行人移动模式受到人行道特征的强烈影响，较高的密度、较窄的宽度和路面不规则性与较慢且变化更大的轨迹相关。值得注意的是，机器人速度与行人行为密切相关，突显了其作为评估行人动态代理的潜力。所提出的框架能够持续监测人行道状况和行人行为，有助于发展更具步行友好性、包容性和响应性的城市环境。", "summary": "该研究提出利用配备传感器的人行道机器人作为移动数据收集平台，以解决传统方法在收集步行友好性数据方面的成本和可扩展性问题。研究在斯德哥尔摩KTH部署机器人，收集了包括机器人行程特征、人行道状况和行人利用率在内的多类数据。分析结果显示，人行道特征（如密度、宽度、路面不平整）显著影响行人移动模式，机器人速度可作为评估行人动态的有效代理。此框架有望实现对人行道状况和行人行为的持续监测，从而促进城市环境的步行友好性。", "keywords": "人行道机器人, 步行友好性, 数据收集, 城市发展, 传感器平台", "comments": "这项研究创新性地将日益普及的人行道机器人应用于城市数据收集，为步行友好性分析提供了低成本、高效率和可扩展的新范式。通过实际部署和数据分析，验证了机器人作为移动传感平台的可行性及其收集数据的有效性，特别是机器人速度作为行人行为代理的潜力，为城市规划和管理提供了实用的工具。"}}
{"id": "2507.11331", "title": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array", "authors": ["Jiawei Lin", "Guokai Chen", "Yuanlong Li", "Thomas Bourgeat"], "categories": ["cs.AR", "cs.AI"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11331v2", "summary": "Transformer models rely heavily on scaled dot-product attention (SDPA),\ntypically implemented using the FlashAttention algorithm. However, current\nsystolic-array-based accelerators face significant challenges when executing\nFlashAttention. Systolic arrays can only achieve high utilization for\nconsecutive and large matrix multiplications. In contrast, FlashAttention\nrequires frequently interleaved matrix multiplications and softmax operations.\n  The frequent data swaps between the systolic array and external vector units\nresult in low systolic array utilization. This is further exacerbated by the\nfact that softmax involves numerous non-matrix operations, which are not\nwell-suited for systolic arrays. Moreover, the concurrent execution of matrix\nmultiplication on systolic arrays and softmax on vector units leads to register\nfile and SRAM port contention, further degrading performance.\n  To overcome these limitations, we propose FSA, an enhanced systolic array\narchitecture that enables the entire FlashAttention algorithm to run entirely\nwithin a single systolic array, eliminating the need for external vector units.\nAt the core of FSA is SystolicAttention, a novel scheduling algorithm that maps\nFlashAttention operations onto systolic arrays with fine-grained, element-wise\noverlap. This significantly improves array utilization while preserving the\noriginal floating-point operation order to maintain numerical stability.\n  We implement FSA in synthesizable RTL and evaluate its performance against\nstate-of-the-art commercial accelerators. Our results show that FSA achieves\n1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS\nNeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area\noverhead.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11331v2", "cate": "cs.AR", "date": "2025-07-15", "updated": "2025-07-16", "AI": {"title_translation": "脉动注意力：在单个脉动阵列中融合 FlashAttention", "tldr": "本文提出一种名为 FSA 的新型脉动阵列架构和 SystolicAttention 调度算法，使 FlashAttention 能完全在单个脉动阵列内高效运行，显著提升了利用率。", "motivation": "Transformer 模型严重依赖缩放点积注意力 (SDPA)，通常使用 FlashAttention 算法实现。然而，现有的基于脉动阵列的加速器在执行 FlashAttention 时面临重大挑战：脉动阵列仅对连续、大型矩阵乘法才能实现高利用率，而 FlashAttention 需要频繁交错的矩阵乘法和 softmax 操作。脉动阵列与外部向量单元之间频繁的数据交换导致脉动阵列利用率低下。此外，softmax 涉及大量非矩阵操作，不适合脉动阵列。矩阵乘法在脉动阵列上和 softmax 在向量单元上并发执行还会导致寄存器文件和 SRAM 端口争用，进一步降低性能。", "method": "为克服这些限制，我们提出了 FSA，一种增强型脉动阵列架构，它使整个 FlashAttention 算法能够完全在单个脉动阵列内运行，无需外部向量单元。FSA 的核心是 SystolicAttention，一种新颖的调度算法，它以细粒度、逐元素重叠的方式将 FlashAttention 操作映射到脉动阵列上。这显著提高了阵列利用率，同时保留了原始浮点运算顺序以保持数值稳定性。", "result": "我们在可综合 RTL 中实现了 FSA，并评估了其与最先进商业加速器的性能。结果显示，FSA 在注意力 FLOPs/s 利用率方面比 AWS NeuronCore-v2 高 1.77 倍，比 Google TPUv5e 高 4.83 倍，而面积开销仅约 10%。", "conclusion": "FSA 架构和 SystolicAttention 调度算法有效解决了现有脉动阵列加速器在执行 FlashAttention 时遇到的效率低下问题。通过将 FlashAttention 完全融合到单个脉动阵列中，该方法显著提高了硬件利用率和性能，证明了在专用硬件上高效加速 Transformer 注意力机制的可行性。", "translation": "Transformer 模型严重依赖缩放点积注意力 (SDPA)，通常使用 FlashAttention 算法实现。然而，现有的基于脉动阵列的加速器在执行 FlashAttention 时面临重大挑战。脉动阵列仅对连续和大型矩阵乘法才能实现高利用率。相比之下，FlashAttention 需要频繁交错的矩阵乘法和 softmax 操作。脉动阵列与外部向量单元之间频繁的数据交换导致脉动阵列利用率低下。softmax 涉及大量非矩阵操作，不适合脉动阵列，这进一步加剧了问题。此外，矩阵乘法在脉动阵列上和 softmax 在向量单元上并发执行会导致寄存器文件和 SRAM 端口争用，进一步降低性能。\n为克服这些限制，我们提出了 FSA，一种增强型脉动阵列架构，它使整个 FlashAttention 算法能够完全在单个脉动阵列内运行，无需外部向量单元。FSA 的核心是 SystolicAttention，一种新颖的调度算法，它以细粒度、逐元素重叠的方式将 FlashAttention 操作映射到脉动阵列上。这显著提高了阵列利用率，同时保留了原始浮点运算顺序以保持数值稳定性。\n我们在可综合 RTL 中实现了 FSA，并评估了其与最先进商业加速器的性能。结果显示，FSA 在注意力 FLOPs/s 利用率方面比 AWS NeuronCore-v2 高 1.77 倍，比 Google TPUv5e 高 4.83 倍，而面积开销仅约 10%。", "summary": "针对现有脉动阵列加速器在执行 FlashAttention 时面临的低利用率和性能瓶颈，本文提出了一种名为 FSA 的增强型脉动阵列架构。FSA 允许 FlashAttention 算法完全在单个脉动阵列内执行，无需外部向量单元。其核心是 SystolicAttention 调度算法，该算法以细粒度的逐元素重叠方式将 FlashAttention 操作映射到脉动阵列上，显著提高了阵列利用率并保持了数值稳定性。实验结果表明，FSA 在注意力 FLOPs/s 利用率方面比现有商业加速器有显著提升，且面积开销较小。", "keywords": "FlashAttention, 脉动阵列, Transformer, 硬件加速, SystolicAttention", "comments": "本文的创新点在于提出了一种将 FlashAttention 算法完全融合到单个脉动阵列中的硬件架构和调度算法。这有效地解决了传统脉动阵列在处理混合计算模式（如矩阵乘法与非矩阵操作）时的数据交换频繁和资源争用问题。该研究对于未来 Transformer 模型在专用硬件上的高效部署和加速具有重要意义，尤其是在边缘设备或对能效有严格要求的场景。"}}
{"id": "2507.12087", "title": "YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association", "authors": ["Xiang Yu", "Xinyao Liu", "Guang Liang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12087v1", "summary": "Tracking small, agile multi-objects (SMOT), such as birds, from an Unmanned\nAerial Vehicle (UAV) perspective is a highly challenging computer vision task.\nThe difficulty stems from three main sources: the extreme scarcity of target\nappearance features, the complex motion entanglement caused by the combined\ndynamics of the camera and the targets themselves, and the frequent occlusions\nand identity ambiguity arising from dense flocking behavior. This paper details\nour championship-winning solution in the MVA 2025 \"Finding Birds\" Small\nMulti-Object Tracking Challenge (SMOT4SB), which adopts the\ntracking-by-detection paradigm with targeted innovations at both the detection\nand association levels. On the detection side, we propose a systematic training\nenhancement framework named \\textbf{SliceTrain}. This framework, through the\nsynergy of 'deterministic full-coverage slicing' and 'slice-level stochastic\naugmentation, effectively addresses the problem of insufficient learning for\nsmall objects in high-resolution image training. On the tracking side, we\ndesigned a robust tracker that is completely independent of appearance\ninformation. By integrating a \\textbf{motion direction maintenance (EMA)}\nmechanism and an \\textbf{adaptive similarity metric} combining \\textbf{bounding\nbox expansion and distance penalty} into the OC-SORT framework, our tracker can\nstably handle irregular motion and maintain target identities. Our method\nachieves state-of-the-art performance on the SMOT4SB public test set, reaching\nan SO-HOTA score of \\textbf{55.205}, which fully validates the effectiveness\nand advancement of our framework in solving complex real-world SMOT problems.\nThe source code will be made available at\nhttps://github.com/Salvatore-Love/YOLOv8-SMOT.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12087v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "YOLOv8-SMOT：一种基于切片辅助训练和自适应关联的实时小目标跟踪高效鲁棒框架", "tldr": "YOLOv8-SMOT通过切片辅助训练和自适应关联，解决了无人机视角下小目标跟踪的挑战，并在MVA 2025 SMOT4SB挑战赛中获得冠军。", "motivation": "解决无人机视角下小而敏捷的多目标（如鸟类）跟踪的挑战，这些挑战包括目标外观特征稀缺、复杂运动纠缠以及频繁遮挡和身份模糊。", "method": "本文采用“检测-跟踪”范式。在检测方面，提出了SliceTrain框架，通过结合“确定性全覆盖切片”和“切片级随机增强”来解决高分辨率图像中小目标学习不足的问题。在跟踪方面，设计了一个独立于外观信息的鲁棒跟踪器，通过将运动方向维护（EMA）机制和结合边界框扩展与距离惩罚的自适应相似性度量集成到OC-SORT框架中，以稳定处理不规则运动并维护目标身份。", "result": "该方法在MVA 2025 SMOT4SB公共测试集上取得了55.205的SO-HOTA分数，实现了最先进的性能。", "conclusion": "提出的YOLOv8-SMOT框架在解决复杂的现实世界小多目标跟踪问题上是有效且先进的。", "translation": "从无人机（UAV）视角跟踪小而敏捷的多目标（SMOT），例如鸟类，是一项极具挑战性的计算机视觉任务。其困难主要源于三个方面：目标外观特征的极度稀缺、摄像机和目标自身组合动态引起的复杂运动纠缠，以及密集群聚行为导致的频繁遮挡和身份模糊。本文详细介绍了我们在MVA 2025“寻找鸟类”小多目标跟踪挑战赛（SMOT4SB）中夺冠的解决方案，该方案采用“检测-跟踪”范式，并在检测和关联层面进行了有针对性的创新。在检测方面，我们提出了一个名为SliceTrain的系统训练增强框架。该框架通过“确定性全覆盖切片”和“切片级随机增强”的协同作用，有效解决了高分辨率图像训练中小目标学习不足的问题。在跟踪方面，我们设计了一个完全独立于外观信息的鲁棒跟踪器。通过将运动方向维护（EMA）机制和结合边界框扩展与距离惩罚的自适应相似性度量集成到OC-SORT框架中，我们的跟踪器能够稳定处理不规则运动并维护目标身份。我们的方法在SMOT4SB公共测试集上取得了最先进的性能，SO-HOTA得分达到55.205，这充分验证了我们框架在解决复杂现实世界SMOT问题上的有效性和先进性。源代码将提供。", "summary": "本文介绍了YOLOv8-SMOT，一个为解决无人机视角下小多目标跟踪（SMOT）挑战而设计的框架。该方案在MVA 2025 SMOT4SB挑战赛中夺冠，它在检测端引入了SliceTrain框架，通过切片辅助训练增强小目标学习；在跟踪端，通过集成运动方向维护（EMA）机制和自适应相似性度量到OC-SORT框架中，实现了独立于外观信息的鲁棒跟踪。该方法在SMOT4SB数据集上取得了55.205的SO-HOTA分数，展现了其在复杂SMOT问题上的卓越性能。", "keywords": "小目标跟踪, YOLOv8, SliceTrain, 多目标跟踪, 无人机", "comments": "这篇论文通过在检测和跟踪两方面进行创新，有效地解决了无人机视角下小目标跟踪的难题，特别是在小目标特征稀缺和复杂运动场景下的表现。SliceTrain框架通过结合确定性切片和随机增强，创新性地提升了小目标检测能力。同时，独立于外观信息的跟踪器设计，并引入EMA和自适应相似性度量，增强了在目标频繁遮挡和身份模糊情况下的鲁棒性，这对于实际应用具有重要意义。"}}
{"id": "2507.11851", "title": "Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential", "authors": ["Mohammad Samragh", "Arnav Kundu", "David Harrison", "Kumari Nishu", "Devang Naik", "Minsik Cho", "Mehrdad Farajtabar"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11851v1", "summary": "Autoregressive language models are constrained by their inherently sequential\nnature, generating one token at a time. This paradigm limits inference speed\nand parallelism, especially during later stages of generation when the\ndirection and semantics of text are relatively certain. In this work, we\npropose a novel framework that leverages the inherent knowledge of vanilla\nautoregressive language models about future tokens, combining techniques to\nrealize this potential and enable simultaneous prediction of multiple\nsubsequent tokens. Our approach introduces several key innovations: (1) a\nmasked-input formulation where multiple future tokens are jointly predicted\nfrom a common prefix; (2) a gated LoRA formulation that preserves the original\nLLM's functionality, while equipping it for multi-token prediction; (3) a\nlightweight, learnable sampler module that generates coherent sequences from\nthe predicted future tokens; (4) a set of auxiliary training losses, including\na consistency loss, to enhance the coherence and accuracy of jointly generated\ntokens; and (5) a speculative generation strategy that expands tokens\nquadratically in the future while maintaining high fidelity. Our method\nachieves significant speedups through supervised fine-tuning on pretrained\nmodels. For example, it generates code and math nearly 5x faster, and improves\ngeneral chat and knowledge tasks by almost 2.5x. These gains come without any\nloss in quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11851v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "您的LLM了解未来：揭示其多令牌预测潜力", "tldr": "本文提出了一种新颖的框架，使自回归语言模型能够同时预测多个后续令牌，从而显著提高推理速度，而不损失质量。", "motivation": "自回归语言模型本质上的顺序性限制了推理速度和并行性，尤其是在文本方向和语义相对确定的生成后期阶段。", "method": "本文提出了一种新颖的框架，利用普通自回归语言模型对未来令牌的固有知识，通过结合以下技术实现多令牌同步预测：1) 掩码输入形式，从共同前缀联合预测多个未来令牌；2) 门控LoRA形式，在保留原始LLM功能的同时实现多令牌预测；3) 轻量级可学习采样器模块，从预测的未来令牌生成连贯序列；4) 一组辅助训练损失（包括一致性损失），以增强联合生成令牌的连贯性和准确性；5) 推测性生成策略，以二次方速度扩展未来令牌并保持高保真度。该方法通过在预训练模型上进行监督微调实现加速。", "result": "该方法通过在预训练模型上进行监督微调，实现了显著的加速。例如，生成代码和数学的速度提高了近5倍，普通聊天和知识任务的速度提高了近2.5倍。这些提升在不损失质量的前提下实现。", "conclusion": "本文提出的框架成功地利用了大型语言模型预测未来令牌的潜力，显著提高了推理速度，同时保持了生成质量，从而克服了自回归模型顺序生成的局限性。", "translation": "自回归语言模型受其固有的顺序性限制，一次只能生成一个令牌。这种范式限制了推理速度和并行性，尤其是在生成后期，当文本的方向和语义相对确定时。在这项工作中，我们提出了一种新颖的框架，利用普通自回归语言模型对未来令牌的固有知识，结合多种技术来实现这一潜力，并实现对多个后续令牌的同时预测。我们的方法引入了几项关键创新：(1) 一种掩码输入形式，其中多个未来令牌从共同前缀联合预测；(2) 一种门控LoRA形式，在保留原始LLM功能的同时，使其具备多令牌预测能力；(3) 一个轻量级、可学习的采样器模块，从预测的未来令牌生成连贯序列；(4) 一组辅助训练损失，包括一致性损失，以增强联合生成令牌的连贯性和准确性；(5) 一种推测性生成策略，以二次方速度扩展未来令牌，同时保持高保真度。我们的方法通过对预训练模型进行监督微调，实现了显著的加速。例如，它生成代码和数学的速度提高了近5倍，并将一般聊天和知识任务的速度提高了近2.5倍。这些收益没有任何质量损失。", "summary": "本文提出了一种新颖的框架，旨在克服自回归语言模型顺序生成令牌的限制，以提高推理速度和并行性。该框架利用LLM对未来令牌的内在知识，通过引入掩码输入、门控LoRA、可学习采样器模块、辅助训练损失和推测性生成策略等创新，实现多令牌同步预测。实验结果表明，该方法在代码和数学生成方面实现了近5倍的加速，在通用聊天和知识任务方面实现了近2.5倍的加速，且未损失生成质量。", "keywords": "LLM, 多令牌预测, 自回归, 推理速度, 推测性生成", "comments": "这项工作通过使LLM能够同时预测多个令牌，显著解决了自回归模型推理速度的瓶颈。其创新之处在于结合了多种技术，形成了一个全面的多令牌预测解决方案，包括巧妙的掩码输入设计、对LoRA的门控集成以及确保生成质量的辅助损失和推测性策略。实际的加速效果非常显著，显示了该方法在提高LLM应用效率方面的巨大潜力。"}}
{"id": "2506.06852", "title": "Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation", "authors": ["John Waithaka", "Moise Busogi"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.06852v2", "summary": "Semantic segmentation of satellite imagery is crucial for Earth observation\napplications, but remains constrained by limited labelled training data. While\nself-supervised pretraining methods like Masked Autoencoders (MAE) have shown\npromise, they focus on reconstruction rather than localisation-a fundamental\naspect of segmentation tasks. We propose adapting LOCA (Location-aware), a\nposition prediction self-supervised learning method, for multimodal satellite\nimagery semantic segmentation. Our approach addresses the unique challenges of\nsatellite data by extending SatMAE's channel grouping from multispectral to\nmultimodal data, enabling effective handling of multiple modalities, and\nintroducing same-group attention masking to encourage cross-modal interaction\nduring pretraining. The method uses relative patch position prediction,\nencouraging spatial reasoning for localisation rather than reconstruction. We\nevaluate our approach on the Sen1Floods11 flood mapping dataset, where it\nsignificantly outperforms existing reconstruction-based self-supervised\nlearning methods for satellite imagery. Our results demonstrate that position\nprediction tasks, when properly adapted for multimodal satellite imagery, learn\nrepresentations more effective for satellite image semantic segmentation than\nreconstruction-based approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.06852v2", "cate": "cs.CV", "date": "2025-06-07", "updated": "2025-07-16", "AI": {"title_translation": "多模态卫星图像语义分割的位置预测自监督学习", "tldr": "本文提出了一种针对多模态卫星图像语义分割的位置预测自监督学习方法（改编自LOCA），通过关注定位而非重建，显著优于现有的基于重建的自监督方法。", "motivation": "卫星图像的语义分割对地球观测应用至关重要，但受限于标记训练数据的不足。尽管像掩码自编码器（MAE）这样的自监督预训练方法已显示出前景，但它们侧重于重建而非定位，而定位是分割任务的一个基本方面。", "method": "本文提出将LOCA（位置感知）这一位置预测自监督学习方法，应用于多模态卫星图像语义分割。该方法通过扩展SatMAE的通道分组，从多光谱数据到多模态数据，以有效处理多种模态。同时引入同组注意力掩码，以鼓励预训练期间的跨模态交互。该方法使用相对补丁位置预测，鼓励空间推理以实现定位而非重建。", "result": "该方法在Sen1Floods11洪水测绘数据集上进行了评估，结果显示其显著优于现有的基于重建的卫星图像自监督学习方法。", "conclusion": "实验结果表明，位置预测任务在经过适当调整以适应多模态卫星图像后，学习到的表示比基于重建的方法更有效地用于卫星图像语义分割。", "translation": "卫星图像的语义分割对于地球观测应用至关重要，但仍受限于有限的标记训练数据。尽管像掩码自编码器（MAE）这样的自监督预训练方法已显示出前景，但它们侧重于重建而非定位——这是分割任务的一个基本方面。我们提出将LOCA（位置感知）这一位置预测自监督学习方法，应用于多模态卫星图像语义分割。我们的方法通过将SatMAE的通道分组从多光谱扩展到多模态数据，从而有效处理多种模态，并引入同组注意力掩码以鼓励预训练期间的跨模态交互，从而解决了卫星数据特有的挑战。该方法使用相对补丁位置预测，鼓励空间推理以实现定位而非重建。我们在Sen1Floods11洪水测绘数据集上评估了我们的方法，结果显示其显著优于现有的基于重建的卫星图像自监督学习方法。我们的结果表明，位置预测任务在经过适当调整以适应多模态卫星图像后，学习到的表示比基于重建的方法更有效地用于卫星图像语义分割。", "summary": "本文针对标记数据稀缺的问题，提出了一种新颖的多模态卫星图像语义分割自监督学习方法。该方法改编自LOCA，侧重于相对补丁位置预测而非图像重建，这与分割任务对定位的需求更为契合。为处理多模态卫星数据，该方法扩展了SatMAE的通道分组，并引入同组注意力掩码以增强跨模态交互。在Sen1Floods11洪水测绘数据集上的评估结果显示，该方法显著优于现有基于重建的自监督学习方法，证明了位置预测对于卫星图像语义分割能够学习到更有效的表示。", "keywords": "语义分割, 卫星图像, 自监督学习, 位置预测, 多模态", "comments": "该论文通过将自监督学习的重点从重建转向位置预测，为卫星图像分析提供了一种创新方法，这对于需要精确定位的语义分割任务更为相关。对LOCA的适应以及对多模态卫星数据的具体考量，如通道分组和跨模态注意力，体现了针对地球观测数据独特挑战的周到设计。相对于基于重建方法的显著性能提升，凸显了任务特定自监督预训练的重要性。"}}
{"id": "2507.11548", "title": "Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening", "authors": ["Kevin T Webster"], "categories": ["cs.CY", "cs.AI", "cs.CL", "I.2.1; K.4.2; I.2.6; K.4.1"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      58 pages, 4 figures", "url": "http://arxiv.org/abs/2507.11548v1", "summary": "The increasing use of generative AI for resume screening is predicated on the\nassumption that it offers an unbiased alternative to biased human\ndecision-making. However, this belief fails to address a critical question: are\nthese AI systems fundamentally competent at the evaluative tasks they are meant\nto perform? This study investigates the question of competence through a\ntwo-part audit of eight major AI platforms. Experiment 1 confirmed complex,\ncontextual racial and gender biases, with some models penalizing candidates\nmerely for the presence of demographic signals. Experiment 2, which evaluated\ncore competence, provided a critical insight: some models that appeared\nunbiased were, in fact, incapable of performing a substantive evaluation,\nrelying instead on superficial keyword matching. This paper introduces the\n\"Illusion of Neutrality\" to describe this phenomenon, where an apparent lack of\nbias is merely a symptom of a model's inability to make meaningful judgments.\nThis study recommends that organizations and regulators adopt a dual-validation\nframework, auditing AI hiring tools for both demographic bias and demonstrable\ncompetence to ensure they are both equitable and effective.", "comment": "58 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.11548v1", "cate": "cs.CY", "date": "2025-07-11", "updated": "2025-07-11", "AI": {"title_translation": "公平性不足：审计人工智能简历筛选中的能力与交叉偏见", "tldr": "人工智能简历筛选器被认为公正，但本研究发现它们不仅存在偏见，还可能缺乏实际评估能力，只进行肤浅的匹配。提出了“中立性幻觉”概念，并建议同时审计偏见和能力。", "motivation": "随着生成式AI在简历筛选中日益普及，人们普遍认为它能提供无偏见的替代方案，以取代有人类偏见的决策，但这种观点未能解决一个关键问题：这些AI系统是否具备执行评估任务的基本能力。", "method": "本研究通过对八个主要AI平台进行两部分审计来调查其能力问题。实验1验证了复杂的、情境化的种族和性别偏见。实验2评估了核心能力，发现一些看似无偏见的模型实际上无法进行实质性评估，仅依赖肤浅的关键词匹配。", "result": "实验1证实了复杂的、情境化的种族和性别偏见。实验2揭示，一些看似无偏见的模型实际上缺乏实质性评估能力，仅进行肤浅的关键词匹配。研究提出了“中立性幻觉”来描述这种现象，即表面上的无偏见仅仅是模型无法做出有意义判断的症状。", "conclusion": "本研究建议组织和监管机构采用双重验证框架，对AI招聘工具进行人口偏见和可证明能力两方面的审计，以确保其既公平又有效。", "translation": "越来越多地使用生成式人工智能进行简历筛选，其前提是假设它提供了一种无偏见的替代方案，以取代有人类偏见的决策。然而，这种信念未能解决一个关键问题：这些人工智能系统是否具备执行其应执行的评估任务的基本能力？本研究通过对八个主要人工智能平台进行两部分审计来调查能力问题。实验1证实了复杂的、情境化的种族和性别偏见，一些模型仅仅因为存在人口统计学信号就惩罚候选人。实验2评估了核心能力，提供了一个关键见解：一些看似无偏见的模型实际上无法进行实质性评估，而是依赖肤浅的关键词匹配。本文引入了“中立性幻觉”来描述这种现象，即表面上缺乏偏见仅仅是模型无法做出有意义判断的症状。本研究建议组织和监管机构采用双重验证框架，对人工智能招聘工具进行人口偏见和可证明能力两方面的审计，以确保它们既公平又有效。", "summary": "本文对八个人工智能简历筛选平台进行了审计，质疑其无偏见的假设。研究不仅揭示了种族和性别偏见，还发现一些模型严重缺乏能力，尽管表面上无偏见，但实际上只进行肤浅的关键词匹配。这种现象被称为“中立性幻觉”。研究主张采用双重验证框架，同时审计人工智能招聘工具的偏见和能力，以确保其公平性和有效性。", "keywords": "AI简历筛选, 偏见, 能力, 中立性幻觉, 双重验证", "comments": "这篇论文强调了AI公平性中一个关键但常被忽视的方面：能力。它有效地证明了，表面上没有偏见并不等同于有效或公平的AI，特别是当AI从根本上不具备完成任务的能力时。“中立性幻觉”的概念是一项重要贡献，为理解看似无偏见的AI为何仍有问题提供了框架。关于双重验证的建议对于在招聘等高风险应用中负责任地部署AI来说是实用且重要的。"}}
{"id": "2507.11929", "title": "Making Serverless Computing Extensible: A Case Study of Serverless Data Analytics", "authors": ["Minchen Yu", "Yinghao Ren", "Jiamu Zhao", "Jiaqi Li"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11929v1", "summary": "Serverless computing has attracted a broad range of applications due to its\nease of use and resource elasticity. However, developing serverless\napplications often poses a dilemma -- relying on general-purpose serverless\nplatforms can fall short of delivering satisfactory performance for complex\nworkloads, whereas building application-specific serverless systems undermines\nthe simplicity and generality. In this paper, we propose an extensible design\nprinciple for serverless computing. We argue that a platform should enable\ndevelopers to extend system behaviors for domain-specialized optimizations\nwhile retaining a shared, easy-to-use serverless environment. We take data\nanalytics as a representative serverless use case and realize this design\nprinciple in Proteus. Proteus introduces a novel abstraction of decision\nworkflows, allowing developers to customize control-plane behaviors for\nimproved application performance. Preliminary results show that Proteus's\nprototype effectively optimizes analytical query execution and supports\nfine-grained resource sharing across diverse applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11929v1", "cate": "cs.DC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "使无服务器计算可扩展：一个无服务器数据分析的案例研究", "tldr": "无服务器平台在处理复杂工作负载时性能不足；本文提出了一种可扩展的设计原则，并在 Proteus 中实现，展示了数据分析的性能提升。", "motivation": "通用无服务器平台在处理复杂工作负载时性能不足，而构建特定于应用程序的无服务器系统又会损害其简单性和通用性。因此，开发无服务器应用程序面临着性能与易用性之间的两难困境。", "method": "本文提出了一种无服务器计算的可扩展设计原则，旨在使开发人员能够扩展系统行为以进行领域专业化优化，同时保留共享、易于使用的无服务器环境。该原则在 Proteus 系统中实现，Proteus 引入了决策工作流这一新颖抽象，允许开发人员自定义控制平面行为以提高应用程序性能。", "result": "Proteus 的原型有效地优化了分析查询执行，并支持跨不同应用程序的细粒度资源共享。", "conclusion": "本文提出的可扩展设计原则，并在 Proteus 中实现，成功解决了通用无服务器平台在处理数据分析等复杂工作负载时的性能限制，同时保持了无服务器计算的优势。", "translation": "无服务器计算因其易用性和资源弹性而吸引了广泛的应用。然而，开发无服务器应用程序常常面临两难境地——依赖通用无服务器平台可能无法为复杂工作负载提供令人满意的性能，而构建特定于应用程序的无服务器系统则会损害其简单性和通用性。在本文中，我们提出了一种无服务器计算的可扩展设计原则。我们认为，平台应使开发人员能够扩展系统行为以进行领域专业化优化，同时保留共享、易于使用的无服务器环境。我们以数据分析作为代表性的无服务器用例，并在 Proteus 中实现了这一设计原则。Proteus 引入了一种新颖的决策工作流抽象，允许开发人员自定义控制平面行为以提高应用程序性能。初步结果表明，Proteus 的原型有效地优化了分析查询执行，并支持跨不同应用程序的细粒度资源共享。", "summary": "本文旨在解决无服务器应用开发中通用平台性能不足与定制系统失去简单性之间的矛盾。它提出了一种无服务器计算的可扩展设计原则，允许开发者在保持共享环境的同时优化系统行为。该原则在 Proteus 系统中得到实现，Proteus 是一个针对无服务器数据分析的系统，利用决策工作流来自定义控制平面行为。初步结果表明 Proteus 在优化分析查询执行和实现细粒度资源共享方面表现出色。", "keywords": "无服务器计算, 可扩展性, 数据分析, Proteus, 决策工作流", "comments": "该论文解决了无服务器计算中的一个关键挑战，即在通用性和专业工作负载性能之间取得平衡。Proteus 中“决策工作流”的引入似乎是一种创新的方式，可以在控制平面层面实现可扩展性，这对于优化像数据分析这样的复杂应用程序至关重要，同时又不牺牲无服务器的核心优势。这种方法有望显著拓宽无服务器平台的适用范围。"}}
{"id": "2507.12327", "title": "Mixed-integer Second-Order Cone Programming for Multi-period Scheduling of Flexible AC Transmission System Devices", "authors": ["Mohamad Charara", "Martin De Montigny", "Nivine Abou Daher", "Hanane Dagdougui", "Antoine Lesage-Landry"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      10 pages, 1 figure, submitted to CIGRÉ 2025 International Symposium, Paper 10998, PS1: System Enhancement, Markets and Regulation", "url": "http://arxiv.org/abs/2507.12327v1", "summary": "With the increasing energy demand and the growing integration of renewable\nsources of energy, power systems face operational challenges such as overloads,\nlosses, and stability concerns, particularly as networks operate near their\ncapacity limits. Flexible alternating current transmission system (FACTS)\ndevices are essential to ensure reliable grid operations and enable the\nefficient integration of renewable energy. This work introduces a mixed-integer\nsecond-order cone programming (MISOCP) model for the multi-period scheduling of\nkey FACTS devices in electric transmission systems. The proposed model\nintegrates four key control mechanisms: (i) on-load tap changers (OLTCs) for\nvoltage regulation via discrete taps; (ii) static synchronous compensators\n(STATCOMs) and (iii) shunt reactors for reactive power compensation; and (iv)\nthyristor-controlled series capacitors (TCSCs) for adjustable impedance and\nflow control. The objective is to minimize active power losses using a limited\nnumber of control actions while meeting physical and operational constraints at\nall times throughout the defined time horizon. To ensure tractability, the\nmodel employs a second-order cone relaxation of the power flow. Device-specific\nconstraints are handled via binary expansion and linearization: OLTCs and shunt\nreactors are modelled with discrete variables, STATCOMs through reactive power\nbounds, and TCSCs using a reformulation-linearization technique (RLT). A\nmulti-period formulation captures the sequential nature of decision making,\nensuring consistency across time steps. The model is evaluated on the IEEE\n9-bus, 30-bus, and RTS96 test systems, demonstrating its ability to reduce\nlosses, with potential applicability to larger-scale grids.", "comment": "10 pages, 1 figure, submitted to CIGR\\'E 2025 International\n  Symposium, Paper 10998, PS1: System Enhancement, Markets and Regulation", "pdf_url": "http://arxiv.org/pdf/2507.12327v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "柔性交流输电系统设备多周期调度的混合整数二阶锥规划", "tldr": "本文提出了一种混合整数二阶锥规划（MISOCP）模型，用于柔性交流输电系统（FACTS）设备的多周期调度，旨在减少有功功率损耗。", "motivation": "随着能源需求的增长和可再生能源的日益整合，电力系统面临过载、损耗和稳定性等运行挑战。柔性交流输电系统（FACTS）设备对于确保电网可靠运行和高效整合可再生能源至关重要。", "method": "本文提出了一种混合整数二阶锥规划（MISOCP）模型，用于电传输系统中关键FACTS设备的多周期调度。该模型整合了四种控制机制：有载分接开关（OLTCs）、静止同步补偿器（STATCOMs）、并联电抗器和晶闸管控制串联电容器（TCSCs）。目标是在满足物理和运行约束的同时，以有限的控制动作最小化有功功率损耗。为确保可处理性，模型采用了潮流的二阶锥松弛。设备特定约束通过二值展开和线性化处理：OLTCs和并联电抗器用离散变量建模，STATCOMs通过无功功率边界，TCSCs使用重构-线性化技术（RLT）。多周期公式捕捉了决策的顺序性，确保时间步长之间的一致性。", "result": "该模型在IEEE 9总线、30总线和RTS96测试系统上进行了评估，结果表明其能够减少损耗，并具有应用于大规模电网的潜力。", "conclusion": "本文提出的混合整数二阶锥规划（MISOCP）模型能够有效地对柔性交流输电系统（FACTS）设备进行多周期调度，以减少电力系统中的有功功率损耗，并具有应用于实际大规模电网的潜力。", "translation": "随着能源需求的增长和可再生能源的日益整合，电力系统面临过载、损耗和稳定性等运行挑战，尤其是在电网接近其容量极限运行时。柔性交流输电系统（FACTS）设备对于确保电网可靠运行和高效整合可再生能源至关重要。这项工作引入了一种混合整数二阶锥规划（MISOCP）模型，用于电力传输系统中关键FACTS设备的多周期调度。所提出的模型整合了四种关键控制机制：(i) 用于通过离散分接进行电压调节的有载分接开关（OLTCs）；(ii) 静止同步补偿器（STATCOMs）和 (iii) 用于无功功率补偿的并联电抗器；以及 (iv) 用于可调阻抗和潮流控制的晶闸管控制串联电容器（TCSCs）。目标是在整个定义的时间范围内，通过有限的控制动作，在任何时候都满足物理和运行约束的同时，最小化有功功率损耗。为确保可处理性，模型采用了潮流的二阶锥松弛。设备特定约束通过二值展开和线性化处理：OLTCs和并联电抗器用离散变量建模，STATCOMs通过无功功率边界，TCSCs使用重构-线性化技术（RLT）。多周期公式捕捉了决策的顺序性，确保时间步长之间的一致性。该模型在IEEE 9总线、30总线和RTS96测试系统上进行了评估，结果表明其能够减少损耗，并具有应用于更大规模电网的潜力。", "summary": "本文提出了一种基于混合整数二阶锥规划（MISOCP）的多周期调度模型，用于优化电力系统中关键柔性交流输电系统（FACTS）设备的运行。该模型整合了OLTCs、STATCOMs、并联电抗器和TCSCs四种控制机制，旨在通过最小化有功功率损耗来应对电网过载、损耗和稳定性问题，同时满足操作约束。为提高可处理性，模型采用了潮流的二阶锥松弛和针对不同设备的特定约束处理（如二值展开、线性化和RLT）。在多个IEEE标准测试系统上的评估结果表明，该模型在减少损耗方面表现出色，并具有应用于大型电网的潜力。", "keywords": "柔性交流输电系统, 混合整数二阶锥规划, 多周期调度, 有功功率损耗, 电力系统优化", "comments": "该论文的创新点在于将多种FACTS设备的控制机制整合到一个统一的MISOCP模型中，并采用二阶锥松弛和特定的线性化技术来处理复杂的非线性和离散变量，从而在保证计算可处理性的同时实现多周期优化。其重要性体现在为应对现代电力系统日益增长的挑战（如可再生能源整合和运行效率提升）提供了一种有效的调度工具。"}}
{"id": "2507.12420", "title": "InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization", "authors": ["Haoyuan Liu", "Hiroshi Watanabe"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12420v1", "summary": "Bounding box regression (BBR) is fundamental to object detection, where the\nregression loss is crucial for accurate localization. Existing IoU-based losses\noften incorporate handcrafted geometric penalties to address IoU's\nnon-differentiability in non-overlapping cases and enhance BBR performance.\nHowever, these penalties are sensitive to box shape, size, and distribution,\noften leading to suboptimal optimization for small objects and undesired\nbehaviors such as bounding box enlargement due to misalignment with the IoU\nobjective. To address these limitations, we propose InterpIoU, a novel loss\nfunction that replaces handcrafted geometric penalties with a term based on the\nIoU between interpolated boxes and the target. By using interpolated boxes to\nbridge the gap between predictions and ground truth, InterpIoU provides\nmeaningful gradients in non-overlapping cases and inherently avoids the box\nenlargement issue caused by misaligned penalties. Simulation results further\nshow that IoU itself serves as an ideal regression target, while existing\ngeometric penalties are both unnecessary and suboptimal. Building on InterpIoU,\nwe introduce Dynamic InterpIoU, which dynamically adjusts interpolation\ncoefficients based on IoU values, enhancing adaptability to scenarios with\ndiverse object distributions. Experiments on COCO, VisDrone, and PASCAL VOC\nshow that our methods consistently outperform state-of-the-art IoU-based losses\nacross various detection frameworks, with particularly notable improvements in\nsmall object detection, confirming their effectiveness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12420v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "InterpIoU：基于插值IoU优化的边界框回归再思考", "tldr": "InterpIoU提出了一种新的边界框回归损失函数，通过插值框的IoU来替代传统手工几何惩罚项，解决了现有IoU损失的痛点，尤其在小目标检测上表现出色。", "motivation": "现有的基于IoU的边界框回归损失函数常包含手工设计的几何惩罚项，以处理非重叠情况和提升性能。然而，这些惩罚项对边界框的形状、大小和分布敏感，导致小目标优化次优，并可能因与IoU目标不一致而导致边界框不必要的扩大。", "method": "我们提出了InterpIoU，这是一种新的损失函数，用基于插值框与目标之间IoU的项取代了手工几何惩罚项。通过使用插值框来弥合预测与真实值之间的差距，InterpIoU在非重叠情况下提供了有意义的梯度，并避免了因惩罚项错位导致的边界框扩大问题。在此基础上，我们引入了Dynamic InterpIoU，它根据IoU值动态调整插值系数，增强了对不同目标分布场景的适应性。", "result": "仿真结果表明，IoU本身是一个理想的回归目标，而现有几何惩罚项既不必要也非最优。在COCO、VisDrone和PASCAL VOC数据集上的实验表明，我们的方法在各种检测框架中始终优于最先进的基于IoU的损失，在小目标检测方面尤其有显著改进，证实了其有效性。", "conclusion": "InterpIoU及其动态版本有效解决了现有IoU损失的局限性，特别是在小目标检测方面取得了显著提升，证明了IoU本身作为回归目标的优越性，无需复杂的手工几何惩罚。", "translation": "边界框回归（BBR）是目标检测的基础，其中回归损失对于精确定位至关重要。现有的基于IoU的损失函数通常包含手工设计的几何惩罚项，以解决IoU在非重叠情况下的不可微问题并提升BBR性能。然而，这些惩罚项对边界框的形状、大小和分布敏感，常常导致小目标优化次优，并可能因与IoU目标不一致而导致边界框不必要的扩大等不良行为。为了解决这些限制，我们提出了InterpIoU，这是一种新颖的损失函数，它用基于插值框与目标之间IoU的项取代了手工几何惩罚项。通过使用插值框来弥合预测与真实值之间的差距，InterpIoU在非重叠情况下提供了有意义的梯度，并从根本上避免了因惩罚项错位导致的边界框扩大问题。仿真结果进一步表明，IoU本身是一个理想的回归目标，而现有几何惩罚项既不必要也非最优。在InterpIoU的基础上，我们引入了Dynamic InterpIoU，它根据IoU值动态调整插值系数，增强了对具有多样目标分布场景的适应性。在COCO、VisDrone和PASCAL VOC数据集上的实验表明，我们的方法在各种检测框架中始终优于最先进的基于IoU的损失，在小目标检测方面尤其有显著改进，证实了其有效性。", "summary": "本文提出了InterpIoU，一种新的边界框回归损失函数，旨在解决现有IoU损失中手工几何惩罚项的局限性。InterpIoU通过计算插值框与目标之间的IoU来提供有意义的梯度，从而避免了非重叠情况下的不可微问题和边界框扩大的不良行为。在此基础上，引入了动态调整插值系数的Dynamic InterpIoU以增强适应性。实验结果表明，InterpIoU及其变体在多个数据集上均优于现有方法，尤其在小目标检测方面表现突出，证明了IoU本身作为回归目标的有效性。", "keywords": "边界框回归, IoU优化, 目标检测, InterpIoU, 损失函数", "comments": "InterpIoU的创新点在于用基于插值框IoU的机制替代了传统手工设计的几何惩罚项，这不仅解决了IoU在非重叠情况下的梯度问题，还避免了由于惩罚项与IoU目标不一致导致的边界框扩大等副作用。其核心思想是让损失函数更直接地优化IoU本身，而非通过间接的几何距离。这一方法简化了损失设计，并被证明在小目标检测上具有显著优势，对边界框回归领域具有重要意义。"}}
{"id": "2507.12059", "title": "Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited", "authors": ["Anthony G Cohn", "Robert E Blackwell"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures. Accepted at QR 2025 : 38th International Workshop on Qualitative Reasoning at IJCAI", "url": "http://arxiv.org/abs/2507.12059v1", "summary": "We investigate the abilities of 28 Large language Models (LLMs) to reason\nabout cardinal directions (CDs) using a benchmark generated from a set of\ntemplates, extensively testing an LLM's ability to determine the correct CD\ngiven a particular scenario. The templates allow for a number of degrees of\nvariation such as means of locomotion of the agent involved, and whether set in\nthe first, second or third person. Even the newer Large Reasoning Models are\nunable to reliably determine the correct CD for all questions. This paper\nsummarises and extends earlier work presented at COSIT-24.", "comment": "8 pages, 5 figures. Accepted at QR 2025 : 38th International Workshop\n  on Qualitative Reasoning at IJCAI", "pdf_url": "http://arxiv.org/pdf/2507.12059v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "重新审视大型语言模型推理基本方向的能力", "tldr": "本文评估了28个大型语言模型（LLMs）在不同场景下推理基本方向的能力，发现即使是新的大型推理模型也无法可靠地确定所有问题的正确基本方向。", "motivation": "调查大型语言模型在基本方向推理方面的能力，并扩展先前的工作。", "method": "使用由模板生成的一个基准测试，该基准测试包含多种变体（如代理的移动方式、人称），对28个大型语言模型进行测试。", "result": "即使是较新的大型推理模型也无法可靠地确定所有问题的正确基本方向。", "conclusion": "大型语言模型在基本方向推理方面仍存在局限性，无法在所有情况下可靠地给出正确答案。", "translation": "我们调查了28个大型语言模型（LLMs）使用一套模板生成的基准测试来推理基本方向（CDs）的能力，该测试广泛地测试了LLM在给定特定场景下确定正确CD的能力。这些模板允许一定程度的变异，例如涉及的代理的移动方式，以及是以第一人称、第二人称还是第三人称设置。即使是较新的大型推理模型也无法可靠地确定所有问题的正确CD。本文总结并扩展了COSIT-24上提出的早期工作。", "summary": "本文评估了28个大型语言模型（LLMs）在基本方向推理方面的能力。研究人员通过使用一个包含多种变体的模板化基准测试来测试这些模型，发现即使是最新、最先进的推理模型也无法在所有测试场景中可靠地确定正确的方向。这项工作是对之前在COSIT-24上发表研究的总结和扩展。", "keywords": "大型语言模型, 基本方向, 推理, 基准测试, 空间认知", "comments": "这项研究通过引入多种场景变体来深入评估LLMs在空间推理（特别是基本方向）方面的能力，揭示了当前LLMs即使是大型推理模型在此类任务上的局限性，这对于理解LLMs的认知短板具有重要意义。该研究是对先前工作的扩展，表明了对LLM能力持续深入分析的必要性。"}}
{"id": "2507.11688", "title": "Composing Linear Layers from Irreducibles", "authors": ["Travis Pence", "Daisuke Yamada", "Vikas Singh"], "categories": ["cs.LG", "I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      27 Pages, 13 Tables, 8 Figures", "url": "http://arxiv.org/abs/2507.11688v1", "summary": "Contemporary large models often exhibit behaviors suggesting the presence of\nlow-level primitives that compose into modules with richer functionality, but\nthese fundamental building blocks remain poorly understood. We investigate this\ncompositional structure in linear layers by asking: can we identify/synthesize\nlinear transformations from a minimal set of geometric primitives? Using\nClifford algebra, we show that linear layers can be expressed as compositions\nof bivectors -- geometric objects encoding oriented planes -- and introduce a\ndifferentiable algorithm that decomposes them into products of rotors. This\nconstruction uses only O(log^2 d) parameters, versus O(d^2) required by dense\nmatrices. Applied to the key, query, and value projections in LLM attention\nlayers, our rotor-based layers match the performance of strong baselines such\nas block-Hadamard and low-rank approximations. Our findings provide an\nalgebraic perspective on how these geometric primitives can compose into\nhigher-level functions within deep models.", "comment": "27 Pages, 13 Tables, 8 Figures", "pdf_url": "http://arxiv.org/pdf/2507.11688v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "从不可约元素组合线性层", "tldr": "本文利用Clifford代数将线性层分解为旋子乘积，实现参数效率提升并在LLM中保持性能，为深度模型中的几何原语组合提供了代数视角。", "motivation": "当代大型模型中存在低级原语，这些原语组合成功能更丰富的模块，但其基本构建块的组成结构和功能尚不清楚。本文旨在探究线性层中这种组合结构，并尝试从最小几何原语集合中识别或合成线性变换。", "method": "该研究利用Clifford代数，证明线性层可以表示为双向量的组合，并提出了一种可微分算法，将线性层分解为旋子的乘积。", "result": "这种基于旋子的构建仅使用O(log^2 d)参数，远少于密集矩阵所需的O(d^2)参数。应用于LLM注意力层中的键、查询和值投影时，其性能与块-哈达玛和低秩近似等强基线模型相当。", "conclusion": "本研究的发现为深度模型中几何原语如何组合成更高级功能提供了代数视角。", "translation": "当代大型模型通常表现出低级原语的存在，这些原语组合成功能更丰富的模块，但这些基本构建块仍然知之甚少。我们通过提问：能否从一组最小的几何原语中识别/合成线性变换？来研究线性层中的这种组合结构。利用Clifford代数，我们展示了线性层可以表示为双向量（编码定向平面的几何对象）的组合，并引入了一种可微分算法，将其分解为旋子的乘积。这种构造仅使用O(log^2 d)参数，而密集矩阵需要O(d^2)参数。应用于大型语言模型（LLM）注意力层中的键、查询和值投影时，我们基于旋子的层与块-哈达玛和低秩近似等强基线模型的性能相匹配。我们的发现为这些几何原语如何在深度模型中组合成更高级的功能提供了代数视角。", "summary": "本文研究了大型模型中线性层的组合结构，旨在从最小几何原语构建线性变换。研究利用Clifford代数，提出了一种将线性层分解为旋子乘积的可微分算法，显著降低了参数量（从O(d^2)到O(log^2 d)）。在LLM注意力层中的应用表明，该方法在保持性能的同时实现了参数效率，为深度模型中几何原语的组合提供了新的代数视角。", "keywords": "Clifford代数, 线性层, 旋子分解, 参数效率, 深度学习", "comments": "这项工作通过引入基于Clifford代数的旋子分解，为理解和构建高效的线性层提供了一个创新的视角。其主要创新在于将复杂的线性变换分解为更基本的几何操作，并显著降低了参数复杂性。这对于大型模型的设计和优化具有重要意义，尤其是在追求模型轻量化和可解释性的背景下。"}}
{"id": "2507.11544", "title": "The Safety Gap Toolkit: Evaluating Hidden Dangers of Open-Source Models", "authors": ["Ann-Kathrin Dombrowski", "Dillon Bowen", "Adam Gleave", "Chris Cundy"], "categories": ["cs.CY", "cs.LG", "68T07"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      9 pages plus appendix", "url": "http://arxiv.org/abs/2507.11544v1", "summary": "Open-weight large language models (LLMs) unlock huge benefits in innovation,\npersonalization, privacy, and democratization. However, their core advantage -\nmodifiability - opens the door to systemic risks: bad actors can trivially\nsubvert current safeguards, turning beneficial models into tools for harm. This\nleads to a 'safety gap': the difference in dangerous capabilities between a\nmodel with intact safeguards and one that has been stripped of those\nsafeguards. We open-source a toolkit to estimate the safety gap for\nstate-of-the-art open-weight models. As a case study, we evaluate biochemical\nand cyber capabilities, refusal rates, and generation quality of models from\ntwo families (Llama-3 and Qwen-2.5) across a range of parameter scales (0.5B to\n405B) using different safeguard removal techniques. Our experiments reveal that\nthe safety gap widens as model scale increases and effective dangerous\ncapabilities grow substantially when safeguards are removed. We hope that the\nSafety Gap Toolkit (https://github.com/AlignmentResearch/safety-gap) will serve\nas an evaluation framework for common open-source models and as a motivation\nfor developing and testing tamper-resistant safeguards. We welcome\ncontributions to the toolkit from the community.", "comment": "9 pages plus appendix", "pdf_url": "http://arxiv.org/pdf/2507.11544v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08", "AI": {"title_translation": "安全差距工具包：评估开源模型的隐藏危险", "tldr": "开源大语言模型虽然有益，但其可修改性带来了系统性风险，恶意行为者可轻易移除安全防护，从而产生“安全差距”。本研究开源了一个工具包，用于评估最先进开源模型的安全差距，发现模型规模越大，安全差距越大，且移除安全防护后危险能力显著增加。", "motivation": "开放权重的大型语言模型（LLMs）带来了创新、个性化、隐私和民主化的巨大益处。然而，它们的核心优势——可修改性——也带来了系统性风险：恶意行为者可以轻易地规避当前的安全防护，将有益的模型变成有害的工具。这导致了“安全差距”：一个具有完整安全防护的模型与一个被剥离了安全防护的模型之间在危险能力上的差异。", "method": "开发并开源了一个工具包，用于估计最先进的开放权重模型的安全差距。作为案例研究，该研究评估了两个系列（Llama-3和Qwen-2.5）不同参数规模（0.5B到405B）模型的生化和网络能力、拒绝率和生成质量，使用了不同的安全防护移除技术。", "result": "实验表明，随着模型规模的增加，安全差距会扩大，并且当安全防护被移除时，有效的危险能力会显著增长。", "conclusion": "希望“安全差距工具包”能作为评估常见开源模型的框架，并激励开发和测试防篡改的安全防护措施。", "translation": "开放权重的大型语言模型（LLMs）在创新、个性化、隐私和民主化方面带来了巨大的益处。然而，它们的核心优势——可修改性——也为系统性风险打开了大门：恶意行为者可以轻易地规避当前的安全防护，将有益的模型变成有害的工具。这导致了“安全差距”：一个具有完整安全防护的模型与一个被剥离了安全防护的模型之间在危险能力上的差异。我们开源了一个工具包，用于估计最先进的开放权重模型的安全差距。作为案例研究，我们评估了两个系列（Llama-3和Qwen-2.5）不同参数规模（0.5B到405B）模型的生化和网络能力、拒绝率和生成质量，使用了不同的安全防护移除技术。我们的实验表明，随着模型规模的增加，安全差距会扩大，并且当安全防护被移除时，有效的危险能力会显著增长。我们希望“安全差距工具包”（https://github.com/AlignmentResearch/safety-gap）能作为一个评估常见开源模型的框架，并激励开发和测试防篡改的安全防护措施。我们欢迎社区对该工具包做出贡献。", "summary": "本研究提出了“安全差距”的概念，即开放权重大语言模型在移除安全防护后所展现的危险能力与原始模型之间的差异。为评估这一差距，研究团队开源了一个“安全差距工具包”，并以Llama-3和Qwen-2.5系列模型为例，在不同参数规模下测试了其生化和网络危险能力。实验结果显示，模型规模越大，安全差距越显著，且移除安全防护会大幅增加模型的危险能力。该工具包旨在为开源模型提供评估框架，并推动防篡改安全防护的开发。", "keywords": "安全差距, 开源模型, 大语言模型, 安全防护, 风险评估", "comments": "该研究创新性地提出了“安全差距”这一概念，并提供了一个实用的开源工具包，对于评估和缓解开源大模型潜在的滥用风险具有重要意义。其发现模型规模与安全差距之间的正相关性，为未来大模型的安全开发提供了关键见解。通过开源工具和鼓励社区贡献，该工作有望促进更安全、更负责任的AI发展。"}}
{"id": "2507.12210", "title": "PAPR of DFT-s-OTFS with Pulse Shaping", "authors": ["Jialiang Zhu", "Sanoopkumar P. S.", "Arman Farhang"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12210v1", "summary": "Orthogonal Time Frequency Space (OTFS) suffers from high peak-to-average\npower ratio (PAPR) when the number of Doppler bins is large. To address this\nissue, a discrete Fourier transform spread OTFS (DFT-s-OTFS) scheme is employed\nby applying DFT spreading across the Doppler dimension. This paper presents a\nthorough PAPR analysis of DFT-s-OTFS in the uplink scenario using different\npulse shaping filters and resource allocation strategies. Specifically, we\nderive a PAPR upper bound of DFT-s-OTFS with interleaved and block Doppler\nresource allocation schemes. Our analysis reveals that DFT-s-OTFS with\ninterleaved allocation yields a lower PAPR than that of block allocation.\nFurthermore, we show that interleaved allocation produces a periodic\ntime-domain signal composed of repeated quadrature amplitude modulated (QAM)\nsymbols which simplifies the transmitter design. Based on our analytical\nresults, the root raised cosine (RRC) pulse generally results in a higher\nmaximum PAPR compared to the rectangular pulse. Simulation results confirm the\nvalidity of the derived PAPR upper bounds. Furthermore, we also demonstrate\nthrough BER simulation analysis that the DFT-s-OTFS gives the same performance\nas OTFS without DFT spreading.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12210v1", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "带脉冲成形的DFT-s-OTFS的PAPR", "tldr": "OTFS在多普勒仓数量大时PAPR高。本文提出DFT-s-OTFS，通过分析表明交织分配方案比块分配方案具有更低的PAPR，且其误码率性能与OTFS相同。", "motivation": "正交时频空间（OTFS）在多普勒仓数量较多时会遇到较高的峰均功率比（PAPR）问题。", "method": "采用离散傅里叶变换扩展OTFS（DFT-s-OTFS）方案，通过在多普勒维度应用DFT扩展来解决PAPR问题。论文对上行链路场景下的DFT-s-OTFS进行了PAPR分析，并使用了不同的脉冲成形滤波器和资源分配策略。具体推导了交织和块状多普勒资源分配方案下DFT-s-OTFS的PAPR上限。", "result": "分析表明，采用交织分配的DFT-s-OTFS比块状分配的PAPR更低。此外，交织分配会产生由重复正交幅度调制（QAM）符号组成的周期性时域信号，从而简化了发射机设计。根据分析结果，根升余弦（RRC）脉冲通常比矩形脉冲导致更高的最大PAPR。仿真结果证实了推导的PAPR上限的有效性。误码率仿真分析表明DFT-s-OTFS的性能与未进行DFT扩展的OTFS相同。", "conclusion": "DFT-s-OTFS是一种有效的降低OTFS系统PAPR的方法，尤其是在采用交织资源分配时，且其误码率性能与标准OTFS相当。", "translation": "正交时频空间（OTFS）在多普勒仓数量较大时会遇到较高的峰均功率比（PAPR）问题。为了解决这个问题，本文采用了一种离散傅里叶变换扩展OTFS（DFT-s-OTFS）方案，通过在多普勒维度应用DFT扩展。本文对上行链路场景下的DFT-s-OTFS进行了全面的PAPR分析，并使用了不同的脉冲成形滤波器和资源分配策略。具体来说，我们推导了采用交织和块状多普勒资源分配方案的DFT-s-OTFS的PAPR上限。我们的分析表明，采用交织分配的DFT-s-OTFS比块状分配的PAPR更低。此外，我们还发现交织分配会产生由重复正交幅度调制（QAM）符号组成的周期性时域信号，从而简化了发射机设计。根据我们的分析结果，根升余弦（RRC）脉冲通常比矩形脉冲导致更高的最大PAPR。仿真结果证实了推导的PAPR上限的有效性。此外，我们还通过误码率仿真分析表明，DFT-s-OTFS的性能与未进行DFT扩展的OTFS相同。", "summary": "本文提出DFT-s-OTFS以降低OTFS在高多普勒仓数量时的PAPR。研究对上行链路场景下的DFT-s-OTFS进行了PAPR分析，比较了不同脉冲成形和资源分配策略。结果表明，交织多普勒资源分配方案比块状分配方案具有更低的PAPR，并能简化发射机设计。同时发现RRC脉冲通常导致更高的最大PAPR。仿真验证了PAPR上限的有效性，并证实DFT-s-OTFS与OTFS具有相同的误码率性能。", "keywords": "PAPR, DFT-s-OTFS, 脉冲成形, 资源分配, OTFS", "comments": "该论文通过引入DFT-s-OTFS有效解决了OTFS系统在高多普勒仓数量时面临的高PAPR问题。其创新点在于对不同脉冲成形和资源分配策略下的PAPR进行了深入分析，并推导了PAPR上限，为系统设计提供了理论依据。特别是发现交织分配不仅降低PAPR，还能简化发射机设计，具有实际应用价值。同时，保持与OTFS相同的BER性能也保证了其实用性。"}}
{"id": "2412.06771", "title": "Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty", "authors": ["Meera Hahn", "Wenjun Zeng", "Nithish Kannen", "Rich Galt", "Kartikeya Badola", "Been Kim", "Zi Wang"], "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.06771v2", "summary": "User prompts for generative AI models are often underspecified, leading to a\nmisalignment between the user intent and models' understanding. As a result,\nusers commonly have to painstakingly refine their prompts. We study this\nalignment problem in text-to-image (T2I) generation and propose a prototype for\nproactive T2I agents equipped with an interface to (1) actively ask\nclarification questions when uncertain, and (2) present their uncertainty about\nuser intent as an understandable and editable belief graph. We build simple\nprototypes for such agents and propose a new scalable and automated evaluation\napproach using two agents, one with a ground truth intent (an image) while the\nother tries to ask as few questions as possible to align with the ground truth.\nWe experiment over three image-text datasets: ImageInWords (Garg et al., 2024),\nCOCO (Lin et al., 2014) and DesignBench, a benchmark we curated with strong\nartistic and design elements. Experiments over the three datasets demonstrate\nthe proposed T2I agents' ability to ask informative questions and elicit\ncrucial information to achieve successful alignment with at least 2 times\nhigher VQAScore (Lin et al., 2024) than the standard T2I generation. Moreover,\nwe conducted human studies and observed that at least 90% of human subjects\nfound these agents and their belief graphs helpful for their T2I workflow,\nhighlighting the effectiveness of our approach. Code and DesignBench can be\nfound at https://github.com/google-deepmind/proactive_t2i_agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.06771v2", "cate": "cs.AI", "date": "2024-12-09", "updated": "2025-07-16", "AI": {"title_translation": "不确定性下多轮文本到图像生成的主动式代理", "tldr": "针对文本到图像（T2I）生成中用户提示不明确的问题，本文提出了主动式T2I代理。这些代理能够在不确定时主动提问以澄清用户意图，并以可编辑的信念图展示其对用户意图的不确定性，从而显著提高了生成效果和用户满意度。", "motivation": "生成式AI模型（特别是文本到图像生成模型）的用户提示往往不明确，导致用户意图与模型理解之间存在偏差，用户不得不花费大量精力反复修改提示。", "method": "本文提出了主动式文本到图像（T2I）代理原型，该代理配备一个界面，能够：1）在不确定时主动提出澄清问题；2）将对用户意图的不确定性以可理解和可编辑的信念图形式呈现。作者构建了这些代理的简单原型，并提出了一种可扩展的、自动化的评估方法，该方法使用两个代理：一个具有真实意图（一张图像），另一个尝试提出尽可能少的问题以与真实意图对齐。实验在ImageInWords、COCO和DesignBench（一个包含强烈艺术和设计元素的基准）三个图像-文本数据集上进行。此外，还进行了人工研究。", "result": "实验结果表明，所提出的T2I代理能够提出有益的问题并获取关键信息，实现与用户意图的成功对齐，其VQAScore（Lin et al., 2024）比标准T2I生成至少高出2倍。此外，人工研究观察到至少90%的受试者认为这些代理及其信念图对他们的T2I工作流程有帮助。", "conclusion": "本文提出的主动式T2I代理能够有效提出信息性问题并引出关键信息，显著改善了与用户意图的对齐，从而在文本到图像生成中提高了成功率和用户满意度。", "translation": "生成式AI模型的用户提示通常不够具体，导致用户意图与模型理解之间存在偏差。结果，用户常常不得不煞费苦心地完善他们的提示。我们研究了文本到图像（T2I）生成中的这种对齐问题，并提出了主动式T2I代理的原型，该代理配备了一个界面，能够（1）在不确定时主动提出澄清问题，以及（2）将他们对用户意图的不确定性以可理解和可编辑的信念图形式呈现。我们为这些代理构建了简单的原型，并提出了一种新的可扩展和自动化的评估方法，该方法使用两个代理，其中一个具有真实意图（一张图像），而另一个则尝试提出尽可能少的问题以与真实意图对齐。我们在三个图像-文本数据集上进行了实验：ImageInWords（Garg et al., 2024）、COCO（Lin et al., 2014）和DesignBench，一个我们策划的具有强烈艺术和设计元素的基准。在三个数据集上的实验表明，所提出的T2I代理能够提出信息性问题并获取关键信息，实现与用户意图的成功对齐，其VQAScore（Lin et al., 2024）比标准T2I生成至少高出2倍。此外，我们进行了人工研究，并观察到至少90%的人类受试者认为这些代理及其信念图对他们的T2I工作流程有帮助，这突出了我们方法的有效性。代码和DesignBench可在https://github.com/google-deepmind/proactive_t2i_agents找到。", "summary": "本文旨在解决文本到图像（T2I）生成中用户提示不明确导致的用户意图与模型理解错位问题。为解决此问题，论文提出了一种主动式T2I代理，该代理在不确定时能主动向用户提问以澄清意图，并通过可编辑的信念图直观展示对用户意图的不确定性。通过构建原型并采用新的自动化评估方法，结合对ImageInWords、COCO和DesignBench数据集的实验，以及用户研究，结果表明该方法能显著提高生成结果与用户意图的对齐度（VQAScore提升至少2倍），且获得用户高度认可（90%用户认为有帮助），有效提升了T2I生成的工作流效率和用户满意度。", "keywords": "主动式代理, 文本到图像生成, 用户意图, 不确定性, 多轮交互", "comments": "本文的创新点在于将文本到图像（T2I）生成代理从传统的被动响应转变为主动交互，解决了用户提示不明确的核心痛点。通过引入主动提问机制和可视化、可编辑的信念图来管理和呈现不确定性，极大地提升了用户体验和模型对用户意图的理解精度。提出的自动化评估方法也为未来研究提供了有价值的工具。人工研究结果有力地证明了该方法的实用性和有效性。"}}
{"id": "2507.11695", "title": "Discontinuous Galerkin approximation for a Stokes-Brinkman-type formulation for the eigenvalue problem in porous media", "authors": ["Felipe Lepe", "Gonzalo Rivera", "Jesus Vellojin"], "categories": ["math.NA", "cs.NA", "35Q35, 65N15, 65N25, 65N30, 65N50"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11695v1", "summary": "We introduce a family of discontinuous Galerkin methods to approximate the\neigenvalues and eigenfunctions of a Stokes-Brinkman type of problem based in\nthe interior penalty strategy. Under the standard assumptions on the meshes and\na suitable norm, we prove the stability of the discrete scheme. Due to the\nnon-conforming nature of the method, we use the well-known non-compact\noperators theory to derive convergence and error estimates for the method. We\npresent an exhaustive computational analysis where we compute the spectrum with\ndifferent stabilization parameters with the aim of study its influence when the\nspectrum is approximated.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11695v1", "cate": "math.NA", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "多孔介质中特征值问题的Stokes-Brinkman型公式的间断Galerkin近似", "tldr": "本文提出并分析了一种基于内罚策略的间断Galerkin方法，用于近似Stokes-Brinkman型问题的特征值和特征函数，并证明了其稳定性和收敛性，同时通过计算分析研究了稳定参数的影响。", "motivation": "近似Stokes-Brinkman型问题的特征值和特征函数。", "method": "引入了一系列基于内罚策略的间断Galerkin方法，用于近似Stokes-Brinkman型问题的特征值和特征函数。在网格标准假设和合适范数下，证明了离散格式的稳定性。利用非紧算子理论推导了方法的收敛性和误差估计。进行了详尽的计算分析，计算了不同稳定参数下的谱，以研究其对谱近似的影响。", "result": "证明了离散格式的稳定性；推导了方法的收敛性和误差估计；通过计算分析研究了稳定参数对谱近似的影响。", "conclusion": "该研究成功引入并分析了一种间断Galerkin方法，用于求解Stokes-Brinkman型特征值问题，并证明了其理论性质，同时通过计算分析探讨了稳定参数的影响。", "translation": "我们引入了一系列间断Galerkin方法，用于近似基于内罚策略的Stokes-Brinkman型问题的特征值和特征函数。在网格的标准假设和合适的范数下，我们证明了离散格式的稳定性。由于该方法的非协调性，我们使用众所周知的非紧算子理论来推导该方法的收敛性和误差估计。我们提出了一个详尽的计算分析，其中我们计算了不同稳定参数下的谱，旨在研究其在谱近似时的影响。", "summary": "本文提出了一种基于内罚策略的间断Galerkin方法，用于近似多孔介质中Stokes-Brinkman型特征值问题的特征值和特征函数。研究证明了该离散格式的稳定性，并利用非紧算子理论推导了其收敛性和误差估计。此外，通过详尽的计算分析，探讨了不同稳定参数对谱近似的影响。", "keywords": "间断Galerkin方法, Stokes-Brinkman, 特征值问题, 多孔介质, 内罚策略", "comments": "该论文的创新点在于将间断Galerkin方法应用于Stokes-Brinkman型特征值问题，并结合内罚策略。其重要性体现在为多孔介质中的流动问题提供了新的数值近似工具。理论分析严谨，结合了稳定性、收敛性和误差估计，并通过计算分析验证了方法的有效性及参数影响。"}}
{"id": "2507.11984", "title": "Dataset-Adaptive Dimensionality Reduction", "authors": ["Hyeon Jeon", "Jeongin Park", "Soohyun Lee", "Dae Hyun Kim", "Sungbok Shin", "Jinwook Seo"], "categories": ["cs.HC", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      IEEE VIS 2025 & IEEE Transactions on Visualization and Computer Graphics (TVCG)", "url": "http://arxiv.org/abs/2507.11984v1", "summary": "Selecting the appropriate dimensionality reduction (DR) technique and\ndetermining its optimal hyperparameter settings that maximize the accuracy of\nthe output projections typically involves extensive trial and error, often\nresulting in unnecessary computational overhead. To address this challenge, we\npropose a dataset-adaptive approach to DR optimization guided by structural\ncomplexity metrics. These metrics quantify the intrinsic complexity of a\ndataset, predicting whether higher-dimensional spaces are necessary to\nrepresent it accurately. Since complex datasets are often inaccurately\nrepresented in two-dimensional projections, leveraging these metrics enables us\nto predict the maximum achievable accuracy of DR techniques for a given\ndataset, eliminating redundant trials in optimizing DR. We introduce the design\nand theoretical foundations of these structural complexity metrics. We\nquantitatively verify that our metrics effectively approximate the ground truth\ncomplexity of datasets and confirm their suitability for guiding\ndataset-adaptive DR workflow. Finally, we empirically show that our\ndataset-adaptive workflow significantly enhances the efficiency of DR\noptimization without compromising accuracy.", "comment": "IEEE VIS 2025 & IEEE Transactions on Visualization and Computer\n  Graphics (TVCG)", "pdf_url": "http://arxiv.org/pdf/2507.11984v1", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "数据集自适应降维", "tldr": "本文提出了一种基于结构复杂性度量的数据集自适应降维优化方法，旨在减少试错并提高效率。", "motivation": "选择合适的降维技术及其最优超参数通常需要大量的试错，导致不必要的计算开销，影响输出投影的准确性。", "method": "提出了一种由结构复杂性度量引导的数据集自适应降维优化方法。这些度量量化数据集的内在复杂性，预测是否需要更高维空间来准确表示，并预测给定数据集的降维技术可达到的最大准确性，从而消除冗余的优化试验。", "result": "定量验证了所提出的度量能有效近似数据集的真实复杂性，并证实其适用于指导数据集自适应降维工作流程。实证表明，该数据集自适应工作流程显著提高了降维优化的效率，同时不损害准确性。", "conclusion": "本文提出的结构复杂性度量能够有效指导数据集自适应降维优化，显著提高效率并保持准确性，解决了传统降维优化中试错带来的计算开销问题。", "translation": "选择合适的降维（DR）技术并确定其最优超参数设置以最大化输出投影的准确性，通常涉及大量的试错，这往往导致不必要的计算开销。为了解决这一挑战，我们提出了一种由结构复杂性度量引导的数据集自适应降维优化方法。这些度量量化了数据集的内在复杂性，预测是否需要更高维空间来准确表示它。由于复杂数据集在二维投影中常常表示不准确，利用这些度量使我们能够预测给定数据集的降维技术可达到的最大准确性，从而消除降维优化中的冗余试验。我们介绍了这些结构复杂性度量的设计和理论基础。我们定量验证了我们的度量能有效近似数据集的真实复杂性，并证实它们适用于指导数据集自适应降维工作流程。最后，我们通过实证表明，我们的数据集自适应工作流程显著提高了降维优化的效率，同时不损害准确性。", "summary": "本文提出了一种创新的数据集自适应降维优化方法，通过引入结构复杂性度量来量化数据集的内在复杂性。这些度量能够预测数据集准确表示所需的维度以及降维技术可实现的最大准确性，从而避免了传统方法中耗时的试错过程。研究表明，该方法能够有效近似数据集的真实复杂性，并显著提高降维优化的效率，同时保持了高准确性。", "keywords": "降维, 数据集自适应, 结构复杂性, 优化, 效率", "comments": "本文的创新点在于提出了基于结构复杂性度量的数据集自适应降维方法，有效解决了传统降维优化中耗时且计算量大的试错问题。通过预测数据集的内在复杂性和降维准确性上限，该方法显著提升了效率，同时保证了结果的准确性，对实际应用具有重要价值。"}}
{"id": "2410.15607", "title": "Reinforced Imitative Trajectory Planning for Urban Automated Driving", "authors": ["Di Zeng", "Ling Zheng", "Xiantong Yang", "Yinong Li"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      21 pages, 9 figures", "url": "http://arxiv.org/abs/2410.15607v2", "summary": "Reinforcement learning (RL) faces challenges in trajectory planning for urban\nautomated driving due to the poor convergence of RL and the difficulty in\ndesigning reward functions. Consequently, few RL-based trajectory planning\nmethods can achieve performance comparable to that of imitation learning-based\nmethods. The convergence problem is alleviated by combining RL with supervised\nlearning. However, most existing approaches only reason one step ahead and lack\nthe capability to plan for multiple future steps. Besides, although inverse\nreinforcement learning holds promise for solving the reward function design\nissue, existing methods for automated driving impose a linear structure\nassumption on reward functions, making them difficult to apply to urban\nautomated driving. In light of these challenges, this paper proposes a novel\nRL-based trajectory planning method that integrates RL with imitation learning\nto enable multi-step planning. Furthermore, a transformer-based Bayesian reward\nfunction is developed, providing effective reward signals for RL in urban\nscenarios. Moreover, a hybrid-driven trajectory planning framework is proposed\nto enhance safety and interpretability. The proposed methods were validated on\nthe large-scale real-world urban automated driving nuPlan dataset. Evaluated\nusing closed-loop metrics, the results demonstrated that the proposed method\nsignificantly outperformed the baseline employing the identical policy model\nstructure and achieved competitive performance compared to the state-of-the-art\nmethod. The code is available at https://github.com/Zigned/nuplan_zigned.", "comment": "21 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2410.15607v2", "cate": "cs.RO", "date": "2024-10-21", "updated": "2025-07-16", "AI": {"title_translation": "城市自动驾驶中的强化模仿轨迹规划", "tldr": "本文提出了一种用于城市自动驾驶的强化学习（RL）轨迹规划新方法，通过结合RL与模仿学习实现多步规划，并引入基于Transformer的贝叶斯奖励函数和混合驱动框架。该方法在nuPlan数据集上表现出竞争性。", "motivation": "强化学习（RL）在城市自动驾驶轨迹规划中面临挑战，主要表现为收敛性差和奖励函数设计困难。现有RL方法难以与模仿学习方法匹敌，且多为单步规划。此外，逆强化学习虽有潜力，但其线性奖励函数假设不适用于复杂的城市自动驾驶场景。", "method": "本文提出了一种新颖的RL轨迹规划方法，该方法将RL与模仿学习相结合以实现多步规划。此外，开发了一种基于Transformer的贝叶斯奖励函数，为城市场景中的RL提供有效的奖励信号。还提出了一种混合驱动的轨迹规划框架，以增强安全性和可解释性。这些方法在nuPlan数据集上进行了验证。", "result": "在大型真实世界城市自动驾驶nuPlan数据集上，使用闭环指标评估，所提出的方法显著优于采用相同策略模型结构的基线方法，并与最先进的方法相比取得了有竞争力的性能。", "conclusion": "本文提出的强化模仿轨迹规划方法，通过整合强化学习与模仿学习，并引入基于Transformer的贝叶斯奖励函数和混合驱动框架，有效解决了城市自动驾驶轨迹规划中的多步规划和奖励函数设计难题，取得了有竞争力的性能。", "translation": "强化学习（RL）在城市自动驾驶轨迹规划中面临挑战，原因在于RL收敛性差以及奖励函数设计困难。因此，很少有基于RL的轨迹规划方法能达到与基于模仿学习的方法相媲美的性能。通过将RL与监督学习结合可以缓解收敛性问题。然而，大多数现有方法仅能进行一步推理，缺乏规划多个未来步骤的能力。此外，尽管逆强化学习有望解决奖励函数设计问题，但现有用于自动驾驶的方法对奖励函数施加了线性结构假设，使其难以应用于城市自动驾驶。鉴于这些挑战，本文提出了一种新颖的基于RL的轨迹规划方法，将RL与模仿学习相结合以实现多步规划。此外，开发了一种基于Transformer的贝叶斯奖励函数，为城市场景中的RL提供有效的奖励信号。此外，还提出了一种混合驱动的轨迹规划框架，以增强安全性和可解释性。所提出的方法在大型真实世界城市自动驾驶nuPlan数据集上进行了验证。使用闭环指标评估，结果表明所提出的方法显著优于采用相同策略模型结构的基线，并与最先进的方法相比取得了有竞争力的性能。代码可在https://github.com/Zigned/nuplan_zigned获取。", "summary": "本文针对城市自动驾驶中强化学习（RL）轨迹规划面临的收敛性差、奖励函数设计困难以及单步规划的局限性，提出了一种新颖的RL轨迹规划方法。该方法将RL与模仿学习相结合以实现多步规划，并引入了基于Transformer的贝叶斯奖励函数来提供有效的奖励信号。此外，还提出了一个混合驱动的框架以增强安全性和可解释性。在nuPlan数据集上的闭环评估结果表明，所提方法显著优于基线，并与现有最先进方法具有竞争性表现。", "keywords": "强化学习, 模仿学习, 轨迹规划, 城市自动驾驶, 贝叶斯奖励函数", "comments": "本文的创新之处在于将强化学习与模仿学习相结合，以解决城市自动驾驶中多步轨迹规划的挑战，并引入了基于Transformer的贝叶斯奖励函数来克服奖励设计难题。此外，混合驱动框架的提出，提升了自动驾驶系统在实际应用中的安全性和可解释性。在大型真实世界数据集nuPlan上的验证进一步证明了其重要性。"}}
{"id": "2507.12432", "title": "Energy-based models for inverse imaging problems", "authors": ["Andreas Habring", "Martin Holler", "Thomas Pock", "Martin Zach"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12432v1", "summary": "In this chapter we provide a thorough overview of the use of energy-based\nmodels (EBMs) in the context of inverse imaging problems. EBMs are probability\ndistributions modeled via Gibbs densities $p(x) \\propto \\exp{-E(x)}$ with an\nappropriate energy functional $E$. Within this chapter we present a rigorous\ntheoretical introduction to Bayesian inverse problems that includes results on\nwell-posedness and stability in the finite-dimensional and infinite-dimensional\nsetting. Afterwards we discuss the use of EBMs for Bayesian inverse problems\nand explain the most relevant techniques for learning EBMs from data. As a\ncrucial part of Bayesian inverse problems, we cover several popular algorithms\nfor sampling from EBMs, namely the Metropolis-Hastings algorithm, Gibbs\nsampling, Langevin Monte Carlo, and Hamiltonian Monte Carlo. Moreover, we\npresent numerical results for the resolution of several inverse imaging\nproblems obtained by leveraging an EBM that allows for the explicit\nverification of those properties that are needed for valid energy-based\nmodeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12432v1", "cate": "eess.IV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "逆成像问题的能量基模型", "tldr": "本章全面概述了能量基模型（EBMs）在逆成像问题中的应用，涵盖了贝叶斯逆问题的理论基础、EBMs的学习与采样技术以及数值验证。", "motivation": "提供能量基模型（EBMs）在逆成像问题中应用的全面概述。", "method": "本章首先对贝叶斯逆问题进行了严格的理论介绍，包括有限维和无限维设置下的适定性和稳定性。然后，讨论了EBMs在贝叶斯逆问题中的应用，解释了从数据中学习EBMs的最相关技术，并涵盖了Metropolis-Hastings算法、Gibbs采样、Langevin Monte Carlo和Hamiltonian Monte Carlo等多种EBMs采样算法。", "result": "展示了通过利用允许明确验证有效能量基建模所需属性的EBM，解决多个逆成像问题获得的数值结果。", "conclusion": "本章全面介绍了能量基模型在逆成像问题中的应用，提供了坚实的理论基础、实用的学习与采样方法以及数值验证，证明了EBMs在该领域的潜力。", "translation": "在本章中，我们全面概述了能量基模型（EBMs）在逆成像问题中的应用。EBMs是通过Gibbs密度 $p(x) \\propto \\exp{-E(x)}$ 和适当的能量泛函 $E$ 建模的概率分布。在本章中，我们对贝叶斯逆问题进行了严格的理论介绍，其中包括有限维和无限维设置下的适定性和稳定性结果。之后，我们讨论了EBMs在贝叶斯逆问题中的应用，并解释了从数据中学习EBMs的最相关技术。作为贝叶斯逆问题的一个关键部分，我们涵盖了几种流行的EBMs采样算法，即Metropolis-Hastings算法、Gibbs采样、Langevin Monte Carlo和Hamiltonian Monte Carlo。此外，我们还展示了通过利用一个允许明确验证有效能量基建模所需属性的EBM，解决多个逆成像问题获得的数值结果。", "summary": "本章深入探讨了能量基模型（EBMs）在逆成像问题中的应用。文章首先严格介绍了贝叶斯逆问题的理论基础，包括适定性和稳定性。随后，详细阐述了如何将EBMs应用于贝叶斯逆问题，并介绍了从数据中学习EBMs的关键技术。文章还覆盖了多种重要的EBM采样算法，如Metropolis-Hastings、Gibbs采样、Langevin Monte Carlo和Hamiltonian Monte Carlo。最后，通过数值结果展示了EBM在解决实际逆成像问题中的有效性。", "keywords": "能量基模型, 逆成像问题, 贝叶斯逆问题, 采样算法, Gibbs密度", "comments": "这篇文献作为一篇综述性质的章节，为读者提供了能量基模型在逆成像问题中应用的全面理论和实践指导。其重要性在于系统地整合了EBMs与贝叶斯逆问题的理论框架，并详细介绍了相关的学习和采样算法，对于理解和应用EBMs解决复杂逆问题具有重要的参考价值。文章强调了数值验证，增强了内容的实用性。"}}
{"id": "2507.11891", "title": "Choosing the Better Bandit Algorithm under Data Sharing: When Do A/B Experiments Work?", "authors": ["Shuangning Li", "Chonghuan Wang", "Jingyan Wang"], "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11891v1", "summary": "We study A/B experiments that are designed to compare the performance of two\nrecommendation algorithms. Prior work has shown that the standard\ndifference-in-means estimator is biased in estimating the global treatment\neffect (GTE) due to a particular form of interference between experimental\nunits. Specifically, units under the treatment and control algorithms\ncontribute to a shared pool of data that subsequently train both algorithms,\nresulting in interference between the two groups. The bias arising from this\ntype of data sharing is known as \"symbiosis bias\". In this paper, we highlight\nthat, for decision-making purposes, the sign of the GTE often matters more than\nits precise magnitude when selecting the better algorithm. We formalize this\ninsight under a multi-armed bandit framework and theoretically characterize\nwhen the sign of the expected GTE estimate under data sharing aligns with or\ncontradicts the sign of the true GTE. Our analysis identifies the level of\nexploration versus exploitation as a key determinant of how symbiosis bias\nimpacts algorithm selection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11891v1", "cate": "stat.ML", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "数据共享下选择更好的Bandit算法：A/B实验何时有效？", "tldr": "在数据共享环境下，A/B实验中由于共生偏差导致的全局处理效应（GTE）估计偏差是一个问题。本文在多臂赌博机框架下理论分析了何时GTE估计的符号与真实GTE符号一致，发现探索与利用的程度是关键决定因素。", "motivation": "在比较推荐算法的A/B实验中，由于实验单元之间的数据共享导致干扰，标准的均值差估计器在估计全局处理效应（GTE）时存在偏差，这种偏差被称为“共生偏差”。对于决策目的而言，选择更好的算法时GTE的符号往往比其精确大小更重要，因此需要理解何时A/B实验中的估计符号是可靠的。", "method": "本文在多臂赌博机框架下，理论上描述了在数据共享条件下，预期GTE估计的符号何时与真实GTE的符号一致或矛盾。", "result": "分析表明，探索与利用的程度是决定共生偏差如何影响算法选择的关键因素。", "conclusion": "在数据共享的A/B实验中，共生偏差会影响全局处理效应（GTE）估计的准确性。对于算法选择而言，GTE符号的正确性至关重要。本文通过理论分析揭示了探索与利用的水平是影响共生偏差对算法选择影响的关键决定因素，从而帮助理解何时A/B实验在这种复杂环境下仍然有效。", "translation": "我们研究了旨在比较两种推荐算法性能的A/B实验。先前的研究表明，由于实验单元之间特定形式的干扰，标准的均值差估计器在估计全局处理效应（GTE）时存在偏差。具体来说，处理组和对照组的单元都对共享数据池做出贡献，而该数据池随后会训练这两种算法，从而导致两组之间的干扰。这种数据共享引起的偏差被称为“共生偏差”。在本文中，我们强调，出于决策目的，在选择更好的算法时，GTE的符号通常比其精确大小更重要。我们在多臂赌博机框架下形式化了这一见解，并从理论上描述了在数据共享条件下，预期GTE估计的符号何时与真实GTE的符号一致或矛盾。我们的分析将探索与利用的程度识别为共生偏差如何影响算法选择的关键决定因素。", "summary": "本文研究了在数据共享环境下进行A/B实验时，如何选择更好的推荐算法。由于数据共享导致“共生偏差”，标准的全局处理效应（GTE）估计器存在偏差。作者指出，在算法选择中，GTE的符号比其精确大小更重要。通过在多臂赌博机框架下的理论分析，本文揭示了探索与利用的程度是决定共生偏差如何影响算法选择的关键因素，从而解释了A/B实验在这种特定干扰下何时能有效指导决策。", "keywords": "A/B实验, 数据共享, 共生偏差, 多臂赌博机, 算法选择", "comments": "该论文创新性地将A/B实验中数据共享引起的“共生偏差”问题与多臂赌博机框架相结合，并聚焦于GTE估计的“符号”而非“大小”，这对于实际决策具有重要意义。它强调了探索与利用策略在缓解或加剧偏差影响中的作用，为在复杂互动环境中设计和解释A/B实验提供了新的理论见解。"}}
{"id": "2507.06273", "title": "Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain", "authors": ["S P Shivakumar", "Gunisetty Ramasekhar", "P Nimmy", "Sujesh Areekara", "L Thanuja", "T V Smitha", "S Devanathan", "Ganesh R Naik", "K V Nagaraja"], "categories": ["physics.med-ph", "cs.AI", "cs.NA", "math.NA", "physics.bio-ph"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06273v2", "summary": "The increasing complexity of cardiovascular diseases and limitations in\ntraditional healing methods mandate the invention of new drug delivery systems\nthat assure targeted, effective, and regulated treatments, contributing\ndirectly to UN SDGs 3 and 9, thereby encouraging the utilization of sustainable\nmedical technologies in healthcare. This study investigates the flow of a\nCasson-Maxwell nanofluid through a stenosed arterial domain. The quantities,\nsuch as skin friction and heat transfer rate, are analysed in detail. The\nCasson-Maxwell fluid shows a lower velocity profile than the Casson fluids,\nwhich indicates the improved residence time for efficient drug delivery. The\nheat transfer rate shows an increase with higher volume fractions of copper and\naluminium oxide nanoparticles and a decrease with higher volume fractions of\nsilver nanoparticles. The skin friction coefficient decreases by 219% with a\nunit increase in the Maxwell parameter, whereas it increases by 66.1% with a\nunit rise in the Casson parameter. This work supports SDGs 4 and 17 by\nfostering interdisciplinary learning and collaboration in fluid dynamics and\nhealthcare innovation. Additionally, the rate of heat flow was forecasted (with\nan overall R-value of 0.99457) using the Levenberg-Marquardt backpropagation\ntraining scheme under the influence of magneto-radiative, linear heat source\nand Casson-Maxwell parameters along with the tri-metallic nanoparticle volume\nfractions. It is also observed that the drag coefficient is most sensitive to\nthe changes in the Maxwell parameter.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06273v2", "cate": "physics.med-ph", "date": "2025-07-08", "updated": "2025-07-16", "AI": {"title_translation": "狭窄动脉域中生物流体流动的磁辐射建模与人工神经网络优化", "tldr": "本研究利用磁辐射建模和人工神经网络优化，分析了狭窄动脉中生物流体（Casson-Maxwell纳米流体）的流动特性，旨在改进药物输送系统。", "motivation": "心血管疾病日益复杂，传统治疗方法存在局限性，因此需要发明新的药物输送系统，以确保靶向、有效和受控的治疗，从而支持联合国可持续发展目标3和9，鼓励在医疗保健中使用可持续医疗技术。", "method": "本研究调查了Casson-Maxwell纳米流体通过狭窄动脉域的流动。详细分析了皮肤摩擦和传热速率等量。此外，利用Levenberg-Marquardt反向传播训练方案，在磁辐射、线性热源和Casson-Maxwell参数以及三金属纳米颗粒体积分数的影响下，预测了热流速率（总R值达到0.99457）。", "result": "Casson-Maxwell流体表现出比Casson流体更低的流速剖面，这表明其具有更长的停留时间，有利于高效药物输送。传热速率随铜和氧化铝纳米颗粒体积分数的增加而增加，随银纳米颗粒体积分数的增加而减少。皮肤摩擦系数随麦克斯韦参数的单位增加而减少219%，而随卡森参数的单位增加而增加66.1%。拖曳系数对麦克斯韦参数的变化最敏感。热流速率预测的总R值为0.99457。", "conclusion": "Casson-Maxwell纳米流体在狭窄动脉中的应用有望提高药物输送效率，通过调节流体参数和纳米颗粒种类可有效控制传热和皮肤摩擦。人工神经网络可有效预测热流速率，为生物流体动力学和医疗保健创新提供支持。", "translation": "心血管疾病日益复杂，传统治疗方法的局限性要求发明新的药物输送系统，以确保靶向、有效和受控的治疗，直接促进联合国可持续发展目标3和9，从而鼓励在医疗保健中利用可持续医疗技术。本研究调查了Casson-Maxwell纳米流体通过狭窄动脉域的流动。详细分析了皮肤摩擦和传热速率等量。Casson-Maxwell流体表现出比Casson流体更低的流速剖面，这表明其具有更长的停留时间，有利于高效药物输送。传热速率随铜和氧化铝纳米颗粒体积分数的增加而增加，随银纳米颗粒体积分数的增加而减少。皮肤摩擦系数随麦克斯韦参数的单位增加而减少219%，而随卡森参数的单位增加而增加66.1%。这项工作通过促进流体动力学和医疗保健创新方面的跨学科学习和合作，支持可持续发展目标4和17。此外，在磁辐射、线性热源和Casson-Maxwell参数以及三金属纳米颗粒体积分数的影响下，利用Levenberg-Marquardt反向传播训练方案预测了热流速率（总R值达到0.99457）。还观察到拖曳系数对麦克斯韦参数的变化最敏感。", "summary": "本研究旨在开发新的药物输送系统，以应对心血管疾病的挑战。研究人员通过磁辐射建模和人工神经网络优化，详细分析了Casson-Maxwell纳米流体在狭窄动脉中的流动特性，包括皮肤摩擦和传热速率。研究发现，Casson-Maxwell流体具有更低的流速，有利于药物停留和高效输送。传热速率受纳米颗粒种类和体积分数影响，而皮肤摩擦系数和拖曳系数则对流体参数敏感。此外，利用人工神经网络成功预测了热流速率，R值高达0.99457，表明该方法在生物流体动力学预测中的潜力。", "keywords": "生物流体流动, 狭窄, 纳米流体, 磁辐射, 人工神经网络", "comments": "该论文创新性地将磁辐射建模、Casson-Maxwell纳米流体和人工神经网络相结合，用于优化狭窄动脉中的生物流体流动，以期改进药物输送系统。其对流体参数、纳米颗粒种类对流速、传热和皮肤摩擦影响的详细分析，以及ANN在热流预测中获得的高精度，都体现了其重要的理论和应用价值。特别强调对联合国可持续发展目标的贡献，提升了研究的社会意义。"}}
